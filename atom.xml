<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-12-04T17:21:56Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4430</id>
    <link href="https://lucatrevisan.wordpress.com/2020/12/04/keith-ball-on-bourgains-legacy-in-geometric-functional-analysis/" rel="alternate" type="text/html"/>
    <title>Keith Ball on Bourgain’s Legacy in Geometric Functional Analysis</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The Bulletin of the AMS has just posted an article by Keith Ball on the legacy of Bourgain’s work on geometric functional analysis. This beautifully written article talks about results and conjectures that are probably familiar to readers of in … <a href="https://lucatrevisan.wordpress.com/2020/12/04/keith-ball-on-bourgains-legacy-in-geometric-functional-analysis/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Bulletin of the AMS has just posted an <a href="https://www.ams.org/journals/bull/0000-000-00/S0273-0979-2020-01719-2/S0273-0979-2020-01719-2.pdf">article by Keith Ball</a> on the legacy of Bourgain’s work on geometric functional analysis. </p>

<p/>

<p>
This beautifully written article talks about results and conjectures that are probably familiar to readers of <i>in theory</i>, but from the perspective of their mathematical motivations and of the bigger picture in which they fit.</p>



<p/></div>
    </content>
    <updated>2020-12-04T13:52:28Z</updated>
    <published>2020-12-04T13:52:28Z</published>
    <category term="math"/>
    <category term="theory"/>
    <category term="Geometric Functional Analysis"/>
    <category term="Jean Bourgain"/>
    <category term="Keith Ball"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2020-12-04T17:20:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/12/04/phd-positions-at-international-max-planck-research-school-on-trustworthy-computing-apply-by-december-31-2020/</id>
    <link href="https://cstheory-jobs.org/2020/12/04/phd-positions-at-international-max-planck-research-school-on-trustworthy-computing-apply-by-december-31-2020/" rel="alternate" type="text/html"/>
    <title>PhD positions  at International Max Planck Research School on Trustworthy Computing (apply by December 31, 2020)</title>
    <summary>The International Max Planck Research School on Trustworthy Computing is a graduate program jointly run by the Max Planck Institutes for Informatics and Software Systems, Saarland University, and TU Kaiserslautern. It offers a fully funded PhD program that leads to a doctoral degree from one of the participating universities and is open to students with […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The International Max Planck Research School on Trustworthy Computing is a graduate program jointly run by the Max Planck Institutes for Informatics and Software Systems, Saarland University, and TU Kaiserslautern. It offers a fully funded PhD program that leads to a doctoral degree from one of the participating universities and is open to students with a degree in computer science or equivalent.</p>
<p>Website: <a href="https://www.imprs-trust.mpg.de/">https://www.imprs-trust.mpg.de/</a><br/>
Email: imprs@mpi-klsb.mpg.de</p></div>
    </content>
    <updated>2020-12-04T12:53:37Z</updated>
    <published>2020-12-04T12:53:37Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-04T17:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7948</id>
    <link href="https://windowsontheory.org/2020/12/03/obfuscation-the-season-4-finale/" rel="alternate" type="text/html"/>
    <title>Obfuscation: The season 4 Finale</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">For many of the famous open problems of theoretical computer science, most researchers agree on what the answer is, but the challenge is to prove it. Most complexity theorists (with few notable exceptions) believe that P≠NP, but we don’t know how to prove it. Similarly, most people working on matrix multiplication believe that there is … <a class="more-link" href="https://windowsontheory.org/2020/12/03/obfuscation-the-season-4-finale/">Continue reading <span class="screen-reader-text">Obfuscation: The season 4 Finale</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p/>



<p>For many of the famous open problems of theoretical computer science, most researchers agree on what the answer is, but the challenge is to <em>prove </em>it. Most complexity theorists (with few notable exceptions) believe that P≠NP, but we don’t know how to prove it. Similarly, most people working on matrix multiplication believe that there is an Õ(n²) algorithm for this problem, but we’re still stuck at <a href="https://arxiv.org/abs/2010.05846">2.3728596</a>.   We believed that primality checking has a deterministic polynomial-time algorithm long before it was <a href="https://en.wikipedia.org/wiki/AKS_primality_test">proven </a>and we still believe the same holds for polynomial identity testing.</p>



<p>The story of <em>cryptographic obfuscation</em> is different. This story deserves a full length blog post (though see my now outdated <a href="https://cacm.acm.org/magazines/2016/3/198855-hopes-fears-and-software-obfuscation/fulltext">survey</a>), but the short version is as follows. In 2001 we (in a <a href="http://www.wisdom.weizmann.ac.il/~oded/p_obfuscate.html">paper </a>with Goldreich, Impagliazzo, Rudich, Sahai, Vadhan, and Yang) showed that what is arguably the most natural definition of obfuscation is impossible to achieve. That paper explored a number of obfuscation-related questions, and in particular left as an open question the existence of so-called <em>indistinguishable obfuscators</em> or <em>IO</em>. Since then there were arguably more negative than positive results in obfuscation research until in 2012, extending some of the ideas behind fully-homomorphic encryption, <a href="https://eprint.iacr.org/2012/610">Garg Gentry and Halevi</a> gave a heuristic construction of multilinear map, which one can think of as “Diffie Hellman on steroids” (or maybe LSD..). Then in 2013 <a href="https://eprint.iacr.org/2013/451">Garg, Gentry, Halevi., Raykova, Sahai and Waters (GGHRSW)</a> built on top of these maps to give a heuristic construction of IO. </p>



<p>The GGHRSW paper opened the floodgates to many papers using IO to achieve many longstanding cryptographic goals as well as show that IO provides a unified approach to solve many classic cryptographic problems. The fact that so many goals were achieved through heuristic constructions was not very comforting to cryptographers. Even less comforting was the fact that several cryptographic attacks were discovered on these heuristic constructions. The years that followed saw a sequence of constructions and breaks,  giving cryptographers an “emotional whiplash”.  Everyone agreed that IO would be amazing if it exists, but whether or not it actually exists depended on who you asked, and what paper in the eprint archive they read that morning…</p>



<p>The “holy grail” in this line of work is to base obfuscation on a standard assumption, and ideally Regev’s <a href="https://en.wikipedia.org/wiki/Learning_with_errors">Learning With Errors (LWE)</a> assumption. Of course, we don’t know that LWE is true (in particular LWE implies P≠NP) but if it’s false it would bring down so much of the field that cryptographers might as well pack their bags and do machine learning (or try to sabotage progress in quantum computing, since the only other standard <a href="https://eprint.iacr.org/2017/365">assumptions for public-key crypto</a> are broken by fully scalable quantum computing).</p>



<p>We have not yet achieved this holy grail (this is only the 4th season) but as described in <a href="https://www.quantamagazine.org/computer-scientists-achieve-crown-jewel-of-cryptography-20201110/">this quanta article</a>, there has been a remarkable progress in the last few months. In particular, <a href="https://eprint.iacr.org/2020/1003">Jain, Lin and Sahai (JLS)</a>  (building on a long sequence of works by  many people including Ananth, Matt, Tessaro and Vaikuntanathan) obtained IO based on LWE and several standard assumptions in cryptography. This is arguably the first “heuristic free” construction, and is a fantastic breakthrough. However, there is still work to do – the JLS construction uses not just LWE but also a variant of it that is not as well studied. It is also based on pairing-based cryptography. This is an area that has thousands of papers, but for which known instantiations can be broken by quantum computers.  However, there is yet more hope – in another  sequence of works by <a href="https://eprint.iacr.org/2018/633">Agrawal</a>, <a href="https://eprint.iacr.org/2020/1024">Brakerski, Döttling, Garg, and Malavolta</a>, <a href="https://eprint.iacr.org/2020/1042">Wee and Wichs</a>, <a href="https://eprint.iacr.org/2020/1010">Gay and Pass</a> a construction of IO was achieved that is “almost” heuristic free. It still uses one heuristic assumption (circular security) but has the advantage that apart from this assumption it only relies on LWE. </p>



<p>One can hope that in the next season, these two lines of work will converge to give a construction of IO based on LWE, achieving a “meta theorem” deriving from LWE a huge array of cryptographic primitives.</p>



<p>Want to learn more about these amazing advances? Want to know what’s next in store for IO? <br/><br/>Fortunately there is a virtual <a href="https://simons.berkeley.edu/workshops/obfuscation-symposium">Simons symposium on indistinguishability obfuscation</a> <strong>coming to your computer screen on December 10-11</strong>. Authors of all the papers mentioned will join together in coordinated presentations to give a unified view of the field and the challenges ahead. We will also have a historical opening talk by Yael Kalai, as well as a talk by Benny Applebaum on the computational assumptions used, followed by a panel discussion with Yael, Benny and Chris Peikert. Finally, like every proper crypto event, there will be a rump session, though you will have to supply your own beer.</p>



<p>See the <a href="https://simons.berkeley.edu/workshops/obfuscation-symposium">schedule of the workshop</a> and you can register on <a href="https://simons.berkeley.edu/workshops/obfuscation-symposium">this page</a>.</p>



<p>Hope you to see you there! Bring your favorite programs to obfuscate with you*<br/><br/>*<sub>Disclaimer/fine print: Due to large constants and exponents, we do not recommend the compiler be used on programs that are more than one nanobit long.</sub></p>



<p>Image credit: <a href="https://news.mit.edu/2015/secure-foundation-any-cryptographic-system-1028">MIT</a></p></div>
    </content>
    <updated>2020-12-04T00:30:44Z</updated>
    <published>2020-12-04T00:30:44Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-12-04T17:21:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5122</id>
    <link href="https://www.scottaaronson.com/blog/?p=5122" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5122#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5122" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Quantum supremacy, now with BosonSampling</title>
    <summary xml:lang="en-US">A group led by Jianwei Pan and Chao-Yang Lu, based mainly at USTC in Hefei, China, announced today that it achieved BosonSampling with 40-70 detected photons—up to and beyond the limit where a classical supercomputer could feasibly verify the results. (Technically, they achieved a variant called Gaussian BosonSampling: a generalization of what I called Scattershot […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>A group led by <a href="https://en.wikipedia.org/wiki/Pan_Jianwei">Jianwei Pan</a> and Chao-Yang Lu, based mainly at USTC in Hefei, China, announced today that it <a href="https://science.sciencemag.org/lookup/doi/10.1126/science.abe8770">achieved BosonSampling with 40-70 detected photons</a>—up to and beyond the limit where a classical supercomputer could feasibly verify the results.  (Technically, they achieved a variant called <a href="https://arxiv.org/abs/1612.01199">Gaussian BosonSampling</a>: a generalization of what I called <a href="https://www.scottaaronson.com/blog/?p=1579">Scattershot BosonSampling</a> in a 2013 post on this blog.)</p>



<p>For more, see also <a href="https://www.sciencenews.org/article/new-light-based-quantum-computer-jiuzhang-supremacy">Emily Conover’s piece in <em>Science News</em></a>, or <a href="https://www.scientificamerican.com/article/light-based-quantum-computer-exceeds-fastest-classical-supercomputers/">Daniel Garisto’s in <em>Scientific American</em></a>, both of which I consulted on.  (Full disclosure: I was one of the reviewers for the Pan group’s <em>Science</em> paper, and will be writing the Perspective article to accompany it.)</p>



<p>The new result follows the <a href="https://arxiv.org/abs/1910.09930">announcement</a> of 14-photon BosonSampling by the same group a year ago.  It represents the second time quantum supremacy has been reported, following Google’s celebrated <a href="https://www.scottaaronson.com/blog/?p=4317">announcement</a> from last year, and the first time it’s been done using photonics rather than superconducting qubits.</p>



<p>As the co-inventor of <a href="https://www.scottaaronson.com/papers/optics.pdf">BosonSampling</a> (with Alex Arkhipov), obviously I’m gratified about this.</p>



<p>For anyone who regards it as boring or obvious, <a href="https://www.scottaaronson.com/blog/?p=2435#comment-798278">here</a> and <a href="https://www.scottaaronson.com/blog/?p=1579#comment-92034">here</a> is Gil Kalai<a href="http://gilkalai.wordpress.com/">,</a> on this blog, telling me why BosonSampling would never scale beyond 8-10 photons.  (He wrote that, if aliens forced us to try, then much like with the <a href="https://en.wikipedia.org/wiki/Ramsey%27s_theorem">Ramsey number</a> R(6,6), our only hope would be to attack the aliens.)  <a href="https://www.youtube.com/watch?v=oR-ufBz13Eg">Here’s </a>Kalai making a similar prediction, on the impossibility of quantum supremacy by BosonSampling or any other means, in his plenary address to the International Congress of Mathematicians two years ago.</p>



<p>Even if we set aside the quantum computing skeptics, many colleagues told me they thought experimental BosonSampling was a dead end, because of photon losses and the staggering difficulty of synchronizing 50-100 single-photon sources.  They said that a convincing demonstration of quantum supremacy would have to await the arrival of <a href="https://en.wikipedia.org/wiki/Quantum_threshold_theorem">quantum fault-tolerance</a>—or at any rate, some hardware platform more robust than photonics.  I always agreed that they might be right.  Furthermore, even if 50-photon BosonSampling <em>was</em> possible, after Google reached the supremacy milestone first with superconducting qubits, it wasn’t clear if anyone would still bother.  Even when I learned a year ago about the USTC group’s intention to go for it, I was skeptical, figuring I’d believe it when I saw the paper.</p>



<p>Obviously the new result isn’t dispositive.  Maybe Gil Kalai really WON, BY A LOT, before Hugo Chávez hacked the Pan group’s computers to make it seem otherwise?  (Sorry, couldn’t resist.)  Nevertheless, as someone whose intellectual origins are close to pure math, it’s strange and exciting to find myself in a field where, once in a while, the world itself gets to weigh in on a theoretical disagreement.</p>



<p>Since excitement is best when paired with accurate understanding, please help yourself to the following FAQ, which I might add more to over the next couple days.</p>



<p><strong>What is BosonSampling?</strong>  You must be new here!  In increasing order of difficulty, <a href="https://news.mit.edu/2011/quantum-experiment-0302">here’s</a> an <em>MIT News</em> article from back in 2011, <a href="https://en.wikipedia.org/wiki/Boson_sampling">here’s</a> the Wikipedia page, <a href="http://www.scottaaronson.com/talks/bbn.ppt">here</a> are my PowerPoint slides, <a href="https://www.scottaaronson.com/blog/?p=1631">here</a> are my lecture notes from Rio de Janeiro, <a href="https://www.scottaaronson.com/papers/optics.pdf">here’s</a> my original paper with Arkhipov… </p>



<p><strong>What is quantum supremacy?</strong>  Roughly, the use of a programmable or configurable quantum computer to solve <em>some</em> well-defined computational problem much faster than we know how to solve it with any existing classical computer.  “Quantum supremacy,” a term <a href="https://arxiv.org/abs/1203.5813">coined</a> by John Preskill in 2012, does <em>not</em> mean useful QC, or universal QC, or scalable QC, or fault-tolerant QC, all of which remain outstanding challenges.  For more, see my <a href="https://www.scottaaronson.com/blog/?p=4317">Supreme Quantum Supremacy FAQ</a>, or (e.g.) my recent <a href="https://www.youtube.com/watch?v=ZLhyTFk-WGs">Lytle Lecture</a> for the University of Washington.</p>



<p><strong>If Google already announced quantum supremacy a year ago, what’s the point of this new experiment?</strong>  To me, at least, quantum supremacy seems important enough to do at least twice!  Also, as I said, this represents the first demonstration that quantum supremacy is possible <em>via photonics</em>.  Finally, as the authors point out, the new experiment has one big technical advantage over Google’s: namely, many more possible output states (~10<sup>30</sup> of them, rather than a mere ~9 quadrillion).  This makes it infeasible to calculate the whole probability distribution over outputs and store it on a gigantic hard disk (after which one could easily generate as many samples as one wanted), which is what IBM proposed doing in its <a href="https://arxiv.org/abs/1910.09534">response</a> to Google’s announcement.</p>



<p><strong>Is BosonSampling a form of universal quantum computing?</strong>  No, we don’t even think it can simulate universal <em>classical</em> computing!  It’s designed for exactly one task: namely, demonstrating quantum supremacy and refuting Gil Kalai.  It <em>might</em> have some other applications besides that, but if so, they’ll be icing on the cake.  This is in contrast to Google’s Sycamore processor, which in principle <em>is</em> a universal quantum computer, just with a severe limit on the number of qubits (53) and how many layers of gates one can apply to them (about 20).</p>



<p><strong>Is BosonSampling at least a <em>step</em> toward universal quantum computing?</strong>  I think so!  In 2000, Knill, Laflamme, and Milburn (KLM) <a href="https://en.wikipedia.org/wiki/KLM_protocol">famously showed</a> that pure, non-interacting photons, passing through a network of beamsplitters, are capable of universal QC, provided we assume one extra thing: namely, the ability to measure the photons at intermediate times, and change which beamsplitters to apply to the remaining photons depending on the outcome.  In other words, “BosonSampling plus adaptive measurements equals universality.”  Basically, KLM is the holy grail that experimental optics groups around the world have been working toward for 20 years, with BosonSampling just a more achievable pit stop along the way.</p>



<p><strong>Are there any applications of BosonSampling?</strong>  We don’t know yet.  There are proposals in the literature to apply BosonSampling to quantum chemistry and other fields, but I’m not yet convinced that these proposals will yield real speedups over the best we can do with classical computers, for any task of practical interest that involves estimating specific numbers (as opposed to sampling tasks, where BosonSampling almost certainly <em>does</em> yield exponential speedups, but which are rarely the thing practitioners directly care about).</p>



<p><strong>How hard is it to simulate BosonSampling on a classical computer?</strong>  As far as we know today, the difficulty of simulating a “generic” BosonSampling experiment increases roughly like 2<sup>n</sup>, where n is the number of detected photons.  It <em>might</em> be easier than that, particularly when noise and imperfections are taken into account; and at any rate it might be easier to spoof the statistical tests that one applies to verify the outputs.  I and others managed to give some theoretical evidence against those possibilities, but just like with Google’s experiment, it’s conceivable that some future breakthrough will change the outlook and remove the case for quantum supremacy.</p>



<p><strong>Do you have any amusing stories?</strong>  When I refereed the <em>Science</em> paper, I asked why the authors directly verified the results of their experiment only for up to 26-30 photons, relying on plausible extrapolations beyond that.  While directly verifying the results of n-photon BosonSampling takes ~2<sup>n</sup> time for any known classical algorithm, I said, surely it should be possible with existing computers to go up to n=40 or n=50?  A couple weeks later, the authors responded, saying that they’d now verified their results up to n=40, but it burned $400,000 worth of supercomputer time so they decided to stop there.  This was by far the most expensive referee report I ever wrote!</p>



<p>Also: when Covid first started, and facemasks were plentiful in China but almost impossible to get in the US, Chao-Yang Lu, one of the leaders of the new work and my sometime correspondent on the theory of BosonSampling, decided to mail me a box of 200 masks (I didn’t ask for it).  I don’t think that influenced my later review, but it was appreciated nonetheless.</p>



<p>Huge congratulations to the whole team for their accomplishment!</p></div>
    </content>
    <updated>2020-12-03T22:19:03Z</updated>
    <published>2020-12-03T22:19:03Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-12-04T16:00:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/12/03/postdoc-at-tel-aviv-university-at-tel-aviv-university-apply-by-december-31-2020/</id>
    <link href="https://cstheory-jobs.org/2020/12/03/postdoc-at-tel-aviv-university-at-tel-aviv-university-apply-by-december-31-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at Tel Aviv University at Tel Aviv University (apply by December 31, 2020)</title>
    <summary>I (Gil Cohen) invite applications for a postdoctoral position to start in September 2021 (the exact start date will be flexible). The position will have an initial appointment of one year, but will be extendible to two years. My main research interests right now include randomness extractors, derandomization of space bounded computation, tree codes, coding […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I (Gil Cohen) invite applications for a postdoctoral position to start in September 2021 (the exact start date will be flexible). The position will have an initial appointment of one year, but will be extendible to two years. My main research interests right now include randomness extractors, derandomization of space bounded computation, tree codes, coding theory, and spectral graph theory.</p>
<p>Website: <a href="https://www.gilcohen.org/postdoc2021">https://www.gilcohen.org/postdoc2021</a><br/>
Email: gil@tauex.tau.ac.il</p></div>
    </content>
    <updated>2020-12-03T18:04:18Z</updated>
    <published>2020-12-03T18:04:18Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-04T17:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/12/03/postdoctoral-associate-at-dimacs-at-rutgers-university-apply-by-january-15-2021/</id>
    <link href="https://cstheory-jobs.org/2020/12/03/postdoctoral-associate-at-dimacs-at-rutgers-university-apply-by-january-15-2021/" rel="alternate" type="text/html"/>
    <title>Postdoctoral Associate at DIMACS at Rutgers University (apply by January 15, 2021)</title>
    <summary>DIMACS, the Center for Discrete Mathematics and Theoretical Computer Science, invites applications for postdoctoral associate positions for 2021-2023. Applicants should be recent PhDs with interest in DIMACS areas, including theoretical computer science, discrete mathematics, statistics, operations research, data science, AI, machine learning, and their applications. Website: https://jobs.rutgers.edu/postings/122935 Email: postdoc@dimacs.rutgers.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>DIMACS, the Center for Discrete Mathematics and Theoretical Computer Science, invites applications for postdoctoral associate positions for 2021-2023. Applicants should be recent PhDs with interest in DIMACS areas, including theoretical computer science, discrete mathematics, statistics, operations research, data science, AI, machine learning, and their applications.</p>
<p>Website: <a href="https://jobs.rutgers.edu/postings/122935">https://jobs.rutgers.edu/postings/122935</a><br/>
Email: postdoc@dimacs.rutgers.edu</p></div>
    </content>
    <updated>2020-12-03T18:02:31Z</updated>
    <published>2020-12-03T18:02:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-04T17:20:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3699673705974309715</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3699673705974309715/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/12/chess-is-back.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3699673705974309715" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3699673705974309715" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/12/chess-is-back.html" rel="alternate" type="text/html"/>
    <title>Chess is Back</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Back in 2005, I wrote a post titled <a href="https://blog.computationalcomplexity.org/2005/11/chess-and-poker.html">Chess and Poker</a>. Not really comparing the two but noting that Chess had lost its mojo while poker had high-stakes prime time tournaments. The inspiration was an <a href="https://www.nytimes.com/2005/11/27/opinion/all-the-right-moves.html">NYT Op-Ed</a> that started "CHESS in America is having a crisis". I suggested that computers getting better than humans may have reduced interest in the game. </p><p>Now chess is <a href="https://www.nytimes.com/2020/11/23/arts/television/chess-set-board-sales.html">booming again</a>, due to all of us being stuck at home and the Netflix limited series <a href="https://www.imdb.com/title/tt10048342/">The Queen's Gambit</a> (highly recommended). </p><p>The fictional show takes place in the 1960's when interest in chess in the US started to pick up due to <a href="https://blog.computationalcomplexity.org/2008/01/bobby-fischer-guest-post-by-ken-regan.html">Bobby Fischer's exploits</a> and well before computers played a decent game. Fischer isn't mentioned in the Netflix series, the main character Beth Harmon sort of plays his role. The games themselves, created by Gary Kasparov and others, are even a joy to watch. Check out <a href="https://www.youtube.com/watch?v=oIMaTKOZG-8">this analysis</a> of the final game (spoiler warning). </p><p>The New York Times <a href="https://www.nytimes.com/2012/04/22/crosswords/chess/chess-50-years-of-new-york-times-columns.html">started a chess column</a> in 1962 and ran its <a href="https://www.nytimes.com/2014/10/12/crosswords/chess/after-rocky-start-grand-prix-finds-a-favorite-in-the-lead.html">last column</a> in 2014, though that might be saying more about the state of newspapers than the state of chess.</p><p>What about the computers? They have just gotten so good and with <a href="https://blog.computationalcomplexity.org/2017/12/our-ai-future-good-and-ugly.html">AlphaZero</a> mastering the game with just machine learning on top of the rules of chess, it's not even fun to watch computer versus computer anymore. Now we're back to watching humans and getting back into the games ourselves.</p><p>Computers have opened the door to cheating. Complexity theorist Ken Regan has a <a href="http://www.buffalo.edu/news/experts/ken-regan-faculty-expert-chess.html">side gig</a> reviewing games to determine if a player punching above their weight secretly used a computer algorithm. </p><p>Microsoft just <a href="https://www.microsoft.com/en-us/research/blog/the-human-side-of-ai-for-chess/">announced</a> chess programs that play as a human at various levels of strength. I suppose someone could use a program like this to cheat in a way that even Ken couldn't detect. But mostly it would be like Googling in pub trivia--just takes the fun out of the game.</p></div>
    </content>
    <updated>2020-12-03T14:48:00Z</updated>
    <published>2020-12-03T14:48:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-12-04T09:58:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/180</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/180" rel="alternate" type="text/html"/>
    <title>TR20-180 |  Shrinkage under Random Projections, and Cubic Formula Lower Bounds for $\mathbf{AC}^0$ | 

	Yuval Filmus, 

	Or Meir, 

	Avishay Tal</title>
    <summary>Håstad showed that any De Morgan formula (composed of AND, OR and NOT gates) shrinks by a factor of $O(p^{2})$ under a random restriction that leaves each variable alive independently with probability $p$ [SICOMP, 1998]. Using this result, he gave an $\widetilde{\Omega}(n^{3})$ formula size lower bound for the Andreev function, which, up to lower order improvements, remains the state-of-the-art lower bound for any explicit function.

  In this work, we extend the shrinkage result of Håstad to hold under a far wider family of random restrictions and their generalization — random projections. Based on our shrinkage results, we obtain an $\widetilde{\Omega}(n^{3})$ formula size lower bound for an explicit function computed in $\mathbf{AC}^0$. This improves upon the best known formula size lower bounds for $\mathbf{AC}^0$, that were only quadratic prior to our work. In addition, we prove that the KRW conjecture [Karchmer et al., Computational Complexity 5(3/4), 1995] holds for inner functions for which the unweighted quantum adversary bound is tight. In particular, this holds for inner functions with a tight Khrapchenko bound.

  Our random projections are tailor-made to the function's structure so that the function maintains structure even under projection --- using such projections is necessary, as standard random restrictions simplify $\mathbf{AC}^0$ circuits. In contrast, we show that any De Morgan formula shrinks by a quadratic factor under our random projections, allowing us to prove the cubic lower bound.

  Our proof techniques build on the proof of Håstad for the simpler case of balanced formulas. This allows for a significantly simpler proof at the cost of slightly worse parameters. As such, when specialized to the case of $p$-random restrictions, our proof can be used as an exposition of Håstad's result.</summary>
    <updated>2020-12-03T02:53:05Z</updated>
    <published>2020-12-03T02:53:05Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-12-04T17:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01323</id>
    <link href="http://arxiv.org/abs/2012.01323" rel="alternate" type="text/html"/>
    <title>The Model Counting Competition 2020</title>
    <feedworld_mtime>1606953600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Johannes K. Fichte, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hecher:Markus.html">Markus Hecher</a>, Florim Hamiti <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01323">PDF</a><br/><b>Abstract: </b>Many computational problems in modern society account to probabilistic
reasoning, statistics, and combinatorics. A variety of these real-world
questions can be solved by representing the question in (Boolean) formulas and
associating the number of models of the formula directly with the answer to the
question. Since there has been an increasing interest in practical problem
solving for model counting over the last years, the Model Counting (MC)
Competition was conceived in fall 2019. The competition aims to foster
applications, identify new challenging benchmarks, and to promote new solvers
and improve established solvers for the model counting problem and versions
thereof. We hope that the results can be a good indicator of the current
feasibility of model counting and spark many new applications. In this paper,
we report on details of the Model Counting Competition 2020, about carrying out
the competition, and the results. The competition encompassed three versions of
the model counting problem, which we evaluated in separate tracks. The first
track featured the model counting problem (MC), which asks for the number of
models of a given Boolean formula. On the second track, we challenged
developers to submit programs that solve the weighted model counting problem
(WMC). The last track was dedicated to projected model counting (PMC). In
total, we received a surprising number of 9 solvers in 34 versions from 8
groups.
</p></div>
    </summary>
    <updated>2020-12-03T22:44:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-12-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01276</id>
    <link href="http://arxiv.org/abs/2012.01276" rel="alternate" type="text/html"/>
    <title>Leveraging Unknown Structure in Quantum Query Algorithms</title>
    <feedworld_mtime>1606953600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Noel T. Anderson, Jay-U Chung, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kimmel:Shelby.html">Shelby Kimmel</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01276">PDF</a><br/><b>Abstract: </b>Quantum span program algorithms for function evaluation commonly have reduced
query complexity when promised that the input has a certain structure. We
design a modified span program algorithm to show these speed-ups persist even
without having a promise ahead of time, and we extend this approach to the more
general problem of state conversion. For example, there is a span program
algorithm that decides whether two vertices are connected in an $n$-vertex
graph with $O(n^{3/2})$ queries in general, but with $O(\sqrt{k}n)$ queries if
promised that, if there is a path, there is one with at most $k$ edges. Our
algorithm uses $\tilde{O}(\sqrt{k}n)$ queries to solve this problem if there is
a path with at most $k$ edges, without knowing $k$ ahead of time.
</p></div>
    </summary>
    <updated>2020-12-03T22:43:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-12-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01226</id>
    <link href="http://arxiv.org/abs/2012.01226" rel="alternate" type="text/html"/>
    <title>Parameterized complexity of Bandwidth of Caterpillars and Weighted Path Emulation</title>
    <feedworld_mtime>1606953600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bodlaender:Hans_L=.html">Hans L. Bodlaender</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01226">PDF</a><br/><b>Abstract: </b>In this paper, we show that Bandwidth is hard for the complexity class $W[t]$
for all $t\in {\bf N}$, even for caterpillars with hair length at most three.
As intermediate problem, we introduce the Weighted Path Emulation problem:
given a vertex-weighted path $P_N$ and integer $M$, decide if there exists a
mapping of the vertices of $P_N$ to a path $P_M$, such that adjacent vertices
are mapped to adjacent or equal vertices, and such that the total weight of the
image of a vertex from $P_M$ equals an integer $c$. We show that {\sc Weighted
Path Emulation}, with $c$ as parameter, is hard for $W[t]$ for all $t\in {\bf
N}$, and is strongly NP-complete. We also show that Directed Bandwidth is hard
for $W[t]$ for all $t\in {\bf N}$, for directed acyclic graphs whose underlying
undirected graph is a caterpillar.
</p></div>
    </summary>
    <updated>2020-12-03T22:38:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-12-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01216</id>
    <link href="http://arxiv.org/abs/2012.01216" rel="alternate" type="text/html"/>
    <title>A natural extension to the convex hull problem and a novel solution</title>
    <feedworld_mtime>1606953600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mao:Xiao.html">Xiao Mao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01216">PDF</a><br/><b>Abstract: </b>We study a natural extension to the well-known convex hull problem by
introducing multiplicity: if we are given a set of convex polygons, and we are
allowed to partition the set into multiple components and take the convex hull
of each individual component, what is the minimum total sum of the perimeters
of the convex hulls? We show why this problem is intriguing, and then introduce
a novel algorithm with a run-time cubic in the total number of vertices. In the
case that the input polygons are disjoint, we show an optimization that
achieves a run-time that, in most cases, is cubic in the total number of
polygons, within a logarithmic factor.
</p></div>
    </summary>
    <updated>2020-12-03T22:48:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-12-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01199</id>
    <link href="http://arxiv.org/abs/2012.01199" rel="alternate" type="text/html"/>
    <title>Tractable Combinations of Theories via Sampling</title>
    <feedworld_mtime>1606953600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bodirsky:Manuel.html">Manuel Bodirsky</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Greiner:Johannes.html">Johannes Greiner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01199">PDF</a><br/><b>Abstract: </b>For a first-order theory $T$, the Constraint Satisfaction Problem of $T$ is
the computational problem of deciding whether a given conjunction of atomic
formulas is satisfiable in some model of $T$. In this article we develop
sufficient conditions for polynomial-time tractability of the constraint
satisfaction problem for the union of two theories with disjoint relational
signatures. To this end, we introduce the concept of sampling for theories and
show that samplings can be applied to examples which are not covered by the
seminal result of Nelson and Oppen.
</p></div>
    </summary>
    <updated>2020-12-03T22:37:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-12-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.01085</id>
    <link href="http://arxiv.org/abs/2012.01085" rel="alternate" type="text/html"/>
    <title>Average-case algorithms for testing isomorphism of polynomials, algebras, and multilinear forms</title>
    <feedworld_mtime>1606953600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grochow:Joshua_A=.html">Joshua A. Grochow</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Qiao:Youming.html">Youming Qiao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Gang.html">Gang Tang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.01085">PDF</a><br/><b>Abstract: </b>We study the problems of testing isomorphism of polynomials, algebras, and
multilinear forms. Our first main results are average-case algorithms for these
problems. For example, we develop an algorithm that takes two cubic forms $f,
g\in \mathbb{F}_q[x_1,\dots, x_n]$, and decides whether $f$ and $g$ are
isomorphic in time $q^{O(n)}$ for most $f$. This average-case setting has
direct practical implications, having been studied in multivariate cryptography
since the 1990s. Our second result concerns the complexity of testing
equivalence of alternating trilinear forms. This problem is of interest in both
mathematics and cryptography. We show that this problem is polynomial-time
equivalent to testing equivalence of symmetric trilinear forms, by showing that
they are both Tensor Isomorphism-complete (Grochow-Qiao, ITCS, 2021), therefore
is equivalent to testing isomorphism of cubic forms over most fields.
</p></div>
    </summary>
    <updated>2020-12-03T22:44:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-12-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.00959</id>
    <link href="http://arxiv.org/abs/2012.00959" rel="alternate" type="text/html"/>
    <title>Local Routing in a Tree Metric 1-Spanner</title>
    <feedworld_mtime>1606953600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brankovic:Milutin.html">Milutin Brankovic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gudmundsson:Joachim.html">Joachim Gudmundsson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Renssen:Andr=eacute=_van.html">André van Renssen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00959">PDF</a><br/><b>Abstract: </b>Solomon and Elkin constructed a shortcutting scheme for weighted trees which
results in a 1-spanner for the tree metric induced by the input tree. The
spanner has logarithmic lightness, logarithmic diameter, a linear number of
edges and bounded degree (provided the input tree has bounded degree). This
spanner has been applied in a series of papers devoted to designing bounded
degree, low-diameter, low-weight $(1+\epsilon)$-spanners in Euclidean and
doubling metrics. In this paper, we present a simple local routing algorithm
for this tree metric spanner. The algorithm has a routing ratio of 1, is
guaranteed to terminate after $O(\log n)$ hops and requires $O(\Delta \log n)$
bits of storage per vertex where $\Delta$ is the maximum degree of the tree on
which the spanner is constructed. This local routing algorithm can be adapted
to a local routing algorithm for a doubling metric spanner which makes use of
the shortcutting scheme.
</p></div>
    </summary>
    <updated>2020-12-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-12-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.00888</id>
    <link href="http://arxiv.org/abs/2012.00888" rel="alternate" type="text/html"/>
    <title>Diffusion is All You Need for Learning on Surfaces</title>
    <feedworld_mtime>1606953600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sharp:Nicholas.html">Nicholas Sharp</a>, Souhaib Attaiki, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Crane:Keenan.html">Keenan Crane</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ovsjanikov:Maks.html">Maks Ovsjanikov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00888">PDF</a><br/><b>Abstract: </b>We introduce a new approach to deep learning on 3D surfaces such as meshes or
point clouds. Our key insight is that a simple learned diffusion layer can
spatially share data in a principled manner, replacing operations like
convolution and pooling which are complicated and expensive on surfaces. The
only other ingredients in our network are a spatial gradient operation, which
uses dot-products of derivatives to encode tangent-invariant filters, and a
multi-layer perceptron applied independently at each point. The resulting
architecture, which we call DiffusionNet, is remarkably simple, efficient, and
scalable. Continuously optimizing for spatial support avoids the need to pick
neighborhood sizes or filter widths a priori, or worry about their impact on
network size/training time. Furthermore, the principled, geometric nature of
these networks makes them agnostic to the underlying representation and
insensitive to discretization. In practice, this means significant robustness
to mesh sampling, and even the ability to train on a mesh and evaluate on a
point cloud. Our experiments demonstrate that these networks achieve
state-of-the-art results for a variety of tasks on both meshes and point
clouds, including surface classification, segmentation, and non-rigid
correspondence.
</p></div>
    </summary>
    <updated>2020-12-03T22:48:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-12-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.00883</id>
    <link href="http://arxiv.org/abs/2012.00883" rel="alternate" type="text/html"/>
    <title>Electric Vehicle Charging Station Search in Stochastic Environments</title>
    <feedworld_mtime>1606953600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Marianne Guillet, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hiermann:Gerhard.html">Gerhard Hiermann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kr=ouml=ller:Alexander.html">Alexander Kröller</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schiffer:Maximilian.html">Maximilian Schiffer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00883">PDF</a><br/><b>Abstract: </b>Electric vehicles are a central component of future mobility systems as they
promise to reduce local noxious and fine dust emissions and CO2 emissions, if
fed by clean energy sources. However, the adoption of electric vehicles so far
fell short of expectations despite significant governmental incentives. One
reason for this slow adoption is the drivers' perceived range anxiety,
especially for individually owned vehicles. Here, bad user-experiences, e.g.,
conventional cars blocking charging stations or inconsistent real-time
availability data, manifest the drivers' range anxiety. Against this
background, we study stochastic search algorithms, that can be readily deployed
in today's navigation systems in order to minimize detours to reach an
available charging station. We model such a search as a finite horizon Markov
decision process and present a comprehensive framework that considers different
problem variants, speed-up techniques, and three solution algorithms: an exact
labeling algorithm, a heuristic labeling algorithm, and a rollout algorithm.
Extensive numerical studies show that our algorithms significantly decrease the
expected time to find a free charging station while increasing the solution
quality robustness and the likelihood that a search is successful compared to
myopic approaches.
</p></div>
    </summary>
    <updated>2020-12-03T22:44:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-12-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.00866</id>
    <link href="http://arxiv.org/abs/2012.00866" rel="alternate" type="text/html"/>
    <title>Huskysort</title>
    <feedworld_mtime>1606953600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hillyard:R=_C=.html">R. C. Hillyard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liaozheng:Yunlu.html">Yunlu Liaozheng</a>, Sai Vineeth K. R <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00866">PDF</a><br/><b>Abstract: </b>Much of the copious literature on the subject of sorting has concentrated on
minimizing the number of comparisons and/or exchanges/copies. However, a more
appropriate yardstick for the performance of sorting algorithms is based on the
total number of array accesses that are required (the "work"). For a sort that
is based on divide-and-conquer (including iterative variations on that theme),
we can divide the work into linear, i.e. $\textbf{O}(N)$, work and
linearithmic, i.e. $\textbf{O}(N log N)$, work. An algorithm that moves work
from the linearithmic phase to the linear phase may be able to reduce the total
number of array accesses and, indirectly, processing time. This paper describes
an approach to sorting which reduces the number of expensive comparisons in the
linearithmic phase as much as possible by substituting inexpensive comparisons.
In Java, the two system sorts are dual-pivot quicksort (for primitives) and
Timsort for objects. We demonstrate that a combination of these two algorithms
can run significantly faster than either algorithm alone for the types of
objects which are expensive to compare. We call this improved sorting algorithm
Huskysort.
</p></div>
    </summary>
    <updated>2020-12-03T22:47:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-12-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.00854</id>
    <link href="http://arxiv.org/abs/2012.00854" rel="alternate" type="text/html"/>
    <title>Transaction Fee Mechanism Design for the Ethereum Blockchain: An Economic Analysis of EIP-1559</title>
    <feedworld_mtime>1606953600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roughgarden:Tim.html">Tim Roughgarden</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00854">PDF</a><br/><b>Abstract: </b>EIP-1559 is a proposal to make several tightly coupled additions to
Ethereum's transaction fee mechanism, including variable-size blocks and a
burned base fee that rises and falls with demand. This report assesses the
game-theoretic strengths and weaknesses of the proposal and explores some
alternative designs.
</p></div>
    </summary>
    <updated>2020-12-03T22:42:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-12-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17821</id>
    <link href="https://rjlipton.wordpress.com/2020/12/02/too-long-didnt-read/" rel="alternate" type="text/html"/>
    <title>Too Long, Didn’t Read</title>
    <summary>How to summarize papers Top row: Cohan, Weld. Bottom: Cachola, Lo. Isabel Cachola, Kyle Lo, Arman Cohan, Daniel Weld are the authors of a recent paper on summarizing papers. They are all connected in various way to the Allen Institute for Artificial Intelligence. Today we take a moment to try out the webtool that comes […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>How to summarize papers</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/12/02/too-long-didnt-read/all-8/" rel="attachment wp-att-17825"><img alt="" class="alignright wp-image-17825" height="134" src="https://rjlipton.files.wordpress.com/2020/12/all.png?w=200&amp;h=134" width="200"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Top row: Cohan, Weld. Bottom: Cachola, Lo.</font></td>
</tr>
</tbody>
</table>
<p>
Isabel Cachola, Kyle Lo, Arman Cohan, Daniel Weld are the authors of a recent <a href="https://arxiv.org/abs/2004.15011">paper</a> on summarizing papers. They are all connected in various way to the <a href="https://allenai.org/papers">Allen Institute</a> for Artificial Intelligence. </p>
<p>
Today we take a moment to try out the <a href="https://scitldr.apps.allenai.org/">webtool</a> that comes with their paper.  It is noted also in a <a href="https://www.nature.com/articles/d41586-020-03277-2">news item</a> last week in <i>Nature</i>.</p>
<p>
They have created a program that reads a science article and outputs a single sentence that summarizes its content. Their goal is to help researchers search through the huge number of published papers faster than looking at abstracts. The software utilizes neural networks trained on many examples. </p>
<p>
For example: Their own <a href="https://arxiv.org/abs/2004.15011">paper</a> has for its abstract:</p>
<blockquote><p><b> </b> <em> We introduce TLDR generation, a new form of extreme summarization, for scientific papers. TLDR generation involves high source compression and requires expert background knowledge and understanding of complex domain-specific language. To facilitate study on this task, we introduce SCITLDR, a new multi-target dataset of 5.4K TLDRs over 3.2K papers. SCITLDR contains both author-written and expert-derived TLDRs, where the latter are collected using a novel annotation protocol that produces high-quality summaries while minimizing annotation burden. We propose CATTS, a simple yet effective learning strategy for generating TLDRs that exploits titles as an auxiliary training signal. CATTS improves upon strong baselines under both automated metrics and human evaluations. </em>
</p></blockquote>
<p/><p>
And this becomes:</p>
<blockquote><p><b> </b> <em> “We introduce SCITLDR, a new multi-target dataset of 5.4K TLDRs over 3.2K papers.” </em>
</p></blockquote>
<p/><p>
Not so impressive, but more on their program shortly.</p>
<p>
</p><p/><h2> Another Tryout </h2><p/>
<p/><p>
Perhaps the big news this week is an advance on protein folding by Google DeepMind, the same team whose work on <a href="https://rjlipton.wordpress.com/2016/03/11/stonefight-at-the-goke-corral/">AlphaGo</a> and <a href="https://rjlipton.wordpress.com/2017/12/17/truth-from-zero/">AlphaZero</a> we have covered. Sure enough, their new system is called <a href="https://en.wikipedia.org/wiki/AlphaFold">AlphaFold</a>—actually, AlphaFold2. See <a href="https://en.wikipedia.org/wiki/Protein_folding">here</a> for basic information: </p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/12/02/too-long-didnt-read/fold-2/" rel="attachment wp-att-17826"><img alt="" class="aligncenter wp-image-17826" height="222" src="https://rjlipton.files.wordpress.com/2020/12/fold.png?w=500&amp;h=222" width="500"/></a></p>
<p/><p><br/>
The detailed <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">announcement</a> on the DeepMind <a href="https://deepmind.com/blog">blog</a> says:</p>
<blockquote><p><b> </b> <em> Until we’ve published a paper on this work, please cite: “High Accuracy Protein Structure Prediction Using Deep Learning,” John Jumper [et al.]. In Fourteenth Critical Assessment of Techniques for Protein Structure Prediction (Abstract Book), 30 November – 4 December 2020. Retrieved from <a href="https://predictioncenter.org/casp14/doc/CASP14_Abstracts.pdf">here</a></em>.
</p></blockquote>
<p>The link under “<a href="https://predictioncenter.org/casp14/doc/CASP14_Abstracts.pdf">here</a>” goes to a long book of abstracts. Among them, there is a <a href="https://www.nature.com/articles/s41586-019-1923-7">paper</a> last January in <em>Nature</em> with many of the same authors, though Jumper not as first author. Using its abstract, we got:</p>
<blockquote><p><b> </b> <em> “We train a neural network to make accurate predictions of the distances between pairs of residues, which convey more information about the structure than contact predictions.” </em>
</p></blockquote>
<p/><p>
The abstracts book has the abstract for the current paper:</p>
<blockquote><p><b> </b> <em> In the CASP14 experiment, we deployed AlphaFold 2. This new system uses a different deep learning method than CASP13 AlphaFold, and it produces much more accurate protein structures and estimates of model accuracy. The training data for the system is publicly available and similar to that used for CASP13 AlphaFold. </em>
</p></blockquote>
<p/><p>
This is already short, but with SCITLDR it becomes:</p>
<blockquote><p><b> </b> <em> “In the CASP14 experiment, we deployed AlphaFold 2.0, a new deep learning system that produces much more accurate protein structures and” </em>
</p></blockquote>
<p/><p>
The dangling “and” is a little mystifying. SCITLDR has optional fields for <i>Introduction</i> and <i>Conclusions</i>. The entry in the abstracts book has a body titled “Methods,” whose last subsection “T1064” reads like a conclusion, so we added them as such. We cleaned up the paste from PDF to have normal line breaks. After a few seconds, we obtained:</p>
<blockquote><p><b> </b> <em> “In the CASP14 experiment, we deployed AlphaFold 2.0, a novel attention-based deep learning architecture that produces accurate protein structures” </em>
</p></blockquote>
<p/><p>
The DeepMind announcement poses a further challenge: how to glean an important paper that for now exists only as a blog post. The first paragraph of their <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">post</a> is boldfaced and reads like an abstract:</p>
<blockquote><p><b> </b> <em> Proteins are essential to life, supporting practically all its functions. They are large complex molecules, made up of chains of amino acids, and what a protein does largely depends on its unique 3D structure. Figuring out what shapes proteins fold into is known as the “protein folding problem,” and has stood as a grand challenge in biology for the past 50 years. In a major scientific advance, the latest version of our AI system AlphaFold has been recognised as a solution to this grand challenge by the organisers of the biennial Critical Assessment of protein Structure Prediction (CASP). This breakthrough demonstrates the impact AI can have on scientific discovery and its potential to dramatically accelerate progress in some of the most fundamental fields that explain and shape our world. </em>
</p></blockquote>
<p/><p>
It becomes: </p>
<blockquote><p><b> </b> <em> “AlphaFold has been recognized as a solution to this grand challenge by the organizers of the Critical Assessment of protein Structure Prediction (CASP)” </em>
</p></blockquote>
<p/><p>
Pretty good—do you agree?</p>
<p>
</p><p/><h2> Even Faster </h2><p/>
<p/><p>
Both Ken and I are fans of the <a href="https://en.wikipedia.org/wiki/The_Mathematical_Experience">book</a> <em>The Mathematical Experience</em> by Philip Davis and Reuben Hersch. The following passage, from the chapter “The Ideal Mathematician,” describes how one writes a paper, but Ken has always taken it to describe the swiftness needed to read a paper:</p>
<blockquote><p><b> </b> <em> The intended readers (all twelve of them) can decode the formal presentation, detect the new idea hidden in lemma 4, ignore the routine and uninteresting calculations of lemmas 1, 2, 3, 5, 6, 7, and see what the author is doing and why he does it. </em>
</p></blockquote>
<p/><p>
Nowadays we pore through papers as they appear on arXiv. For most, we just scan the titles. For others, we go to the main page with the abstract. For some, we click on the PDF to read the paper. This may be the greatest exercise in freedom of intellect we have our professional lives, but it is also an exercise in speed. We who do research in time complexity need to minimize our own time. </p>
<p>
</p><p/><h2> Some CS Examples </h2><p/>
<p/><p>
Another way to say this: we all need to read through the literature faster and more precisely. Here are a few examples of their one sentence abstracts for theory papers from the SCITLDR program. Rate them by seeing if you can match the summarizes with the papers.</p>
<p/><p><br/>
Here are the one sentence summaries: </p>
<ol>
<li>
“Finite automata are considered in this paper as instruments for classifying finite tapes.” <p/>
</li><li>
“The number of steps required to compute a function depends, in general, on the type of computer that is used, on the choice of computer program” <p/>
</li><li>
“In this paper, it is proven that when both randomization and interaction are allowed, the proofs that can be verified in polynomial time are” <p/>
</li><li>
“In this paper a computational complexity theory of the “knowledge” contained in a proof is developed.” <p/>
</li><li>
“It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be “reduced” <p/>
</li><li>
“We prove that there are arbitrarily long arithmetic progressions of primes.” <p/>
</li><li>
“Nonuniform Upper Bounds: The Converse Direction of the Nonuniform Complexity Bounds .”
</li></ol>
<p/><p><br/>
Match them to the paper titles: </p>
<ol>
<li>
The complexity of theorem-proving procedures <p/>
</li><li>
Some connections between nonuniform and uniform complexity classes <p/>
</li><li>
Finite Automata and Their Decision Problem <p/>
</li><li>
A Machine-Independent theory of the Complexity of Recursive Functions <p/>
</li><li>
Some connections between nonuniform and uniform complexity classes <p/>
</li><li>
The Knowledge Complexity Of Interactive Proof Systems <p/>
</li><li>
The primes contain arbitrarily long arithmetic progressions
</li></ol>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p>The papers:</p>
<ol>
<li>
“Finite automata are considered in this paper as instruments for classifying finite tapes.” <a href="http://www.cse.chalmers.se/~coquand/AUTOMATA/rs.pdf">1</a><p/>
<p/></li><li>
“The number of steps required to compute a function depends, in general, on the type of computer that is used, on the choice of computer program” <a href="http://port70.net/~nsz/articles/classic/blum_complexity_1976.pdf">2</a><p/>
<p/></li><li>
“In this paper, it is proven that when both randomization and interaction are allowed, the proofs that can be verified in polynomial time are” <a href="https://dl.acm.org/doi/10.1145/146585.146609">3</a><p/>
<p/></li><li>
“In this paper a computational complexity theory of the “knowledge” contained in a proof is developed.” <a href="http://crypto.cs.mcgill.ca/~crepeau/COMP647/2007/TOPIC02/GMR89.pdf">4</a><p/>
<p/></li><li>
“It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be “reduced” <a href="https://dl.acm.org/doi/10.1145/800157.805047">5</a><p/>
<p/></li><li>
“We prove that there are arbitrarily long arithmetic progressions of primes.” <a href="https://arxiv.org/abs/math/0404188">6</a><p/>
<p/></li><li>
“Nonuniform Upper Bounds: The Converse Direction of the Nonuniform Complexity Bounds .” <a href="https://dl.acm.org/doi/10.1145/800141.804678">7</a>
</li></ol>
<p>
The answers in brief: <b>a-5, b-7,c-1,d-2,e-3,f-4,g-6</b>.</p>
<p/><p><br/>
[fixed blog formatting issues, fixed paper ascription in the intro]</p></font></font></div>
    </content>
    <updated>2020-12-02T22:17:28Z</updated>
    <published>2020-12-02T22:17:28Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Results"/>
    <category term="literature"/>
    <category term="papers"/>
    <category term="protein folding"/>
    <category term="search"/>
    <category term="summary"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-12-04T17:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/179</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/179" rel="alternate" type="text/html"/>
    <title>TR20-179 |  Decoding Multivariate Multiplicity Codes on Product Sets | 

	Mrinal Kumar, 

	Siddharth Bhandari, 

	Prahladh Harsha, 

	Madhu Sudan</title>
    <summary>The multiplicity Schwartz-Zippel lemma bounds the total multiplicity of zeroes of a multivariate polynomial on a product set. This lemma motivates the multiplicity codes of Kopparty, Saraf and Yekhanin [J. ACM, 2014], who showed how to use this lemma to construct high-rate locally-decodable codes. However, the algorithmic results about these codes crucially rely on the fact that the polynomials are evaluated on a vector space and not an arbitrary product set. 

In this work, we show how to decode multivariate multiplicity codes of large multiplicities in polynomial time over finite product sets (over fields of large characteristic and zero characteristic).  Previously such decoding algorithms were not known even for a positive fraction of errors. In contrast, our work goes all the way to the distance of the code and in particular exceeds both the unique decoding bound and the Johnson bound. For errors exceeding the Johnson bound, even combinatorial list-decodablity of these codes was not known.

Our algorithm is an application of the classical polynomial method directly to the multivariate setting. In particular, we do not rely on a reduction from the multivariate to the univariate case as is typical of many of the existing results on decoding codes based on multivariate polynomials.  However, a vanilla application of the polynomial method in the multivariate setting does not yield a polynomial upper bound on the list size. We obtain a polynomial bound on the list size by taking an alternative view of multivariate multiplicity codes. In this view,  we glue all the partial derivatives of the same order  together  using a fresh set $\mathbf{z}$ of variables.  We then apply the polynomial method by viewing this as a problem over the field $\mathbb{F}(\mathbf{z})$ of rational functions in $\mathbf{z}$.</summary>
    <updated>2020-12-02T15:26:31Z</updated>
    <published>2020-12-02T15:26:31Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-12-04T17:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/12/02/tenure-track-assistant-professors-at-rochester-institute-of-technology-apply-by-january-2-2021/</id>
    <link href="https://cstheory-jobs.org/2020/12/02/tenure-track-assistant-professors-at-rochester-institute-of-technology-apply-by-january-2-2021/" rel="alternate" type="text/html"/>
    <title>Tenure-track assistant professors at Rochester Institute of Technology (apply by January 2, 2021)</title>
    <summary>The Department of Computer Science at the Rochester Institute of Technology invites applications for full-time tenure-track assistant professor positions starting in Fall 2021. We are looking to hire in all areas of computer science that strengthen our department. Website: https://sjobs.brassring.com/TGnewUI/Search/Home/Home?partnerid=25483&amp;siteid=5291#jobDetails=1534060_5291 Email: csfacsearch@cs.rit.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at the Rochester Institute of Technology invites applications for full-time tenure-track assistant professor positions starting in Fall 2021. We are looking to hire in all areas of computer science that strengthen our department.</p>
<p>Website: <a href="https://sjobs.brassring.com/TGnewUI/Search/Home/Home?partnerid=25483&amp;siteid=5291#jobDetails=1534060_5291">https://sjobs.brassring.com/TGnewUI/Search/Home/Home?partnerid=25483&amp;siteid=5291#jobDetails=1534060_5291</a><br/>
Email: csfacsearch@cs.rit.edu</p></div>
    </content>
    <updated>2020-12-02T01:44:24Z</updated>
    <published>2020-12-02T01:44:24Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-04T17:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1814</id>
    <link href="https://theorydish.blog/2020/12/01/motwani-postdoc-announced/" rel="alternate" type="text/html"/>
    <title>Motwani Postdoc Announced</title>
    <summary>After discussing postdoc opportunities with me and the opportunities as part of the Simons Collaboration on the Theory of Algorithmic Fairness, let me conclude with postdoc opportunities with Stanford theory group: The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below. Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15. Website: https://academicjobsonline.org/ajo/jobs/17685Email: theory.stanford@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>After discussing <a href="https://theorydish.blog/2020/11/16/hiring-postdocs/">postdoc opportunities with me</a> and the <a href="https://toc4fairnesses.org/postdoc-opportunities/">opportunities as part of the Simons Collaboration on the Theory of Algorithmic Fairness</a>, let me conclude with postdoc opportunities with Stanford theory group:</p>



<p>The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below. Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15.</p>



<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/17685">https://academicjobsonline.org/ajo/jobs/17685</a><br/>Email: theory.stanford@gmail.com</p></div>
    </content>
    <updated>2020-12-01T18:59:01Z</updated>
    <published>2020-12-01T18:59:01Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-12-04T17:21:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/12/01/motwani-postdoctoral-fellowship-at-stanford-computer-science-apply-by-december-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/12/01/motwani-postdoctoral-fellowship-at-stanford-computer-science-apply-by-december-15-2020/" rel="alternate" type="text/html"/>
    <title>Motwani Postdoctoral Fellowship at Stanford Computer Science (apply by December 15, 2020)</title>
    <summary>The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below. Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15. Website: https://academicjobsonline.org/ajo/jobs/17685 Email: theory.stanford@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below. Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/17685">https://academicjobsonline.org/ajo/jobs/17685</a><br/>
Email: theory.stanford@gmail.com</p></div>
    </content>
    <updated>2020-12-01T00:48:59Z</updated>
    <published>2020-12-01T00:48:59Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-04T17:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1809</id>
    <link href="https://theorydish.blog/2020/11/30/postdoc-opportunities-in-algorithmic-fairness/" rel="alternate" type="text/html"/>
    <title>Postdoc Opportunities in Algorithmic Fairness</title>
    <summary>As promised, more postdoctoral positions now available for 2021 The Simons Collaboration on the Theory of Algorithmic Fairness seek highly qualified candidates (within five years of the award of their PhD) for a postdoctoral research position. Appointments will begin Summer or Fall 2021. This multi-year program will host several postdoctoral researchers working on modeling and theoretical work understanding (a) the sources of discriminatory behavior of algorithms, and (b) how best to mitigate such impacts. Descriptions of the scientific agendas of this research collaboration can be found at https://toc4fairnesses.org/. Fellows will be able to collaborate broadly, including with researchers at partner institutions: Stanford University, Toyota Institute of Technology at Chicago, Massachusetts Institute of Technology, Harvard University, UC Berkeley, Cornell University,  Hebrew University of Jerusalem, Weizmann Institute of Science, University of Toronto,  University of Washington, and University of Pennsylvania.  The anticipated term for a fellowship is one or two years – to be decided at the time of appointment, with the possibility of extension based on mutual agreement. In addition to competitive salary and benefits, the fellowship also includes funding for independent travel to workshops, conferences and other universities and research labs. In order to apply, please email a CV, research statement, and have two [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://theorydish.blog/2020/11/16/hiring-postdocs/">As promised</a>, more postdoctoral positions now available for 2021</p>



<p>The <a href="https://www.simonsfoundation.org/2020/06/18/foundation-announces-simons-collaboration-on-the-theory-of-algorithmic-fairness/">Simons Collaboration on the Theory of Algorithmic Fairness</a> seek highly qualified candidates (within five years of the award of their PhD) for a postdoctoral research position. Appointments will begin Summer or Fall 2021.</p>



<p>This multi-year program will host several postdoctoral researchers working on modeling and theoretical work understanding (a) the sources of discriminatory behavior of algorithms, and (b) how best to mitigate such impacts.</p>



<p>Descriptions of the scientific agendas of this research collaboration can be found at <a href="https://toc4fairnesses.org/" rel="noreferrer noopener" target="_blank">https://toc4fairnesses.org/</a>.</p>



<p>Fellows will be able to collaborate broadly, including with researchers at partner institutions: Stanford University, Toyota Institute of Technology at Chicago, Massachusetts Institute of Technology, Harvard University, UC Berkeley, Cornell University,  Hebrew University of Jerusalem, Weizmann Institute of Science, University of Toronto,  University of Washington, and University of Pennsylvania.</p>



<p> The anticipated term for a fellowship is one or two years – to be decided at the time of appointment, with the possibility of extension based on mutual agreement. In addition to competitive salary and benefits, the fellowship also includes funding for independent travel to workshops, conferences and other universities and research labs.</p>



<p>In order to apply, please email a CV, research statement, and have two reference letters sent to <a href="mailto:jamiemmt@cs.washington.edu" rel="noreferrer noopener" target="_blank">jamiemmt@cs.washington.edu</a>. Applications and reference letters are due Dec. 31, 2020, though we will consider applications which arrive after that date. Decisions will be made in February.</p>



<p>Jamie Morgenstern, chair of the postdoctoral search committee<br/>Simons Collaboration on the Foundations of Fairness in Machine Learning</p></div>
    </content>
    <updated>2020-11-30T21:38:08Z</updated>
    <published>2020-11-30T21:38:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-12-04T17:21:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/11/30/faculty-at-university-of-california-santa-cruz-apply-by-january-12-2021/</id>
    <link href="https://cstheory-jobs.org/2020/11/30/faculty-at-university-of-california-santa-cruz-apply-by-january-12-2021/" rel="alternate" type="text/html"/>
    <title>Faculty at University of California, Santa Cruz (apply by January 12, 2021)</title>
    <summary>The Computer Science &amp; Engineering department at UC Santa Cruz is recruiting for six junior faculty positions, two in theoretical computer science, two in applied machine learning, and two in experimental systems. (The TCS position URL is given below. For the others, look at the open recruitments in Computer Science and Engineering.) Website: https://recruit.ucsc.edu/JPF00962 Email: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Computer Science &amp; Engineering department at UC Santa Cruz is recruiting for six junior faculty positions, two in theoretical computer science, two in applied machine learning, and two in experimental systems.<br/>
(The TCS position URL is given below. For the others, look at the open recruitments in Computer Science and Engineering.)</p>
<p>Website: <a href="https://recruit.ucsc.edu/JPF00962">https://recruit.ucsc.edu/JPF00962</a><br/>
Email: C. Seshadhri</p></div>
    </content>
    <updated>2020-11-30T21:15:21Z</updated>
    <published>2020-11-30T21:15:21Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-04T17:20:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/11/30/linkage</id>
    <link href="https://11011110.github.io/blog/2020/11/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>An amusing if minor repeated typo in the literature: “appiled superconductivity (\(\mathbb{M}\)). I think its 177 Google Scholar hits are the fault of IEEE, which spells Trans. on Applied Superconductivity correctly on its site but misspells it repeatedly in the doi database. So if you get your citations from doi metadata, you will get this error. You can see the metadata for an example by curl -LH "Accept: application/x-bibtex" https://doi.org/10.1109/TASC.2005.849553.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://scholar.google.com/scholar?q=%22Appiled+Superconductivity%22">An amusing if minor repeated typo in the literature: “appiled superconductivity</a> (<a href="https://mathstodon.xyz/@11011110/105224219465552642">\(\mathbb{M}\)</a>). I think its 177 Google Scholar hits are the fault of IEEE, which spells <em>Trans. on Applied Superconductivity</em> correctly on its site but misspells it repeatedly in the doi database. So if you get your citations from doi metadata, you will get this error. You can see the metadata for an example by <code class="language-plaintext highlighter-rouge">curl -LH "Accept: application/x-bibtex" https://doi.org/10.1109/TASC.2005.849553</code>.</p>
  </li>
  <li>
    <p><a href="https://post.lurk.org/@crickxson/105199692913412250">A map of the percentages of female researchers in Europe</a>. The numbers are highest in the Baltics and Balkans; the discussion thread suggests that there’s a negative correlation with pay.</p>
  </li>
  <li>
    <p><a href="https://news.ycombinator.com/item?id=25149206">YouTube no longer an acceptable platform for course lecture or academic talk content</a> (<a href="https://mathstodon.xyz/@11011110/105238898515120908">\(\mathbb{M}\)</a>). Unless, of course, you and your university are comfortable with your students or other audience members being subject to advertisements that interrupt the lectures and are beyond your control both in their placement and content.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/geometry-reveals-how-the-world-is-assembled-from-cubes-20201119/">Scientists uncover the universal geometry of geology</a> (<a href="https://mathstodon.xyz/@11011110/105241748181882434">\(\mathbb{M}\)</a>). This is all a bit mystic and breathless and woo, but what <em>Quanta</em> really seems to mean to is that if you subdivide space by randomly recursively splitting by planes (sort of like a 3d <a href="https://en.wikipedia.org/wiki/Gilbert_tessellation">Gilbert tessellation</a>) then the average number of sides per bottom-level polyhedron is six.</p>
  </li>
  <li>
    <p><a href="https://cameroncounts.wordpress.com/2020/11/19/a-paradox-and-where-it-led/">A paradox, and where it led</a> (<a href="https://mathstodon.xyz/@11011110/105249285864846993">\(\mathbb{M}\)</a>). Peter Cameron looks at the inclusion graphs of countable models of not-well-founded set theories. The well-founded ones are all the Rado graph, but without foundation the results are more varied.</p>
  </li>
  <li>
    <p><a href="https://theconversation.com/curved-origami-offers-a-creative-route-to-making-robots-and-other-mechanical-devices-150253">Curved origami robot grippers with tunable stiffness</a> (<a href="https://mathstodon.xyz/@11011110/105260956314627650">\(\mathbb{M}\)</a>).</p>
  </li>
  <li>
    <p><a href="https://blog.archive.org/2020/11/23/foss-wins-again-free-and-open-source-communities-comes-through-on-19th-century-newspapers-and-books-and-periodicals/">Archive.org improves accuracy of OCR and compression of PDF on its huge collection of old scanned printed documents by switching to open-source software</a> (<a href="https://mathstodon.xyz/@11011110/105264347147907544">\(\mathbb{M}\)</a>).</p>
  </li>
  <li>
    <p><a href="https://hackers.town/@_cr0_tab/105165210380388504">Four common mathematical means of two quantities in a single compass-and-straightedge construction</a>.</p>
  </li>
  <li>
    <p><a href="http://cstaecker.fairfield.edu/~cstaecker/machines/graphsheets.html">More different kinds of graph paper than you might have even thought possible</a> (<a href="https://mathstodon.xyz/@11011110/105275252021160077">\(\mathbb{M}\)</a>).</p>
  </li>
  <li>
    <p><a href="https://renato.athaydes.com/posts/comparing-jvm-alternatives-to-js.html">Comparison of six ways to get your old Java applets running again on the modern web</a> (<a href="https://mathstodon.xyz/@11011110/105284817164400009">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=19714924">via</a>). I have a couple of old defunct ones that I’m tempted to try this on…</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@jsiehler/105288859971030412">New names for special types of hexagon: “squashogon”, “boltogon”, “extremely irregular hexagon”, and “treeah star”</a>. Boltogons are the zigzag 180-degree symmetric ones.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2020-11-29/Essay">Some tips for avoiding sexist language when writing about women</a> (<a href="https://mathstodon.xyz/@11011110/105298265490259050">\(\mathbb{M}\)</a>). This is from 2015, when singular “they” was more controversial, and mostly aimed at Wikipedia editing, but it was recently reprinted in the Wikipedia <em>Signpost</em>, and I think it is still topical more generally.)</p>
  </li>
  <li>
    <p><a href="https://www.ams.org/journals/notices/202011/rnoti-p1780.pdf">The place of blogs in the modern math world, Katherine Thompson, <em>Notices of the AMS</em></a> (<a href="https://mathstodon.xyz/@11011110/105301116392488191">\(\mathbb{M}\)</a>). “Clearly, mathematicians are using blogs. … And yet despite all of the work that goes into blogs, the mathematical community has no idea what to make of them—even at the most basic level like citation.”</p>
  </li>
</ul></div>
    </content>
    <updated>2020-11-30T18:15:00Z</updated>
    <published>2020-11-30T18:15:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-12-01T02:42:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/178</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/178" rel="alternate" type="text/html"/>
    <title>TR20-178 |  Reciprocal Inputs in Arithmetic and Tropical Circuits | 

	Stasys Jukna, 

	Hannes Seiwert, 

	Igor Sergeev</title>
    <summary>It is known that the size of monotone arithmetic $(+,\ast)$ circuits can be  exponentially decreased by allowing just one division  "at the very end," at the output gate. A natural question is: can the size of $(+,\ast)$ circuits be substantially  reduced if we allow divisions "at the very beginning," that is, if besides  nonnegative real constants and variables $x_1,\ldots,x_n$, the circuits can also use their reciprocals $1/x_1,\ldots,1/x_n$ as inputs. We answer this question in the negative: the gain in circuit size is  then always at most quadratic.


Over tropical $(\min,+)$ and $(\max,+)$ semirings, division turns into subtraction; so, reciprocal inputs are then $-x_1,\ldots,-x_n$.  We give the same negative answer also for tropical circuits. The question of whether reciprocal inputs can substantially speed up tropical $(\min,+,\max)$ circuits, using both $\min$ and $\max$ gates, remains open.</summary>
    <updated>2020-11-30T17:48:06Z</updated>
    <published>2020-11-30T17:48:06Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-12-04T17:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/11/30/tenure-track-assistant-professors-at-aalto-university-apply-by-january-10-2021/</id>
    <link href="https://cstheory-jobs.org/2020/11/30/tenure-track-assistant-professors-at-aalto-university-apply-by-january-10-2021/" rel="alternate" type="text/html"/>
    <title>Tenure Track Assistant Professors at Aalto University (apply by January 10, 2021)</title>
    <summary>The Department of Computer Science at Aalto University invites applications for tenure-track positions at the Assistant Professor level. We are a diverse community welcoming applications in ALL AREAS of Computer Science. Our CS Theory group (https://research.cs.aalto.fi/theory/) has e.g. received the best paper awards in FOCS 2019 and ICALP 2017, as well as ERC starting grants […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at Aalto University invites applications for tenure-track positions at the Assistant Professor level. We are a diverse community welcoming applications in ALL AREAS of Computer Science.</p>
<p>Our CS Theory group (<a href="https://research.cs.aalto.fi/theory/">https://research.cs.aalto.fi/theory/</a>) has e.g. received the best paper awards in FOCS 2019 and ICALP 2017, as well as ERC starting grants in 2014 and 2017.</p>
<p>Website: <a href="https://www.aalto.fi/en/open-positions/tenure-track-assistant-professors-in-computer-science">https://www.aalto.fi/en/open-positions/tenure-track-assistant-professors-in-computer-science</a><br/>
Email: laura.kuusisto-noponen@aalto.fi</p></div>
    </content>
    <updated>2020-11-30T15:42:33Z</updated>
    <published>2020-11-30T15:42:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-04T17:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/11/30/research-associate-postdoc-at-university-of-edinburgh-apply-by-january-6-2021/</id>
    <link href="https://cstheory-jobs.org/2020/11/30/research-associate-postdoc-at-university-of-edinburgh-apply-by-january-6-2021/" rel="alternate" type="text/html"/>
    <title>Research Associate (Postdoc) at University of Edinburgh (apply by January 6, 2021)</title>
    <summary>Applications are invited for research associate positions in Algorithms and Complexity, funded by the European Research Council (ERC) starting grant “New Approaches to Counting and Sampling” (NACS), led by Dr. Heng Guo in the School of Informatics, University of Edinburgh. Website: https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/123/ Email: hguo@inf.ed.ac.uk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for research associate positions in Algorithms and Complexity, funded by the European Research Council (ERC) starting grant “New Approaches to Counting and Sampling” (NACS), led by Dr. Heng Guo in the School of Informatics, University of Edinburgh.</p>
<p>Website: <a href="https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/123/">https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/123/</a><br/>
Email: hguo@inf.ed.ac.uk</p></div>
    </content>
    <updated>2020-11-30T10:30:00Z</updated>
    <published>2020-11-30T10:30:00Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-04T17:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/11/30/postdoc-at-technion-israel-institute-of-technology-apply-by-march-1-2021/</id>
    <link href="https://cstheory-jobs.org/2020/11/30/postdoc-at-technion-israel-institute-of-technology-apply-by-march-1-2021/" rel="alternate" type="text/html"/>
    <title>postdoc at Technion Israel Institute of Technology (apply by March 1, 2021)</title>
    <summary>Looking for excellent post graduate researchers for a yearlong postdoc position at the Computer Science Department at Technion. Main research theme is intersection of theoretical computer science with learning, information and data. Website: https://nailon.net.technion.ac.il/openings/ Email: mayasidis@cs.technion.ac.il</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Looking for excellent post graduate researchers for a yearlong postdoc position at the Computer Science Department at Technion. Main research theme is intersection of theoretical computer science with learning, information and data.</p>
<p>Website: <a href="https://nailon.net.technion.ac.il/openings/">https://nailon.net.technion.ac.il/openings/</a><br/>
Email: mayasidis@cs.technion.ac.il</p></div>
    </content>
    <updated>2020-11-30T07:43:39Z</updated>
    <published>2020-11-30T07:43:39Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-12-04T17:20:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1036999202735486243</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1036999202735486243/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/11/james-randi-magicians-author-skeptic.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1036999202735486243" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1036999202735486243" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/11/james-randi-magicians-author-skeptic.html" rel="alternate" type="text/html"/>
    <title>James Randi, Magicians-Author-Skeptic, passed away at the age of 92</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><br/></p><p>James The Amazing Randi died on October 20, 2020, at the age of 92. He is survived by</p><p>his husband Jose Alvarez.  His Wikipedia page is <a href="https://en.wikipedia.org/wiki/James_Randi">here</a></p><div> </div><div>A few Randi Points:</div><div><br/></div><div><div><br/></div><div>0) Wikipedia lists his careers as Magician, Author, Skeptic. I didn't know that skeptic was a career.</div><div><br/></div><div>1) Randi debunked many paranormal claims, though he did not like the term <i>debunke</i>r. He preferred <i>investigator</i>.</div><div><br/></div><div>2) Martin Gardner and James Randi founded the</div><div><br/></div><div><i>Committee for Scientific Investigation of Claims of the Paranormal.</i></div><div><br/></div><div>which publishes</div><div><br/></div><div><i>The Skeptical Inquirer</i>: see <a href="https://skepticalinquirer.org/?gclid=Cj0KCQjwuL_8BRCXARIsAGiC51AlnsnROpbKH-O1K-3WoumIXHGLAACCVDxByb2lFy0rkKunUHblUOAaAmUmEALw_wcB">here</a>  </div></div><div><br/></div><div><div><br/></div><div>3) The internet is both a place where unchecked claims of paranormal activity (and more dangerous lies) can grow faster than in an earlier time, but also a place where magazines like The Skeptical Inquirer, and fact-checking websites, can help check the unchecked claims. What is winning? I leave that as an exercise for the reader. </div><div><br/></div><div>4) I suspect most (all?) people reading this blog do not believe in astrology, UFO's, ESP, or other crank theories. Hence I was surprised to read that Alan Turing thought the evidence for  ESP was <i>overwhelming. </i>This was mentioned in passing in his paper on The Turing Test (called there <i>The</i> <i>Imitation Game</i>) as something the Turing Test will have to account for. I've tried to find out why he believed this, without success. Some websites mentioned that belief in the paranormal was more... normal in those days. One suggested that after the counter-intuitive theories of quantum mechanics and relatively were out there, other counter-intuitive theories took hold, like ESP.  Even so, what was the evidence he was referring to?</div><div><br/></div><div>5) Claims that<i>  I was abducted by a UFO</i> or <i>I saw a UFO</i> have decreased since people now have cell phones so ALWAYS have a way to take pictures. Also rumors like (I had heard this one)</div><div><br/></div><div><i>There is an alternative ending to the movie BLAH which made is way to a few DVDs by mistake.</i></div><div><br/></div><div>are no longer made since IF true you could EASILY produce evidence of such (post to you tube or elsewhere).</div><div><br/></div><div>6) The term<i> skeptic</i> just means someone who doubts something, and is not necc a positive things.</div><div><br/></div><div><i>I am a skeptic when it comes go Global Warming</i></div><div><br/></div><div>being one example.</div></div><div><br/></div><div><div>Randi largely debunked things that were obviously false and not-political. (That the very existence of Global Warming is political is  appalling. At some future point the question of whether or not we ever got to the moon will be political: Something done by big government that worked is impossible, hence it did not happen. See Scott's Blog on disbelief that we ever went to the moon <a href="https://www.scottaaronson.com/blog/?p=4267">here</a>. And people like Randi will need to debunk the notion that the moon landing was faked.) </div><div><br/></div><div>7) Back to Turing- There is a large diff between believing in ESP and believing in astrology.</div><div><br/></div><div>For ESP Turing mentioned <i>overwhelming evidence. </i> While he was WRONG, he did see the need to HAVE evidence. And note that ESP CAN be tested and found to NOT be true. Also note that it is plausible (though I really doubt it) that some humans somehow have some level of ESP. Astrology has NO redeeming value or hope whatsoever. (I am reminded that in Martin Gardner's book <i>Fads and Fallacies in the name of science </i>he noted that most people would say things like `YES, I liked your debunking of A, but you are wrong about B--- B is for real!')</div><div><br/></div><div>UFO's: I do not believe that aliens have come here and abducted people or left crop circles or anything of the sort. The intelligent question of  <i>is there intelligent life in the universe  </i>is quite another matter.</div><div><br/></div><div>7) When I saw magicians as a kid (1960's) I knew that it was all tricks- though very skillful tricks which were impressive. Sometimes they would indicate that it was <i>real magic </i>but I did not know what they meant. Since then I have learned that in an earlier time it was common that magicians claimed they used  <i>real magic</i>.  I still don't quite know what that means, which is just as well since it does not exist.</div><div><br/></div><div>8) Randi has been sued by people whose tricks he has debunked. Randi seems to have always won.  I say <i>seems to </i> since legal cases are not as clear cut as mathematics.  I also looked up Uri Geller. He has sued A LOT of people, and not just people who deny his claims. Thinks like using his likeness  without permission  (he may have a point there). Very hard to tell how he is doing on balance.</div><div><br/></div><div>9) According to Wikipedia Randi dropped out of High School. I assume he learned A LOT on his own.</div><div><br/></div><div>(Trivia-- who was the last president who did not have a college degree? I will answer at the end.)</div><div><br/></div><div>10) This seems like a paradox... or something (quoted from Wikipedia):</div></div><div><br/></div><div><div>BEGIN</div><div><br/></div><div>Randi has been accused of actually using <i>psychic powers</i> to perform acts such as spoon bending. According to James Alcock, at a meeting where Randi was duplicating the performances of Uri Geller, a professor from the University at Buffalo shouted out that Randi was a fraud.  Randi said: "<i>Yes, indeed</i>, <i>I'm a trickste</i>r, <i>I'm a cheat, I'm a charlatan, that's what I do for a living. Everything I've done here was by trickery</i>. The professor shouted back:</div><div><br/></div><div><i>That's not what I mean. You're a fraud because you're pretending to do these things through trickery, but you're actually using psychic powers and misleading us by not admitting it.</i></div><div><br/></div><div>A similar event involved Senator Claiborne Pell, a confirmed believer in psychic phenomena.  When Randi personally demonstrated to Pell that he could reveal—by simple trickery—a concealed drawing that had been secretly made by the senator, Pell refused to believe that it was a trick, saying: "<i>I think</i> <i>Randi may be a </i><i>psychic and doesn't realize it</i>." Randi consistently denied having any paranormal powers or abilities.</div><div><br/></div><div>END</div><div><br/></div><div>Reminds me of <a href="https://blog.computationalcomplexity.org/2013/06/fraud-or-not.html">this</a> blog entry where I speculate about someone who codes up a great new classical  factoring algorithm and claims he has a quantum computer, or someone who has a working quantum computer and claims its a great new classical factoring algorithm. </div><div><br/></div><div><br/></div><div>11) The last president who did not have a college degree: Harry Truman.</div></div><div><br/></div><div><br/></div><div><br/></div></div>
    </content>
    <updated>2020-11-30T04:36:00Z</updated>
    <published>2020-11-30T04:36:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-12-04T09:58:07Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-5616947953323689751</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/5616947953323689751/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=5616947953323689751" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/5616947953323689751" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/5616947953323689751" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2020/11/adapt-designing-activity-informed-viral.html" rel="alternate" type="text/html"/>
    <title>ADAPT:  Designing Activity-Informed Viral Diagnostic Assays</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><span style="font-size: small;">I wanted to give a pointer to a <a href="https://www.biorxiv.org/content/10.1101/2020.11.28.401877v1" rel="nofollow" target="_blank">new preprint on bioRxiv</a> on developing diagnostic assays for viruses, by (first author) <a href="https://www.haydenmetsky.com/" rel="nofollow" target="_blank">Hayden Metsky</a> (and others!) out of the <a href="https://www.sabetilab.org/" rel="nofollow" target="_blank">Sabeti Lab</a> at the Broad Institute (that I've been a bit involved with).  Hayden, who somehow is both a computer science PhD and an expert in virology, has devised a novel software pipeline for developing diagnostics that are designed from the start to deal with genomic diversity (a virus evolves to have many somewhat different variants) and the challenge of false matches (you don't want to get false positives from matching some other different virus) -- also known as sensitivity and specificity.  Algorithmically, he uses machine learning to determine scores for possible tests for matches to small pieces of the genome, or probes, and utilizes locality-sensitive hashing, combinatorial optimization algorithms for submodular maximization, and sharding pattern matching across tries as substages in the overall design.  </span></p><div class="gmail_default" style="font-size: small;">I am always excited to see algorithmic ideas being used to solve real-world problems, and this is a deep and difficult example of the "algorithmic lens"  at work.  I am optimistically hopeful that this type of technology will help drive the development of viral diagnostic and monitoring methods forward.     </div><div class="yj6qo"/><div class="gmail_default adL" style="font-size: small;"><br style="background-color: white; color: #222222; font-family: Arial, Helvetica, sans-serif;"/></div><div class="gmail_default adL" style="font-size: small;">Some additional pointers:  <a href="https://github.com/broadinstitute/adapt" rel="nofollow" target="_blank">to code</a>, <a href="https://adapt.sabetilab.org/covid-19/" rel="nofollow" target="_blank">to some array designs for SARS-CoV-2</a>, and <a href="https://twitter.com/haydenmetsky/status/1333121522127548416" rel="nofollow" target="_blank">Hayden's twitter thread describing the work</a>.  </div></div>
    </content>
    <updated>2020-11-30T03:25:00Z</updated>
    <published>2020-11-30T03:25:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2020-11-30T06:16:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/177</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/177" rel="alternate" type="text/html"/>
    <title>TR20-177 |  Counting Subgraphs in Degenerate Graphs | 

	Lior Gishboliner, 

	Asaf Shapira, 

	Yevgeny Levanzov</title>
    <summary>We consider the problem of counting the number of copies of a fixed graph $H$ within an input graph $G$. This is one of the most well-studied algorithmic graph problems, with many theoretical and practical applications. We focus on solving this problem when the input $G$ has {\em bounded degeneracy}. This is a rich family of graphs, containing all graphs without a fixed minor (e.g. planar graphs), as well as graphs generated by various random processes (e.g. preferential attachment graphs). We say that $H$ is {\em easy} if there is a linear-time algorithm for counting the number of copies of $H$ in an input $G$ of bounded degeneracy. A seminal result of Chiba and Nishizeki from '85 states that every $H$ on at most 4 vertices is easy. Bera, Pashanasangi, and Seshadhri recently extended this to all $H$ on 5 vertices, and further proved that for every $k &gt; 5$ there is a $k$-vertex $H$ which is not easy. They left open the natural problem of characterizing all easy graphs $H$. 
		
Bressan has recently introduced a framework for counting subgraphs in degenerate graphs, from which one can extract a sufficient condition for a graph $H$ to be  easy. Here we show that this sufficient condition is also necessary, thus fully answering the Bera--Pashanasangi--Seshadhri problem. We further resolve two closely related problems; namely characterizing the graphs that are easy with respect to counting induced copies, and with respect to counting homomorphisms. Our proofs rely on several novel approaches for proving hardness results in the context of subgraph-counting.</summary>
    <updated>2020-11-29T16:43:59Z</updated>
    <published>2020-11-29T16:43:59Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-12-04T17:20:33Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-11-29-the-lock-commit-paradigm/</id>
    <link href="https://decentralizedthoughts.github.io/2020-11-29-the-lock-commit-paradigm/" rel="alternate" type="text/html"/>
    <title>The Lock-Commit Paradigm</title>
    <summary>In this post, we explore the Lock-Commit paradigm for consensus protocols. This approach is probably the most celebrated and widely used technique for reaching consensus in a safe manner. This approach is one of the key techniques in DLS88 and Lamport’s Paxos. We exemplify this paradigm by showing a single-shot...</summary>
    <updated>2020-11-29T13:02:00Z</updated>
    <published>2020-11-29T13:02:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-12-04T16:21:52Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/11/27/study-triangular-bottle</id>
    <link href="https://11011110.github.io/blog/2020/11/27/study-triangular-bottle.html" rel="alternate" type="text/html"/>
    <title>Study of a triangular bottle</title>
    <summary>We acquired this small blue glass bottle nearly 15 years ago, as a prop for a Harry Potter themed birthday party. For much of the time since then it’s been decorating our bathroom window with several other blue bottles. Like most bottles these days, it’s molded rather than blown, but a little roughly so the welding seams are more visible than they usually are on wine or liquor bottles.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We acquired this small blue glass bottle nearly 15 years ago, as a prop for a Harry Potter themed birthday party. For much of the time since then it’s been decorating our bathroom window with several other blue bottles. Like most bottles these days, it’s molded rather than blown, but a little roughly so the welding seams are more visible than they usually are on wine or liquor bottles.</p>

<div><table style="margin-left: auto; margin-right: auto;">
<tbody><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><img alt="Triangular blue glass bottle" src="http://www.ics.uci.edu/~eppstein/pix/triangularbottle/1-m.jpg" style="border-style: solid; border-color: black;" width="240"/></td>
<td style="padding: 10px;"><img alt="Triangular blue glass bottle" src="http://www.ics.uci.edu/~eppstein/pix/triangularbottle/2-m.jpg" style="border-style: solid; border-color: black;" width="360"/></td>
</tr><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><img alt="Triangular blue glass bottle" src="http://www.ics.uci.edu/~eppstein/pix/triangularbottle/3-m.jpg" style="border-style: solid; border-color: black;" width="280"/></td>
<td style="padding: 10px;"><img alt="Triangular blue glass bottle" src="http://www.ics.uci.edu/~eppstein/pix/triangularbottle/4-m.jpg" style="border-style: solid; border-color: black;" width="300"/></td>
</tr></tbody></table></div>

<p>As you can see, it has an unusual triangular cross-section. The final image, with a Reuleaux triangle overlaid, shows that the curvature of this cross-section is less than a Reuleaux triangle would have. I don’t think its outline was chosen with any particular mathematics in mind, but only (as so many other curved triangles) to make an interesting shape.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/105286711285736529">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-11-27T18:20:00Z</updated>
    <published>2020-11-27T18:20:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-12-01T02:42:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=20494</id>
    <link href="https://gilkalai.wordpress.com/2020/11/27/recent-progress-on-high-dimensional-turan-type-problems-by-andrey-kupavskii-alexandr-polyanskii-istvan-tomon-and-dmitriy-zakharov-and-by-jason-long-bhargav-narayanan-and-corrine-yap/" rel="alternate" type="text/html"/>
    <title>Recent progress on high dimensional Turan-Type problems by Andrey Kupavskii, Alexandr Polyanskii, István Tomon, and Dmitriy Zakharov and by Jason Long, Bhargav Narayanan, and Corrine Yap.</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The extremal number for surfaces Andrey Kupavskii, Alexandr Polyanskii, István Tomon, Dmitriy Zakharov: The extremal number of surfaces Abstract: In 1973, Brown, Erdős and Sós proved that if is a 3-uniform hypergraph on vertices which contains no triangulation of the sphere, then   … <a href="https://gilkalai.wordpress.com/2020/11/27/recent-progress-on-high-dimensional-turan-type-problems-by-andrey-kupavskii-alexandr-polyanskii-istvan-tomon-and-dmitriy-zakharov-and-by-jason-long-bhargav-narayanan-and-corrine-yap/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h3>The extremal number for surfaces</h3>



<h3>Andrey Kupavskii, Alexandr Polyanskii, István Tomon, Dmitriy Zakharov: <a href="https://arxiv.org/abs/2010.07191">The extremal number of surfaces</a></h3>



<p/><p><strong>Abstract:</strong> In 1973, Brown, Erdős and Sós proved that if <img alt="\cal H" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccal+H&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\cal H"/> is a 3-uniform hypergraph on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> vertices which contains no triangulation of the sphere, then <img alt="\cal H" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccal+H&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\cal H"/>  has at most <img alt="O(n^{5/2})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28n%5E%7B5%2F2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="O(n^{5/2})"/> edges, and this bound is the best possible up to a constant factor. Resolving a conjecture of Linial, also reiterated by Keevash, Long, Narayanan, and Scott, we show that the same result holds for triangulations of the torus. Furthermore, we extend our result to every closed orientable surface <img alt="\cal S" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccal+S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\cal S"/>.</p> <p><span style="color: #0000ff;"><strong>Remarks:</strong> </span></p> <p><span style="color: #0000ff;">1) When <img alt="\cal S" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccal+S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\cal S"/> is fixed Nati proved that there is a simplicial complex with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> vertices and <img alt="c n^{5/2}" class="latex" src="https://s0.wp.com/latex.php?latex=c+n%5E%7B5%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="c n^{5/2}"/> 2-faces that does not contain a triangulation of <img alt="\cal S" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccal+S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\cal S"/>. </span></p> <p><span style="color: #0000ff;">2) It is not known if there is an example with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> vertices and <img alt="c n^{5/2}" class="latex" src="https://s0.wp.com/latex.php?latex=c+n%5E%7B5%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="c n^{5/2}"/> 2-faces which does not contain a triangulation of any orientable closed surface <img alt="\cal S" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccal+S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\cal S"/>. </span></p> <p><span style="color: #0000ff;">We can ask the same question also for pseudomanifolds. What is the number of edges that guarantees a subcomplex with the property that every 1-face is included in precisely two 2-faces.</span></p> <p><span style="color: #0000ff;">3) Nati conjectured that for every 2-dimensional simplicial complex <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="S"/> there is a constant <img alt="C_S" class="latex" src="https://s0.wp.com/latex.php?latex=C_S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="C_S"/> such that a 2-dimensional simplicial complex with $n$ vertices and $C_Sn^{5/2}$ 2-faces always contains a homeomorph of <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="S"/>. The paper  by Andrey, Alexandr, István, and Dmitriy asserts that proving the exponent 5/2 for the real projective space will imply the same exponent for all nonorientable closed surfaces. </span></p> <p><span style="color: #0000ff;">4) The paper also mentions an unpublished result by Friedgut and Linial that <img alt="n^{8/9}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B8%2F9%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n^{8/9}"/> 2-faces suffice for a torus. <br/></span></p> <p><span style="color: #008000;">5) Here is another problem I am curious about: How many 2-faces guarantee a subcomplex K with <img alt="H_2(K) \ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=H_2%28K%29+%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="H_2(K) \ne 0"/> and <img alt="H_1(K)=0" class="latex" src="https://s0.wp.com/latex.php?latex=H_1%28K%29%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="H_1(K)=0"/>?  (You can choose the field of coefficients.)  Without the second requirement the answer is roughly <img alt="n^2" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n^2"/>. </span></p> <h2>Universal exponent for homeomorphs.</h2> <h3><strong>Nati’s Problem 2:</strong> Given a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k"/>-dimensional-complex <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="S"/>, how many facets can a  <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k"/>-complex on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> vertices have if it contains no topological copy of <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="S"/>? (Topological copy = homeomorphic image)</h3> <p>Jason Long, Bhargav Narayanan, and Corrine Yap:  <a href="https://arxiv.org/abs/2011.08167">Simplicial homeomorphs and trace-bounded hypergraphs </a></p><p/>


<p><strong>Abstract:</strong> Our first main result is a uniform bound, in every dimension <img alt="k \in \mathbb N" class="latex" src="https://s0.wp.com/latex.php?latex=k+%5Cin+%5Cmathbb+N&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k \in \mathbb N"/>, on the topological Turán numbers of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k"/>-dimensional simplicial complexes: for each <img alt="k \in \mathbb N" class="latex" src="https://s0.wp.com/latex.php?latex=k+%5Cin+%5Cmathbb+N&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k \in \mathbb N"/>, there is a <img alt="\lambda_k \ge k^{-2k^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_k+%5Cge+k%5E%7B-2k%5E2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\lambda_k \ge k^{-2k^2}"/> such that for any <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k"/>-dimensional simplicial complex <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="S"/>, every <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k"/>-complex on <img alt="n \ge n_0(S)" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cge+n_0%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n \ge n_0(S)"/> vertices with at least <img alt="n^{k+1-\lambda_k}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7Bk%2B1-%5Clambda_k%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n^{k+1-\lambda_k}"/>  facets contains a homeomorphic copy of S.</p>
<p>This was previously known only in dimensions one and two, both by highly dimension-specific arguments: the existence of <img alt="\lambda_1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\lambda_1"/> is a result of Mader from 1967, and the existence of <img alt="\lambda_2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_2&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\lambda_2"/> was suggested by Linial in 2006 and recently proved by Keevash-Long-Narayanan-Scott.</p>
<p>Jason Long, Bhargav Narayanan, and Corrine Yap deduce this theorem  from a very interesting purely combinatorial result about trace-bounded hypergraphs.</p>
<p>Here is the link to the aforementioned paper Peter Keevash, Jason Long, Bhargav Narayanan, and Alex Scott: <a href="https://arxiv.org/abs/2004.02657">A universal exponent for homeomorphs</a>. The main theorem asserts that <img alt="\lambda_2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_2&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\lambda_2"/> can be taken to be <strong>14/5</strong>.</p>
<p>Let me also mention a 2018 result by  Agelos Georgakopoulos, John Haslegrave, Richard Montgomery, and Bhargav Narayanan  in their 2018 paper <a href="https://arxiv.org/abs/1808.06864">Spanning surfaces in 3-graphs</a> where they prove a topological extension of Dirac’s theorem about Hamiltonian cycles in graphs proposed by Gowers in 2005.</p>
<p><span style="color: #0000ff;">Finally, finding the correct value for <img alt="\lambda_k" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\lambda_k"/> would be very interesting.</span></p></div>
    </content>
    <updated>2020-11-27T12:12:04Z</updated>
    <published>2020-11-27T12:12:04Z</published>
    <category term="Combinatorics"/>
    <category term="Geometry"/>
    <category term="Alexandr Polyanskii"/>
    <category term="Andrey Kupavskii"/>
    <category term="Bhargav Narayanan"/>
    <category term="Corrine Yap"/>
    <category term="Dmitriy Zakharov"/>
    <category term="Istv&#xE1;n Tomon"/>
    <category term="Jason Long"/>
    <category term="Nati Linial"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-12-04T17:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=522</id>
    <link href="https://tcsplus.wordpress.com/2020/11/27/tcs-talk-wednesday-december-2-yang-liu-stanford-university/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, December 2 — Yang Liu, Stanford University</title>
    <summary>We hope you are all doing well and, in the case of our US audience, are slowly emerging from a comfortable Thanksgiving food-induced stupor! Our last TCS+ talk of the semester will take place this coming Wednesday, December 2nd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Yang […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We hope you are all doing well and, in the case of our US audience, are slowly emerging from a comfortable Thanksgiving food-induced stupor! Our last TCS+ talk of the semester will take place this coming Wednesday, December 2nd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Yang Liu</strong> from Stanford University will speak about “<em>Faster Algorithms for Unit Maximum Flow</em>” (abstract below). </p>



<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>



<p class="wp-block-quote">Abstract: The maximum flow problem is one of the most well-studied problems in combinatorial optimization, encompassing a broad range of cut, matching, and scheduling problems. Here we present a recent line of work obtaining provably faster algorithms for solving the maximum flow problem using interior point methods. In particular, we show how to solve the maximum flow problem in <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002" title="m"/>-edge unit capacity graphs in time almost <img alt="m^{4/3}" class="latex" src="https://s0.wp.com/latex.php?latex=m%5E%7B4%2F3%7D&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002" title="m^{4/3}"/>, improving over the breakthrough <img alt="m^{10/7}" class="latex" src="https://s0.wp.com/latex.php?latex=m%5E%7B10%2F7%7D&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002" title="m^{10/7}"/> time algorithm of Mądry.<br/><br/>This is based on joint work with Aaron Sidford (<a href="https://arxiv.org/abs/1910.14276">arxiv.org/abs/1910.14276</a>, <a href="https://arxiv.org/abs/2003.08929">arxiv.org/abs/2003.08929</a>).</p></div>
    </content>
    <updated>2020-11-27T09:37:25Z</updated>
    <published>2020-11-27T09:37:25Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-12-04T17:21:15Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2020/11/27/reg_dl_not_norm/</id>
    <link href="http://offconvex.github.io/2020/11/27/reg_dl_not_norm/" rel="alternate" type="text/html"/>
    <title>Can implicit regularization in deep learning be explained by norms?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This post is based on my <a href="https://arxiv.org/pdf/2005.06398.pdf">recent paper</a> with <a href="https://noamrazin.github.io/">Noam Razin</a> (to appear at NeurIPS 2020), studying the question of whether norms can explain implicit regularization in deep learning.
TL;DR: we argue they cannot.</p>

<h2 id="implicit-regularization--norm-minimization">Implicit regularization = norm minimization?</h2>

<p>Understanding the implicit regularization induced by gradient-based optimization is possibly the biggest challenge facing theoretical deep learning these days.
In classical machine learning we typically regularize via norms, so it seems only natural to hope that in deep learning something similar is happening under the hood, i.e. the implicit regularization strives to find minimal norm solutions.
This is actually the case in the simple setting of overparameterized linear regression $-$ there, by a folklore analysis (cf. <a href="https://openreview.net/pdf?id=Sy8gdB9xx">Zhang et al. 2017</a>), gradient descent (and any other reasonable gradient-based optimizer) initialized at zero is known to converge to the minimal Euclidean norm solution.
A spur of recent works (see <a href="https://arxiv.org/pdf/2005.06398.pdf">our paper</a> for a thorough review) has shown that for various other models an analogous result holds, i.e. gradient descent (when initialized appropriately) converges to solutions that minimize a certain (model-dependent) norm.
On the other hand, as discussed last year in posts by <a href="http://www.offconvex.org/2019/06/03/trajectories/">Sanjeev</a> as well as <a href="http://www.offconvex.org/2019/07/10/trajectories-linear-nets/">Wei and myself</a>, mounting theoretical and empirical evidence suggest that it may not be possible to generally describe implicit regularization in deep learning as minimization of norms.
Which is it then?</p>

<h2 id="a-standard-test-bed-matrix-factorization">A standard test-bed: matrix factorization</h2>

<p>A standard test-bed for theoretically studying implicit regularization in deep learning is <em>matrix factorization</em> $-$ matrix completion via linear neural networks.
Wei and I already presented this model in our <a href="http://www.offconvex.org/2019/07/10/trajectories-linear-nets/">previous post</a>, but for self-containedness I will do so again here.</p>

<p>In <em>matrix completion</em>, we are given entries $\{ M_{i, j} : (i, j) \in \Omega \}$ of an unknown matrix $M$, and our job is to recover the remaining entries.
This can be seen as a supervised learning (regression) problem, where the training examples are the observed entries of $M$, the model is a matrix $W$ trained with the loss:
[
\qquad \ell(W) = \sum\nolimits_{(i, j) \in \Omega} (W_{i, j} - M_{i, j})^2 ~, \qquad\qquad \color{purple}{\text{(1)}}
]
and generalization corresponds to how similar $W$ is to $M$ in the unobserved locations.
In order for the problem to be well-posed, we have to assume something about $M$ (otherwise the unobserved locations can hold any values, and guaranteeing generalization is impossible).
The standard assumption (which has many <a href="https://en.wikipedia.org/wiki/Matrix_completion#Applications">practical applications</a>) is that $M$ has low rank, meaning the goal is to find, among all global minima of the loss $\ell(W)$, one with minimal rank.
The classic algorithm for achieving this is <a href="https://en.wikipedia.org/wiki/Matrix_norm#Schatten_norms"><em>nuclear norm</em></a> minimization $-$ a convex program which, given enough observed entries and under certain technical assumptions (“incoherence”), recovers $M$ exactly (cf. <a href="https://statweb.stanford.edu/~candes/papers/MatrixCompletion.pdf">Candes and Recht</a>).</p>

<p>Matrix factorization represents an alternative, deep learning approach to matrix completion.
The idea is to use a <em>linear neural network</em> (fully-connected neural network with linear activation), and optimize the resulting objective via gradient descent (GD).
More specifically, rather than working with the loss $\ell(W)$ directly, we choose a depth $L \in \mathbb{N}$, and run GD on the <em>overparameterized objective</em>:
[
\phi ( W_1 , W_2 , \ldots , W_L ) := \ell ( W_L W_{L - 1} \cdots W_1) ~. ~~\qquad~ \color{purple}{\text{(2)}}
]
Our solution to the matrix completion problem is then:
[
\qquad\qquad W_{L : 1} := W_L W_{L - 1} \cdots W_1 ~, \qquad\qquad\qquad \color{purple}{\text{(3)}}
] 
which we refer to as the <em>product matrix</em>.
While (for $L \geq 2$) it is possible to constrain the rank of $W_{L : 1}$ by limiting dimensions of the parameter matrices $\{ W_j \}_j$, from an implicit regularization standpoint, the case of interest is where rank is unconstrained (i.e. dimensions of $\{ W_j \}_j$ are large enough for $W_{L : 1}$ to take on any value).
In this case there is <em>no explicit regularization</em>, and the kind of solution GD will converge to is determined implicitly by the parameterization.
The degenerate case $L = 1$ is obviously uninteresting (nothing is learned in the unobserved locations), but what happens when depth is added ($L \geq 2$)?</p>

<p>In their <a href="https://papers.nips.cc/paper/2017/file/58191d2a914c6dae66371c9dcdc91b41-Paper.pdf">NeurIPS 2017 paper</a>, Gunasekar et al. showed empirically that with depth $L = 2$, if GD is run with small learning rate starting from near-zero initialization, then the implicit regularization in matrix factorization tends to produce low-rank solutions (yielding good generalization under the standard assumption of $M$ having low rank).
They conjectured that behind the scenes, what takes place is the classic nuclear norm minimization algorithm:</p>

<blockquote>
  <p><strong>Conjecture 1 (<a href="https://papers.nips.cc/paper/7195-implicit-regularization-in-matrix-factorization.pdf">Gunasekar et al. 2017</a>; informally stated):</strong>
GD (with small learning rate and near-zero initialization) over a depth $L = 2$ matrix factorization finds solution with minimum nuclear norm.</p>
</blockquote>

<p>Moreover, they were able to prove the conjecture in a certain restricted setting, and others (e.g. <a href="http://proceedings.mlr.press/v75/li18a/li18a.pdf">Li et al. 2018</a>) later derived proofs for additional specific cases.</p>

<p>Two years after Conjecture 1 was made, in a <a href="https://papers.nips.cc/paper/2019/file/c0c783b5fc0d7d808f1d14a6e9c8280d-Paper.pdf">NeurIPS 2019 paper</a> with Sanjeev, Wei and Yuping Luo, we presented empirical and theoretical evidence (see <a href="http://www.offconvex.org/2019/07/10/trajectories-linear-nets/">previous blog post</a> for details) which led us to hypothesize the opposite, namely, that for any depth $L \geq 2$, the implicit regularization in matrix factorization can <em>not</em> be described as minimization of a norm:</p>

<blockquote>
  <p><strong>Conjecture 2 (<a href="https://papers.nips.cc/paper/2019/file/c0c783b5fc0d7d808f1d14a6e9c8280d-Paper.pdf">Arora et al. 2019</a>; informally stated):</strong>
Given a depth $L \geq 2$ matrix factorization, for any norm $\|{\cdot}\|$, there exist matrix completion tasks on which GD (with small learning rate and near-zero initialization) finds solution that does not minimize $\|{\cdot}\|$.</p>
</blockquote>

<p>Due to technical subtleties in their formal statements, Conjectures 1 and 2 do not necessarily contradict.
However, they represent opposite views on the question of whether or not norms can explain implicit regularization in matrix factorization.
The goal of my recent work with <a href="https://noamrazin.github.io/">Noam</a> was to resolve this open question.</p>

<h2 id="implicit-regularization-can-drive-all-norms-to-infinity">Implicit regularization can drive all norms to infinity</h2>

<p>The main result in our <a href="https://arxiv.org/pdf/2005.06398.pdf">paper</a> is a proof that there exist simple matrix completion settings where the implicit regularization in matrix factorization drives <strong><em>all norms towards infinity</em></strong>.
By this we affirm Conjecture 2, and in fact go beyond it in the following sense:
<em>(i)</em> not only is each norm disqualified by some setting, but there are actually settings that jointly disqualify all norms;
and
<em>(ii)</em> not only are norms not necessarily minimized, but they can grow towards infinity.</p>

<p>The idea behind our analysis is remarkably simple.
We prove the following:</p>

<blockquote>
  <p><strong>Theorem (informally stated):</strong>
During GD over matrix factorization (i.e. over $\phi ( W_1 , W_2 , \ldots , W_L)$ defined by Equations $\color{purple}{\text(1)}$ and $\color{purple}{\text(2)}$), if learning rate is sufficiently small and initialization sufficiently close to the origin, then the determinant of the product matrix $W_{1: L}$ (Equation $\color{purple}{\text(3)}$) doesn’t change sign.</p>
</blockquote>

<p>A corollary is that if $\det ( W_{L : 1} )$ is positive at initialization (an event whose probability is $0.5$ under any reasonable initialization scheme), then it stays that way throughout.
This seemingly benign observation has far-reaching implications.
As a simple example, consider the following matrix completion problem ($*$ here stands for unobserved entry):
[
\qquad\qquad
\begin{pmatrix}
* &amp; 1 \newline
1 &amp; 0 
\end{pmatrix}
~. \qquad\qquad \color{purple}{\text{(4)}}
]
Every solution to this problem, i.e. every matrix that agrees with its observations, must have determinant $-1$.
It is therefore only logical to expect that when solving the problem using matrix factorization, the determinant of the product matrix $W_{L : 1}$ will converge to $-1$.
On the other hand, we know that (with probability $0.5$ over initialization) $\det ( W_{L : 1} )$ is always positive, so what is going on?
This conundrum can only mean one thing $-$ as $W_{L : 1}$ fits the observations, its value in the unobserved location (i.e. $(W_{L : 1})_{11}$) diverges to infinity, which implies that <em>all norms grow to infinity!</em></p>

<p>The above idea goes way beyond the simple example given in Equation $\color{purple}{\text(4)}$.
We use it to prove that in a wide array of matrix completion settings, the implicit regularization in matrix factorization leads norms to <em>increase</em>.
We also demonstrate it empirically, showing that in such settings unobserved entries grow during optimization.
Here’s the result of an experiment with the setting of Equation $\color{purple}{\text(4)}$:</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/reg_dl_not_norm_mf_exp.png" style="width: 300px;"/>
<br/>
<i><b>Figure 1:</b> 
Solving matrix completion problem defined by Equation $\color{purple}{\text(4)}$ using matrix factorization leads absolute value of unobserved entry to increase (which in turn means norms increase) as loss decreases.
</i>
</div>

<h2 id="what-is-happening-then">What is happening then?</h2>

<p>If the implicit regularization in matrix factorization is not minimizing a norm, what is it doing?
While a complete theoretical characterization is still lacking, there are signs that a potentially useful interpretation is <strong><em>minimization of rank</em></strong>.
In our aforementioned <a href="https://papers.nips.cc/paper/2019/file/c0c783b5fc0d7d808f1d14a6e9c8280d-Paper.pdf">NeurIPS 2019 paper</a>, we derived a dynamical characterization (and showed supporting experiments) suggesting that matrix factorization is implicitly conducting some kind of greedy low-rank search (see <a href="http://www.offconvex.org/2019/07/10/trajectories-linear-nets/">previous blog post</a> for details).
This phenomenon actually facilitated a new autoencoding architecture suggested in a recent <a href="https://arxiv.org/pdf/2010.00679.pdf">empirical paper</a> (to appear at NeurIPS 2020) by Yann LeCun and his team at Facebook AI.
Going back to the example in Equation $\color{purple}{\text(4)}$, notice that in this matrix completion problem all solutions have rank $2$, but it is possible to essentially minimize rank to $1$ by taking (absolute value of) unobserved entry to infinity.
As we’ve seen, this is exactly what the implicit regularization in matrix factorization does!</p>

<p>Intrigued by the rank minimization viewpoint, <a href="https://noamrazin.github.io/">Noam</a> and I empirically explored an extension of matrix factorization to <em>tensor factorization</em>.
Tensors can be thought of as high dimensional arrays, and they admit natural factorizations similarly to matrices (two dimensional arrays).
We found that on the task of <em>tensor completion</em> (defined analogously to matrix completion $-$ see Equation $\color{purple}{\text(1)}$ and surrounding text), GD on a tensor factorization tends to produce solutions with low rank, where rank is defined in the context of tensors (for a formal definition, and a general intro to tensors and their factorizations, see this <a href="http://www.kolda.net/publication/TensorReview.pdf">excellent survey</a> by Kolda and Bader).
That is, just like in matrix factorization, the implicit regularization in tensor factorization also strives to minimize rank!
Here’s a representative result from one of our experiments:</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/reg_dl_not_norm_tf_exp.png" style="width: 700px;"/>
<br/>
<i><b>Figure 2:</b> 
In analogy with matrix factorization, the implicit regularization of tensor factorization (high dimensional extension) strives to find a low (tensor) rank solution.
Plots show reconstruction error and (tensor) rank of final solution on multiple tensor completion problems differing in the number of observations.
GD over tensor factorization is compared against "linear" method $-$ GD over direct parameterization of tensor initialized at zero (this is equivalent to fitting observations while placing zeros in unobserved locations).
</i>
<br/>
<br/>
</div>

<p>So what can tensor factorizations tell us about deep learning?
It turns out that, similarly to how matrix factorizations correspond to prediction of matrix entries via linear neural networks, tensor factorizations can be seen as prediction of tensor entries with a certain type of <em>non-linear</em> neural networks, named <em>convolutional arithmetic circuits</em> (in my PhD I worked a lot on analyzing the expressive power of these models, as well as showing that they work well in practice $-$ see this <a href="https://arxiv.org/pdf/1705.02302.pdf">survey</a> for a soft overview).</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/reg_dl_not_norm_mf_lnn_tf_cac.png" style="width: 900px;"/>
<br/>
<i><b>Figure 3:</b> 
The equivalence between matrix factorizations and linear neural networks extends to an equivalence between tensor factorizations and a certain type of non-linear neural networks named convolutional arithmetic circuits.
</i>
<br/>
<br/>
</div>

<p>Analogously to how the input-output mapping of a linear neural network can be thought of as a matrix, that of a convolutional
arithmetic circuit is naturally represented by a tensor.
The experiment reported in Figure 2 (and similar ones presented in <a href="https://arxiv.org/pdf/2005.06398.pdf">our paper</a>) thus provides a second example of a neural network architecture whose implicit regularization strives to lower a notion of rank for its input-output mapping.
This leads us to believe that implicit rank minimization may be a general phenomenon, and developing notions of rank for input-output mappings of contemporary models may be key to explaining generalization in deep learning.</p>

<p><a href="http://www.cohennadav.com/">Nadav Cohen</a></p></div>
    </summary>
    <updated>2020-11-27T09:00:00Z</updated>
    <published>2020-11-27T09:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2020-12-03T22:52:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-267315146714574732</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/267315146714574732/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=267315146714574732" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/267315146714574732" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/267315146714574732" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2020/11/tcs-connections-questionnaire.html" rel="alternate" type="text/html"/>
    <title>TCS Connections Questionnaire</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I wanted to link to a survey that is up entitled <a href="https://docs.google.com/forms/d/e/1FAIpQLSeubLuaICwNvHfHto7nBDw_gwkrqKdo-_Fjyz7XZONJ0tJRoA/viewform" rel="nofollow" target="_blank">Committee on TCS Connections Questionnaire</a>.  They are examining modifying approaches to publishing in the theoretical computer science community, and they are focusing on FOCS/STOC.</p><p>I personally approve of the idea of the committee, though I admit I am concerned that it's too little, too late.  For years, FOCS/STOC has been a culture concerned with some sense of "prestige" -- the number of accepted papers has to be kept low, because we want people outside of theory to take FOCS/STOC as an imprimatur for the top theory work.  Because of this, FOCS/STOC has stayed essentially the same size, while the field (whether you view the field as TCS or computer science writ large) has expanded.  This has led to a proliferation of additional conferences (ITCS, HALG, various theory workshops...) that reduce the importance of FOCS/STOC and their role in creating community cohesion.  It has also led to other areas (most notably AI) becoming the home to work that should be quite at home in major TCS conferences.  </p><p>I don't think FOCS/STOC is what is used to be (the central home for theory results, when theory was smaller) or what it has supposedly wanted to be (the home for the best theory results).  I think it makes a lot of sense to stop and think about what they should be for the future.  Hence the survey is important, and I encourage the theoretical computer science community to respond.  I'm not sure, though, that there are great answers -- external forces, and the community's general aversion to change, may mean that there is not much to be done.  </p></div>
    </content>
    <updated>2020-11-26T15:46:00Z</updated>
    <published>2020-11-26T15:46:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2020-11-30T06:16:22Z</updated>
    </source>
  </entry>
</feed>
