<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-02-18T07:22:26Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4616</id>
    <link href="https://www.scottaaronson.com/blog/?p=4616" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4616#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4616" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">My video interview with Lex Fridman at MIT about philosophy and quantum computing</title>
    <summary xml:lang="en-US">Here it is (about 90 minutes; I recommend the 1.5x speed) I had buried this as an addendum to my previous post on the quantum supremacy lecture tour, but then decided that a steely-eyed assessment of what’s likely to have more or less interest for this blog’s readers probably militated in favor of a separate […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://www.youtube.com/watch?v=uX5t8EivCaM">Here it is</a> (about 90 minutes; I recommend the 1.5x speed)</p>



<p>I had buried this as an addendum to my previous post on the quantum supremacy lecture tour, but then decided that a steely-eyed assessment of what’s likely to have more or less interest for this blog’s readers probably militated in favor of a separate post.</p>



<p>Thanks so much to Lex for arranging the interview and for his questions!</p></div>
    </content>
    <updated>2020-02-18T05:36:06Z</updated>
    <published>2020-02-18T05:36:06Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Uncategorized"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-02-18T06:04:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06960</id>
    <link href="http://arxiv.org/abs/2002.06960" rel="alternate" type="text/html"/>
    <title>Computing rank-revealing factorizations of matrices stored out-of-core</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heavner:Nathan.html">Nathan Heavner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Martinsson:Per=Gunnar.html">Per-Gunnar Martinsson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Quintana=Ort=iacute=:Gregorio.html">Gregorio Quintana-Ortí</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06960">PDF</a><br/><b>Abstract: </b>This paper describes efficient algorithms for computing rank-revealing
factorizations of matrices that are too large to fit in RAM, and must instead
be stored on slow external memory devices such as solid-state or spinning disk
hard drives (out-of-core or out-of-memory). Traditional algorithms for
computing rank revealing factorizations, such as the column pivoted QR
factorization, or techniques for computing a full singular value decomposition
of a matrix, are very communication intensive. They are naturally expressed as
a sequence of matrix-vector operations, which become prohibitively expensive
when data is not available in main memory. Randomization allows these methods
to be reformulated so that large contiguous blocks of the matrix can be
processed in bulk. The paper describes two distinct methods. The first is a
blocked version of column pivoted Householder QR, organized as a
``left-looking'' method to minimize the number of write operations (which are
more expensive than read operations on a spinning disk drive). The second
method results in a so called UTV factorization which expresses a matrix $A$ as
$A = U T V^*$ where $U$ and $V$ are unitary, and $T$ is triangular. This method
is organized as an algorithm-by-blocks, in which floating point operations
overlap read and write operations. The second method incorporates power
iterations, and is exceptionally good at revealing the numerical rank; it can
often be used as a substitute for a full singular value decomposition.
Numerical experiments demonstrate that the new algorithms are almost as fast
when processing data stored on a hard drive as traditional algorithms are for
data stored in main memory. To be precise, the computational time for fully
factorizing an $n\times n$ matrix scales as $cn^{3}$, with a scaling constant
$c$ that is only marginally larger when the matrix is stored out of core.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06957</id>
    <link href="http://arxiv.org/abs/2002.06957" rel="alternate" type="text/html"/>
    <title>A Fast Counting Method for 6-motifs with Low Connectivity</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Taha Sevim, Muhammet Selçuk Güvel, Lale Özkahya <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06957">PDF</a><br/><b>Abstract: </b>A $k$-motif (or graphlet) is a subgraph on $k$ nodes in a graph or network.
Counting of motifs in complex networks has been a well-studied problem in
network analysis of various real-word graphs arising from the study of social
networks and bioinformatics. In particular, the triangle counting problem has
received much attention due to its significance in understanding the behavior
of social networks. Similarly, subgraphs with more than 3 nodes have received
much attention recently. While there have been successful methods developed on
this problem, most of the existing algorithms are not scalable to large
networks with millions of nodes and edges.
</p>
<p>The main contribution of this paper is a preliminary study that genaralizes
the exact counting algorithm provided by Pinar, Seshadhri and Vishal to a
collection of 6-motifs. This method uses the counts of motifs with smaller size
to obtain the counts of 6-motifs with low connecivity, that is, containing a
cut-vertex or a cut-edge. Therefore, it circumvents the combinatorial explosion
that naturally arises when counting subgraphs in large networks.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06948</id>
    <link href="http://arxiv.org/abs/2002.06948" rel="alternate" type="text/html"/>
    <title>Finding All Global Minimum Cuts In Practice</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Henzinger:Monika.html">Monika Henzinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Noe:Alexander.html">Alexander Noe</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schulz:Christian.html">Christian Schulz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Strash:Darren.html">Darren Strash</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06948">PDF</a><br/><b>Abstract: </b>We present a practically efficient algorithm that finds all global minimum
cuts in huge undirected graphs. Our algorithm uses a multitude of kernelization
rules to reduce the graph to a small equivalent instance and then finds all
minimum cuts using an optimized version of the algorithm of Nagamochi, Nakao
and Ibaraki. In shared memory we are able to find all minimum cuts of graphs
with up to billions of edges and millions of minimum cuts in a few minutes. We
also give a new linear time algorithm to find the most balanced minimum cuts
given as input the representation of all minimum cuts.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06947</id>
    <link href="http://arxiv.org/abs/2002.06947" rel="alternate" type="text/html"/>
    <title>Efficiently stabbing convex polygons and variants of the Hadwiger-Debrunner $(p, q)$-theorem</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Justin Dallant, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schnider:Patrick.html">Patrick Schnider</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06947">PDF</a><br/><b>Abstract: </b>Hadwiger and Debrunner showed that for families of convex sets in
$\mathbb{R}^d$ with the property that among any $p$ of them some $q$ have a
common point, the whole family can be stabbed with $p-q+1$ points if $p \geq q
\geq d+1$ and $(d-1)p &lt; d(q-1)$. This generalizes a classical result by Helly.
We show how such a stabbing set can be computed for $n$ convex polygons of
constant size in the plane in $O((p-q+1)n^{4/3}\log^{2+\epsilon}(n) +
p^2\log(p))$ expected time. For convex polyhedra in $\mathbb{R}^3$, the method
yields an algorithm running in $O((p-q+1)n^{13/5+\epsilon} + p^4)$ expected
time. We also show that analogous results of the Hadwiger and Debrunner
$(p,q)$-theorem hold in other settings, such as convex sets in
$\mathbb{R}^d\times\mathbb{Z}^k$ or abstract convex geometries.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06912</id>
    <link href="http://arxiv.org/abs/2002.06912" rel="alternate" type="text/html"/>
    <title>A Note on Arc-Disjoint Cycles in Bipartite Tournaments</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Babu:Jasine.html">Jasine Babu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jacob:Ajay_Saju.html">Ajay Saju Jacob</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krithika:R=.html">R. Krithika</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rajendraprasad:Deepak.html">Deepak Rajendraprasad</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06912">PDF</a><br/><b>Abstract: </b>We show that for each non-negative integer k, every bipartite tournament
either contains k arc-disjoint cycles or has a feedback arc set of size at most
7(k - 1).
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06887</id>
    <link href="http://arxiv.org/abs/2002.06887" rel="alternate" type="text/html"/>
    <title>Approximating Multistage Matching Problems</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chimani:Markus.html">Markus Chimani</a>, Niklas Troost, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wiedera:Tilo.html">Tilo Wiedera</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06887">PDF</a><br/><b>Abstract: </b>In multistage perfect matching problems we are given a sequence of graphs on
the same vertex set and asked to find a sequence of perfect matchings,
corresponding to the sequence of graphs, such that consecutive matchings are as
similar as possible. More precisely, we aim to maximize the intersections, or
minimize the unions between consecutive matchings. We show that these problems
are NP-hard even in very restricted scenarios. We propose new approximation
algorithms and present methods to transfer results between different problem
variants without loosing approximation guarantees.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06863</id>
    <link href="http://arxiv.org/abs/2002.06863" rel="alternate" type="text/html"/>
    <title>On the Power and Limits of Dynamic Pricing in Combinatorial Markets</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berger:Ben.html">Ben Berger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eden:Alon.html">Alon Eden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldman:Michal.html">Michal Feldman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06863">PDF</a><br/><b>Abstract: </b>We study the power and limits of optimal dynamic pricing in combinatorial
markets; i.e., dynamic pricing that leads to optimal social welfare. Previous
work by Cohen-Addad et al. [EC'16] demonstrated the existence of optimal
dynamic prices for unit-demand buyers, and showed a market with coverage
valuations that admits no such prices. However, finding the frontier of markets
(i.e., valuation functions) that admit optimal dynamic prices remains an open
problem. In this work we establish positive and negative results that narrow
the existing gap.
</p>
<p>On the positive side, we provide tools for handling markets beyond
unit-demand valuations. In particular, we characterize all optimal allocations
in multi-demand markets. This characterization allows us to partition the items
into equivalence classes according to the role they play in achieving
optimality. Using these tools, we provide a poly-time optimal dynamic pricing
algorithm for up to $3$ multi-demand buyers.
</p>
<p>On the negative side, we establish a maximal domain theorem, showing that for
every non-gross substitutes valuation, there exist unit-demand valuations such
that adding them yields a market that does not admit an optimal dynamic
pricing. This result is reminiscent of the seminal maximal domain theorem by
Gul and Stacchetti [JET'99] for Walrasian equilibrium. Yang [JET'17] discovered
an error in their original proof, and established a different, incomparable
version of their maximal domain theorem. En route to our maximal domain theorem
for optimal dynamic pricing, we provide the first complete proof of the
original theorem by Gul and Stacchetti.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06827</id>
    <link href="http://arxiv.org/abs/2002.06827" rel="alternate" type="text/html"/>
    <title>Large-Scale Evaluation of Shape-Aware Neighborhood Weights &amp; Neighborhood Sizes</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Skrodzki:Martin.html">Martin Skrodzki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zimmermann:Eric.html">Eric Zimmermann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06827">PDF</a><br/><b>Abstract: </b>Point sets arise naturally in many 3D acquisition processes and have diverse
applications in several areas of geometry processing. Besides their
advantages---for instance low storage cost---they do not provide connectivity
information. Thus, for each point, the notion of its neighborhood has to be
defined and computed. Common approaches include combinatorial or geometric
neighborhoods. However, neither of these incorporates curvature information of
the point set. In this paper, we present an approach to take the shape of the
geometry into account when weighting its neighborhoods. This makes the obtained
neighborhoods more reliable in the sense that connectivity also depends on the
orientation of the point set. For example, these neighborhoods grow on a
comparably flat part of the geometry and do not include points on a nearby
surface patch with differently oriented normals. We utilize a sigmoid to define
a neighborhood weighting scheme based on the normal variation. For its
evaluation, we turn to a Shannon entropy model for feature separation. Based on
this model, we apply our weight terms to a large scale of clean and to several
real world models. This evaluation provides results regarding the choice of a
weighting scheme and the neighborhood size.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06812</id>
    <link href="http://arxiv.org/abs/2002.06812" rel="alternate" type="text/html"/>
    <title>Approximate Distance Oracles Subject to Multiple Vertex Failures</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Duan:Ran.html">Ran Duan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gu:Yong.html">Yong Gu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ren:Hanlin.html">Hanlin Ren</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06812">PDF</a><br/><b>Abstract: </b>Given an undirected graph $G=(V,E)$ of $n$ vertices and $m$ edges with
weights in $[1,W]$, we construct vertex sensitive distance oracles (VSDO),
which are data structures that preprocess the graph, and answer the following
kind of queries: Given a source vertex $u$, a target vertex $v$, and a batch of
$d$ failed vertices $D$, output (an approximation of) the distance between $u$
and $v$ in $G-D$ (that is, the graph $G$ with vertices in $D$ removed). An
oracle has stretch $\alpha$ if it always holds that
$\delta_{G-D}(u,v)\le\tilde{\delta}(u,v)\le\alpha\cdot\delta_{G-D}(u,v)$, where
$\delta_{G-D}(u,v)$ is the actual distance between $u$ and $v$ in $G-D$, and
$\tilde{\delta}(u,v)$ is the distance reported by the oracle.
</p>
<p>In this paper we construct efficient VSDOs for any number $d$ of failures.
For any constant $c\geq 1$, we propose two oracles:
</p>
<p>* The first oracle has size $n^{2+1/c}(\log n/\epsilon)^{O(d)}\cdot \log W$,
answers a query in ${\rm poly}(\log n,d^c,\log\log W,\epsilon^{-1})$ time, and
has stretch $1+\epsilon$, for any constant $\epsilon&gt;0$.
</p>
<p>* The second oracle has size $n^{2+1/c}{\rm poly}(\log (nW),d)$, answers a
query in ${\rm poly}(\log n,d^c,\log\log W)$ time, and has stretch ${\rm
poly}(\log n,d)$.
</p>
<p>Both of these oracles can be preprocessed in time polynomial in their space
complexity. These results are the first approximate distance oracles of
poly-logarithmic query time for any constant number of vertex failures in
general undirected graphs. Previously there are $(1+\epsilon)$-approximate
$d$-edge sensitive distance oracles [Chechik et al. 2017] answering distance
queries when $d$ edges fail, which have size $O(n^2(\log n/\epsilon)^d\cdot
d\log W)$ and query time ${\rm poly}(\log n, d, \log\log W)$.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06796</id>
    <link href="http://arxiv.org/abs/2002.06796" rel="alternate" type="text/html"/>
    <title>Detecting $k$-(Sub-)Cadences and Equidistant Subsequence Occurrences</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Funakoshi:Mitsuru.html">Mitsuru Funakoshi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakashima:Yuto.html">Yuto Nakashima</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Inenaga:Shunsuke.html">Shunsuke Inenaga</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bannai:Hideo.html">Hideo Bannai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Takeda:Masayuki.html">Masayuki Takeda</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shinohara:Ayumi.html">Ayumi Shinohara</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06796">PDF</a><br/><b>Abstract: </b>The equidistant subsequence pattern matching problem is considered. Given a
pattern string $P$ and a text string $T$, we say that $P$ is an
\emph{equidistant subsequence} of $T$ if $P$ is a subsequence of the text such
that consecutive symbols of $P$ in the occurrence are equally spaced. We can
consider the problem of equidistant subsequences as generalizations of
(sub-)cadences. We give bit-parallel algorithms that yield $o(n^2)$ time
algorithms for finding $k$-(sub-)cadences and equidistant subsequences.
Furthermore, $O(n\log^2 n)$ and $O(n\log n)$ time algorithms, respectively for
equidistant and Abelian equidistant matching for the case $|P| = 3$, are shown.
The algorithms make use of a technique that was recently introduced which can
efficiently compute convolutions with linear constraints.
</p></div>
    </summary>
    <updated>2020-02-18T02:20:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06786</id>
    <link href="http://arxiv.org/abs/2002.06786" rel="alternate" type="text/html"/>
    <title>DAWGs for parameterized matching: online construction and related indexing structures</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakashima:Katsuhito.html">Katsuhito Nakashima</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fujisato:Noriki.html">Noriki Fujisato</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hendrian:Diptarama.html">Diptarama Hendrian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakashima:Yuto.html">Yuto Nakashima</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yoshinaka:Ryo.html">Ryo Yoshinaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Inenaga:Shunsuke.html">Shunsuke Inenaga</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bannai:Hideo.html">Hideo Bannai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shinohara:Ayumi.html">Ayumi Shinohara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Takeda:Masayuki.html">Masayuki Takeda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06786">PDF</a><br/><b>Abstract: </b>Two strings $x$ and $y$ over $\Sigma \cup \Pi$ of equal length are said to
parameterized match (p-match) if there is a renaming bijection $f:\Sigma \cup
\Pi \rightarrow \Sigma \cup \Pi$ that is identity on $\Sigma$ and transforms
$x$ to $y$ (or vice versa). The p-matching problem is to look for substrings in
a text that p-match a given pattern. In this paper, we propose parameterized
suffix automata (p-suffix automata) and parameterized directed acyclic word
graphs (PDAWGs) which are the p-matching versions of suffix automata and DAWGs.
While suffix automata and DAWGs are equivalent for standard strings, we show
that p-suffix automata can have $\Theta(n^2)$ nodes and edges but PDAWGs have
only $O(n)$ nodes and edges, where $n$ is the length of an input string. We
also give $O(n |\Pi| \log (|\Pi| + |\Sigma|))$-time $O(n)$-space algorithm that
builds the PDAWG in a left-to-right online manner. We then show that an
implicit representation for the PDAWG can be built in $O(n \log (|\Pi| +
|\Sigma|))$ time and $O(n)$ space from left to right. As a byproduct, it is
shown that the parameterized suffix tree for the reversed string can also be
built in the same time and space, in a right-to-left online manner. We also
discuss parameterized compact DAWGs.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06764</id>
    <link href="http://arxiv.org/abs/2002.06764" rel="alternate" type="text/html"/>
    <title>Computing Covers under Substring Consistent Equivalence Relations</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Natsumi Kikuchi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hendrian:Diptarama.html">Diptarama Hendrian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yoshinaka:Ryo.html">Ryo Yoshinaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shinohara:Ayumi.html">Ayumi Shinohara</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06764">PDF</a><br/><b>Abstract: </b>Covers are a kind of quasiperiodicity in strings. A string $C$ is a cover of
another string $T$ if any position of $T$ is inside some occurrence of $C$ in
$T$. The literature has proposed linear-time algorithms computing longest and
shortest cover arrays taking border arrays as input. An equivalence relation
$\approx$ over strings is called a substring consistent equivalence relation
(SCER) iff $X \approx Y$ implies (1) $|X| = |Y|$ and (2) $X[i:j] \approx
Y[i:j]$ for all $1 \le i \le j \le |X|$. In this paper, we generalize the
notion of covers for SCERs and prove that existing algorithms to compute the
shortest cover array and the longest cover array of a string $T$ under the
identity relation will work for any SCERs taking the accordingly generalized
border arrays.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06762</id>
    <link href="http://arxiv.org/abs/2002.06762" rel="alternate" type="text/html"/>
    <title>How fast can you update your MST? (Dynamic algorithms for cluster computing)</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gilbert:Seth.html">Seth Gilbert</a>, Lawrence Li <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06762">PDF</a><br/><b>Abstract: </b>Imagine a large graph that is being processed by a cluster of computers,
e.g., described by the $k$-machine model or the Massively Parallel Computation
Model. The graph, however, is not static; instead it is receiving a constant
stream of updates. How fast can the cluster process the stream of updates? The
fundamental question we want to ask in this paper is whether we can update the
graph fast enough to keep up with the stream. We focus specifically on the
problem of maintaining a minimum spanning tree (MST), and we give an algorithm
for the $k$-machine model that can process $O(k)$ graph updates per $O(1)$
rounds with high probability. (And these results carry over to the Massively
Parallel Computation (MPC) model.) We also show a lower bound, i.e., it is
impossible to process $k^{1+\epsilon}$ updates in $O(1)$ rounds. Thus we
provide a nearly tight answer to the question of how fast a cluster can respond
to a stream of graph modifications while maintaining an MST.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06752</id>
    <link href="http://arxiv.org/abs/2002.06752" rel="alternate" type="text/html"/>
    <title>Overlaid oriented Voronoi diagrams and the 1-Steiner tree problem</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Payne:Michael_S=.html">Michael S. Payne</a>, Charl Ras, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Volz:Marcus.html">Marcus Volz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06752">PDF</a><br/><b>Abstract: </b>Overlaid oriented Voronoi diagrams (OOVDs) are known to provide useful data
for the construction of optimal Euclidean $1$-Steiner trees. The theoretical
time complexity of construction methods exploiting the OOVD is $O(n^2)$, but a
computational study has never been performed, and robust constructions for
OOVDs have not previously been implemented.
</p>
<p>In this paper, we outline a numerically stable implementation for
constructing OOVDs using tools from the Computational Geometry Algorithms
Library (CGAL), and test its performance on random point sets. We then study
the effect that the OOVD data has in reducing the complexity of $1$-Steiner
tree construction when compared to a naive approach. The number of iterations
of the main loop of the 1-Steiner algorithm is directly determined by the
number of faces in the OOVD, and this appears to be linear for the random
inputs we tested. We also discuss methods for processing the OOVD data that
lead to a reduction in construction time by roughly a factor of 12.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06742</id>
    <link href="http://arxiv.org/abs/2002.06742" rel="alternate" type="text/html"/>
    <title>(Individual) Fairness for $k$-Clustering</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahabadi:Sepideh.html">Sepideh Mahabadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vakilian:Ali.html">Ali Vakilian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06742">PDF</a><br/><b>Abstract: </b>We give a local search based algorithm for $k$-median ($k$-means) clustering
from the perspective of individual fairness. More precisely, for a point $x$ in
a point set $P$ of size $n$, let $r(x)$ be the minimum radius such that the
ball of radius $r(x)$ centered at $x$ has at least $n/k$ points from $P$.
Intuitively, if a set of $k$ random points are chosen from $P$ as centers,
every point $x\in P$ expects to have a center within radius $r(x)$. An
individually fair clustering provides such a guarantee for every point $x\in
P$. This notion of fairness was introduced in [Jung et al., 2019] where they
showed how to get an approximately feasible $k$-clustering with respect to this
fairness condition.
</p>
<p>In this work, we show how to get an approximately optimal such fair
$k$-clustering. The $k$-median ($k$-means) cost of our solution is within a
constant factor of the cost of an optimal fair $k$-clustering, and our solution
approximately satisfies the fairness condition (also within a constant factor).
Further, we complement our theoretical bounds with empirical evaluation.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06712</id>
    <link href="http://arxiv.org/abs/2002.06712" rel="alternate" type="text/html"/>
    <title>Computing Boundary Cycle of a Pseudo-Triangle Polygon from its Visibility Graph</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Hossein Boomari Soheila Farokhi <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06712">PDF</a><br/><b>Abstract: </b>Visibility graph of a simple polygon is a graph with the same vertex set in
which there is an edge between a pair of vertices if and only if the segment
through them lies completely inside the polygon. Each pair of adjacent vertices
on the boundary of the polygon are assumed to be visible. Therefore, the
visibility graph of each polygon always contains its boundary edges. This
implies that we have always a Hamiltonian cycle in a visibility graph which
determines the order of vertices on the boundary of the corresponding polygon.
In this paper, we propose a polynomial time algorithm for determining such a
Hamiltonian cycle for a pseudo-triangle polygon from its visibility graph.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06683</id>
    <link href="http://arxiv.org/abs/2002.06683" rel="alternate" type="text/html"/>
    <title>The normalized algorithmic information distance can not be approximated</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bauwens:Bruno.html">Bruno Bauwens</a>, Ilya Blinnikov <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06683">PDF</a><br/><b>Abstract: </b>It is known that the normalized algorithmic information distance $N$ is not
computable and not semicomputable. We show that for all $\epsilon &lt; 1/2$, there
exist no semicomputable functions that differ from $N$ by at most~$\epsilon$.
Moreover, for any computable function $f$ such that $|\lim_t f(x,y,t) - N(x,y)|
\le \epsilon$ and for all $n$, there exist strings $x,y$ of length $n$ such
that $\sum_t |f(x,y,t+1) - f(x,y,t)| \ge \Omega(\log n)$. This is optimal up to
constant factors. We also show that the maximal number of oscillations of a
limit approximation of $N$ is $\Omega(n/\log n)$. This strengthens the
$\omega(1)$ lower bound from [K. Ambos-Spies, W. Merkle, and S.A. Terwijn,
2019, Normalized information distance and the oscillation hierarchy], see
<a href="http://export.arxiv.org/abs/1708.03583">arXiv:1708.03583</a> .
</p></div>
    </summary>
    <updated>2020-02-18T02:20:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06650</id>
    <link href="http://arxiv.org/abs/2002.06650" rel="alternate" type="text/html"/>
    <title>Coresets for the Nearest-Neighbor Rule</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Alejandro Flores Velazco, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mount:David_M=.html">David M. Mount</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06650">PDF</a><br/><b>Abstract: </b>The problem of nearest-neighbor condensation deals with finding a subset R
from a set of labeled points P such that for every point p in R the
nearest-neighbor of p in R has the same label as p. This is motivated by
applications in classification, where the nearest-neighbor rule assigns to an
unlabeled query point the label of its nearest-neighbor in the point set. In
this context, condensation aims to reduce the size of the set needed to
classify new points. However, finding such subsets of minimum cardinality is
NP-hard, and most research has focused on practical heuristics without
performance guarantees. Additionally, the use of exact nearest-neighbors is
always assumed, ignoring the effect of condensation in the classification
accuracy when nearest-neighbors are computed approximately.
</p>
<p>In this paper, we address these shortcomings by proposing new
approximation-sensitive criteria for the nearest-neighbor condensation problem,
along with practical algorithms with provable performance guarantees. We
characterize sufficient conditions to guarantee correct classification of
unlabeled points using approximate nearest-neighbor queries on these subsets,
which introduces the notion of coresets for classification with the
nearest-neighbor rule. Moreover, we prove that it is NP-hard to compute subsets
with these characteristics, whose cardinality approximates that of the minimum
cardinality subset. Additionally, we propose new algorithms for computing such
subsets, with tight approximation factors in general metrics, and improved
factors for doubling metrics and l_p metrics with p &gt;= 2. Finally, we show an
alternative implementation scheme that reduces the worst-case time complexity
of one of these algorithms, becoming the first truly subquadratic approximation
algorithm for the nearest-neighbor condensation problem.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06451</id>
    <link href="http://arxiv.org/abs/2002.06451" rel="alternate" type="text/html"/>
    <title>Symmetric Arithmetic Circuits</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dawar:Anuj.html">Anuj Dawar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wilsenach:Gregory.html">Gregory Wilsenach</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06451">PDF</a><br/><b>Abstract: </b>We introduce symmetric arithmetic circuits, i.e. arithmetic circuits with a
natural symmetry restriction. In the context of circuits computing polynomials
defined on a matrix of variables, such as the determinant or the permanent, the
restriction amounts to requiring that the shape of the circuit is invariant
under row and column permutations of the matrix. We establish unconditional,
nearly exponential, lower bounds on the size of any symmetric circuit for
computing the permanent over any field of characteristic other than 2. In
contrast, we show that there are polynomial-size symmetric circuits for
computing the determinant over fields of characterisitic zero.
</p></div>
    </summary>
    <updated>2020-02-18T02:20:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06421</id>
    <link href="http://arxiv.org/abs/2002.06421" rel="alternate" type="text/html"/>
    <title>Kruskal-based approximation algorithm for the multi-level Steiner tree problem</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Reyan Ahmed, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sahneh:Faryad_Darabi.html">Faryad Darabi Sahneh</a>, Stephen Kobourov, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spence:Richard.html">Richard Spence</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06421">PDF</a><br/><b>Abstract: </b>We study the multi-level Steiner tree problem: a generalization of the
Steiner tree problem in graphs, in which the terminals $T$ require different
levels, or equivalently, have different priorities. The problem requires that
terminals be connected with edges satisfying their priority requirements and
has applications in network design and multi-level graph visualization. The
case where edge costs are proportional to their priority is approximable to
within a constant factor from the optimal solution. For the more general case
of non-proportional costs, the problem is hard to approximate to within a ratio
of $\log \log n$, where $n$ is the number of vertices in the graph. A simple
greedy algorithm by Charikar et al., however, provides a $\min\{2(\ln |T|+1),
\ell \rho\}$-approximation in this setting.
</p>
<p>In this paper, we describe a natural generalization to the multi-level case
of the classical (single-level) Steiner tree approximation algorithm based on
Kruskal's minimum spanning tree algorithm. We prove that this algorithm
achieves an approximation ratio at least as good as Charikar et al., and
experimentally performs better with respect to the optimum solution. We develop
an integer linear programming formulation to compute an exact solution for the
multi-level Steiner tree problem with non-proportional edge costs and use it to
evaluate the performance of our algorithm.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06418</id>
    <link href="http://arxiv.org/abs/2002.06418" rel="alternate" type="text/html"/>
    <title>A Note on Unbounded Polyhedra Derived from Convex Caps</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Joseph O'Rourke <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06418">PDF</a><br/><b>Abstract: </b>The construction of an unbounded polyhedron from a "jagged'' convex cap is
described, and several of its properties discussed, including its relation to
Alexandrov's "limit angle."
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06296</id>
    <link href="http://arxiv.org/abs/2002.06296" rel="alternate" type="text/html"/>
    <title>Sparse Coresets for SVD on Infinite Streams</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Braverman:Vladimir.html">Vladimir Braverman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldman:Dan.html">Dan Feldman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lang:Harry.html">Harry Lang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rus:Daniela.html">Daniela Rus</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Statman:Adiel.html">Adiel Statman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06296">PDF</a><br/><b>Abstract: </b>In streaming Singular Value Decomposition (SVD), $d$-dimensional rows of a
possibly infinite matrix arrive sequentially as points in $\mathbb{R}^d$. An
$\epsilon$-coreset is a (much smaller) matrix whose sum of square distances of
the rows to any hyperplane approximates that of the original matrix to a $1 \pm
\epsilon$ factor. Our main result is that we can maintain a $\epsilon$-coreset
while storing only $O(d \log^2 d / \epsilon^2)$ rows. Known lower bounds of
$\Omega(d / \epsilon^2)$ rows show that this is nearly optimal. Moreover, each
row of our coreset is a weighted subset of the input rows. This is highly
desirable since it: (1) preserves sparsity; (2) is easily interpretable; (3)
avoids precision errors; (4) applies to problems with constraints on the input.
Previous streaming results for SVD that return a subset of the input required
storing $\Omega(d \log^3 n / \epsilon^2)$ rows where $n$ is the number of rows
seen so far. Our algorithm, with storage independent of $n$, is the first
result that uses finite memory on infinite streams. We support our findings
with experiments on the Wikipedia dataset benchmarked against state-of-the-art
algorithms.
</p></div>
    </summary>
    <updated>2020-02-18T02:30:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06265</id>
    <link href="http://arxiv.org/abs/2002.06265" rel="alternate" type="text/html"/>
    <title>On Extensions of Maximal Repeats in Compressed Strings</title>
    <feedworld_mtime>1581984000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pape=Lange:Julian.html">Julian Pape-Lange</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06265">PDF</a><br/><b>Abstract: </b>This paper provides an upper bound for several subsets of maximal repeats and
maximal pairs in compressed strings and also presents a formerly unknown
relationship between maximal pairs and the run-length Burrows-Wheeler
transform.
</p>
<p>This relationship is used to obtain a different proof for the Burrows-Wheeler
conjecture which has recently been proven by Kempa and Kociumaka in "Resolution
of the Burrows-Wheeler Transform Conjecture".
</p>
<p>More formally, this paper proves that a string $S$ with $z$ LZ77-factors and
without $q$-th powers has at most $73(\log_2 |S|)(z+2)^2$ runs in the
run-length Burrows-Wheeler transform and the number of arcs in the compacted
directed acyclic word graph of $S$ is bounded from above by $18q(1+\log_q
|S|)(z+2)^2$.
</p></div>
    </summary>
    <updated>2020-02-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://corner.mimuw.edu.pl/?p=1104</id>
    <link href="http://corner.mimuw.edu.pl/?p=1104" rel="alternate" type="text/html"/>
    <title>Postdoc position in theoretical computer science</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">We announce POSTDOC POSITIONS  at the Institute of Informatics, University of Warsaw, Poland. The positions are supported by the ERC Consolidator Grant TUgbOAT: “Towards Unification of Algorithmic Tools” led by Piotr Sankowski. The TUgbOAT’ focus is on basic algorithmic problems. … <a href="http://corner.mimuw.edu.pl/?p=1104">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We announce</p>



<p><strong>POSTDOC POSITIONS </strong></p>



<p>at the Institute of Informatics, University of Warsaw, Poland. The positions are supported by the ERC Consolidator Grant TUgbOAT: “Towards Unification of Algorithmic Tools” led by Piotr Sankowski.</p>



<p>The TUgbOAT’ focus is on basic algorithmic problems. Example topics include:</p>



<p> * algorithms for finding matchings in graphs;</p>



<p> * online algorithms in various settings;</p>



<p> * studying and algorithmically exploiting properties of data.</p>



<p>The theoretical computer science group in Warsaw is strong and growing. Apart from the algorithms group members specializing in parameterized, approximation and graph algorithms (Łukasz Kowalik, Marcin Mucha, Marcin Pilipczuk, Michał Pilipczuk, Piotr Sankowski), we have also a leading research group in logic and automata (Mikołaj Bojańczyk, Bartosz Klin, Sławomir Lasota).</p>



<p>We are looking for outstanding <strong>candidates with a Ph.D.</strong> (or soon to obtain a Ph.D.) in Computer Science or Mathematics who have already proven their high scientific potential in the area of algorithms or graph theory through publications in proceedings of highly ranked international conferences and/or journals. Background in the specific areas of projects in question will be an advantage.</p>



<p>The gross annual salary is around <strong>100,000 PLN</strong>. For comparison, this translates to around twice the average salary in Poland. The position comes with <strong>generous travel support</strong> and <strong>no teaching duties</strong>. The application deadline is <strong>15th March 2020</strong>. The default length of the contract is one year. The starting date is flexible.</p>



<p>To apply, send a CV to Piotr Sankowski &lt;sank@mimuw.edu.pl&gt;.</p>



<p>Questions and informal inquiries are welcome.</p></div>
    </content>
    <updated>2020-02-17T22:07:25Z</updated>
    <published>2020-02-17T22:07:25Z</published>
    <category term="post"/>
    <author>
      <name>Renata Czarniecka</name>
    </author>
    <source>
      <id>http://corner.mimuw.edu.pl</id>
      <link href="http://corner.mimuw.edu.pl/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="http://corner.mimuw.edu.pl" rel="alternate" type="text/html"/>
      <subtitle>University of Warsaw</subtitle>
      <title>Banach's Algorithmic Corner</title>
      <updated>2020-02-18T00:01:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4608</id>
    <link href="https://www.scottaaronson.com/blog/?p=4608" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4608#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4608" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">My “Gil Kalai Was Wrong” 2020 World Speaking Tour</title>
    <summary xml:lang="en-US">(An anonymous friend suggested the above title for what I’ve been doing all winter: traveling the world in response to various invitations to give talks about the theoretical foundations of quantum supremacy experiments, Google’s recent claimed achievement of quantum supremacy, and what it means for quantum computing’s future prospects. I wish to clarify that I […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>(An anonymous friend suggested the above title for what I’ve been doing all winter: traveling the world in response to various invitations to give talks about the theoretical foundations of quantum supremacy experiments, Google’s recent claimed achievement of quantum supremacy, and what it means for quantum computing’s future prospects.  I wish to clarify that I <em>by no means</em> endorse my friend’s title; I’m merely passing it along.)</p>



<p>As part of the tour, I’ve already given talks at the following fine places:</p>



<p>World Economic Forum at Davos<br/>University of Waterloo<br/>Perimeter Institute<br/>UC Berkeley<br/>Harvard<br/>MIT<br/>Princeton</p>



<p>And I’ll be giving talks at the following places over the next couple of months:</p>



<p>University of Houston<br/>Louisiana State University<br/>Pittsburgh Quantum Institute<br/>Fermilab<br/>Yale</p>



<p>For anyone who’s interested, I’ll add links and dates to this post later (if you want that to happen any faster, feel free to hunt them down for me!).</p>



<p>In the meantime, there are also interviews!  See, for example, <a href="https://www.texasstandard.org/stories/why-quantum-computing-gets-special-attention-in-the-trump-administrations-budget-proposal/">this 5-minute one on Texas Standard</a> (an NPR affiliate), where I’m asked about the current state of quantum computing in the US, in light of the Trump administration’s recent proposal to give a big boost to quantum computing and AI research, even while slashing and burning basic science more broadly.  I made some critical comments—for example, about the need to support the whole basic research ecosystem (I pointed out that “quantum computing can’t thrive in isolation”), and also about the urgent need to make it feasible for the best researchers from around the world to get US visas and green cards.  Unfortunately, those parts seem to have been edited out, in favor of my explanations of basic points about quantum computing.</p>



<p><strong>More Updates:</strong></p>



<p>There was a discussion on Twitter of the ethics of the “Quantum Bullshit Detector” Twitter feed—which dishes out vigilante justice,  like some dark and troubled comic-book hero, by rendering anonymous, unexplained, unaccountable, very often correct albeit not infallible verdicts of “Bullshit” or “Not Bullshit” on claimed quantum information advances.  As part of that discussion, <a href="https://twitter.com/cjsavoie/status/1229495571016278017">Christopher Savoie wrote</a>:</p>



<blockquote class="wp-block-quote"><p>[Criticizing] is what we do in science.  [But not calling] “bullshit” anonymously and without any accountability.  Look at Scott Aaronson’s blog.  He takes strong positions.  But as Scott.  I respect that.</p></blockquote>



<p>What do people think: should “He takes strong positions.  But as Scott.” be added onto the <em>Shtetl-Optimized</em> header bar?</p>



<p>In other news, I was amused by the following headline, for a <em>Vice</em> story about the MIP*=RE breakthrough: <a href="https://www.vice.com/en_us/article/xgqg9a/mathematicians-are-studying-planet-sized-quantum-computers-with-god-like-powers">Mathematicians Are Studying Planet-Sized Supercomputers With God-Like Powers</a>.  (If I’m going to quibble about accuracy: only planet-sized???)</p></div>
    </content>
    <updated>2020-02-17T20:41:10Z</updated>
    <published>2020-02-17T20:41:10Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Adventures in Meatspace"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-02-18T06:04:57Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/02/17/spanners-have-sparse</id>
    <link href="https://11011110.github.io/blog/2020/02/17/spanners-have-sparse.html" rel="alternate" type="text/html"/>
    <title>Spanners have sparse crossings</title>
    <summary>In a 2017 SIGSPATIAL paper with Sid Gupta, Sid and I modeled non-planar road networks as graph drawings whose edges intersect sparsely, and showed that this implies that these graphs have small separators, allowing algorithms designed for planar graphs (such as linear-time shortest paths) to be extended to them. My latest preprint, with UCI student Hadi Khodabandeh, uses similar ideas of sparse edge intersections to show that greedy geometric spanners also have small separators. The paper is “On the edge crossings of the greedy spanner” (arXiv:2002.05854).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In a <a href="https://arxiv.org/abs/1709.06113">2017 SIGSPATIAL paper</a> with Sid Gupta, Sid and I <a href="https://11011110.github.io/blog/2017/09/19/graphs-with-sparse.html">modeled non-planar road networks as graph drawings whose edges intersect sparsely, and showed that this implies that these graphs have small separators</a>, allowing algorithms designed for planar graphs (such as linear-time shortest paths) to be extended to them. My latest preprint, with UCI student Hadi Khodabandeh, uses similar ideas of sparse edge intersections to show that <a href="https://en.wikipedia.org/wiki/Greedy_geometric_spanner">greedy geometric spanners</a> also have small separators. The paper is <a href="https://arxiv.org/abs/2002.05854">“On the edge crossings of the greedy spanner” (arXiv:2002.05854)</a>.</p>

<p>Here, a spanner is a graph whose vertices are a given finite set of points in the plane, with the property that shortest paths in the graph (with distance measured geometrically along each edge) are a good approximation to shortest paths in the plane, the straight line segments between two given points. The graph is not allowed to have extra vertices, and we don’t care about distances between points that are not in the given set. These things have all sorts of applications, for instance in approximation algorithms (you can approximate a geometric problem involving distances by solving a graph problem on the spanner). Of course, a <a href="https://en.wikipedia.org/wiki/Complete_graph">complete graph</a> is a spanner in this sense, but it has a lot of edges. We’d like spanners that are sparser, and still accurately approximate all the distances.</p>

<p>You can get a constant-factor approximation with some planar graphs (like the Delaunay triangulation), and planar graphs are sparse and have <a href="https://en.wikipedia.org/wiki/Planar_separator_theorem">good separators</a>, among other properties. But the example of four points in a square shows that to get a distance ratio better than  we need to allow edges to cross each other. A standard way of doing this is to use a greedy algorithm: just consider all pairs of points, in order, and add an edge when the graph you’ve built so far doesn’t include a short-enough path between them. For any target distance ratio, this turns out to give spanners that are sparse (a linear rather than quadratic number of edges, and more strongly having bounded degree at each vertex) and low weight (within a constant factor of the minimum spanning tree). Versions of these spanners can be constructed in near-linear time, and work in Euclidean spaces of any bounded dimension.</p>

<p>Here, for instance, is a greedy spanner of 100 random points with distance ratio 2 (big enough that, in this example, there are no crossings):</p>

<p style="text-align: center;"><img alt="Greedy spanner with distance ratio 2" src="https://11011110.github.io/blog/assets/2020/greedy2.svg"/></p>

<p>And here is a much more accurate greedy spanner on the same points, one with distance ratio 1.1:</p>

<p style="text-align: center;"><img alt="Greedy spanner with distance ratio 1.1" src="https://11011110.github.io/blog/assets/2020/greedy1.1.svg"/></p>

<p>What we show is that for greedy spanners in the plane, each spanner edge is crossed by a bounded number of longer or equal-length edges. An edge can be crossed by an unbounded number of shorter edges, but our result implies that the <a href="https://en.wikipedia.org/wiki/Intersection_graph">intersection graph</a> of the edges is itself a sparse graph. (In any subgraph of the intersection graph, the longest edge has bounded degree, so the graph as a whole has bounded <a href="https://en.wikipedia.org/wiki/Degeneracy_(graph_theory)">degeneracy</a>.) And that, in combination with the results of the SIGSPATIAL paper, implies that these graphs also have small separators: any -vertex subgraph of a greedy spanner can be split into two smaller graphs of at most  vertices each by the removal of  vertices.</p>

<p>Unlike many of the other known results on greedy spanners, this works only in the plane. It doesn’t make sense to talk about crossings in higher-dimensional greedy spanners, because for points in general position there won’t be any crossings, even in the complete graph. So we don’t know whether higher-dimensional greedy spanners have sublinear separators or not; it would be of interest to find out.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/103677400632411777">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-02-17T18:01:00Z</updated>
    <published>2020-02-17T18:01:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-02-18T02:08:07Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-25562705.post-3683250814233232375</id>
    <link href="http://aaronsadventures.blogspot.com/feeds/3683250814233232375/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=25562705&amp;postID=3683250814233232375" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/3683250814233232375" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/3683250814233232375" rel="self" type="application/atom+xml"/>
    <link href="http://aaronsadventures.blogspot.com/2020/02/fair-prediction-with-endogenous-behavior.html" rel="alternate" type="text/html"/>
    <title>Fair Prediction with Endogenous Behavior</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h2 style="text-align: center;">Can Game Theory Help Us Choose Among Fairness Constraints?</h2><br/><div style="text-align: center;"><i>This blog post is about a <a href="https://www.cis.upenn.edu/~aaroth/Papers/endogenous.pdf">new paper</a>, joint with Christopher Jung, Sampath Kannan, Changhwa Lee, Mallesh M. Pai, and Rakesh Vohra.</i></div><br/><br/>A lot of the recent boom in interest in fairness in machine learning can be traced back to the 2016 Propublica article <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Machine Bias</a>. To summarize what you will already know if you have interacted with the algorithmic fairness literature at all --- Propublica discovered that the COMPAS recidivism prediction instrument (used to inform bail and parole decisions by predicting whether individuals would go on to commit violent crimes if released)  made errors of different sorts on different populations. The false positive rate (i.e. the rate at which it incorrectly labeled people "high risk") was much higher on the African American population than on the white population, and the false negative rate (i.e. the rate at which it incorrectly labeled people as "low risk") was much higher on the white population. Because being falsely labeled high risk is harmful (it decreases the chance you are released), this was widely and reasonably viewed as unfair.<br/><br/>But the story wasn't so simple. Northpointe, the company that produced COMPAS (They have since changed their name) <a href="https://go.volarisgroup.com/rs/430-MBX-989/images/ProPublica_Commentary_Final_070616.pdf">responded </a>by pointing out that their instrument satisfied predictive parity across the two populations --- i.e. that the <i>positive predictive value </i>of their instrument was roughly the same for both white and African American populations. This means that their predictions conveyed the same meaning across the two populations: the people that COMPAS predicted were high risk had roughly the same chance of recidivating, on average, whether or not they were black or white. This is also desirable, because if we use an instrument that produces predictions whose meanings differ according to an individual's demographic group, then we are explicitly incentivizing judges to make decisions based on race, after they are shown the prediction of the instrument. Of course, we now know that simultaneously equalizing false positive rates, false negative rates, and positive predictive values across populations is <a href="https://arxiv.org/abs/1610.07524">generically impossible</a> --- i.e. it is impossible except under very special conditions, such as when the underlying crime rate is exactly the same in both populations. This <a href="http://aaronsadventures.blogspot.com/2019/02/impossibility-results-in-fairness-as.html">follows from thinking about Bayes Rule</a>.<br/><br/>Another sensible notion of fairness suggests that "similarly risky people should be treated similarly". This harkens back to notions of <a href="https://arxiv.org/abs/1104.3913">individual fairness</a>, and suggests that we should do something like the following: we should gather as much information about an individual as we possibly can, and condition on all of it to find a (hopefully correct) posterior belief that they will go on to commit a crime. Then, we should make incarceration decisions by subjecting everyone to the same threshold on these posterior beliefs --- any individual who crosses some uniform threshold should be incarcerated; anyone who doesn't cross the threshold should not be. This is the approach that <a href="https://arxiv.org/abs/1808.00023">Corbett-Davies and Goel </a>advocate for, and it seems to have a lot going for it. In addition to uniform thresholds feeling fair, its also easy to see that doing this is the Bayes-optimal decision rule to optimize any societal cost function that differently weights the cost of false positives and false negatives. But applying a uniform threshold on posterior distributions unfortunately will generally result in a decision rule that neither equalizes false positive and false negative rates, nor positive predictive value. Similarly, satisfying these other notions of fairness will generally result in a decision rule that is sub-optimal in terms of its predictive performance.<br/><br/>Unfortunately, this leaves us with little guidance --- should we aim to equalize false positive and negative rates (sometime called <i><a href="https://arxiv.org/abs/1610.02413">equalized odds</a></i> in this literature)? Should we aim to equalize positive predictive value? Or should we aim for using uniform thresholds on posterior beliefs? Should we aim for something else entirely? More importantly, by what means should we aim to make these decisions?<br/><br/><h2>A Game Theoretic Model</h2><div>One way we can attempt to choose among different fairness "solution concepts" is to try and think about the larger societal effects that imposing a fairness constraint on a classifier will have. This is tricky, of course --- if we don't commit to some model of the world, then different fairness constraints can have either <a href="https://arxiv.org/abs/1803.04383">good or bad long term effects</a>, which still doesn't give us much guidance. Of course making modeling assumptions has its own risks: inevitably the model won't match reality, and we should worry that the results that we derive in our stylized model will not tell us anything useful about the real world. Nevertheless, it is worth trying to proceed: all models are wrong, but some are useful. Our goal will be to come up with a clean, simple model, in which results are robust to modelling choices, and the necessary assumptions are clearly identified. Hopefully the result is some nugget of insight that applies outside of the model. This is what we try to do in our <a href="https://www.cis.upenn.edu/~aaroth/Papers/endogenous.pdf">new paper</a> with Chris Jung, Sampath Kannan, Changhwa Lee, Mallesh Pai, and Rakesh Vohra. We'll use the language of criminal justice here, but the model is simple enough that you could apply it to a number of other settings of interest in which we need to design binary classification rules. </div><div><br/></div><div>In our model, individuals make rational choices about whether or not to commit crimes: that is, individuals have some "outside option" (their opportunity for legal employment, for example), some expected monetary benefit of crime, and some dis-utility for being incarcerated. In deciding whether or not to commit a crime, an individual will weigh their expected benefit of committing a crime, compared to taking their outside option ---- and this calculation will involve their risk of being incarcerated if they commit a crime, and also if they do not (since inevitably any policy will both occasionally free the guilty as well as incarcerate the innocent). Different people might make different decisions because their benefits and costs of crime may differ --- for example, some people will have better opportunities for legal employment than others. And in our model, the only way two different populations differ is in their distributions of these benefits and costs. Each person draws, i.i.d. from a distribution corresponding to their group, a type which encodes this outside option value and cost for incarceration. So in our model, populations differ e.g. only in their access to legal employment opportunities, and this is what will underlie any difference in criminal base rates.  </div><div><br/></div><div>As a function of whether each person commits a crime or not, a "noisy signal" is generated. In general, think of higher signals as corresponding to increased evidence of guilt, and so if someone commits a crime, they will tend to draw higher signals than those who don't commit crimes --- but the signals are noisy, so there is no way to perfectly identify the guilty. </div><div><br/></div><div>Incarceration decisions are made as a function of these noisy signals: society has a choice as to what incarceration rule to choose, and can potentially choose a different rule for different groups. Once an incarceration rule is chosen, this determines each person's incentive to commit crime, which in turn fixes a base rate of crime in each population. In general, base rates will be different across different groups (because outside option distributions differ), so the impossibility of e.g. equalizing false positive rates, false negative rates, and positive predictive value across groups will hold in our setting. Since crime rates in our setting are a function of the incarceration rule we choose, there is a natural objective to consider: finding the policy that <i>minimizes crime</i>. </div><div><br/></div><div>Lets think about how we might implement different fairness notions in this setting. First, how should we think about posterior probabilities that an individual will commit a crime? Before we see an individual's noisy signal, but after we see his group membership, we can form our <i>prior </i>belief that he has committed a crime --- this is just the base crime rate in his population. After we observe his noisy signal, we can use Bayes rule to calculate a posterior probability that he has committed a crime. So we could apply the "uniform posterior threshold" approach to fairness and use an incarceration rule that would incarcerate an individual exactly when their posterior probability of having committed a crime exceeded some uniform threshold. But note that because crime rates (and hence prior probabilities of crime) will generically differ between populations (because outside option distributions differ), setting the -same- threshold on posterior probability of crime for both groups corresponds to setting <i>different</i> thresholds on the raw noisy signals. This makes sense --- a Bayesian doesn't need as strong evidence to convince her that someone from a high crime group has committed a crime, as she would need to be convinced that someone from a low crime group has committed a crime, because she started off with a higher prior belief about the person from the high crime group. This (as we already know) results in a classification rule that has different false positive rates and false negative rates across groups. </div><div><br/></div><div>On the other hand, if we want to equalize false positive and false negative rates across groups, we need an incarceration rule that sets the same threshold on raw noisy signals, independently of group. This will of course correspond to setting different thresholds on the posterior probability of crime (i.e. thresholding calibrated risk scores differently for different groups). And this will always be sub-optimal from the point of view of predicting crime --- the Bayes optimal predictor uniformly thresholds posterior probabilities. </div><div><br/></div><h2>Which Notions of Fairness Lead to Desirable Outcomes?</h2><div><br/></div><div>But only one of these solutions is consistent with our social goal of minimizing crime. And its not the Bayes optimal predictor. The crime-minimizing solution is the one that sets <i>different</i> thresholds on posterior probabilities (i.e. uniform thresholds on signals) so as to equalize false positive rates and false negative rates. In other words, to minimize crime, society should explicitly commit to <i>not</i> conditioning on group membership, even when group membership is statistically informative for the goal of predicting crime. </div><div><br/></div><div>Why? Its because although using demographic information is statistically informative for the goal of predicting crime when base rates differ, it is not something that is under the control of individuals --- they can control their own choices, but not what group they were born into. And making decisions about individuals using information that is not under their control has the effect of distorting their dis-incentive to commit crime --- it ends up providing less of a dis-incentive to individuals from the higher crime group (since they are more likely to be wrongly incarcerated even if they don't commit a crime). And because in our model people are rational actors, minimizing crime is all about managing incentives. </div><div><br/></div><div>This is our baseline model, and in <a href="https://www.cis.upenn.edu/~aaroth/Papers/endogenous.pdf">the paper</a> we introduce a number of extensions, generalizations, and elaborations on the model in order to stress-test it. The conclusions continue to hold in more elaborate and general settings, but at a high level, the key assumptions that are needed to reach them are that:</div><div><div><ol><li>The underlying base rates are rationally responsive to the decision rule used by society.</li><li>Signals are observed at the same rates across populations, and</li><li>The signals are conditionally independent of an individual’s group, conditioned on the individual’s decision about whether or not to commit crime.</li></ol></div><div>Here, conditions (2) and (3) are unlikely to hold precisely in most situations,  but we show that they can be relaxed in various ways while still preserving the core conclusion.</div><div><br/></div><div>But more generally, if we are in a setting in which we believe that individual decisions are rationally made in response to the deployed classifier, and yet the deployed classifier does not equalize false  positive and negative rates, then this is an indication that <i>either </i>the deployed classifier is sub-optimal (for the purpose of minimizing crime rates), or that one of conditions (2) and (3) fails to hold.  Since in fairness relevant settings, the failure of conditions (2) and (3) is itself undesirable, this can be a diagnostic to highlight discriminatory conditions earlier in the pipeline than the final incarceration rule.  In particular, if conditions (2) or (3) fail to hold, then imposing technical fairness constraints on a deployed classifier may be premature, and instead attention should be focused on structural differences in the observations that are being fed into the deployed classifier.</div></div></div>
    </content>
    <updated>2020-02-17T16:08:00Z</updated>
    <published>2020-02-17T16:08:00Z</published>
    <author>
      <name>Aaron</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/09952936358739421126</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-25562705</id>
      <category term="game theory"/>
      <category term="news"/>
      <author>
        <name>Aaron</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/09952936358739421126</uri>
      </author>
      <link href="http://aaronsadventures.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://aaronsadventures.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <title>Adventures in Computation</title>
      <updated>2020-02-17T16:54:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19341</id>
    <link href="https://gilkalai.wordpress.com/2020/02/17/hoi-neguyen-and-melanie-wood-remarkable-formulas-for-the-probability-that-projections-of-lattices-are-surjective/" rel="alternate" type="text/html"/>
    <title>Hoi Neguyen and Melanie Wood: Remarkable Formulas for the Probability that Projections of Lattices are Surjective</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Following a lecture by Hoi Neguyen at Oberwolfach, I would like to tell you a little about the paper: Random integral matrices: universality of surjectivity and the cokernel by Hoi Neguyen and Melanie Wood. Two background questions: Hoi started with … <a href="https://gilkalai.wordpress.com/2020/02/17/hoi-neguyen-and-melanie-wood-remarkable-formulas-for-the-probability-that-projections-of-lattices-are-surjective/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Following a lecture by <a href="https://math.osu.edu/people/nguyen.1261">Hoi Neguyen</a> at Oberwolfach, I would like to tell you a little about the paper: <a href="https://arxiv.org/abs/1806.00596">Random integral matrices: universality of surjectivity and the cokernel</a> by Hoi Neguyen and <a href="https://math.berkeley.edu/~mmwood/">Melanie Wood</a>.</p>
<h2>Two background questions:</h2>
<p>Hoi started with two background questions –</p>
<p>Background Question 1: Consider an <img alt="n \times n" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \times n"/> 0-1 matrix where the entries are taken at random. What is the probability that the matrix is singular (over the rationals)?</p>
<p>Hoi mentioned the <a href="https://gilkalai.wordpress.com/2019/02/02/konstantin-tikhomrov-the-probability-that-a-bernoulli-matrix-is-singular/">recent result of Konstantin Tikhomirov,</a> and moved to talk about matrices over the integers.</p>
<p>Background Question 2: Now, think about the lattice spanned by the rows of the matrix. How likely it is that this is the full <img alt="\mathbb Z^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb Z^n"/>? (In other words that the determinant is +1 or -1.)</p>
<p>Probably, I thought, the answer is less than exponentially small.</p>
<h2>The main question</h2>
<p>Hoi moved quickly to the main question</p>
<p><strong>Main question:</strong> Now think about the rows of a random 0-1 <img alt="(n+1) \times n" class="latex" src="https://s0.wp.com/latex.php?latex=%28n%2B1%29+%5Ctimes+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(n+1) \times n"/> matrix. How likely it is that this is the full <img alt="\mathbb Z^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb Z^n"/>?</p>
<p>Hmm, I was not sure how quickly the answer should tend to zero. But I learnt quickly that the answer does not tend to zero at all!</p>
<h3><span style="color: #ff0000;">A remarkable heuristic formula: the probability for a random integral matrix from (n+1)-dimensions to n-dimenssions to be surjective is </span></h3>
<h3 style="text-align: center;"><span style="color: #ff0000;"><strong><span style="color: #ff0000;">one over <em> (ζ(2)ζ(3)ζ(4)ζ(5)…) </em></span></strong></span></h3>
<p>What would justify this formula? Hoi described the following heuristic argument.</p>
<ol>
<li>To be surjective you need to be surjective modulo p for every prime number p.</li>
<li> Take some p. The probability to be surjective modulo p when the entries are uniformly random (independently) numbers modulo p is <img alt="\prod_{j=2}^{n+1}(1-p^{-j})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cprod_%7Bj%3D2%7D%5E%7Bn%2B1%7D%281-p%5E%7B-j%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\prod_{j=2}^{n+1}(1-p^{-j})"/>.</li>
<li>This probability continues to work if you consider 0-1 entries.</li>
<li>You can assume that all these probabilities for different primes are statistically independent.</li>
<li>When you multiply all these probabilities you get</li>
</ol>
<p style="text-align: center;"><img alt="\zeta(2)^{-1}\zeta(3)^{-1}\zeta(5)^{-1}\zeta(7)^{-1}\cdots" class="latex" src="https://s0.wp.com/latex.php?latex=%5Czeta%282%29%5E%7B-1%7D%5Czeta%283%29%5E%7B-1%7D%5Czeta%285%29%5E%7B-1%7D%5Czeta%287%29%5E%7B-1%7D%5Ccdots&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\zeta(2)^{-1}\zeta(3)^{-1}\zeta(5)^{-1}\zeta(7)^{-1}\cdots"/></p>
<p>When Hoi reached this formula in his Oberfolfach lecture my immediate thought was this: This is a remarkable formula; maybe it is even true although it looks very hard to justify the two crucial steps  in the heuristics. Why you can assume that 0-1 matrices behave like random matrices with uniform entries and why we have statistical independence that allows us to multiply probabilities just like in high school probability class? And maybe it is not true.</p>
<p>(This heuristics is known as the Cohen Lenstra heuristics and it was made for understanding the structure of class groups of quadratic fields.)</p>
<p>And then came the next slide of the presentation.</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/02/w2j-1.png"><img alt="" class="alignnone size-full wp-image-19345" height="335" src="https://gilkalai.files.wordpress.com/2020/02/w2j-1.png?w=640&amp;h=335" width="640"/></a></p>
<p> </p>
<h3>Hoi Neguyen and Melanie Wood actually proved this formula!</h3>
<p>This is  a special case of a considerably more general formula. Look at<a href="https://arxiv.org/abs/1806.00596"> the paper for more details</a> and for the proofs.</p>
<p>It looks to me that the proof is tour de force and it uses various difficult and delicious techniques and earlier results. Various new and old Littlewood-Oﬀord type results which are independently interesting are used.</p>
<p>And here is a related paper by Hoi and Melanie:<a href="https://arxiv.org/abs/1806.10068"> Cokernels of adjacency matrices of random r-regular graphs</a>.</p>
<p> </p>
<h3>Little more</h3>
<p>As for background problem 2, the paper mentioned that the fact that the probability tends to 0 follows from Corollary 3.4 from a paper by Melanie Wood: <a href="https://arxiv.org/abs/1504.04391">Random integral matrices and the Cohen Lenstra Heuristics.</a>  (Maybe there are different avenues for showing that there is a vanishing probability for every specific value of the determinant as well.) I don’t know if it is known that the probability that the determinant is 1 is exponentially small. (You can guess it is like square root of n! or something like that.) Also I don’t know if the ratio between the probabilities that the determinant is 3 and that it is 7 respects the Cohen Lenstra heuristics. Do we expect it at all? You can regard the determinant as a strange random walk what is the reason that stopping at 3 will be different than stopping at 7?  It is also not known and this is raised as a question in the paper if the probability that the determinant is a perfect square respects the Cohen-Lenstra heuristics (and this seems reasonable).</p>
<p>There are similar nice questions for simplicial complexes. See the paper <a href="https://arxiv.org/abs/1710.05683">Cohen–Lenstra heuristics for torsion in homology of random complexes</a>, by Matthew Kahle, Frank Lutz, Andrew Newman, and Kyle Parsons.</p>
<p>So if you consider the torsion of the 7 dimensional homology of a random 14 dimensional manifolds. Then (unless there are theorems to the contrary) it is natural to guess that the torsion will obey a Cohen-Lenstra heuristic of some kind.  This also applies to rationally acyclic complexes (hypertrees) and various other gadgets.</p>
<p> </p></div>
    </content>
    <updated>2020-02-17T15:29:58Z</updated>
    <published>2020-02-17T15:29:58Z</published>
    <category term="Algebra"/>
    <category term="Combinatorics"/>
    <category term="Number theory"/>
    <category term="Probability"/>
    <category term="Hoi Neguyen"/>
    <category term="Melanie Wood"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-02-18T07:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06083</id>
    <link href="http://arxiv.org/abs/2002.06083" rel="alternate" type="text/html"/>
    <title>Deciding the existence of quasi weak near unanimity terms in finite algebras</title>
    <feedworld_mtime>1581897600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kazda:Alexandr.html">Alexandr Kazda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06083">PDF</a><br/><b>Abstract: </b>We show that for a fixed positive integer k one can efficiently decide if a
finite algebra A admits a k-ary weak near unanimity operation by looking at the
local behavior of the terms of A. We also observe that the problem of deciding
if a given finite algebra has a quasi Taylor operation is solvable in
polynomial time by looking, essentially, for local quasi Siggers operations.
</p></div>
    </summary>
    <updated>2020-02-17T23:22:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06078</id>
    <link href="http://arxiv.org/abs/2002.06078" rel="alternate" type="text/html"/>
    <title>On the complexity of finding large odd induced subgraphs and odd colorings</title>
    <feedworld_mtime>1581897600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Belmonte:R=eacute=my.html">Rémy Belmonte</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sau:Ignasi.html">Ignasi Sau</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06078">PDF</a><br/><b>Abstract: </b>We study the complexity of the problems of finding, given a graph $G$, a
largest induced subgraph of $G$ with all degrees odd (called an odd subgraph),
and the smallest number of odd subgraphs that partition $V(G)$. We call these
parameters ${\sf mos}(G)$ and $\chi_{{\sf odd}}(G)$, respectively. We prove
that deciding whether $\chi_{{\sf odd}}(G) \leq q$ is polynomial-time solvable
if $q \leq 2$, and NP-complete otherwise. We provide algorithms in time
$2^{O({\sf rw})} \cdot n^{O(1)}$ and $2^{O(q \cdot {\sf rw})} \cdot n^{O(1)}$
to compute ${\sf mos}(G)$ and to decide whether $\chi_{{\sf odd}}(G) \leq q$ on
$n$-vertex graphs of rank-width at most ${\sf rw}$, respectively, and we prove
that the dependency on rank-width is asymptotically optimal under the ETH.
Finally, we give some tight bounds for these parameters on restricted graph
classes or in relation to other parameters.
</p></div>
    </summary>
    <updated>2020-02-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06037</id>
    <link href="http://arxiv.org/abs/2002.06037" rel="alternate" type="text/html"/>
    <title>A Simple 1-1/e Approximation for Oblivious Bipartite Matching</title>
    <feedworld_mtime>1581897600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Zhihao_Gavin.html">Zhihao Gavin Tang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Xiaowei.html">Xiaowei Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Yuhao.html">Yuhao Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06037">PDF</a><br/><b>Abstract: </b>We study the oblivious matching problem, which aims at finding a maximum
matching on a graph with unknown edge set. Any algorithm for the problem
specifies an ordering of the vertex pairs. The matching is then produced by
probing the pairs following the ordering, and including a pair if both of them
are unmatched and there exists an edge between them. The unweighted (Chan et
al. (SICOMP 2018)) and the vertex-weighted (Chan et al. (TALG 2018)) versions
of the problem are well studied.
</p>
<p>In this paper, we consider the edge-weighted oblivious matching problem on
bipartite graphs, which generalizes the stochastic bipartite matching problem.
Very recently, Gamlath et al. (SODA 2019) studied the stochastic bipartite
matching problem, and proposed an (1-1/e)-approximate algorithm. We give a very
simple algorithm adapted from the Ranking algorithm by Karp et al. (STOC 1990),
and show that it achieves the same (1-1/e) approximation ratio for the
oblivious matching problem on bipartite graph.
</p></div>
    </summary>
    <updated>2020-02-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.06005</id>
    <link href="http://arxiv.org/abs/2002.06005" rel="alternate" type="text/html"/>
    <title>A Breezing Proof of the KMW Bound</title>
    <feedworld_mtime>1581897600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Corinna Coupette, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lenzen:Christoph.html">Christoph Lenzen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.06005">PDF</a><br/><b>Abstract: </b>In their seminal paper from 2004, Kuhn, Moscibroda, and Wattenhofer (KMW)
proved a hardness result for several fundamental graph problems in the LOCAL
model: For any (randomized) algorithm, there are input graphs with $n$ nodes
and maximum degree $\Delta$ on which $\Omega(\min\{\sqrt{\log n/\log \log
n},\log \Delta/\log \log \Delta\})$ (expected) communication rounds are
required to obtain polylogarithmic approximations to a minimum vertex cover,
minimum dominating set, or maximum matching, respectively. Via reduction, this
hardness extends to symmetry breaking tasks like finding maximal independent
sets or maximal matchings. Today, more than $15$ years later, there is still no
proof of this result that is easy on the reader. Setting out to change this, in
this work, we provide a fully self-contained and \emph{simple} proof of the KMW
lower bound. The key argument is algorithmic, and it relies on an invariant
that can be readily verified from the generation rules of the lower bound
graphs.
</p></div>
    </summary>
    <updated>2020-02-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.05910</id>
    <link href="http://arxiv.org/abs/2002.05910" rel="alternate" type="text/html"/>
    <title>Kinetic Geodesic Voronoi Diagrams in a Simple Polygon</title>
    <feedworld_mtime>1581897600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Korman:Matias.html">Matias Korman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Renssen:Andr=eacute=_van.html">André van Renssen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roeloffzen:Marcel.html">Marcel Roeloffzen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Staals:Frank.html">Frank Staals</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.05910">PDF</a><br/><b>Abstract: </b>We study the geodesic Voronoi diagram of a set $S$ of $n$ linearly moving
sites inside a static simple polygon $P$ with $m$ vertices. We identify all
events where the structure of the Voronoi diagram changes, bound the number of
such events, and then develop a kinetic data structure (KDS) that maintains the
geodesic Voronoi diagram as the sites move. To this end, we first analyze how
often a single bisector, defined by two sites, or a single Voronoi center,
defined by three sites, can change. For both these structures we prove that the
number of such changes is at most $O(m^3)$, and that this is tight in the worst
case. Moreover, we develop compact, responsive, local, and efficient kinetic
data structures for both structures. Our data structures use linear space and
process a worst-case optimal number of events. Our bisector KDS handles each
event in $O(\log m)$ time, and our Voronoi center handles each event in
$O(\log^2 m)$ time. Both structures can be extended to efficiently support
updating the movement of the sites as well. Using these data structures as
building blocks we obtain a compact KDS for maintaining the full geodesic
Voronoi diagram.
</p></div>
    </summary>
    <updated>2020-02-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.05854</id>
    <link href="http://arxiv.org/abs/2002.05854" rel="alternate" type="text/html"/>
    <title>On the Edge Crossings of the Greedy Spanner</title>
    <feedworld_mtime>1581897600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eppstein:David.html">David Eppstein</a>, Hadi Khodabandeh <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.05854">PDF</a><br/><b>Abstract: </b>$t$-spanners are used to approximate the pairwise distances between a set of
points in a metric space. They have only a few edges compared to the total
number of pairs and they provide a $t$-approximation on the distance of any two
arbitrary points. There are many ways to construct such graphs and one of the
most efficient ones, in terms of weight and the number of edges of the
resulting graph, is the greedy spanner. In this paper, we study the edge
crossings of the greedy spanner for points in the Euclidean plane. We prove a
constant upper bound for the number of intersections with larger edges that
only depends on the stretch factor of the spanner, $t$, and we show there can
be more than a bounded number of intersections with smaller edges. Our results
imply that greedy spanners for points in the plane have separators of size
$\mathcal{O}(\sqrt n)$, that their planarizations have linear size, and that a
separator hierarchy for these graphs can be constructed from their
planarizations in linear time.
</p></div>
    </summary>
    <updated>2020-02-17T23:48:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.05808</id>
    <link href="http://arxiv.org/abs/2002.05808" rel="alternate" type="text/html"/>
    <title>Online Algorithms for Multi-shop Ski Rental with Machine Learned Predictions</title>
    <feedworld_mtime>1581897600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Shufan.html">Shufan Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jian.html">Jian Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Shiqiang.html">Shiqiang Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.05808">PDF</a><br/><b>Abstract: </b>We study the problem of augmenting online algorithms with machine learned
(ML) predictions. In particular, we consider the \emph{multi-shop ski rental}
(MSSR) problem, which is a generalization of the classical ski rental problem.
In MSSR, each shop has different prices for buying and renting a pair of skis,
and a skier has to make decisions on when and where to buy. We obtain both
deterministic and randomized online algorithms with provably improved
performance when either a single or multiple ML predictions are used to make
decisions. These online algorithms have no knowledge about the quality or the
prediction error type of the ML predictions. The performance of these online
algorithms are robust to the poor performance of the predictors, but improve
with better predictions. We numerically evaluate the performance of our
proposed online algorithms in practice.
</p></div>
    </summary>
    <updated>2020-02-17T23:22:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-02-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16691</id>
    <link href="https://rjlipton.wordpress.com/2020/02/16/a-beetle-math-puzzle/" rel="alternate" type="text/html"/>
    <title>A Beetle Math Puzzle</title>
    <summary>Lessons from a puzzle about prime numbers [ Wikipedia ] Doron Zeilberger is a famous combinatorial mathematician based at Rutgers. He is noted for actively using computers in research. His computers even get co-authorship credit under the name “Shalosh B. Ekhad,” which is Hebrew for 3B1—a computer that came from building 3, corridor B, room […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Lessons from a puzzle about prime numbers</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/02/16/a-beetle-math-puzzle/unknown-134/" rel="attachment wp-att-16694"><img alt="" class="alignright size-full wp-image-16694" src="https://rjlipton.files.wordpress.com/2020/02/unknown-1.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Wikipedia ]</font></td>
</tr>
</tbody>
</table>
<p>
Doron Zeilberger is a famous combinatorial mathematician based at Rutgers. He is noted for actively using computers in research. His computers even get co-authorship credit under the name “Shalosh B. Ekhad,” which is Hebrew for 3B1—a computer that came from building 3, corridor B, room 1 of AT&amp;T Bell Labs.</p>
<p>
Today I thought we would talk about a recent joint <a href="https://arxiv.org/abs/1801.05097">paper</a> of Zeilberger on Covering Systems.</p>
<p>
This paper has one co-author who is human, Anthony Zaleski, also of Rutgers. It starts with a puzzle about beetles on a circular track. The puzzle does not need a computer to solve—though a computerized visualization would make it more enjoyable. It makes several interesting points, points that are distinctly human, and I hope you might enjoy it. </p>
<p>
</p><p/><h2> The Puzzle </h2><p/>
<p/><p>
They ascribe the <a href="https://www.pourlascience.fr/sd/mathematiques/cinq-enigmes-mathematiques-pour-la-rentree-9796.php">puzzle</a> to Jean-Paul Delahaye, who modified Peter Winkler’s writeup of a folk puzzle that Winkler stated about ants. </p>
<blockquote><p><b> </b> <em> One places nine beetles on a circular track, where the nine arc distances, measured in meters, between two consecutive beetles are the first nine prime numbers, <img alt="{2,3,5,7,11,13,17,19,23}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%2C3%2C5%2C7%2C11%2C13%2C17%2C19%2C23%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{2,3,5,7,11,13,17,19,23}"/>. The order is arbitrary, and each number appears exactly once as a distance.</em></p><em>
</em><p><em>
At the starting time, each beetle decides randomly whether she would go, traveling at a speed of 1 meter per minute, clockwise or counter-clockwise. When two beetles bump into each other, they immediately do a “U-turn”, i.e. reverse direction. We assume that the size of the beetles is negligible. At the end of <img alt="{50}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B50%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{50}"/> minutes, after many collisions, one notices the distances between the new positions of the beetles. </em>
</p></blockquote>
<p/><p>
Note that there are two levels of probability: the initial order of the vector of distances and the initial direction of each beetle. Yet after <img alt="{50}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B50%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{50}"/> minutes there is a high probability of the distances being exactly the same: the first nine prime numbers. Is this a miracle? What is the probability?</p>
<p>
</p><p/><h2> The Lessons </h2><p/>
<p/><p>
The point is we have deliberately stated the puzzle to make it harder. The way we stated it is misleading and the following lessons are hints to help solve the puzzle.</p>
<ul>
<li>
That the arc lengths are prime numbers is unimportant. The puzzle works whether or not the distances between the beetles are prime numbers. <p/>
</li><li>
The probability is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> that the beetles are at the given positions. There is no chance that they will not arrive at the antipode points. None.
</li></ul>
<p>
</p><p/><h2> The Solution </h2><p/>
<p/><p>
The first observation is that the circular track’s length is 	</p>
<p align="center"><img alt="\displaystyle  2+3+5+7+11+13+17+19+23=100. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++2%2B3%2B5%2B7%2B11%2B13%2B17%2B19%2B23%3D100.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  2+3+5+7+11+13+17+19+23=100. "/></p>
<p><a href="https://rjlipton.wordpress.com/2020/02/16/a-beetle-math-puzzle/antipode/" rel="attachment wp-att-16698"><img alt="" class="aligncenter size-full wp-image-16698" src="https://rjlipton.files.wordpress.com/2020/02/antipode.png?w=600"/></a></p>
<p>The second is that the probability is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> that the distances are the same after <img alt="{50}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B50%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{50}"/> minutes. Imagine that each beetle carries a flag. Instead of reversing direction when they collide, let the beetles exchange their flags and continue moving as before. Now the flags always are moving in the same direction at the same speed. This means that after <img alt="{50}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B50%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{50}"/> minutes the flags are at the antipode position. But the beetles are located at the same places as flags, and so the distances are the same as before. Note, the beetles are each located at the position of some unique flag, but which flag can change many times.</p>
<p>
The only constraint is that the distance traveled in <img alt="{50}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B50%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{50}"/> minutes divides the length of the circular track. The fact that the distances are primes is never used.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Zaleski and Zeilberger say:</p>
<blockquote><p><b> </b> <em> We point out that very often primes are red herrings. This is definitely the case for covering system, and who knows, perhaps also for the Riemann Hypothesis. </em>
</p></blockquote>
<p/><p>
I assume this is a bit tongue in cheek, but their point is valid. Do we miss solutions to problems when we use information that is not really important? How do we decide which information is key and which is redundant? This why I like this puzzle. </p>
<p/></font></font></div>
    </content>
    <updated>2020-02-16T18:35:51Z</updated>
    <published>2020-02-16T18:35:51Z</published>
    <category term="Ideas"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="beetle"/>
    <category term="primes"/>
    <category term="puzzle"/>
    <category term="solution"/>
    <category term="trick"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-02-18T07:20:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1276607874189152226</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1276607874189152226/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/02/pre-publish-and-perish.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1276607874189152226" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1276607874189152226" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/02/pre-publish-and-perish.html" rel="alternate" type="text/html"/>
    <title>Pre-(Publish and Perish)</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><i>Guest post by Evangelos Georgiadis</i><br/>
<div>
<br/></div>
Quite a few posts have recently focused on papers,publications and venues;
"optimal" venues for papers under different objective functions,e.g.
minimizing carbon footprint while maximizing community building, networking
as well as information sharing, see <a href="https://cacm.acm.org/magazines/2020/1/241717-publish-and-perish/fulltext">Moshe Vardi</a>.<br/>
<br/>
Here we would like to take a closer look at one of the key assumptions 
-- the paper.
In order to generate a paper, one needs to come up with a result, something
novel, fresh or interesting to say.
The question that has baffled this author is what represents a conducive
or perhaps even optimal setting for generating papers.
Since papers come in different flavors ranging from "<a href="https://blog.computationalcomplexity.org/2009/11/innovation.html">solid technical papers to risky innovative ones</a>" the 
settings
may vary; but ultimately, what would be interesting to investigate (or
for that matter crowdsource) is whether there is a common denominator
in terms of setting or environment, a necessary but not sufficient 
condition (so to speak).
<br/>
<br/>
Here are some accounts of others which may be helpful as reference points.
<br/>
<br/>
Knuth's papers entitled "<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.455.1434&amp;rep=rep1&amp;type=pdf">Semantics of context free grammar</a>" along with
"The analysis of algorithms" represent two instances that suggest research
institutes might not provide an optimal environment for idea generation.
<br/>
<br/>
As Knuth points out in "<a href="https://www-cs-faculty.stanford.edu/~knuth/cl.html">Selected Papers on Computer Languages</a>" (Chapter 18, p. 431):<br/>
<blockquote class="tr_bq">
Perhaps new ideas emerge most often from hectic, disorganized 
activity,
      when a great many sources of stimulation are present at once -- 
when numerous
     deadlines need to be met, and when other miscellaneous activities 
like child-rearing
     are also mixed into the agenda.</blockquote>
Knuth goes on to say, that it was challenging to do creative work in 
office and that finding
a few hideaways provided some form of solution -- aka sitting under 
'that' oak tree
near Lake Lagunita.
That said, the inspirational setting for getting into the zone for the 
aforementioned two papers
were provided by (Californian) beaches. Hold that observation. Is this 
not something we
have come across somewhere else ?
Fields medalist Stephen Smale in  "<a href="http://math.berkeley.edu/~smale/biblio/chaos.ps">Chaos: Finding a Horseshoe on the Beaches of Rio</a>" suggests that some of his best work happened at his "beach office". 
Whether beaches do provide
for a good setting remains to be shown; perhaps for very innovative 
ideas, oceanic freedom is necessary.
That said, the author recalls (hopefully accurately enough) an account 
by the young  James H Simons,
who attended a conference in Japan in the early days.
Instead of choosing a spacious accommodation (which he was able to 
afford), he restricted himself to the typically confined room type --
not only confined by space, but also pressured by time, young Simons was 
able to generate an interesting result for that conference.
(This probably demonstrates that technical results don't necessarily 
require 'oceanic freedom'.)<br/>
<br/>
Some meaningful probabilistic advice comes from  the fat-tails department,
in "The Black Swan" by Nassim Taleb (on page 209) :
"Go to parties! If you're a scientist, you will chance upon a remark 
that might spark a new research. "
<br/>
<br/>
Murray Gell-Mann provides an interesting collective account in his 
Google Tech Talk entitled "On Getting Creative Ideas."
He <a href="https://youtu.be/3fSB6ut-cT0?t=118">recollects</a> a workshop he attended in 1969 in Aspen that focused on 
the experience
of getting creative ideas, not just among mathematicians and theoretical 
physicists but also poets and
artists. This account seems to 
neglect the actual setting that might
nurture creative thought process, but provides interesting references to 
people such as
  Hermann von Helmholtz, who happened to have thought about this topic 
and partitioned the process
in terms of "saturation, incubation and illumination".
<br/>
<br/>
For those interested in an account that focuses on the Eureka moments of 
exclusively
mathematicians/theoretical physicists see Jacques Hadamard's book "<a href="https://www.amazon.com/Mathematicians-Mind-Jacques-Hadamard/dp/0691029318">The Mathematician's Mind</a>". 
Hadamard
iterated on Helmholtz's 3 stage process and it's worth taking a look at 
what he came up.
<br/>
<br/>
At last, what are good venues or workshops for generating papers ? Or 
let's rephrase that a bit,
what type of atmosphere at venues fosters creativity -- what food for 
thought to provide
participants and how to distribute that food for thought over a given day ?
Ryan R Williams proposed (as practiced by 34th Bellairs Winter Workshop 
on Computational Geometry)
  "... easy problems, informal atmosphere focusing exclusively
       on thinking about problems in a cycle of down-time where
       one meets in two intense sessions and have free time otherwise."
(This type of setting seems to resonate with the 3 stages of 
"saturation, incubation and illumination".)
<br/>
<br/>
That said, most workshops including the Simons workshops don't seem to 
follow such a recipe.
They are more geared towards the follow-up step, namely, communicating 
what people have found,
rather than collaborating with them to tackle open problems.
Perhaps some re-evaluation might be required in how workshops are run.</div>
    </content>
    <updated>2020-02-16T16:02:00Z</updated>
    <published>2020-02-16T16:02:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-02-17T11:45:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/012</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/012" rel="alternate" type="text/html"/>
    <title>TR20-012 |  (Semi)Algebraic Proofs over $\{\pm 1\}$ Variables | 

	Dmitry Sokolov</title>
    <summary>One of the major open problems in proof complexity is to prove lower bounds on $AC_0[p]$-Frege proof
systems. As a step toward this goal Impagliazzo, Mouli and Pitassi in a recent paper suggested to prove
lower bounds on the size for Polynomial Calculus over the $\{\pm 1\}$ basis. In this paper we show a
technique for proving such lower bounds and moreover we also give lower bounds on the size for
Sum-of-Squares over the $\{\pm 1\}$ basis.

We show lower bounds on random $\Delta$-CNF formulas and formulas composed with a gadget. As a byproduct,
we establish a separation between Polynomial Calculus and Sum-of-Squares over the $\{\pm 1\}$ basis by
proving a lower bound on the Pigeonhole Principle.</summary>
    <updated>2020-02-16T06:22:49Z</updated>
    <published>2020-02-16T06:22:49Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-18T07:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/011</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/011" rel="alternate" type="text/html"/>
    <title>TR20-011 |  Super Strong ETH is true for strong PPSZ | 

	Navid Talebanfard, 

	Dominik Scheder</title>
    <summary>We construct $k$-CNFs with $m$ variables on which the strong version of PPSZ $k$-SAT algorithm, which uses bounded width resolution, has success probability at most $2^{-(1 - (1 + \epsilon)2/k)m}$ for every $\epsilon &gt; 0$. Previously such a bound was known only for the weak PPSZ algorithm which exhaustively searches through small subformulas of the CNF to see if any of them forces the value of a given variable, and for strong PPSZ the best known previous upper bound was $2^{-(1 - O(\log(k)/k))m}$ (Pudlák et al., ICALP 2017).</summary>
    <updated>2020-02-16T06:21:24Z</updated>
    <published>2020-02-16T06:21:24Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-02-18T07:20:38Z</updated>
    </source>
  </entry>
</feed>
