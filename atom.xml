<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-11-06T01:21:41Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/05/postdoc-in-complexity-theory-at-university-of-warwick-apply-by-december-2-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/05/postdoc-in-complexity-theory-at-university-of-warwick-apply-by-december-2-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc in Complexity Theory at University of Warwick (apply by December 2, 2019)</title>
    <summary>A Postdoctoral Research Fellow position at the University of Warwick in computational complexity and related areas is available for up to 16 months ending in March/2021. The start date can be negotiated for the successful candidate. Note that obtaining a phd before joining Warwick is not strictly necessary. The position is available in connection with […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A Postdoctoral Research Fellow position at the University of Warwick in computational complexity and related areas is available for up to 16 months ending in March/2021. The start date can be negotiated for the successful candidate. Note that obtaining a phd before joining Warwick is not strictly necessary.</p>
<p>The position is available in connection with a research grant of Igor Carboni Oliveira.</p>
<p>Website: <a href="https://www.dcs.warwick.ac.uk/~igorcarb/">https://www.dcs.warwick.ac.uk/~igorcarb/</a><br/>
Email: igorcarb@gmail.com</p></div>
    </content>
    <updated>2019-11-05T10:10:22Z</updated>
    <published>2019-11-05T10:10:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-06T01:20:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/151</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/151" rel="alternate" type="text/html"/>
    <title>TR19-151 |  Optimal Inapproximability with Universal Factor Graphs | 

	Johan Hastad, 

	Per Austrin, 

	Jonah Brown-Cohan</title>
    <summary>The factor graph of an instance of a constraint satisfaction problem (CSP) is the bipartite graph indicating which variables appear in each constraint.  An instance of the CSP is given by the factor graph together with a list of which predicate is applied for each constraint. We establish that many Max-CSPs remains as hard to approximate as in the general case even when the factor graph is fixed (depending only on the size of the instance) and known in advance.

Examples of results obtained for this restricted setting are:

Optimal inapproximability for Max-3-Lin.

Approximation resistance for predicates supporting pairwise independent subgroups.

Hardness of the ``$(2+\epsilon)$-Sat'' problem and other Promise CSPs.

The main technical tool used to establish these results is a new way of folding the long code which we call ``functional folding''.</summary>
    <updated>2019-11-05T09:01:26Z</updated>
    <published>2019-11-05T09:01:26Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-11-06T01:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/150</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/150" rel="alternate" type="text/html"/>
    <title>TR19-150 |  A Logical Characteristic of Read-Once Branching Programs | 

	Stanislav Žák</title>
    <summary>We present a mathematical model of the intuitive notions such as the
knowledge or the information arising at different stages of
computations on branching programs (b.p.). The model has two
appropriate
properties:\\
i) The "knowledge" arising at a stage of computation in question is
derivable from the "knowledge" arising at the previous stage
according to the rules of the model and according to the local
arrangement of the b.p.\\
ii) The model confirms the intuitively well-known fact that the
knowledge arising at a node of a computation depends not only on
it but in some cases also on a "mystery" information. (I. e.
different computations reaching the same node may have different
knowledge(s) arisen at it.)\\
We prove that with respect to our model no such information exists
in read-once b.p.`s but on the other hand in b. p.`s which are not
read-once such information must be present. The read-once property
forms a frontier.\\
More concretely, we may see the instances of our models as a systems
$S=(U,D)$ where $U$ is a universe of knowledge and $D$ are
derivation rules. We say that a b.p. $P$ is compatible with a system
$S$ iff along each computation in $P$ $S$ derives $F$ ($false$) or
$T$ ($true$) at the end correctly according to the label of the
reached sink. This key notion modifies the classic paradigm
according to which the computational complexity is defined with
respect to different classes of restricted b.p.`s (e.g. read-once
b.p.`s, k-b.p.`s, b.p.`s computing in limited time etc.). Now, the
restriction is defined by a subset of systems and only these
programs are taken into account which are compatible with
at least one of the chosen systems.\\
Further  we may understand the sets $U$ of knowledge(s) as a sets of
admissible logical formulae.  More rich  sets $U$`s imply the larger
(= more free) restrictions on b.p.`s and consequently the smaller
complexities of Boolean functions are detected. More rich logical
equipment implies stronger computational effectiveness.\\</summary>
    <updated>2019-11-05T08:46:13Z</updated>
    <published>2019-11-05T08:46:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-11-06T01:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/11/05/prague-summer-school-on-discrete-mathematics-2020/</id>
    <link href="https://cstheory-events.org/2019/11/05/prague-summer-school-on-discrete-mathematics-2020/" rel="alternate" type="text/html"/>
    <title>Prague Summer School on Discrete Mathematics 2020</title>
    <summary>August 24, 2012 – August 28, 2020 Prague, Czechia http://pssdm.math.cas.cz/ Registration deadline: March 15, 2020 A one-week summer school primarily for PhD students and postdocs. Lecture courses given by Subhash Khot (New York University) and Shayan Oveis Gharan (University of Washington).</summary>
    <updated>2019-11-05T07:50:37Z</updated>
    <published>2019-11-05T07:50:37Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-11-06T01:21:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blogs.princeton.edu/imabandit/?p=1406</id>
    <link href="https://blogs.princeton.edu/imabandit/2019/11/05/convex-body-chasing-steiner-point-sellke-point-and-soda-2020-best-papers/" rel="alternate" type="text/html"/>
    <title>Convex body chasing, Steiner point, Sellke point, and SODA 2020 best papers</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Big congratulations to my former intern Mark Sellke, and to the CMU team (C. J. Argue, Anupam Gupta, Guru Guruganesh, and Ziye Tang) for jointly winning the best paper award at SODA 2020 (as well as the best student paper … <a href="https://blogs.princeton.edu/imabandit/2019/11/05/convex-body-chasing-steiner-point-sellke-point-and-soda-2020-best-papers/">Continue reading <span class="meta-nav">→</span></a></p></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Big congratulations to my former intern <a class="liexternal" href="http://web.stanford.edu/~msellke/main">Mark Sellke</a>, and to the CMU team (<a class="liexternal" href="http://www.math.cmu.edu/~cargue/">C. J. Argue</a>, <a class="liexternal" href="http://www.cs.cmu.edu/~anupamg/">Anupam Gupta</a>, Guru Guruganesh, and Ziye Tang) for jointly winning the <a class="liinternal" href="https://www.siam.org/conferences/cm/program/special-events/soda20-special-events">best paper award at SODA 2020</a> (as well as the best student paper for Mark)! They obtain a linear in the dimension competitive ratio for convex body chasing, a problem which was entirely open for any <img alt="d \geq 3" class="ql-img-inline-formula " height="16" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e001a3fd5bcc2fc507220b28ff996717_l3.png?resize=42%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="42"/> just two years ago. What’s more is that they found <a class="liinternal" href="https://arxiv.org/abs/1905.11968">the algorithm (and proof)</a> from The Book! Let me explain.</p>
<p> </p>
<p><strong>Convex body chasing</strong></p>
<p>In convex body chasing an online algorithm is presented at each time step with a convex body <img alt="K_t \subset \mathbb{R}^d" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3fdc69e932e1950b410306bf5e91f317_l3.png?resize=65%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="65"/>, and it must choose a point <img alt="x_t \in K_t" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-dcddd0271254f09cb70e59f7636af336_l3.png?resize=58%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="58"/>. The online algorithm is trying to minimize its total movement, namely <img alt="\sum_{t \geq 0} \|x_{t+1} - x_{t}\|" class="ql-img-inline-formula " height="21" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ac0ba40fd0d872561b9bbfe0c2430fa6_l3.png?resize=132%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="132"/> (all the norms here will be Euclidean, for simplicity). To evaluate the performance of the algorithm, one benchmarks it against the smallest movement one could achieve for this sequence of bodies, if one knew in advance the whole sequence. A good example to have in mind is if the sequence <img alt="K_t" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3acdb1aa9c31aca7aa2a197708de9e60_l3.png?resize=20%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> corresponds to lines rotating around some fixed point, then the best thing to do is to move to this fixed point and never move again, while a greedy algorithm might have infinite movement (in the continuous time limit). The competitive ratio is the worst case (over all possible sequences of convex bodies) ratio of the algorithm’s performance to those of the oracle optimum. This problem was introduced in 1993 by Linial and Friedman, mainly motivated by considering a more geometric version of the <a class="liimagelink" href="https://blogs.princeton.edu/imabandit/2017/12/16/k-server-part-1-online-learning-and-online-algorithms/"><img alt="k" class="ql-img-inline-formula " height="13" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9dc53f8ecc1bcf15020c6df4c12f1c27_l3.png?resize=9%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/>-server problem</a>.</p>
<p>As it turns out, this problem in fact has a lot of “real” applications. It is not too surprising given how elementary the problem is. Just to give a flavor, <a class="liexternal" href="http://users.cms.caltech.edu/~adamw/">Adam Wierman</a> and friends show that <a class="lipdf" href="http://www.caia.swin.edu.au/cv/landrew/pubs/capacity_provision_ToN.pdf">dynamic powering of data centers</a> can be viewed as an instance of convex *function* chasing. In convex function chasing, instead of a convex body one gets a convex function <img alt="f_t" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9bdb4107531e167960c3d7ea0ac6c6e3_l3.png?resize=14%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="14"/>, and there is then a movement cost <img alt="\|x_t - x_{t-1}\|" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a5c985c7efa58f7b4fc27244d6ceecab_l3.png?resize=85%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="85"/> and a *service cost* <img alt="f_t(x_t)" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9a9f0c7799e133ea6e52dce0ee96f00f_l3.png?resize=43%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="43"/>. While this is more general than convex body chasing, it turns out that convex body chasing in dimension <img alt="d+1" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c9bf571295c1727c51ef654b528967d2_l3.png?resize=39%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="39"/> is enough to solve convex function chasing in dimension <img alt="d" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ef6965453c87cda7872c06b350e81478_l3.png?resize=10%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> (this is left to the reader as an exercise). Roughly speaking in dynamic power management, one controls various power levels (number of servers online, etc), and a request correspond to a new set of jobs. Turning on/off servers has an associated cost (the movement cost), while servicing the jobs with a certain number of servers has an associated delay (the service cost). You get the idea.</p>
<p> </p>
<p><strong>The Steiner point</strong></p>
<p>In <a class="liinternal" href="https://arxiv.org/abs/1811.00999">a paper</a> to appear at SODA too, we propose (with <a class="liexternal" href="http://yintat.com/">Yin Tat Lee</a>, <a class="liinternal" href="https://web.stanford.edu/~yuanzhil/">Yuanzhi Li</a>, <a class="liinternal" href="https://www.weizmann.ac.il/math/klartag/home">Bo’az Klartag</a>, and <a class="liexternal" href="http://web.stanford.edu/~msellke/main">Mark Sellke</a>) to use the <strong>Steiner point</strong> for the nested convex body chasing problem. In nested convex body chasing the sequence of bodies is nested, and to account for irrelevant additive constant we assume that the oracle optimum starts from the worst point in the starting set <img alt="K_0" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-145ecd5f60fadeca35a63e23997d92f2_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/>. In other words, opt is starting at the point the furthest away in <img alt="K_0" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-145ecd5f60fadeca35a63e23997d92f2_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/> from the closest point in <img alt="K_T" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c59edf016e3136f9eb4e117bb8f69221_l3.png?resize=25%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="25"/>, so its movement is exactly equal to the <a class="liinternal" href="https://en.wikipedia.org/wiki/Hausdorff_distance" rel="nofollow">Hausdorff distance</a> between <img alt="K_0" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-145ecd5f60fadeca35a63e23997d92f2_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/> and <img alt="K_T" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c59edf016e3136f9eb4e117bb8f69221_l3.png?resize=25%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="25"/>. So all we have to do is to give an online algorithm whose movement is proportional to this Hausdorff distance. Some kind of Lipschitzness in Hausdorff distance. Well, it turns out that mathematicians have been looking at this for centuries already, and Steiner back in the 1800’s introduced just what we need: a <strong>selector</strong> (a map from convex sets to points in them, i.e. <img alt="S(K) \in K" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9a5879256c4564abf0f19723bdcbd0f2_l3.png?resize=80%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="80"/> for any convex set <img alt="K" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b760ebc707e08dd6e1888ea8da4c2454_l3.png?resize=16%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="16"/>) which is Lipschitz with respect to the Hausdorff distance, that is:</p>
<p class="ql-center-displayed-equation" style="line-height: 21px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \|S(K) - S(K')\| \leq L \cdot \mathrm{dist}_H(K,K') \,. \]" class="ql-img-displayed-equation " height="21" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-88bc573a98d3513706bc117297bfc04e_l3.png?resize=281%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="281"/></p>
<p>Note that obtaining such a selector is not trivial, for example the first natural guess would be the center of gravity, but it turns out that this is <strong>not</strong> Lipschitz (consider for example what happens with <img alt="K" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b760ebc707e08dd6e1888ea8da4c2454_l3.png?resize=16%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="16"/> being a very thin triangle and <img alt="K'" class="ql-img-inline-formula " height="14" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b063268581b06951ebc5637f21fad0fd_l3.png?resize=20%2C14&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="20"/> being the base of this triangle). Crazy thing is, this Steiner point selector (to be defined shortly) is not only Lipschitz, it is in fact <strong>the most Lipschitz selector</strong> for convex sets. How would you prove such a thing? Well, you clearly need a miracle to happen, and the miracle here is that the Steiner point satisfies some symmetries, which define it uniquely. From there all you need to do is that starting with any selector, you can add some of these symmetries while also improving the Lipschitz constant (for more on this see the references in the linked paper above).</p>
<p>OK, so what is the Steiner point? It has many definitions, but a particular appealing one from an optimizer’s viewpoint is as follows. For a convex set <img alt="K" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b760ebc707e08dd6e1888ea8da4c2454_l3.png?resize=16%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="16"/> and a vector <img alt="\theta \in \mathbb{R}^d" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-24a3864c0a0fdb33b8b28c5c9e29f616_l3.png?resize=51%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="51"/> let <img alt="g_K(\theta)" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d1ee2708d01f3d597e257c20c654f8bc_l3.png?resize=43%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="43"/> be the maximizer of the linear function <img alt="\theta" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-218cdf16b16c99af5ecb73d9adb061f4_l3.png?resize=9%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> in the set <img alt="K" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b760ebc707e08dd6e1888ea8da4c2454_l3.png?resize=16%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="16"/>. Then the Steiner point of <img alt="K" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b760ebc707e08dd6e1888ea8da4c2454_l3.png?resize=16%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="16"/>, <img alt="\mathrm{St}(K)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-47dba33d5bf995134c83d02ac5b3b458_l3.png?resize=46%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="46"/> is defined by:</p>
<p class="ql-center-displayed-equation" style="line-height: 21px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \mathrm{St}(K) = \mathbb{E}_{\theta : \|\theta\| \leq 1} [g_K(\theta)] \,. \]" class="ql-img-displayed-equation " height="21" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1ed1a61ff1d6b62cd71a620f8bdeebb5_l3.png?resize=193%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="193"/></p>
<p>In words: for any direction take the furthest point in <img alt="K" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b760ebc707e08dd6e1888ea8da4c2454_l3.png?resize=16%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="16"/> in that direction, and average over all directions. This feels like a really nice object, and clearly it satisfies <img alt="\mathrm{St}(K) \in K" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0600d9b6a7b40aa047e56d5b11f0f0d3_l3.png?resize=85%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="85"/> (i.e., it is a selector). The algorithm we proposed in our SODA paper is simply to move to <img alt="x_t = \mathrm{St}(K_t)" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-07cd7d19d64122c29f27b6976bbe68f2_l3.png?resize=90%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="90"/>. Let us now see how to analyze this algorithm.</p>
<p> </p>
<p><strong>The nested case proof</strong></p>
<p>First we give an alternative formula for the Steiner point. Denote <img alt="h_K(\theta) = \max_{x \in K} \theta \cdot x" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-8eebb9649a1de2ee8930a5cc0519bb77_l3.png?resize=168%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="168"/>, and observe that <img alt="g_K(\theta) = \nabla h_K(\theta)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-f721cf39b79100662e95d1ee8ef8d5ea_l3.png?resize=128%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="128"/> for almost all <img alt="\theta" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-218cdf16b16c99af5ecb73d9adb061f4_l3.png?resize=9%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/>. Thus using the <a class="liinternal" href="https://en.wikipedia.org/wiki/Divergence_theorem" rel="nofollow">divergence theorem</a> one obtains:</p>
<p class="ql-center-displayed-equation" style="line-height: 21px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \mathrm{St}(K) = d \cdot \mathbb{E}_{\theta : \|\theta\| = 1} [\theta h_K(\theta)] \,. \]" class="ql-img-displayed-equation " height="21" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9e786f72667e6f0939c1fc5e0e436e41_l3.png?resize=225%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="225"/></p>
<p>(The factor <img alt="d" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ef6965453c87cda7872c06b350e81478_l3.png?resize=10%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> comes from the ratio of the volume of the ball to the sphere, and the <img alt="\theta" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-218cdf16b16c99af5ecb73d9adb061f4_l3.png?resize=9%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> in the expectation is because the normal to <img alt="\theta" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-218cdf16b16c99af5ecb73d9adb061f4_l3.png?resize=9%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> is <img alt="\theta" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-218cdf16b16c99af5ecb73d9adb061f4_l3.png?resize=9%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> on the sphere.)</p>
<p>Now we have the following one-line inequality to control the movement of the Steiner point:</p>
<p class="ql-center-displayed-equation" style="line-height: 52px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\begin{align*} \|\mathrm{St}(K) - \mathrm{St}(K')\| &amp; = d \cdot \| \mathbb{E}_{\theta : \|\theta\| = 1} [\theta (h_K(\theta) - h_{K'}(\theta))] \| \\ &amp; \leq d \cdot \mathbb{E}_{\theta : \|\theta\| = 1} [ |h_K(\theta) - h_{K'}(\theta)| ] \end{align*}" class="ql-img-displayed-equation " height="52" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bf37a0d06362627ccbf1c16cdfccce58_l3.png?resize=410%2C52&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="410"/></p>
<p>It only remains to observe that <img alt="|h_K(\theta) - h_{K'}(\theta)| \leq \mathrm{dist}_H(K,K')" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-fa3f0632ef28037f09617b6c8b676ba7_l3.png?resize=249%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="249"/> to obtain a proof that Steiner is <img alt="d" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ef6965453c87cda7872c06b350e81478_l3.png?resize=10%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/>-Lipschitz (in fact as an exercise you can try to improve the above argument to obtain <img alt="O(\sqrt{d})" class="ql-img-inline-formula " height="20" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-8286f5a825001e7cfbcea2430495a77b_l3.png?resize=51%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="51"/>-Lipschitz). Now for nested convex body chasing we will have <img alt="K' \subset K" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3c0e71eb2cbbf930d61ca3800bfa1559_l3.png?resize=61%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="61"/> so that</p>
<p><img alt="|h_K(\theta) - h_{K'}(\theta)| = h_K(\theta) - h_{K'}(\theta)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-6e1794a42bb76829d10b26116a31d32e_l3.png?resize=267%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="267"/> (i.e., no absolute values), and thus the upper bound on the movement will telescope! More precisely:</p>
<p class="ql-center-displayed-equation" style="line-height: 96px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\begin{align*} \sum_{t \geq 0} \|\mathrm{St}(K_t) - \mathrm{St}(K_{t+1})\| &amp; \leq d \cdot \sum_{t \geq 0} \mathbb{E}_{\theta : \|\theta\| = 1} [ h_{K_t}(\theta) - h_{K_{t+1}}(\theta) ] \\ &amp; = d \cdot \mathbb{E}_{\theta : \|\theta\| = 1} [ h_{K_0}(\theta) - h_{K_{T}}(\theta) ] \\ &amp; \leq d \cdot \mathrm{dist}_H(K_0, K_T) \,. \end{align*}" class="ql-img-displayed-equation " height="96" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e648f7a36eb3795aae31e998ff0866c5_l3.png?resize=470%2C96&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="470"/></p>
<p>This proves that the Steiner point is <img alt="d" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ef6965453c87cda7872c06b350e81478_l3.png?resize=10%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/>-competitive for nested convex body chasing. How to generalize this to the non-nested case seemed difficult, and the breakthrough of Mark and the CMU team is to bring back an old friend of the online algorithm community: the work function.</p>
<p> </p>
<p><strong>The work function</strong></p>
<p>The work function <img alt="W_t : \mathbb{R}^d \rightarrow \mathbb{R}" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c06617c85ba7669c6be3e632519a2dec_l3.png?resize=99%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="99"/> is defined as follows. For any point <img alt="x \in \mathbb{R}^d" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9c6f585f2818eec84b05213c11071a67_l3.png?resize=53%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="53"/> it is the smallest cost one can pay to satisfy all the requests <img alt="K_0, \hdots, K_t" class="ql-img-inline-formula " height="16" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-6fade2700ee9892a15c16c975bae1750_l3.png?resize=82%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="82"/> and end up at <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/>. First observe that this function is convex. Indeed take two point <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> and <img alt="y" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0e13c52c4764efa3f5b1e98e3c2cf98a_l3.png?resize=9%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="9"/>, and <img alt="z" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d9d772a59543419785ce66946592259a_l3.png?resize=9%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> the middle point between <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> and <img alt="y" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0e13c52c4764efa3f5b1e98e3c2cf98a_l3.png?resize=9%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="9"/> (any point on the segment between <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> and <img alt="y" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0e13c52c4764efa3f5b1e98e3c2cf98a_l3.png?resize=9%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="9"/> would be treated similarly). In the definition of the work function there is an associated trajectory for both <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> and <img alt="y" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0e13c52c4764efa3f5b1e98e3c2cf98a_l3.png?resize=9%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="9"/>. By convexity of the requests, the sequence of mid points between those two trajectories is a valid trajectory for <img alt="z" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d9d772a59543419785ce66946592259a_l3.png?resize=9%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/>! And moreover the movement of this mid trajectory is (by triangle inequality) less than the average of the movement of the trajectory for <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> and <img alt="y" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0e13c52c4764efa3f5b1e98e3c2cf98a_l3.png?resize=9%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="9"/>. Hence <img alt="W_t((x+y)/2) \leq (W_t(x) + W_t(y))/2" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b2b62227d1720529c220c1704a46f21_l3.png?resize=277%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="277"/>.</p>
<p>A very simple property we will need from the work function is that the norm of its gradient carries some information on the current request. Namely, <img alt="x \not\in K_t \Rightarrow \|\nabla W_t(x)\| = 1" class="ql-img-inline-formula " height="19" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3b1e7323a40ebc675833af415d7b3d42_l3.png?resize=191%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="191"/> (indeed, if <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> is not in the current request set, then the best way to end up there is to move to a point <img alt="z" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d9d772a59543419785ce66946592259a_l3.png?resize=9%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> in <img alt="K_t" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3acdb1aa9c31aca7aa2a197708de9e60_l3.png?resize=20%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> and then move to <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/>, and if <img alt="K_t" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3acdb1aa9c31aca7aa2a197708de9e60_l3.png?resize=20%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> is a polytope then when you move a little bit <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> you don’t move <img alt="z" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d9d772a59543419785ce66946592259a_l3.png?resize=9%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/>, so the cost is changing at rate <img alt="1" class="ql-img-inline-formula " height="13" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-21b5b4cbe9a10b6d847eeb4265b99898_l3.png?resize=7%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="7"/>, hence the norm of the gradient being <img alt="1" class="ql-img-inline-formula " height="13" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-21b5b4cbe9a10b6d847eeb4265b99898_l3.png?resize=7%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="7"/>). Or to put it differently: <img alt="\|\nabla W_t(x)\| &lt; 1 \Rightarrow x \in K_t" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d5613103c6538abdfe07fb8a6f0bdf73_l3.png?resize=189%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="189"/>.</p>
<p> </p>
<p><strong>The Sellke point</strong></p>
<p>Mark’s beautiful idea (and the CMU team very much related –in fact equivalent– idea) to generalize the Steiner point to the non-nested case is to use the work function as a surrogate for the request. Steiner of <img alt="K_t" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3acdb1aa9c31aca7aa2a197708de9e60_l3.png?resize=20%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> will clearly not work since all of <img alt="K_t" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3acdb1aa9c31aca7aa2a197708de9e60_l3.png?resize=20%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> does not matter in the same way, as some points might be essentially irrelevant because they are very far from the previous requests, a fact which will be uncovered by the work function (while on the other hand the random direction from the Steiner point definition is oblivious to the geometry of the previous requests). So how to pick an appropriately random point in <img alt="K_t" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3acdb1aa9c31aca7aa2a197708de9e60_l3.png?resize=20%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> while respecting the work function structure? Well we just saw that <img alt="\|\nabla W_t(x)\| &lt; 1 \Rightarrow x \in K_t" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d5613103c6538abdfe07fb8a6f0bdf73_l3.png?resize=189%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="189"/>. So how about taking a random direction <img alt="\theta" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-218cdf16b16c99af5ecb73d9adb061f4_l3.png?resize=9%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/>, and applying the inverse of the gradient map, namely the gradient of the <strong>Fenchel dual</strong> <img alt="W_t^*" class="ql-img-inline-formula " height="17" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ef52bfe9fd84a48a8585c0d4cc7445c5_l3.png?resize=25%2C17&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="25"/>? Recall that the Fenchel dual is defined by:</p>
<p class="ql-center-displayed-equation" style="line-height: 29px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ W_t^*(\theta) = \max_{x \in \mathbb{R}^d} \theta \cdot x - W_t(x) \,. \]" class="ql-img-displayed-equation " height="29" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-38f4e45e13b56402f2542d6d10104c23_l3.png?resize=216%2C29&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="216"/></p>
<p>This is exactly the algorithm Mark proposes and it goes like this (Mark calls it the *functional Steiner point*):</p>
<p class="ql-center-displayed-equation" style="line-height: 22px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \mathrm{Se}(K_t) = \mathbb{E}_{\theta : \|\theta\| &lt; 1} [\nabla W_t^*(\theta)] \,. \]" class="ql-img-displayed-equation " height="22" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1c48be67527ecd410d08235502958d42_l3.png?resize=219%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="219"/></p>
<p>Crucially this is a valid point, namely <img alt="\mathrm{Se}(K_t) \in K_t" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4a1a15b2c69480b3c0cad98acf3b2ad9_l3.png?resize=94%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="94"/>. Moreover just like for the Steiner point we can apply the divergence theorem and obtain:</p>
<p class="ql-center-displayed-equation" style="line-height: 22px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \mathrm{Se}(K_t) = d \cdot \mathbb{E}_{\theta : \|\theta\| = 1} [\theta W_t^*(\theta)] \,. \]" class="ql-img-displayed-equation " height="22" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-329630ec5ed1634f7880d91ce9666807_l3.png?resize=235%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="235"/></p>
<p>The beautiful thing is that we can now <strong>exactly</strong> repeat the nested convex body argument, since <img alt="W_{t+1}^*(\theta) \leq W_t^*(\theta)" class="ql-img-inline-formula " height="21" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3dd6961afcbaae41b54d8e7651b9cd94_l3.png?resize=135%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="135"/> for all <img alt="\theta" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-218cdf16b16c99af5ecb73d9adb061f4_l3.png?resize=9%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> (just like we had in the nested case <img alt="h_{K_{t+1}}(\theta) \leq h_{K_t}(\theta)" class="ql-img-inline-formula " height="21" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-f34e37633e4a00d3fa90457f5a676ef7_l3.png?resize=139%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="139"/>) and so we get:</p>
<p class="ql-center-displayed-equation" style="line-height: 40px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \sum_{t \geq 0} \|\mathrm{Se}(K_t) - \mathrm{Se}(K_{t+1})\| \leq d \cdot \mathbb{E}_{\theta : \|\theta\| = 1} [ W_{0}^*(\theta) - W^*_{{T}}(\theta) ] \]" class="ql-img-displayed-equation " height="40" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-593f9a9e90a2740715be744ac89275ac_l3.png?resize=426%2C40&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="426"/></p>
<p>The first term with <img alt="W_0^*" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-03b6bb14cb85145aa8efb2ba6b6fba23_l3.png?resize=25%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="25"/> is just some additive constant which we can ignore, while the second term is bounded as follows:</p>
<p class="ql-center-displayed-equation" style="line-height: 105px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\begin{align*} \mathbb{E}_{\theta : \|\theta\| = 1} [ - W^*_{{T}}(\theta) ] &amp; = \mathbb{E}_{\theta : \|\theta\| = 1} [ \min_{x \in \mathbb{R}^d} W_t(x) - \theta \cdot x ] \\ &amp; \leq \min_{x \in \mathbb{R}^d} \mathbb{E}_{\theta : \|\theta\| = 1}[ W_t(x) - \theta \cdot x ] \\ &amp; = \min_{x \in \mathbb{R}^d} W_t(x) \,. \end{align*}" class="ql-img-displayed-equation " height="105" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-f7d98d503b4ecd2f79bb081ccddccceb_l3.png?resize=364%2C105&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="364"/></p>
<p>Thus we exactly proved that the movement of the Sellke point is upped bounded by a constant plus <img alt="d" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ef6965453c87cda7872c06b350e81478_l3.png?resize=10%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> times the minimum of the work function, and the latter is nothing but the value of the oracle optimum!</p>
<p>Note that once everything is done and said, the proof has only <strong>two</strong> inequalities (triangle inequality as in the nested case, and the minimum of the expectation is less than the expectation of the minimum). It doesn’t get any better than this!</p></div>
    </content>
    <updated>2019-11-05T05:40:20Z</updated>
    <published>2019-11-05T05:40:20Z</published>
    <category term="Theoretical Computer Science"/>
    <author>
      <name>Sebastien Bubeck</name>
    </author>
    <source>
      <id>https://blogs.princeton.edu/imabandit</id>
      <link href="https://blogs.princeton.edu/imabandit/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blogs.princeton.edu/imabandit" rel="alternate" type="text/html"/>
      <subtitle>Random topics in optimization, probability, and statistics. By Sébastien Bubeck</subtitle>
      <title>I’m a bandit</title>
      <updated>2019-11-05T23:53:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01414</id>
    <link href="http://arxiv.org/abs/1911.01414" rel="alternate" type="text/html"/>
    <title>Counting Small Permutation Patterns</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Even=Zohar:Chaim.html">Chaim Even-Zohar</a>, Calvin Leng <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01414">PDF</a><br/><b>Abstract: </b>A sample of n generic points in the xy-plane defines a permutation that
relates their ranks along the two axes. Every subset of k points similarly
defines a pattern, which occurs in that permutation. The number of occurrences
of small patterns in a large permutation arises in many areas, including
nonparametric statistics. It is therefore desirable to count them more
efficiently than the straightforward ~O(n^k) time algorithm.
</p>
<p>This work proposes new algorithms for counting patterns. We show that all
patterns of order 2 and 3, as well as eight patterns of order 4, can be counted
in nearly linear time. To that end, we develop an algebraic framework that we
call corner tree formulas. Our approach generalizes the existing methods and
allows a systematic study of their scope.
</p>
<p>Using the machinery of corner trees, we find twenty-three independent linear
combinations of order-4 patterns, that can be computed in time ~O(n). We also
describe an algorithm that counts another 4-pattern, and hence all 4-patterns,
in time ~O(n^(3/2)).
</p>
<p>As a practical application, we provide a nearly linear time computation of a
statistic by Yanagimoto (1970), Bergsma and Dassios (2010). This statistic
yields a natural and strongly consistent variant of Hoeffding's test for
independence of X and Y, given a random sample as above. This improves upon the
so far most efficient ~O(n^2) algorithm.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01411</id>
    <link href="http://arxiv.org/abs/1911.01411" rel="alternate" type="text/html"/>
    <title>Lifting Sum-of-Squares Lower Bounds: Degree-$2$ to Degree-$4$</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mohanty:Sidhanth.html">Sidhanth Mohanty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raghavendra:Prasad.html">Prasad Raghavendra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Jeff.html">Jeff Xu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01411">PDF</a><br/><b>Abstract: </b>The degree-$4$ Sum-of-Squares (SoS) SDP relaxation is a powerful algorithm
that captures the best known polynomial time algorithms for a broad range of
problems including MaxCut, Sparsest Cut, all MaxCSPs and tensor PCA. Despite
being an explicit algorithm with relatively low computational complexity, the
limits of degree-$4$ SoS SDP are not well understood. For example, existing
integrality gaps do not rule out a $(2-\varepsilon)$-algorithm for Vertex Cover
or a $(0.878+\varepsilon)$-algorithm for MaxCut via degree-$4$ SoS SDPs, each
of which would refute the notorious Unique Games Conjecture.
</p>
<p>We exhibit an explicit mapping from solutions for degree-$2$ Sum-of-Squares
SDP (Goemans-Williamson SDP) to solutions for the degree-$4$ Sum-of-Squares SDP
relaxation on boolean variables. By virtue of this mapping, one can lift lower
bounds for degree-$2$ SoS SDP relaxation to corresponding lower bounds for
degree-$4$ SoS SDPs. We use this approach to obtain degree-$4$ SoS SDP lower
bounds for MaxCut on random $d$-regular graphs, Sherington-Kirkpatrick model
from statistical physics and PSD Grothendieck problem.
</p>
<p>Our constructions use the idea of pseudocalibration towards candidate SDP
vectors, while it was previously only used to produce the candidate matrix
which one would show is PSD using much technical work. In addition, we develop
a different technique to bound the spectral norms of _graphical matrices_ that
arise in the context of SoS SDPs. The technique is much simpler and yields
better bounds in many cases than the _trace method_ -- which was the sole
technique for this purpose.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01402</id>
    <link href="http://arxiv.org/abs/1911.01402" rel="alternate" type="text/html"/>
    <title>Providing Input-Discriminative Protection for Local Differential Privacy</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gu:Xiaolan.html">Xiaolan Gu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Ming.html">Ming Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xiong:Li.html">Li Xiong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cao:Yang.html">Yang Cao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01402">PDF</a><br/><b>Abstract: </b>Local Differential Privacy (LDP) provides provable privacy protection for
data collection without the assumption of the trusted data server. In the
real-world scenario, different data have different privacy requirements due to
the distinct sensitivity levels. However, LDP provides the same protection for
all data. In this paper, we tackle the challenge of providing
input-discriminative protection to reflect the distinct privacy requirements of
different inputs. We first present the Input-Discriminative LDP (ID-LDP)
privacy notion and focus on a specific version termed MinID-LDP, which is shown
to be a fine-grained version of LDP. Then, we develop the IDUE mechanism based
on Unary Encoding for single-item input and the extended mechanism IDUE-PS
(with Padding-and-Sampling protocol) for item-set input. The results on both
synthetic and real-world datasets validate the correctness of our theoretical
analysis and show that the proposed mechanisms satisfying MinID-LDP have better
utility than the state-of-the-art mechanisms satisfying LDP due to the
input-discriminative protection.
</p></div>
    </summary>
    <updated>2019-11-05T23:31:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01381</id>
    <link href="http://arxiv.org/abs/1911.01381" rel="alternate" type="text/html"/>
    <title>Bare quantum simultaneity versus classical interactivity in communication complexity</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gavinsky:Dmitry.html">Dmitry Gavinsky</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01381">PDF</a><br/><b>Abstract: </b>A relational bipartite communication problem is presented that has an
efficient quantum simultaneous-messages protocol, but no efficient classical
two-way protocol.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01374</id>
    <link href="http://arxiv.org/abs/1911.01374" rel="alternate" type="text/html"/>
    <title>Algorithms for Intersection Graphs of Multiple Intervals and Pseudo Disks</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chekuri:Chandra.html">Chandra Chekuri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Inamdar:Tanmay.html">Tanmay Inamdar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01374">PDF</a><br/><b>Abstract: </b>Intersection graphs of planar geometric objects such as intervals, disks,
rectangles and pseudo-disks are well studied. Motivated by various
applications, Butman et al. in SODA 2007 considered algorithmic questions in
intersection graphs of $t$-intervals. A $t$-interval is a union of at most $t$
distinct intervals (here $t$ is a parameter) -- these graphs are referred to as
Multiple-Interval Graphs. Subsequent work by Kammer et al. in Approx 2010 also
considered $t$-disks and other geometric shapes. In this paper we revisit some
of these algorithmic questions via more recent developments in computational
geometry. For the minimum weight dominating set problem, we give a simple $O(t
\log t)$ approximation for Multiple-Interval Graphs, improving on the
previously known bound of $t^2$ . We also show that it is NP-hard to obtain an
$o(t)$-approximation in this case. In fact, our results hold for the
intersection graph of a set of t-pseudo-disks which is a much larger class. We
obtain an ${\Omega}(1/t)$-approximation for the maximum weight independent set
in the intersection graph of $t$-pseudo-disks. Our results are based on simple
reductions to existing algorithms by appropriately bounding the union
complexity of the objects under consideration.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01351</id>
    <link href="http://arxiv.org/abs/1911.01351" rel="alternate" type="text/html"/>
    <title>Faster Update Time for Turnstile Streaming Algorithms</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alman:Josh.html">Josh Alman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Huacheng.html">Huacheng Yu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01351">PDF</a><br/><b>Abstract: </b>In this paper, we present a new algorithm for maintaining linear sketches in
turnstile streams with faster update time. As an application, we show that
$\log n$ \texttt{Count} sketches or \texttt{CountMin} sketches with a constant
number of columns (i.e., buckets) can be implicitly maintained in
\emph{worst-case} $O(\log^{0.582} n)$ update time using $O(\log n)$ words of
space, on a standard word RAM with word-size $w=\Theta(\log n)$. The exponent
$0.582\approx 2\omega/3-1$, where $\omega$ is the current matrix multiplication
exponent. Due to the numerous applications of linear sketches, our algorithm
improves the update time for many streaming problems in turnstile streams, in
the high success probability setting, without using more space, including
$\ell_2$ norm estimation, $\ell_2$ heavy hitters, point query with $\ell_1$ or
$\ell_2$ error, etc. Our algorithm generalizes, with the same update time and
space, to maintaining $\log n$ linear sketches, where each sketch partitions
the coordinates into $k&lt;\log^{o(1)} n$ buckets using a $c$-wise independent
hash function for constant $c$, and maintains the sum of coordinates for each
bucket. Moreover, if arbitrary word operations are allowed, the update time can
be further improved to $O(\log^{0.187} n)$, where $0.187\approx \omega/2-1$.
Our update algorithm is adaptive, and it circumvents the non-adaptive
cell-probe lower bounds for turnstile streaming algorithms by Larsen, Nelson
and Nguy{\^{e}}n (STOC'15).
</p>
<p>On the other hand, our result also shows that proving unconditional
cell-probe lower bound for the update time seems very difficult, even if the
space is restricted to be (nearly) the optimum. If $\omega=2$, the cell-probe
update time of our algorithm would be $\log^{o(1)} n$. Hence, proving any
higher lower bound would imply $\omega&gt;2$.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01348</id>
    <link href="http://arxiv.org/abs/1911.01348" rel="alternate" type="text/html"/>
    <title>Nearly Optimal Static Las Vegas Succinct Dictionary</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Huacheng.html">Huacheng Yu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01348">PDF</a><br/><b>Abstract: </b>Given a set $S$ of $n$ (distinct) keys from key space $[U]$, each associated
with a value from $\Sigma$, the \emph{static dictionary} problem asks to
preprocess these (key, value) pairs into a data structure, supporting
value-retrieval queries: for any given $x\in [U]$, $\mathtt{valRet}(x)$ must
return the value associated with $x$ if $x\in S$, or return $\bot$ if $x\notin
S$. The special case where $|\Sigma|=1$ is called the \emph{membership}
problem. The "textbook" solution is to use a hash table, which occupies linear
space and answers each query in constant time. On the other hand, the minimum
possible space to encode all (key, value) pairs is only $\mathtt{OPT}:=
\lceil\lg_2\binom{U}{n}+n\lg_2|\Sigma|\rceil$ bits, which could be much less.
</p>
<p>In this paper, we design a randomized dictionary data structure using
$\mathtt{OPT}+\mathrm{poly}\lg n+O(\lg\lg\lg\lg\lg U)$ bits of space, and it
has \emph{expected constant} query time, assuming the query algorithm can
access an external lookup table of size $n^{0.001}$. The lookup table depends
only on $U$, $n$ and $|\Sigma|$, and not the input. Previously, even for
membership queries and $U\leq n^{O(1)}$, the best known data structure with
constant query time requires $\mathtt{OPT}+n/\mathrm{poly}\lg n$ bits of space
(Pagh [Pag01] and P\v{a}tra\c{s}cu [Pat08]); the best-known using
$\mathtt{OPT}+n^{0.999}$ space has query time $O(\lg n)$; the only known
non-trivial data structure with $\mathtt{OPT}+n^{0.001}$ space has $O(\lg n)$
query time and requires a lookup table of size $\geq n^{2.99}$ (!). Our new
data structure answers open questions by P\v{a}tra\c{s}cu and Thorup
[Pat08,Tho13].
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01330</id>
    <link href="http://arxiv.org/abs/1911.01330" rel="alternate" type="text/html"/>
    <title>Bitcoin Coin Selection with Leverage</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Daniel J. Diroff <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01330">PDF</a><br/><b>Abstract: </b>We present a new Bitcoin coin selection algorithm, "coin selection with
leverage", which aims to improve upon cost savings than that of standard
knapsack like approaches. Parameters to the new algorithm are available to be
tuned at the users discretion to address other goals of coin selection. Our
approach naturally fits as a replacement for the standard knapsack ingredient
of full coin selection procedures.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01319</id>
    <link href="http://arxiv.org/abs/1911.01319" rel="alternate" type="text/html"/>
    <title>Fast sampling and counting k-SAT solutions in the local lemma regime</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feng:Weiming.html">Weiming Feng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Heng.html">Heng Guo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yin:Yitong.html">Yitong Yin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Chihao.html">Chihao Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01319">PDF</a><br/><b>Abstract: </b>We give new algorithms based on Markov chains to sample and approximately
count satisfying assignments to $k$-uniform CNF formulas where each variable
appears at most $d$ times. For any $k$ and $d$ satisfying $kd&lt;n^{o(1)}$ and
$k\ge 20\log k + 20\log d + 60$, the new sampling algorithm runs in close to
linear time, and the counting algorithm runs in close to quadratic time.
</p>
<p>Our approach is inspired by Moitra (JACM, 2019) which remarkably utilizes the
Lov\'{a}sz local lemma in approximate counting. Our main technical contribution
is to use the local lemma to bypass the connectivity barrier in traditional
Markov chain approaches, which makes the well developed MCMC method applicable
on disconnected state spaces such as SAT solutions. The benefit of our approach
is to avoid the enumeration of local structures and obtain fixed polynomial
running times, even if $k=\omega(1)$ or $d=\omega(1)$.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01169</id>
    <link href="http://arxiv.org/abs/1911.01169" rel="alternate" type="text/html"/>
    <title>Optimal Adaptive Detection of Monotone Patterns</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ben=Eliezer:Omri.html">Omri Ben-Eliezer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Letzter:Shoham.html">Shoham Letzter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Waingarten:Erik.html">Erik Waingarten</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01169">PDF</a><br/><b>Abstract: </b>We investigate adaptive sublinear algorithms for detecting monotone patterns
in an array. Given fixed $2 \leq k \in \mathbb{N}$ and $\varepsilon &gt; 0$,
consider the problem of finding a length-$k$ increasing subsequence in an array
$f \colon [n] \to \mathbb{R}$, provided that $f$ is $\varepsilon$-far from free
of such subsequences. Recently, it was shown that the non-adaptive query
complexity of the above task is $\Theta((\log n)^{\lfloor \log_2 k \rfloor})$.
In this work, we break the non-adaptive lower bound, presenting an adaptive
algorithm for this problem which makes $O(\log n)$ queries. This is optimal,
matching the classical $\Omega(\log n)$ adaptive lower bound by Fischer [2004]
for monotonicity testing (which corresponds to the case $k=2$), and implying in
particular that the query complexity of testing whether the longest increasing
subsequence (LIS) has constant length is $\Theta(\log n)$.
</p></div>
    </summary>
    <updated>2019-11-05T23:28:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.01145</id>
    <link href="http://arxiv.org/abs/1911.01145" rel="alternate" type="text/html"/>
    <title>Minimum Cut in $O(m\log^2 n)$ Time</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Paweł Gawrychowski, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mozes:Shay.html">Shay Mozes</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weimann:Oren.html">Oren Weimann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.01145">PDF</a><br/><b>Abstract: </b>We give a randomized algorithm that finds a minimum cut in an undirected
weighted $m$-edge $n$-vertex graph $G$ with high probability in $O(m \log^2 n)$
time. This is the first improvement to Karger's celebrated $O(m \log^3 n)$ time
algorithm from 1996. Our main technical contribution is an $O(m \log n)$ time
algorithm that, given a spanning tree $T$ of $G$, finds a minimum cut of $G$
that 2-respects (cuts two edges of) $T$.
</p></div>
    </summary>
    <updated>2019-11-05T23:27:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.00944</id>
    <link href="http://arxiv.org/abs/1911.00944" rel="alternate" type="text/html"/>
    <title>Shannon capacity and the categorical product</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Simonyi:G=aacute=bor.html">Gábor Simonyi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.00944">PDF</a><br/><b>Abstract: </b>Shannon OR-capacity $C_{\rm OR}(G)$ of a graph $G$, that is the traditionally
more often used Shannon AND-capacity of the complementary graph, is a
homomorphism monotone graph parameter satisfying $C_{\rm OR}(F\times
G)\le\min\{C_{\rm OR}(F),C_{\rm OR}(G)\}$ for every pair of graphs, where
$F\times G$ is the categorical product of graphs $F$ and $G$. Here we initiate
the study of the question when could we expect equality in this inequality.
Using a strong recent result of Zuiddam, we show that if this "Hedetniemi-type"
equality is not satisfied for some pair of graphs then the analogous equality
is also not satisfied for this graph pair by some other graph invariant that
has a much "nicer" behavior concerning some different graph operations. In
particular, unlike Shannon capacity or the chromatic number, this other
invariant is both multiplicative under the OR-product and additive under the
join operation, while it is also nondecreasing along graph homomorphisms. We
also present a natural lower bound on $C_{\rm OR}(F\times G)$ and elaborate on
the question of how to find graph pairs for which it is known to be strictly
less, than the upper bound $\min\{C_{\rm OR}(F),C_{\rm OR}(G)\}$. We present
such graph pairs using the properties of Paley graphs.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.00911</id>
    <link href="http://arxiv.org/abs/1911.00911" rel="alternate" type="text/html"/>
    <title>Testing noisy linear functions for sparsity</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Xue.html">Xue Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/De:Anindya.html">Anindya De</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Servedio:Rocco_A=.html">Rocco A. Servedio</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.00911">PDF</a><br/><b>Abstract: </b>We consider the following basic inference problem: there is an unknown
high-dimensional vector $w \in \mathbb{R}^n$, and an algorithm is given access
to labeled pairs $(x,y)$ where $x \in \mathbb{R}^n$ is a measurement and $y = w
\cdot x + \mathrm{noise}$. What is the complexity of deciding whether the
target vector $w$ is (approximately) $k$-sparse? The recovery analogue of this
problem --- given the promise that $w$ is sparse, find or approximate the
vector $w$ --- is the famous sparse recovery problem, with a rich body of work
in signal processing, statistics, and computer science.
</p>
<p>We study the decision version of this problem (i.e.~deciding whether the
unknown $w$ is $k$-sparse) from the vantage point of property testing. Our
focus is on answering the following high-level question: when is it possible to
efficiently test whether the unknown target vector $w$ is sparse versus
far-from-sparse using a number of samples which is completely independent of
the dimension $n$? We consider the natural setting in which $x$ is drawn from a
i.i.d.~product distribution $\mathcal{D}$ over $\mathbb{R}^n$ and the
$\mathrm{noise}$ process is independent of the input $x$. As our main result,
we give a general algorithm which solves the above-described testing problem
using a number of samples which is completely independent of the ambient
dimension $n$, as long as $\mathcal{D}$ is not a Gaussian. In fact, our
algorithm is fully noise tolerant, in the sense that for an arbitrary $w$, it
approximately computes the distance of $w$ to the closest $k$-sparse vector. To
complement this algorithmic result, we show that weakening any of our condition
makes it information-theoretically impossible for any algorithm to solve the
testing problem with fewer than essentially $\log n$ samples.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.00864</id>
    <link href="http://arxiv.org/abs/1911.00864" rel="alternate" type="text/html"/>
    <title>Proportionally Representative Participatory Budgeting with Ordinal Preferences</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aziz:Haris.html">Haris Aziz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Barton_E=.html">Barton E. Lee</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.00864">PDF</a><br/><b>Abstract: </b>Participatory budgeting (PB) is a democratic paradigm whereby voters decide
on which projects to fund. We consider PB in which voters may be asymmetric,
and they report ordinal preferences over projects. We propose proportional
representation axioms for the setting and clarify how they fit into other
preference aggregation settings. As a result of our study, we also discover a
new solution concept that is stronger than proportional justified
representation (PJR) for approval-based multi-winner voting.
</p></div>
    </summary>
    <updated>2019-11-05T23:28:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.00722</id>
    <link href="http://arxiv.org/abs/1911.00722" rel="alternate" type="text/html"/>
    <title>A Solution of the P versus NP Problem based on specific property of clique function</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Boyu Sima <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.00722">PDF</a><br/><b>Abstract: </b>Circuit lower bounds are important since it is believed that a
super-polynomial circuit lower bound for a problem in NP implies that P!=NP.
Razborov has proved superpolynomial lower bounds for monotone circuits by using
method of approximation. By extending this approach, researchers have proved
exponential lower bounds for the monotone network complexity of several
different functions. But until now, no one could prove a non-linear lower bound
for the non-monotone complexity of any Boolean function in NP. While we show
that in this paper by replacement of each Not gates into constant 1
equivalently in standard circuit for clique problem, it can be proved that
non-monotone network has the same or higher lower bound compared to the
monotone one for computing the clique function. This indicates that the
non-monotone network complexity of the clique function is super-polynomial
which implies that P!=NP.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.00687</id>
    <link href="http://arxiv.org/abs/1911.00687" rel="alternate" type="text/html"/>
    <title>Topological Feature Search in Time-Varying Multifield Data</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Tripti Agarwal, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chattopadhyay:Amit.html">Amit Chattopadhyay</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Natarajan:Vijay.html">Vijay Natarajan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.00687">PDF</a><br/><b>Abstract: </b>A wide range of data that appear in scientific experiments and simulations
are multivariate or multifield in nature, consisting of multiple scalar fields.
Topological feature search of such data aims to reveal important properties
useful to the domain scientists. It has been shown in recent works that a
single scalar field is insufficient to capture many important topological
features in the data, instead one needs to consider topological relationships
between multiple scalar fields. In the current paper, we propose a novel method
of finding similarity between two multifield data by comparing their respective
fiber component distributions. Given a time-varying multifield data, the method
computes a metric plot for each pair of histograms at consecutive time stamps
to understand the topological changes in the data over time. We validate the
method using real and synthetic data. The effectiveness of the proposed method
is shown by its ability to capture important topological features that are not
always possible to detect using the individual component scalar fields.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.00678</id>
    <link href="http://arxiv.org/abs/1911.00678" rel="alternate" type="text/html"/>
    <title>3D tissue reconstruction with Kinect to evaluate neck lymphedema</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Gerrit Brugman, Beril Sirmacek <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.00678">PDF</a><br/><b>Abstract: </b>Lymphedema is a condition of localized tissue swelling caused by a damaged
lymphatic system. Therapy to these tissues is applied manually. Some of the
methods are lymph drainage, compression therapy or bandaging. However, the
therapy methods are still insufficiently evaluated. Especially, because of not
having a reliable method to measure the change of such a soft and flexible
tissue. In this research, our goal has been providing a 3d computer vision
based method to measure the changes of the neck tissues. To do so, we used
Kinect as a depth sensor and built our algorithms for the point cloud data
acquired from this sensor. The resulting 3D models of the patient necks are
used for comparing the models in time and measuring the volumetric changes
accurately. Our discussions with the medical doctors validate that, when used
in practice this approach would be able to give better indication on which
therapy method is helping and how the tissue is changing in time.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.00675</id>
    <link href="http://arxiv.org/abs/1911.00675" rel="alternate" type="text/html"/>
    <title>ProbMinHash -- A Class of Locality-Sensitive Hash Algorithms for the (Probability) Jaccard Similarity</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ertl:Otmar.html">Otmar Ertl</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.00675">PDF</a><br/><b>Abstract: </b>The probability Jaccard similarity was recently proposed as a natural
generalization of the Jaccard similarity to measure the proximity of sets whose
elements are associated with relative frequencies or probabilities. In
combination with a hash algorithm that maps those weighted sets to compact
signatures which allow fast estimation of pairwise similarities, it constitutes
a valuable method for big data applications such as near-duplicate detection,
nearest neighbor search, or clustering. This paper introduces a class of
locality-sensitive one-pass hash algorithms that are orders of magnitude faster
than the original approach. The performance gain is achieved by calculating
signature components not independently, but collectively. Four different
algorithms are proposed based on this idea. Two of them are statistically
equivalent to the original approach and can be used as direct replacements. The
other two may even improve the estimation error by breaking the statistical
independence of signature components. Moreover, the presented techniques can be
specialized for the conventional Jaccard similarity, resulting in highly
efficient algorithms that outperform traditional minwise hashing.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.00612</id>
    <link href="http://arxiv.org/abs/1911.00612" rel="alternate" type="text/html"/>
    <title>Computing Circle Packing Representations of Planar Graphs</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dong:Sally.html">Sally Dong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Yin_Tat.html">Yin Tat Lee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Quanrud:Kent.html">Kent Quanrud</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.00612">PDF</a><br/><b>Abstract: </b>The Circle Packing Theorem states that every planar graph can be represented
as the tangency graph of a family of internally-disjoint circles. A well-known
generalization is the Primal-Dual Circle Packing Theorem for 3-connected planar
graphs. The existence of these representations has widespread applications in
theoretical computer science and mathematics; however, the algorithmic aspect
has received relatively little attention. In this work, we present an algorithm
based on convex optimization for computing a primal-dual circle packing
representation of maximal planar graphs, i.e. triangulations. This in turn
gives an algorithm for computing a circle packing representation of any planar
graph. Both take $\widetilde{O}(n \log(R/\varepsilon))$ expected run-time to
produce a solution that is $\varepsilon$ close to a true representation, where
$R$ is the ratio between the maximum and minimum circle radius in the true
representation.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.00586</id>
    <link href="http://arxiv.org/abs/1911.00586" rel="alternate" type="text/html"/>
    <title>CNF Encodings of Cardinality Constraints Based on Comparator Networks</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Michał Karpiński <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.00586">PDF</a><br/><b>Abstract: </b>Boolean Satisfiability Problem (SAT) is one of the core problems in computer
science. As one of the fundamental NP-complete problems, it can be used - by
known reductions - to represent instances of variety of hard decision problems.
Additionally, those representations can be passed to a program for finding
satisfying assignments to Boolean formulas, for example, to a program called
MiniSat. Those programs (called SAT-solvers) have been intensively developed
for many years and - despite their worst-case exponential time complexity - are
able to solve a multitude of hard practical instances. A drawback of this
approach is that clauses are neither expressive, nor compact, and using them to
describe decision problems can pose a big challenge on its own.
</p>
<p>We can improve this by using high-level constraints as a bridge between a
problem at hand and SAT. Such constraints are then automatically translated to
eqisatisfiable Boolean formulas. The main theme of this thesis revolves around
one type of such constraints, namely Boolean Cardinality Constraints (or simply
cardinality constraints). Cardinality constraints state that at most (at least,
or exactly) k out of n propositional literals can be true. Such cardinality
constraints appear naturally in formulations of different real-world problems
including cumulative scheduling, timetabling or formal hardware verification.
</p>
<p>The goal of this thesis is to propose and analyze new and efficient methods
to encode (translate) cardinality constraints into equisatisfiable proposition
formulas in CNF, such that the resulting SAT instances are small and that the
SAT-solver runtime is as short as possible.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.00573</id>
    <link href="http://arxiv.org/abs/1911.00573" rel="alternate" type="text/html"/>
    <title>An Experimental Study of a 1-planarity Testing and Embedding Algorithm</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Binucci:Carla.html">Carla Binucci</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Didimo:Walter.html">Walter Didimo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Montecchiani:Fabrizio.html">Fabrizio Montecchiani</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.00573">PDF</a><br/><b>Abstract: </b>The definition of $1$-planar graphs naturally extends graph planarity, namely
a graph is $1$-planar if it can be drawn in the plane with at most one crossing
per edge. Unfortunately, while testing graph planarity is solvable in linear
time, deciding whether a graph is $1$-planar is NP-complete, even for
restricted classes of graphs. Although several polynomial-time algorithms have
been described for recognizing specific subfamilies of $1$-planar graphs, no
implementations of general algorithms are available to date. We investigate the
feasibility of a $1$-planarity testing and embedding algorithm based on a
backtracking strategy. While the experiments show that our approach can be
successfully applied to graphs with up to 30 vertices, they also suggest the
need of more sophisticated techniques to attack larger graphs. Our contribution
provides initial indications that may stimulate further research on the design
of practical approaches for the $1$-planarity testing problem.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.00571</id>
    <link href="http://arxiv.org/abs/1911.00571" rel="alternate" type="text/html"/>
    <title>Cylindrical Shape Decomposition Algorithm for 3D Segmentation</title>
    <feedworld_mtime>1572912000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abdollahzadeh:Ali.html">Ali Abdollahzadeh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sierra:Alejandra.html">Alejandra Sierra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tohka:Jussi.html">Jussi Tohka</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.00571">PDF</a><br/><b>Abstract: </b>Shape decomposition is a fundamental problem in geometry processing where an
arbitrary object is regarded as an arrangement of simple primitives or semantic
components. The application of 3D shape decomposition in the context of image
segmentation, however, is not well-studied. In this paper, we develop a shape
decomposition algorithm called cylindrical shape decomposition (CSD) to be
applied for the segmentation of tubular structures in large-scale 3D images.
CSD starts by partitioning the curve skeleton of a tubular object into
maximal-length sub-skeletons, minimizing an orientation objective. Each
sub-skeleton corresponds to a semantic component. To determine boundaries
between the semantic components, CSD searches for critical points where the
object cross-section substantially changes. CSD then cuts the object at
critical points and assigns the same label to those object parts which are
along the same sub-skeleton, defining a semantic tubular component. CSD further
rectify/reconstructs these semantic components using generalized cylinders. We
demonstrate the application of CSD in the segmentation of large-scale 3D
electron microscopy image datasets of myelinated axons, the decomposition of
vascular networks, and synthetic objects. We also compare CSD to other
state-of-the-art decomposition techniques in these applications. These
experiments indicate that CSD outperforms other decomposition techniques and
achieves a promising performance.
</p></div>
    </summary>
    <updated>2019-11-05T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-05T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/04/assistant-professor-at-uc-san-diego-apply-by-december-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/04/assistant-professor-at-uc-san-diego-apply-by-december-15-2019/" rel="alternate" type="text/html"/>
    <title>Assistant professor at UC San Diego (apply by December 15, 2019)</title>
    <summary>The University of California, San Diego invites applications from outstanding candidates for a tenure-track faculty position for primary appointment at the Halicioglu Data Science Institute with optional joint appointment in another academic department. One of the focus areas this year is theory of data science. More details are in the website. Website: https://apol-recruit.ucsd.edu/JPF02319 Email: shachar.lovett@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The University of California, San Diego invites applications from outstanding candidates for a tenure-track faculty position for primary appointment at the Halicioglu Data Science Institute with optional joint appointment in another academic department. One of the focus areas this year is theory of data science. More details are in the website.</p>
<p>Website: <a href="https://apol-recruit.ucsd.edu/JPF02319">https://apol-recruit.ucsd.edu/JPF02319</a><br/>
Email: shachar.lovett@gmail.com</p></div>
    </content>
    <updated>2019-11-04T23:40:59Z</updated>
    <published>2019-11-04T23:40:59Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-06T01:20:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/04/faculty-at-oregon-state-university-apply-by-november-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/04/faculty-at-oregon-state-university-apply-by-november-15-2019/" rel="alternate" type="text/html"/>
    <title>Faculty at Oregon State University (apply by November 15, 2019)</title>
    <summary>The School of Electrical Engineering and Computer Science at Oregon State University invites applications for several full-time, nine-month, tenure-track faculty positions to begin in Fall 2020. Candidates with a strong research record in the following areas of Computer Science will be considered: Software Engineering, Programming Languages, Data-intensive Systems, or Theory. Website: http://eecs.oregonstate.edu/prospective-faculty/current-job-openings#cs Email: jonathan.rich@oregonstate.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The School of Electrical Engineering and Computer Science at Oregon State University invites applications for several full-time, nine-month, tenure-track faculty positions to begin in Fall 2020. Candidates with a strong research record in the following areas of Computer Science will be considered: Software Engineering, Programming Languages, Data-intensive Systems, or Theory.</p>
<p>Website: <a href="http://eecs.oregonstate.edu/prospective-faculty/current-job-openings#cs">http://eecs.oregonstate.edu/prospective-faculty/current-job-openings#cs</a><br/>
Email: jonathan.rich@oregonstate.edu</p></div>
    </content>
    <updated>2019-11-04T17:34:40Z</updated>
    <published>2019-11-04T17:34:40Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-06T01:20:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/149</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/149" rel="alternate" type="text/html"/>
    <title>TR19-149 |  Log-Seed Pseudorandom Generators via Iterated Restrictions | 

	Dean Doron, 

	William Hoza, 

	Pooya Hatami</title>
    <summary>There are only a few known general approaches for constructing explicit pseudorandom generators (PRGs). The ``iterated restrictions'' approach, pioneered by Ajtai and Wigderson [AW89], has provided PRGs with seed length $\mathrm{polylog} n$ or even $\tilde{O}(\log n)$ for several restricted models of computation. Can this approach ever achieve the optimal seed length of $O(\log n)$?

In this work, we answer this question in the affirmative. Using the iterated restrictions approach, we construct an explicit PRG for read-once depth-$2$ $\mathbf{AC}^0[\oplus]$ formulas with seed length $O(\log n) + \tilde{O}(\log(1/\epsilon))$. In particular, our PRG achieves optimal seed length $O(\log n)$ with near-optimal error $\epsilon = \exp(-\tilde{\Omega} (\log n))$. Even for constant error, the best prior PRG for this model (which includes read-once CNFs and read-once $\mathbb{F}_2$-polynomials) has seed length $\Theta(\log n \cdot (\log \log n)^2)$ [Lee19]. 

A key step in the analysis of our PRG is a tail bound for subset-wise symmetric polynomials, a generalization of elementary symmetric polynomials. Like elementary symmetric polynomials, subset-wise symmetric polynomials provide a way to organize the expansion of $\prod_{i = 1}^m (1 + y_i)$. Elementary symmetric polynomials simply organize the terms by degree, i.e., they keep track of the number of variables participating in each monomial. Subset-wise symmetric polynomials keep track of more data: for a fixed partition of $[m]$, they keep track of the number of variables from each subset participating in each monomial. Our tail bound extends prior work by Gopalan and Yehudayoff [GY14] on elementary symmetric polynomials.</summary>
    <updated>2019-11-04T13:16:42Z</updated>
    <published>2019-11-04T13:16:42Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-11-06T01:20:34Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6412925669087119335</id>
    <link href="https://blog.computationalcomplexity.org/feeds/6412925669087119335/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/11/limits-of-using-web-for-info-self.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6412925669087119335" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6412925669087119335" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/11/limits-of-using-web-for-info-self.html" rel="alternate" type="text/html"/>
    <title>Limits of using the web for info- self-reference</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">(I wrote this a while back so when I say `I Googled BLAH' I meant back then. It is prob different now.)<br/>
<br/>
While the web is a <i>wonderful</i> to find things out there are times when it doesn't quite work.  <br/>
<ol>
<li> An old blog of Scott Aaronson's  had as part of its title <a href="http://scottaaronson.com/blog/?p=240">a Woitian Link</a>. Wanting to find out what <i>a Woitian Link</i> is but not wanting to bother Scott (he's busy enough making comments on Shtetl-Optimized) I went to google and typed in <i>"Woitian Link"</i>. The ONLY hits I got back were to Scotts blog. I finally had to email Scott. He told me that it was referring to the blog <a href="http://www.math.columbia.edu/~woit/wordpress">not even wrong</a> by Peter Woit which often has links that... Well, Scott never told me quite what it was but I'll go there myself and try to figure it out.<br/>
</li>
<li> An old blog of mine was <a href="http://weblog.fortnow.com/2007/05/man-who-loved-algorithms.html">the man who loved algorithms</a>. Part of my blog said that I thought the man would be Knuth but it was not. (It was Thomas Kailath) One of the commenters said that it couldn't be Knuth since he was still alive. This made me want to check the original article to see if  Thomas Kailath, is also still alive (he is). I didn't have the issue with me at the time so I typed "the man who loved algorithms" into google. The first page of hits all refered to my posting.  Eventually I found one to verify that yes, indeed, he was still alive.<br/>
</li>
<li> Donald Knuth VOLUME FOUR was originally published in a series of fascicile's. Whats a fascicle? Here the web was helpful- Wikipedia said it was a book that comes out in short pieces, the pieces of which are called `fascicle'. They gave only one example: <i>Donald Knuth's Volume 4 will be coming out in Fascicle.</i> Still, they DID tell me what I want to know. (Note- this was a while back, they have since removed that comment.) For most things the web is great. But for some more obscure things, better off asking someone who knows stuff. </li>
</ol>
<div>
Do you have experiences where you ask the web for a question and you end up in a circle?</div></div>
    </content>
    <updated>2019-11-04T06:04:00Z</updated>
    <published>2019-11-04T06:04:00Z</published>
    <author>
      <name>Unknown</name>
      <email>noreply@blogger.com</email>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-11-05T11:33:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1213</id>
    <link href="https://ptreview.sublinear.info/?p=1213" rel="alternate" type="text/html"/>
    <title>News for October 2019</title>
    <summary>Last month was a lean month, with only three papers: one on direct product testing, one on finding forbidden patterns in a sequence, and one (an update of a paper which we had missed in the Spring) on quantum distribution testing. Direct sum testing – the general case, by Irit Dinur and Konstantin Golubev (ECCC). […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Last month was a lean month, with only three papers: one on direct product testing,  one on finding forbidden patterns in a sequence, and one (an update of a paper which we had missed in the Spring) on quantum distribution testing.</p>



<p style="text-align: left;"><strong>Direct sum testing – the general case</strong>, by Irit Dinur and Konstantin Golubev (<a href="https://eccc.weizmann.ac.il/report/2019/139/">ECCC</a>). Say a function \(f\colon \prod_{i=1}^d [n_i] \to \mathbb{F}_2\) is a direct product if it can be factored as \(f(x_1,\dots,x_d)=\sum_{i=1}^d f_i(x_i)\), where \(f_i\colon [n_i]\to\mathbb{F}_2\).<br/>This paper provides a 4-query tester (i.e., a <em>proximity oblivious tester</em> (POT)) for the direct product property, reminiscent of (and relying on) the BLR linearity test: specifically, draw two subsets \(S,T\subseteq [d]\) and two inputs \(x,y\in \prod_{i=1}^d [n_i]\) u.a.r., and accept iff<br/>\(f(x)+f(x_Sy)+f(x_Ty)+f(x_{S\Delta T}y) = 0\,.\)<br/>The main theorem of the paper is to show that the probability that this simple test rejects is lower bounded (up to a constant factor) by the distance of \(f\) to direct-product-ness. (The authors also provide a different POT making \(d+1\) queries, but with a simpler analysis.)</p>



<p><strong>Finding monotone patterns in sublinear time</strong>, by Omri Ben-Eliezer, Clément Canonne, Shoham Letzter, and Erik Waingarten (<a href="https://eccc.weizmann.ac.il/report/2019/134/">ECCC</a>). Given a function \(f\colon [n]\to\mathbb{R}\), a <em>monotone subsequence</em> of size \(k\) is a \(k\)-tuple of indices \(i_1 &lt; \dots &lt;i_k\) such that \(f(i_j) &lt; f(i_{j+1})\) for all \(j\). This work considers (non-adaptive) one-sided testing of monotone-subsequence-freeness, or, equivalently, the task of <em>finding</em> such a monotone subsequence in a function promised to contain many of them. (This, in particular, generalizes the problem of one-sided monotonicity testing, which is the case \(k=2\).) The main result is a full characterization of the query complexity of this question (for constant \(k\)): strange as the exponent may seem, \(\Theta_\varepsilon( (\log n)^{\lfloor \log_2 k\rfloor} )\) queries are necessary and sufficient. The  proof relies on a structural dichotomy result, stating that any  far-from-free sequence either contains “easy to find” increasing  subsequences with increasing gaps between the elements, or has a specific hierarchical structure.</p>



<p><strong>Quantum Closeness Testing: A Streaming Algorithm and Applications</strong>, by Nengkun Yu (<a href="https://arxiv.org/abs/1904.03218">arXiv</a>). This paper is concerned with quantum distribution testing in the <em>local</em> model, which only allows a very restricted (albeit, as the author argues, more natural and easier to implement) type of measurements, and is particularly well-suited to a streaming setting. The main contribution of this paper is to show a connection to <em>classical</em> distribution testing, allowing one to obtain quantum distribution testing upper bounds from their classical distribution testing counterparts. In more detail, the paper shows that, from local measurements to two \(d\)-dimensional quantum states \(\rho,\sigma\), one can provide access to two classical distributions \(p,q\) on \(\approx d^2\) elements such that (i) \(\| p-q\|_2 \approx \|\rho-\sigma\|_2/d\) and (ii) \(\| p\|_2,\| q\|_2 = O(1/d)\).<br/>Using this connection, the paper proceeds to establish a variety of upper bounds for testing several distribution properties in the local quantum model.</p></div>
    </content>
    <updated>2019-11-03T22:28:23Z</updated>
    <published>2019-11-03T22:28:23Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Clement Canonne</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-11-05T23:54:20Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-6347857345982876641</id>
    <link href="http://processalgebra.blogspot.com/feeds/6347857345982876641/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=6347857345982876641" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6347857345982876641" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6347857345982876641" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/11/call-for-opinions-length-of-papes-in.html" rel="alternate" type="text/html"/>
    <title>Call for opinions: Length of papes in conference proceedings in TCS</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">As current chair of the editorial board of <a href="https://www.dagstuhl.de/publikationen/lipics/">LIPIcs, Leibniz International Proceedings in Informatics</a>, I have been looking at some data about the length of the papers published in the series. The average length of the articles published in LIPIcs in 2019 so far is of 15.8 pages, including front matter and bibliography. However, three of the published papers are over 40 pages and three conferences have an average article length above 20 pages (22,  23.9 and 28.4, respectively).<br/><br/>I have seen that some conferences in TCS have no limit on the length of the submitted papers. A colleague whose opinions I hold in high esteem wrote to me saying: <br/><blockquote>Some people in the "conference name removed" community strongly feel there should be no page limit. My opinion may not be as strong as some, but I believe these people have a point. </blockquote><blockquote>Whether we like it or not, most papers in the TOC community only appear in conferences. Many of those conferences have no page limit for submissions, and encourage authors to include all proofs while making sure that the key ideas are presented in the first 10 pages or so. Scientific progress is hindered when authors are then forced to take out parts of their writeups for the conference proceedings in order for their papers to fit within the page limits. One may wish that they'd publish a full version of their paper in a journal subsequently, but most of them won't bother. The net effect is that there is no actual paper with all the details, which is no good. </blockquote>I share the point made in the last sentence, but I am somewhat bothered by the fact that full versions of papers in TCS are increasingly not being submitted to journals. I am probably very old fashioned, but I feel that it is desirable to see our published results vetted by a journal-strength review process. I still view conferences as means for the rapid dissemination of results and as a meeting point for their community of reference, and I consider journals as the media for final archival publication of mature pieces of research. However, with my LIPIcs EB chair hat on and out of personal interest, I am keen to hear your opinion on whether it is good for the TCS community to publish only in conferences and to publish conference papers without page limits, bearing in mind that, quoting from the <a href="http://focs2019.cs.jhu.edu/cfp/">FOCS 2019 call for papers</a>:<br/><blockquote>Although there is no bound on the length of a submission, material other than the title page, references, and the first ten pages will be read at the committee’s discretion.  </blockquote>I'd be grateful if you could post your thoughts on this matter in the comment section. Let's focus on what is best for the dissemination of science, even though long articles are more expensive than those whose average length is around 15 pages.<br/><br/>I look forward to hearing your opinions. Thanks in advance!<br/><br/></div>
    </content>
    <updated>2019-11-03T12:30:00Z</updated>
    <published>2019-11-03T12:30:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-11-03T18:04:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/148</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/148" rel="alternate" type="text/html"/>
    <title>TR19-148 |  Simultaneous Max-Cut is harder to approximate than Max-Cut | 

	Amey Bhangale, 

	Subhash Khot</title>
    <summary>A systematic study of simultaneous optimization of constraint satisfaction problems was initiated in [BKS15]. The simplest such problem is the simultaneous Max-Cut. [BKKST18] gave a $.878$-minimum approximation algorithm for simultaneous Max-Cut which is {\em almost optimal} assuming the Unique Games Conjecture (UGC). For a single instance Max-Cut, [GW95] gave an $\alpha_{GW}$-approximation algorithm where $\alpha_{GW}\approx .87856720...$ which is {\em optimal} assuming the UGC.

It was left open whether one can achieve an $\alpha_{GW}$-minimum approximation algorithm for simultaneous Max-Cut. We answer the question by showing that there exists an absolute constant $\varepsilon_0\geq 10^{-5}$ such that it is NP-hard to get an $(\alpha_{GW}- \varepsilon_0)$-minimum approximation for simultaneous Max-Cut assuming the UGC.</summary>
    <updated>2019-11-03T09:17:37Z</updated>
    <published>2019-11-03T09:17:37Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-11-06T01:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/03/associate-professor-in-algorithms-at-university-in-bergen-norway-apply-by-january-31-2020/</id>
    <link href="https://cstheory-jobs.org/2019/11/03/associate-professor-in-algorithms-at-university-in-bergen-norway-apply-by-january-31-2020/" rel="alternate" type="text/html"/>
    <title>Associate professor in Algorithms at University in Bergen, Norway (apply by January 31, 2020)</title>
    <summary>There is a vacancy for an associate professor at the Department of Informatics, University of Bergen, in Algorithms. See the link below for more details Website: https://www.jobbnorge.no/en/available-jobs/job/177203/associate-professor-in-algorithms Email: fedor.fomin@uib.no</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>There is a vacancy for an associate professor at the Department of Informatics, University of Bergen, in Algorithms. See the link below for more details</p>
<p>Website: <a href="https://www.jobbnorge.no/en/available-jobs/job/177203/associate-professor-in-algorithms">https://www.jobbnorge.no/en/available-jobs/job/177203/associate-professor-in-algorithms</a><br/>
Email: fedor.fomin@uib.no</p></div>
    </content>
    <updated>2019-11-03T08:58:20Z</updated>
    <published>2019-11-03T08:58:20Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-06T01:20:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/147</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/147" rel="alternate" type="text/html"/>
    <title>TR19-147 |  Capacity-Approaching Deterministic Interactive Coding Schemes Against Adversarial Errors | 

	Gil Cohen, 

	Shahar Samocha</title>
    <summary>We devise a deterministic interactive coding scheme with rate $1-O(\sqrt{\varepsilon\log(1/\varepsilon)})$ against $\varepsilon$-fraction of adversarial errors. The rate we obtain is tight by a result of Kol and Raz (STOC 2013). Prior to this work, deterministic coding schemes for any constant fraction $\varepsilon&gt;0$ of adversarial errors could obtain rate no larger than $1/2$. Achieving higher rate was obtained either using probabilistic coding schemes by Haeupler (FOCS 2014) or otherwise assumed weaker error models such as binary symmetric channels, erasure channels or feedback channels.</summary>
    <updated>2019-11-03T07:09:44Z</updated>
    <published>2019-11-03T07:09:44Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-11-06T01:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/03/tenure-track-faculty-at-university-of-california-davis-apply-by-november-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/03/tenure-track-faculty-at-university-of-california-davis-apply-by-november-15-2019/" rel="alternate" type="text/html"/>
    <title>Tenure track faculty at University of California, Davis (apply by November 15, 2019)</title>
    <summary>The Department of Mathematics at UC Davis invites applications for one Assistant Professor (tenure-track) faculty position. This position is in the area of the mathematics of data science. Minimum qualifications for the position include a Ph.D. or its equivalent in the Mathematical Sciences or a related field and demonstrated potential for performance in teaching and […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Mathematics at UC Davis invites applications for one Assistant Professor (tenure-track) faculty position. This position is in the area of the mathematics of data science. Minimum qualifications for the position include a Ph.D. or its equivalent in the Mathematical Sciences or a related field and demonstrated potential for performance in teaching and research.</p>
<p>Website: <a href="https://recruit.ucdavis.edu/JPF02958">https://recruit.ucdavis.edu/JPF02958</a><br/>
Email: lrademac@ucdavis.edu</p></div>
    </content>
    <updated>2019-11-03T05:22:30Z</updated>
    <published>2019-11-03T05:22:30Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-06T01:20:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/02/faculty-at-dartmouth-apply-by-december-31-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/02/faculty-at-dartmouth-apply-by-december-31-2019/" rel="alternate" type="text/html"/>
    <title>Faculty at Dartmouth (apply by December 31, 2019)</title>
    <summary>The Department of Computer Science at Dartmouth is conducting a search for three tenure track positions. One of the focus areas is Algorithms. Please see the link for more details. Website: https://web.cs.dartmouth.edu/news-events/dartmouth-cs-hiring-3-tenure-track-faculty-lines Email: facsearch-2019@cs.dartmouth.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at Dartmouth is conducting a search for three tenure track positions. One of the focus areas is Algorithms. Please see the link for more details.</p>
<p>Website: <a href="https://web.cs.dartmouth.edu/news-events/dartmouth-cs-hiring-3-tenure-track-faculty-lines">https://web.cs.dartmouth.edu/news-events/dartmouth-cs-hiring-3-tenure-track-faculty-lines</a><br/>
Email: facsearch-2019@cs.dartmouth.edu</p></div>
    </content>
    <updated>2019-11-02T01:19:48Z</updated>
    <published>2019-11-02T01:19:48Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-06T01:20:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/01/post-doctoral-positions-at-tata-institute-of-fundamental-research-tifr-apply-by-january-31-2020/</id>
    <link href="https://cstheory-jobs.org/2019/11/01/post-doctoral-positions-at-tata-institute-of-fundamental-research-tifr-apply-by-january-31-2020/" rel="alternate" type="text/html"/>
    <title>Post-doctoral Positions at Tata Institute of Fundamental Research (TIFR) (apply by January 31, 2020)</title>
    <summary>MULTIPLE POSTDOCTORAL POSITIONS , TATA INSTITUTE OF FUNDAMENTAL RESEARCH, Mumbai The School of Technology and Computer Science, TIFR Mumbai invites applications for visiting fellow positions. Areas include applied probability, automata, complexity, communications, control, formal verification, information theory, logic, machine learning and quantum computing. Check members’ webpages for info. Website: https://www.tcs.tifr.res.in/ Email: facultyapp@tifr.res.in</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>MULTIPLE POSTDOCTORAL POSITIONS , TATA INSTITUTE OF FUNDAMENTAL RESEARCH, Mumbai</p>
<p>The School of Technology and Computer Science, TIFR Mumbai invites applications for visiting fellow positions. Areas include applied probability, automata, complexity, communications, control, formal verification, information theory, logic, machine learning and quantum computing. Check members’ webpages for info.</p>
<p>Website: <a href="https://www.tcs.tifr.res.in/">https://www.tcs.tifr.res.in/</a><br/>
Email: facultyapp@tifr.res.in</p></div>
    </content>
    <updated>2019-11-01T10:20:38Z</updated>
    <published>2019-11-01T10:20:38Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-06T01:20:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16354</id>
    <link href="https://rjlipton.wordpress.com/2019/10/31/hobgoblins-in-our-equations/" rel="alternate" type="text/html"/>
    <title>Hobgoblins in Our Equations</title>
    <summary>With consequences for physics Britannica source Paul Painlevé was a French mathematician who specialized in classical mechanics. He is known for a conjecture in 1895 about anomalies in Isaac Newton’s equations that was proved in 1988. Tonight, Ken and I celebrate Halloween with some mathematical horrors that may have real physical consequences. Painlevé is also […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>With consequences for physics</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/10/paul-painleve.jpg"><img alt="" class="alignright size-thumbnail wp-image-16356" height="150" src="https://rjlipton.files.wordpress.com/2019/10/paul-painleve.jpg?w=118&amp;h=150" width="118"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><i>Britannica</i> <a href="https://www.britannica.com/biography/Paul-Painleve">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Paul Painlevé was a French mathematician who specialized in classical mechanics. He is known for a conjecture in 1895 about anomalies in Isaac Newton’s equations that was proved in 1988.</p>
<p>
Tonight, Ken and I celebrate Halloween with some mathematical horrors that may have real physical consequences.</p>
<p>
Painlevé is also known for having been Prime Minister of France for two short stints in 1917 and 1925. He was also Minister of War under President Raymond Poincaré, a cousin of Henri Poincaré. He was the first Frenchman in powered flight—alongside Wilbur Wright in 1908—and at the end of his life headed the French Air Force. </p>
<p>
A basic fact about Newtonian gravity is that the gravitational potential energy of two point masses <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> and <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> is proportional to </p>
<p align="center"><img alt="\displaystyle  -\frac{mM}{R}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++-%5Cfrac%7BmM%7D%7BR%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  -\frac{mM}{R}, "/></p>
<p>where <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> is the distance between them. We usually think of how gravity becomes weaker as <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> grows but when <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> is tiny it becomes quite strong. Since the potential is negative, it is possible for an individual particle in a finite <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-body system to accelerate to arbitrary speed without violating the conservation of energy. But can it happen in a finite amount of time—and without <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> actually becoming zero in a collision? </p>
<p>
Painlevé proved a ‘no’ answer for <img alt="{n = 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 3}"/> but suspected ‘yes’ for <img alt="{n \geq 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cgeq+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \geq 4}"/>. Zhihong Xia proved in 1988 it can happen for <img alt="{n = 5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 5}"/>, extending earlier advances by his thesis advisor, Donald Saari. The case <img alt="{n = 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 4}"/> is still open; in all cases, the initial conditions for it to happen form a measure-zero subset of the configuration space. </p>
<p>
The difference from <img alt="{n = 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 3}"/> is shown by this diagram from their 1995 <em>AMS Notices</em> <a href="http://copernico.dm.unipi.it/~gronchi/PDF/didattica/2006_07/mecc_sup/inf.pdf">paper</a>, which has a greatly understandable telling of the whole story. We, however, envision a fantasy story about what could have happened much earlier.</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2019/10/mass.jpg"><img alt="" class="aligncenter size-medium wp-image-16358" height="159" src="https://rjlipton.files.wordpress.com/2019/10/mass.jpg?w=300&amp;h=159" width="300"/></a></p>
<p>
</p><p/><h2> A Fantasy </h2><p/>
<p/><p>
We want to imagine that Xia’s result was proved not near the end of the 20th century but near the start—in particular, before Albert Einstein’s creation of General Relativity, but after Special Relativity. Say the result was obtained in 1908 by Painlevé after his flight with Wright. That same year, Hugo von Zeipold proved a startling consequence of Painlevé’s conjecture, which we now know to be a theorem:</p>
<blockquote><p><b>Theorem 1</b> <em> Under Newtonian gravity, a <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>-body set of point masses can eject a particle to infinity in finite time. </em>
</p></blockquote>
<p/><p>
That is, without collisions, a Newtonian <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-body problem of point masses can create separations <img alt="{R'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R'}"/> between particles that grow to infinity within a finite time. Saari and Xia say that the effect can be partially seen if you do the following:</p>
<blockquote><p><b> </b> <em> Place a tennis ball on top of a basketball and drop the pair from chest height. The tennis ball rebound is pretty dramatic—enough so that it should be done outside. </em>
</p></blockquote>
<p/><p>
Ken tried it and it works. It does not work so well if the tennis ball is replaced by a piece of Halloween candy. If the basketball is replaced by a pumpkin, it definitely will not work.</p>
<p>
We know already, however, from Einstein’s theory of special relativity that it cannot work. We would have an instant before the singular time at which the point mass has just passed the speed of light. At that time it has acquired infinite energy according to special relativity, but cannot have withdrawn it from the potential by then. </p>
<p>
In 1908 this would have been an internal indication that Newton’s theory of gravity must break down. There were of course external indicators, such as the theory’s incorrect prediction of the orbit of Mercury. Maybe internal ones were known, but this seems most glaring in retrospect. Are we right in this interpretation? The result by Xia is shocking enough as it stands, and makes us wonder what other surprises lurk in equations.</p>
<p>
</p><p/><h2> It Could End With a Bang </h2><p/>
<p/><p>
Other possibilities of singularities happening within finite time have not been ruled out by any physical theories. The New York Times Magazine in July 2015 ran a <a href="https://www.nytimes.com/2015/07/26/magazine/the-singular-mind-of-terry-tao.html">profile</a> titled “The Singular Mind of Terry Tao” with a great opening sentence:</p>
<blockquote><p><b> </b> <em> This April, as undergraduates strolled along the street outside his modest office on the campus of the University of California, Los Angeles, the mathematician Terence Tao mused about the possibility that water could spontaneously explode. </em>
</p></blockquote>
<p/><p>
Indeed, Tao <a href="https://terrytao.wordpress.com/2014/02/04/finite-time-blowup-for-an-averaged-three-dimensional-navier-stokes-equation/">proved</a> it can happen under a plausible modification of the Navier-Stokes equations of fluid dynamics. He writes there:</p>
<blockquote><p><b> </b> <em> Intriguingly, the method of proof in fact hints at a possible route to establishing blowup for the true Navier-Stokes equations, which I am now increasingly inclined to believe is the case (albeit for a very small set of initial data). </em>
</p></blockquote>
<p/><p>
As with Painlevé’s conjecture—Xia’s theorem—the point would be not that the initial conditions could happen with any perceptible probability, but that our world is capable of their happening at all. At least, that is, with the equations by which we describe our world. Our own <a href="https://rjlipton.wordpress.com/2015/01/04/mathematics-its-about-the-future/">mention</a> at the start of 2015 alluded to the possibility of Tao’s blowup applying to fluid-like fields in cosmological theories.</p>
<p>
Just last week, a <a href="https://www.forbes.com/sites/startswithabang/2019/10/18/dark-matters-biggest-problem-might-simply-be-a-numerical-error/#167c398d8979">column</a> on the <a href="https://www.forbes.com/sites/startswithabang/">Starts With a Bang</a> blog alerted us to an issue with equations that could be skewing cosmological theories today. The blog is written by Ethan Siegel for <em>Forbes</em> and its items are linked regularly on <a href="https://www.realclearscience.com/">RealClear Science</a>. Siegel draws an analogy to a phenomenon with Fourier series that feeds into things Dick and I (Ken writing this part) have already been thinking about. Things used all the time in theory…</p>
<p>
</p><p/><h2> Hobgoblins You Can Hear </h2><p/>
<p/><p>
The Fourier phenomenon is <a href="https://en.wikipedia.org/wiki/Gibbs_phenomenon">named</a> for the American physicist Josiah Gibbs, but Gibbs was not the original discoverer. We could add this to our old <a href="https://rjlipton.wordpress.com/2011/04/08/why-is-everything-named-after-gauss/">post</a> on a <a href="https://en.wikipedia.org/wiki/Stigler's_law_of_eponymy">law</a> named for Stephen Stigler, who did not discover it, that no scientific law is named for its original discoverer. The first discoverer of the Gibbs Phenomenon was—evidently—Henry Wilbraham in 1848. Through the magic of the Internet we can convey it by lifting Wilbraham’s original figure straight from his <a href="https://books.google.com/books?id=JrQ4AAAAMAAJ&amp;pg=PA198#v=onepage&amp;q&amp;f=false">paper</a>:</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2019/10/wilbrahamfigure.png"><img alt="" class="aligncenter wp-image-16359" height="385" src="https://rjlipton.files.wordpress.com/2019/10/wilbrahamfigure.png?w=365&amp;h=385" width="365"/></a></p>
<p>
What this shows is the convergence of a sum of sine waves to a square wave. The convergence is pointwise except at the jump discontinuities <img alt="{x = t\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%3D+t%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x = t\pi}"/>, but it is not uniform. The <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/>-values do not converge on any interval crossing <img alt="{t\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t\pi}"/> but instead rise about <img alt="{18\%}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B18%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{18\%}"/> above the square wave function value <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> in the vicinity of <img alt="{t\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t\pi}"/>, no matter how many terms are summed in the approximations <img alt="{f_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_n}"/>. Wilbraham’s middle drawing depicts this in finer detail than any other rendering I have found. The persistent overshoot is physically real—it is the cause of <a href="https://en.wikipedia.org/wiki/Ringing_artifacts">ringing</a> artifacts in signal processing.</p>
<p>
Now the convergence does satisfy a criterion of <b><img alt="{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon}"/>-approximation</b> of a function <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> that we use all the time in theory: for any <img alt="{\epsilon &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon &gt; 0}"/> and large enough <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, <img alt="{|f_n(x) - f(x)| &lt; \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cf_n%28x%29+-+f%28x%29%7C+%3C+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|f_n(x) - f(x)| &lt; \epsilon}"/> except for an <img alt="{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon}"/> fraction of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> in the domain. This kind of convergence is used internally in the proofs of quantum algorithms for linear algebra which we recently <a href="https://rjlipton.wordpress.com/2019/09/26/quantum-switch-em/">discussed</a>. If the value <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> is explicitly what you’re after, this is fine. But if you use the value only implicitly while composing the approximation with some other function <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/>, you must beware that the compositions <img alt="{g_n = g\circ f_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg_n+%3D+g%5Ccirc+f_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g_n = g\circ f_n}"/> are not thrown off in a constant way by the overshoots.</p>
<p>
</p><p/><h2> Dark Matter in Shadows? </h2><p/>
<p/><p>
Siegel draws attention to what is alleged as something similar actually happening to current physical theories that use a well-known class of algorithmic simulations. The details are in a new <a href="https://arxiv.org/abs/1808.03088v2">paper</a> by Anton Baushev and Sergey Pilipenko, titled “The central cusps in dark matter halos: fact or fiction?” To show the relation between this and the opening example in this post, we need only quote the paper (page 2)—</p>
<blockquote><p><b> </b> <em> However, the present state-of-art of <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{N}"/>-body simulation tests … can hardly be named adequate. The commonly-used criterion of the convergence of <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{N}"/>-body simulations in the halo center is solely the density profile stability [per which] the central cusp (close to <img alt="{\rho \propto r^{-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho+%5Cpropto+r%5E%7B-1%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\rho \propto r^{-1}}"/>) is formed quite rapidly (<img alt="{t &lt; \tau_r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%3C+%5Ctau_r%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{t &lt; \tau_r}"/>). </em>
</p></blockquote>
<p/><p>
—and then quote Siegel’s own description of the core-cusp problem and the allegation:</p>
<blockquote><p><b> </b> <em> In theory, matter should fall into a gravitationally bound structure and undergo what’s known as violent relaxation, where a large number of interactions cause the heaviest-mass objects to fall towards the center (becoming more tightly bound) while the lower-mass ones get exiled to the outskirts (becoming more loosely bound) and can even get ejected entirely. </em></p><em>
</em><p><em>
Since similar phenomena to the expectations of violent relaxation were seen in the simulations, and all the different simulations had these features, we assumed that they were representative of real physics. However, it’s also possible that they don’t represent real physics, but rather represent a numerical artifact inherent to the simulation itself. </em>
</p></blockquote>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Is all this real physics? Or is it artifacts showing that current theories and/or algorithms are flawed? Whichever is the truth, our equations have tricks that may not lead to treats.</p>
<p>
For a relevant postscript, Painlevé did not abandon physics when he rose in politics. In 1921, he <a href="https://astromontgeron.fr/Painleve-article-english.pdf">effectively</a> <a href="https://en.wikipedia.org/wiki/Gullstrand-Painleve_coordinates">removed</a> an apparent singularity at the event horizons of black holes in general relativity. He and colleagues <a href="https://astromontgeron.fr/Painleve-article-english.pdf">discussed</a> this with Einstein the following year, but apparently not the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-body conjecture. How far are we right in our interpretation that the (proved) conjecture plus special relativity suffices to disprove Newtonian gravity by itself?</p>
<p/></font></font></div>
    </content>
    <updated>2019-11-01T03:21:51Z</updated>
    <published>2019-11-01T03:21:51Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Results"/>
    <category term="Anton Baushev"/>
    <category term="approximation"/>
    <category term="Donald Saari"/>
    <category term="dynamics"/>
    <category term="Ethan Siegel"/>
    <category term="Halloween"/>
    <category term="n-body problem"/>
    <category term="Paul Painleve"/>
    <category term="Physics"/>
    <category term="relativity"/>
    <category term="Sergey Pilipenko"/>
    <category term="singularity"/>
    <category term="Terence Tao"/>
    <category term="Zhihong Xia"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-11-06T01:20:43Z</updated>
    </source>
  </entry>
</feed>
