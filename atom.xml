<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-07-21T00:42:23Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4912</id>
    <link href="https://www.scottaaronson.com/blog/?p=4912" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4912#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4912" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Is this blog obsolete?</title>
    <summary xml:lang="en-US">Longtime friend-of-the-blog Michael Nielsen, formerly a quantum computing theorist and now an independent thinker about science and AI and learning, posted the following exchange with the astounding GPT-3 text generator / chatbot: Q: Is it possible to use quantum computers to solve NP-complete problems in polynomial time?A: It is not possible to use quantum computers […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Longtime friend-of-the-blog <a href="http://michaelnielsen.org/">Michael Nielsen</a>, formerly a quantum computing theorist and now an independent thinker about science and AI and learning, posted the following <a href="https://twitter.com/michael_nielsen/status/1284988349418098688">exchange</a> with the astounding <a href="https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/">GPT-3</a> text generator / chatbot:</p>



<blockquote class="wp-block-quote"><p>Q: Is it possible to use quantum computers to solve NP-complete problems in polynomial time?<br/>A: It is not possible to use quantum computers to solve NP-complete problems in polynomial time.</p><p>Q: Why not?<br/>A: Because NP-complete problems are not in BQP.</p><p>Q: You’ve just restated your earlier assertion!  What I’d like is to understand the underlying reason why not!<br/>A: I’m sorry, but I don’t have time to explain the underlying reason why not.</p><p>Q: No offence, but this seems really bogus.  I don’t believe you understand the reason why!<br/>A: I’m sorry, but I don’t have time to explain the underlying reason why not.</p></blockquote>



<p>(And then there are a few more rounds of the AI not having time to “explain the underlying reason why not.”)</p>



<p>This is, like, 80% of the way to replacing <em>Shtetl-Optimized</em>!</p>



<p>For much more discussion of GPT-3 and its implications, and samples of its output, see for example the <a href="https://www.reddit.com/r/slatestarcodex/">SSC subreddit</a>.  At the moment, as far as I can tell, the closest a person off the street can easily come to experimenting with GPT-3 themselves is using a website called <a href="https://play.aidungeon.io/">AI Dungeon</a>.</p>



<p>And yes, as many have already remarked, this is clearly the <a href="https://en.wikipedia.org/wiki/Altair_8800">MITS Altair</a> of text-generating AI, an amusing toy that’s also the start of something that will change the world.</p></div>
    </content>
    <updated>2020-07-21T00:16:18Z</updated>
    <published>2020-07-21T00:16:18Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-07-21T00:16:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.09116</id>
    <link href="http://arxiv.org/abs/2007.09116" rel="alternate" type="text/html"/>
    <title>The Combinatorial Santa Claus Problem or: How to Find Good Matchings in Non-Uniform Hypergraphs</title>
    <feedworld_mtime>1595289600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Etienne Bamas, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garg:Paritosh.html">Paritosh Garg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rohwedder:Lars.html">Lars Rohwedder</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.09116">PDF</a><br/><b>Abstract: </b>We consider hypergraphs on vertices $P\cup R$ where each hyperedge contains
exactly one vertex in $P$. Our goal is to select a matching that covers all of
$P$, but we allow each selected hyperedge to drop all but an
$(1/\alpha)$-fraction of its intersection with $R$ (thus relaxing the matching
constraint). Here $\alpha$ is to be minimized. We dub this problem the
Combinatorial Santa Claus problem, since we show in this paper that this
problem and the Santa Claus problem are almost equivalent in terms of their
approximability.
</p>
<p>The non-trivial observation that any uniform regular hypergraph admits a
relaxed matching for $\alpha = O(1)$ was a major step in obtaining a constant
approximation rate for a special case of the Santa Claus problem, which
received great attention in literature. It is natural to ask if the uniformity
condition can be omitted. Our main result is that every (non-uniform) regular
hypergraph admits a relaxed matching for $\alpha = O(\log\log(|R|))$, when all
hyperedges are sufficiently large (a condition that is necessary). In
particular, this implies an $O(\log\log(|R|))$-approximation algorithm for the
Combinatorial Santa Claus problem with large hyperedges.
</p></div>
    </summary>
    <updated>2020-07-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.09065</id>
    <link href="http://arxiv.org/abs/2007.09065" rel="alternate" type="text/html"/>
    <title>Improved Approximation Factor for Adaptive Influence Maximization via Simple Greedy Strategies</title>
    <feedworld_mtime>1595289600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Gianlorenzo D'Angelo, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Poddar:Debashmita.html">Debashmita Poddar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vinci:Cosimo.html">Cosimo Vinci</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.09065">PDF</a><br/><b>Abstract: </b>In the adaptive influence maximization problem, we are given a social network
and a budget $k$, and we iteratively select $k$ nodes, called seeds, in order
to maximize the expected number of nodes that are reached by an influence
cascade that they generate according to a stochastic model for influence
diffusion. Differently from the non-adaptive influence maximization problem,
where all the seeds must be selected beforehand, here nodes are selected
sequentially one by one, and the decision on the $i$th seed is based on the
observed cascade produced by the first $i-1$ seeds. We focus on the myopic
feedback model, in which we can only observe which neighbors of previously
selected seeds have been influenced and on the independent cascade model, where
each edge is associated with an independent probability of diffusing influence.
Previous works showed that the adaptivity gap is at most $4$, which implies
that the non-adaptive greedy algorithm guarantees an approximation factor of
$\frac{1}{4}\left(1-\frac{1}{e}\right)$ for the adaptive problem. In this
paper, we improve the bounds on both the adaptivity gap and on the
approximation factor. We directly analyze the approximation factor of the
non-adaptive greedy algorithm, without passing through the adaptivity gap, and
show that it is at least $\frac{1}{2}\left(1-\frac{1}{e}\right)$. Therefore,
the adaptivity gap is at most $\frac{2e}{e-1}\approx 3.164$. To prove these
bounds, we introduce a new approach to relate the greedy non-adaptive algorithm
to the adaptive optimum. The new approach does not rely on multi-linear
extensions or random walks on optimal decision trees, which are commonly used
techniques in the field. We believe that it is of independent interest and may
be used to analyze other adaptive optimization problems.
</p></div>
    </summary>
    <updated>2020-07-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.09018</id>
    <link href="http://arxiv.org/abs/2007.09018" rel="alternate" type="text/html"/>
    <title>Solving hard cut problems via flow-augmentation</title>
    <feedworld_mtime>1595289600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kim:Eun_Jung.html">Eun Jung Kim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kratsch:Stefan.html">Stefan Kratsch</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pilipczuk:Marcin.html">Marcin Pilipczuk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wahlstr=ouml=m:Magnus.html">Magnus Wahlström</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.09018">PDF</a><br/><b>Abstract: </b>We present a new technique for designing FPT algorithms for graph cut
problems in undirected graphs, which we call flow augmentation. Our technique
is applicable to problems that can be phrased as a search for an (edge)
$(s,t)$-cut of cardinality at most $k$ in an undirected graph $G$ with
designated terminals $s$ and $t$.
</p>
<p>More precisely, we consider problems where an (unknown) solution is a set $Z
\subseteq E(G)$ of size at most $k$ such that (1) in $G-Z$, $s$ and $t$ are in
distinct connected components, (2) every edge of $Z$ connects two distinct
connected components of $G-Z$, and (3) if we define the set $Z_{s,t} \subseteq
Z$ as these edges $e \in Z$ for which there exists an $(s,t)$-path $P_e$ with
$E(P_e) \cap Z = \{e\}$, then $Z_{s,t}$ separates $s$ from $t$. We prove that
in this scenario one can in randomized time $k^{O(1)} (|V(G)|+|E(G)|)$ add a
number of edges to the graph so that with $2^{-O(k \log k)}$ probability no
added edge connects two components of $G-Z$ and $Z_{s,t}$ becomes a minimum cut
between $s$ and $t$.
</p>
<p>We apply our method to obtain a randomized FPT algorithm for a notorious
"hard nut" graph cut problem we call Coupled Min-Cut. This problem emerges out
of the study of FPT algorithms for Min CSP problems, and was unamenable to
other techniques for parameterized algorithms in graph cut problems, such as
Randomized Contractions, Treewidth Reduction or Shadow Removal.
</p>
<p>To demonstrate the power of the approach, we consider more generally Min
SAT($\Gamma$), parameterized by the solution cost. We show that every problem
Min SAT($\Gamma$) is either (1) FPT, (2) W[1]-hard, or (3) able to express the
soft constraint $(u \to v)$, and thereby also the min-cut problem in directed
graphs. All the W[1]-hard cases were known or immediate, and the main new
result is an FPT algorithm for a generalization of Coupled Min-Cut.
</p></div>
    </summary>
    <updated>2020-07-21T00:36:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.08914</id>
    <link href="http://arxiv.org/abs/2007.08914" rel="alternate" type="text/html"/>
    <title>All-Pairs LCA in DAGs: Breaking through the $O(n^{2.5})$ barrier</title>
    <feedworld_mtime>1595289600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grandoni:Fabrizio.html">Fabrizio Grandoni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Italiano:Giuseppe_F=.html">Giuseppe F. Italiano</a>, Aleksander Łukasiewicz, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parotsidis:Nikos.html">Nikos Parotsidis</a>, Przemysław Uznański <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08914">PDF</a><br/><b>Abstract: </b>Let $G=(V,E)$ be an $n$-vertex directed acyclic graph (DAG). A lowest common
ancestor (LCA) of two vertices $u$ and $v$ is a common ancestor $w$ of $u$ and
$v$ such that no descendant of $w$ has the same property. In this paper, we
consider the problem of computing an LCA, if any, for all pairs of vertices in
a DAG. The fastest known algorithms for this problem exploit fast matrix
multiplication subroutines and have running times ranging from $O(n^{2.687})$
[Bender et al.~SODA'01] down to $O(n^{2.615})$ [Kowaluk and Lingas~ICALP'05]
and $O(n^{2.569})$ [Czumaj et al.~TCS'07]. Somewhat surprisingly, all those
bounds would still be $\Omega(n^{2.5})$ even if matrix multiplication could be
solved optimally (i.e., $\omega=2$). This appears to be an inherent barrier for
all the currently known approaches, which raises the natural question on
whether one could break through the $O(n^{2.5})$ barrier for this problem.
</p>
<p>In this paper, we answer this question affirmatively: in particular, we
present an $\tilde O(n^{2.447})$ ($\tilde O(n^{7/3})$ for $\omega=2$) algorithm
for finding an LCA for all pairs of vertices in a DAG, which represents the
first improvement on the running times for this problem in the last 13 years. A
key tool in our approach is a fast algorithm to partition the vertex set of the
transitive closure of $G$ into a collection of $O(\ell)$ chains and $O(n/\ell)$
antichains, for a given parameter $\ell$. As usual, a chain is a path while an
antichain is an independent set. We then find, for all pairs of vertices, a
\emph{candidate} LCA among the chain and antichain vertices, separately. The
first set is obtained via a reduction to min-max matrix multiplication. The
computation of the second set can be reduced to Boolean matrix multiplication
similarly to previous results on this problem. We finally combine the two
solutions together in a careful (non-obvious) manner.
</p></div>
    </summary>
    <updated>2020-07-21T00:26:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.08840</id>
    <link href="http://arxiv.org/abs/2007.08840" rel="alternate" type="text/html"/>
    <title>Adaptive Gradient Methods for Constrained Convex Optimization</title>
    <feedworld_mtime>1595289600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ene:Alina.html">Alina Ene</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nguyen:Huy_L=.html">Huy L. Nguyen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vladu:Adrian.html">Adrian Vladu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08840">PDF</a><br/><b>Abstract: </b>We provide new adaptive first-order methods for constrained convex
optimization. Our main algorithm AdaAGD+ is an accelerated method, which is
universal in the sense that it achieves nearly-optimal convergence rates for
both smooth and non-smooth functions, even when it only has access to
stochastic gradients. In addition, it does not require any prior knowledge on
how the objective function is parametrized, since it automatically adjusts its
per-coordinate learning rate. This can be seen as a truly accelerated AdaGrad
method for constrained optimization.
</p>
<p>We complement it with a simpler algorithm AdaGrad+ which enjoys the same
features, and achieves the standard non-accelerated convergence rate. We also
present a set of new results involving adaptive methods for unconstrained
optimization and monotone operators.
</p></div>
    </summary>
    <updated>2020-07-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.08836</id>
    <link href="http://arxiv.org/abs/2007.08836" rel="alternate" type="text/html"/>
    <title>Efficient Exact Algorithms for Maximum Balanced Biclique Search in Bipartite Graphs</title>
    <feedworld_mtime>1595289600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Lu.html">Lu Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Chengfei.html">Chengfei Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Rui.html">Rui Zhou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Jiajie.html">Jiajie Xu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jianxin.html">Jianxin Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08836">PDF</a><br/><b>Abstract: </b>Given a bipartite graph, the maximum balanced biclique (\textsf{MBB})
problem, discovering a mutually connected while equal-sized disjoint sets with
the maximum cardinality, plays a significant role for mining the bipartite
graph and has numerous applications. Despite the NP-hardness of the
\textsf{MBB} problem, in this paper, we show that an exact \textsf{MBB} can be
discovered extremely fast in bipartite graphs for real applications. We propose
two exact algorithms dedicated for dense and sparse bipartite graphs
respectively. For dense bipartite graphs, an $\mathcal{O}^{*}( 1.3803^{n})$
algorithm is proposed. This algorithm in fact can find an \textsf{MBB} in near
polynomial time for dense bipartite graphs that are common for applications
such as VLSI design. This is because, using our proposed novel techniques, the
search can fast converge to sufficiently dense bipartite graphs which we prove
to be polynomially solvable. For large sparse bipartite graphs typical for
applications such as biological data analysis, an $\mathcal{O}^{*}(
1.3803^{\ddot{\delta}})$ algorithm is proposed, where $\ddot{\delta}$ is only a
few hundreds for large sparse bipartite graphs with millions of vertices. The
indispensible optimizations that lead to this time complexity are: we transform
a large sparse bipartite graph into a limited number of dense subgraphs with
size up to $\ddot{\delta}$ and then apply our proposed algorithm for dense
bipartite graphs on each of the subgraphs. To further speed up this algorithm,
tighter upper bounds, faster heuristics and effective reductions are proposed,
allowing an \textsf{MBB} to be discovered within a few seconds for bipartite
graphs with millions of vertices. Extensive experiments are conducted on
synthetic and real large bipartite graphs to demonstrate the efficiency and
effectiveness of our proposed algorithms and techniques.
</p></div>
    </summary>
    <updated>2020-07-21T00:30:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.08811</id>
    <link href="http://arxiv.org/abs/2007.08811" rel="alternate" type="text/html"/>
    <title>Parameterized Complexity of Graph Burning</title>
    <feedworld_mtime>1595289600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobayashi:Yasuaki.html">Yasuaki Kobayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Otachi:Yota.html">Yota Otachi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08811">PDF</a><br/><b>Abstract: </b>Graph Burning asks, given a graph $G = (V,E)$ and an integer $k$, whether
there exists $(b_{0},\dots,b_{k-1}) \in V^{k}$ such that every vertex in $G$
has distance at most $i$ from some $b_{i}$. This problem is known to be
NP-complete even on connected caterpillars of maximum degree $3$. We study the
parameterized complexity of this problem and answer all questions arose by Kare
and Reddy [IWOCA 2019] about parameterized complexity of the problem. We show
that the problem is W[2]-complete parameterized by $k$ and that it does no
admit a polynomial kernel parameterized by vertex cover number unless
$\mathrm{NP} \subseteq \mathrm{coNP/poly}$. We also show that the problem is
fixed-parameter tractable parameterized by clique-width plus the maximum
diameter among all connected components. This implies the fixed-parameter
tractability parameterized by modular-width, by treedepth, and by distance to
cographs. Although the parameterization by distance to split graphs cannot be
handled with the clique-width argument, we show that this is also tractable by
a reduction to a generalized problem with a smaller solution size.
</p></div>
    </summary>
    <updated>2020-07-21T00:13:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.08787</id>
    <link href="http://arxiv.org/abs/2007.08787" rel="alternate" type="text/html"/>
    <title>Adaptive Exact Learning in a Mixed-Up World: Dealing with Periodicity, Errors, and Jumbled-Index Queries in String Reconstruction</title>
    <feedworld_mtime>1595289600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Afshar:Ramtin.html">Ramtin Afshar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Amir:Amihood.html">Amihood Amir</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goodrich:Michael_T=.html">Michael T. Goodrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Matias:Pedro.html">Pedro Matias</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08787">PDF</a><br/><b>Abstract: </b>We study the query complexity of exactly reconstructing a string from
adaptive queries, such as substring, subsequence, and jumbled-index queries.
Such problems have applications, e.g., in computational biology. We provide a
number of new and improved bounds for exact string reconstruction for settings
where either the string or the queries are "mixed-up".
</p></div>
    </summary>
    <updated>2020-07-21T00:18:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.08761</id>
    <link href="http://arxiv.org/abs/2007.08761" rel="alternate" type="text/html"/>
    <title>Dominated Minimal Separators are Tame (Nearly All Others are Feral)</title>
    <feedworld_mtime>1595289600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gartland:Peter.html">Peter Gartland</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lokshtanov:Daniel.html">Daniel Lokshtanov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08761">PDF</a><br/><b>Abstract: </b>A class ${\cal F}$ of graphs is called {\em tame} if there exists a constant
$k$ so that every graph in ${\cal F}$ on $n$ vertices contains at most $O(n^k)$
minimal separators, {\em strongly-quasi-tame} if every graph in ${\cal F}$ on
$n$ vertices contains at most $O(n^{k \log n})$ minimal separators, and {\em
feral} if there exists a constant $c &gt; 1$ so that ${\cal F}$ contains
$n$-vertex graphs with at least $c^n$ minimal separators for arbitrarily large
$n$. The classification of graph classes into tame or feral has numerous
algorithmic consequences, and has recently received considerable attention.
</p>
<p>A key graph-theoretic object in the quest for such a classification is the
notion of a $k$-{\em creature}. In a recent manuscript [Abrishami et al., Arxiv
2020] conjecture that every hereditary class ${\cal F}$ that excludes
$k$-creatures for some fixed constant $k$ is tame. We give a counterexample to
this conjecture and prove the weaker result that a hereditary class ${\cal F}$
is strongly quasi-tame if it excludes $k$-creatures for some fixed constant $k$
and additionally every minimal separator can be dominated by another fixed
constant $k'$ number of vertices. The tools developed also lead to a number of
additional results of independent interest.
</p>
<p>{\bf (i) We obtain a complete classification of all hereditary graph classes
defined by a finite set of forbidden induced subgraphs into strongly quasi-tame
or feral. This generalizes Milani\v{c} and Piva\v{c} [WG'19]. {\bf (ii)} We
show that hereditary class that excludes $k$-creatures and additionally
excludes all cycles of length at least $c$, for some constant $c$, are tame.
This generalizes the result of [Chudnovsky et al., Arxiv 2019]. {\bf (iii)} We
show that every hereditary class that excludes $k$-creatures and additionally
excludes a complete graph on $c$ vertices for some fixed constant $c$ is tame.
</p></div>
    </summary>
    <updated>2020-07-21T00:14:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.08669</id>
    <link href="http://arxiv.org/abs/2007.08669" rel="alternate" type="text/html"/>
    <title>Memoryless Algorithms for the Generalized $k$-server Problem on Uniform Metrics</title>
    <feedworld_mtime>1595289600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Christou:Dimitris.html">Dimitris Christou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fotakis:Dimitris.html">Dimitris Fotakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koumoutsos:Grigorios.html">Grigorios Koumoutsos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08669">PDF</a><br/><b>Abstract: </b>We consider the generalized $k$-server problem on uniform metrics. We study
the power of memoryless algorithms and show tight bounds of $\Theta(k!)$ on
their competitive ratio. In particular we show that the \textit{Harmonic
Algorithm} achieves this competitive ratio and provide matching lower bounds.
This improves the $\approx 2^{2^k}$ doubly-exponential bound of Chiplunkar and
Vishwanathan for the more general setting of uniform metrics with different
weights.
</p></div>
    </summary>
    <updated>2020-07-21T00:35:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.08643</id>
    <link href="http://arxiv.org/abs/2007.08643" rel="alternate" type="text/html"/>
    <title>Dynamic Geometric Independent Set</title>
    <feedworld_mtime>1595289600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhore:Sujoy.html">Sujoy Bhore</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cardinal:Jean.html">Jean Cardinal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iacono:John.html">John Iacono</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koumoutsos:Grigorios.html">Grigorios Koumoutsos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08643">PDF</a><br/><b>Abstract: </b>We present fully dynamic approximation algorithms for the Maximum Independent
Set problem on several types of geometric objects: intervals on the real line,
arbitrary axis-aligned squares in the plane and axis-aligned $d$-dimensional
hypercubes.
</p>
<p>It is known that a maximum independent set of a collection of $n$ intervals
can be found in $O(n\log n)$ time, while it is already \textsf{NP}-hard for a
set of unit squares. Moreover, the problem is inapproximable on many important
graph families, but admits a \textsf{PTAS} for a set of arbitrary pseudo-disks.
Therefore, a fundamental question in computational geometry is whether it is
possible to maintain an approximate maximum independent set in a set of dynamic
geometric objects, in truly sublinear time per insertion or deletion. In this
work, we answer this question in the affirmative for intervals, squares and
hypercubes.
</p>
<p>First, we show that for intervals a $(1+\varepsilon)$-approximate maximum
independent set can be maintained with logarithmic worst-case update time. This
is achieved by maintaining a locally optimal solution using a constant number
of constant-size exchanges per update.
</p>
<p>We then show how our interval structure can be used to design a data
structure for maintaining an expected constant factor approximate maximum
independent set of axis-aligned squares in the plane, with polylogarithmic
amortized update time. Our approach generalizes to $d$-dimensional hypercubes,
providing a $O(4^d)$-approximation with polylogarithmic update time.
</p>
<p>Those are the first approximation algorithms for any set of dynamic arbitrary
size geometric objects; previous results required bounded size ratios to obtain
polylogarithmic update time. Furthermore, it is known that our results for
squares (and hypercubes) cannot be improved to a
$(1+\varepsilon)$-approximation with the same update time.
</p></div>
    </summary>
    <updated>2020-07-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.08585</id>
    <link href="http://arxiv.org/abs/2007.08585" rel="alternate" type="text/html"/>
    <title>Planar Distance Oracles with Better Time-Space Tradeoffs</title>
    <feedworld_mtime>1595289600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Long:Yaowei.html">Yaowei Long</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pettie:Seth.html">Seth Pettie</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08585">PDF</a><br/><b>Abstract: </b>In a recent breakthrough, Charalampopoulos, Gawrychowski, Mozes, and Weimann
(STOC 2019) showed that exact distance queries on planar graphs could be
answered in $n^{o(1)}$ time by a data structure occupying $n^{1+o(1)}$ space,
i.e., up to $o(1)$ terms, optimal exponents in time (0) and space (1) can be
achieved simultaneously. Their distance query algorithm is recursive: it makes
successive calls to a point-location algorithm for planar Voronoi diagrams,
which involves many recursive distance queries. The depth of this recursion is
non-constant and the branching factor logarithmic, leading to $(\log
n)^{\omega(1)} = n^{o(1)}$ query times.
</p>
<p>In this paper we present a new way to do point-location in planar Voronoi
diagrams, which leads to a new exact distance oracle. At the two extremes of
our space-time tradeoff curve we can achieve either
</p>
<p>$n^{1+o(1)}$ space and $\log^{2+o(1)}n$ query time, or
</p>
<p>$n\log^{2+o(1)}n$ space and $n^{o(1)}$ query time.
</p>
<p>All previous oracles with $\tilde{O}(1)$ query time occupy space
$n^{1+\Omega(1)}$, and all previous oracles with space $\tilde{O}(n)$ answer
queries in $n^{\Omega(1)}$ time.
</p></div>
    </summary>
    <updated>2020-07-21T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.08575</id>
    <link href="http://arxiv.org/abs/2007.08575" rel="alternate" type="text/html"/>
    <title>Polyhedral value iteration for discounted games and energy games</title>
    <feedworld_mtime>1595289600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kozachinskiy:Alexander.html">Alexander Kozachinskiy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.08575">PDF</a><br/><b>Abstract: </b>We present a deterministic algorithm solving discounted games with $n$ nodes
in strongly $n^{O(1)}\cdot (2 + \sqrt{2})^n$-time. For a special case of
bipartite discounted games our algorithm runs in $n^{O(1)}\cdot 2^n$-time.
Prior to our work no deterministic algorithm running in time $2^{o(n\log n)}$
regardless of the discount factor was known.
</p>
<p>We call our approach polyhedral value iteration. We rely on a well-known fact
that the values of a discounted game can be found from the so-called optimality
equations. In the algorithm we consider a polyhedron obtained by relaxing
optimality equations. We iterate the points on the border of this polyhedron by
moving each time along a carefully chosen shift as far as possible. This
continues until the current point satisfies optimality equations.
</p>
<p>Our approach is heavily inspired by a recent algorithm of Dorfman et al.
(ICALP 2019) for energy games. For completeness, we present their algorithm in
terms of polyhedral value iteration. Our exposition, unlike the original
algorithm, does not require edge weights to be integers and works for arbitrary
real weights.
</p></div>
    </summary>
    <updated>2020-07-21T00:36:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/stoc2020/</id>
    <link href="https://differentialprivacy.org/stoc2020/" rel="alternate" type="text/html"/>
    <title>Conference Digest - STOC 2020</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="http://acm-stoc.org/stoc2020/">STOC 2020</a> was recently held online, as one of the first major theory conferences during the COVID-19 era.
It featured four papers on differential privacy, which we list and link below.
Each one is accompanied by a video from the conference, as well as a longer video if available.
Please let us know if we missed any papers on differential privacy, either in the comments below or by email.</p>

<ul>
  <li>
    <p><a href="https://arxiv.org/abs/1911.08339">The Power of Factorization Mechanisms in Local and Central Differential Privacy</a> (<a href="https://www.youtube.com/watch?v=hSenRTxhZhM">video</a>)<br/>
<a href="https://dblp.uni-trier.de/pers/hd/e/Edmonds:Alexander">Alexander Edmonds</a>, <a href="http://www.cs.toronto.edu/~anikolov/">Aleksandar Nikolov</a>, <a href="https://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2005.04763">Private Stochastic Convex Optimization: Optimal Rates in Linear Time</a> (<a href="https://www.youtube.com/watch?v=Tlc-z-MFAmM">video</a>)<br/>
<a href="http://vtaly.net/">Vitaly Feldman</a>, <a href="https://tomerkoren.github.io/">Tomer Koren</a>, <a href="http://kunaltalwar.org/">Kunal Talwar</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1911.04014">Interaction is necessary for distributed learning with privacy or communication constraints</a> (<a href="https://www.youtube.com/watch?v=AWgzaFOU_HM">video</a>)<br/>
<a href="https://yuvaldagan.wordpress.com/">Yuval Dagan</a>, <a href="http://vtaly.net/">Vitaly Feldman</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1906.05271">Does Learning Require Memorization? A Short Tale about a Long Tail</a> (<a href="https://www.youtube.com/watch?v=sV59uoWJRnk">video</a>, <a href="https://www.youtube.com/watch?v=Fp7cgHRl8Yc">longer video</a>)<br/>
<a href="http://vtaly.net/">Vitaly Feldman</a></p>
  </li>
</ul></div>
    </summary>
    <updated>2020-07-20T14:00:00Z</updated>
    <published>2020-07-20T14:00:00Z</published>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2020-07-21T00:42:23Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://gradientscience.org/transfer-learning/</id>
    <link href="https://gradientscience.org/transfer-learning/" rel="alternate" type="text/html"/>
    <title>Transfer Learning with Adversarially Robust Models</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="bbutton" href="https://arxiv.org/abs/2007.08489" style="float: left; width: 45%;">
<i class="fas fa-file-pdf"/>
    Paper
</a>
<a class="bbutton" href="https://github.com/Microsoft/robust-models-transfer" style="float: left; width: 45%;">
<i class="fab fa-github"/>
   Models and Code
</a>
<br/></p>

<p><i>In our <a href="https://arxiv.org/abs/2007.08489">latest paper</a>, in collaboration with <a href="https://www.microsoft.com/en-us/research/">Microsoft Research</a>, we explore adversarial
robustness as an avenue for training computer vision models with more transferrable
features. We find that robust models outperform their standard counterparts on
a variety of transfer learning tasks.</i></p>

<h2 id="what-is-transfer-learning">What is transfer learning?</h2>

<p>Transfer learning is a paradigm where one leverages information
from a “source” task to better solve another “target” task. Particularly when there is little training data or compute available for solving the target
task, transfer learning provides a simple and efficient way to obtain performant
machine learning models.</p>

<p>Transfer learning has already proven its utility in many ML contexts. In natural language processing, for example, one can leverage language models pre-trained on large
text corpora to beat state-of-the-art performance on
tasks like query answering, entity recognition or part-of-speech classification.</p>

<p>In our work we focus on computer vision; in this context, a standard—and
remarkably successful—transfer learning pipeline is “ImageNet pre-training.”
This pipeline starts with a deep neural network trained on the <a href="http://image-net.org">ImageNet-1K</a>
dataset, and then refines this pre-trained model for a target task. The target task can range
from classification of smaller datasets (e.g., <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR</a>) to more complex
tasks like object detection (e.g., <a href="http://host.robots.ox.ac.uk/pascal/VOC/">VOC</a>).</p>

<p>Although there are many ways in which one can refine a pre-trained model, we
will restrict our attention to the two most popular methods:</p>

<ul>
  <li><strong>Fixed-feature</strong>: In fixed-feature transfer learning, we replace the final
(linear) layer of the neural network with a new layer that has the correct
number of outputs for the target task. Then, keeping the rest of the layers
<em>fixed</em>, we train the newly replaced layer on the target task.</li>
  <li><strong>Full-network</strong>: In full-network transfer learning, we also replace the last
layer but do not freeze any layers afterwards. Instead, we use the pre-trained
network
as a sort of “initialization,” and continue training <em>all</em> the layers on the
target task.</li>
</ul>

<p>When at least a moderate amount of data is available, full-network transfer
learning typically outperforms the fixed-feature strategy.</p>

<h2 id="how-can-we-improve-transfer-learning">How can we improve transfer learning?</h2>

<p>Although we don’t have a comprehensive understanding of what makes transfer
learning algorithms tick, there has been a long line of work focused on identifying 
factors that improve (or worsen) performance (examples include
<a href="https://arxiv.org/abs/1406.5774">[1]</a>,
<a href="https://arxiv.org/abs/1608.08614">[2]</a>,
<a href="https://arxiv.org/abs/1805.08974">[3]</a>,
<a href="https://arxiv.org/abs/1804.08328">[4]</a>,
<a href="https://arxiv.org/abs/1411.1792">[5]</a>).</p>

<p>By design, the pre-trained ImageNet model itself plays a major role here:
indeed, a recent study by <a href="https://arxiv.org/abs/1805.08974">Kornblith, Shlens, and Le</a> finds that
pre-trained models which achieve a higher ImageNet accuracy also perform better when
transferred to downstream classification tasks, with a tight linear
correspondence between ImageNet accuracy and the accuracy on the target task:</p>

<p><img alt="A scatter plot of ImageNet accuracy versus downstream     transfer accuracy showing the linear relation." class="bigimg" src="https://gradientscience.org/assets/robust-transfer-learning/ksl.png"/></p>
<div class="footnote">
Reproduced from <a href="https://arxiv.org/abs/1805.08974">[KSL19]</a>. 
Each dot is a pre-trained model whose $x$ coordinate is given by its 
ImageNet accuracy and $y$ coordinate is given by its downstream 
accuracy on the target task (after the corresponding refinement on that task).
</div>

<p>But is improving ImageNet accuracy of the pre-trained model the <em>only</em> way to improve transfer learning performance?</p>

<p>After all, we want to obtain models that have learned broadly applicable features from the
source dataset. ImageNet accuracy likely correlates with the quality of
features that a model has learned, but may not fully describe the downstream
utility of these features.
Ultimately, the nature of learned features stems from the <em>priors</em> placed on
them during training. For example, there have been studies of the (sometimes
implicit) priors imposed by architectural components (e.g., <a href="https://dmitryulyanov.github.io/deep_image_prior">convolutional layers</a>),
<a href="https://www.tandfonline.com/doi/abs/10.1198/10618600152418584">data</a>
<a href="https://arxiv.org/abs/1911.09071">augmentation</a>, 
<a href="https://arxiv.org/abs/1811.00401">loss functions</a> and even
<a href="https://stats385.github.io/assets/lectures/Stanford_Donoho_class_Nov_19.pdf">gradient descent</a> on neural network training.</p>

<p>In <a href="https://arxiv.org/abs/2007.08489">our paper</a>, we study another prior: <em>adversarial robustness</em>.
Adversarial robustness—a rather frequent subject on this blog—refers to
model’s invariance to small (often imperceptible) perturbations of natural
inputs, called <a href="https://gradientscience.org/intro_adversarial">adversarial examples</a>.</p>

<p>Standard neural networks (i.e., trained with the goal of maximizing
accuracy) are extremely vulnerable to such adversarial examples. For example,
with just a tiny perturbation to the pig image below, a pre-trained ImageNet
classifier will predict it as an “airliner” with 99% confidence:</p>

<p><img alt="An adversarial example: a pig on the left which is imperceptibly perturbed to be classified as an airliner on the right." src="https://gradientscience.org/images/piggie.png"/></p>
<div class="footnote">
A "pigs-can-fly" adversarial example: The "pig" image on the left is correctly classified by a standard ML model, but its imperceptibly perturbed counterpart on the right is classified as an "airliner" with 99% confidence.
</div>

<p>Adversarial robustness is thus typically induced at training time by replacing
the standard loss minimization objective with a <em>robust optimization</em> objective
(see our <a href="https://gradientscience.org/robust_opt_pt1">post on robust optimization</a> for more background):</p>



<p>The above objective trains models to be robust to image perturbations that are
small in (pixel-wise) $\ell_2$ (Euclidean) normIn reality, an $\ell_2$ ball doesn't perfectly capture the
set of imperceptible perturbations we want models to be robust to—but robustness with respect to this fairly rudimentary notion of perturbations turns out to be already non-trivial and very helpful.. 
The parameter $\varepsilon$ is a hyperparameter
governing the intended degree of invariance of the resulting models to the
corresponding perturbations. Setting 
$\varepsilon = 0$ corresponds to standard training, and increasing $\varepsilon$
asks the model to be robust to increasingly large perturbations.
In short, the objective asks the model to minimize risk on not only the 
training datapoints but also the entire radius-$\varepsilon$
neighbourhood around them.</p>

<p><em>[A quick plug: Our <a href="https://github.com/MadryLab/robustness"><code class="language-plaintext highlighter-rouge">robustness</code> Python library</a>, used for the code release of this paper, enables one to easily train and manipulate both standard and adversarially robust models.]</em></p>

<p>Although adversarial robustness has been initially studied solely through the lens of machine learning security, a line
of recent work (including some that’s been <a href="https://gradientscience.org/adv">previously</a> 
<a href="https://gradientscience.org/robust_apps">covered</a> on this blog) has begun to study
adversarially robust models in their own right, framing adversarial robustness
as a prior that forces models to learn features that are locally stable.
These works have found that on the one hand, adversarially robust models tend
to attain lower accuracy than their standardly-trained
counterparts.</p>

<p>On the other hand, recent work suggests that the feature
representations of robust models carry several advantages over those of
standard models, such as <a href="https://arxiv.org/abs/1805.12152">better-behaved</a>
<a href="https://arxiv.org/abs/1905.09797">gradients</a>, <a href="https://arxiv.org/abs/1910.08640">representation
invertibility</a>, and more <a href="https://arxiv.org/abs/2005.10190">specialized
features</a>.
We’ve actually discussed some of these observations in earlier posts on this
blog—see, e.g., our posts about 
<a href="https://gradientscience.org/robust_reps">representation learning</a> and 
<a href="https://gradientscience.org/robust_apps">image synthesis</a>.</p>

<p>These desirable properties
might suggest that robust neural networks are learning better feature
representations than standard networks, which could improve transfer
performance.</p>

<h3 id="adversarial-robustness-and-transfer-learning">Adversarial robustness and transfer learning</h3>

<p>So in summary, we have standard models with high accuracy on the source task but
little (or no) robustness; and we have adversarially robust models, which are
worse in terms of ImageNet accuracy, but have the “nice”
representational properties identified and discussed by prior works. Which
models are better for transfer learning?</p>

<p>To answer this question, we trained and examined a large collection
of standard and robust ImageNet models, while grid searching over a wide range of
hyperparameters and architectures to find the best model of each type. (All
models are available for download via our <a href="https://github.com/microsoft/robust-models-transfer">code/model
release</a> and more
details on our training procedure can be found there and in <a href="https://arxiv.org/abs/2007.08489">our
paper</a>). We then performed transfer
learning (using both fixed-feature and full-network refinement) from each
trained model to 12 downstream classification tasks.</p>

<p>It turns out that 
adversarially robust source models fairly consistently outperform their standard counterparts in
terms of downstream accuracy. In the table below, we compare the accuracies of
the best standard model (searching over hyperparameters and
architecture) and the best robust model (searching over the
previous factors as well as robustness level $\varepsilon$):</p>

<p><img alt="Table showing that robust models     perform better than their standard counterparts." class="bigimg" src="https://gradientscience.org/assets/robust-transfer-learning/results-table.svg" style="width: 100%;"/></p>
<div class="footnote">
    The main result: Adversarially robust models outperform their standard counterparts when transferred to downstream classification tasks.
</div>

<p>This difference in performance tends to be particularly striking in the context of fixed-feature transfer learning. The following graph shows, for each architecture and
downstream classification task, the best standard model compared to the best
robust model in that setting. As we can see, adversarially robust models
improve on the performance of their standard counterparts, and the gap tends to
<em>increase</em> as networks increase in width:</p>

<p><img alt="A bar chart showing that robust models improve on     standard ones even without taking the maximum over architectures." class="bigimg" src="https://gradientscience.org/assets/robust-transfer-learning/LogisticRegression.svg"/></p>
<div class="footnote">
    Adversarially robust models tend to improve over standard networks for
    individual architectures too. (An analogous graph for full-network
    transfer learning is given in Figure 3 of <a href="https://arxiv.org/abs/2007.08489">our paper</a>.)
</div>

<p>Adversarial robustness improved downstream transfer
performance even when the target task was not a classification one. For example, the
following table compares standard and robust pre-training for use in downstream
object detection and instance segmentation:</p>

<p><img class="bigimg" src="https://gradientscience.org/../assets/robust-transfer-learning/obj-det-results.svg" style="width: 80%;"/></p>
<div class="footnote">
</div>

<h3 id="robustness-versus-accuracy">Robustness versus accuracy</h3>

<p>So it seems like robust models, despite being less accurate on the source task, are actually
better for transfer learning purposes. Indeed, the linear relation between
 ImageNet accuracy and transfer performance observed in prior work (see our discussion above) doesn’t seem
 to hold when the robustness parameter is varied. Compare the graphs below to the ones at the very start of this post:</p>

<p><img class="bigimg" src="https://gradientscience.org/assets/robust-transfer-learning/wide_resnet50_4_LogisticRegression.svg"/></p>
<div class="footnote">
    Source-task (ImageNet) versus target (fixed-feature) accuracy for models with the same
    architecture while varying the robustness levels. Each dot is a
    WideResNet-50x4 model with $x$ coordinate given by source-task accuracy and
    $y$ coordinate given by fixed-feature transfer learning accuracy.
    Contrast the trends here with the "fixed-feature" trend in the first
    figure of this post—the linear trend depicted there largely disappears as less
    accurate but more robust models perform better in terms of transfer.
</div>

<p>How do we reconcile our observations with these trends observed by prior work?</p>

<p>We hypothesize that robustness and accuracy have <em>disentangled</em> effects on
transfer performance. That is, for a fixed level of robustness, higher
accuracy on the source task helps transfer, and for a fixed level of
accuracy, increased robustness helps transfer. Indeed, as shown below, for a
fixed level of robustness, the accuracy-transfer relation tends to hold
strongly:</p>

<p><img class="bigimg" src="https://gradientscience.org/assets/robust-transfer-learning/fixed-robustness.svg"/></p>
<div class="footnote">
Even though robust models appear to break the linear
accuracy-transfer trend, this trend is actually preserved for a fixed value of
robustness. Each dot in the graph is a different architecture, trained for the same level of robustness ($\varepsilon = 3.0$). The $x$ coordinate is source task (ImageNet) accuracy, and the $y$ coordinate is the downstream accuracy on each target dataset.
</div>

<p>In addition to reconciling our results with those of prior work, these findings suggest that ongoing work on developing more accurate robust models
may have the added benefit of further improving transfer learning performance.</p>

<h3 id="other-empirical-mysteries-and-future-work">Other empirical mysteries and future work</h3>

<p>This post discussed how adversarially robust models might constitute a promising
avenue for improving transfer learning, and already often outperform standard
models in terms of downstream accuracy. In <a href="https://arxiv.org/abs/2007.08489">our paper</a>, 
we study this phenomenon more closely: for example, we examine the effects of
model width, and we compare adversarial robustness to other notions of
robustness. We also uncover a few somewhat mysterious properties: for example,
resizing images seems to have a non-trivial effect on the relationship between
robustness and downstream accuracy.</p>

<p>Finally, while our work provides evidence that adversarially
robust computer vision models transfer better, understanding precisely <em>why</em> this is the case remains open. More broadly, the results we
observe indicate that we still do not yet fully understand (even empirically)
the ingredients that make transfer learning successful. We hope that our work
prompts an inquiry into the underpinnings of modern transfer learning.</p></div>
    </summary>
    <updated>2020-07-20T00:00:00Z</updated>
    <published>2020-07-20T00:00:00Z</published>
    <source>
      <id>https://gradientscience.org/</id>
      <author>
        <name>Gradient Science</name>
      </author>
      <link href="https://gradientscience.org/" rel="alternate" type="text/html"/>
      <link href="https://gradientscience.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Research highlights and perspectives on machine learning and optimization from MadryLab.</subtitle>
      <title>gradient science</title>
      <updated>2020-07-21T00:40:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.09099</id>
    <link href="http://arxiv.org/abs/2007.09099" rel="alternate" type="text/html"/>
    <title>A dichotomy theorem for nonuniform CSPs simplified</title>
    <feedworld_mtime>1595203200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bulatov:Andrei_A=.html">Andrei A. Bulatov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.09099">PDF</a><br/><b>Abstract: </b>In a non-uniform Constraint Satisfaction problem CSP(G), where G is a set of
relations on a finite set A, the goal is to find an assignment of values to
variables subject to constraints imposed on specified sets of variables using
the relations from G. The Dichotomy Conjecture for the non-uniform CSP states
that for every constraint language G the problem CSP(G) is either solvable in
polynomial time or is NP-complete. It was proposed by Feder and Vardi in their
seminal 1993 paper. In this paper we confirm the Dichotomy Conjecture.
</p></div>
    </summary>
    <updated>2020-07-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.09075</id>
    <link href="http://arxiv.org/abs/2007.09075" rel="alternate" type="text/html"/>
    <title>Efficient Linear and Affine Codes for Correcting Insertions/Deletions</title>
    <feedworld_mtime>1595203200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheng:Kuan.html">Kuan Cheng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guruswami:Venkatesan.html">Venkatesan Guruswami</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haeupler:Bernhard.html">Bernhard Haeupler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Xin.html">Xin Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.09075">PDF</a><br/><b>Abstract: </b>This paper studies \emph{linear} and \emph{affine} error-correcting codes for
correcting synchronization errors such as insertions and deletions. We call
such codes linear/affine insdel codes.
</p>
<p>Linear codes that can correct even a single deletion are limited to have
information rate at most $1/2$ (achieved by the trivial 2-fold repetition
code). Previously, it was (erroneously) reported that more generally no
non-trivial linear codes correcting $k$ deletions exist, i.e., that the
$(k+1)$-fold repetition codes and its rate of $1/(k+1)$ are basically optimal
for any $k$. We disprove this and show the existence of binary linear codes of
length $n$ and rate just below $1/2$ capable of correcting $\Omega(n)$
insertions and deletions. This identifies rate $1/2$ as a sharp threshold for
recovery from deletions for linear codes, and reopens the quest for a better
understanding of the capabilities of linear codes for correcting
insertions/deletions.
</p>
<p>We prove novel outer bounds and existential inner bounds for the rate vs.
(edit) distance trade-off of linear insdel codes. We complement our existential
results with an efficient synchronization-string-based transformation that
converts any asymptotically-good linear code for Hamming errors into an
asymptotically-good linear code for insdel errors. Lastly, we show that the
$\frac{1}{2}$-rate limitation does not hold for affine codes by giving an
explicit affine code of rate $1-\epsilon$ which can efficiently correct a
constant fraction of insdel errors.
</p></div>
    </summary>
    <updated>2020-07-20T23:29:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.09045</id>
    <link href="http://arxiv.org/abs/2007.09045" rel="alternate" type="text/html"/>
    <title>Integer factorization and Riemann's hypothesis: Why two-item joint replenishment is hard</title>
    <feedworld_mtime>1595203200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schulz:Andreas_S=.html">Andreas S. Schulz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Telha:Claudio.html">Claudio Telha</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.09045">PDF</a><br/><b>Abstract: </b>Distribution networks with periodically repeating events often hold great
promise to exploit economies of scale. Joint replenishment problems are a
fundamental model in inventory management, manufacturing, and logistics that
capture these effects. However, finding an efficient algorithm that optimally
solves these models, or showing that none may exist, has long been open,
regardless of whether empty joint orders are possible or not. In either case,
we show that finding optimal solutions to joint replenishment instances with
just two products is at least as difficult as integer factorization. To the
best of the authors' knowledge, this is the first time that integer
factorization is used to explain the computational hardness of any kind of
optimization problem. Under the assumption that Riemann's Hypothesis is
correct, we can actually prove that the two-item joint replenishment problem
with possibly empty joint ordering points is NP-complete under randomized
reductions, which implies that not even quantum computers may be able to solve
it efficiently. By relating the computational complexity of joint replenishment
to cryptography, prime decomposition, and other aspects of prime numbers, a
similar approach may help to establish (integer factorization) hardness of
additional open periodic problems in supply chain management and beyond, whose
solution has eluded standard methods.
</p></div>
    </summary>
    <updated>2020-07-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.09023</id>
    <link href="http://arxiv.org/abs/2007.09023" rel="alternate" type="text/html"/>
    <title>Parameterized Complexity of Scheduling Chains of Jobs with Delays</title>
    <feedworld_mtime>1595203200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bodlaender:Hans_L=.html">Hans L. Bodlaender</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wegen:Marieke_van_der.html">Marieke van der Wegen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.09023">PDF</a><br/><b>Abstract: </b>In this paper, we consider the parameterized complexity of the following
scheduling problem. We must schedule a number of jobs on $m$ machines, where
each job has unit length, and the graph of precedence constraints consists of a
set of chains. Each precedence constraint is labelled with an integer that
denotes the exact (or minimum) delay between the jobs. We study different
cases; delays can be given in unary and in binary, and the case that we have a
single machine is discussed separately. We consider the complexity of this
problem parameterized by the number of chains, and by the thickness of the
instance, which is the maximum number of chains whose intervals between release
date and deadline overlap.
</p>
<p>We show that this scheduling problem with exact delays in unary is
$W[t]$-hard for all $t$, when parameterized by the thickness, even when we have
a single machine ($m = 1$). When parameterized by the number of chains, this
problem is $W[1]$-complete when we have a single or a constant number of
machines, and $W[2]$-complete when the number of machines is a variable. The
problem with minimum delays, given in unary, parameterized by the number of
chains (and as a simple corollary, also when parameterized by the thickness) is
$W[1]$-hard for a single or a constant number of machines, and $W[2]$-hard when
the number of machines is variable.
</p>
<p>With a dynamic programming algorithm, one can show membership in XP for exact
and minimum delays in unary, for any number of machines, when parameterized by
thickness or number of chains. For a single machine, with exact delays in
binary, parameterized by the number of chains, membership in XP can be shown
with branching and solving a system of difference constraints. For all other
cases for delays in binary, membership in XP is open.
</p></div>
    </summary>
    <updated>2020-07-20T23:21:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2418581440113974615</id>
    <link href="https://blog.computationalcomplexity.org/feeds/2418581440113974615/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/erdos-turan-for-k3-is-true.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2418581440113974615" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2418581440113974615" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/erdos-turan-for-k3-is-true.html" rel="alternate" type="text/html"/>
    <title>Erdos-Turan for k=3 is True!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">(All of the math in this post is summarized (without proofs) in a writeup by Erik Metz and myself which you can find <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/3apblog.pdf">here</a>. It is a pdf file so you can click on links in it to get to the papers it refers to. There have been posts on this topic by <a href="https://gilkalai.wordpress.com/2020/07/08/to-cheer-you-up-in-difficult-times-7-bloom-and-sisask-just-broke-the-logarithm-barrier-for-roths-theorem/">Gil Kalai</a> and  <a href="https://lucatrevisan.wordpress.com/2020/07/08/silver-linings/">Luca Trevisan</a>. If you know of others then let me know so I can add them to this post.)<br/>
<br/>
<br/>
<br/>
This is a sequel to <a href="https://blog.computationalcomplexity.org/2010/12/breakthrough-result-on-density-and-3.html">A BREAKTHROUGH result on density and 3-AP's</a> and <a href="https://blog.computationalcomplexity.org/2017/06/big-news-on-w3r.html">Big news on W(3,r)!</a><br/>
<br/>
For this post N is large, and all inequalites have a big-O or a big-Omega.<br/>
<br/>
For this post [N] is {1,...,N}<br/>
<br/>
Let<br/>
<br/>
r(N) be the least w such that if A is a subset of [N] and |A|  &gt;  w, then A has a 3-AP.<br/>
<br/>
There has been a long sequence of results getting smaller and smaller upper bounds on r(N).<br/>
<br/>
The motivation for getting these results is that if r(N) is &lt; N/(log N)^{1+\delta} with delta&gt;0 then the following holds:<br/>
<br/>
If sum_{x\in A} 1/x diverges then A has a 3-AP.<br/>
<br/>
This is the k=3 case of one of the Erdos-Turan Conjectures.<br/>
<br/>
Bloom and Sisack HAVE gotten N/(log N)^{1+delta} so they HAVE gotten ET k=3. Wow!<br/>
<br/>
1) I am NOT surprised that its true.<br/>
<br/>
2) I am SHOCKED and DELIGHTED that it was proven.  Shocked because the results leading up to it (see the write up referenced at the beginning of this post) seemed Zeno-like, approaching the result needed got but not getting there. Delighted because... uh, as the kids say, just cause.<br/>
<br/>
I've heard that k=4 really is much harder (see my comments and Gil's response on his blog post, pointed to at the beginning of this post)  and it is true that there has been far less progress on that case (the write up I pointed to at the beginning of this post says what is known). Hence I will again be <i>shocked </i>if it is proven.  So, unlike The Who (see <a href="https://www.youtube.com/watch?v=UDfAdHBtK_Q">here</a>) I CAN be fooled again. That's okay--- I will  be <i>delighted</i>. (ADDED LATER- there are more comments no Gil's website, from Thomas Bloom and Ben Green about what is likely to happen in the next 10 years.)<br/>
<br/>
Erdos offered a prize of $3000 for a proof that A has, for all k, a k-AP.  The prize is now $5000. After Erdos passed away Ronald Graham became the Erdos-Bank and paid out the money when people solved a problem Erdos put a bounty on. What happens now? (If I have the facts wrong and/or if you know the answer, please leave a polite and enlightening comment.)<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2020-07-19T19:12:00Z</updated>
    <published>2020-07-19T19:12:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-07-20T21:32:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/109</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/109" rel="alternate" type="text/html"/>
    <title>TR20-109 |  On Testing Hamiltonicity in the Bounded Degree Graph Model | 

	Oded Goldreich</title>
    <summary>We show that testing Hamiltonicity in the bounded-degree graph model requires a linear number of queries. This refers to both the path and the cycle versions of the problem, and similar results hold also for the directed analogues.
In addition, we present an alternative proof for the known fact that testing Independent Set Size (in this model) requires a linear number of queries.</summary>
    <updated>2020-07-19T15:45:33Z</updated>
    <published>2020-07-19T15:45:33Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-21T00:39:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/108</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/108" rel="alternate" type="text/html"/>
    <title>TR20-108 |  Query Complexity of Global Minimum Cut | 

	Arijit Bishnu, 

	Arijit Ghosh, 

	Gopinath Mishra, 

	Manaswi Paraashar</title>
    <summary>In this work, we resolve the query complexity of global minimum cut problem for a graph by designing a randomized algorithm for approximating the size of minimum cut in a graph, where the graph can be accessed through local queries like \textsc{Degree}, \textsc{Neighbor}, and \textsc{Adjacency} queries.

Given $\epsilon \in (0,1)$, the algorithm with high probability outputs an estimate $\hat{t}$ satisfying the following $(1-\epsilon) t \leq \hat{t} \leq (1+\epsilon) t$, where $m$ is the number of edges in the graph and $t$ is the size of minimum cut in the graph. The expected number of local queries used by our algorithm is $\min\left\{m+n,\frac{m}{t}\right\}\mbox{poly}\left(\log n,\frac{1}{\epsilon}\right)$ where $n$ is the number of vertices in the graph. Eden and Rosenbaum showed that $\Omega(m/t)$ many local queries are required for approximating the size of minimum cut in graphs. These two results together resolve the query complexity of the problem of estimating the size of minimum cut in graphs using local queries.

Building on the lower bound of Eden and Rosenbaum, we show that, for all $t \in \mathbb{N}$, $\Omega(m)$ local queries are required to decide if the size of the minimum cut in the graph is $t$ or $t-2$. Also, we show that, for any $t \in \mathbb{N}$, $\Omega(m)$ local queries are required to find all the minimum cut edges even if it is promised that the input graph has a minimum cut of size $t$. Both of our lower bound results are randomized, and hold even if we can make \textsc{Random Edge} query apart from local queries.</summary>
    <updated>2020-07-19T13:02:59Z</updated>
    <published>2020-07-19T13:02:59Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-21T00:39:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/107</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/107" rel="alternate" type="text/html"/>
    <title>TR20-107 |  Testing linear inequalities of subgraph statistics | 

	Lior Gishboliner, 

	Asaf Shapira, 

	Henrique Stagni</title>
    <summary>Property testers are fast randomized algorithms whose task is to distinguish between inputs satisfying some predetermined property ${\cal P}$ and those that are far from satisfying it. Since these algorithms operate by inspecting a small randomly selected portion of the input, the most natural property one would like to be able to test is whether the input does not contain certain forbidden small substructures. In the setting of graphs, such a result was obtained by Alon et al., who proved that for any finite family of graphs ${\cal F}$, the property of being induced ${\cal F}$-free (i.e. not containing an induced copy of any $F \in {\cal F}$) is testable.

It is natural to ask if one can go one step further and prove that more elaborate properties involving induced subgraphs are also testable. One such generalization of the result of Alon et al. was formulated by Goldreich and Shinkar who conjectured that for any finite family of graphs ${\cal F}$, and any linear inequality involving the densities of the graphs $F \in {\cal F}$ in the input graph,
the property of satisfying this inequality can be tested in a certain restricted model of graph property testing. Our main result in this paper disproves this conjecture in the following strong form: some properties of this type are not testable even in the classical (i.e. unrestricted) model of graph property testing.

The proof deviates significantly from prior non-testability results in this area. The main idea is to use a linear inequality relating induced subgraph densities in order to encode the property of being a quasirandom graph.</summary>
    <updated>2020-07-19T13:01:55Z</updated>
    <published>2020-07-19T13:01:55Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-21T00:39:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17307</id>
    <link href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/" rel="alternate" type="text/html"/>
    <title>Mathematical Search</title>
    <summary>A flying start from nearby Rochester Anurag Agarwal and Richard Zanibbi are tenured faculty in Mathematics and Computer Science, respectively, at RIT. They partner with Clyde Lee Giles of Penn State and Douglas Oard of U.Md. on the MathSeer project. If the name reminds you of CiteSeer, no surprise: Giles co-originated that and still directs […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>A flying start from nearby Rochester</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/agarwalzanibbi/" rel="attachment wp-att-17309"><img alt="" class="alignright size-thumbnail wp-image-17309" height="142" src="https://rjlipton.files.wordpress.com/2020/07/agarwalzanibbi.png?w=150&amp;h=142" width="150"/></a></p>
<p>
Anurag Agarwal and Richard Zanibbi are tenured faculty in Mathematics and Computer Science, respectively, at RIT. They partner with Clyde Lee Giles of Penn State and Douglas Oard of U.Md. on the <a href="https://www.cs.rit.edu/~dprl/mathseer/">MathSeer</a> project. If the name reminds you of <a href="http://citeseerx.ist.psu.edu/">CiteSeer<img alt="{{\,}^x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5C%2C%7D%5Ex%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\,}^x}"/></a>, no surprise: Giles co-originated that and still directs it.</p>
<p>
Today we note last month’s release of a major piece of MathSeer called <a href="https://mathdeck.cs.rit.edu/">MathDeck</a> and show how to have fun with it.</p>
<p>
Agarwal is a PhD graduate from Buffalo. He did his thesis in the Mathematics Department under Thomas Cusick on cryptography, but often visited Computer Science. He took part in seminars on lattice-based cryptography led by Jin-Yi Cai when he was in Buffalo and in one of mine on related topics. I also knew him socially as a housemate of Pavan Aduri, whose joint work we’ve mentioned <a href="https://rjlipton.wordpress.com/2012/07/14/it-dont-come-easy/">here</a>. </p>
<p>
A long time ago, Dick wrote a <a href="https://rjlipton.wordpress.com/2010/12/20/some-mathematical-gifts/">post</a> on <a href="http://detexify.kirelabs.org/classify.html">Detexify</a>, which does optical character recognition (OCR) for mathematical symbols and finds corresponding (La)TeX commands. <em>MathDeck</em> does OCR as well, but what it is really trying to recognize is the <em>formula</em> you are trying to write. If it is a famous formula—or one you have already saved in your “deck”—it will find and complete it for you. It also takes input from LaTeX. <em>MathDeck</em> was created by Gavin Nishizawa, Jennifer Liu, Yancarlos Diaz, Abishai Dmello, and Wei Zhong along with Zanibbi. They are credited on a brief <a href="https://www.cs.rit.edu/~rlaz/files/ECIR2020_MathDeck_Demo.pdf">paper</a> and <a href="https://www.cs.rit.edu/~dprl/mathseer/demos.html">video</a>.</p>
<p>
</p><p/><h2> Trying MathDeck </h2><p/>
<p/><p>
On first visit, the site shows a very brief tutorial which can be dismissed via a sometimes-invisible X in the upper-right corner. The first formula I thought to write was Leonhard Euler’s “mystic equation” <img alt="{e^{i\pi} + 1 = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%5E%7Bi%5Cpi%7D+%2B+1+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e^{i\pi} + 1 = 0}"/>. Its OCR sprang into action as I drew and converted my attempt to draw a curly <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> and then <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi}"/> as <img alt="{7n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B7n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{7n}"/> with an extra crossbar.  (The website graphics are much sharper than our screenshots here.)</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/eulerformulamathdeck/" rel="attachment wp-att-17310"><img alt="" class="aligncenter wp-image-17310" height="400" src="https://rjlipton.files.wordpress.com/2020/07/eulerformulamathdeck.jpg?w=540&amp;h=400" width="540"/></a></p>
<p/><p><br/>
Nevertheless, its default deck of “WikiCards” recognizes the attempt and includes “Euler’s Identity” as an option. Selecting the card changes the display to an immaculately typeset version. I then decided to change it to the form <img alt="{e^{i\pi} = -1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%5E%7Bi%5Cpi%7D+%3D+-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e^{i\pi} = -1}"/>. <em>MathDeck</em> does not have a pixel eraser like Microsoft Paint does but allows you to delete a region after selecting it:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/eulerformulatypeset/" rel="attachment wp-att-17312"><img alt="" class="aligncenter wp-image-17312" height="190" src="https://rjlipton.files.wordpress.com/2020/07/eulerformulatypeset.jpg?w=360&amp;h=190" width="360"/></a></p>
<p/><p><br/>
Selecting “trash” did not close up the space to the equals sign. I drew a minus bar at far right, but my attempts to follow with <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> kept being interpreted as “<img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/>” or something worse, and the alternate form of Euler’s identity did not come up below. Finally, I restored the LaTeX-input box on the right and edited the source to read, <font size="+1"><tt>e^{i\pi} = -1</tt></font>:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/eulerformulatypeset2/" rel="attachment wp-att-17314"><img alt="" class="aligncenter wp-image-17314" height="175" src="https://rjlipton.files.wordpress.com/2020/07/eulerformulatypeset2.jpg?w=540&amp;h=175" width="540"/></a></p>
<p/><p><br/>
The artifact of my hand-drawn minus sign was still at far right. I could not select and trash it even after refreshing the page. What fixed the issue was drawing something else over the squiggle and having the OCR interpret the tandem into something else, which I could then select and delete. </p>
<p>
</p><p/><h2> Superposing Forms and Associations </h2><p/>
<p/><p>
I next wondered how the system would react to my trying to write Schrödinger’s equation. One challenge is that it has many forms. I chose the form given uppermost in Wikipedia’s <a href="https://en.wikipedia.org/wiki/Schrodinger_equation#Equation">article</a>: </p>
<p align="center"><img alt="\displaystyle  i\hbar \frac{d |\Psi(t)\rangle}{d t} = \hat{H}|\Psi(t)\rangle " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++i%5Chbar+%5Cfrac%7Bd+%7C%5CPsi%28t%29%5Crangle%7D%7Bd+t%7D+%3D+%5Chat%7BH%7D%7C%5CPsi%28t%29%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  i\hbar \frac{d |\Psi(t)\rangle}{d t} = \hat{H}|\Psi(t)\rangle "/></p>
<p>To arrive at the challenge gradually, I first omitted the quantum <em>ket</em> notation, the hat on <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H}"/>, and the dependence on <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/>. I wrote partial derivatives and lowercase <img alt="{\psi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\psi}"/>. Thus what I first tried to handwrite was: </p>
<p align="center"><img alt="\displaystyle  i\hbar \frac{\partial \psi}{\partial t} = H\psi " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++i%5Chbar+%5Cfrac%7B%5Cpartial+%5Cpsi%7D%7B%5Cpartial+t%7D+%3D+H%5Cpsi+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  i\hbar \frac{\partial \psi}{\partial t} = H\psi "/></p>
<p>The system jumped on my handwriting right away and I won’t report the results except to say it looked like Dada art with math symbols. One can, however, do a drawing in Paint or similar app and upload it. So I drew</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/schrodingerdrawing/" rel="attachment wp-att-17315"><img alt="" class="aligncenter size-full wp-image-17315" src="https://rjlipton.files.wordpress.com/2020/07/schrodingerdrawing.png?w=600"/></a></p>
<p/><p><br/>
and obtained</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/schrodingerrendered/" rel="attachment wp-att-17316"><img alt="" class="aligncenter wp-image-17316" height="260" src="https://rjlipton.files.wordpress.com/2020/07/schrodingerrendered.jpg?w=360&amp;h=260" width="360"/></a></p>
<p/><p><br/>
The ten cards returned (one is below the snip) have some wild but inspired associations. Handwriting Wikipedia’s form as given did not produce better results. However, I realized I could snip what appears on Wikipedia and upload that:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/schrodingersnip/" rel="attachment wp-att-17317"><img alt="" class="aligncenter size-full wp-image-17317" src="https://rjlipton.files.wordpress.com/2020/07/schrodingersnip.jpg?w=600"/></a></p>
<p/><p><br/>
The result was a ghostly evocation of the equation, with LaTeX to boot:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/schrodingerdada/" rel="attachment wp-att-17318"><img alt="" class="aligncenter wp-image-17318" height="78" src="https://rjlipton.files.wordpress.com/2020/07/schrodingerdada.jpg?w=540&amp;h=78" width="540"/></a></p>
<p/><p><br/>
The LaTeX output reminded me that I could enter Schrödinger’s equation in LaTeX and remove all doubt. I did the short form first. Would the system recognize it?</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/schrodinger1/" rel="attachment wp-att-17319"><img alt="" class="aligncenter wp-image-17319" height="328" src="https://rjlipton.files.wordpress.com/2020/07/schrodinger1.jpg?w=540&amp;h=328" width="540"/></a></p>
<p/><p><br/>
The name <em>Schrödinger</em> popped up in the eighth card at bottom center, but not the form I had typed. It has an integral and no equals sign. Of greater note, the center card called up another giant of quantum mechanics and began with exactly the left-hand side I had typed. To its left came Wolfgang Pauli with another occurrence of <img alt="{i\hbar}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%5Chbar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i\hbar}"/>. None of the output had the time variable <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/>, however, so I put it in:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/schrodinger2/" rel="attachment wp-att-17320"><img alt="" class="aligncenter wp-image-17320" height="349" src="https://rjlipton.files.wordpress.com/2020/07/schrodinger2.jpg?w=540&amp;h=349" width="540"/></a></p>
<p/><p><br/>
Bingo—the card labeled simply <em>Schrödinger Equation</em> appears at upper center. Unlike Wikipedia’s version, it includes <b>r</b> standing for other coordinates and—hence—properly uses partial derivatives. Otherwise it is exactly what my search intended to summon.</p>
<p>
I felt the real reward came in the other cards. I did not know that Hubble’s law had such a simple statement. I knew quantum mechanics takes glory in symmetries, of course, but did not know what equation would bear the definitive moniker, “Symmetry in Quantum Mechanics.” I remember as a child the fun of unstructured time in libraries where the physical card catalog was sorted by theme and one could browse adjacent ideas, as also on the shelves. </p>
<p>
Now I put in the ket notation, the hat to make <img alt="{\hat{H}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Chat%7BH%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\hat{H}}"/>, and the uppercase <img alt="{\Psi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Psi}"/>. The latter two changes evidently moved the <em>Schrödinger Equation</em> card to the top of the deck, with <em>Pauli Equation</em> moving up behind it, but other cards completely changed:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/schrodinger3/" rel="attachment wp-att-17321"><img alt="" class="aligncenter wp-image-17321" height="349" src="https://rjlipton.files.wordpress.com/2020/07/schrodinger3.jpg?w=540&amp;h=349" width="540"/></a></p>
<p/><p><br/>
I had not known the term <em>Einselection</em>. Finally, I decided to wipe the canvas and simply enter <img alt="{H\Psi = E\Psi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%5CPsi+%3D+E%5CPsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H\Psi = E\Psi}"/> as the minimalist form of Schrödinger’s equation. I’ll leave you to see what the system comes up with on your own fresh canvas.</p>
<p>
</p><p/><h2> Search and Research </h2><p/>
<p/><p>
The goal is to augment search that includes equations as well as text. For instance, right now I’d like to find sources that use a formula like </p>
<p align="center"><img alt="\displaystyle  \sum_{r=0}^{\infty}\frac{r^2}{e^{ar}} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Br%3D0%7D%5E%7B%5Cinfty%7D%5Cfrac%7Br%5E2%7D%7Be%5E%7Bar%7D%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \sum_{r=0}^{\infty}\frac{r^2}{e^{ar}} "/></p>
<p>in the context of statistical tests for distinguishing between distributions. I’ve had success with Google on smaller pieces of TeX but this chunk yields nothing sensible. Changing the variable “<img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/>” to “<img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>” changes some of the results but comes no closer; nor does changing to <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> or editing the sum to begin with <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> not <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>. The search should somehow recognize that <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> is a constant but is also the main parameter.</p>
<p>
The fact that I’ve typed a particular LaTeX form might be an impediment. I could have written <img alt="{r^2 e^{-ar}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%5E2+e%5E%7B-ar%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r^2 e^{-ar}}"/> in the body of the sum without using a fraction. The <em>MathDeck</em> documentation focuses on enabling mathematical search for non-LaTeX users, but independence from syntax for all users is a commensurate goal. The idea is to make formulas “chunks” in their own right, chunks governed by semantics more than syntax, and promote saving and recombining them. For instance, I could save the body and replace the sum by an integral. </p>
<p>
The visual unit for this in <em>MathDeck</em> is the blue oval enclosing a formula. They can be created and edited at the top, imported to make a new <em>card</em>, and combined onto the canvas to build up larger formulas. The paper calls them “chips” but for me they evoke hieroglyphic <a href="https://en.wikipedia.org/wiki/Cartouche">cartouches</a> enclosing royal names. Cards can be marked as favorites and the collection added to. </p>
<p>
Here is an example where I made a cartouche and card out of the abstract form of the main equation in my chess model, as I expounded in a <a href="https://rjlipton.wordpress.com/2018/10/18/london-calling/">post</a> to mark the 2018 world chess championship match in London.</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/chessequation/" rel="attachment wp-att-17324"><img alt="" class="aligncenter wp-image-17324" height="368" src="https://rjlipton.files.wordpress.com/2020/07/chessequation.jpg?w=600&amp;h=368" width="600"/></a></p>
<p/><p><br/>
Once again the system pitches in with interesting associations. Some were expected but others are surprises. Logit and logarithmic loss are naturally associated but I had not heard of “Perplexity,” and what is Benford’s Law doing here? (Dick and I have been trying to find natural <em>exceptions</em> to Benford’s Law in Covid-19 statistics—we’ve not had time yet to tell whether we’ll succeed.)</p>
<p>
The searches at top are still “vanilla” Google search, and the search below the canvas is only within a deck or decks. We look forward to when a truly smart integration of mathematics into major search engines will be engendered by this project.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
How do you see <em>MathDeck</em> and the larger <em>MathSeer</em> project growing in the near future? We hope <em>MathDeck</em> stokes some immediate enjoyment and curiosity.</p>
<p/></font></font></div>
    </content>
    <updated>2020-07-18T16:11:54Z</updated>
    <published>2020-07-18T16:11:54Z</published>
    <category term="All Posts"/>
    <category term="News"/>
    <category term="Teaching"/>
    <category term="Anurag Agarwal"/>
    <category term="CiteSeer"/>
    <category term="Clyde Giles"/>
    <category term="Douglas Oard"/>
    <category term="MathDeck"/>
    <category term="mathematical writing"/>
    <category term="MathSeer"/>
    <category term="Richard Zanibbi"/>
    <category term="web search"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-07-21T00:40:09Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-07-17-polynomial-secret-sharing-and-the-lagrange-basis/</id>
    <link href="https://decentralizedthoughts.github.io/2020-07-17-polynomial-secret-sharing-and-the-lagrange-basis/" rel="alternate" type="text/html"/>
    <title>Polynomial Secret Sharing and the Lagrange Basis</title>
    <summary>In this post, we highlight an amazing result: Shamir’s secret sharing scheme. This is one of the most powerful uses of polynomials over a finite field in distributed computing. Intuitively, this scheme allows a $Dealer$ to commit to a secret $s$ by splitting it into shares distributed to $n$ parties....</summary>
    <updated>2020-07-17T18:23:00Z</updated>
    <published>2020-07-17T18:23:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-07-21T00:42:17Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-07-17-the-marvels-of-polynomials-over-a-field/</id>
    <link href="https://decentralizedthoughts.github.io/2020-07-17-the-marvels-of-polynomials-over-a-field/" rel="alternate" type="text/html"/>
    <title>The Marvels of Polynomials over a Field</title>
    <summary>In this series of posts, we explore the mathematical foundations of polynomials over a field. These objects are at the heart of several results in computer science: secret sharing, Multi Party Computation, Complexity, and Zero Knowledge protocols. All this wonder and more can be traced back to a very useful...</summary>
    <updated>2020-07-17T17:55:00Z</updated>
    <published>2020-07-17T17:55:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-07-21T00:42:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7775</id>
    <link href="https://windowsontheory.org/2020/07/17/cfp-symposium-on-simplicity-in-algorithms-sosa/" rel="alternate" type="text/html"/>
    <title>CFP: Symposium on Simplicity in Algorithms (SOSA)</title>
    <summary>[Guest post by Valerie King. TL;DR SOSA 21 will take place jointly with SODA 21. To submit register by August 12, paper deadline August 19.] Call for Papers: Registration deadline August 12, 2020 3rd SIAM Symposium on Simplicity in Algorithms  (SOSA)January 11-12, 2021Alexandria, Virginia, U.S.(Held jointly with SODA 2021) Symposium on Simplicity in Algorithms (SOSA) […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>[Guest post by Valerie King. TL;DR <a href="https://www.siam.org/conferences/cm/conference/sosa21">SOSA 21</a> will take place jointly with SODA 21. To submit register by August 12, paper deadline August 19.] </em></p>



<p><strong>Call for Papers:</strong> Registration deadline August 12, 2020</p>



<p>3rd SIAM <a href="https://www.siam.org/conferences/cm/conference/sosa21">Symposium on Simplicity in Algorithms </a> (SOSA)<br/>January 11-12, 2021<br/>Alexandria, Virginia, U.S.<br/>(Held jointly with SODA 2021)<br/><br/>Symposium on Simplicity in Algorithms (SOSA) is a conference in theoretical computer science dedicated to advancing algorithms research by promoting simplicity and elegance in the design and analysis of algorithms. The benefits of simplicity are manifold: simpler algorithms manifest a better understanding of the problem at hand; they are more likely to be implemented and trusted by practitioners; they can serve as benchmarks, as an initialization step, or as the basis for a “state of the art” algorithm;  they are more easily taught and are more likely to be included in algorithms textbooks; and they attract a broader set of researchers to difficult algorithmic problems.<br/><br/>Papers in all areas of algorithms research are sought.  An ideal submission will advance our understanding of an algorithmic problem by, for example, introducing a simpler algorithm, presenting a simpler analysis of an existing algorithm, or offering insights that generally simplify our understanding of important algorithms or computational problems.<br/><br/>We are especially interested in papers that make material more accessible to a wider audience, such as undergraduates, or for more specialized topics, general algorithms researchers.<br/><br/>Submissions should contain novel ideas or attractive insights, but they are not expected to prove novel theorems. That is, the results themselves can be known, but their presentation must be new. Conference website is <a href="https://www.siam.org/conferences/cm/conference/sosa21" rel="noreferrer noopener" target="_blank">https://www.siam.org/conferences/cm/conference/sosa21</a><br/><br/>Program Committee<br/>Aaron Bernstein, Rutgers University, U.S.<br/>Allan Borodin, University of Toronto, Canada<br/>Timothy Chan, University of Illinois at Urbana-Champaign, U.S.<br/>Edith Cohen, Google Research, U.S. and Tel Aviv University, Israel<br/>Vincent Cohen-Addad, Google Research, Zürich, Switzerland<br/>Sanjoy Dasgupta, University of California, San Diego, U.S.<br/>Michael Elkin, Ben-Gurion University of the Negev, Israel<br/>Funda Ergun, NSF and University of Indiana, Bloomington, U.S.<br/>Mike Fellows, University of Bergen, Norway<br/>Arnold Filtser, Columbia University, U.S.<br/>Kasper Green Larsen,  Aarhus University, Denmark<br/>Andrew Goldberg, Amazon, U.S.<br/>John Iacono, Université libre de Bruxelles, Belgium<br/>Russell Impagliazzo, University of California, San Diego, U.S.<br/>Giuseppe Italiano,   LUISS Guido Carli, Rome, Italy<br/>Michael Kapralov,  École Polytechnique Fédérale de Lausanne (EPFL), Switzerland<br/>Anna Karlin, University of Washington, Seattle, U.S.<br/>Valerie King, University of Victoria, Canada (Co-chair)<br/>Hung Le, University of Victoria, Canada and  University of Massachusetts at Amherst, U.S. (Co-chair)<br/>Daniel Lokshtanov, University of California, Santa Barbara, U.S.<br/>S. Cenk Sahinalp, NIH and University of Indiana, Bloomington, U.S.<br/>Jared Saia, University of New Mexico, U.S.<br/>Shay Solomon, Tel Aviv University, Israel<br/>Mario Szegedy, Alibaba and Rutgers University, U.S.<br/>Robert Tarjan, Princeton University, U.S.<br/>Seeun William Umboh, University of Sydney, Australia<br/>Qin Zhang, University of Indiana, Bloomington, U.S.<br/>Uri Zwick, Tel Aviv University, Israel<br/><br/>Steering Committee<br/>Michael A. Bender, Stony Brook University, U.S.<br/>David Karger,  Massachusetts Institute of Technology, U.S.<br/>Tsvi Kopelowitz, Bar-Ilan University, Israel<br/>Seth Pettie,  University of Michigan, U.S.<br/>Robert Tarjan, Princeton University, U.S.<br/>Mikkel Thorup, University of Copenhagen, Denmark<br/><br/>Submissions and Deadlines:<br/>A link to the submission site is available <a href="https://easychair.org/my/conference?conf=sosa21" rel="noreferrer noopener" target="_blank">https://easychair.org/my/conference?conf=sosa21</a>.<br/>Short Abstract Submission and Paper Registration Deadline: August 12, 2020, 4:59 PM Eastern Time<br/>Full Paper Submission Deadline: August 19, 2020, 4:59 PM Eastern Time<br/>Acceptance Notification: early October 2020<br/>Proceedings (posted online):  early January 2021<br/><br/><br/>How to Participate<br/>Authors must submit their papers electronically, in PDF format.<br/>Submissions should begin with a title page containing the paper title, each author’s name, affiliation, and email address, and an abstract summarizing the contributions of the paper. There is no page limit. The paper should begin with a clear description of the algorithmic problem to be solved, a survey of prior work on the problem—including a candid assessment of prior work in terms of simplicity and elegance—and a discussion of the contributions of the paper. The body of the paper should be written for a general theoretical computer science audience, and substantiate the main claims of the paper with full proofs. The submission should be typeset using 11 point font, in a single-column format with ample spacing throughout and ample margins all around.  The submissions ought to be visually easy to read.<br/>Brevity is a hallmark of simplicity. Authors are specifically encouraged to submit short and simple papers. Final papers may not exceed fifteen (15) pages in double column format.<br/><br/>The program committee may designate one or more papers as SOSA Best Papers. All submissions will be considered.</p></div>
    </content>
    <updated>2020-07-17T17:20:56Z</updated>
    <published>2020-07-17T17:20:56Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-07-21T00:40:31Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/trustmodels/</id>
    <link href="https://differentialprivacy.org/trustmodels/" rel="alternate" type="text/html"/>
    <title>Trust models, and notions of privacy</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>There exist various notions of differential privacy which, while sharing a common core, differ in some key specific aspects. Broadly speaking, vary among a few main axes, such as the type of guarantee they provide, the specific similarity between data they consider, and the trust model they aim to address. This last point will be the focus of this post: <em>which notion of privacy is best suited to the specific scenario at hand?</em></p>

<p>We will cover 4 of these notions.</p>
<ul>
  <li>(central) differential privacy (DP)</li>
  <li>local differential privacy (LDP)</li>
  <li>pan-privacy</li>
  <li>shuffle privacy</li>
</ul>

<p>Typically, the world can be divided in a few categories: (i) the users, who hold the data; (ii) the “server,” who runs the algorithm; and (iii) the rest of the world, which does what the rest of the world does. As the name indicates, the <em>trust model</em> boils down to the following simple question: as a user, <strong>who do you trust</strong> with your sensitive data?</p>

<p>In the <em>DP model</em> <strong>[DMNS06]</strong>, the answer is essentially “the server, and nobody else.” Users are happy to provide their data to the server, which runs the algorithm on the resulting dataset; however, the <em>output</em> of that algorithm, which is released to the (untrusted) world, needs to be private, and not reveal sensitive information about any single user.</p>

<p>In the <em>LDP model</em> <strong>[EGS03,KLNRS08]</strong>, the server itself is untrusted, and the answer is “nobody.” Any data communicated by the users must already be private, and even a prying server cannot learn much about any single user. Of course, this is a strictly more stringent privacy model than the central DP one, and this comes at a price: the utility one can obtain from the same amount of data is typically smaller than in the DP model.</p>

<p>The <em>pan-privacy model</em> <strong>[DNPRY10]</strong> introduces the notion of time. Each user contributes their data to the server sequentially, one after the other; once the server is done receiving and processing this data, the output is revealed to the world. The answer to the question then is that users trust the server <em>at the time they send it their data</em>, but maybe not in the future (and they <em>definitely</em> don’t trust the outside world). Put differently, this captures settings where a server can be compromised: at the time a  user sends their data, they trust the server; if the server is compromised at any point in the future, then the data already in the server <em>stays</em> private (but, of course, sending any more data after the server has already been attacked is a bad idea).</p>

<p>Finally, the recent <em>shuffle model</em> of privacy <strong>[CSUZZ19,EFMRTT19]</strong> is in some sense intermediate between the central and local models of DP: users do not trust the server (and, god forbid, they still don’t trust the outside world!); however, they do trust some small blackbox in the middle, whose role is to randomly, well, <em>shuffle</em> the data. That is, when all users send their data to the untrusted server, this box-in-the-middle randomly permutes all the data points, so that the server had no idea who sent which part of the data. This simple-yet-helpful trusted backbox, in turn, can be implemented using e.g., cryptographic primitives; and the goal is to try and provide stronger privacy than in the DP model, while suffering a smaller utility loss than in the stringent LDP model.</p>

<p>It is important to note that <em>there is no right or wrong model</em> of privacy here, and one cannot say that any of the above notion is “better” than the others with regard to both privacy and accuracy. They all aim at modeling different scenarios, and provide incomparable guarantees: depending on your situation, pick the one that fits best.</p>

<hr/>

<p><strong>[<a href="https://arxiv.org/abs/1808.01394">CSUZZ19</a>]</strong> Albert Cheu, Adam D. Smith, Jonathan Ullman, David Zeber, Maxim Zhilyaev:
<em>Distributed Differential Privacy via Shuffling.</em> EUROCRYPT (1) 2019: 375-403</p>

<p><strong>[<a href="https://journalprivacyconfidentiality.org/index.php/jpc/article/view/405">DMNS06</a>]</strong> Cynthia Dwork, Frank McSherry, Kobbi Nissim, Adam D. Smith:
<em>Calibrating Noise to Sensitivity in Private Data Analysis.</em> TCC 2006: 265-284</p>

<p><strong>[<a href="https://conference.iiis.tsinghua.edu.cn/ICS2010/content/papers/6.html">DNPRY10</a>]</strong> Cynthia Dwork, Moni Naor, Toniann Pitassi, Guy N. Rothblum, Sergey Yekhanin:
<em>Pan-Private Streaming Algorithms.</em> ICS 2010: 66-80</p>

<p><strong>[<a href="https://arxiv.org/abs/1811.12469">EFMRTT19</a>]</strong> Úlfar Erlingsson, Vitaly Feldman, Ilya Mironov, Ananth Raghunathan, Kunal Talwar, Abhradeep Thakurta:
<em>Amplification by Shuffling: From Local to Central Differential Privacy via Anonymity.</em> SODA 2019: 2468-2479</p>

<p><strong>[<a href="https://dl.acm.org/doi/10.1145/773153.773174">EGS03</a>]</strong> Alexandre V. Evfimievski, Johannes Gehrke, Ramakrishnan Srikant:
<em>Limiting privacy breaches in privacy preserving data mining.</em> PODS 2003: 211-222</p>

<p><strong>[<a href="https://arxiv.org/abs/0803.0924">KLNRS08</a>]</strong> Shiva Prasad Kasiviswanathan, Homin K. Lee, Kobbi Nissim, Sofya Raskhodnikova, Adam D. Smith:
<em>What Can We Learn Privately?</em> FOCS 2008: 531-540</p></div>
    </summary>
    <updated>2020-07-17T15:45:00Z</updated>
    <published>2020-07-17T15:45:00Z</published>
    <author>
      <name>Clément Canonne</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2020-07-21T00:42:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/07/17/postdoc-at-harvard-apply-by-august-3-2020/</id>
    <link href="https://cstheory-jobs.org/2020/07/17/postdoc-at-harvard-apply-by-august-3-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at Harvard (apply by August 3, 2020)</title>
    <summary>Funding for a research project on the use of AI techniques, specifically imitation learning and deep multi-agent reinforcement learning, for economic design. The ideal researcher will have a technical background in an area related to computer science and economics, especially machine learning; experience with economic theory is desirable but not required. Website: http://www.eecs.harvard.edu/~parkes/7-20EconAI-postdocad2.pdf Email: PARKES@EECS.HARVARD.EDU</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Funding for a research project on the use of AI techniques, specifically imitation learning and deep multi-agent reinforcement learning, for economic design. The ideal researcher will have a technical background in an area related to computer science and economics, especially machine learning; experience with economic theory is desirable but not required.</p>
<p>Website: <a href="http://www.eecs.harvard.edu/~parkes/7-20EconAI-postdocad2.pdf">http://www.eecs.harvard.edu/~parkes/7-20EconAI-postdocad2.pdf</a><br/>
Email: PARKES@EECS.HARVARD.EDU</p></div>
    </content>
    <updated>2020-07-17T12:08:27Z</updated>
    <published>2020-07-17T12:08:27Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-21T00:40:14Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/welcome/</id>
    <link href="https://differentialprivacy.org/welcome/" rel="alternate" type="text/html"/>
    <title>Welcome to DifferentialPrivacy.org!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Hello, welcome to this new website! Our goal is to serve as a hub for the differential privacy research community and to promote the work in this area. Please read on to learn more!</p>

<p>We anticipate posting a variety of content, from announcements to mini-surveys of topics in the differential privacy literature. These are archived on our <a href="https://differentialprivacy.org/categories/">Posts</a> page. 
We have also assembled a collection of <a href="https://differentialprivacy.org/resources/">Resources</a>, which we hope will help newcomers learn and enter the field.</p>

<p>We have created a <a href="https://groups.google.com/forum/#!forum/differential-privacy-org">mailing list</a> for the differential privacy community. 
The goal is to create a channel which could reach the entire differential privacy community at once.
We envision this list being used only to send out announcements of the most broad interest, and as such, it is anticipated to be very low-traffic (≈ 1 post per month). 
Click <a href="https://groups.google.com/forum/#!forum/differential-privacy-org/join">here</a> to join.</p>

<p>To follow the latest updates on DifferentialPrivacy.org, you can:</p>
<ol>
  <li>Follow us on <a href="https://twitter.com/DiffPriv">Twitter</a></li>
  <li>Subscribe to our <a href="https://differentialprivacy.org/feed.xml">RSS feed</a></li>
  <li>Sign up for <a href="https://feedburner.google.com/fb/a/mailverify?uri=DifferentialPrivacy">email updates</a> (note: distinct from the Google Groups mailing list)</li>
  <li>Set this website to be your homepage ;)</li>
</ol>

<p>This is a community-driven effort and we welcome participation. 
If you are interested in contributing, please reach out to us (by email or in the comments below). 
Further details are on <a href="https://differentialprivacy.org/about/">About</a> and <a href="https://github.com/differentialprivacy/differentialprivacy">Github</a>.</p>

<p>To get things started, here is a definition:</p>

<blockquote>
  <p><strong>Definition 1.</strong> [<a href="https://journalprivacyconfidentiality.org/index.php/jpc/article/view/405">DMNS06</a>, <a href="https://www.iacr.org/archive/eurocrypt2006/40040493/40040493.pdf">DKMMN06</a>]</p>

  <p>A randomized algorithm \(M : \mathcal{X}^n \to \mathcal{Y}\) is \((\varepsilon,\delta)\)-differentially private if, for all \(x,x’ \in \mathcal{X}^n\) differing on a single entry and all measurable \(E \subseteq \mathcal{Y}\), we have \[\mathbb{P}[M(x) \in E] \le e^\varepsilon \cdot \mathbb{P}[M(x’) \in E]  + \delta.\]</p>
</blockquote></div>
    </summary>
    <updated>2020-07-17T01:00:00Z</updated>
    <published>2020-07-17T01:00:00Z</published>
    <author>
      <name>Zhiwei Steven Wu</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2020-07-21T00:42:23Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/07/16/comparing-multi-sport</id>
    <link href="https://11011110.github.io/blog/2020/07/16/comparing-multi-sport.html" rel="alternate" type="text/html"/>
    <title>Comparing multi-sport athletes using bounding-box area</title>
    <summary>Where you have a triangle center defined by the intersection point of three lines or curves, you often also have a Voronoi diagram or minimization diagram whose cells have those lines as boundaries. For the circumcenter, equidistant from the three vertices of a triangle, the diagram is the classical Voronoi diagram of those three points. For the incenter, equidistant from the three sides, the diagram is the medial axis of the triangle. The Fermat point (when it doesn’t degenerate to a vertex) comes from a diagram that tells you which of the three sides of the triangle spans the widest field of view.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Where you have a <a href="https://en.wikipedia.org/wiki/Triangle_center">triangle center</a> defined by the intersection point of three lines or curves, you often also have a <a href="https://en.wikipedia.org/wiki/Voronoi_diagram">Voronoi diagram</a> or minimization diagram whose cells have those lines as boundaries. For the <a href="https://en.wikipedia.org/wiki/Circumscribed_circle">circumcenter</a>, equidistant from the three vertices of a triangle, the diagram is the classical Voronoi diagram of those three points. For the <a href="https://en.wikipedia.org/wiki/Incenter">incenter</a>, equidistant from the three sides, the diagram is the <a href="https://en.wikipedia.org/wiki/Medial_axis">medial axis</a> of the triangle. The <a href="https://en.wikipedia.org/wiki/Fermat_point">Fermat point</a> (when it doesn’t degenerate to a vertex) comes from a diagram that tells you which of the three sides of the triangle spans the widest field of view.</p>

<p>So when I posted recently about <a href="https://11011110.github.io/blog/2020/04/28/cartesian-triangle-centers.html">Cartesian triangle centers</a> defined by an equality of areas of three bounding boxes, I had in mind a minimization diagram for bounding box area, or actually the signed area  of the bounding box of the moving point  and a fixed site . Here’s one of these diagrams for six points:</p>

<p style="text-align: center;"><img alt="Minimization diagram for signed bounding box area" src="https://11011110.github.io/blog/assets/2020/bounding-box-diagram.svg"/></p>

<p>If you subtract  from the signed areas, you don’t change the minimization diagram (because you’re subtracting the same thing from all the signed areas) but it makes the functions you’re minimizing become linear in  and , explaining the polygonal shape and linear boundaries of the cells in the minimization diagram. As the previous post already described, the bisector between any two cells is the diagonal line of the bounding box of two sites.</p>

<p>I use these diagrams in a paper to appear in the Canadian Conference on Computational Geometry, now online as a preprint: “Dynamic products of ranks” (<a href="https://arxiv.org/abs/2007.08123">arXiv:2007.08123</a>). The goal of the paper is to combine two different and unrelated numerical scores of the same items such as the skiing speed and shooting accuracy of a group of <a href="https://en.wikipedia.org/wiki/Biathlon">biathletes</a>. Biathlons do this by using an arbitrary conversion factor to penalize skiing time based on shooting misses (essentially, adding the converted scores from the two parts of the sport) but instead some other sports multiply the ranks of the athletes within each discipline. So if you got, say, fifth in shooting but second in skiing, your overall score would be ten. My paper studies how quickly you can find the new winner after changing the score of a single competitor or by adding or removing a competitor in a sport using this system.</p>

<p>We can represent a set of items or group of athletes as points in the plane, whose coordinates are their ranks (not their raw scores). Then an update to the data that lies outside both the horizontal and vertical range of these points doesn’t change their relative positions: it might change their ranks, but all in the same way. So for these updates, the signed bounding box area minimization diagram stays unchanged. Because the bounding box area is just the product of ranks, we can use this diagram to quickly look up the winner among these shifted points. The overall strategy of the data structure in my paper is to divide the input data into smaller subsets and maintain their diagrams in such a way that most diagrams stay unchanged, and only a few need rebuilding, after each update. Dividing into more subsets reduces the rebuilding time, because fewer input items will belong to rebuilt diagrams, but increases the query time, because you have to query more diagrams. The  update time for the data structure in the paper comes from choosing the optimal tradeoff between these two terms of the total time.</p>

<p>There are other applications for this sort of rank aggregation beyond athletics; see the paper for details.</p>

<p>Because CCCG is online this year, I also have a video talk prepared, but it’s not yet online; I’ll post a link later. In the meantime, <a href="http://vga.usask.ca/cccg2020/">registration for CCCG is free this year, with a deadline of July 25</a>, and enables both early access to the videos and access to the Q&amp;A sessions with each speaker at the conference itself.</p></div>
    </content>
    <updated>2020-07-16T18:12:00Z</updated>
    <published>2020-07-16T18:12:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-07-17T01:13:58Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/07/15/linkage</id>
    <link href="https://11011110.github.io/blog/2020/07/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>A stained glass window of a Latin square () will be removed from Cambridge University because it honors prominent eugenicist R. A. Fisher. The window visualizes a nice piece of mathematics, with a long history that surprisingly originates in Korea (predating Euler) but in context among windows celebrating Cambridge luminaries it could not be separated from Fisher’s racist history, so it’s sad but I think it’s the right decision.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p>A <a href="https://en.wikipedia.org/wiki/Sir_Ronald_Fisher_window">stained glass window of a Latin square</a> (<a href="https://mathstodon.xyz/@11011110/104440661362867680"/>) will be <a href="https://www.theguardian.com/education/2020/jun/27/cambridge-gonville-caius-college-eugenicist-window-ronald-fisher">removed from Cambridge University</a> because it honors <a href="https://en.wikipedia.org/wiki/Ronald_Fisher">prominent eugenicist R. A. Fisher</a>. The window visualizes a nice piece of mathematics, with a long history that surprisingly originates in Korea (predating Euler) but in context among windows celebrating Cambridge luminaries it could not be separated from Fisher’s racist history, so it’s sad but I think it’s the right decision.</p>
  </li>
  <li>
    <p>What is it about <em>Quanta</em>’s oversimplifications (<a href="https://mathstodon.xyz/@11011110/104448448945740867"/>)?  A <a href="https://www.quantamagazine.org/new-geometric-perspective-cracks-old-problem-about-rectangles-20200625/">recent article</a> is on a variation of the problem of <a href="https://en.wikipedia.org/wiki/Inscribed_square_problem">squares in Jordan curves</a>, known to exist in smooth curves but unknown for some nastier ones. The new result described by <em>Quanta</em> concerns <a href="https://arxiv.org/abs/2005.09193">rectangles of given aspect ratio in smooth Jordan curves</a>. Wikipedia editors have had to fend off repeated edits by Quanta readers who came away thinking the new paper solved the original problem. It doesn’t.</p>
  </li>
  <li>
    <p><a href="http://www.mseymour.ca/hex_puzzle/hexpuzzle.html">Hex puzzles by Matthew Seymour</a> (<a href="https://mathstodon.xyz/@jsiehler/104412077950183358"/>). 500 of them, designed to guide you to greater Hex mastery, in an online applet. In the Mastodon post, Jacob Siehler explains that he can justify playing with these as work, because it relates to an upcoming course he’s teaching.</p>
  </li>
  <li>
    <p><a href="http://www.dam.brown.edu/people/mumford/blog/2020/Ridiculous.html">David Mumford on the long history of ridiculous word problems in mathematics</a> (<a href="https://mathstodon.xyz/@11011110/104462285880982461"/>, <a href="https://news.ycombinator.com/item?id=23739243">via</a>).</p>
  </li>
  <li>
    <p>A tiny improvement sometimes makes for a big result (<a href="https://mathstodon.xyz/@11011110/104465689831962167"/>): In a new preprint “<a href="https://arxiv.org/abs/2007.01409">A (Slightly) Improved Approximation Algorithm for Metric TSP</a>”, Anna Karlin, Nathan Klein, and Shayan Oveis Gharan claim a reduction in the approximation ratio for traveling salesperson in arbitrary metric spaces from  to . But it’s the first such improvement since Christofides and Serdyukov in 1976, on a central problem in approximation algorithms.</p>
  </li>
  <li>
    <p><a href="https://www.ice.gov/news/releases/sevp-modifies-temporary-exemptions-nonimmigrant-students-taking-online-courses-during">US Department of Homeland Security tried to require foreign students in the US to either attend in-person classes or leave the country</a> (<a href="https://mathstodon.xyz/@11011110/104468994612372729"/>, <a href="https://news.ycombinator.com/item?id=23751931">via</a>, <a href="https://www.nbcnews.com/politics/immigration/ice-tells-foreign-students-leave-u-s-if-their-school-n1233026">see also</a>). After facing pushback in the courts, they gave up. But while it was happening, it had the appearance of pressuring US universities into opening up in-person classes despite the ongoing pandemic, using the threat of taking away all of their foreign students.</p>
  </li>
  <li>
    <p><a href="https://www.ams.org/news?news_id=6244">Sad news from the AMS: Ron Graham has died</a> (<a href="https://mathstodon.xyz/@11011110/104477077422403456"/>). See also the blog posts about him by <a href="https://www.solipsys.co.uk/new/MeetingRonGraham.html?tg08mn">Lipton and Regan</a>, <a href="https://blog.computationalcomplexity.org/2020/07/ronald-graham-summary-of-blog-posts-we.html">Gasarch</a>, <a href="https://blog.plover.com/math/graham.html">Dominus</a>, <a href="https://www.bradyharanblog.com/blog/the-day-i-met-ron-graham">Haran</a>, and (mostly from earlier) <a href="https://www.solipsys.co.uk/new/MeetingRonGraham.html?tg08mn">Wright</a>.</p>
  </li>
  <li>
    <p><a href="http://paulbourke.net/miscellaneous/reverseperspective/">Experiments on reverse perspective</a> (<a href="https://mathstodon.xyz/@11011110/104486648345638828"/>), recent post by Paul Bourke with a link to a recent video, “<a href="https://www.youtube.com/watch?v=iJ4yL6kaV1A">Hypercentric optics</a>” by Ben Krasnow, showing how to achieve reverse perspective physically using a giant Fresnel lens.</p>
  </li>
  <li>
    <p><a href="https://eccc.weizmann.ac.il/report/2020/096/">On the asymptotic complexity of sorting</a> (<a href="https://mathstodon.xyz/@11011110/104493642072558461"/>), Igor Sergeev. We still study the number of comparisons for sorting in introductory CS, although other factors like locality of reference may be more important in practice. Common topics are the  comparison-tree lower bound and the nearly-matching  merge sort upper bound. Better sorts were known but still with an  error term. Now Sergeev has reduced the error term <span style="white-space: nowrap;">to .</span></p>
  </li>
  <li>
    <p>A messy story of unethical doings at ISCA, a major computer architecture conference (<a href="https://mathstodon.xyz/@11011110/104496752991792669"/>, <a href="https://retractionwatch.com/2020/07/11/weekend-reads-a-paper-mill-science-needs-to-clean-its-own-house-is-the-covid-19-retraction-rate-exceptionally-high/">via</a>):</p>

    <ul>
      <li>
        <p>Junk research accepted to ISCA <a href="https://medium.com/@huixiangvoice/the-hidden-story-behind-the-suicide-phd-candidate-huixiang-chen-236cd39f79d3">causes its student coauthor to kill himself</a>.</p>
      </li>
      <li>
        <p>The ensuing investigation brings to light apparent serious breaches of ISCA’s double-blind reviewing process, but <a href="https://medium.com/@huixiangvoice/evidence-put-doubts-on-the-ieee-acms-investigation-991a6d50802a">ACM and IEEE find no wrongdoing</a>.</p>
      </li>
      <li>
        <p>A <a href="https://www.natureindex.com/news-blog/probe-into-leaked-papers-submitted-to-leading-engineering-conference">somewhat-confused description of the affair hits <em>Nature</em></a>.</p>
      </li>
    </ul>
  </li>
  <li>
    <p><a href="https://www.latimes.com/world-nation/story/2020-06-27/in-chinas-universities-targeted-attacks-on-intellectuals-raise-memories-of-the-cultural-revolution">“Spied on. Fired. Publicly shamed. China’s crackdown on professors reminds many of Mao era.”</a> (<a href="https://mathstodon.xyz/@11011110/104513232965232968"/>). (If the paywalled <em>LA Times</em> link is a problem, <a href="https://beta.trimread.com/">trimread</a> might help.)</p>
  </li>
  <li>
    <p><a href="https://www.flyingcoloursmaths.co.uk/ask-uncle-colin-a-fraction-of-a-square/">A cute dissection proof of an area calculation of a tilted square within a square</a> (<a href="https://mathstodon.xyz/@11011110/104516441062427682"/>). But to generalize from there to: tick marks that split the sides in the ratio  (in this example, 1:2) give a ratio of areas of the inner tilted square to the outer square that is  (in this case 4:10, simplifying to 2:5) it seems easier to apply similar triangles and then use Pythagoras in the tilted grid.</p>
  </li>
  <li>
    <p><a href="https://www.efavdb.com/quinoa%20packing">Quinoa packing 2 + 1 = 4</a> (<a href="https://mathstodon.xyz/@11011110/104520918846919905"/>, <a href="https://news.ycombinator.com/item?id=23727749">via</a>). This blog post theorizes that the combination of 2 cups of water and 1 cup of quinoa to form 4 cups of cooked quinoa might happen because the water fills the spaces between the grains before cooking, but merges into the grains causing them to pack like spheres with air pockets between them afterwards. On the other hand, maybe they just expand into a less-dense combination of materials that takes more room.</p>
  </li>
</ul></div>
    </content>
    <updated>2020-07-15T22:20:00Z</updated>
    <published>2020-07-15T22:20:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-07-17T01:13:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/106</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/106" rel="alternate" type="text/html"/>
    <title>TR20-106 |  Explicit Extremal Designs and Applications to Extractors | 

	Eshan Chattopadhyay, 

	Jesse Goodman</title>
    <summary>An $(n,r,s)$-design, or $(n,r,s)$-partial Steiner system, is an $r$-uniform hypergraph over $n$ vertices with pairwise hyperedge intersections of size $0$, we extract from $(N,K,n,k)$-adversarial sources of locality $0$, where $K\geq N^\delta$ and $k\geq\text{polylog }n$. The previous best result (Chattopadhyay et al., STOC 2020) required $K\geq N^{1/2+o(1)}$. As a result, we get extractors for small-space sources over $n$ bits with entropy requirement $k\geq n^{1/2+\delta}$, whereas the previous best result (Chattopadhyay et al., STOC 2020) required $k\geq n^{2/3+\delta}$.</summary>
    <updated>2020-07-15T16:25:04Z</updated>
    <published>2020-07-15T16:25:04Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-21T00:39:47Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-07-15-asynchronous-fault-tolerant-computation-with-optimal-resilience/</id>
    <link href="https://decentralizedthoughts.github.io/2020-07-15-asynchronous-fault-tolerant-computation-with-optimal-resilience/" rel="alternate" type="text/html"/>
    <title>Asynchronous Fault Tolerant Computation with Optimal Resilience</title>
    <summary>A basic question of distributed computing: Is there a fundamental limit to fault tolerant computation in the Asynchronous model? The celebrated FLP theorem says that any protocol that solves Agreement in the asynchronous model that is resilient to at least one crash failure must have a non-terminating execution. This means...</summary>
    <updated>2020-07-15T08:39:00Z</updated>
    <published>2020-07-15T08:39:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-07-21T00:42:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/105</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/105" rel="alternate" type="text/html"/>
    <title>TR20-105 |  Automating Regular or Ordered Resolution is NP-Hard | 

	Zoë Bell</title>
    <summary>We show that is hard to find regular or even ordered (also known as Davis-Putnam) Resolution proofs, extending the breakthrough result for general Resolution from Atserias and Müller to these restricted forms. Namely, regular and ordered Resolution are automatable if and only if P = NP. Specifically, for a CNF formula $F$ the problem of distinguishing between the existence of a polynomial-size ordered Resolution refutation of $F$ and an at least exponential-size general Resolution proof being required to refute $F$ is NP-complete.</summary>
    <updated>2020-07-14T13:43:02Z</updated>
    <published>2020-07-14T13:43:02Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-21T00:39:47Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2020/07/14/there-are-none/</id>
    <link href="http://benjamin-recht.github.io/2020/07/14/there-are-none/" rel="alternate" type="text/html"/>
    <title>There are none</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In the <a href="http://www.argmin.net/2020/07/08/gain-margin/">last post</a>, we showed that continuous-time LQR has “natural robustness” insofar as the optimal solution is robust to a variety of model-mismatch conditions. LQR makes the assumption that the state of the system is fully, perfectly observed. In many situations, we don’t have access to such perfect state information. What changes?</p>

<p>The generalization of LQR to the case with imperfect state observation is called “Linear Quadratic Gaussian” control (LQG). This is the simplest, special case of a Partially Observed Markov Decision Process (POMDP). We again assume linear dynamics:</p>



<p>where the state is now corrupted by zero-mean Gaussian noise, $w_t$. Instead of measuring the state $x_t$ directly, we instead  measure a signal $y_t$ of the form</p>



<p>Here, $v_t$ is also zero-mean Gaussian noise. Suppose we’d still like to minimize a quadratic cost function</p>



<p>This problem is very similar to our LQR problem except for the fact that we get an indirect measurement of the state and need to apply some sort of <em>filtering</em> of the $y_t$ signal to estimate $x_t$.</p>

<p>The optimal solution for LQG is strikingly elegant. Since the observation of $x_t$ is through a Gaussian process, the maximum likelihood estimation algorithm has a clean, closed form solution, even in continuous time. Our best estimate for $x_t$, denoted $\hat{x}_t$, given all of the data observed up to time $t$ obeys a differential equation</p>



<p>The matrix $L$ that can be found by solving an algebraic Riccati equation that depends on the variance of $v_t$ and $w_t$ and on the matrices $A$ and $C$. In particular, it’s the CARE with data $(A^\top,C^\top,\Sigma_w,\Sigma_v)$. This solution is called a <em>Kalman Filter</em> and is a continuous limit of the discrete time Kalman Filter one might see in a course on graphical models.</p>

<p>The optimal LQG solution takes the estimate of the Kalman Filter, $\hat{x}_t$, and sets the control signal to be</p>



<p>Here, $K$ is gain matrix that would be used to solve the LQR problem with data $(A,B,Q,R)$. That is, LQG performs optimal filtering to compute the best state estimate, and then computes a feedback policy as if this estimate was a noiseless measurement of the state. That this turns out to be optimal is one of the more amazing results in control theory. It decouples the process of designing an optimal filter from designing an optimal controller, enabling simplicity and modularity in control design. This decoupling where we treat the output of our state estimator as the true state is an example of <em>certainty equivalence</em>, the umbrella term for using point estimates of stochastic quantities as if they were the correct value. Though certainty equivalent control may be suboptimal in general, it remains ubiquitous for all of the benefits it brings as a design paradigm. Unfortunately, not only is this decoupled design of filters and controllers often suboptimal, it has many hidden fragilities. LQG highlights a particular scenario where certainty equivalent control leads to misplaced optimism about robustness.</p>

<p>We saw in the previous post that LQR had this amazing robustness property: even if you optimize with the wrong model, you’ll still probably be OK. Is the same true about LQG? What are the guaranteed stability margins for LQG regulators? The answer was succinctly summed up in the <a href="https://ieeexplore.ieee.org/document/1101812">abstract of a 1978 paper by John Doyle</a>: “There are none.”</p>

<p class="center"><img alt="There Are None" src="http://www.argmin.net/assets/there_are_none.png" width="400px"/></p>

<p>What goes wrong? Doyle came up with a simple counterexample, that I’m going to simplify even further for the purpose of contextualizing in our modern discussion. Before presenting the example, let’s first dive into <em>why</em> LQG is likely less robust than LQR. Let’s assume that the true dynamics obeys the ODE:</p>



<p>though we computed the optimal controller with the matrix $B$. Define an error signal, $e_t = x_t - \hat{x}_t$, that measures the current deviation between the actual state and the estimate. Then, using the fact that $u_t = -K \hat{x}_t$, we get the closed loop dynamics</p>



<p>When $B=B_\star$, the bottom left block is equal to zero. The system is then stable provided $A-BK$ and $A-LC$ are both stable matrices (i.e., have eigenvalues in the left half plane). However, small perturbations in the off-diagonal block can make the matrix unstable. For intuition, consider the matrix</p>



<p>The eigenvalues of this matrix are $-1$ and $-2$, so the matrix is clearly stable. But the matrix</p>



<p>has an eigenvalue greater than zero if $t&gt;0.01$. So a tiny perturbation significantly shifts the eigenvalues and makes the matrix unstable.</p>

<p>Similar things happen in LQG. In Doyle’s example he uses the problem instance:</p>







<p>The open loop system here is unstable, having two eigenvalues at $1$. We can stabilize the system only by modifying the second state. The state disturbance is aligned along the $[1;1]$ direction, and the state cost only penalizes states aligned with this disturbance. So the goal is simply to remove as much signal as possible in the $[1;1]$ direction without using too much control authority. We only are able to measure the first component of the state, and this measurement is corrupted by Gaussian noise.</p>

<p>What does the optimal policy look like? Perhaps unsurprisingly, it focuses all of its energy on ensuring that there is little state signal along the disturbance direction. The optimal $K$ and $L$ matrices are</p>



<p>Now what happens when we have model mismatch? If we set $B_\star=tB$ and use the formula for the closed loop above, we see that closed loop state transition matrix is</p>



<p>It’s straight forward to check that when $t=1$ (i.e., no model mismatch), the eigenvalues of  $A-BK$ and $A-LC$ all have negative real parts. For the full closed loop matrix, analytically computing the eigenvalues themselves is a pain, but we can prove instability by looking at the characteristic polynomial. For a matrix to have all of its eigenvalues in the left half plane, its characteristic polynomial necessarily must have all positive coefficients. If we look at the linear term in the polynomial, we see that we must have</p>



<p>if we’d like any hope of having a stable system. Hence, we can guarantee that this closed loop system is unstable if $t\geq 1+\sigma$. This is a very conservative condition, and we could get a tighter bound if we’d like, but it’s good enough to reveal some paradoxical properties of LQG. The most striking is that if we build a sensor that gives us a better and better measurement, our system becomes more and more fragile to perturbation and model mismatch. For machine learning scientists, this seems to go against all of our training. How can a system become <em>less</em> robust if we improve our sensing and estimation?</p>

<p>Let’s look at the example in more detail to get some intuition for what’s happening. When the sensor noise gets small, the optimal Kalman Filter is more aggressive. If the model is true, then the disturbance has equal value in both states, so, when $\sigma$ is small, the filter can effectively just set the value of the second state to be equal to whatever is in the first state. The filter is effectively deciding that the first state should equal the observation $y_t$, and the second state should be equal to the first state. In other words, it rapidly damps any errors in the disturbance direction $[1;1]$ and, as $d$ increases, it damps the $[0;1]$ direction less. When $t \neq 1$, we are effectively introducing a disturbance that makes the two states unequal. That is, $B-B_\star$ is aligned in the $[0;1]$ and can be treated as a disturbance signal. This undamped component of the error is fed errors from the state estimate $\hat{x}$, and these errors compound each other. Since we spend so much time focusing on our control along the direction of the injected state noise, we become highly susceptible to errors in a different direction and these are the exact errors that occur when there is a gain mismatch between the model and reality.</p>

<p>The fragility of LQG has many takeaways. It highlights that noiseless state measurement can be a dangerous modeling assumption, because it is then optimal to trust our model too much. Though we apparently got a freebie with LQR, for LQG, model mismatch must be explicitly accounted for when designing the controller.</p>

<p>This should be a cautionary tale for modern AI systems. Most of the papers I read in reinforcement learning consider MDPs where we get perfect state measurement. Building an entire field around optimal actions with perfect state observation builds too much optimism. Any realistic scenario is going to have partial state observation, and such problems are much thornier.</p>

<p>A second lesson is that it is not enough to just improve the prediction components in feedback systems that are powered by machine learning. I have spoken with many applied machine learning engineers who have told me that they have seen performance degrade in production systems when they improve their prediction model. They might spend months building some state of the art LSTM mumbo jumbo that is orders of magnitude more accurate in prediction, but in production yields worse performance than the legacy system with a boring ARMA model. It is quite possible that these performance drops are due to the Doyle effect: the improved prediction system is increasing sensitivity to a modeling flaw in some other part of the engineering pipeline.</p>

<p>The story turns out to be even worse than what I have described thus far. The supposed robustness guarantees we derived for LQR assume not just full noiseless state measurement, but that the sensors and actuators have infinite bandwidth. That is, they assume you can build controllers $K$ with arbitrarily large entries and that react instantaneously, without delay, to changes in the state. In the next post, I’ll show how realistic sampled data controllers for LQR, even with noiseless state measurement, also have no guarantees.</p></div>
    </summary>
    <updated>2020-07-14T00:00:00Z</updated>
    <published>2020-07-14T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2020-07-21T00:41:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=3843</id>
    <link href="https://francisbach.com/gradient-descent-for-wide-two-layer-neural-networks-implicit-bias/" rel="alternate" type="text/html"/>
    <title>Gradient descent for wide two-layer neural networks – II: Generalization and implicit bias</title>
    <summary>In this blog post, we continue our investigation of gradient flows for wide two-layer “relu” neural networks. In the previous post, Francis explained that under suitable assumptions these dynamics converge to global minimizers of the training objective. Today, we build on this to understand qualitative aspects of the predictor learnt by such neural networks. The...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text">In this blog post, we continue our investigation of gradient flows for wide two-layer “relu” neural networks. In the <a href="https://francisbach.com/gradient-descent-neural-networks-global-convergence/">previous post</a>, Francis explained that under suitable assumptions these dynamics converge to global minimizers of the training objective. Today, we build on this to understand qualitative aspects of the predictor learnt by such neural networks. The content is mostly based on our recent joint work [<a href="https://arxiv.org/pdf/2002.04486.pdf">1</a>].</p>



<h2>1. Generalization with weight decay regularization</h2>



<p class="justify-text">Let us start our journey with the comfortable case where the training objective includes an explicit <em>weight decay</em> regularization (i.e. \(\ell_2\)-regularization on the parameters). Using the notations of the previous post, this consists in the following objective function on the space of probability measures on \(\mathbb{R}^{d+1}\):  $$ \underbrace{R\Big(\int_{\mathbb{R}^{d+1}} \Phi(w)d\mu(w)\Big)}_{\text{Data fitting term}} + \underbrace{\frac{\lambda}{2} \int_{\mathbb{R}^{d+1}} \Vert w \Vert^2_2d\mu(w)}_{\text{Regularization}} \tag{1}$$ where \(R\) is the loss and \(\lambda&gt;0\) is the regularization strength. Remember that a  neural network of finite width with \(m\) neurons is recovered with an empirical measure \(\mu = \frac1m \sum_{j=1}^m\delta_{w_j}\), in which case this regularization is proportional to the sum of the squares of all the parameters \(\frac{\lambda}{2m}\sum_{j=1}^m \Vert w_j\Vert^2_2\).</p>



<p class="justify-text"><strong>Variation norm.</strong> In the previous post, we have seen that the Wasserstein gradient flow of this objective function — an idealization of the gradient descent training dynamics in the large width limit — converges to a global minimizer \(\mu^*\) when initialized properly. An example of an admissible initialization is the hidden weights \(b_j\) distributed according to the uniform distribution \(\tau\) on the unit sphere \(\mathbb{S}^{d-1}\subset \mathbb{R}^d\) and the output weights \(a_j\) uniform in \(\{-1,1\}\). What does this minimizer look like in predictor space when the objective function is as in Eq. (1) ? </p>



<p class="justify-text">To answer this question, we define for a predictor \(h:\mathbb{R}^d\to \mathbb{R}\), the quantity $$ \Vert h \Vert_{\mathcal{F}_1} := \min_{\mu \in \mathcal{P}(\mathbb{R}^{d+1})} \frac{1}{2} \int_{\mathbb{R}^{d+1}} \Vert w\Vert^2_2 d\mu(w) \quad \text{s.t.}\quad h = \int_{\mathbb{R}^{d+1}} \Phi(w)d\mu(w).\tag{2} $$ As the notation suggests, \(\Vert \cdot \Vert_{\mathcal{F}_1}\) is a norm in the space of predictors. It is known as the <em>variation norm</em> [<a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">2</a>, <a href="https://www.cs.cas.cz/~vera/publications/journals/I3Edin.pdf">3</a>]. We call \(\mathcal{F}_1\) the space of functions with finite norm, which is a Banach space. By construction, the learnt predictor \(h^* = \int \Phi(w)d\mu^*(w)\) is a minimizer of the \(\mathcal{F}_1\)-regularized regression: $$ \min_{h:\mathbb{R}^d\to \mathbb{R}} R(h) + \lambda \Vert h \Vert_{\mathcal{F}_1} \tag{3}.$$ This \(\mathcal{F}_1\)-norm regularization shares similarity with \(\ell_1\) regularization [<a href="https://arxiv.org/pdf/1412.6614.pdf">4</a>]. To see this, observe that the “magnitude” \(\vert a\vert \Vert b\Vert_2\) of a relu function \(x\mapsto a(b^\top x)_+\) with parameter \(w=(a,b)\) equals \(\Vert w\Vert^2_2/2\) if \(\vert a\vert = \Vert b\Vert_2\) and is smaller otherwise. Thus parameterizing the relus by their direction \(\theta = b/\Vert b\Vert_2\) and optimizing over their signed magnitude \(r(\theta) = a\Vert b\Vert_2\)  we have $$ \Vert h \Vert_{\mathcal{F}_1} = \inf_{r:\mathbb{S}^{d-1}\to \mathbb{R}} \int_{\mathbb{S}^{d-1}} \vert r(\theta)\vert d\tau(\theta) \quad \text{s.t.}\quad h(x) = \int _{\mathbb{S}^{d-1}} r(\theta) (\theta^\top x)_+ d\tau(\theta).\tag{4}$$</p>



<p class="justify-text"><strong>Conjugate RKHS norm.</strong> The regression in the space \(\mathcal{F}_1\) is best understood when compared with the regression obtained by only training the output weights. We consider the same training dynamics with weight decay except that we fix the hidden weights to their initial value, where they are distributed according to the uniform distribution \(\tau\) on the sphere. In that case, the Wasserstein gradient flow also converges to the solution of a regularized regression as in Eq. (3) — this is in fact a convex problem —  but the regularizing norm is different and now defined as $$ \Vert h \Vert_{\mathcal{F}_2}^2 := \min_{r:\mathbb{S}^{d-1}\to \mathbb{R}} \int_{\mathbb{S}^{d-1}} \vert r(\theta)\vert^2 d\tau(\theta) \quad \text{s.t.}\quad h(x) = \int _{\mathbb{S}^{d-1}} r(\theta) (\theta^\top x)_+ d\tau(\theta).$$ We call \(\mathcal{F}_2\) the set of functions with finite norm. It can be shown to be a <a href="https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space">Reproducing Kernel Hilbert Space</a> (RKHS), with kernel  $$ K(x,x’) = \int_{\mathbb{S}^{d-1}} (\theta^\top x)_+ (\theta^\top x’)_+ d\tau(\theta),$$ which has a closed form expression [<a href="https://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf">5</a>]. In this context, taking a finite width neural network corresponds to a random feature approximation of the kernel [<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.9306&amp;rep=rep1&amp;type=pdf">6</a>, <a href="https://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines">7</a>].</p>



<p class="justify-text">Let us informally compare the properties of these spaces \(\mathcal{F}_1\) and \(\mathcal{F}_2\) (see [<a href="https://arxiv.org/abs/1412.8690">2</a>] for details):</p>



<ul class="justify-text"><li><strong>Approximation power.</strong> In high dimension, only very smooth functions have small \(\mathcal{F}_2\)-norm (in rough terms, the \(\lceil (d+3)/2\rceil\) first derivatives should be small). In contrast, there exists non-smooth functions with small \(\mathcal{F}_1\)-norm, an example being the relu function \(x\mapsto (\theta^\top x)_+\). Remarkably, if we define \(f(x)=g(Ux)\) where \(U\) is an orthogonal projection then \(\Vert f\Vert_{\mathcal{F}_1} \leq  \Vert g\Vert_{\mathcal{F}_2}\). This shows in particular that \(\mathcal{F}_1\) contains \(\mathcal{F}_2\) and that \(\mathcal{F}_1\) is <em>adaptive</em> to lower dimensional structures.</li><li><strong>Statistical complexity.</strong> It could be feared that the good approximation properties of \(\mathcal{F}_1\) come at the price of being “too large” as a hypothesis space, making it difficult to estimate a predictor in \(\mathcal{F}_1\) from few samples. But, as measured by their Rademacher complexities, the unit ball of \(\mathcal{F}_1\) is only \(O(\sqrt{d})\) larger than that of \(\mathcal{F}_2\). By going from \(\mathcal{F}_2\) to \(\mathcal{F}_1\), we thus add some nicely structured predictors to our hypothesis space, but not too much garbage that could fit unstructured noise.</li><li><strong>Generalization guarantees.</strong> By combining the two previous points, it is possible to prove that supervised learning in \(\mathcal{F}_1\) breaks the curse of dimensionality when the output depends on a lower dimensional projection of the input: the required number of training samples only depends mildly on the dimension \(d\).</li><li><strong>Optimization guarantees.</strong> However \(\mathcal{F}_1\) has a strong drawback : there is no known algorithm that solves the problem of Eq. (3) in polynomial time. On practical problems, gradient descent seems to behave well, but in general only qualitative results such as presented in the previous post are known. In contrast, various provably efficient algorithms can solve regression in \(\mathcal{F}_2\), which is a classical kernel ridge regression problem [Chap. 14.4.3, <a href="https://doc.lagout.org/science/Artificial%20Intelligence/Machine%20learning/Machine%20Learning_%20A%20Probabilistic%20Perspective%20%5BMurphy%202012-08-24%5D.pdf">8</a>].</li></ul>



<p class="justify-text">In the plot below, we compare the predictor learnt by gradient descent for a 2-D regression with the square loss and weight decay, after training (a) both layers — which is regression in \(\mathcal{F}_1\) — or (b) just the output layer — which is regression in \(\mathcal{F}_2\). This already illustrates some distinctive features of both spaces, although the differences become more stringent in higher dimensions. In particular, observe that in (a) the predictor is the combination of few relu functions, which illustrates  the sparsifying effect of the \(L^1\)-norm in Eq. (4). To simplify notations, we do not include a bias/intercept in the formulas but our numerical experiments include it, so in this plot the input is of the form \(x=(x_1,x_2,1)\) and \(d=3\).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-4231" height="293" src="https://francisbach.com/wp-content/uploads/2020/07/regularized-2.png" width="564"/>Predictor learnt by the gradient flow on the square loss with weight decay, when training (a) both layers (b) only the output layer. The markers indicate the location of the training samples  \((x_i)_{i=1}^n\). <a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_weightdecay.jl">[code]</a></figure></div>



<p class="justify-text">The qualitative picture is quite clear so far, but something is a bit unsettling: weight decay is often not needed to obtain a good performance in practice. Our line of reasoning however completely falls apart without such a regularization: if the objective function depends on the predictor only via its values on the training set, being a minimizer does not guarantee anything about generalization outside of the training set (remember that wide relu neural networks are <a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">universal approximators</a>). Why does it still work in the unregularized case? There must be something in the algorithm…</p>



<h2>2. Implicit bias: linear classification</h2>



<p class="justify-text">This something is called the <em>implicit bias</em> : when there are several minimizers, the optimization algorithm makes a specific choice. In the unregularized case, the “quality” of this choice is a crucial property of an algorithm; much more crucial than, say, its convergence speed on the training objective. To gradually build our intuition of the implicit bias of gradient flows, let us put neural networks aside for a moment and consider, following Soudry, Hoffer, Nacson, Gunasekar and Srebro [<a href="http://www.jmlr.org/papers/volume19/18-188/18-188.pdf">9</a>], a linear classification task.</p>



<p class="justify-text"><strong>Gradient flow of the smooth-margin.</strong> Let \((x_i,y_i)_{i=1}^n\) be a training set of \(n\) pairs of inputs \(x_i\in \mathbb{R}^d\) and outputs \(y_i\in \{-1,1\}\) and let us choose the exponential loss. The analysis that follows also apply to the logistic loss (which is the same as the cross-entropy loss after a sigmoid non-linearity) because only the “tail” of the loss matters, but it is more straightforward with the exponential loss. In order to give a natural “scale” to the problem, we  renormalize the empirical risk by taking minus its logarithm and consider the concave objective $$ F_\beta(a) = -\frac{1}{\beta}\log\Big( \frac1n \sum_{i=1}^n \exp(-\beta y_i \ x_i^\top a) \Big).\tag{5}$$ </p>



<p class="justify-text">Here \(\beta&gt;0\) is a parameter that will be useful in a moment. For now, we take \(\beta=1\) and we note \(F(a)=F_1(a)\).  In this context, the <em>margin</em> of a vector \(a\in \mathbb{R}^d\) is the quantity \(\min_{i} y_i\ x_i^\top a\) which quantifies how far this linear predictor is from making a wrong prediction on the training set.  </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-4274" height="386" src="https://francisbach.com/wp-content/uploads/2020/07/max_margin-4.png" width="453"/>The margin of the linear predictor \(x \mapsto a^\top x\) with parameters \(a \in \mathbb{S}^{d-1}\) is the smallest distance of a training point to the decision boundary. We show here the max-margin predictor.</figure></div>



<p class="justify-text">Obtained via simple manipulations, the inequalities  $$ \min_i y_i\ x_i^\top a \leq F_\beta(a) \leq \min_i y_i\ x_i^\top a +\frac{\log(n)}{\beta}, \tag{6}$$ suggest to call \(F_\beta\) the <em>smooth-margin</em> because, well, it is smooth and converges to the margin \(F_\infty(a) := \min_i y_i x_i^\top a\) as \(\beta\to \infty\). Let us look at the gradient flow in the ascent direction that maximizes the smooth-margin: $$ a'(t) = \nabla F(a(t))$$ initialized with \(a(0)=0\) (here the initialization does not matter so much). The path followed by this gradient flow is exactly the same as the gradient flow on the empirical risk: taking the logarithm only changes the time parameterization or, in practice, the step-size.</p>



<p class="justify-text"><strong>Convergence to the max-margin.</strong> Assume that the data set is linearly separable, which means that the \(\ell_2\)-max-margin $$ \gamma := \max_{\Vert a\Vert_2 \leq 1} \min_i y_i x_i^\top a$$ is positive. In this case \(F\) is unbounded (indeed \(\lim_{\alpha \to \infty} F(\alpha a) =\infty\) whenever \(a\)  has a positive margin) and thus \(a(t)\) diverges. This is not an issue as such, since for classification, only the sign of the prediction matters.  This just means that the relevant question is not “where does \(a(t)\) converge?” but rather “towards which direction does it diverge?”. In other words, we are interested in the limit of \(\bar a(t):= a(t)/\Vert a(t)\Vert_2\) (in convex analysis, this is called the <em>cosmic limit</em> of \(a(t)\) [Chap. 3, <a href="https://www.springer.com/gp/book/9783540627722">10</a>], isn’t it beautiful ?).</p>



<p class="justify-text">The argument that follows is adapted from [<a href="https://arxiv.org/pdf/1802.08246.pdf">11</a>, <a href="https://arxiv.org/pdf/1803.07300.pdf">12</a>] and can be traced back to [<a href="http://proceedings.mlr.press/v28/telgarsky13-supp.pdf">13</a>] for coordinate ascent. It can be shown by looking at the structure of the gradient (see the end of the blog post) that \(\Vert \nabla F(a)\Vert_2\geq \gamma\) for all \(a\in \mathbb{R}^d\). By the inequality of Eq. (6) and the gradient flow property \(\frac{d}{dt}F(a(t))=\Vert \nabla F(a(t))\Vert_2^2\), it follows $$\begin{aligned}\min_i y_i x_i^\top a(t) \geq F(a(t)) \  – \log(n) \geq \gamma \int_0^t \Vert \nabla F(a(s))\Vert_2ds -\log (n).\end{aligned}$$  For \(t&gt; \log(n)/\gamma^2\), this lower bound is positive. We can then divide the left-hand side by \(\Vert a(t)\Vert_2\) and the right-hand side by the larger quantity \(\int_0^t \Vert\nabla F(a(s))\Vert_2ds\), and we get $$\min_i y_i x_i^\top \bar a(t) \geq \gamma -\frac{\log(n)}{\int_0^t \Vert\nabla F(a(s))\Vert_2ds} \geq \gamma -\frac{\log(n)}{\gamma t}.$$ This shows that the margin of \(\bar a(t) := a(t)/\Vert a(t)\Vert_2\) converges to the \(\ell_2\)-max-margin at a rate \(\log(n)/\gamma t\). That’s it, the implicit bias of this gradient flow is exposed!</p>



<p class="justify-text"><strong>Stability to step-size choice.</strong> To translate this argument to discrete time, we need decreasing step-sizes of order \(1/\sqrt{t}\) which deteriorates the convergence rate to \(\tilde O(1/\sqrt{t})\), see [<a href="https://arxiv.org/pdf/1802.08246.pdf">11</a>, <a href="https://arxiv.org/pdf/1803.07300.pdf">12</a>]. In [<a href="https://arxiv.org/pdf/2002.04486.pdf">1</a>], we proposed a different proof strategy (based on an online optimization interpretation of \(\bar a(t)\), as below) which recovers the same convergence rate \(O(1/\sqrt{t})\) with <em>exponentially larger</em> step-sizes. This suggests that these diverging trajectories are extremely robust to the choice of step-size.</p>



<p class="justify-text"><strong>Illustration. </strong>In the figure below, we plot on the left the evolution of the parameter \(a(t)\) and on the right the predictor \(x\mapsto (x,1)^\top a(t)\) with \(x\in \mathbb{R}^2\). In parameter space, we apply the hyperbolic tangent to the radial component which allows to easily visualize diverging trajectories. This way, the unit sphere represents the <em>horizon</em> of \(\mathbb{R}^d\), i.e., the set of directions at infinity [Chap. 3 in <a href="https://www.springer.com/gp/book/9783540627722">9</a>]. We will use the same convention in the other plots below.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-4106" height="288" src="https://francisbach.com/wp-content/uploads/2020/07/linear.gif" width="586"/>Implicit bias of gradient descent for a linear classification task with the exponential loss: (left) parameter space, (right) predictor space.</figure></div>



<h2>3. Implicit bias:  training only the output layer</h2>



<p class="justify-text">Despite its apparently restrictive setting, the previous result already tells us something about wide neural networks. Consider the situation touched upon earlier where we only train the output weights \(a_j\) and the hidden weights \(b_j\) are picked uniformly at random on the sphere. This corresponds to learning a linear classifier on top of the random feature \([(b_j^\top x)_+]_{j=1}^m\). </p>



<p class="justify-text">As we have just shown, if the training set is separable, the normalized gradient flow of the unregularized exponential loss (or logistic loss) converges to a solution to  $$ \max_{\Vert a\Vert_2 \leq 1}\min_i y_i \sum_{j=1}^m  a_j (b_j^\top x_i)_+.$$ </p>



<p class="justify-text">This is a random feature approximation for the unregularized kernel support vector machine problem in the RKHS \(\mathcal{F}_2\), which is recovered in the large width limit \(m\to \infty\):  $$\max_{\Vert h\Vert_{\mathcal{F}_2}\leq 1} \min_i y_i h(x_i).$$ Notice that if \(m\) is large enough, the linear separability assumption is not even needed anymore, because any training set is separable in \(\mathcal{F}_2\) (at least if all \(x_i\)s are distinct and if we do not forget to include the bias/intercept).</p>



<p class="justify-text"><strong>Illustration.</strong> In the animation below, we plot on the left the evolution of the parameters and on the right the predictor for a 2-D classification task. In parameter space, each particle represents a neuron: their direction is fixed, their distance to \(0\) is their absolute weight and the color is red (+) or blue (-) depending on the sign of the weight. As above, the unit sphere is at infinity and the particles diverge. In predictor space, the markers represent the training samples of both classes, the color shows the predictor and the black line is the decision boundary. The fact that the predictor has a smooth decision boundary is in accordance with the properties of \(\mathcal{F}_2\) given above. </p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img alt="" class="wp-image-4275" src="https://francisbach.com/wp-content/uploads/2020/07/film_output_comp-1.gif"/>Gradient descent on the output layer of a two-layer relu neural network with the exponential loss: (left) parameter space, (right) predictor space. <a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_output.jl">[code]</a></figure></div>



<h2>4. Implicit bias: 2-homogeneous linear classifiers</h2>



<p class="justify-text">Although the analyses where neural networks behave like kernel methods are pleasant for us theoreticians because we are in conquered territory, they miss essential aspects of neural networks such as their adaptivity and their ability to learn a representation. Let us see if we can characterize the implicit bias of the gradient flow of the unregularized exponential loss when training <em>both</em> layers of the neural network.</p>



<p class="justify-text"><strong>A 2-homogeneous linear model.</strong> From an optimization point of view, an important property of two layer relu neural networks is that \(\Phi(\alpha w)= \alpha^2 \Phi(w)\) for all \(\alpha&gt;0\), i.e., they are positively 2-homogeneous in the training parameters. In contrast, a linear model is 1-homogeneous in the parameters. This seemingly little difference leads to drastic changes in the gradient flow dynamics. </p>



<p class="justify-text">Let us again build our intuition with a simplified model that captures key aspects of the dynamics, namely the linear classification setting of above. This time, we take any initialization \(r(0)\in \mathbb{R}^d\) with positive entries and the gradient flow in the ascent direction of the function \( F(r\odot r)\) where \(\odot\) is the pointwise product between two vectors and \(F\) is defined in Eq. (5). This is just a trick to obtain a 2-homogeneous parameterization of a linear model. This gradient flow satisfies $$ r'(t) = 2 r(t)\odot \nabla F(r(t)\odot r(t)).$$ </p>



<p class="justify-text"><strong>Normalized dynamics.</strong> Let us define \(\bar a(t):=(r(t)\odot r(t))/\Vert r(t)\Vert_2^2\) the normalized predictor associated to our dynamics which, by definition, belongs to the simplex \(\Delta_d\), i.e., the set of nonnegative vectors in \(\mathbb{R}^d\) that sum to one. Using the fact that \(\nabla F(\beta a) = \nabla F_\beta (a)\) for all \(\beta&gt;0\), we obtain $$\begin{aligned} \bar a'(t) &amp;= 2\frac{r(t)\odot r'(t)}{\Vert r(t)\Vert_2^2} -2 (r(t)^\top r'(t))\frac{r(t)\odot r(t)}{\Vert r(t)\Vert_2^4}\\ &amp;=4\bar a(t) \odot \nabla F_{\Vert r(t)\Vert_2^2}(\bar a(t))\ – \alpha(t) \bar a(t)\end{aligned}$$ where \(\alpha(t)\) is the scalar such that \(\sum_{i=1}^d a’_i(t) =0\). Online optimization experts might have recognized that this is (continuous time) <em>online mirror ascent in the simplex</em> for the sequence of smooth-margin functions \(F_{\Vert r(t)\Vert_2^2}\). Notice in particular the multiplicative updates: they correspond to the entropy mirror function, and they are particularly well suited for optimization in the high dimensional simplex [Chap.4, <a href="https://arxiv.org/pdf/1405.4980.pdf">14</a>].</p>



<p>What do we learn from this reformulation? </p>



<ul class="justify-text"><li>We can prove (by similar means) that if the data set is linearly separable then \(\Vert r(t)\Vert_2^2\) diverges. So the sequence of functions \(F_{\Vert r\Vert_2^2}\) converges to the margin \(F_\infty\) which means that \(\bar a(t)\) just ends up optimizing the function \(F_\infty\). As a consequence, we have $$\lim_{t\to \infty} y_i x_i^\top \bar a(t) = \max_{a\in \Delta_d} \min_{i} y_i x_i^\top a.$$ This exposes another implicit bias of gradient flow. Notice the key difference with the implicit bias obtained with a linear parameterization: we obtain here the \(\ell_1\)-max-margin (over classifiers with non-negative entries) instead of the \(\ell_2\)-max-margin.  </li><li>Beyond exposing the implicit bias, this reformulation shows that \(\bar a(t)\) implicitly optimizes a sequence of smooth objectives which converge to the margin \(F_\infty\). Unknowingly, we have recovered the well-principled optimization method that consists in approximating a non-smooth objective with smooth functions [<a href="https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf">15</a>].</li><li>While the conclusion above was only formal, this point of view leads to rigorous proofs of convergence and convergence rates in discrete time in \(\tilde O(1/\sqrt{t})\) with a step-size in \(O(1/\sqrt{t})\), by  exploiting tools from online optimization, see [<a href="https://arxiv.org/pdf/2002.04486.pdf">1</a>].</li></ul>



<h2>5. Implicit bias: fully trained 2-layer neural networks</h2>



<p class="justify-text">Once again this argument about linear predictors applies to neural networks: if we train both layers but only the magnitude of the hidden weights and not their direction, then this is equivalent to learning a 2-homogeneous linear model on top of the random feature \([  a_j(0) (x_i^\top b_j(0))_+]_{j=1}^m\). If each feature appears twice with opposite signs — which is essentially the case in the large width limit — then the simplex constraint can be equivalently replaced by an \(\ell_1\)-norm constraint on the weights. Recalling the definition of the \(\mathcal{F}_1\)-norm from Eq. (4), we thus obtain that, in the infinite-width limit, the normalized predictor converges to a solution to $$ \max_{\Vert h\Vert_{\mathcal{F}_1} \leq 1} \min_i y_i h(x_i).$$</p>



<p class="justify-text">This result is correct, but it is not relevant. In contrast to functions in \(\mathcal{F}_2\), functions in \(\mathcal{F}_1\) <em>can not</em> in general be approximated with few <em>random</em> features in high dimension. In fact, lower bounds that are exponential in the dimension exist in certain settings [Sec. X, <a href="http://www.stat.yale.edu/~arb4/publications_files/UniversalApproximationBoundsForSuperpositionsOfASigmoidalFunction.pdf">16</a>]. They can be approximated with a small number of features but those need to be data-dependent: in that sense, it is necessary to learn a representation – here,  a distribution over the hidden weights — in order to learn in \(\mathcal{F}_1\). </p>



<p class="justify-text">This raises the following question: do we obtain the same implicit bias when training both layers of the neural network, without fixing the direction of the input weights? In the following result, which is the main theorem of our paper [<a href="https://arxiv.org/abs/2002.04486">1</a>], we answer by the affirmative.</p>



<p class="justify-text"><strong>Theorem</strong> (C. and Bach [<a href="https://arxiv.org/abs/2002.04486">1</a>], informal). Assume that for some \(\sigma&gt;0\), the hidden weights \(b_j\) are initialized uniformly on the sphere of radius \(\sigma\) and the output weights \(a_j\) are uniform in \(\{-\sigma,\sigma\}\). Let \(\mu_t\) be the Wasserstein gradient flow for the unregularized exponential loss and \(h_t = \int \Phi(w)d\mu_t(w)\) be the corresponding dynamics in predictor space. Under some technical assumptions, the normalized predictor \(h_t/\Vert h_t\Vert_{\mathcal{F}_1}\) converges to a solution to the \(\mathcal{F}_1\)-max-margin problem: $$\max_{\Vert h\Vert_{\mathcal{F}_1} \leq 1} \min_i y_i h(x_i).$$</p>



<p class="justify-text">Giving an idea of proof would be a bit too technical for this blog post, but let us make some remarks:</p>



<ul class="justify-text"><li>The strength of this result is that although this dynamics could get trapped towards limit directions which are not optimal, this choice of initialization allows to avoid them all and to only converge to <em>global</em> minimizers of this max-margin problem. The principle behind this is similar to the global convergence result in the previous blog post. </li><li>The fact that optimizing on the direction of the hidden weights is compatible with the global optimality conditions of the \(\mathcal{F}_1\)-max-margin problem is very specific to the structure of positively 2-homogeneous problems, and should not be taken for granted for other architectures of neural networks.</li><li>Although at a formal level this result works for any initialization that is diverse enough (such as the standard Gaussian initialization), the initialization proposed here yields dynamics with a better behavior for relu networks: by initializing the hidden and output weights with equal norms – a property preserved by the dynamics – we avoid some instabilities in the gradient. Also notice that this result applies to any scale \(\sigma&gt;0\) of the initialization (we’ll see an intriguing consequence of this in the next section).</li></ul>



<p class="justify-text"><strong>Illustration.</strong> In the figure below, we plot the training dynamics when both layers are trained. In parameter space (left), each particle represents a neuron: its position is \(\vert a_j\vert b_j\) and its color depends on the sign of \(a_j\).  Here again the unit sphere is at infinity. The inactive neurons at the bottom correspond to those with a bias that is “too negative” at initialization. We observe that all the other neurons gather into few clusters: this is the sparsifying effect of the \(L^1\)-norm in Eq. (4). In predictor space, we obtain a polygonal classifier, as expected for a \(\mathcal{F}_1\)-max-margin classifier. See the paper [<a href="https://arxiv.org/pdf/2002.04486.pdf">1</a>] for experiments that illustrate the strengths of this classifier in terms of generalization.</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img alt="" class="wp-image-4194" src="https://francisbach.com/wp-content/uploads/2020/07/film_both_comp.gif"/>Training both layers of a wide relu neural network with the exponential loss: (left) space of parameters, (right) space of predictors. <a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_bothlayers.jl">[code]</a></figure></div>



<h2>6. Lazy regime and the neural tangent kernel</h2>



<p class="justify-text">This blog post would not be complete without mentioning the <em>lazy regime</em>. This is yet another kind of implicit bias which, in our context, takes place when at initialization the weights have a large magnitude and the step-size is small. It was first exhibited in [<a href="https://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">17</a>] for deep neural networks.</p>



<p class="justify-text"><strong>Lazy training via scaling.</strong> This phenomenon is in fact very general so let us present it with a generic parametric predictor \(h(W)\) with differential \(Dh(W)\). We introduce a scaling factor \(\alpha&gt;0\) and look at the gradient flow of \(F(W) := R(\alpha h(W))\) with a step-size \(1/\alpha^2\), that is $$ W'(t) = \ – \frac{1}{\alpha}Dh(W(t))^\top \nabla R(\alpha h(W(t))),$$ with initialization \(W(0)\). In terms of the predictor \(\alpha h(W)\), this yields the dynamics $$\frac{d}{dt} \alpha h(W(t)) = \ – Dh(W(t))Dh(W(t))^\top \nabla R(\alpha h(W(t)).$$ </p>



<p class="justify-text">Lazy training [<a href="https://arxiv.org/pdf/1812.07956.pdf">18</a>] happens when we take \(\alpha\) large while making sure that \(\alpha h(W(0))\) stays bounded. In this case, we see that the parameters change at a rate \(O(1/\alpha)\), while the predictor changes at a rate independent of \(\alpha\). On any bounded time interval, in the limit of  a large \(\alpha\), the parameters only move infinitesimally, while the predictor still makes significant progress, hence the name <em>lazy training</em>.</p>



<p class="justify-text"><strong>Equivalent linear model.</strong> Since the parameters hardly move, if we assume that \(Dh(W(0))\neq 0\) then we can replace the map \(h\) by its linearization \(W \mapsto h(W(0))+Dh(W(0))(W-W(0))\). This means that the training dynamics essentially follows the gradient flow of the  objective $$ R\big ( \alpha h(W(0)) + \alpha Dh(W(0))(W-W(0)) \big)$$ which is a convex function of \(W\) as soon as \(R\) is convex.</p>



<p class="justify-text">If this objective admits a minimizer that is not too far away from \(W(0)\), then \(W(t)\) converges to this minimizer. If in contrast all  the minimizers are too far away (think of the exponential loss where they are at infinity), then the parameters will eventually move significantly and the lazy regime is just a transient regime in the early phase of training.  Of course, all these behaviors can be quantified and made more precise, because this phenomenon brings us back to the realm of linear models. </p>



<p class="justify-text">What all of this has to do with two-layer neural networks? As it happens, this scale factor appears implicit in various situations for these models; let us detail two of them. </p>



<p class="justify-text"><strong>Neural networks with \(1/\sqrt{m}\) scaling.</strong> For two-layer neural networks, lazy training occurs if we define \(h = \frac{1}{\sqrt{m}} \sum_{j=1}^m \Phi(w_j)\) instead of \(h=\frac{1}{m} \sum_{j=1}^m \Phi(w_j)\) before taking the infinite width limit. Indeed:</p>



<ul class="justify-text"><li>This induces a scaling factor \(\alpha = \sqrt{m} \to \infty\) compared to \(1/m\) which, as we have already seen, is the “correct” scaling that leads to a non-degenerate dynamics in parameter space as \(m\) increases. </li><li>Moreover, by the central limit theorem,  \(\frac{1}{\sqrt{m}} \sum_{j=1}^m \Phi(w_j(0)) = O(1)\) for typical random initializations of the parameters. So the initial predictor stays bounded.</li></ul>



<p class="justify-text">To take the Wasserstein gradient flow limit, the step-size has to be of order \(m\) (see previous blog post). So here we should take a step-size of order \(m/\alpha^2 = 1\). With such a step-size, all the conditions for lazy training are gathered when \(m\) is large. Intuitively, each neuron only moves infinitesimally, but they collectively produce a significant movement in predictor space.</p>



<p class="justify-text"><strong>Neural networks with large initialization.</strong> Coming back to our scaling in \(1/m\) and our Wasserstein gradient flow that is obtained in the large width limit, there is another way to enter the lazy regime: by increasing the variance of the initialization. </p>



<p class="justify-text">To see this, assume that \(h\) is a positively \(p\)-homogeneous parametric predictor, which means that \(h(\sigma W)=\sigma^p h(W)\) for all \(\sigma&gt;0\) and some \(p&gt;1\) (remember that this is true with \(p=2\) for our two-layer relu neural network). Take an initialization of the form \(W(0) = \sigma \bar W_0\) where \(\sigma&gt;0\) and \(h(\bar W_0)=0\) (which is also satisfied for our infinite width neural networks with the initialization considered previously). Consider the gradient flow of \(R(h(W))\) with step-size \(\sigma^{2-2p}\).   By defining \(\bar W(t) = W(t)/\sigma\) and using the fact that the differential of a p-homogeneous function <a href="https://en.wikipedia.org/wiki/Homogeneous_function#Positive_homogeneity">is (p-1)-homogeneous</a>, we have, on the one hand $$ \bar W'(t) = -\sigma^{-p} Dh(\bar W(t))^\top \nabla R(\sigma^p h(\bar W(t))), $$ and on the other hand $$\frac{d}{dt} \sigma^p h(\bar W(t)) =\  – Dh(\bar W(t))Dh(\bar W(t))^\top \nabla R(\sigma^p h(\bar W(t))).$$ So in terms of the dynamics \(\bar W(t)\), the situation is exactly equivalent to having a scaling factor \(\alpha=\sigma^p\). This implies that as the magnitude \(\sigma\) of the initialization increases, we enter the lazy regime, provided the step-size is of order \(\sigma^{2-2p}\).</p>



<p class="justify-text"><strong>Neural tangent kernel. </strong>What does the lazy regime tell us about the learnt predictor for two-layer neural networks? Assuming for simplicity that the predictor at initialization is \(0\), this regime amounts to learning a linear model on top of the feature \([(b_j^\top x)_+]_{j=1}^m\) — the derivative with respect to the output weights — concatenated with the feature \([x a_j 1_{b_j^\top x &gt; 0} ]_{j=1}^m\)  — the derivative with respect to the input weights. Compared to training only the output layer, this thus simply adds some features. </p>



<p class="justify-text">Assume for concreteness, that at initialization the hidden weights \(b_j\) are uniform on a sphere of large radius \(\sigma&gt;0\) and the output weights are uniform on \(\{-\kappa\sigma, \kappa\sigma\}\) where \(\kappa\geq 0\). For a large width and a large \(\sigma\), we enter the lazy regime which amounts to learning in a RKHS — let us call it \(\mathcal{F}_{2,\kappa}\) — that is slightly different from \(\mathcal{F}_2 = \mathcal{F}_{2,0}\), since its kernel \(K_\kappa\) contains another term: $$ K_\kappa(x,x’) = \int_{\mathbb{S}^{d-1}} (\theta^\top x)_+ (\theta^\top x’)_+d\tau(\theta) + \kappa^2 \int_{\mathbb{S}^{d-1}} (x^\top x’) 1_{\theta^\top x &gt; 0}1_{\theta^\top x’ &gt; 0}d\tau(\theta). $$</p>



<p class="justify-text">This kernel is called the Neural Tangent Kernel [<a href="https://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">17</a>] and the properties of the associated RKHS have been studied in [<a href="https://arxiv.org/pdf/1904.12191.pdf">19</a>, <a href="http://papers.nips.cc/paper/9449-on-the-inductive-bias-of-neural-tangent-kernels.pdf">20</a>], where it is shown to include functions that are slightly less smooth than those of \(\mathcal{F}_2\) when \(\kappa\) increases. This is illustrated in the plot below, obtained by training a wide neural network with \(\sigma\) large (to reach the lazy regime) on the square loss, and various values of \(\kappa\).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-4213" height="287" src="https://francisbach.com/wp-content/uploads/2020/07/interp-4.png" width="574"/>1-D regression with a wide two-layer relu neural network (gradient descent on square loss, in the lazy regime) with 4 training samples (black dots). At initialization, output weights have \(\kappa\) times the (large) magnitude of the hidden weights. This implicitly solves kernel ridgeless regression for a kernel that depends on \(\kappa\). <a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_NTK.jl">[code]</a></figure></div>



<p class="justify-text"><strong>Two implicit biases in one shot.</strong> The attentive reader might have noticed that for large initialization scale \(\sigma\gg 1\), when training both layers on the unregularized exponential loss, two of our analyses apply:  lazy training — that leads to a max-margin predictor in \(\mathcal{F}_{2,\kappa}\) — and the asymptotic implicit bias — that leads to a max-margin predictor in \(\mathcal{F}_{1}\).  So, where is the catch? </p>



<p class="justify-text">There is none! Since the minimizers of this loss are at infinity, the lazy regime is just a transient phase and we will observe both implicit biases along the training dynamics! Take a look at the video below: we observe that in early phases of training, the neurons do not move while learning a smooth classifier — this is the lazy regime and the classifier approaches the \(\mathcal{F}_{2,\kappa}\)-max-margin classifier. In later stages of training, the neurons start moving and the predictor converges to a \(\mathcal{F}_1\)-max-margin classifier as stated by the main theorem. The predictor jitters a little bit during training because I have chosen rather aggressive step-sizes.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large"><img alt="" class="wp-image-4219" src="https://francisbach.com/wp-content/uploads/2020/07/film_lazy2sparse_ns_comp-1.gif"/>Training both layers with gradient descent for the unregularized exponential loss. The only difference with the previous video is that at initialization the variance \(\sigma^2\) is larger and the step-size smaller \(\approx \sigma^{-2}\). First the network learns a classifier in the lazy regime (a kernel max-margin classifier) and eventually converges to the \(\mathcal{F}_1\)-max-margin classifier.</figure></div>



<h2>Discussion</h2>



<p class="justify-text">In this blog post, I described how analyses of the training dynamics can help us understand the properties of the predictor learnt by neural networks even in the absence of an explicit regularization. Already for the simplest algorithm one can think of — gradient descent — we have found a variety of behaviors depending on the loss, the initialization or the step-size. </p>



<p class="justify-text">To achieve this description, the infinite width limit is of great help. It allows to obtain synthetic and precise characterizations of the learnt predictor, that can be used to derive generalization bounds. Yet, there are many interesting non-asymptotic effects caused by having a finite width.  In that sense, we were only concerned with the end of the curve of double descent [<a href="https://www.pnas.org/content/pnas/116/32/15849.full.pdf">21</a>].</p>



<h2>References</h2>



<p class="justify-text">[1] Lénaïc Chizat, Francis Bach. <a href="https://arxiv.org/pdf/2002.04486.pdf">Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks Trained with the Logistic Loss.</a> <em>To appear in Conference On Learning Theory</em>, 2020.<br/>[2] Francis Bach. <a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">Breaking the curse of dimensionality with convex neural networks.</a> <em>The Journal of Machine Learning Research</em>, <em>18</em>(1), 629-681, 2017.<br/>[3]  Vera Kurková, Marcello Sanguineti. <a href="https://www.cs.cas.cz/~vera/publications/journals/I3Edin.pdf">Bounds on rates of variable-basis and neural-network approximation.</a> <em>IEEE Transactions on Information Theory</em>, 47(6):2659-2665, 2001.  <br/>[4] Behnam Neyshabur, Ryota Tomioka, Nathan Srebro. <a href="https://arxiv.org/pdf/1412.6614.pdf">In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning.</a> <em>ICLR (Workshop)</em>. 2015.<br/>[5] Youngmin Cho, Lawrence K. SAUL.  <a href="https://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf">Kernel methods for deep learning.</a> <em>Advances in neural information processing systems</em>. 342-350, 2009.<br/>[6] Radford M. Neal. <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.9306&amp;rep=rep1&amp;type=pdf"><em>Bayesian learning for neural networks</em>.</a> Springer Science &amp; Business Media, 2012.<br/>[7] Ali Rahimi, Benjamin Recht. <a href="https://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf">Random features for large-scale kernel machines.</a> <em>Advances in neural information processing systems</em>. 1177-1184, 2008.<br/>[8] Kevin P. Murphy. Machine Learning: A Probabilistic Perspective. <em>The MIT Press</em>, 2012<br/>[9] Daniel Soudry, Elad Hoffer, Mor Shpigel Nacson, Suriya Gunasekar, Nathan Srebro. <a href="http://www.jmlr.org/papers/volume19/18-188/18-188.pdf">The Implicit Bias of Gradient Descent on Separable Data.</a><em> The Journal of Machine Learning Research</em>, <em>19</em>(1), 2822-2878, 2018.<br/>[10] R. Tyrrell Rockafellar, Roger J-B. Wets. <a href="https://www.springer.com/gp/book/9783540627722"><em>Variational analysis</em>.</a> Springer Science &amp; Business Media, 2009.<br/>[11] Suriya Gunasekar,  Jason D. Lee, Daniel Soudry, Nathan Srebro.  <a href="https://par.nsf.gov/servlets/purl/10107856">Characterizing implicit bias in terms of optimization geometry.</a> <em>International Conference on Machine Learning</em>, 2018.<br/>[12] Ziwei Ji, Matus Telgarsky. <a href="https://arxiv.org/pdf/1803.07300.pdf">Risk and parameter convergence of logistic regression.</a> 2018.<br/>[13] Matus Telgarsky. <a href="https://arxiv.org/abs/1303.4172">Margins, Shrinkage, and Boosting.</a> <em>International Conference on Machine Learning</em>, 307-315, 2013.<br/>[14] Sébastien Bubeck. <a href="https://arxiv.org/pdf/1405.4980.pdf">Convex Optimization: Algorithms and Complexity.</a> Foundations and Trends in Machine Learning, 8(3-4):231-357, 2015.<br/>[15] Yuri Nesterov. <a href="https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf">Smooth minimization of non-smooth functions.</a> <em>Mathematical programming</em>, 103(1):127-152, 2005.<br/>[16] Anrew R. Barron. <a href="http://www.stat.yale.edu/~arb4/publications_files/UniversalApproximationBoundsForSuperpositionsOfASigmoidalFunction.pdf">Universal approximation bounds for superpositions of a sigmoidal function.</a> <em>IEEE Transactions on Information theory. </em>39(3), 930-945, 1993.<br/>[17] Jacot, Arthur, Franck Gabriel, Clément Hongler. <a href="https://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">Neural tangent kernel: Convergence and generalization in neural networks.</a> <em>Advances in neural information processing systems.</em> 8571-8580, 2018.<br/>[18] Lénaïc Chizat, Édouard Oyallon, Francis Bach. <a href="https://papers.nips.cc/paper/8559-on-lazy-training-in-differentiable-programming.pdf">On lazy training in differentiable programming.</a> <em>Advances in Neural Information Processing Systems.</em> 2937-2947, 2019.<br/>[19] Behrooz Ghorbani, Song Mei, Theodor Misiakiewicz, Andrea Montanari. <a href="https://arxiv.org/pdf/1904.12191.pdf">Linearized two-layers neural networks in high dimension.</a> To appear in <em>Annals of Statistics</em>. 2019.<br/>[20] Alberto Bietti, Julien Mairal. <a href="http://papers.nips.cc/paper/9449-on-the-inductive-bias-of-neural-tangent-kernels">On the Inductive Bias of Neural Tangent Kernels</a>. <em>Advances in Neural Information Processing Systems.</em> p. 12893-12904, 2019.<br/>[21] Mikhail Belkin, Daniel Hsu, Siyuan Ma, Soumik Mandal. <a href="https://www.pnas.org/content/pnas/116/32/15849.full.pdf">Reconciling modern machine-learning practice and the classical bias–variance trade-off.</a> <em>Proceedings of the National Academy of Sciences.</em> <em>116</em>(32), 15849-15854, 2019.</p>



<h3>Lower bound on the gradient norm for linear classification with the exponential loss</h3>



<p class="justify-text">In the context of Section 2, we want to prove that \(\Vert \nabla F(a)\Vert_2\geq \gamma\). For this, let \(Z\in \mathbb{R}^{n\times d}\) be the matrix with rows \(y_i x_i\) and let \(\Delta_n\) be the simplex in \(\mathbb{R}^n\). We have by duality $$ \gamma = \max_{\Vert a\Vert_2\leq 1}\min_{p\in \Delta_n} p^\top Z a =   \min_{p\in \Delta_n} \max_{\Vert a\Vert_2\leq 1} a^\top Z^\top p = \min_{p\in \Delta_n} \Vert Z^\top p\Vert_2 .$$  Also, notice that \(\nabla F(a) = Z^\top p\) with \(p_i = \frac{e^{-y_ix_i^\top a}}{\sum_{j=1}^n e^{-y_{j}x_{j}^\top a}}\). Since \(p \in \Delta_n\), we conclude that \(\Vert \nabla F(a)\Vert_2\geq \min_{p\in \Delta_n} \Vert Z^\top p\Vert_2 = \gamma\).</p></div>
    </content>
    <updated>2020-07-13T19:39:11Z</updated>
    <published>2020-07-13T19:39:11Z</published>
    <category term="Machine learning"/>
    <author>
      <name>Lénaïc Chizat</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2020-07-21T00:42:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7770</id>
    <link href="https://windowsontheory.org/2020/07/13/simons-institute-lectures-on-analysis-of-boolean-functions/" rel="alternate" type="text/html"/>
    <title>Simons institute lectures on analysis of Boolean functions</title>
    <summary>(Does it still make sense to blog such announcements or is these days Twitter the only way to go about this? Asking for a friend 🙂 ) Prasad Raghavendra and Avishay Tal have organized a sequence of 6 lectures on some of the exciting recent advances in analysis of Boolean functions. Lecture Series: Advances in […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>(Does it still make sense to blog such announcements or is these days <a href="https://twitter.com/boazbaraktcs/status/1282443765224017920">Twitter</a> the only way to go about this? Asking for a friend <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/> )</em></p>



<p>Prasad Raghavendra and Avishay Tal have organized a sequence of 6 lectures on some of the exciting recent advances in analysis of Boolean functions. </p>



<p><a href="https://simons.berkeley.edu/events/boolean" rel="noreferrer noopener" target="_blank">Lecture Series: Advances in Boolean Function Analysis</a><br/></p>



<p>The Simons Institute is organizing a series of lectures on Advances in Boolean Function Analysis, that will highlight a few major developments in the area. The series will feature weekly two-hour lectures from July 15th to Aug 18th.  The lectures aim to address both the broad context of the results and their technical details. Though closely related in theme, each lecture will be self-contained.  The schedule is attached below (more info at <a href="https://simons.berkeley.edu/events/boolean" rel="noreferrer noopener" target="_blank">link</a>). </p>



<p>Talks take place on Wednesdays at 10am Pacific time (1pm Eastern). If you can’t catch them live, they will be redcorded.</p>



<p><strong>Zoom Link: </strong><a href="https://berkeley.zoom.us/j/93086371156" rel="noreferrer noopener" target="_blank">https://berkeley.zoom.us/j/93086371156</a><br/></p>



<p><strong><u>Talk Schedule:</u></strong></p>



<p>July 15, Wednesday  10:00am PDT (1pm EDT) <em>Dor Minzer (Institute of Advanced Study)<a href="https://simons.berkeley.edu/events/boolean-1" rel="noreferrer noopener" target="_blank">On the Fourier-Entropy Influence Conjecture</a></em></p>



<p><br/>July 22, Wednesday, 10:00am PDT (1pm EDT) <em>Hao Huang (Emory University) &amp; Avishay Tal (UC Berkeley)<a href="https://simons.berkeley.edu/events/boolean-3" rel="noreferrer noopener" target="_blank">Sensitivity Conjecture and Its Applications</a></em></p>



<p><br/>August 3rd, Monday, 10:00am PDT (1pm EDT)<em>  Shachar Lovett (UC San Diego)<a href="https://simons.berkeley.edu/events/boolean-2" rel="noreferrer noopener" target="_blank">Improved Bounds for the Sunflower Lemma</a></em></p>



<p><br/>August 5, Wednesday, 10:00am PDT (1pm EDT) <em>Ronen Eldan (Weizmann Institute)</em><a href="https://simons.berkeley.edu/events/boolean-4" rel="noreferrer noopener" target="_blank"><em>Concentration on the Boolean Hypercube via Pathwise Stochastic Analysis</em></a></p>



<p><br/>August 12, Wednesday, 10:00am <em>Esty Kelman (Tel Aviv University) <a href="https://simons.berkeley.edu/events/boolean-5" rel="noreferrer noopener" target="_blank">KKL via Random Restrictions</a></em></p>



<p><br/>August 18, Tuesday, 10:00am <em>Pooya Hatami (Ohio State University)<a href="https://simons.berkeley.edu/events/boolean-6" rel="noreferrer noopener" target="_blank">Pseudorandom Generators from Polarizing Random Walks</a></em></p></div>
    </content>
    <updated>2020-07-13T16:18:40Z</updated>
    <published>2020-07-13T16:18:40Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-07-21T00:40:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3507</id>
    <link href="https://agtb.wordpress.com/2020/07/13/adfocs-2020-market-design-and-computational-fair-division/" rel="alternate" type="text/html"/>
    <title>ADFOCS 2020 (Market Design and Computational Fair Division)</title>
    <summary>Via Pieter Kleer: 21st Max Planck Summer School: Advanced Course on the Foundations of Computer Science (ADFOCS 2020) August 24 – 28, 2020 Saarbruecken, Germany THIS IS A VIRTUAL EVENT http://www.mpi-inf.mpg.de/conference/adfocs ————————————————————————————————— About ADFOCS ADFOCS is an international summer school that has been held annually for the last twenty years at the Max Planck Institute […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Via Pieter Kleer:</p>
<hr/>
<p>21st Max Planck Summer School:<br/>
Advanced Course on the Foundations of Computer Science (ADFOCS 2020)</p>
<p>August 24 – 28, 2020</p>
<p>Saarbruecken, Germany</p>
<p>THIS IS A VIRTUAL EVENT<a href="http://www.mpi-inf.mpg.de/conference/adfocs" rel="noopener noreferrer" target="_blank"/></p><a href="http://www.mpi-inf.mpg.de/conference/adfocs" rel="noopener noreferrer" target="_blank">
</a><p><a href="http://www.mpi-inf.mpg.de/conference/adfocs" rel="noopener noreferrer" target="_blank">http://www.mpi-inf.mpg.de/conference/adfocs</a><br/>
—————————————————————————————————</p>
<p><b>About ADFOCS</b><br/>
ADFOCS is an international summer school that has been held annually for the last twenty years at the Max Planck Institute for Informatics (MPII) in Saarbruecken, Germany. It is organized as part of the activities of the MPII, in particular the International Max Planck Research School (IMPRS), MPII’s graduate program. The purpose of this summer school is to introduce young researchers to topics which are the focus of current research in theoretical computer science. We bring together leading researchers in the field and international participants at the graduate level and above. This year’s focus is on:</p>
<p><b>*** Market Design and Computational Fair Division ***</b><br/>
<b>Program</b><br/>
Our invited speakers give five 60-min lectures with subsequent exercise and discussion sessions. These sessions will take place daily from 14:30 to 18:30 UTC+2 (CEST) in the week of August 24-28. On some days there will be a social event after the regular schedule. This year’s speakers are:</p>
<p>* Nicole Immorlica, Microsoft Research Lab, New York City, USA<br/>
* Jugal Garg and Ruta Mehta, University of Illinois at Urbana-Champaign, USA<br/>
<b>Registration</b><br/>
This year registration is free as the event takes place virtually. Nevertheless, registration is MANDATORY and can be done through the website (at the latest August 10)</p>
<p><b>Contact</b><br/>
The homepage of ADFOCS, including forms for registration, can be found at <a href="http://www.mpi-inf.mpg.de/conference/adfocs" rel="noopener noreferrer" target="_blank">http://www.mpi-inf.mpg.de/conference/adfocs</a></p>
<p>If you have further questions, please do not hesitate to contact the ADFOCS team by sending an email to <a href="mailto:adfocs@mpi-inf.mpg.de" rel="noopener" target="_blank">adfocs@mpi-inf.mpg.de</a></p>
<p>Organizers: Cosmina Croitoru, Sandor Kisfaludi-Bak and Pieter Kleer</p></div>
    </content>
    <updated>2020-07-13T01:25:45Z</updated>
    <published>2020-07-13T01:25:45Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>timroughgarden</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2020-07-21T00:40:05Z</updated>
    </source>
  </entry>
</feed>
