<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-10-08T03:39:41Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.03620</id>
    <link href="http://arxiv.org/abs/2110.03620" rel="alternate" type="text/html"/>
    <title>Hyperparameter Tuning with Renyi Differential Privacy</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Papernot:Nicolas.html">Nicolas Papernot</a>, Thomas Steinke <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.03620">PDF</a><br/><b>Abstract: </b>For many differentially private algorithms, such as the prominent noisy
stochastic gradient descent (DP-SGD), the analysis needed to bound the privacy
leakage of a single training run is well understood. However, few studies have
reasoned about the privacy leakage resulting from the multiple training runs
needed to fine tune the value of the training algorithm's hyperparameters. In
this work, we first illustrate how simply setting hyperparameters based on
non-private training runs can leak private information. Motivated by this
observation, we then provide privacy guarantees for hyperparameter search
procedures within the framework of Renyi Differential Privacy. Our results
improve and extend the work of Liu and Talwar (STOC 2019). Our analysis
supports our previous observation that tuning hyperparameters does indeed leak
private information, but we prove that, under certain assumptions, this leakage
is modest, as long as each candidate training run needed to select
hyperparameters is itself differentially private.
</p></div>
    </summary>
    <updated>2021-10-08T01:23:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.03460</id>
    <link href="http://arxiv.org/abs/2110.03460" rel="alternate" type="text/html"/>
    <title>Finding popular branchings in vertex-weighted digraphs</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Kei Natsui, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Takazawa:Kenjiro.html">Kenjiro Takazawa</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.03460">PDF</a><br/><b>Abstract: </b>Popular matchings have been intensively studied recently as a relaxed concept
of stable matchings. By applying the concept of popular matchings to branchings
in directed graphs, Kavitha et al.\ (2020) introduced popular branchings. In a
directed graph $G=(V_G,E_G)$, each vertex has preferences over its incoming
edges. For branchings $B_1$ and $B_2$ in $G$, a vertex $v\in V_G$ prefers $B_1$
to $B_2$ if $v$ prefers its incoming edge of $B_1$ to that of $B_2$, where
having an arbitrary incoming edge is preferred to having none, and $B_1$ is
more popular than $B_2$ if the number of vertices that prefer $B_1$ is greater
than the number of vertices that prefer $B_2$. A branching $B$ is called a
popular branching if there is no branching more popular than $B$. Kavitha et
al.\ (2020) proposed an algorithm for finding a popular branching when the
preferences of each vertex are given by a strict partial order. The validity of
this algorithm is proved by utilizing classical theorems on the duality of
weighted arborescences. In this paper, we generalize popular branchings to
weighted popular branchings in vertex-weighted directed graphs in the same
manner as weighted popular matchings by Mestre (2014). We give an algorithm for
finding a weighted popular branching, which extends the algorithm of Kavitha et
al., when the preferences of each vertex are given by a total preorder and the
weights satisfy certain conditions. Our algorithm includes elaborated
procedures resulting from the vertex-weights, and its validity is proved by
extending the argument of the duality of weighted arborescences.
</p></div>
    </summary>
    <updated>2021-10-08T01:26:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.03279</id>
    <link href="http://arxiv.org/abs/2110.03279" rel="alternate" type="text/html"/>
    <title>Polynomial Turing Kernels for Clique with an Optimal Number of Queries</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fluschnik:Till.html">Till Fluschnik</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heeger:Klaus.html">Klaus Heeger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hermelin:Danny.html">Danny Hermelin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.03279">PDF</a><br/><b>Abstract: </b>A polynomial Turing kernel for some parameterized problem $P$ is a
polynomial-time algorithm that solves $P$ using queries to an oracle of $P$
whose sizes are upper-bounded by some polynomial in the parameter. Here the
term "polynomial" refers to the bound on the query sizes, as the running time
of any kernel is required to be polynomial. One of the most important open
goals in parameterized complexity is to understand the applicability and
limitations of polynomial Turing Kernels. As any fixed-parameter tractable
problem admits a Turing kernel of some size, the focus has mostly being on
determining which problems admit such kernels whose query sizes can be indeed
bounded by some polynomial.
</p>
<p>In this paper we take a different approach, and instead focus on the number
of queries that a Turing kernel uses, assuming it is restricted to using only
polynomial sized queries. Our study focuses on one the main problems studied in
parameterized complexity, the Clique problem: Given a graph $G$ and an integer
$k$, determine whether there are $k$ pairwise adjacent vertices in $G$. We show
that Clique parameterized by several structural parameters exhibits the
following phenomena:
</p>
<p>- It admits polynomial Turing kernels which use a sublinear number of
queries, namely $O(n/\log^c n)$ queries where $n$ is the total size of the
graph and $c$ is any constant. This holds even for a very restrictive type of
Turing kernels which we call OR-kernels.
</p>
<p>- It does not admit polynomial Turing kernels which use $O(n^{1-\epsilon})$
queries, unless NP$\subseteq$coNP/poly.
</p>
<p>For proving the second item above, we develop a new framework for bounding
the number of queries needed by polynomial Turing kernels. This framework is
inspired by the standard lower bounds framework for Karp kernels, and while it
is quite similar, it still requires some novel ideas to allow its extension to
the Turing setting.
</p></div>
    </summary>
    <updated>2021-10-08T01:24:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.03195</id>
    <link href="http://arxiv.org/abs/2110.03195" rel="alternate" type="text/html"/>
    <title>Coresets for Decision Trees of Signals</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jubran:Ibrahim.html">Ibrahim Jubran</a>, Ernesto Evgeniy Sanches Shayda, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Newman:Ilan.html">Ilan Newman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldman:Dan.html">Dan Feldman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.03195">PDF</a><br/><b>Abstract: </b>A $k$-decision tree $t$ (or $k$-tree) is a recursive partition of a matrix
(2D-signal) into $k\geq 1$ block matrices (axis-parallel rectangles, leaves)
where each rectangle is assigned a real label. Its regression or classification
loss to a given matrix $D$ of $N$ entries (labels) is the sum of squared
differences over every label in $D$ and its assigned label by $t$. Given an
error parameter $\varepsilon\in(0,1)$, a $(k,\varepsilon)$-coreset $C$ of $D$
is a small summarization that provably approximates this loss to \emph{every}
such tree, up to a multiplicative factor of $1\pm\varepsilon$. In particular,
the optimal $k$-tree of $C$ is a $(1+\varepsilon)$-approximation to the optimal
$k$-tree of $D$.
</p>
<p>We provide the first algorithm that outputs such a $(k,\varepsilon)$-coreset
for \emph{every} such matrix $D$. The size $|C|$ of the coreset is polynomial
in $k\log(N)/\varepsilon$, and its construction takes $O(Nk)$ time. This is by
forging a link between decision trees from machine learning -- to partition
trees in computational geometry.
</p>
<p>Experimental results on \texttt{sklearn} and \texttt{lightGBM} show that
applying our coresets on real-world data-sets boosts the computation time of
random forests and their parameter tuning by up to x$10$, while keeping similar
accuracy. Full open source code is provided.
</p></div>
    </summary>
    <updated>2021-10-08T01:25:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.03152</id>
    <link href="http://arxiv.org/abs/2110.03152" rel="alternate" type="text/html"/>
    <title>Optimal (Euclidean) Metric Compression</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Indyk:Piotr.html">Piotr Indyk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wagner:Tal.html">Tal Wagner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.03152">PDF</a><br/><b>Abstract: </b>We study the problem of representing all distances between $n$ points in
$\mathbb R^d$, with arbitrarily small distortion, using as few bits as
possible. We give asymptotically tight bounds for this problem, for Euclidean
metrics, for $\ell_1$ (a.k.a.~Manhattan) metrics, and for general metrics.
</p>
<p>Our bounds for Euclidean metrics mark the first improvement over compression
schemes based on discretizing the classical dimensionality reduction theorem of
Johnson and Lindenstrauss (Contemp.~Math.~1984). Since it is known that no
better dimension reduction is possible, our results establish that Euclidean
metric compression is possible beyond dimension reduction.
</p></div>
    </summary>
    <updated>2021-10-08T01:20:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.03122</id>
    <link href="http://arxiv.org/abs/2110.03122" rel="alternate" type="text/html"/>
    <title>Faster algorithm for Unique $(k,2)$-CSP</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zamir:Or.html">Or Zamir</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.03122">PDF</a><br/><b>Abstract: </b>In a $(k,2)$-Constraint Satisfaction Problem we are given a set of arbitrary
constraints on pairs of $k$-ary variables, and are asked to find an assignment
of values to these variables such that all constraints are satisfied. The
$(k,2)$-CSP problem generalizes problems like $k$-coloring and
$k$-list-coloring. In the Unique $(k,2)$-CSP problem, we add the assumption
that the input set of constraints has at most one satisfying assignment.
</p>
<p>Beigel and Eppstein gave an algorithm for $(k,2)$-CSP running in time
$O\left(\left(0.4518k\right)^n\right)$ for $k&gt;3$ and $O\left(1.356^n\right)$
for $k=3$, where $n$ is the number of variables. Feder and Motwani improved
upon the Beigel-Eppstein algorithm for $k\geq 11$. Hertli, Hurbain, Millius,
Moser, Scheder and Szedl{\'a}k improved these bounds for Unique $(k,2)$-CSP for
every $k\geq 5$.
</p>
<p>We improve the result of Hertli et al. and obtain better bounds for
Unique~$(k,2)$-CSP for~$k\geq 5$. In particular, we improve the running time of
Unique~$(5,2)$-CSP from~$O\left(2.254^n\right)$ to~$O\left(2.232^n\right)$ and
Unique~$(6,2)$-CSP from~$O\left(2.652^n\right)$ to~$O\left(2.641^n\right)$.
</p></div>
    </summary>
    <updated>2021-10-08T01:24:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.03070</id>
    <link href="http://arxiv.org/abs/2110.03070" rel="alternate" type="text/html"/>
    <title>Robust Algorithms for GMM Estimation: A Finite Sample Viewpoint</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rohatgi:Dhruv.html">Dhruv Rohatgi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Syrgkanis:Vasilis.html">Vasilis Syrgkanis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.03070">PDF</a><br/><b>Abstract: </b>For many inference problems in statistics and econometrics, the unknown
parameter is identified by a set of moment conditions. A generic method of
solving moment conditions is the Generalized Method of Moments (GMM). However,
classical GMM estimation is potentially very sensitive to outliers. Robustified
GMM estimators have been developed in the past, but suffer from several
drawbacks: computational intractability, poor dimension-dependence, and no
quantitative recovery guarantees in the presence of a constant fraction of
outliers. In this work, we develop the first computationally efficient GMM
estimator (under intuitive assumptions) that can tolerate a constant $\epsilon$
fraction of adversarially corrupted samples, and that has an $\ell_2$ recovery
guarantee of $O(\sqrt{\epsilon})$. To achieve this, we draw upon and extend a
recent line of work on algorithmic robust statistics for related but simpler
problems such as mean estimation, linear regression and stochastic
optimization. As two examples of the generality of our algorithm, we show how
our estimation algorithm and assumptions apply to instrumental variables linear
and logistic regression. Moreover, we experimentally validate that our
estimator outperforms classical IV regression and two-stage Huber regression on
synthetic and semi-synthetic datasets with corruption.
</p></div>
    </summary>
    <updated>2021-10-08T01:22:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02898</id>
    <link href="http://arxiv.org/abs/2110.02898" rel="alternate" type="text/html"/>
    <title>Coresets for Kernel Clustering</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Shaofeng_H==C=.html">Shaofeng H.-C. Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krauthgamer:Robert.html">Robert Krauthgamer</a>, Jianing Lou, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Yubo.html">Yubo Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02898">PDF</a><br/><b>Abstract: </b>We devise the first coreset for kernel $k$-Means, and use it to obtain new,
more efficient, algorithms. Kernel $k$-Means has superior clustering capability
compared to classical $k$-Means particularly when clusters are separable
non-linearly, but it also introduces significant computational challenges. We
address this computational issue by constructing a coreset, which is a reduced
dataset that accurately preserves the clustering costs.
</p>
<p>Our main result is the first coreset for kernel $k$-Means, whose size is
independent of the number of input points $n$, and moreover is constructed in
time near-linear in $n$. This result immediately implies new algorithms for
kernel $k$-Means, such as a $(1+\epsilon)$-approximation in time near-linear in
$n$, and a streaming algorithm using space and update time $\mathrm{poly}(k
\epsilon^{-1} \log n)$.
</p>
<p>We validate our coreset on various datasets with different kernels. Our
coreset performs consistently well, achieving small errors while using very few
points. We show that our coresets can speed up kernel $k$-Means++ (the
kernelized version of the widely used $k$-Means++ algorithm), and we further
use this faster kernel $k$-Means++ for spectral clustering. In both
applications, we achieve up to 1000x speedup while the error is comparable to
baselines that do not use coresets.
</p></div>
    </summary>
    <updated>2021-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02830</id>
    <link href="http://arxiv.org/abs/2110.02830" rel="alternate" type="text/html"/>
    <title>Parameterized Algorithms for the Steiner Tree Problem on a Directed Hypercube</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Sugyani Mahapatra, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narayanan:Manikandan.html">Manikandan Narayanan</a>, N S Narayanaswamy, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramamoorthi:Vijayaragunathan.html">Vijayaragunathan Ramamoorthi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02830">PDF</a><br/><b>Abstract: </b>We address the problem of computing a Steiner Arborescence on a directed
hypercube, that enjoys a special connectivity structure among its node set but
is exponential in $m$ size rendering traditional Steiner tree algorithms
inefficient. Even though the problem was known to be NP-complete, parameterized
complexity of the problem was unknown. With applications in evolutionary tree
reconstruction algorithms and incremental algorithms for computing a property
on multiple input graphs, any algorithm for this problem would open up new ways
to study these applications. In this paper, we present the first algorithms, to
the best our knowledge, that prove the problem to be fixed parameter tractable
(FPT) wrt two natural parameters -- number of input terminals and penalty of
the arborescence. These parameters along with the special structure of the
hypercube offer different trade-offs in terms of running time tractability vs.
approximation guarantees that are interestingly additive in nature.
</p>
<p>Given any directed $m$-dimensional hypercube, rooted at the zero node, and a
set of input terminals $R$ that needs to be spanned by the Steiner
arborescence, we prove that the problem is FPT wrt the penalty parameter $q$,
by providing a randomized algorithm that computes an optimal arborescence $T$
in $O\left(q^44^{q\left(q+1\right)}+q\left|R\right|m^2\right)$ with probability
at least $4^{-q}$. If we trade-off exact solution for an additive approximation
one, then we can design a parameterized approximation algorithm with better
running time - computing an arborescence $T$ with cost at most
$OPT+(\left|R\right|-4)(q_{opt}-1)$ in time
$O\left|R\right|m^2+1.2738^{q_{opt}})$. We also present a dynamic programming
algorithm that computes an optimal arborescence in
$O(3^{\left|R\right|}\left|R\right|m)$ time, thus proving that the problem is
FPT on the parameter $\left|R\right|$.
</p></div>
    </summary>
    <updated>2021-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02807</id>
    <link href="http://arxiv.org/abs/2110.02807" rel="alternate" type="text/html"/>
    <title>Fitting Distances by Tree Metrics Minimizing the Total Error within a Constant Factor</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen=Addad:Vincent.html">Vincent Cohen-Addad</a>, Debarati Das, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kipouridis:Evangelos.html">Evangelos Kipouridis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parotsidis:Nikos.html">Nikos Parotsidis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thorup:Mikkel.html">Mikkel Thorup</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02807">PDF</a><br/><b>Abstract: </b>We consider the numerical taxonomy problem of fitting a positive distance
function ${D:{S\choose 2}\rightarrow \mathbb R_{&gt;0}}$ by a tree metric. We want
a tree $T$ with positive edge weights and including $S$ among the vertices so
that their distances in $T$ match those in $D$. A nice application is in
evolutionary biology where the tree $T$ aims to approximate the branching
process leading to the observed distances in $D$ [Cavalli-Sforza and Edwards
1967]. We consider the total error, that is the sum of distance errors over all
pairs of points. We present a deterministic polynomial time algorithm
minimizing the total error within a constant factor. We can do this both for
general trees, and for the special case of ultrametrics with a root having the
same distance to all vertices in $S$.
</p>
<p>The problems are APX-hard, so a constant factor is the best we can hope for
in polynomial time. The best previous approximation factor was $O((\log n)(\log
\log n))$ by Ailon and Charikar [2005] who wrote "Determining whether an $O(1)$
approximation can be obtained is a fascinating question".
</p></div>
    </summary>
    <updated>2021-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02750</id>
    <link href="http://arxiv.org/abs/2110.02750" rel="alternate" type="text/html"/>
    <title>Extensions of Karger's Algorithm: Why They Fail in Theory and How They Are Useful in Practice</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jenner:Erik.html">Erik Jenner</a>, Enrique Fita Sanmartín, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hamprecht:Fred_A=.html">Fred A. Hamprecht</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02750">PDF</a><br/><b>Abstract: </b>The minimum graph cut and minimum $s$-$t$-cut problems are important
primitives in the modeling of combinatorial problems in computer science,
including in computer vision and machine learning. Some of the most efficient
algorithms for finding global minimum cuts are randomized algorithms based on
Karger's groundbreaking contraction algorithm. Here, we study whether Karger's
algorithm can be successfully generalized to other cut problems. We first prove
that a wide class of natural generalizations of Karger's algorithm cannot
efficiently solve the $s$-$t$-mincut or the normalized cut problem to
optimality. However, we then present a simple new algorithm for seeded
segmentation / graph-based semi-supervised learning that is closely based on
Karger's original algorithm, showing that for these problems, extensions of
Karger's algorithm can be useful. The new algorithm has linear asymptotic
runtime and yields a potential that can be interpreted as the posterior
probability of a sample belonging to a given seed / class. We clarify its
relation to the random walker algorithm / harmonic energy minimization in terms
of distributions over spanning forests. On classical problems from seeded image
segmentation and graph-based semi-supervised learning on image data, the method
performs at least as well as the random walker / harmonic energy minimization /
Gaussian processes.
</p></div>
    </summary>
    <updated>2021-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02730</id>
    <link href="http://arxiv.org/abs/2110.02730" rel="alternate" type="text/html"/>
    <title>Tight bounds for counting colorings and connected edge sets parameterized by cutwidth</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Groenland:Carla.html">Carla Groenland</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nederlof:Jesper.html">Jesper Nederlof</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mannens:Isja.html">Isja Mannens</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Szil=aacute=gyi:Krisztina.html">Krisztina Szilágyi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02730">PDF</a><br/><b>Abstract: </b>We study the fine-grained complexity of counting the number of colorings and
connected spanning edge sets parameterized by the cutwidth and treewidth of the
graph. Let $p,q \in \mathbb{N}$ such that $p$ is a prime and $q \geq 3$. We
show:
</p>
<p>- If $p$ divides $q-1$, there is a $(q-1)^{{\text{ctw}}}n^{O(1)}$ time
algorithm for counting list $q$-colorings modulo $p$ of $n$-vertex graphs of
cutwidth ${\text{ctw}}$. Furthermore, no algorithm can count the number of
distinct $q$-colorings modulo $p$ in time $(q-1-\varepsilon)^{\text{ctw}}
n^{O(1)}$ for some $\varepsilon&gt;0$, assuming the Strong Exponential Time
Hypothesis (SETH).
</p>
<p>- If $p$ does not divide $q-1$, no algorithm can count the number of distinct
$q$-colorings modulo $p$ in time $(q-\varepsilon)^{\text{ctw}} n^{O(1)}$ for
some $\varepsilon&gt;0$, assuming SETH.
</p>
<p>The lower bounds are in stark contrast with the existing
$2^{{\text{ctw}}}n^{O(1)}$ time algorithm to compute the chromatic number of a
graph by Jansen and Nederlof~[Theor. Comput. Sci.'18]. Furthermore, by building
upon the above lower bounds, we obtain the following lower bound for counting
connected spanning edge sets: there is no $\varepsilon&gt;0$ for which there is an
algorithm that, given a graph $G$ and a cutwidth ordering of cutwidth
${\text{ctw}}$, counts the number of spanning connected edge sets of $G$ modulo
$p$ in time $(p - \varepsilon)^{\text{ctw}} n^{O(1)}$, assuming SETH. We also
give an algorithm with matching running time for this problem. Before our work,
even for the treewidth parameterization, the best conditional lower bound by
Dell et al.~[ACM Trans. Algorithms'14] only excluded
$2^{o({\text{tw}})}n^{O(1)}$ time algorithms for this problem. Both our
algorithms and lower bounds employ use of the matrix rank method.
</p></div>
    </summary>
    <updated>2021-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02709</id>
    <link href="http://arxiv.org/abs/2110.02709" rel="alternate" type="text/html"/>
    <title>Subquadratic-time algorithm for the diameter and all eccentricities on median graphs</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berg=eacute=:Pierre.html">Pierre Bergé</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Ducoffe:Guillaume.html">Guillaume Ducoffe</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Habib:Michel.html">Michel Habib</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02709">PDF</a><br/><b>Abstract: </b>On sparse graphs, Roditty and Williams [2013] proved that no
$O(n^{2-\varepsilon})$-time algorithm achieves an approximation factor smaller
than $\frac{3}{2}$ for the diameter problem unless SETH fails. In this article,
we solve a longstanding question: can we use the structural properties of
median graphs to break this global quadratic barrier?
</p>
<p>We propose the first combinatiorial algorithm computing exactly all
eccentricities of a median graph in truly subquadratic time. Median graphs
constitute the family of graphs which is the most studied in metric graph
theory because their structure represent many other discrete and geometric
concepts, such as CAT(0) cube complexes. Our result generalizes a recent one,
stating that there is a linear-time algorithm for all eccentricities in median
graphs with bounded dimension $d$, i.e. the dimension of the largest induced
hypercube. This prerequisite on $d$ is not necessarily anymore to determine all
eccentricities in subquadratic time. The execution time of our algorithm is
$O(n^{1.6456}\log^{O(1)} n)$.
</p>
<p>We provide also some satellite outcomes related to this general result. In
particular, restricted to simplex graphs, this algorithm enumerate all
eccentricities with a quasilinear running time. Moreover, an algorithm is
proposed to compute exactly all reach centralities in time
$O(2^{3d}n\log^{O(1)}n)$.
</p></div>
    </summary>
    <updated>2021-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02688</id>
    <link href="http://arxiv.org/abs/2110.02688" rel="alternate" type="text/html"/>
    <title>Towards Non-Uniform k-Center with Constant Types of Radii</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jia:Xinrui.html">Xinrui Jia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rohwedder:Lars.html">Lars Rohwedder</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sheth:Kshiteej.html">Kshiteej Sheth</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Svensson:Ola.html">Ola Svensson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02688">PDF</a><br/><b>Abstract: </b>In the Non-Uniform k-Center problem we need to cover a finite metric space
using k balls of different radii that can be scaled uniformly. The goal is to
minimize the scaling factor. If the number of different radii is unbounded, the
problem does not admit a constant-factor approximation algorithm but it has
been conjectured that such an algorithm exists if the number of radii is
constant. Yet, this is known only for the case of two radii. Our first
contribution is a simple black box reduction which shows that if one can handle
the variant of t-1 radii with outliers, then one can also handle t radii.
Together with an algorithm by Chakrabarty and Negahbani for two radii with
outliers, this immediately implies a constant-factor approximation algorithm
for three radii, thus making further progress on the conjecture. Furthermore,
using algorithms for the k-center with outliers problem, that is the one radii
with outliers case, we also get a simple algorithm for two radii.
</p>
<p>The algorithm by Chakrabarty and Negahbani uses a top-down approach, starting
with the larger radius and then proceeding to the smaller one. Our reduction,
on the other hand, looks only at the smallest radius and eliminates it, which
suggests that a bottom-up approach is promising. In this spirit, we devise a
modification of the Chakrabarty and Negahbani algorithm which runs in a
bottom-up fashion, and in this way we recover their result with the advantage
of having a simpler analysis.
</p></div>
    </summary>
    <updated>2021-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02555</id>
    <link href="http://arxiv.org/abs/2110.02555" rel="alternate" type="text/html"/>
    <title>Profile-based optimal stable matchings in the Roommates problem</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Sofia Simola, David Manlove <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02555">PDF</a><br/><b>Abstract: </b>The stable roommates problem can admit multiple different stable matchings.
We have different criteria for deciding which one is optimal, but computing
those is often NP-hard.
</p>
<p>We show that the problem of finding generous or rank-maximal stable matchings
in an instance of the roommates problem with incomplete lists is NP-hard even
when the preference lists are at most length 3. We show that just maximising
the number of first choices or minimising the number of last choices is NP-hard
with the short preference lists.
</p>
<p>We show that the number of $R^{th}$ choices, where $R$ is the minimum-regret
of a given instance of SRI, is 2-approximable among all the stable matchings.
Additionally, we show that the problem of finding a stable matching that
maximises the number of first choices does not admit a constant time
approximation algorithm and is W[1]-hard with respect to the number of first
choices.
</p>
<p>We implement integer programming and constraint programming formulations for
the optimality criteria of SRI. We find that constraint programming outperforms
integer programming and an earlier answer set programming approach by Erdam et.
al. (2020) for most optimality criteria. Integer programming outperforms
constraint programming and answer set programming on the almost stable
roommates problem.
</p></div>
    </summary>
    <updated>2021-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02543</id>
    <link href="http://arxiv.org/abs/2110.02543" rel="alternate" type="text/html"/>
    <title>A logical approach for temporal and multiplex networks analysis</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bautista:Esteban.html">Esteban Bautista</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Latapy:Matthieu.html">Matthieu Latapy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02543">PDF</a><br/><b>Abstract: </b>Many systems generate data as a set of triplets (a, b, c): they may represent
that user a called b at time c or that customer a purchased product b in store
c. These datasets are traditionally studied as networks with an extra dimension
(time or layer), for which the fields of temporal and multiplex networks have
extended graph theory to account for the new dimension. However, such
frameworks detach one variable from the others and allow to extend one same
concept in many ways, making it hard to capture patterns across all dimensions
and to identify the best definitions for a given dataset. This extended
abstract overrides this vision and proposes a direct processing of the set of
triplets. In particular, our work shows that a more general analysis is
possible by partitioning the data and building categorical propositions that
encode informative patterns. We show that several concepts from graph theory
can be framed under this formalism and leverage such insights to extend the
concepts to data triplets. Lastly, we propose an algorithm to list propositions
satisfying specific constraints and apply it to a real world dataset.
</p></div>
    </summary>
    <updated>2021-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02538</id>
    <link href="http://arxiv.org/abs/2110.02538" rel="alternate" type="text/html"/>
    <title>A Local Updating Algorithm for Personalized PageRank via Chebyshev Polynomials</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bautista:Esteban.html">Esteban Bautista</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Latapy:Matthieu.html">Matthieu Latapy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02538">PDF</a><br/><b>Abstract: </b>The personalized PageRank algorithm is one of the most versatile tools for
the analysis of networks. In spite of its ubiquity, maintaining personalized
PageRank vectors when the underlying network constantly evolves is still a
challenging task. To address this limitation, this work proposes a novel
distributed algorithm to locally update personalized PageRank vectors when the
graph topology changes. The proposed algorithm is based on the use of Chebyshev
polynomials and a novel update equation that encompasses a large family of
PageRank-based methods. In particular, the algorithm has the following
advantages: (i) it has faster convergence speed than state-of-the-art
alternatives for local PageRank updating; and (ii) it can update the solution
of recent generalizations of PageRank for which no updating algorithms have
been developed. Experiments in a real-world temporal network of an autonomous
system validate the effectiveness of the proposed algorithm.
</p></div>
    </summary>
    <updated>2021-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02503</id>
    <link href="http://arxiv.org/abs/2110.02503" rel="alternate" type="text/html"/>
    <title>More on Change-Making and Related Problems</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chan:Timothy_M=.html">Timothy M. Chan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/He:Qizheng.html">Qizheng He</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02503">PDF</a><br/><b>Abstract: </b>Given a set of $n$ integer-valued coin types and a target value $t$, the
well-known change-making problem asks for the minimum number of coins that sum
to $t$, assuming an unlimited number of coins in each type. In the more general
all-targets version of the problem, we want the minimum number of coins summing
to $j$, for every $j=0,\ldots,t$. For example, the textbook dynamic programming
algorithms can solve the all-targets problem in $O(nt)$ time. Recently, Chan
and He (SOSA'20) described a number of $O(t\,\textrm{polylog}\,t)$-time
algorithms for the original (single-target) version of the change-making
problem, but not the all-targets version.
</p>
<p>We obtain a number of new results on change-making and related problems,
including:
</p>
<p>1. A new algorithm for the all-targets change-making problem with running
time $\tilde{O}(t^{4/3})$, improving a previous $\tilde{O}(t^{3/2})$-time
algorithm.
</p>
<p>2. A very simple $\tilde{O}(u^2+t)$-time algorithm for the all-targets
change-making problem, where $u$ denotes the maximum coin value. The analysis
of the algorithm uses a theorem of Erd\H{o}s and Graham (1972) on the Frobenius
problem. This algorithm can be extended to solve the all-capacities version of
the unbounded knapsack problem (for integer item weights bounded by $u$).
</p>
<p>3. For the original (single-target) coin changing problem, we describe a
simple modification of one of Chan and He's algorithms that runs in
$\tilde{O}(u)$ time (instead of $\tilde{O}(t)$).
</p>
<p>4. For the original (single-capacity) unbounded knapsack problem, we describe
a simple algorithm that runs in $\tilde{O}(nu)$ time, improving previous
near-$u^2$-time algorithms.
</p>
<p>5. We also observe how one of our ideas implies a new result on the minimum
word break problem, an optimization version of a string problem studied by
Bringmann et al. (FOCS'17), generalizing change-making (which corresponds to
the unary special case).
</p></div>
    </summary>
    <updated>2021-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02487</id>
    <link href="http://arxiv.org/abs/2110.02487" rel="alternate" type="text/html"/>
    <title>An Improved Approximation for Maximum $k$-Dependent Set on Bipartite Graphs</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hosseinian:Seyedmohammadhossein.html">Seyedmohammadhossein Hosseinian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Butenko:Sergiy.html">Sergiy Butenko</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02487">PDF</a><br/><b>Abstract: </b>We present a $(1+\frac{k}{k+2})$-approximation algorithm for the Maximum
$k$-dependent Set problem on bipartite graphs for any $k\ge1$. For a graph with
$n$ vertices and $m$ edges, the algorithm runs in $O(k m \sqrt{n})$ time and
improves upon the previously best-known approximation ratio of
$1+\frac{k}{k+1}$ established by Kumar et al. [Theoretical Computer Science,
526: 90--96 (2014)]. Our proof also indicates that the algorithm retains its
approximation ratio when applied to the (more general) class of
K\"{o}nig-Egerv\'{a}ry graphs.
</p></div>
    </summary>
    <updated>2021-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02400</id>
    <link href="http://arxiv.org/abs/2110.02400" rel="alternate" type="text/html"/>
    <title>Periodic Reranking for Online Matching of Reusable Resources</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Udwani:Rajan.html">Rajan Udwani</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02400">PDF</a><br/><b>Abstract: </b>We consider a generalization of the vertex weighted online bipartite matching
problem where the offline vertices, called resources, are reusable. In
particular, when a resource is matched it is unavailable for a deterministic
time duration $d$ after which it becomes available for a re-match. Thus, a
resource can be matched to many different online vertices over a period of
time. While recent work on the problem has resolved the asymptotic case where
we have large starting inventory (i.e., many copies) of every resource, we
consider the (more general) case of unit inventory and give the first algorithm
that is provably better than the na\"ive greedy approach which has a
competitive ratio of (exactly) 0.5. In particular, we achieve a competitive
ratio of 0.589 against an LP relaxation of the offline problem.
</p></div>
    </summary>
    <updated>2021-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02387</id>
    <link href="http://arxiv.org/abs/2110.02387" rel="alternate" type="text/html"/>
    <title>Approximate $\mathrm{CVP}$ in time $2^{0.802 \, n}$ -- now in any norm!</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rothvoss:Thomas.html">Thomas Rothvoss</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Venzin:Moritz.html">Moritz Venzin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02387">PDF</a><br/><b>Abstract: </b>We show that a constant factor approximation of the shortest and closest
lattice vector problem in any norm can be computed in time $2^{0.802\, n}$.
This contrasts the corresponding $2^n$ time, (gap)-SETH based lower bounds for
these problems that even apply for small constant approximation. For both
problems, $\mathrm{SVP}$ and $\mathrm{CVP}$, we reduce to the case of the
Euclidean norm. A key technical ingredient in that reduction is a twist of
Milman's construction of an $M$-ellipsoid which approximates any symmetric
convex body $K$ with an ellipsoid $\mathcal{E}$ so that $2^{\varepsilon n}$
translates of a constant scaling of $\mathcal{E}$ can cover $K$ and vice versa.
</p></div>
    </summary>
    <updated>2021-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02341</id>
    <link href="http://arxiv.org/abs/2110.02341" rel="alternate" type="text/html"/>
    <title>How to Query An Oracle? Efficient Strategies to Label Data</title>
    <feedworld_mtime>1633651200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lahouti:Farshad.html">Farshad Lahouti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kostina:Victoria.html">Victoria Kostina</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hassibi:Babak.html">Babak Hassibi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02341">PDF</a><br/><b>Abstract: </b>We consider the basic problem of querying an expert oracle for labeling a
dataset in machine learning. This is typically an expensive and time consuming
process and therefore, we seek ways to do so efficiently. The conventional
approach involves comparing each sample with (the representative of) each class
to find a match. In a setting with $N$ equally likely classes, this involves
$N/2$ pairwise comparisons (queries per sample) on average. We consider a
$k$-ary query scheme with $k\ge 2$ samples in a query that identifies
(dis)similar items in the set while effectively exploiting the associated
transitive relations. We present a randomized batch algorithm that operates on
a round-by-round basis to label the samples and achieves a query rate of
$O(\frac{N}{k^2})$. In addition, we present an adaptive greedy query scheme,
which achieves an average rate of $\approx 0.2N$ queries per sample with
triplet queries. For the proposed algorithms, we investigate the query rate
performance analytically and with simulations. Empirical studies suggest that
each triplet query takes an expert at most 50\% more time compared with a
pairwise query, indicating the effectiveness of the proposed $k$-ary query
schemes. We generalize the analyses to nonuniform class distributions when
possible.
</p></div>
    </summary>
    <updated>2021-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/10/07/research-team-leader-at-ideas-ncbr-ltd-apply-by-december-31-2021/</id>
    <link href="https://cstheory-jobs.org/2021/10/07/research-team-leader-at-ideas-ncbr-ltd-apply-by-december-31-2021/" rel="alternate" type="text/html"/>
    <title>Research Team Leader at IDEAS NCBR Ltd.  (apply by December 31, 2021)</title>
    <summary>Place of work: Warsaw, Poland The newly established IDEAS NCBR institute is looking for a position of Research Team Leader dealing with formal modeling and proving the security of cryptographic protocols used in blockchain technology. The research will be carried out in cooperation with the cryptography and blockchain laboratory headed by prof. Stefan Dziembowski at […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Place of work: Warsaw, Poland</p>
<p>The newly established IDEAS NCBR institute is looking for a position of Research Team Leader dealing with formal modeling and proving the security of cryptographic protocols used in blockchain technology. The research will be carried out in cooperation with the cryptography and blockchain laboratory headed by prof. Stefan Dziembowski at the University of Warsaw.</p>
<p>Website: <a href="https://ideas-ncbr.pl/en/research-team-leader/">https://ideas-ncbr.pl/en/research-team-leader/</a><br/>
Email: jobs@ideas-ncbr.pl</p></div>
    </content>
    <updated>2021-10-07T13:43:24Z</updated>
    <published>2021-10-07T13:43:24Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-10-08T03:37:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4562</id>
    <link href="https://lucatrevisan.wordpress.com/2021/10/07/buser-inequalities-in-graphs/" rel="alternate" type="text/html"/>
    <title>Buser Inequalities in Graphs</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">As life is tentatively returning to normal, I would like to once again post technical material here. Before returning to online optimization, I would like to start with something from 2015 that we never wrote up properly, that has to … <a href="https://lucatrevisan.wordpress.com/2021/10/07/buser-inequalities-in-graphs/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>As life is tentatively returning to normal, I would like to once again post technical material here. Before returning to online optimization, I would like to start with something from 2015 that we never wrote up properly, that has to do with <em>graph curvature</em> and with <em>Buser inequalities in graphs</em>.</p>
<p><span id="more-4562"/></p>
<p>The starting point is the Cheeger inequalities on graphs.</p>
<p>If <img alt="{G= (V,E)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%3D+%28V%2CE%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-regular graph, and <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is its adjacency matrix, then we define the <em>normalized Laplacian matrix</em> of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as <img alt="{L: = I - A/d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%3A+%3D+I+-+A%2Fd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and we call <img alt="{\lambda_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> the second smallest (counting multiplicities) eigenvalue of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. It is important in the spectral theory of graphs that this eigenvalue has a variational characterization as the solution of the following optimization problem:</p>
<p align="center"><img alt="\displaystyle  \lambda_2 = \min_{x \in {\mathbb R}^V : \langle x, {\bf 1} \rangle=0} \ \frac { x^T L x}{||x||^2} = \min_{x \in {\mathbb R}^V : \langle x,{\bf 1} \rangle=0} \ \frac { \sum_{(u,v) \in E} (x_u - x_v)^2}{d\sum_v x_v^2 } " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_2+%3D+%5Cmin_%7Bx+%5Cin+%7B%5Cmathbb+R%7D%5EV+%3A+%5Clangle+x%2C+%7B%5Cbf+1%7D+%5Crangle%3D0%7D+%5C+%5Cfrac+%7B+x%5ET+L+x%7D%7B%7C%7Cx%7C%7C%5E2%7D+%3D+%5Cmin_%7Bx+%5Cin+%7B%5Cmathbb+R%7D%5EV+%3A+%5Clangle+x%2C%7B%5Cbf+1%7D+%5Crangle%3D0%7D+%5C+%5Cfrac+%7B+%5Csum_%7B%28u%2Cv%29+%5Cin+E%7D+%28x_u+-+x_v%29%5E2%7D%7Bd%5Csum_v+x_v%5E2+%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>The <em>normalized edge expansion</em> of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is defined as</p>
<p align="center"><img alt="\displaystyle  \phi(G) = \min_{S : |S| \leq |V|/2} \ \frac{ cut(S) }{d|S|} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cphi%28G%29+%3D+%5Cmin_%7BS+%3A+%7CS%7C+%5Cleq+%7CV%7C%2F2%7D+%5C+%5Cfrac%7B+cut%28S%29+%7D%7Bd%7CS%7C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> where <img alt="{cut(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bcut%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> denotes the number of edges with one endpoint in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and one endpoint outside <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. We have talked about these quantities several times, so we will just jump to the fact that the following <em>Cheeger inequalities</em> hold:</p>
<p align="center"><img alt="\displaystyle  \frac {\lambda_2 }2 \leq \phi(G) \leq \sqrt {2 \lambda_2} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac+%7B%5Clambda_2+%7D2+%5Cleq+%5Cphi%28G%29+%5Cleq+%5Csqrt+%7B2+%5Clambda_2%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>Those inequalities are called Cheeger inequality because the upper bound is the discrete analog of a result of Cheeger concerning Riemann manifolds. There were previous posts about this <a href="https://lucatrevisan.wordpress.com/2013/03/20/the-cheeger-inequality-in-manifolds/">here</a> and <a href="https://lucatrevisan.wordpress.com/2013/03/21/proof-of-the-cheeger-inequality-in-manifolds/">here</a>, and for our current purposes it will be enough to recall that, roughly speaking, a Riemann manifold defines a space on which we can define real-valued and complex-valued functions, and such functions can be integrated and differentiated. Subsets <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of a Riemann manifold have, if they are measurable, a well defined volume, and their boundary <img alt="{\partial S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpartial+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> a well defined lower-dimensional volume; it possible to define a Cheeger constant of a manifold in a way that is syntactically analogous to the definition of edge expansion:</p>
<p align="center"><img alt="\displaystyle  \phi (M) = \min_{S : vol(S) \leq vol(M)/2} \ \ \ \frac{vol(\partial S)}{vol(S)} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cphi+%28M%29+%3D+%5Cmin_%7BS+%3A+vol%28S%29+%5Cleq+vol%28M%29%2F2%7D+%5C+%5C+%5C+%5Cfrac%7Bvol%28%5Cpartial+S%29%7D%7Bvol%28S%29%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>It is also possible to define a Laplacian operator <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> on smooth functions <img alt="{f: M \rightarrow {\mathbb C}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%3A+M+%5Crightarrow+%7B%5Cmathbb+C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and if <img alt="{\lambda_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the second smallest eigenvalue of <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> we have the characterization</p>
<p align="center"><img alt="\displaystyle  \lambda_2 = \min_{f : M \rightarrow {\mathbb R} \ \ {\rm smooth}, \int_M f = 0} \ \ \frac{ \langle Lf , f\rangle}{\langle f,f\rangle} = \min_{f : M \rightarrow {\mathbb R} \ \ {\rm smooth}, \int_M f = 0} \ \ \frac{ \int_M ||\nabla f||^2}{\int_M f^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_2+%3D+%5Cmin_%7Bf+%3A+M+%5Crightarrow+%7B%5Cmathbb+R%7D+%5C+%5C+%7B%5Crm+smooth%7D%2C+%5Cint_M+f+%3D+0%7D+%5C+%5C+%5Cfrac%7B+%5Clangle+Lf+%2C+f%5Crangle%7D%7B%5Clangle+f%2Cf%5Crangle%7D+%3D+%5Cmin_%7Bf+%3A+M+%5Crightarrow+%7B%5Cmathbb+R%7D+%5C+%5C+%7B%5Crm+smooth%7D%2C+%5Cint_M+f+%3D+0%7D+%5C+%5C+%5Cfrac%7B+%5Cint_M+%7C%7C%5Cnabla+f%7C%7C%5E2%7D%7B%5Cint_M+f%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and Cheeger proved</p>
<p align="center"><img alt="\displaystyle  \phi(M) \leq 2 \sqrt{\lambda_2 } " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cphi%28M%29+%5Cleq+2+%5Csqrt%7B%5Clambda_2+%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> which is syntactically almost the same inequality and, actually, has a syntactically very similar proof (the extra <img alt="{\sqrt 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> factor comes from the fact that things are normalized slightly differently).</p>
<p>The “dictionary” between finite graphs and compact manifolds is that vertices correspond to points, degree correspond to dimensionality, adjacent vertices <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> correspond to “infinitesimally close” points along one dimension, and the set of edges in the cut <img alt="{(S,V-S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28S%2CV-S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> correspond to the boundary <img alt="{\partial S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpartial+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of a set <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, “volume” corresponds to number of edges (both when we think of volume of the boundary and volume of a set), vectors <img alt="{x\in {\mathbb R}^V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin+%7B%5Cmathbb+R%7D%5EV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> correspond to smooth functions <img alt="{f: M \rightarrow {\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%3A+M+%5Crightarrow+%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and the collection of values of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> at the neighbors of a vertex <img alt="{\{ x_v : (u,v) \in E \}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+x_v+%3A+%28u%2Cv%29+%5Cin+E+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> corresponds to the gradient <img alt="{\nabla f(u)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cnabla+f%28u%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of a function at point <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>Having made this long premise, the point of this post is that the inequality</p>
<p align="center"><img alt="\displaystyle  \phi(G) \geq \frac {\lambda_2}2 \ , " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cphi%28G%29+%5Cgeq+%5Cfrac+%7B%5Clambda_2%7D2+%5C+%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> which is the easy direction to show in the graph case, does not hold for manifolds.</p>
<p>The easy proof for graphs is that if <img alt="{(S,V-S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28S%2CV-S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the cut that realizes the minimum edge expansion, we can take <img alt="{x = {\bf 1}_S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%3D+%7B%5Cbf+1%7D_S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, or rather the projection of the above vector on the space orthogonal to <img alt="{{\bf 1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and a two-line calculation gives the inequality.</p>
<p>If, however, <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a subset of points of the manifold that realizes the Cheeger constant, we cannot define <img alt="{f(\cdot)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to be the indicator of <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, because the function would not be smooth and its gradient would be undefined.</p>
<p>We could think of rescuing the proof by taking a smoothed version of the indicator of <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, something that goes to 1 on one side and to 0 on the other side of the cut, as a function of the distance from the boundary. The “quadratic form” of such a function, however, would depend not just on the area of the boundary of <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, but also on how quickly the volume of the subset of the manifold at distance <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> from the boundary of <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> grows as a function of <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>If the Ricci curvature of the manifold is negative, this volume grows very quickly, and the quadratic form of the smoothed function is very bad. The graph analog of this would be a graph made of two expanders joined by a bridge edge, and the problem is that the analogy between graphs and manifolds breaks down because “infinitesimal distance” in the manifold corresponds to any <img alt="{o(\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bo%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> distance on the graph, and although the bridge edge is a sparse cut in the graph, it is crossed by a lot of paths of length <img alt="{o(\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bo%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, or at least this is the best intuition that I have been able to build about what breaks down here in the analogy between graphs and manifolds.</p>
<p>If the Ricci curvature of the manifold is non-negative and the dimension is bounded, there is however an inequality in manifolds that goes in the direction of the “easy graph Cheeger inequality,” and it has the form</p>
<p align="center"><img alt="\displaystyle  \lambda_2 \leq 10 \phi^2 (M) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_2+%5Cleq+10+%5Cphi%5E2+%28M%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> This is the <em>Buser inequality</em> for manifolds of non-negative Ricci curvature, and note how strong it is: it says that <img alt="{\phi(M)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%28M%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{\sqrt{\lambda_2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7B%5Clambda_2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> approximate each other up to the constant factor <img alt="{2\sqrt{10}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Csqrt%7B10%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>If the Ricci curvature <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is negative, and <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the dimension of the manifold, then one has the inequality</p>
<p align="center"><img alt="\displaystyle  \lambda_2 \leq 2 \sqrt{|R| \cdot (n-1)} \cdot \phi(M) + 10 \phi^2 (M) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_2+%5Cleq+2+%5Csqrt%7B%7CR%7C+%5Ccdot+%28n-1%29%7D+%5Ccdot+%5Cphi%28M%29+%2B+10+%5Cphi%5E2+%28M%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>Given the importance that curvature has in the study of manifolds, there has been considerable interest in defining a notion of curvature for graphs. For example curvature relates to how quickly balls around a point grow with the diameter the ball, a concept that is of great importance in graphs as well; curvature is a locally defined concept that has a global consequences, and in graph property testing one is precisely interested in understanding global properties based on local ones; and a Buser-type inequality in graphs would be very interesting because it would provide a class of graphs for which Fiedler’s algorithm provides constant-factor approximation for sparsest cut.</p>
<p>There have been multiple attempts at defining notions of curvature for graphs, the main ones being Olivier curvature and Bakry-Emery curvature. Each captures some but not all of the useful properties of Ricci curvature in manifolds. My (admittedly, poorly informed) intuition is that curvature in manifold is defined “locally” but, as we mentioned above, “local” in graphs can have multiple meanings depending on the distance scale, and it is difficult to come up with a clean and usable definition that talks about multiple distance scales.</p>
<p>Specifically to the point of the Buser inequality, <a href="https://arxiv.org/pdf/1306.2561.pdf">Bauer et al</a> and <a href="https://arxiv.org/pdf/1501.00516.pdf">Klartag et al</a> prove Buser inequalities for graphs with respect to the Bakry-Emery definition. Because Cayley graphs of Abelian groups happen to have curvature 0 according to this definition, their work gives the following result:</p>
<blockquote><p><b>Theorem 1 (Buser inequality for Cayley graphs of Abelian groups)</b> <em> If <img alt="{G=(V,E)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%3D%28V%2CE%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-regular Cayley graph of an Abelian group, <img alt="{\lambda_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the second smallest normalized Laplacian eigenvalue of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{\phi(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the normalized edge expansion of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we have </em></p>
<p><em/></p><em>
<p align="center"><img alt="\displaystyle  \lambda_2 \leq O(d) \cdot \phi^2 (G) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_2+%5Cleq+O%28d%29+%5Ccdot+%5Cphi%5E2+%28G%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</em><p><em/><em> </em></p></blockquote>
<p>(Klartag et al. state the result as above; Bauer et al. state it only for certain groups, but I think that their proof applies to all Abelian groups)</p>
<p>In particular, the above statement implies that if we have a <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-regular Abelian Cayley graph then <img alt="{\sqrt {\lambda_2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt+%7B%5Clambda_2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> provides an approximation of the sparsest cut up to a multiplicative error <img alt="{O(\sqrt d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt+d%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and that Fiedler’s algorithm is an <img alt="{O(\sqrt d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt+d%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> approximate algorithm for sparsest cut in Abelian Cayley graphs.</p>
<p>At some point in 2015 (or maybe 2014, during the Simons program on spectral graph theory?), I read the paper of Bauer at al. and wondered about a few questions. First of all, is there a way to prove the above theorem without using any notion of curvature?</p>
<p>Secondly, the theorem implies that Fiedler’s algorithm has a good approximation, but it does so in a very unusual way: we have <img alt="{\lambda_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that is a continuous relaxation of the sparsest cut problem, and we have Fiedler’s algorithm that, as analyzed by Cheeger’s inequality, provides a somewhat bad rounding, and finally the Buser inequality is telling us that the relaxation has very poor integrality gap on all Abelian Cayley graphs, and so even though the rounding seems bad it is actually good compared to the integral optimum. There should be an underlying reason for all this, meaning some other relaxation that has an actual integrality gap for sparsest cut that is at most <img alt="{O(\sqrt d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt+d%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>I mentioned these questions to Shayan Oveis Gharan, and we were able to prove that if <img alt="{ARV(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BARV%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the value of the Arora-Rao-Vazirani (or Goemans-Linial) semidefinite programming relaxation of sparsest cut, then, for all <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-regular Cayley graphs, we have</p>
<p align="center"><img alt="\displaystyle  \lambda_2 \leq O(d) \cdot (ARV(G))^2 \leq O(d) \cdot \phi^2 (G) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_2+%5Cleq+O%28d%29+%5Ccdot+%28ARV%28G%29%29%5E2+%5Cleq+O%28d%29+%5Ccdot+%5Cphi%5E2+%28G%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> which proves the above theorem and, together with the Cheeger inequality <img alt="{\lambda_2 \geq \phi^2(G)/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_2+%5Cgeq+%5Cphi%5E2%28G%29%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, also shows</p>
<p align="center"><img alt="\displaystyle  \phi (G) \leq O(\sqrt d) \cdot ARV(G) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cphi+%28G%29+%5Cleq+O%28%5Csqrt+d%29+%5Ccdot+ARV%28G%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> that is, the ARV relaxation has integrality gap at most <img alt="{O(\sqrt d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt+d%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> on Abelian Cayley graphs. I will discuss the proof (which is a sort of “sum-of-squares version” of the proof of Bauer et al.) in the next post.</p></div>
    </content>
    <updated>2021-10-07T10:38:14Z</updated>
    <published>2021-10-07T10:38:14Z</published>
    <category term="math"/>
    <category term="theory"/>
    <category term="Buser inequality"/>
    <category term="Cheeger inequality"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2021-10-08T03:37:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/10/07/faculty-positions-at-all-levels-at-university-at-buffalo-apply-by-november-30-2021/</id>
    <link href="https://cstheory-jobs.org/2021/10/07/faculty-positions-at-all-levels-at-university-at-buffalo-apply-by-november-30-2021/" rel="alternate" type="text/html"/>
    <title>Faculty positions at all levels at University at Buffalo (apply by November 30, 2021)</title>
    <summary>We have 6 tenure/tenure track position out of which one is focused on theory. We are looking for folks in both algorithms and complexity. (The Nov 30 deadline is a suggestion, we will be considering applications a bit after that as well.) Website: https://www.ubjobs.buffalo.edu/postings/30481 Email: atri@buffalo.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We have 6 tenure/tenure track position out of which one is focused on theory. We are looking for folks in both algorithms and complexity. (The Nov 30 deadline is a suggestion, we will be considering applications a bit after that as well.)</p>
<p>Website: <a href="https://www.ubjobs.buffalo.edu/postings/30481">https://www.ubjobs.buffalo.edu/postings/30481</a><br/>
Email: atri@buffalo.edu</p></div>
    </content>
    <updated>2021-10-07T02:10:26Z</updated>
    <published>2021-10-07T02:10:26Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-10-08T03:37:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02809</id>
    <link href="http://arxiv.org/abs/2110.02809" rel="alternate" type="text/html"/>
    <title>Partial order alignment by adjacencies and breakpoints</title>
    <feedworld_mtime>1633564800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Rain.html">Rain Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Kai.html">Kai Jiang</a>, Minghui Jiang <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02809">PDF</a><br/><b>Abstract: </b>Linearizing two partial orders to maximize the number of adjacencies and
minimize the number of breakpoints is APX-hard. This holds even if one of the
two partial orders is already a linear order and the other is an interval
order, or if both partial orders are weak orders.
</p></div>
    </summary>
    <updated>2021-10-07T22:37:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02300</id>
    <link href="http://arxiv.org/abs/2110.02300" rel="alternate" type="text/html"/>
    <title>Complexity of Traveling Tournament Problem with Trip Length More Than Three</title>
    <feedworld_mtime>1633564800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chatterjee:Diptendu.html">Diptendu Chatterjee</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02300">PDF</a><br/><b>Abstract: </b>The Traveling Tournament Problem is a sports-scheduling problem where the
goal is to minimize the total travel distance of teams playing a double
round-robin tournament. The constraint 'k' is an imposed upper bound on the
number of consecutive home or away matches. It is known that TTP is NP-Hard for
k=3 as well as k=infinity. In this work, the general case has been settled by
proving that TTP-k is NP-Complete for any fixed k&gt;3.
</p></div>
    </summary>
    <updated>2021-10-07T22:38:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2110.02279</id>
    <link href="http://arxiv.org/abs/2110.02279" rel="alternate" type="text/html"/>
    <title>Turing approximations, toric isometric embeddings &amp; manifold convolutions</title>
    <feedworld_mtime>1633564800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>P. Suárez-Serrato <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2110.02279">PDF</a><br/><b>Abstract: </b>Convolutions are fundamental elements in deep learning architectures. Here,
we present a theoretical framework for combining extrinsic and intrinsic
approaches to manifold convolution through isometric embeddings into tori. In
this way, we define a convolution operator for a manifold of arbitrary topology
and dimension. We also explain geometric and topological conditions that make
some local definitions of convolutions which rely on translating filters along
geodesic paths on a manifold, computationally intractable. A result of Alan
Turing from 1938 underscores the need for such a toric isometric embedding
approach to achieve a global definition of convolution on computable, finite
metric space approximations to a smooth manifold.
</p></div>
    </summary>
    <updated>2021-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/10/06/postdoc-at-durham-university-apply-by-december-1-2021/</id>
    <link href="https://cstheory-jobs.org/2021/10/06/postdoc-at-durham-university-apply-by-december-1-2021/" rel="alternate" type="text/html"/>
    <title>Postdoc at Durham University (apply by December 1, 2021)</title>
    <summary>I’m looking for a postdoctoral researcher from Jan 22 to work on an EPSRC-funded project on password-hashing algorithms and idealized models of computation at Durham Uni. Applicants with backgrounds in Cryptography, Algorithms and Complexity are very welcome. Durham is one of the top universities in the UK, &amp; the CS dept. hosts one of the […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’m looking for a postdoctoral researcher from Jan 22 to work on an EPSRC-funded project on password-hashing algorithms and idealized models of computation at Durham Uni. Applicants with backgrounds in Cryptography, Algorithms and Complexity are very welcome. Durham is one of the top universities in the UK, &amp; the CS dept. hosts one of the strongest theory groups across the ACiD and NESTiD groups.</p>
<p>Website: <a href="https://gow.epsrc.ukri.org/NGBOViewGrant.aspx?GrantRef=EP/V034065/1">https://gow.epsrc.ukri.org/NGBOViewGrant.aspx?GrantRef=EP/V034065/1</a><br/>
Email: pooya.farshim@gmail.com</p></div>
    </content>
    <updated>2021-10-06T16:26:12Z</updated>
    <published>2021-10-06T16:26:12Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-10-08T03:37:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://ptreview.sublinear.info/?p=1576</id>
    <link href="https://ptreview.sublinear.info/2021/10/news-for-september-2021/" rel="alternate" type="text/html"/>
    <title>News for September 2021</title>
    <summary>A nice array of papers for this month, ranging from distribution testing, dense graph property testing, sublinear graph algorithms, and various mixtures of them. Let us now sample our spread! (Adding another semistreaming paper who achieved similar results to another posted paper. -Ed) A Lower Bound on the Complexity of Testing Grained Distributions by Oded […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p id="block-79f77829-3f22-4392-8cc9-3f466129d855">A nice array of papers for this month, ranging from distribution testing, dense graph property testing, sublinear graph algorithms, and various mixtures of them. Let us now sample our spread! <em>(Adding another semistreaming paper who achieved similar results to another posted paper. -Ed)</em></p>



<p id="block-db4c65bf-46c4-4c3e-ad70-d3348de84ff3"><strong>A Lower Bound on the Complexity of Testing Grained Distributions</strong> by Oded Goldreich and Dana Ron (<a href="https://eccc.weizmann.ac.il/report/2021/129/">ECCC</a>). A discrete distribution is called \(m\)-grained if all probabilities are integer multiples of \(1/m\). This paper studies the complexity of testing this property of distributions. For simplicity, consider the property of being \(n/2\)-grained, where the support size is \(n\). The classic lower bound for testing uniformity shows that \(\Omega(\sqrt{n})\) samples are required to distinguish the uniform distribution from a distribution uniform on \(n/2\) elements. Thus, we get a lower bound of \(\Omega(\sqrt{n})\) for testing \(n/2\)-grainedness (if I am permitted to use that word). This paper proves a lower bound of \(\Omega(n^c)\), for all constant \(c &lt; 1\). It is conjectured that the lower bound is actually \(\Omega(n/\log n)\), which would match the upper bound (for any label-invariant property).</p>



<p><strong>Testing Distributions of Huge Objects</strong> by Oded Goldreich and Dana Ron (<a href="https://eccc.weizmann.ac.il/report/2021/133/">ECCC</a>). This paper introduced a new model that marries distribution testing with property testing on strings. The “object” of interest is a distribution \(\mathcal{D}\) over strings of length \(n\). We wish to test if \(\mathcal{D}\) possesses some property. The tester can get a random string \(x\) from the distribution, and can query any desired index of \(x\). The distance between distributions is defined using the earthmover distance (where we use the Hamming distance between strings). This model is called the DoHO (Distributions of Huge Objects) model. There are many questions posed and connections drawn to classical property testing and distribution testing. What I find interesting is a compelling application: the distribution \(\mathcal{D}\) may represent noisy or perturbed versions of a single object. The DoHO model gives a natural generalization of standard property testing to noisy objects. This paper considers problems such as testing if \(\mathcal{D}\) is: a random perturbation of a string, or a random cyclic shift, or a random isomorphism of a graph. </p>



<p><strong>Sublinear Time and Space Algorithms for Correlation Clustering via Sparse-Dense Decompositions</strong> by Sepehr Assadi and Chen Wang (<a href="https://arxiv.org/pdf/2109.14528.pdf">arXiv</a>). Correlation clustering is a classic problem where edges in a graph are labeled ‘+’ or ‘-‘, denoting whether these edges should be uncut or cut. The aim is to cluster the graph minimizing the total “disagreements” (cut ‘+’ edges or uncut ‘-‘ edges). This paper gives an \(O(1)\)-approximation algorithm that runs in \(O(n\log^2n)\) time; this is the first sublinear time approximation algorithm for this problem. Correlation clustering has seen results for the property testing/sublinear algorithms community, first by <a href="https://arxiv.org/abs/1312.5105">Bonchi, Garcia Soriano, and Kutzkov</a>. But previous results were essentially on the dense graph model, giving \(O(\epsilon n^2)\) error assuming adjacency matrix input. This paper considers access to the adjacency list of ‘+’ edges. Interestingly (from a technical standpoint), the key tool is a new <em>sparse-dense</em> decomposition. Such decompositions emerged from the seminal work of <a href="https://arxiv.org/abs/1807.08886">Assadi-Chen-Khanna</a> for sublinear \((\Delta+1)\)-colorings, and it is great to see applications beyond coloring.</p>



<p><strong>Sublinear-Time Computation in the Presence of Online Erasures</strong> by Iden Kalemaj, Sofya Raskhodnikova, and Nithin Varma (<a href="https://arxiv.org/abs/2109.08745">arXiv</a>). Can property testing be done when portions of the input are hidden? This question was first raised by <a href="https://arxiv.org/abs/1607.05786">Dixit-Raskhodnikova-Thakurta-Varma</a>, who gave a model of <em>erasure-resilient testing.</em> There is an adversary who hides (erases) part of the input function; queries to those parts just yield a dummy symbol. This paper defines an online version of this model. There is an erasure parameter \(t\). On each query by the property tester, the adversary can erase \(t\) values of the function. Consider the property of classic linearity of functions \(f:\{0,1\}^d \rightarrow \{0,1\}\). The BLR tester queries triples of pairs \((x,y, x \oplus y)\). Observe how this tester is easily defeated by our adversary, by erasing the value \(f(x\oplus y)\). One of the main results of this paper is a \(O(1/\varepsilon)\)-query tester for linearity, that works for any constant erasure parameter \(t\). Note that this matches the bound for the standard setting. There are a number of results for other classic properties, such as monotonicity (sortedness) and Lipschitz.</p>



<p>S<strong>ublinear Time Eigenvalue Approximation via Random Sampling</strong> by Rajarshi Bhattacharjee, Cameron Musco, and Archan Ray (<a href="https://arxiv.org/abs/2109.07647">arXiv</a>). Consider the problem of estimating all the eigenvalues of a real, symmetric \(n \times n\) matrix \(M\) with bounded entries, in sublinear time. The main result shows that the eigenvalues of a uniform random \(O(\epsilon^{-4}\log n)\) principal submatrix can be used to approximate all eigenvalues of \(M\) up to additive error \(\epsilon n\). One can think of this as a sort of concentration inequality for eigenvalues. This result follows (and builds upon) work of <a href="https://arxiv.org/abs/2005.06441">Bakshi-Chepurko-Jayaram</a> on property testing semidefiniteness. The key idea is that eigenvectors corresponding to large eigenvalues have small infinity norm: intuitively, since all entries in \(M\) are bounded, such an eigenvector must have its mass spread out among many coordinates. Hence, we can get information about it by randomly sampling a few coordinates. The paper also shows that approach of taking principal submatrices requires taking \(\Omega(\epsilon^{-2})\) columns/rows.</p>



<p><strong>Deterministic Graph Coloring in the Streaming Model</strong> by Sepehr Assadi, Andrew Chen, and Glenn Sun (arXiv). This is technically not a sublinear algorithms paper<em> (well ok, streaming is sublinear, but we tend not to cover the streaming literature. Maybe we should? – Ed.)</em> But, I think that the connections are of interest to our community of readers. The main tool of sublinear \((\Delta+1)\)-coloring algorithm of <a href="https://arxiv.org/abs/1807.08886">Assadi-Chen-Khanna</a> is the palette sparsification lemma (\(\Delta\) is the maximum degree). This lemma shows that vertices can randomly shorten their ”palette” of colors, after which all colorings from these palettes lead to very few monochromatic edges. This is an immensely powerful tool, since one can get immediately sublinear complexity algorithms in many models: adjacency list, streaming, distributed. Is the randomness necessary? Note that these algorithms run in \(\Omega(n)\) time/space, so it is conceivable that deterministic sublinear algorithms exists. This paper shows that randomization is necessary in the semi-streaming model (space \(O(n poly(\log n))\)). Indeed, there exist no deterministic semi-streaming algorithms that can achieve even \(\exp(\Delta^{o(1)})\) colorings.</p>



<p><strong>Adversarially Robust Coloring for Graph Stream</strong> by Amit Chakrabarti, Prantar Ghosh, and Manuel Stoeckl (<a href="https://arxiv.org/abs/2109.11130">arXiv</a>). This paper studies the same problem as the above, but presents the results in a different way. In a randomized algorithm, we normally think of an adversary that fixes a (hard) input, and the algorithm then makes its random decisions. An adaptive adversary is one that changes the input (stream) based on the decisions of an algorithm. In this definition, a robust algorithm is one that can give correct answers, even for adversarially generated output. A deterministic algorithm is automatically robust. This paper show that there do not exist semi-streaming algorithms that can achieve \((\Delta+1)\)-colorings. The quantitative lower bound is weaker (\(\Omega(\Delta^2)\) colors), but it is against a stronger adversary.</p></div>
    </content>
    <updated>2021-10-06T04:31:45Z</updated>
    <published>2021-10-06T04:31:45Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Seshadhri</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2021-10-08T00:47:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=573</id>
    <link href="https://tcsplus.wordpress.com/2021/10/05/tcs-talk-wednesday-october-13-nutan-limaye-it-university-of-copenhagen/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, October 13 — Nutan Limaye, IT University of Copenhagen</title>
    <summary>The next TCS+ talk will take place next Wednesday, October 13th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC: check your time zone!). Nutan Limaye from IT University of Copenhagen will speak about “Superpolynomial Lower Bounds Against Low-Depth Algebraic Circuits” (abstract below). You can reserve a spot as […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place next Wednesday, October 13th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC: <a href="https://www.timeanddate.com/worldclock/converter.html?iso=20211013T170000&amp;p1=tz_pt&amp;p2=tz_et&amp;p3=tz_cest&amp;p4=1440">check your time zone!</a>). <a href="https://www.cse.iitb.ac.in/~nutan/"><strong>Nutan Limaye</strong></a> from IT University of Copenhagen will speak about “<em>Superpolynomial Lower Bounds Against Low-Depth Algebraic Circuits</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: Every multivariate polynomial P(X) can be written as a sum of monomials, i.e. a sum of products of variables and field constants. In general, the size of such an expression is the number of monomials that have a non-zero coefficient in P.</p>
<p>What happens if we add another layer of complexity, and consider sums of products of sums (of variables and field constants) expressions? Now, it becomes unclear how to prove that a given polynomial P(X) does not have small expressions. In this result, we solve exactly this problem.</p>
<p>More precisely, we prove that certain explicit polynomials have no polynomial-sized “Sigma-Pi-Sigma” (sums of products of sums) representations. We can also show similar results for Sigma-Pi-Sigma-Pi, Sigma-Pi-Sigma-Pi-Sigma and so on for all “constant-depth” expressions.</p>
<p>The talk is based on a joint work of Nutan Limaye, Srikanth Srinivasan, and Sébastien Tavenas.</p></blockquote></div>
    </content>
    <updated>2021-10-05T21:34:49Z</updated>
    <published>2021-10-05T21:34:49Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2021-10-08T03:38:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4554</id>
    <link href="https://lucatrevisan.wordpress.com/2021/10/05/hasselmann-manabe-and-parisi-win-2021-physics-nobel-prize/" rel="alternate" type="text/html"/>
    <title>Hasselmann, Manabe and Parisi win 2021 Physics Nobel Prize</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Today the Italian academic community, along with lots of other people, was delighted to hear that Giorgio Parisi is one of the three recipients of the 2021 Nobel Prize for Physics. Parisi has been a giant in the area of … <a href="https://lucatrevisan.wordpress.com/2021/10/05/hasselmann-manabe-and-parisi-win-2021-physics-nobel-prize/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><img alt="itscomingrome-lorenza-parisi" class="alignnone size-full wp-image-4558" src="https://lucatrevisan.files.wordpress.com/2021/10/itscomingrome-lorenza-parisi-1.jpeg?w=584"/></p>
<p>Today the Italian academic community, along with lots of other people, was delighted to hear that <a href="https://en.wikipedia.org/wiki/Giorgio_Parisi">Giorgio Parisi</a> is one of the three recipients of the 2021 Nobel Prize for Physics.</p>
<p>Parisi has been a giant in the area of understanding “complex” and “disordered” systems. Perhaps, his most influential contribution has been his “replica method” for the analysis of the Sherrington-Kirkpatrick model. His ideas have led to several breakthroughs in statistical physics by Parisi and his collaborators, and they have also found applications in computer science: to tight analyses on a number of questions about combinatorial optimization on random graphs, to results on random constraint satisfaction problems (including the famous connection with random k-SAT analyzed by Mezard, Parisi and Zecchina) and random error correcting codes, and to understanding the solution landscape in optimization problems arising from machine learning. Furthermore these ideas have also led to the development and analysis of algorithms.</p>
<p>The news was particularly well received at Bocconi, where most of the faculty of the future CS department has done work that involved the replica method. (Not to be left out, even I <a href="https://arxiv.org/abs/2008.05648">have recently used replica methods</a>.)</p>
<p>Mezard and Montanari have written a <a href="https://web.stanford.edu/~montanar/RESEARCH/book.html">book-length treatment</a> on the interplay between ideas from statistical physics, algorithms, optimization, information theory and coding theory that arise from this tradition. Readers of <em>in theory</em> looking for a shorter exposition aimed at theoretical computer scientists will enjoy these <a href="https://windowsontheory.org/2021/08/11/replica-method-for-the-machine-learning-theorist-part-1-of-2/">notes posted by Boaz Barak</a>, or <a href="https://windowsontheory.org/2018/03/14/statistical-physics-dictionary/">this even shorter post by Boaz</a>.</p>
<p>In this post, I will try to give a sense to the reader of what the replica method for the Sherrington-Kirkpatrick model looks like when applied to the average-case analysis of optimization problems, stripped of all the physics. Of course, without the physics, nothing makes any sense, and the interested reader should look at Boaz’s posts (and to references that he provides) for an introduction to the context. I did not have time to check too carefully what I wrote, so be aware that several details could be wrong.</p>
<p>What is the typical value of the max cut in a <img alt="{G_{n,\frac 12}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG_%7Bn%2C%5Cfrac+12%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> random graph with <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> vertices?</p>
<p>Working out an upper bound using union bounds and Chernoff bound, and a lower bound by thinking about a greedy algorithm, we can quickly convince ourselves that the answer is <img alt="{\frac {n^2}{4} + \Theta(n^{1.5})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac+%7Bn%5E2%7D%7B4%7D+%2B+%5CTheta%28n%5E%7B1.5%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Great, but <em>what is the constant in front of the <img alt="{n^{1.5}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B1.5%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>?</em> This question is answered by the <em>Parisi formula</em>, though this fact was not rigorously established by Parisi. (Guerra proved that the formula gives an upper bound, Talagrand proved that it gives a tight bound.)</p>
<p>Some manipulations can reduce the question above to the following question: suppose that I pick a random <img alt="{n\times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> symmetric matrix <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, say with zero diagonal, and such that (up to the symmetry requirement) the entries are mutually independent and each entry is equally likely to be <img alt="{+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> or <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, or perhaps each entry is distributed according to a standard normal distribution (the two versions can be proved to be equivalent), what is the typical value of</p>
<p align="center"><img alt="\displaystyle  \max _{x \in \{+1,1\}^n } \ \ \frac 1{n^{1.5}} x^T M x " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmax+_%7Bx+%5Cin+%5C%7B%2B1%2C1%5C%7D%5En+%7D+%5C+%5C+%5Cfrac+1%7Bn%5E%7B1.5%7D%7D+x%5ET+M+x+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> up to <img alt="{o_n(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bo_n%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> additive terms,?</p>
<p>As a first step, we could replace the maximum with a “soft-max,” and note that, for every choice of <img alt="{\beta&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we have</p>
<p align="center"><img alt="\displaystyle  \max _{x \in \{+1,1\}^n } \ \ x^T M x \leq \frac 1 \beta \log \sum_{x \in \{+1,1\}^n } e^{\beta x^T Mx} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmax+_%7Bx+%5Cin+%5C%7B%2B1%2C1%5C%7D%5En+%7D+%5C+%5C+x%5ET+M+x+%5Cleq+%5Cfrac+1+%5Cbeta+%5Clog+%5Csum_%7Bx+%5Cin+%5C%7B%2B1%2C1%5C%7D%5En+%7D+e%5E%7B%5Cbeta+x%5ET+Mx%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> The above upper bound gets tighter and tighter for larger <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, so if we were able to estimate</p>
<p align="center"><img alt="\displaystyle  \mathop{\mathbb E} \log \sum_{x \in \{+1,1\}^n } e^{\beta x^T Mx} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Clog+%5Csum_%7Bx+%5Cin+%5C%7B%2B1%2C1%5C%7D%5En+%7D+e%5E%7B%5Cbeta+x%5ET+Mx%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> for every <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (where the expectation is over the randomness of <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>) then we would be in good shape.</p>
<p>We could definitely use convexity and write</p>
<p align="center"><img alt="\displaystyle  \mathop{\mathbb E} \max _{x \in \{+1,1\}^n } \ \ x^T M x \leq \frac 1 \beta \mathop{\mathbb E} \log \sum_{x \in \{+1,1\}^n } e^{\beta x^T Mx} \leq \frac 1 \beta \log \mathop{\mathbb E} \sum_{x \in \{+1,1\}^n } e^{\beta x^T Mx} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Cmax+_%7Bx+%5Cin+%5C%7B%2B1%2C1%5C%7D%5En+%7D+%5C+%5C+x%5ET+M+x+%5Cleq+%5Cfrac+1+%5Cbeta+%5Cmathop%7B%5Cmathbb+E%7D+%5Clog+%5Csum_%7Bx+%5Cin+%5C%7B%2B1%2C1%5C%7D%5En+%7D+e%5E%7B%5Cbeta+x%5ET+Mx%7D+%5Cleq+%5Cfrac+1+%5Cbeta+%5Clog+%5Cmathop%7B%5Cmathbb+E%7D+%5Csum_%7Bx+%5Cin+%5C%7B%2B1%2C1%5C%7D%5En+%7D+e%5E%7B%5Cbeta+x%5ET+Mx%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and then use linearity of expectation and independence of the entries of <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to get to</p>
<p align="center"><img alt="\displaystyle  \leq \frac 1 \beta \log \sum_{x \in \{+1,1\}^n } \prod_{1\leq i &lt; j\leq n} \mathop{\mathbb E} e^{2\beta M_{i,j} x_i x_j } " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+%5Cfrac+1+%5Cbeta+%5Clog+%5Csum_%7Bx+%5Cin+%5C%7B%2B1%2C1%5C%7D%5En+%7D+%5Cprod_%7B1%5Cleq+i+%3C+j%5Cleq+n%7D+%5Cmathop%7B%5Cmathbb+E%7D+e%5E%7B2%5Cbeta+M_%7Bi%2Cj%7D+x_i+x_j+%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> Now things simplify quite a bit, because for all <img alt="{i&lt;j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%3Cj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> the expression <img alt="{M_{i,j} x_i x_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM_%7Bi%2Cj%7D+x_i+x_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, in the Rademacher setting, is equally likely to be <img alt="{+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> or <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, so that, for <img alt="{\beta = o(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta+%3D+o%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we have</p>
<p align="center"><img alt="\displaystyle  \mathop{\mathbb E} e^{2\beta M_{i,j} x_i x_j } = cosh (2\beta) \leq 1 + O(\beta^2) \leq e^{O(\beta^2)} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+e%5E%7B2%5Cbeta+M_%7Bi%2Cj%7D+x_i+x_j+%7D+%3D+cosh+%282%5Cbeta%29+%5Cleq+1+%2B+O%28%5Cbeta%5E2%29+%5Cleq+e%5E%7BO%28%5Cbeta%5E2%29%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and</p>
<p align="center"><img alt="\displaystyle  \sum_{x \in \{+1,1\}^n } \prod_{1\leq i &lt; j\leq n} \mathop{\mathbb E} e^{2\beta M_{i,j} x_i x_j } \leq 2^n \cdot e^{O(\beta^2 n^2)} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bx+%5Cin+%5C%7B%2B1%2C1%5C%7D%5En+%7D+%5Cprod_%7B1%5Cleq+i+%3C+j%5Cleq+n%7D+%5Cmathop%7B%5Cmathbb+E%7D+e%5E%7B2%5Cbeta+M_%7Bi%2Cj%7D+x_i+x_j+%7D+%5Cleq+2%5En+%5Ccdot+e%5E%7BO%28%5Cbeta%5E2+n%5E2%29%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> so that</p>
<p align="center"><img alt="\displaystyle  \frac 1 \beta \log \sum_{x \in \{+1,1\}^n } \prod_{1\leq i &lt; j\leq n} \mathop{\mathbb E} e^{2\beta M_{i,j} x_i x_j } \leq \frac {O(n)}{\beta} + O(\beta n^2) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac+1+%5Cbeta+%5Clog+%5Csum_%7Bx+%5Cin+%5C%7B%2B1%2C1%5C%7D%5En+%7D+%5Cprod_%7B1%5Cleq+i+%3C+j%5Cleq+n%7D+%5Cmathop%7B%5Cmathbb+E%7D+e%5E%7B2%5Cbeta+M_%7Bi%2Cj%7D+x_i+x_j+%7D+%5Cleq+%5Cfrac+%7BO%28n%29%7D%7B%5Cbeta%7D+%2B+O%28%5Cbeta+n%5E2%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> which, choosing <img alt="{\beta = 1/\sqrt n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta+%3D+1%2F%5Csqrt+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, gives an <img alt="{O(n^{1.5})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%7B1.5%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> upper bound which is in the right ballpark. Note that this is exactly the same calculations coming out of a Chernoff bound and union bound. If we optimize the choice of <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> we unfortunately do not get the right constant in front of <img alt="{n^{1.5}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B1.5%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>So, if we call</p>
<p align="center"><img alt="\displaystyle  F := \sum_{x \in \{+1,1\}^n } e^{\beta x^T Mx} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F+%3A%3D+%5Csum_%7Bx+%5Cin+%5C%7B%2B1%2C1%5C%7D%5En+%7D+e%5E%7B%5Cbeta+x%5ET+Mx%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> we see that we lose too much if we do the step</p>
<p align="center"><img alt="\displaystyle  \mathop{\mathbb E} \log F \leq \log \mathop{\mathbb E} F " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Clog+F+%5Cleq+%5Clog+%5Cmathop%7B%5Cmathbb+E%7D+F+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> But what else can we do to get rid of the logarithm and to reduce to an expression in which we take expectations of products of independent quantities (if we are not able to exploit the assumption that <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> has mutually independent entries, we will not be able to make progress)?</p>
<p>The idea is that if <img alt="{k&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a small enough quantity (something much smaller than <img alt="{1/\log F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F%5Clog+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>), then <img alt="{F^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is close to 1 and we have the approximation</p>
<p align="center"><img alt="\displaystyle  \log F^k \approx F^k-1 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clog+F%5Ek+%5Capprox+F%5Ek-1+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and we obviously have</p>
<p align="center"><img alt="\displaystyle  \log F^k = k \log F " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clog+F%5Ek+%3D+k+%5Clog+F+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> so we can use the approximation</p>
<p align="center"><img alt="\displaystyle  \log F \approx \frac 1k (F^k - 1) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clog+F+%5Capprox+%5Cfrac+1k+%28F%5Ek+-+1%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and</p>
<p align="center"><img alt="\displaystyle  \mathop{\mathbb E} \log F \approx \frac 1k (\mathop{\mathbb E} F^k - 1) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Clog+F+%5Capprox+%5Cfrac+1k+%28%5Cmathop%7B%5Cmathbb+E%7D+F%5Ek+-+1%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> Let’s forget for a moment that we want <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to be a very small parameter. If <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> was an integer, we would have</p>
<p align="center"><img alt="\displaystyle  \mathop{\mathbb E} F^k = \mathop{\mathbb E} \left( \sum_{x \in \{+1,1\}^n } e^{\beta x^T Mx} \right)^k = \sum_{x^{(1)},\ldots x^{(k)} \in \{+1,-1\}^n} \mathop{\mathbb E} e^{\beta \cdot ( x^{(1) T} M x^{(1)} + \cdots + x^{(k)T} M x^{(k)}) } " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+F%5Ek+%3D+%5Cmathop%7B%5Cmathbb+E%7D+%5Cleft%28+%5Csum_%7Bx+%5Cin+%5C%7B%2B1%2C1%5C%7D%5En+%7D+e%5E%7B%5Cbeta+x%5ET+Mx%7D+%5Cright%29%5Ek+%3D+%5Csum_%7Bx%5E%7B%281%29%7D%2C%5Cldots+x%5E%7B%28k%29%7D+%5Cin+%5C%7B%2B1%2C-1%5C%7D%5En%7D+%5Cmathop%7B%5Cmathbb+E%7D+e%5E%7B%5Cbeta+%5Ccdot+%28+x%5E%7B%281%29+T%7D+M+x%5E%7B%281%29%7D+%2B+%5Ccdots+%2B+x%5E%7B%28k%29T%7D+M+x%5E%7B%28k%29%7D%29+%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p align="center"><img alt="\displaystyle  = \sum_{x^{(1)},\ldots x^{(k)} \in \{+1,-1\}^n} \ \ \prod_{i&lt; j} \ \mathop{\mathbb E} e^{2\beta M_{i,j} \cdot ( x^{(1)}_i x^{(1)}_j + \cdots + x^{(k)}_i x^{(k)}_j )} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+%5Csum_%7Bx%5E%7B%281%29%7D%2C%5Cldots+x%5E%7B%28k%29%7D+%5Cin+%5C%7B%2B1%2C-1%5C%7D%5En%7D+%5C+%5C+%5Cprod_%7Bi%3C+j%7D+%5C+%5Cmathop%7B%5Cmathbb+E%7D+e%5E%7B2%5Cbeta+M_%7Bi%2Cj%7D+%5Ccdot+%28+x%5E%7B%281%29%7D_i+x%5E%7B%281%29%7D_j+%2B+%5Ccdots+%2B+x%5E%7B%28k%29%7D_i+x%5E%7B%28k%29%7D_j+%29%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> Note that the above expression involves choices of <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-tuples of feasible solutions of our maximization problem. These are the “replicas” in “replica method.”</p>
<p>The above expression does not look too bad, and note how we were fully able to use the independence assumption and “simplify” the expression. Unfortunately, it is actually still very bad. In this case it is preferable to assume the <img alt="{M_{i,j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM_%7Bi%2Cj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to be Gaussian, write the expectation as an integral, do a change of variable and some tricks so that we reduce to computing the maximum of a certain function, let’s call it <img alt="{G(z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, where the input <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a <img alt="{k \times k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%5Ctimes+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> matrix, and then we have to guess what is an input of maximum value for this function. If we are lucky, the maximum is equivalent by a <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in which all entries are identical, the <em>replica symmetric solution</em>. In the Sherrington-Kirkpatrick model we don’t have such luck, and the next guess is that the optimal <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a block-diagonal matrix, or a <em>replica symmetry-breaking solution</em>. For large <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and large number of blocks, we can approximate the choice of such matrices by writing down a system of differential equations, the <em>Parisi equations</em>, and we are going to assume that such equations do indeed describe an optimal <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and so a solution to the integral, and so they give as a computation of <img alt="{(\mathop{\mathbb E} F^k - 1)/k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cmathop%7B%5Cmathbb+E%7D+F%5Ek+-+1%29%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>After all this, we get an expression for <img alt="{(\mathop{\mathbb E} F^k - 1)/k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cmathop%7B%5Cmathbb+E%7D+F%5Ek+-+1%29%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for every sufficiently large integer <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, as a function of <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> up to lower order errors. What next? Remember how we wanted <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to be a tiny real number and not a sufficiently large integer? Well, we take the expression, we forget about the error terms, and we set <img alt="{k=0\ldots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D0%5Cldots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p></div>
    </content>
    <updated>2021-10-05T20:53:23Z</updated>
    <published>2021-10-05T20:53:23Z</published>
    <category term="science"/>
    <category term="Giorgio Parisi"/>
    <category term="things that are excellent"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2021-10-08T03:37:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/10/05/tenure-track-faculty-positions-at-portland-state-university-apply-by-november-1-2021/</id>
    <link href="https://cstheory-jobs.org/2021/10/05/tenure-track-faculty-positions-at-portland-state-university-apply-by-november-1-2021/" rel="alternate" type="text/html"/>
    <title>tenure-track faculty positions at Portland State University (apply by November 1, 2021)</title>
    <summary>The Computer Science department at Portland State University has multiple Faculty openings this year. Theory is a top interest area. One position is part of a cluster hire in computational science, which also welcomes theory folks if their research intersects with big data analysis, scalable ML, scientific computing etc. Website: https://www.pdx.edu/computer-science/open-faculty-positions Email: cssearch@pdx.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Computer Science department at Portland State University has multiple Faculty openings this year. Theory is a top interest area. One position is part of a cluster hire in computational science, which also welcomes theory folks if their research intersects with big data analysis, scalable ML, scientific computing etc.</p>
<p>Website: <a href="https://www.pdx.edu/computer-science/open-faculty-positions">https://www.pdx.edu/computer-science/open-faculty-positions</a><br/>
Email: cssearch@pdx.edu</p></div>
    </content>
    <updated>2021-10-05T20:16:35Z</updated>
    <published>2021-10-05T20:16:35Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-10-08T03:37:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5859</id>
    <link href="https://www.scottaaronson.com/blog/?p=5859" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5859#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5859" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">The Physics Nobel, Gaussian BosonSampling, and Dorian Abbot</title>
    <summary xml:lang="en-US">1. Huge congratulations to the winners of this year’s Nobel Prize in Physics: Syukuro Manabe and Klaus Hasselmann for climate modelling, and separately, Giorgio Parisi for statistical physics. While I don’t know the others, I had the great honor to get to know Parisi three years ago, when he was chair of the committee that […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>1. Huge congratulations to the <a href="https://www.nobelprize.org/prizes/physics/2021/summary/">winners</a> of this year’s Nobel Prize in Physics: <a href="https://en.wikipedia.org/wiki/Syukuro_Manabe">Syukuro Manabe</a> and <a href="https://en.wikipedia.org/wiki/Klaus_Hasselmann">Klaus Hasselmann</a> for climate modelling, and separately, <a href="https://en.wikipedia.org/wiki/Giorgio_Parisi">Giorgio Parisi</a> for statistical physics.  While I don’t know the others, I had the great honor to get to know Parisi three years ago, when he was chair of the committee that awarded me the <a href="https://www.scottaaronson.com/blog/?p=3955">Tomassoni-Chisesi Prize in Physics</a>, and when I visited Parisi’s department at Sapienza University of Rome to give the prize lecture and collect the award.  I remember Parisi’s kindness, a lot of good food, and a lot of discussion of the interplay between theoretical computer science and physics.  Note that, while much of Parisi’s work is beyond my competence to comment on, in computer science he’s very well-known for applying statistical physics methods to the analysis of <a href="https://arxiv.org/abs/cs/0212002">survey propagation</a>—an algorithm that revolutionized the study of random 3SAT when it was introduced two decades ago.</p>



<hr class="wp-block-separator"/>



<p>2. Two weeks ago, a group at Google <a href="https://arxiv.org/abs/2109.11525">put out a paper</a> with a new efficient classical algorithm to simulate the recent Gaussian BosonSampling experiments from USTC in China.  They argued that this algorithm called into question USTC’s claim of BosonSampling-based quantum supremacy.  Since then, I’ve been in contact with Sergio Boixo from Google, Chaoyang Lu from USTC, and Jelmer Renema, a Dutch BosonSampling expert and friend of the blog, to try to get to the bottom of this.  Very briefly, the situation seems to be that Google’s new algorithm outperforms the USTC experiment on one particular metric: namely, <em>total variation distance from the ideal marginal distribution, if (crucially) you look at only a subset of the optical modes</em>, <em>say 14 modes out of 144 total</em>.  Meanwhile, though, if you look at the k<sup>th</sup>-order correlations for large values of k, then the USTC experiment continues to win.  With the experiment, the correlations fall off exponentially with k but still have a meaningful, detectable signal even for (say) k=19, whereas with Google’s spoofing algorithm, you choose the k that you want to spoof (say, 2 or 3), and then the correlations become nonsense for larger k.</p>



<p>Now, given that you were only ever <em>supposed</em> to see a quantum advantage from BosonSampling if you looked at the k<sup>th</sup>-order correlations for large values of k, and given that we already knew, from the work of Leonid Gurvits, that <em>very</em> small marginals in BosonSampling experiments would be easy to reproduce on a classical computer, my inclination is to say that USTC’s claim of BosonSampling-based quantum supremacy still stands.  On the other hand, it’s true that, with BosonSampling especially, more so than with qubit-based random circuit sampling, we currently lack an adequate theoretical understanding of what the <em>target</em> should be.  That is, which numerical metric should an experiment aim to maximize, and how well does it have to score on that metric before it’s plausibly outperforming any fast classical algorithm?  One thing I feel confident about is that, whichever metric is chosen—Linear Cross-Entropy or whatever else—it needs to capture the k<sup>th</sup>-order correlations for large values of k.  No metric that’s insensitive to those correlations is good enough.</p>



<hr class="wp-block-separator"/>



<p>3. Like many others, I was outraged and depressed that MIT <a href="https://bariweiss.substack.com/p/mit-abandons-its-mission-and-me">uninvited Dorian Abbot</a> (see also <a href="https://www.newsweek.com/mit-cancels-geophysicists-lecture-after-activists-outrage-over-his-views-diversity-1635371">here</a>), a geophysicist at the University of Chicago, who was slated to give the Carlson Lecture in the Department of Earth, Atmospheric, and Planetary Sciences about the atmospheres of extrasolar planets.  The reason for the cancellation was that, totally unrelatedly to his scheduled lecture, Abbot had <a href="https://www.newsweek.com/diversity-problem-campus-opinion-1618419">argued in <em>Newsweek</em></a> and elsewhere that Diversity, Equity, and Inclusion initiatives should aim for equality for opportunity rather than equality of outcomes, a Twitter-mob decided to go after him in retaliation, and they succeeded.  It should go without saying that it’s perfectly reasonable to <strong>disagree</strong> with Abbot’s stance, to <strong>counterargue</strong>—if those very concepts haven’t gone the way of floppy disks.  It should also go without saying that the MIT EAPS department chair is <em>free</em> to bow to social-media pressure, as he did, rather than standing on principle … just like I’m <em>free</em> to criticize him for it.  To my mind, though, cancelling a scientific talk because of the speaker’s centrist (!) political views completely, 100% validates the right’s narrative about academia, that it’s become a fanatically intolerant echo chamber.  To my fellow progressive academics, I beseech thee in the bowels of Bertrand Russell: <em>why would you commit such an unforced error?</em></p>



<p>Yes, one can <em>imagine</em> views (e.g., open Nazism) so hateful that they might justify the cancellation of unrelated scientific lectures by people who hold those views, as many physicists after WWII refused to speak to Werner Heisenberg.  But it seems obvious to me—as it would’ve been obvious to everyone else not long ago—that no matter where a reasonable person draws the line, Abbot’s views as he expressed them in <em>Newsweek</em> don’t come within a hundred miles of it.  To be more explicit still: if Abbot’s views justify deplatforming him as a planetary scientist, then <strong>all my quantum computing and theoretical computer science lectures deserve to be cancelled too</strong>, for the many attempts I’ve made on this blog over the past 16 years to share my honest thoughts and life experiences, to write like a vulnerable human being rather than like a university press office.  While I’m sure some sneerers gleefully embrace that implication, I ask everyone else to consider how deeply they believe in the idea of academic freedom at all—keeping in mind that such a commitment <em>only ever gets tested</em> when there’s a chance someone might denounce you for it.</p>



<p><strong><span class="has-inline-color has-vivid-red-color">Update:</span></strong> Princeton’s James Madison Program has <a href="https://jmp.princeton.edu/events/climate-and-potential-life-other-planets">volunteered</a> to host Abbot’s Zoom talk in place of MIT.  The talk is entitled “Climate and the Potential for Life on Other Planets.”  Like probably hundreds of others who heard about this only because of the attempted cancellation, I plan to attend!</p>



<p><strong><span class="has-inline-color has-vivid-red-color">Unrelated Bonus Update:</span></strong> <a href="https://www.youtube.com/watch?v=934eLObPLmM">Here’s a neat YouTube video</a> put together by the ACM about me as well as David Silver of AlphaGo and AlphaZero, on the occasion of our ACM Prizes in Computing.</p></div>
    </content>
    <updated>2021-10-05T19:23:45Z</updated>
    <published>2021-10-05T19:23:45Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Obviously I'm Not Defending Aaronson"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="http://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-10-05T20:54:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://nisheethvishnoi.wordpress.com/?p=123</id>
    <link href="https://nisheethvishnoi.wordpress.com/2021/10/04/focs-2021-best-paper-awards/" rel="alternate" type="text/html"/>
    <title>FOCS 2021 Best Paper Awards</title>
    <summary>On behalf of the FOCS 2021 PC, I am delighted to announce the Best Paper Awards. Best paper: Nutan Limaye, Srikanth Srinivasan and Sébastien Tavenas. Superpolynomial Lower Bounds Against Low-Depth Algebraic Circuits This paper makes a fundamental advance by proving super-polynomial lower bounds against algebraic circuits of arbitrary constant depth. Paper: https://eccc.weizmann.ac.il/report/2021/081/ Machtey Award for Best […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>On behalf of the FOCS 2021 PC, I am delighted to announce the Best Paper Awards.</p>



<p><strong>Best paper: </strong></p>



<p>Nutan Limaye, Srikanth Srinivasan and Sébastien Tavenas. <em>Superpolynomial Lower Bounds Against Low-Depth Algebraic Circuits</em></p>



<p/>



<p>This paper makes a fundamental advance by proving super-polynomial lower bounds against algebraic circuits of arbitrary constant depth. </p>



<p>Paper: <a href="https://eccc.weizmann.ac.il/report/2021/081/" rel="nofollow">https://eccc.weizmann.ac.il/report/2021/081/</a></p>



<p/>



<p><strong>Machtey Award for Best Student Paper:</strong></p>



<p>Xiao Mao. <em>Breaking the Cubic Barrier for (Unweighted) Tree Edit Distance</em><a href="https://twitter.com/NisheethVishnoi"><br/></a><br/>This paper shows how, unlike the weighted case, the unweighted tree edit distance problem has a sub-cubic time algorithm. </p>



<p>Paper: <a href="https://t.co/G8yw1EZwuR?amp=1" rel="noreferrer noopener" target="_blank">https://arxiv.org/abs/2106.02026</a></p>



<p/>



<p>Congratulations to the winners and see you all in Denver from Feb 7-10, 2022!<a href="https://twitter.com/NisheethVishnoi/status/1445099200274960390/photo/1"/></p></div>
    </content>
    <updated>2021-10-04T18:58:20Z</updated>
    <published>2021-10-04T18:58:20Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>nisheethvishnoi</name>
    </author>
    <source>
      <id>https://nisheethvishnoi.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://nisheethvishnoi.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://nisheethvishnoi.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Algorithms, Nature, and Society</title>
      <updated>2021-10-08T03:39:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/10/04/five-tenure-track-faculty-positions-in-cs-at-the-university-of-virginia-at-university-of-virginia-apply-by-december-1-2021/</id>
    <link href="https://cstheory-jobs.org/2021/10/04/five-tenure-track-faculty-positions-in-cs-at-the-university-of-virginia-at-university-of-virginia-apply-by-december-1-2021/" rel="alternate" type="text/html"/>
    <title>Five Tenure-Track Faculty Positions in CS at the University of Virginia at University of Virginia  (apply by December 1, 2021)</title>
    <summary>Computer Science Department at the University of Virginia seeks 5 tenured or tenure-track faculty at all ranks, with Theory as one of our core targeted areas. Review of applications begins 12/1/2021. Website: https://uva.wd1.myworkdayjobs.com/en-US/UVAJobs/job/Charlottesville-VA/Open-Rank-Faculty-Position-in-Computer-Science_R0028993 Email: selbaum@virginia.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Computer Science Department at the University of Virginia seeks 5 tenured or tenure-track faculty at all ranks, with Theory as one of our core targeted areas. Review of applications begins 12/1/2021.</p>
<p>Website: <a href="https://uva.wd1.myworkdayjobs.com/en-US/UVAJobs/job/Charlottesville-VA/Open-Rank-Faculty-Position-in-Computer-Science_R0028993">https://uva.wd1.myworkdayjobs.com/en-US/UVAJobs/job/Charlottesville-VA/Open-Rank-Faculty-Position-in-Computer-Science_R0028993</a><br/>
Email: selbaum@virginia.edu</p></div>
    </content>
    <updated>2021-10-04T18:40:21Z</updated>
    <published>2021-10-04T18:40:21Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-10-08T03:37:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2021-10-04-crusader-agreement-with-dollars-slash-leq-1-slash-3$-error-is-impossible-for-$n-slash-leq-3f$-if-the-adversary-can-simulate/</id>
    <link href="https://decentralizedthoughts.github.io/2021-10-04-crusader-agreement-with-dollars-slash-leq-1-slash-3$-error-is-impossible-for-$n-slash-leq-3f$-if-the-adversary-can-simulate/" rel="alternate" type="text/html"/>
    <title>Crusader Agreement with $\leq 1/3$ Error is Impossible for $n\leq 3f$ if the Adversary can Simulate</title>
    <summary>The classic FLM lower bound says that in Synchrony, Byzantine Agreement is impossible when $n \leq 3f$. We discussed this important bound in a previous post. In this post we strengthen the FLM lower bound in two important ways: Maybe randomization allows circumventing the FLM lower bound? No! Even allowing...</summary>
    <updated>2021-10-04T14:46:00Z</updated>
    <published>2021-10-04T14:46:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2021-10-08T00:48:07Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-989853369577969981</id>
    <link href="http://blog.computationalcomplexity.org/feeds/989853369577969981/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/10/how-have-computers-changed-society.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/989853369577969981" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/989853369577969981" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/10/how-have-computers-changed-society.html" rel="alternate" type="text/html"/>
    <title>How have computers changed society? Harry Lewis (with co-authors) have a book out on that.</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> (Disclosure - Harry Lewis was my PhD advisor.)</p><p><br/></p><p>It seems like just a few weeks ago I I blogged about a book of Harry Lewis's that was recently available (see <a href="https://blog.computationalcomplexity.org/2021/08/what-are-most-important-46-papers-in.html">here</a>).  And now I am blogging about another one. Writing two books in two years seems hard! I can only think of one other computer scientist who has done that recently (see <a href="https://www.amazon.com/Mathematical-Muffin-Morsels-Problem-Mathematics-ebook/dp/B08BJ4G2Z1/ref=sr_1_2?dchild=1&amp;keywords=gasarch&amp;qid=1626492618&amp;sr=8-2">here</a> and <a href="https://www.amazon.com/Problems-Point-Exploring-Computer-Science/dp/9813279729/ref=sr_1_2?dchild=1&amp;keywords=gasarch+point&amp;qid=1626492655&amp;sr=8-2">here</a>).</p><p><br/></p><p>In 2008 Abelson, Ledeen, and Lewis wrote </p><p><i>Blown to Bits: Your Life, Liberty, and Happiness after the Digital Explosion</i></p><p>which I reviewed in SIGACT news, see <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/bitsbook.pdf">here</a></p><p><br/></p><p>Both computers and society have changed since 2008. Hence an update was needed. </p><p>In 2021 Adelson, Ledeen, Lewis, and Seltzer wrote a second edition.</p><p><br/></p><p>Should you buy the new version if you bought the old version? </p><p>1) Not my problem- I got them both for free since I reviewed them. </p><p>2) Not your problem- The second edition is available free-on-line <a href="https://www.bitsbook.com/thebook/">here</a>. Is that a link to some dark corner of the dark web? No, its the formal webpage about the book. So the book is available free-on-line legally, if you care (and even if you don't care). </p><p>3) If you like paper, the book is on amazon. (If you don't like paper, the book is still on amazon). </p><p><br/></p><p>I reviewed it in SIGACT news. A non-paywalled link: <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/b2bits2.pdf">here</a> (is that link legal? I have no idea.) </p><p>In this post I'll just mention two things that changed since the last book</p><p>1) Shared Music and pirating were an issue back in 2008.  It does not seem to be anymore since there is now a variety of services that seem to make pirating not worth it: itunes, streaming services, and some bands give it away for free and ask you to pay what its worth. Movies are still struggling with this issue. </p><p>2) AI systems that reinforce existing bias is a new problem.</p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2021-10-04T04:19:00Z</updated>
    <published>2021-10-04T04:19:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-10-07T22:05:45Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/10/02/generating-fibbinary-numbers</id>
    <link href="https://11011110.github.io/blog/2021/10/02/generating-fibbinary-numbers.html" rel="alternate" type="text/html"/>
    <title>Generating fibbinary numbers, three ways</title>
    <summary>I just added to Wikipedia two articles on the Jordan–Pólya numbers and fibbinary numbers, two integer sequences used in my recent paper on Egyptian fractions. Jordan–Pólya numbers are the products of factorials, while the fibbinary numbers are the ones with binary representations having no two consecutive 1’s. The OEIS page on the fibbinary numbers, A003714, lists many ways of generating this sequence algorithmically, of which most are boring or slow (generate all binary numbers and test which ones belong to the sequence; you can test if a variable x is fibbinary by checking that x&amp;(x&gt;&gt;1) is zero). I thought it might be interesting to highlight two of those methods that are a little more clever and generate these numbers in small numbers of operations.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I just added to Wikipedia two articles on the <a href="https://en.wikipedia.org/wiki/Jordan%E2%80%93P%C3%B3lya_number">Jordan–Pólya numbers</a> and <a href="https://en.wikipedia.org/wiki/Fibbinary_number">fibbinary numbers</a>, two integer sequences used in <a href="https://11011110.github.io/blog/2021/09/24/which-integer-sequences.html">my recent paper on Egyptian fractions</a>. Jordan–Pólya numbers are the products of factorials, while the fibbinary numbers are the ones with binary representations having no two consecutive 1’s. The OEIS page on the fibbinary numbers, <a href="https://oeis.org/A003714">A003714</a>, lists many ways of generating this sequence algorithmically, of which most are boring or slow (generate all binary numbers and test which ones belong to the sequence; you can test if a variable <code class="language-plaintext highlighter-rouge">x</code> is fibbinary by checking that <code class="language-plaintext highlighter-rouge">x&amp;(x&gt;&gt;1)</code> is zero). I thought it might be interesting to highlight two of those methods that are a little more clever and generate these numbers in small numbers of operations.</p>

<p>Some functional languages, and in part Python even though it’s mostly not functional, have a notion of a stream, a potentially infinite sequence of values generated by a coroutine. In Python, you can program these using <a href="https://www.python.org/dev/peps/pep-0255/">simple generators</a> and the <code class="language-plaintext highlighter-rouge">yield</code> keyword. I wrote here long ago about <a href="https://11011110.github.io/blog/2011/10/02/generating-permutations-with.html">methods for using generators recursively</a>: a generator can call itself, manipulate the resulting sequence of values, and pass them on to its output. It’s actually a very old idea, used for instance to generate <a href="https://en.wikipedia.org/wiki/Regular_number">regular numbers</a> by Dijkstra <a href="http://web.cecs.pdx.edu/~black/AdvancedProgramming/Lectures/Smalltalk%20II/Dijkstra%20on%20Hamming%27s%20Problem.pdf">in his 1976 book <em>A Discipline of Programming</em></a>. Reinhard Zumkeller used the same idea to generate the fibbinary numbers in Haskell, based on the observation that the sequence of positive fibbinary numbers can be generated, starting from the number 1, by two operations, doubling smaller values or replacing a smaller value \(x\) with \(4x+1\). Here is is, translated into Python:</p>

<figure class="highlight"><pre><code class="language-python"><span class="kn">from</span> <span class="nn">heapq</span> <span class="kn">import</span> <span class="n">merge</span>

<span class="k">def</span> <span class="nf">affine</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">stream</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">x</span><span class="o">*</span><span class="n">a</span><span class="o">+</span><span class="n">b</span>

<span class="k">def</span> <span class="nf">fibbinary</span><span class="p">():</span>
    <span class="k">yield</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">merge</span><span class="p">(</span><span class="n">affine</span><span class="p">(</span><span class="n">fibbinary</span><span class="p">(),</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="n">affine</span><span class="p">(</span><span class="n">fibbinary</span><span class="p">(),</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">)):</span>
        <span class="k">yield</span> <span class="n">x</span></code></pre></figure>

<p>It’s elegant, but has a couple of minor flaws. First, it omits the number \(0\), and while it can be modified to include \(0\), the modifications make the code messier. But second, it takes more than a constant amount of time per element to generate each sequence element. A fibbinary number \(x\) has to be generated from a sequence of smaller elements by repeated doubling and quadrupling, and that takes \(\log x\) steps per element. Even if we assume those steps to take constant time each, generating the first \(n\) elements in this way takes time \(\Theta(n\log n)\). It’s better than the \(\Theta(n^{\log_\varphi 2})\approx n^{1.44}\) that you would get from generate-and-test, but still not as good as we might hope for. One way to fix this would be to memoize the generator, so that the recursive calls look at a stored copy of the sequence generated by the outer call rather than generating the same sequence redundantly, but this again makes the code messier and also takes more storage than necessary.</p>

<p>Instead, Jörg Arndt observed that you can generate each fibbinary number directly from the previous one by a process closely resembling binary addition. Adding one to a binary number sets the first available bit from zero to one, and zeros out all the smaller bits; here, a bit is available if it is already zero. Finding the next fibbinary number does the same thing, but with a different definition of availability: a bit is available if both it and the next larger bit are zero. We can find the available bit using binary addition on a modified word that fills in bits whose neighbor is nonzero. Using this idea, we can generate the fibbinary numbers in a constant number of bitwise binary word-level operations per number. Here it is again in Python, translated from Arndt’s C++ and simplified based on <a href="https://mathstodon.xyz/@efroach76/107037399683569338">a comment by efroach76</a>:</p>

<figure class="highlight"><pre><code class="language-python"><span class="k">def</span> <span class="nf">fibbinary</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">x</span>
        <span class="n">y</span> <span class="o">=</span> <span class="o">~</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">y</span></code></pre></figure>

<p>It’s even possible to use the same idea to generate the fibbinary numbers in a constant amortized number of bit-level operations per number, although this ends up being a little less efficient in practice because high-level languages end up translating all these bit operations into word operations anyway.</p>

<figure class="highlight"><pre><code class="language-python"><span class="k">def</span> <span class="nf">fibbinary</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">x</span>
        <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">while</span> <span class="n">x</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y</span> <span class="o">|</span> <span class="p">(</span><span class="n">y</span><span class="o">&lt;&lt;</span><span class="mi">1</span><span class="p">))</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">&amp;=~</span> <span class="n">y</span>
            <span class="n">y</span> <span class="o">&lt;&lt;=</span> <span class="mi">1</span>
        <span class="n">x</span> <span class="o">|=</span> <span class="n">y</span></code></pre></figure>

<p>The inner loop ends immediately at fibbinary numbers whose successor is odd (at positions given by the ones of the <a href="https://en.wikipedia.org/wiki/Fibonacci_word">Fibonacci word</a>), whose fraction of the total is \(1-1/\varphi\approx 0.382\), where \(\varphi\) is the golden ratio. It ends in two steps for the remaining values when their next bit is odd, in the same proportion, and so on. So the average number of steps for the inner loop adds in a geometric series to \(O(1)\).</p>

<p>(<a href="https://mathstodon.xyz/@11011110/107034017632258123">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2021-10-02T13:53:00Z</updated>
    <published>2021-10-02T13:53:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-10-03T20:00:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/10/02/postdoc-at-irif-paris-france-apply-by-november-1-2021/</id>
    <link href="https://cstheory-jobs.org/2021/10/02/postdoc-at-irif-paris-france-apply-by-november-1-2021/" rel="alternate" type="text/html"/>
    <title>postdoc at IRIF, Paris, France (apply by November 1, 2021)</title>
    <summary>IRIF, Paris, France, is seeking excellent candidates for postdoctoral positions in all areas of the Foundations of Computer Science. IRIF is a joint laboratory of the CNRS (French National Center for Scientific Research) and Université de Paris; see https://www.irif.fr/en/informations/presentation . Knowledge of French is not required; applications can be sent either in French or in […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>IRIF, Paris, France, is seeking excellent candidates for postdoctoral positions in all areas of the Foundations of Computer Science.</p>
<p>IRIF is a joint laboratory of the CNRS (French National Center for Scientific Research) and Université de Paris; see <a href="https://www.irif.fr/en/informations/presentation">https://www.irif.fr/en/informations/presentation</a> .</p>
<p>Knowledge of French is not required; applications can be sent either in French or in English.</p>
<p>Website: <a href="https://www.irif.fr/postes/postdoc">https://www.irif.fr/postes/postdoc</a><br/>
Email: postdoc-advice@irif.fr</p></div>
    </content>
    <updated>2021-10-02T07:50:27Z</updated>
    <published>2021-10-02T07:50:27Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-10-08T03:37:51Z</updated>
    </source>
  </entry>
</feed>
