<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-11-19T07:21:39Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3443</id>
    <link href="https://agtb.wordpress.com/2019/11/19/a-market-for-tcs-papers/" rel="alternate" type="text/html"/>
    <title>A Market for TCS Papers??</title>
    <summary>By David Eppstein &amp; Vijay Vazirani No, not to make theoreticians rich! Besides, who will buy your papers anyway? (Quite the opposite, you will be lucky if you can convince someone to take them for free, just for sake of publicity!) What we are proposing is a market in which no money changes hands – […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>By David Eppstein &amp; Vijay Vazirani</em></p>
<p>No, not to make theoreticians rich! Besides, who will buy your papers anyway? (Quite the opposite, you will be lucky if you can convince someone to take them for free, just for sake of publicity!) What we are proposing is a market in which no money changes hands – a matching market – for matching papers to conferences.</p>
<p>First, a short preamble on how the idea emerged.</p>
<p><strong>Preamble</strong> (by Vijay):  Soon after my recent <a href="https://www.youtube.com/watch?v=MLr6Ud5qmt4&amp;t=74s"><u>Simons talk</u></a> on Matching Markets, I sent its url to Al Roth. Obviously, I wasn’t expecting a return email. However, the perfect gentleman and ultimate scholar that Al is, he did reply, and mentioned that he did not like my “definition” of matching markets and said, “I guess I would say matching markets are markets because they aggregate information that is held by the participants, which is what markets do (even if they don’t use prices to do it..).” This hit me like lightening from the sky – suddenly it crystallized the innate intuition about markets which I had formed through work on algorithmic aspects of markets! I thanked Al profusely and added, “This definitely helps in me get the right perspective on the notion!”</p>
<p>About a week ago, while updating my talk for a seminar at Columbia University, I included this beautiful insight in it and then a thought occurred: Each PC meeting involves aggregation of information from a large number of agents: PC members as well as external experts. Hence, isn’t a conference a matching market? Excitedly, I sent this question to Al. He replied, “… the conference process, matching papers to conferences, is a market and a particular conference might be a marketplace … ”</p>
<p>When I returned home, my esteemed colleague, David Eppstein, stunned me by declaring that he had thought of a market relevant to our field in which no money changes hands. I immediately knew he was thinking of the conference process. But he got to it out of the blue … and not the long process it took me!</p>
<p><strong>Back to the idea:  </strong>In the past, matching markets have brought immense efficiency and order in allocation problems in which use of money is considered repugnant, the prime examples being matching medical residents to hospitals, kidney exchange, and assignment of students of a large city to its schools.</p>
<p>At present we are faced with massive inefficiencies in the conference process – numerous researchers are trapped in unending cycles of submit … get reject … incorporate comments … resubmit — often to the next deadline which has been conveniently arranged a couple of days down the road so the unwitting participants are conditioned into mindlessly keep coming back for more, much like Pavlov’s dog.</p>
<p>We are proposing a matching market approach to finally obliterate this madness. We believe such a market is feasible using the following ideas. No doubt our scheme will have some drawbacks; however, as should be obvious, the advantages far outweigh them.</p>
<p>First, for co-located symposia within a larger umbrella conference, such as the<br/>
conferences within ALGO or FCRC, the following process should be a no-brainer:</p>
<p>1). Ensure a common deadline for all symposia; denote the latter by <em>S.</em></p>
<p>2). Let <em>R</em> denote the set of researchers who wish to submit one paper to a symposium in this umbrella conference – assume that researchers submitting more than one paper will have multiple names, one for each submission. Each researcher will provide a strict preference order over the subset of symposia to which they wish to submit their paper. Let <em>G</em> denote the bipartite graph with vertex sets (<em>R, S</em>) and an edge (<em>r, s</em>) only if researcher <em>r</em> chose symposium <em>s.</em></p>
<p>3). The umbrella conference will have a large common PC with experts representing all of its symposia. The process of assigning papers to PC members will of course use <em>G</em> in a critical way.</p>
<p>Once papers are reviewed by PC members and external reviewers, each symposium will rank its submissions using its own criteria of acceptance. We believe the overhead of ranking each paper multiple times is minimal since that is just an issue of deciding how “on-topic” a paper is – an easy task once the reviews of the paper are available.</p>
<p>4). Finally, using all these preference lists, a researcher-proposing stable matching is computed using the Gale-Shapley algorithm. As is well-known, this mechanism will be dominant strategy incentive compatible for researchers.</p>
<p>With a little extra effort, a similar scheme can also be used for a group of conferences at diverse locations but similar times, such as some of the annual summer theory conferences, STOC, ICALP, ESA, STAC, WADS/SWAT, etc.</p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-11-19T01:31:12Z</updated>
    <published>2019-11-19T01:31:12Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Kevin Leyton-Brown</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-11-19T07:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07536</id>
    <link href="http://arxiv.org/abs/1911.07536" rel="alternate" type="text/html"/>
    <title>Time-inconsistent Planning: Simple Motivation Is Hard to Find</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fomin:Fedor_V=.html">Fedor V. Fomin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Str=oslash=mme:Torstein_J=_F=.html">Torstein J. F. Strømme</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07536">PDF</a><br/><b>Abstract: </b>With the introduction of the graph-theoretic time-inconsistent planning model
due to Kleinberg and Oren, it has been possible to investigate the
computational complexity of how a task designer best can support a
present-biased agent in completing the task. In this paper, we study the
complexity of finding a choice reduction for the agent; that is, how to remove
edges and vertices from the task graph such that a present-biased agent will
remain motivated to reach his target even for a limited reward. While this
problem is NP-complete in general, this is not necessarily true for instances
which occur in practice, or for solutions which are of interest to task
designers. For instance, a task designer may desire to find the best task graph
which is not too complicated.
</p>
<p>We therefore investigate the problem of finding simple motivating subgraphs.
These are structures where the agent will modify his plan at most $k$ times
along the way. We quantify this simplicity in the time-inconsistency model as a
structural parameter: The number of branching vertices (vertices with
out-degree at least $2$) in a minimal motivating subgraph.
</p>
<p>Our results are as follows: We give a linear algorithm for finding an optimal
motivating path, i.e. when $k=0$. On the negative side, we show that finding a
simple motivating subgraph is NP-complete even if we allow only a single
branching vertex --- revealing that simple motivating subgraphs are indeed hard
to find. However, we give a pseudo-polynomial algorithm for the case when $k$
is fixed and edge weights are rationals, which might be a reasonable assumption
in practice.
</p></div>
    </summary>
    <updated>2019-11-19T02:22:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07504</id>
    <link href="http://arxiv.org/abs/1911.07504" rel="alternate" type="text/html"/>
    <title>Minimum-Width Double-Strip and Parallelogram Annulus</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bae:Sang_Won.html">Sang Won Bae</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07504">PDF</a><br/><b>Abstract: </b>In this paper, we study the problem of computing a minimum-width double-strip
or parallelogram annulus that encloses a given set of $n$ points in the plane.
A double-strip is a closed region in the plane whose boundary consists of four
parallel lines and a parallelogram annulus is a closed region between two
edge-parallel parallelograms. We present several first algorithms for these
problems. Among them are $O(n^2)$ and $O(n^3 \log n)$-time algorithms that
compute a minimum-width double-strip and parallelogram annulus, respectively,
when their orientations can be freely chosen.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07465</id>
    <link href="http://arxiv.org/abs/1911.07465" rel="alternate" type="text/html"/>
    <title>Implicit Enumeration of Topological-Minor-Embeddings and Its Application to Planar Subgraph Enumeration</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakahata:Yu.html">Yu Nakahata</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kawahara:Jun.html">Jun Kawahara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Horiyama:Takashi.html">Takashi Horiyama</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Minato:Shin=ichi.html">Shin-ichi Minato</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07465">PDF</a><br/><b>Abstract: </b>Given graphs $G$ and $H$, we propose a method to implicitly enumerate
topological-minor-embeddings of $H$ in $G$ using decision diagrams. We show a
useful application of our method to enumerating subgraphs characterized by
forbidden topological minors, that is, planar, outerplanar, series-parallel,
and cactus subgraphs. Computational experiments show that our method can find
all planar subgraphs in a given graph at most five orders of magnitude faster
than a naive backtracking-based method.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07417</id>
    <link href="http://arxiv.org/abs/1911.07417" rel="alternate" type="text/html"/>
    <title>Algorithmic Discrepancy Minimization</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Whitmeyer:Michael.html">Michael Whitmeyer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Jonathan.html">Jonathan Liu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07417">PDF</a><br/><b>Abstract: </b>This report will be a literature review on a result in algorithmic
discrepancy theory. We will begin by providing a quick overview on discrepancy
theory and some major results in the field, and then focus on an important
result by Shachar Lovett and Raghu Meka. We restate the main algorithm and
ideas of the paper, and rewrite proofs for some of the major results in the
paper.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07378</id>
    <link href="http://arxiv.org/abs/1911.07378" rel="alternate" type="text/html"/>
    <title>Finding Skewed Subcubes Under a Distribution</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gopalan:Parikshit.html">Parikshit Gopalan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levin:Roie.html">Roie Levin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wieder:Udi.html">Udi Wieder</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07378">PDF</a><br/><b>Abstract: </b>Say that we are given samples from a distribution $\psi$ over an
$n$-dimensional space. We expect or desire $\psi$ to behave like a product
distribution (or a $k$-wise independent distribution over its marginals for
small $k$). We propose the problem of enumerating/list-decoding all large
subcubes where the distribution $\psi$ deviates markedly from what we expect;
we refer to such subcubes as skewed subcubes. Skewed subcubes are certificates
of dependencies between small subsets of variables in $\psi$. We motivate this
problem by showing that it arises naturally in the context of algorithmic
fairness and anomaly detection.
</p>
<p>In this work we focus on the special but important case where the space is
the Boolean hypercube, and the expected marginals are uniform. We show that the
obvious definition of skewed subcubes can lead to intractable list sizes, and
propose a better definition of a minimal skewed subcube, which are subcubes
whose skew cannot be attributed to a larger subcube that contains it. Our main
technical contribution is a list-size bound for this definition and an
algorithm to efficiently find all such subcubes. Both the bound and the
algorithm rely on Fourier-analytic techniques, especially the powerful
hypercontractive inequality.
</p>
<p>On the lower bounds side, we show that finding skewed subcubes is as hard as
the sparse noisy parity problem, and hence our algorithms cannot be improved on
substantially without a breakthrough on this problem which is believed to be
intractable. Motivated by this, we study alternate models allowing query access
to $\psi$ where finding skewed subcubes might be easier.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07375</id>
    <link href="http://arxiv.org/abs/1911.07375" rel="alternate" type="text/html"/>
    <title>Top-down induction of decision trees: rigorous guarantees and inherent limitations</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blanc:Guy.html">Guy Blanc</a>, Jane Lange, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tan:Li=Yang.html">Li-Yang Tan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07375">PDF</a><br/><b>Abstract: </b>Consider the following heuristic for building a decision tree for a function
$f : \{0,1\}^n \to \{\pm 1\}$. Place the most influential variable $x_i$ of $f$
at the root, and recurse on the subfunctions $f_{x_i=0}$ and $f_{x_i=1}$ on the
left and right subtrees respectively; terminate once the tree is an
$\varepsilon$-approximation of $f$. We analyze the quality of this heuristic,
obtaining near-matching upper and lower bounds:
</p>
<p>$\circ$ Upper bound: For every $f$ with decision tree size $s$ and every
$\varepsilon \in (0,\frac1{2})$, this heuristic builds a decision tree of size
at most $s^{O(\log(s/\varepsilon)\log(1/\varepsilon))}$.
</p>
<p>$\circ$ Lower bound: For every $\varepsilon \in (0,\frac1{2})$ and $s \le
2^{\tilde{O}(\sqrt{n})}$, there is an $f$ with decision tree size $s$ such that
this heuristic builds a decision tree of size $s^{\tilde{\Omega}(\log s)}$.
</p>
<p>We also obtain upper and lower bounds for monotone functions:
$s^{O(\sqrt{\log s}/\varepsilon)}$ and $s^{\tilde{\Omega}(\sqrt[4]{\log s } )}$
respectively. The lower bound disproves conjectures of Fiat and Pechyony (2004)
and Lee (2009).
</p>
<p>Our upper bounds yield new algorithms for properly learning decision trees
under the uniform distribution. We show that these algorithms---which are
motivated by widely employed and empirically successful top-down decision tree
learning heuristics such as ID3, C4.5, and CART---achieve provable guarantees
that compare favorably with those of the current fastest algorithm (Ehrenfeucht
and Haussler, 1989). Our lower bounds shed new light on the limitations of
these heuristics.
</p>
<p>Finally, we revisit the classic work of Ehrenfeucht and Haussler. We extend
it to give the first uniform-distribution proper learning algorithm that
achieves polynomial sample and memory complexity, while matching its
state-of-the-art quasipolynomial runtime.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07357</id>
    <link href="http://arxiv.org/abs/1911.07357" rel="alternate" type="text/html"/>
    <title>Random Restrictions of High-Dimensional Distributions and Uniformity Testing with Subcube Conditioning</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Canonne:Cl=eacute=ment_L=.html">Clément L. Canonne</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Xi.html">Xi Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kamath:Gautam.html">Gautam Kamath</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levi:Amit.html">Amit Levi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Waingarten:Erik.html">Erik Waingarten</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07357">PDF</a><br/><b>Abstract: </b>We give a nearly-optimal algorithm for testing uniformity of distributions
supported on $\{-1,1\}^n$, which makes $\tilde O (\sqrt{n}/\varepsilon^2)$
queries to a subcube conditional sampling oracle (Bhattacharyya and Chakraborty
(2018)). The key technical component is a natural notion of random restriction
for distributions on $\{-1,1\}^n$, and a quantitative analysis of how such a
restriction affects the mean vector of the distribution. Along the way, we
consider the problem of mean testing with independent samples and provide a
nearly-optimal algorithm.
</p></div>
    </summary>
    <updated>2019-11-19T02:39:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07352</id>
    <link href="http://arxiv.org/abs/1911.07352" rel="alternate" type="text/html"/>
    <title>Robust Algorithms for the Secretary Problem</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bradac:Domagoj.html">Domagoj Bradac</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Anupam.html">Anupam Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singla:Sahil.html">Sahil Singla</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zuzic:Goran.html">Goran Zuzic</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07352">PDF</a><br/><b>Abstract: </b>In classical secretary problems, a sequence of $n$ elements arrive in a
uniformly random order, and we want to choose a single item, or a set of size
$K$. The random order model allows us to escape from the strong lower bounds
for the adversarial order setting, and excellent algorithms are known in this
setting. However, one worrying aspect of these results is that the algorithms
overfit to the model: they are not very robust. Indeed, if a few "outlier"
arrivals are adversarially placed in the arrival sequence, the algorithms
perform poorly. E.g., Dynkin's popular $1/e$-secretary algorithm fails with
even a single adversarial arrival.
</p>
<p>We investigate a robust version of the secretary problem. In the Byzantine
Secretary model, we have two kinds of elements: green (good) and red (rogue).
The values of all elements are chosen by the adversary. The green elements
arrive at times uniformly randomly drawn from $[0,1]$. The red elements,
however, arrive at adversarially chosen times. Naturally, the algorithm does
not see these colors: how well can it solve secretary problems?
</p>
<p>We give algorithms which get value comparable to the value of the optimal
green set minus the largest green item. Specifically, we give an algorithm to
pick $K$ elements that gets within $(1-\varepsilon)$ factor of the above
benchmark, as long as $K \geq \mathrm{poly}(\varepsilon^{-1} \log n)$. We
extend this to the knapsack secretary problem, for large knapsack size $K$.
</p>
<p>For the single-item case, an analogous benchmark is the value of the
second-largest green item. For value-maximization, we give a $\mathrm{poly}
\log^* n$-competitive algorithm, using a multi-layered bucketing scheme that
adaptively refines our estimates of second-max over time. For
probability-maximization, we show the existence of a good randomized algorithm,
using the minimax principle.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07324</id>
    <link href="http://arxiv.org/abs/1911.07324" rel="alternate" type="text/html"/>
    <title>Testing Properties of Multiple Distributions with Few Samples</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aliakbarpour:Maryam.html">Maryam Aliakbarpour</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Silwal:Sandeep.html">Sandeep Silwal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07324">PDF</a><br/><b>Abstract: </b>We propose a new setting for testing properties of distributions while
receiving samples from several distributions, but few samples per distribution.
Given samples from $s$ distributions, $p_1, p_2, \ldots, p_s$, we design
testers for the following problems: (1) Uniformity Testing: Testing whether all
the $p_i$'s are uniform or $\epsilon$-far from being uniform in
$\ell_1$-distance (2) Identity Testing: Testing whether all the $p_i$'s are
equal to an explicitly given distribution $q$ or $\epsilon$-far from $q$ in
$\ell_1$-distance, and (3) Closeness Testing: Testing whether all the $p_i$'s
are equal to a distribution $q$ which we have sample access to, or
$\epsilon$-far from $q$ in $\ell_1$-distance. By assuming an additional natural
condition about the source distributions, we provide sample optimal testers for
all of these problems.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07306</id>
    <link href="http://arxiv.org/abs/1911.07306" rel="alternate" type="text/html"/>
    <title>Quantum Speedup for Graph Sparsification, Cut Approximation and Laplacian Solving</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Apers:Simon.html">Simon Apers</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolf:Ronald_de.html">Ronald de Wolf</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07306">PDF</a><br/><b>Abstract: </b>Graph sparsification underlies a large number of algorithms, ranging from
approximation algorithms for cut problems to solvers for linear systems in the
graph Laplacian. In its strongest form, "spectral sparsification" reduces the
number of edges to near-linear in the number of nodes, while approximately
preserving the cut and spectral structure of the graph. The breakthrough work
by Bencz\'ur and Karger (STOC'96) and Spielman and Teng (STOC'04) showed that
sparsification can be done optimally in time near-linear in the number of edges
of the original graph.
</p>
<p>In this work we show that quantum algorithms allow to speed up spectral
sparsification, and thereby many of the derived algorithms. Given
adjacency-list access to a weighted graph with $n$ nodes and $m$ edges, our
algorithm outputs an $\epsilon$-spectral sparsifier in time
$\widetilde{O}(\sqrt{mn}/\epsilon)$. We prove that this is tight up to
polylog-factors. The algorithm builds on a string of existing results, most
notably sparsification algorithms by Spielman and Srivastava (STOC'08) and
Koutis and Xu (TOPC'16), a spanner construction by Thorup and Zwick (STOC'01),
a single-source shortest-paths quantum algorithm by D\"urr et al. (ICALP'04)
and an efficient $k$-wise independent hash construction by Christiani, Pagh and
Thorup (STOC'15). Combining our sparsification algorithm with existing
classical algorithms yields the first quantum speedup, roughly from
$\widetilde{O}(m)$ to $\widetilde{O}(\sqrt{mn})$, for approximating the max
cut, min cut, min $st$-cut, sparsest cut and balanced separator of a graph.
Combining our algorithm with a classical Laplacian solver, we demonstrate a
similar speedup for Laplacian solving, for approximating effective resistances,
cover times and eigenvalues of the Laplacian, and for spectral clustering.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07287</id>
    <link href="http://arxiv.org/abs/1911.07287" rel="alternate" type="text/html"/>
    <title>A Crossing Lemma for Families of Jordan Curves with a Bounded Intersection Number</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Maya Bechler-Speicher <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07287">PDF</a><br/><b>Abstract: </b>A family of closed simple (i.e., Jordan) curves is {\it $m$-intersecting} if
any pair of its curves have at most $m$ points of common intersection. We say
that a pair of such curves {\it touch} if they intersect at a single point of
common tangency. In this work we show that any $m$-intersecting family of $n$
Jordan curves in general position in the plane contains
$O\left(n^{2-\frac{1}{3m+15}}\right)$ touching pairs.\footnote{A family of
Jordan curves is in general position if no three of its curves pass through the
same point, and no two of them overlap. The constant of proportionality with
the $O(\cdot)$-notation may depend on $m$.}
</p>
<p>Furthermore, we use the string separator theorem of Fox and Pach \cite{FP10}
in order to establish the following Crossing Lemma for contact graphs of Jordan
curves: Let $\Gamma$ be an $m$-intersecting family of closed Jordan curves in
general position in the plane with exactly $T=\Omega(n)$ touching pairs of
curves, then the curves of $\Gamma$ determine
$\Omega\left(T\cdot\left(\frac{T}{n}\right)^{\frac{1}{9m+45}}\right)$
intersection points.
</p>
<p>This extends the similar bounds that were previously established by Salazar
for the special case of pairwise intersecting (and $m$-intersecting) curves.
Specializing to the case at hand, this substantially improves the bounds that
were recently derived by Pach, Rubin and Tardos for arbitrary families of
Jordan curves.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07255</id>
    <link href="http://arxiv.org/abs/1911.07255" rel="alternate" type="text/html"/>
    <title>Deep geometric matrix completion: Are we doing it right?</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Boyarski:Amit.html">Amit Boyarski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vedula:Sanketh.html">Sanketh Vedula</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bronstein:Alex.html">Alex Bronstein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07255">PDF</a><br/><b>Abstract: </b>We address the problem of reconstructing a matrix from a subset of its
entries. Current methods, branded as geometric matrix completion, augment
classical rank regularization techniques by incorporating geometric information
into the solution. This information is usually provided as graphs encoding
relations between rows/columns. In this work we propose a simple spectral
approach for solving the matrix completion problem, via the framework of
functional maps. We introduce the zoomout loss, a multiresolution spectral
geometric loss inspired by recent advances in shape correspondence, whose
minimization leads to state-of-the-art results on various recommender systems
datasets. Surprisingly, for some datasets we were able to achieve comparable
results even without incorporating geometric information. This puts into
question both the quality of such information and current methods' ability to
use it in a meaningful and efficient way.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07234</id>
    <link href="http://arxiv.org/abs/1911.07234" rel="alternate" type="text/html"/>
    <title>Approximation of Steiner Forest via the Bidirected Cut Relaxation</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Ali Çivril <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07234">PDF</a><br/><b>Abstract: </b>The classical algorithm of Agrawal, Klein and Ravi [SIAM J. Comput., 24
(1995), pp. 440-456], stated in the setting of the primal-dual schema by
Goemans and Williamson [SIAM J. Comput., 24 (1995), pp. 296-317] uses the
undirected cut relaxation for the Steiner forest problem. Its approximation
ratio is $2-\frac{1}{k}$, where $k$ is the number of terminal pairs. A variant
of this algorithm more recently proposed by K\"onemann et al. [SIAM J. Comput.,
37 (2008), pp. 1319-1341] is based on the lifted cut relaxation. In this paper,
we continue this line of work and consider the bidirected cut relaxation for
the Steiner forest problem, which lends itself to a novel algorithmic idea
yielding the same approximation ratio as the classical algorithm. In doing so,
we introduce an extension of the primal-dual schema in which we run two
different phases to satisfy connectivity requirements in both directions. This
reveals more about the combinatorial structure of the problem. In particular,
there are examples on which the classical algorithm fails to give a good
approximation, but the new algorithm finds a near-optimal solution.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07232</id>
    <link href="http://arxiv.org/abs/1911.07232" rel="alternate" type="text/html"/>
    <title>5/4-Approximation of Minimum 2-Edge-Connected Spanning Subgraph</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Ali Çivril <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07232">PDF</a><br/><b>Abstract: </b>We provide a $5/4$-approximation algorithm for the 2-edge connected spanning
subgraph problem. This improves upon the previous best ratio of $4/3$. The
algorithm is based on applying local improvement steps on a starting solution
provided by a standard ear decomposition. Unlike previous approaches, we
consider modifications involving $5$-ears together with $3$-ears.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07166</id>
    <link href="http://arxiv.org/abs/1911.07166" rel="alternate" type="text/html"/>
    <title>On the existence of four or more curved foldings with common creases and crease patterns</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Honda:Atsufumi.html">Atsufumi Honda</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Naokawa:Kosuke.html">Kosuke Naokawa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saji:Kentaro.html">Kentaro Saji</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Umehara:Masaaki.html">Masaaki Umehara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yamada:Kotaro.html">Kotaro Yamada</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07166">PDF</a><br/><b>Abstract: </b>Consider a curve $\Gamma$ in a domain $D$ in the plane $\boldsymbol{R}^2$.
Thinking of $D$ as a piece of paper, one can make a curved folding in the
Euclidean space $\boldsymbol{R}^3$. This can be expressed as the image of an
`origami map' $\varphi:D\to \boldsymbol{R}^3$ such that $\Gamma$ is the
singular set of $\varphi$, the word `origami' coming from the Japanese term for
paper folding. We call the singular set image $C:=\varphi(\Gamma)$ the crease
of $\varphi$ and the singular set $\Gamma$ the crease pattern of $\varphi$. We
are interested in the number of origami maps whose creases and crease patterns
are $C$ and $\Gamma$ respectively. Two such possibilities have been known. In
the previous authors' work, two other new possibilities and an explicit example
with four such non-congruent distinct curved foldings were established. In this
paper, we show that the case of four mutually non-congruent curved foldings
with the same crease and crease pattern occurs if and only if $\Gamma$ and $C$
do not admit any symmetries. Moreover, when $C$ is a closed curve, we show that
there are infinitely many distinct possibilities for curved foldings with the
same crease and crease pattern, in general.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07154</id>
    <link href="http://arxiv.org/abs/1911.07154" rel="alternate" type="text/html"/>
    <title>Sparse Hopsets in Congested Clique</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nazari:Yasamin.html">Yasamin Nazari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07154">PDF</a><br/><b>Abstract: </b>We give the first Congested Clique algorithm that computes a sparse hopset
with polylogarithmic hopbound in polylogarithmic time. Given a graph $G=(V,E)$,
a $(\beta,\epsilon)$-hopset $H$ with "hopbound" $\beta$, is a set of edges
added to $G$ such that for any pair of nodes $u$ and $v$ in $G$ there is a path
with at most $\beta$ hops in $G \cup H$ with length within $(1+\epsilon)$ of
the shortest path between $u$ and $v$ in $G$.
</p>
<p>Our hopsets are significantly sparser than the recent construction of
Censor-Hillel et al. [6], that constructs a hopset of size
$\tilde{O}(n^{3/2})$, but with a smaller polylogarithmic hopbound. On the other
hand, the previously known constructions of sparse hopsets with polylogarithmic
hopbound in the Congested Clique model, proposed by Elkin and Neiman
[10],[11],[12], all require polynomial rounds.
</p>
<p>One tool that we use is an efficient algorithm that constructs an
$\ell$-limited neighborhood cover, that may be of independent interest.
</p>
<p>Finally, as a side result, we also give a hopset construction in a variant of
the low-memory Massively Parallel Computation model, with improved running time
over existing algorithms.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07151</id>
    <link href="http://arxiv.org/abs/1911.07151" rel="alternate" type="text/html"/>
    <title>A one-phase tree-based algorithm for mining high-utility itemsets from a transaction database</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dawar:Siddharth.html">Siddharth Dawar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goyal:Vikram.html">Vikram Goyal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bera:Debajyoti.html">Debajyoti Bera</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07151">PDF</a><br/><b>Abstract: </b>High-utility itemset mining finds itemsets from a transaction database with
utility no less than a fixed user-defined threshold. The utility of an itemset
is defined as the sum of the utilities of its item. Several algorithms were
proposed to mine high-utility itemsets. However, no state-of-the-art algorithm
performs consistently good across dense and sparse datasets. In this paper, we
propose a novel data structure called Utility-Tree, and a tree-based algorithm
called UT-Miner that mines high-utility itemsets in one-phase only without
generating any candidates and uses a lightweight construction method to reduce
the cost of creating projected databases during the search space exploration.
The transaction information is stored compactly with every node of the
Utility-Tree, and the information is computed efficiently during the recursive
invocation of the algorithm. Experimental results on several real-life dense
and sparse datasets reveal that UT-Miner is among the top-performing efficient
algorithms across different datasets.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07124</id>
    <link href="http://arxiv.org/abs/1911.07124" rel="alternate" type="text/html"/>
    <title>Faster Integer Multiplication Using Preprocessing</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Groff:Matt.html">Matt Groff</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07124">PDF</a><br/><b>Abstract: </b>A New Number Theoretic Transform(NTT), which is a form of FFT, is introduced,
that is faster than FFTs. Also, a multiplication algorithm is introduced that
uses this to perform integer multiplication faster than O(n log n). It uses
preprocessing to achieve an upper bounds of (n log n/(log log n/ log log log
n).
</p>
<p>Also, we explore the possibility of O(n) time multiplication via NTTs that
require only O(n) operations, using preprocessing.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.07020</id>
    <link href="http://arxiv.org/abs/1911.07020" rel="alternate" type="text/html"/>
    <title>Counting solutions to random CNF formulas</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galanis:Andreas.html">Andreas Galanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldberg:Leslie_Ann.html">Leslie Ann Goldberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Heng.html">Heng Guo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Kuan.html">Kuan Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.07020">PDF</a><br/><b>Abstract: </b>We give the first efficient algorithm to approximately count the number of
solutions in the random $k$-SAT model when the density of the formula scales
exponentially with $k$. The best previous counting algorithm was due to
Montanari and Shah and was based on the correlation decay method, which works
up to densities $(1+o_k(1))\frac{2\log k}{k}$, the Gibbs uniqueness threshold
for the model. Instead, our algorithm harnesses a recent technique by Moitra to
work for random formulas. The main challenge in our setting is to account for
the presence of high-degree variables whose marginal distributions are hard to
control and which cause significant correlations within the formula.
</p></div>
    </summary>
    <updated>2019-11-19T02:28:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.06985</id>
    <link href="http://arxiv.org/abs/1911.06985" rel="alternate" type="text/html"/>
    <title>Constructing the Bijective BWT</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bannai:Hideo.html">Hideo Bannai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/K=auml=rkk=auml=inen:Juha.html">Juha Kärkkäinen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/K=ouml=ppl:Dominik.html">Dominik Köppl</a>, Marcin Picatkowski <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.06985">PDF</a><br/><b>Abstract: </b>The Burrows-Wheeler transform (BWT) is a permutation whose applications are
prevalent in data compression and text indexing. The bijective BWT (BBWT) is a
bijective variant of it. Although it is known that the BWT can be constructed
in linear time for integer alphabets by using a linear time suffix array
construction algorithm, it was up to now only conjectured that the BBWT can
also be constructed in linear time. We confirm this conjecture by proposing a
construction algorithm that is based on SAIS, improving the best known result
of $O(n \lg n /\lg \lg n)$ time to linear.
</p></div>
    </summary>
    <updated>2019-11-19T02:30:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.06958</id>
    <link href="http://arxiv.org/abs/1911.06958" rel="alternate" type="text/html"/>
    <title>Regularized Weighted Low Rank Approximation</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ban:Frank.html">Frank Ban</a>, David Woodruff, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Qiuyi.html">Qiuyi Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.06958">PDF</a><br/><b>Abstract: </b>The classical low rank approximation problem is to find a rank $k$ matrix
$UV$ (where $U$ has $k$ columns and $V$ has $k$ rows) that minimizes the
Frobenius norm of $A - UV$. Although this problem can be solved efficiently, we
study an NP-hard variant of this problem that involves weights and
regularization. A previous paper of [Razenshteyn et al. '16] derived a
polynomial time algorithm for weighted low rank approximation with constant
rank. We derive provably sharper guarantees for the regularized version by
obtaining parameterized complexity bounds in terms of the statistical dimension
rather than the rank, allowing for a rank-independent runtime that can be
significantly faster. Our improvement comes from applying sharper matrix
concentration bounds, using a novel conditioning technique, and proving
structural theorems for regularized low rank problems.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.06951</id>
    <link href="http://arxiv.org/abs/1911.06951" rel="alternate" type="text/html"/>
    <title>Memory-Efficient Performance Monitoring on Programmable Switches with Lean Algorithms</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Zaoxing.html">Zaoxing Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Samson.html">Samson Zhou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rottenstreich:Ori.html">Ori Rottenstreich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Braverman:Vladimir.html">Vladimir Braverman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rexford:Jennifer.html">Jennifer Rexford</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.06951">PDF</a><br/><b>Abstract: </b>Network performance problems are notoriously difficult to diagnose. Prior
profiling systems collect performance statistics by keeping information about
each network flow, but maintaining per-flow state is not scalable on
resource-constrained NIC and switch hardware. Instead, we propose sketch-based
performance monitoring using memory that is sublinear in the number of flows.
Existing sketches estimate flow monitoring metrics based on flow sizes. In
contrast, performance monitoring typically requires combining information
across pairs of packets, such as matching a data packet with its acknowledgment
to compute a round-trip time. We define a new class of \emph{lean} algorithms
that use memory sublinear in both the size of input data and the number of
flows. We then introduce lean algorithms for a set of important statistics,
such as identifying flows with high latency, loss, out-of-order, or
retransmitted packets. We implement prototypes of our lean algorithms on a
commodity programmable switch using the P4 language. Our experiments show that
lean algorithms detect $\sim$82\% of top 100 problematic flows among real-world
packet traces using just 40KB memory.
</p></div>
    </summary>
    <updated>2019-11-19T02:36:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.06924</id>
    <link href="http://arxiv.org/abs/1911.06924" rel="alternate" type="text/html"/>
    <title>Approximating the Distance to Monotonicity of Boolean Functions</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pallavoor:Ramesh_Krishnan_S=.html">Ramesh Krishnan S. Pallavoor</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raskhodnikova:Sofya.html">Sofya Raskhodnikova</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Waingarten:Erik.html">Erik Waingarten</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.06924">PDF</a><br/><b>Abstract: </b>We design a nonadaptive algorithm that, given a Boolean function $f\colon
\{0,1\}^n \to \{0,1\}$ which is $\alpha$-far from monotone, makes poly$(n,
1/\alpha)$ queries and returns an estimate that, with high probability, is an
$\widetilde{O}(\sqrt{n})$-approximation to the distance of $f$ to monotonicity.
Furthermore, we show that for any constant $\kappa &gt; 0,$ approximating the
distance to monotonicity up to $n^{1/2 - \kappa}$-factor requires
$2^{n^\kappa}$ nonadaptive queries, thereby ruling out a poly$(n,
1/\alpha)$-query nonadaptive algorithm for such approximations. This answers a
question of Seshadhri (Property Testing Review, 2014) for the case of
nonadaptive algorithms. Approximating the distance to a property is closely
related to tolerantly testing that property. Our lower bound stands in contrast
to standard (non-tolerant) testing of monotonicity that can be done
nonadaptively with $\widetilde{O}(\sqrt{n} / \varepsilon^2)$ queries.
</p>
<p>We obtain our lower bound by proving an analogous bound for erasure-resilient
testers. An $\alpha$-erasure-resilient tester for a desired property gets
oracle access to a function that has at most an $\alpha$ fraction of values
erased. The tester has to accept (with probability at least 2/3) if the
erasures can be filled in to ensure that the resulting function has the
property and to reject (with probability at least 2/3) if every completion of
erasures results in a function that is $\varepsilon$-far from having the
property. Our method yields the same lower bounds for unateness and being a
$k$-junta. These lower bounds improve exponentially on the existing lower
bounds for these properties.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.06907</id>
    <link href="http://arxiv.org/abs/1911.06907" rel="alternate" type="text/html"/>
    <title>Strategy-Stealing is Non-Constructive</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bodwin:Greg.html">Greg Bodwin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grossman:Ofer.html">Ofer Grossman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.06907">PDF</a><br/><b>Abstract: </b>In many combinatorial games, one can prove that the first player wins under
best play using a simple but non-constructive argument called
strategy-stealing. This work is about the complexity behind these proofs: how
hard is it to actually find a winning move in a game, when you know by
strategy-stealing that one exists? We prove that this problem is PSPACE-hard
already for Minimum Poset Games and Symmetric Maker-Maker Games, which are
simple classes of games that capture two of the main types of strategy-stealing
arguments in the current literature.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.06895</id>
    <link href="http://arxiv.org/abs/1911.06895" rel="alternate" type="text/html"/>
    <title>Delta-stepping SSSP: from Vertices and Edges to GraphBLAS Implementations</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sridhar:Upasana.html">Upasana Sridhar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blanco:Mark.html">Mark Blanco</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mayuranath:Rahul.html">Rahul Mayuranath</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spampinato:Daniele_G=.html">Daniele G. Spampinato</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Low:Tze_Meng.html">Tze Meng Low</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/McMillan:Scott.html">Scott McMillan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.06895">PDF</a><br/><b>Abstract: </b>GraphBLAS is an interface for implementing graph algorithms. Algorithms
implemented using the GraphBLAS interface are cast in terms of linear
algebra-like operations. However, many graph algorithms are canonically
described in terms of operations on vertices and/or edges. Despite the known
duality between these two representations, the differences in the way
algorithms are described using the two approaches can pose considerable
difficulties in the adoption of the GraphBLAS as standard interface for
development. This paper investigates a systematic approach for translating a
graph algorithm described in the canonical vertex and edge representation into
an implementation that leverages the GraphBLAS interface. We present a two-step
approach to this problem. First, we express common vertex- and edge-centric
design patterns using a linear algebraic language. Second, we map this
intermediate representation to the GraphBLAS interface. We illustrate our
approach by translating the delta-stepping single source shortest path
algorithm from its canonical description to a GraphBLAS implementation, and
highlight lessons learned when implementing using GraphBLAS.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.06889</id>
    <link href="http://arxiv.org/abs/1911.06889" rel="alternate" type="text/html"/>
    <title>New Query Lower Bounds for Submodular Function MInimization</title>
    <feedworld_mtime>1574121600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Andrei Graur, Tristan Pollner, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramaswamy:Vidhya.html">Vidhya Ramaswamy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weinberg:S=_Matthew.html">S. Matthew Weinberg</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.06889">PDF</a><br/><b>Abstract: </b>We consider submodular function minimization in the oracle model: given
black-box access to a submodular set function $f:2^{[n]}\rightarrow
\mathbb{R}$, find an element of $\arg\min_S \{f(S)\}$ using as few queries to
$f(\cdot)$ as possible. State-of-the-art algorithms succeed with
$\tilde{O}(n^2)$ queries [LeeSW15], yet the best-known lower bound has never
been improved beyond $n$ [Harvey08].
</p>
<p>We provide a query lower bound of $2n$ for submodular function minimization,
a $3n/2-2$ query lower bound for the non-trivial minimizer of a symmetric
submodular function, and a $\binom{n}{2}$ query lower bound for the non-trivial
minimizer of an asymmetric submodular function.
</p>
<p>Our $3n/2-2$ lower bound results from a connection between SFM lower bounds
and a novel concept we term the cut dimension of a graph. Interestingly, this
yields a $3n/2-2$ cut-query lower bound for finding the global mincut in an
undirected, weighted graph, but we also prove it cannot yield a lower bound
better than $n+1$ for $s$-$t$ mincut, even in a directed, weighted graph.
</p></div>
    </summary>
    <updated>2019-11-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/18/faculty-at-boston-university-apply-by-december-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/18/faculty-at-boston-university-apply-by-december-1-2019/" rel="alternate" type="text/html"/>
    <title>Faculty at Boston University (apply by December 1, 2019)</title>
    <summary>Boston University Computer Science has openings for multiple tenure-track assistant professorships beginning July 1, 2020. Applications in all areas of computer science are invited. The university is also considering senior applicants for its Data Science Initiative. The Department, currently at 31 faculty members, is in the midst of an extended period of sustained growth. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Boston University Computer Science has openings for multiple tenure-track assistant professorships beginning July 1, 2020. Applications in all areas of computer science are invited. The university is also considering senior applicants for its Data Science Initiative.</p>
<p>The Department, currently at 31 faculty members, is in the midst of an extended period of sustained growth.</p>
<p>Website: <a href="https://www.bu.edu/cs/2019/11/18/bu-cs-searching-for-new-faculty-members/">https://www.bu.edu/cs/2019/11/18/bu-cs-searching-for-new-faculty-members/</a><br/>
Email: ads22@bu.edu</p></div>
    </content>
    <updated>2019-11-18T19:59:22Z</updated>
    <published>2019-11-18T19:59:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-19T07:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/18/faculty-quantum-computation-at-uc-san-diego-apply-by-january-1-2020/</id>
    <link href="https://cstheory-jobs.org/2019/11/18/faculty-quantum-computation-at-uc-san-diego-apply-by-january-1-2020/" rel="alternate" type="text/html"/>
    <title>faculty – quantum computation at UC San Diego (apply by January 1, 2020)</title>
    <summary>The Computer Science and the Mathematics departments at UC San Diego are looking for excellent candidates in Quantum Computation. This includes: computational complexity of quantum computation, quantum algorithms, ways to establish quantum supremacy, applications of quantum computation in the sciences, quantum error-correction, quantum communication complexity, or similar topics. Website: https://apol-recruit.ucsd.edu/JPF02292 Email: shachar.lovett@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Computer Science and the Mathematics departments at UC San Diego are looking for excellent candidates in Quantum Computation. This includes: computational complexity of quantum computation, quantum algorithms, ways to establish quantum supremacy, applications of quantum computation in the sciences, quantum error-correction, quantum communication complexity, or similar topics.</p>
<p>Website: <a href="https://apol-recruit.ucsd.edu/JPF02292">https://apol-recruit.ucsd.edu/JPF02292</a><br/>
Email: shachar.lovett@gmail.com</p></div>
    </content>
    <updated>2019-11-18T17:54:44Z</updated>
    <published>2019-11-18T17:54:44Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-11-19T07:20:41Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3436178446517561376</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3436178446517561376/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/11/fields-used-to-be-closer-together-than.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3436178446517561376" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3436178446517561376" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/11/fields-used-to-be-closer-together-than.html" rel="alternate" type="text/html"/>
    <title>Fields used to be closer together than they are now. Good? Bad?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">There was a retired software Eng professor that I had heard two very non-controversial rumors about:<br/>
<br/>
1) He got his PhD in Numerical Analysis<br/>
<br/>
2) He got his PhD in Compiler Optimization.<br/>
<br/>
So I asked him which was true.<br/>
<br/>
The answer: Both! In those days you had to optimize your code to get your NA code to run fast enough.<br/>
<br/>
We cannot imagine that anymore. Or at least I cannot.<br/>
<br/>
Over time the fields of computer science advance more so its hard to be  master of more than one field.  But its not that simple: there has been work recently applying Machine Learning to... well<br/>
everything really. Even so, I think the trend is more towards separation. Or perhaps it oscillates.<br/>
<br/>
I am NOT going to be the grumpy old man (Google once thought I was 70, see <a href="https://blog.computationalcomplexity.org/2018/10/google-added-years-to-my-life.html">here</a>) who says things were better in my day when the fields were closer together. But I will ask the question:<br/>
<br/>
1) Are people more specialized new? While I think yes since each field has gotten more complicated and harder to master. There are exceptions: Complexity theory uses much more sophisticated mathematics then when I was a grad student (1980-1985), and of course Quantum Computing has lead to more comp sci majors knowing physics.<br/>
<br/>
2) Is it good for the field that people are specialized? I am supposed to say that it is terrible and that great advances are made when people are interdiscplinary. But there are many more small advances that are made by someone who has a mastery of one (or two) fields.<br/>
<br/>
3) The PhD Process and the Tenure Process encourage specialization. This I think IS bad since there are different modes of research that should all be respected.'<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-11-18T04:53:00Z</updated>
    <published>2019-11-18T04:53:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-11-18T18:19:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/165</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/165" rel="alternate" type="text/html"/>
    <title>TR19-165 |  Random Restrictions of High-Dimensional Distributions and Uniformity Testing with Subcube Conditioning | 

	Clement Canonne, 

	Xi Chen, 

	Gautam Kamath, 

	Amit Levi, 

	Erik Waingarten</title>
    <summary>We give a nearly-optimal algorithm for testing uniformity of distributions supported on $\{-1,1\}^n$, which makes $\tilde O (\sqrt{n}/\varepsilon^2)$ queries to a subcube conditional sampling oracle (Bhattacharyya and Chakraborty (2018)). The key technical component is a natural notion of random restriction for distributions on $\{-1,1\}^n$, and a quantitative analysis of how such a restriction affects the mean vector of the distribution. Along the way, we consider the problem of mean testing with independent samples and provide a nearly-optimal algorithm.</summary>
    <updated>2019-11-18T01:16:46Z</updated>
    <published>2019-11-18T01:16:46Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-11-19T07:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.06793</id>
    <link href="http://arxiv.org/abs/1911.06793" rel="alternate" type="text/html"/>
    <title>Testing linear-invariant properties</title>
    <feedworld_mtime>1574035200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tidor:Jonathan.html">Jonathan Tidor</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhao:Yufei.html">Yufei Zhao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.06793">PDF</a><br/><b>Abstract: </b>We prove that all linear-invariant, linear-subspace hereditary, locally
characterized properties are proximity-oblivious testable (with one-sided error
and constant query-complexity). In other words, we show that we can distinguish
functions $\mathbb F_p^n\to[R]$ satisfying a given property from those that are
$\epsilon$-far from satisfying the property as long as the property is
definable by restrictions to bounded dimension subspaces.
</p>
<p>This result can be equivalently stated as an induced arithmetic removal
lemma: given a set of colored patterns $\mathbb F_p^d \to [R]$, for every
$\epsilon &gt; 0$ there exists $\delta &gt; 0$ such that if a function $f\colon
\mathbb F_p^n\to[R]$ has density at most $\delta$ of each of the prescribed
patterns, then $f$ can be made free of these patterns by recoloring at most
$\epsilon p^n$ points.
</p>
<p>The proof of this result uses two main techniques. The first builds upon a
long line of work which applies regularity methods, including results from
higher order Fourier analysis, to prove results on property testing and removal
lemmas. The second, the main innovation of this work, is a novel recoloring
technique that allows us to handle an important obstacle encountered by
previous works in the arithmetic setting. Roughly speaking, this obstacle is
the inability of regularity methods to regularize functions in a neighborhood
of the origin.
</p></div>
    </summary>
    <updated>2019-11-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.06791</id>
    <link href="http://arxiv.org/abs/1911.06791" rel="alternate" type="text/html"/>
    <title>Non-Monotone Submodular Maximization with Multiple Knapsacks in Static and Dynamic Settings</title>
    <feedworld_mtime>1574035200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Vanja Doskoč, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Friedrich:Tobias.html">Tobias Friedrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=ouml=bel:Andreas.html">Andreas Göbel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Neumann:Frank.html">Frank Neumann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Neumann:Aneta.html">Aneta Neumann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Quinzan:Francesco.html">Francesco Quinzan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.06791">PDF</a><br/><b>Abstract: </b>We study the problem of maximizing a non-monotone submodular function under
multiple knapsack constraints. We propose a simple discrete greedy algorithm to
approach this problem, and prove that it yields strong approximation guarantees
for functions with bounded curvature. In contrast to other heuristics, this
requires no problem relaxation to continuous domains and it maintains a
constant-factor approximation guarantee in the problem size. In the case of a
single knapsack, our analysis suggests that the standard greedy can be used in
non-monotone settings.
</p>
<p>Additionally, we study this problem in a dynamic setting, by which knapsacks
change during the optimization process. We modify our greedy algorithm to avoid
a complete restart at each constraint update. This modification retains the
approximation guarantees of the static case.
</p>
<p>We evaluate our results experimentally on a video summarization and sensor
placement task. We show that our proposed algorithm competes with the
state-of-the-art in static settings. Furthermore, we show that in dynamic
settings with tight computational time budget, our modified greedy yields
significant improvements over starting the greedy from scratch, in terms of the
solution quality achieved.
</p></div>
    </summary>
    <updated>2019-11-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.06790</id>
    <link href="http://arxiv.org/abs/1911.06790" rel="alternate" type="text/html"/>
    <title>Computationally Data-Independent Memory Hard Functions</title>
    <feedworld_mtime>1574035200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ameri:Mohammad_Hassan.html">Mohammad Hassan Ameri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blocki:Jeremiah.html">Jeremiah Blocki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Samson.html">Samson Zhou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.06790">PDF</a><br/><b>Abstract: </b>Memory hard functions (MHFs) are an important cryptographic primitive that
are used to design egalitarian proofs of work and in the construction of
moderately expensive key-derivation functions resistant to brute-force attacks.
Broadly speaking, MHFs can be divided into two categories: data-dependent
memory hard functions (dMHFs) and data-independent memory hard functions
(iMHFs). iMHFs are resistant to certain side-channel attacks as the memory
access pattern induced by the honest evaluation algorithm is independent of the
potentially sensitive input e.g., password. While dMHFs are potentially
vulnerable to side-channel attacks (the induced memory access pattern might
leak useful information to a brute-force attacker), they can achieve higher
cumulative memory complexity (CMC) in comparison than an iMHF. In this paper,
we introduce the notion of computationally data-independent memory hard
functions (ciMHFs). Intuitively, we require that memory access pattern induced
by the (randomized) ciMHF evaluation algorithm appears to be independent from
the standpoint of a computationally bounded eavesdropping attacker --- even if
the attacker selects the initial input. We then ask whether it is possible to
circumvent known upper bound for iMHFs and build a ciMHF with CMC
$\Omega(N^2)$. Surprisingly, we answer the question in the affirmative when the
ciMHF evaluation algorithm is executed on a two-tiered memory architecture
(RAM/Cache).
</p>
<p>See paper for the full abstract.
</p></div>
    </summary>
    <updated>2019-11-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.06738</id>
    <link href="http://arxiv.org/abs/1911.06738" rel="alternate" type="text/html"/>
    <title>Semi-Algebraic Proofs, IPS Lower Bounds and the $\tau$-Conjecture: Can a Natural Number be Negative?</title>
    <feedworld_mtime>1574035200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alekseev:Yaroslav.html">Yaroslav Alekseev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grigoriev:Dima.html">Dima Grigoriev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hirsch:Edward_A=.html">Edward A. Hirsch</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tzameret:Iddo.html">Iddo Tzameret</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.06738">PDF</a><br/><b>Abstract: </b>We introduce the binary value principle which is a simple subset-sum instance
expressing that a natural number written in binary cannot be negative, relating
it to central problems in proof and algebraic complexity. We prove conditional
superpolynomial lower bounds on the Ideal Proof System (IPS) refutation size of
this instance, based on a well-known hypothesis by Shub and Smale about the
hardness of computing factorials, where IPS is the strong algebraic proof
system introduced by Grochow and Pitassi (2018). Conversely, we show that short
IPS refutations of this instance bridge the gap between sufficiently strong
algebraic and semi-algebraic proof systems. Our results extend to full-fledged
IPS the paradigm introduced in Forbes et al. (2016), whereby lower bounds
against subsystems of IPS were obtained using restricted algebraic circuit
lower bounds, and demonstrate that the binary value principle captures the
advantage of semi-algebraic over algebraic reasoning, for sufficiently strong
systems. Specifically, we show the following: (abstract continues in document.)
</p></div>
    </summary>
    <updated>2019-11-18T23:20:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.06664</id>
    <link href="http://arxiv.org/abs/1911.06664" rel="alternate" type="text/html"/>
    <title>Automated Derivation of Parametric Data Movement Lower Bounds for Affine Programs</title>
    <feedworld_mtime>1574035200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Auguste Olivry, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Langou:Julien.html">Julien Langou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pouchet:Louis=No=euml=l.html">Louis-Noël Pouchet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sadayappan:P=.html">P. Sadayappan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rastello:Fabrice.html">Fabrice Rastello</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.06664">PDF</a><br/><b>Abstract: </b>For most relevant computation, the energy and time needed for data movement
dominates that for performing arithmetic operations on all computing systems
today. Hence it is of critical importance to understand the minimal total data
movement achievable during the execution of an algorithm. The achieved total
data movement for different schedules of an algorithm can vary widely depending
on how efficiently the cache is used, e.g., untiled versus effectively tiled
matrix-matrix multiplication. A significant current challenge is that no
existing tool is able to meaningfully quantify the potential reduction to the
data movement of a computation that can be achieved by more effective use of
the cache through operation rescheduling. Asymptotic parametric expressions of
data movement lower bounds have previously been manually derived for a limited
number of algorithms, often without scaling constants. In this paper, we
present the first compile-time approach for deriving non-asymptotic parametric
expressions of data movement lower bounds for arbitrary affine computations.
The approach has been implemented in a fully automatic tool (IOLB) that can
generate these lower bounds for input affine programs.
</p>
<p>IOLB's use is demonstrated by exercising it on all the benchmarks of the
PolyBench suite. The advantages of IOLB are many: (1) IOLB enables us to derive
bounds for few dozens of algorithms for which these lower bounds have never
been derived. This reflects an increase of productivity by automation. (2)
Anyone is able to obtain these lower bounds through IOLB, no expertise is
required. (3) For some of the most well-studied algorithms, the lower bounds
obtained by \tool are higher than any previously reported manually derived
lower bounds.
</p></div>
    </summary>
    <updated>2019-11-18T23:21:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-11-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.06600</id>
    <link href="http://arxiv.org/abs/1911.06600" rel="alternate" type="text/html"/>
    <title>GraphX-Convolution for Point Cloud Deformation in 2D-to-3D Conversion</title>
    <feedworld_mtime>1574035200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nguyen:Anh=Duc.html">Anh-Duc Nguyen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Choi:Seonghwa.html">Seonghwa Choi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kim:Woojae.html">Woojae Kim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Sanghoon.html">Sanghoon Lee</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.06600">PDF</a><br/><b>Abstract: </b>In this paper, we present a novel deep method to reconstruct a point cloud of
an object from a single still image. Prior arts in the field struggle to
reconstruct an accurate and scalable 3D model due to either the inefficient and
expensive 3D representations, the dependency between the output and number of
model parameters or the lack of a suitable computing operation. We propose to
overcome these by deforming a random point cloud to the object shape through
two steps: feature blending and deformation. In the first step, the global and
point-specific shape features extracted from a 2D object image are blended with
the encoded feature of a randomly generated point cloud, and then this mixture
is sent to the deformation step to produce the final representative point set
of the object. In the deformation process, we introduce a new layer termed as
GraphX that considers the inter-relationship between points like common graph
convolutions but operates on unordered sets. Moreover, with a simple trick, the
proposed model can generate an arbitrary-sized point cloud, which is the first
deep method to do so. Extensive experiments verify that we outperform existing
models and halve the state-of-the-art distance score in single image 3D
reconstruction.
</p></div>
    </summary>
    <updated>2019-11-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.06511</id>
    <link href="http://arxiv.org/abs/1911.06511" rel="alternate" type="text/html"/>
    <title>Graph Iso/Auto-morphism: A Divide-&amp;-Conquer Approach</title>
    <feedworld_mtime>1574035200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Can.html">Can Lu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Jeffrey_Xu.html">Jeffrey Xu Yu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Zhiwei.html">Zhiwei Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheng:Hong.html">Hong Cheng</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.06511">PDF</a><br/><b>Abstract: </b>The graph isomorphism is to determine whether two graphs are isomorphic. A
closely related problem is automorphism detection, where an isomorphism between
two graphs is a bijection between their vertex sets that preserves adjacency,
and an automorphism is an isomorphism from a graph to itself. Applications of
graph isomorphism/automorphism include database indexing, network
simplification, network anonymization. By graph automorphism, we deal with
symmetric subgraph matching (SSM), which is to find all subgraphs that are
symmetric to a given subgraph in G. An application of SSM is to identify
multiple seed sets that have the same influence power as a seed set found by
influence maximization in a social network. To test two graphs for isomorphism,
canonical labeling has been studied to relabel a graph in such a way that
isomorphic graphs are identical after relabeling. Efficient canonical labeling
algorithms have been designed by individualization-refinement. They enumerate
all permutations using a search tree, and select the minimum as the canonical
labeling, which prunes candidates during enumeration. Despite high performance
in benchmark graphs, these algorithms face difficulties in handling massive
graphs. In this paper, we design a new efficient canonical labeling algorithm
DviCL. Different from previous algorithms, we take a divide-&amp;-conquer approach
to partition G. By partitioning G, an AutoTree is constructed, which preserves
symmetric structures and the automorphism group of G. The canonical labeling
for a tree node can be obtained by the canonical labeling of its child nodes,
and the canonical labeling for the root is the one for G. Such AutoTree can
also be effectively used to answer the automorphism group, symmetric subgraphs.
We conducted extensive performance studies using 22 large graphs, and confirmed
that DviCL is much more efficient and robust than the state-of-the-art.
</p></div>
    </summary>
    <updated>2019-11-18T23:28:23Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.06436</id>
    <link href="http://arxiv.org/abs/1911.06436" rel="alternate" type="text/html"/>
    <title>Weighted Triangle-free 2-matching Problem with Edge-disjoint Forbidden Triangles</title>
    <feedworld_mtime>1574035200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobayashi:Yusuke.html">Yusuke Kobayashi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.06436">PDF</a><br/><b>Abstract: </b>The weighted $\mathcal{T}$-free $2$-matching problem is the following
problem: given an undirected graph $G$, a weight function on its edge set, and
a set $\mathcal{T}$ of triangles in $G$, find a maximum weight $2$-matching
containing no triangle in $\mathcal{T}$. When $\mathcal{T}$ is the set of all
triangles in $G$, this problem is known as the weighted triangle-free
$2$-matching problem, which is a long-standing open problem. A main
contribution of this paper is to give a first polynomial-time algorithm for the
weighted $\mathcal{T}$-free $2$-matching problem under the assumption that
$\mathcal{T}$ is a set of edge-disjoint triangles. In our algorithm, a key
ingredient is to give an extended formulation representing the solution set,
that is, we introduce new variables and represent the convex hull of the
feasible solutions as a projection of another polytope in a higher dimensional
space. Although our extended formulation has exponentially many inequalities,
we show that the separation problem can be solved in polynomial time, which
leads to a polynomial-time algorithm for the weighted $\mathcal{T}$-free
$2$-matching problem.
</p></div>
    </summary>
    <updated>2019-11-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-11-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.06403</id>
    <link href="http://arxiv.org/abs/1911.06403" rel="alternate" type="text/html"/>
    <title>New Bounds on $k$-Planar Crossing Numbers</title>
    <feedworld_mtime>1574035200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Alireza Shavali, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zarrabi=Zadeh:Hamid.html">Hamid Zarrabi-Zadeh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.06403">PDF</a><br/><b>Abstract: </b>The crossing number $cr(G)$ of a graph $G$ is the minimum number of crossings
over all possible drawings of $G$ in the plane. Analogously, the $k$-planar
crossing number of $G$, denoted by $cr_{k}(G)$, is the minimum number of
crossings over all possible drawings of the edges of $G$ in $k$ disjoint
planes. We present new bounds on the $k$-planar crossing number of complete
graphs and complete bipartite graphs. In particular, for the case of $k=2$, we
improve the current best lower bounds on biplanar crossing numbers by a factor
of 1.37 for complete graphs, and by a factor of 1.34 for complete bipartite
graphs. We extend our results to the $k$-planar crossing number of complete
(bipartite) graphs, for any positive integer $k \geq 2$. To better understand
the relation between crossing numbers and biplanar crossing numbers, we pose a
new problem of finding the largest crossing number that implies biplanarity. In
particular, we prove that for every graph $G$, $cr(G) \leq 10$ implies
$cr_{2}(G)=0$.
</p></div>
    </summary>
    <updated>2019-11-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-11-18T01:30:00Z</updated>
    </source>
  </entry>
</feed>
