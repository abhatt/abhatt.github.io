<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-03-16T00:22:18Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/042</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/042" rel="alternate" type="text/html"/>
    <title>TR21-042 |  Strong Parallel Repetition for Unique Games on Small Set Expanders | 

	Dana Moshkovitz</title>
    <summary>We show that NP-hardness of approximating Boolean unique games on small set expanders can be amplified to the full Unique Games Conjecture on small set expanders. 
The latter conjecture is known to imply hardness results for problems like Balanced-Separator, Minimum-Linear-Rearrangement and Small-Set-Expansion that are not known under the Unique Games Conjecture.
Our result follows from: (1) A transformation that fortifies any unique game on a small set expander. (2) An improved parallel repetition theorem for fortified games on small set expanders. 
Our approach avoids the known limitation on strong parallel repetition of unique games by enlarging the alphabet considerably before repetition. The limitation does not hold for unique games with a sufficiently large alphabet. 
Prior to this work, parallel repetition from fortification was only known for projection games, and seemed hopeless for unique games. 
Perhaps surprisingly, the idea for fortification of unique games comes from a reduction of Raghavendra and Steurer from Small-Set-Expansion to Unique Games.</summary>
    <updated>2021-03-15T22:30:59Z</updated>
    <published>2021-03-15T22:30:59Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-03-16T00:20:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/03/15/phd-position-at-university-of-salzburg-apply-by-april-25-2021/</id>
    <link href="https://cstheory-jobs.org/2021/03/15/phd-position-at-university-of-salzburg-apply-by-april-25-2021/" rel="alternate" type="text/html"/>
    <title>PhD position at University of Salzburg (apply by April 25, 2021)</title>
    <summary>There is an open position for a PhD student in the project “Dynamic Algorithms Against Strong Adversaries (DynASoAr)” funded by the ERC Starting Grant of Assistant Professor Sebastian Forster from the Efficient Algorithms Group at the University of Salzburg, Austria. The main goal of this project is to design new dynamic algorithms with theoretical guarantees […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>There is an open position for a PhD student in the project “Dynamic Algorithms Against Strong Adversaries (DynASoAr)” funded by the ERC Starting Grant of Assistant Professor Sebastian Forster from the Efficient Algorithms Group at the University of Salzburg, Austria. The main goal of this project is to design new dynamic algorithms with theoretical guarantees for fundamental graph problems.</p>
<p>Website: <a href="https://www.cs.sbg.ac.at/~forster/jobs.html">https://www.cs.sbg.ac.at/~forster/jobs.html</a><br/>
Email: forster@cs.sbg.ac.at</p></div>
    </content>
    <updated>2021-03-15T17:05:39Z</updated>
    <published>2021-03-15T17:05:39Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-03-16T00:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/041</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/041" rel="alternate" type="text/html"/>
    <title>TR21-041 |  An Efficient Coding Theorem via Probabilistic Representations and its Applications | 

	Zhenjian Lu, 

	Igor Carboni Oliveira</title>
    <summary>A probabilistic representation of a string $x \in \{0,1\}^n$ is given by the code of a randomized algorithm that outputs $x$ with high probability [Oliveira, ICALP 2019]. We employ probabilistic representations to establish the first unconditional Coding Theorem in time-bounded Kolmogorov complexity. More precisely, we show that if a distribution ensemble $\mathcal{D}_m$ can be uniformly sampled in time $T(m)$ and generates a string $x \in \{0,1\}^*$ with probability at least $\delta$, then $x$ admits a time-bounded probabilistic representation of complexity $O(\log(1/\delta) + \log (T) + \log(m))$. Under mild assumptions, a representation of this form can be  computed from $x$ and the code of the sampler in time polynomial in $n = |x|$. 
		
We derive consequences of this result relevant to the study of data compression, pseudodeterministic algorithms, time hierarchies for sampling distributions, and complexity lower bounds. In particular, we describe an instance-based search-to-decision reduction for Levin's Kt complexity [Levin, Information and Control 1984] and its probabilistic analogue rKt [Oliveira, ICALP 2019]. As a consequence, if a string $x$ admits a succinct time-bounded representation, then a near-optimal representation can be generated from $x$ with high probability in polynomial time. This partially addresses in a time-bounded setting a question from [Levin, Information and Control 1984] on the efficiency of computing an  optimal encoding of a string.</summary>
    <updated>2021-03-15T13:26:58Z</updated>
    <published>2021-03-15T13:26:58Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-03-16T00:20:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/040</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/040" rel="alternate" type="text/html"/>
    <title>TR21-040 |  Majority vs. Approximate Linear Sum and Average-Case Complexity Below NC1 | 

	Lijie Chen, 

	Zhenjian Lu, 

	Xin Lyu, 

	Igor Carboni Oliveira</title>
    <summary>We develop a general framework that characterizes strong average-case lower bounds against circuit classes $\mathcal{C}$ contained in $\mathrm{NC}^1$, such as $\mathrm{AC}^0[\oplus]$ and $\mathrm{ACC}^0$. We apply this framework to show:

- Generic seed reduction: Pseudorandom generators (PRGs) against $\mathcal{C}$ of seed length $\leq n -1$ and error $\varepsilon(n) = n^{-\omega(1)}$ can be converted into PRGs of sub-polynomial seed length.

- Hardness under natural distributions: If $\mathrm{E}$ (deterministic exponential time) is average-case hard against $\mathcal{C}$ under some distribution, then $\mathrm{E}$ is average-case hard against $\mathcal{C}$ under the uniform distribution.

- Equivalence between worst-case and average-case hardness: Worst-case lower bounds against $\mathrm{MAJ} \circ \mathcal{C}$ for problems in $E$ are equivalent to strong average-case lower bounds against $\mathcal{C}$. This can be seen as a certain converse to the Discriminator Lemma [Hajnal et al., JCSS'93].

These results were not known to hold for circuit classes that do not compute majority. Additionally, we prove that classical and recent approaches to worst-case lower bounds against $\mathrm{ACC}^0$ via communication lower bounds for NOF multi-party  protocols [Hastad and Goldmann, CC'91; Razborov and Wigderson, IPL'93] and Torus polynomials degree lower bounds [Bhrushundi et al., ITCS'19] also imply strong average-case hardness against $\mathrm{ACC}^0$ under the uniform distribution.

Crucial to these results is the use of non-black-box hardness amplification techniques and the interplay between Majority ($\mathrm{MAJ}$) and Approximate Linear Sum ($\widetilde{\mathrm{SUM}}$) gates. Roughly speaking, while a $\mathrm{MAJ}$ gate outputs $1$ when the sum of the $m$ input bits is at least $m/2$, a $\widetilde{\mathrm{SUM}}$ gate computes a real-valued bounded weighted sum of the input bits and outputs $1$ (resp. $0$) if the sum is close to $1$ (resp. close to $0$), with the promise that one of the two cases always holds. As part of our framework, we explore ideas introduced in [Chen and Ren, STOC'20] to show that, for the purpose of proving lower bounds, a top layer $MAJ$ gate is equivalent to a (weaker) $\widetilde{\mathrm{SUM}}$ gate. Motivated by this result, we extend the algorithmic method and establish stronger lower bounds against bounded-depth circuits with layers of $\mathrm{MAJ}$ and $\widetilde{\mathrm{SUM}}$ gates. Among them, we prove that:
    
- Lower bound: $\mathrm{NQP}$ does not admit fixed quasi-polynomial size $\mathrm{MAJ} \circ \widetilde{\mathrm{SUM}} \circ \mathrm{ACC}^0 \circ \mathrm{THR}$ circuits.

This is the first explicit lower bound against circuits with distinct layers of $\mathrm{MAJ}$, $\widetilde{\mathrm{SUM}}$, and $\mathrm{THR}$ gates. Consequently, if the aforementioned equivalence between $\mathrm{MAJ}$ and $\widetilde{\mathrm{SUM}}$ as a top gate can be extended to intermediate layers, long sought-after lower bounds against the class $\mathrm{THR} \circ \mathrm{THR}$ of depth-$2$ polynomial-size threshold circuits would follow.</summary>
    <updated>2021-03-15T13:23:12Z</updated>
    <published>2021-03-15T13:23:12Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-03-16T00:20:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/039</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/039" rel="alternate" type="text/html"/>
    <title>TR21-039 |  Pseudodeterministic Algorithms and the Structure of Probabilistic Time | 

	Zhenjian Lu, 

	Igor Carboni Oliveira, 

	Rahul Santhanam</title>
    <summary>We connect the study of pseudodeterministic algorithms to two major open problems about the structural complexity of $BPTIME$: proving hierarchy theorems and showing the existence of complete problems. Our main contributions can be summarised as follows.

1. A new pseudorandom generator and its consequences: We build on techniques developed to prove hierarchy theorems for probabilistic time with advice (Fortnow and Santhanam, FOCS 2004) to construct the first unconditional pseudorandom generator of polynomial stretch computable in pseudodeterministic polynomial time (with one bit of advice) that is secure infinitely often against polynomial-time computations.  As an application of this construction, we obtain new results about the complexity of generating and representing prime numbers. For instance, we show unconditionally for each $\varepsilon &gt; 0$ that infinitely many primes $p_n$ have a succinct representation in the following sense: there is a fixed probabilistic polynomial time algorithm that generates $p_n$ with high probability from its succinct representation of size $O(|p_n|^{\varepsilon})$. This offers an exponential improvement over the running time of previous results, and shows that infinitely many primes have succinct and efficient representations. 
		
2. Structural results for probabilistic time from pseudodeterministic algorithms: Oliveira and Santhanam (STOC 2017) established unconditionally that there is a pseudodeterministic algorithm for the Circuit Acceptance Probability Problem ($CAPP$) that runs in sub-exponential time and is correct with high probability over any samplable distribution on circuits on infinitely many input lengths. We show that improving  this running time or obtaining a result that holds for every large input length would imply new time hierarchy theorems for probabilistic time. In addition, we prove that a worst-case polynomial-time pseudodeterministic algorithm for $CAPP$ would imply that $BPP$ has complete problems.
		
3. Equivalence between pseudodeterministic constructions and hierarchies: We establish an equivalence between a certain explicit pseudodeterministic construction problem and the existence of strong hierarchy theorems for probabilistic time. More precisely, we show that pseudodeterministically constructing in exponential time strings of large $rKt$ complexity (Oliveira, ICALP 2019) is possible if and only if for every constructive function $T(n) \leq \exp(o(\exp(n)))$ we have $BPTIME[poly(T)] \not\subseteq i.o.BPTIME[T]/\log T$.

More generally, these results suggest new approaches for designing pseudodeterministic algorithms for search problems and for unveiling the structure of probabilistic time.</summary>
    <updated>2021-03-15T13:19:50Z</updated>
    <published>2021-03-15T13:19:50Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-03-16T00:20:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/038</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/038" rel="alternate" type="text/html"/>
    <title>TR21-038 |  Post-Quantum Succinct Arguments | 

	Alessandro Chiesa, 

	Fermi Ma, 

	Nicholas Spooner, 

	Mark Zhandry</title>
    <summary>We prove that Kilian's four-message succinct argument system is post-quantum secure in the standard model when instantiated with any probabilistically checkable proof and any collapsing hash function (which in turn exist based on the post-quantum hardness of Learning with Errors). 

At the heart of our proof is a new "measure-and-repair" quantum rewinding procedure that achieves asymptotically optimal knowledge error.</summary>
    <updated>2021-03-15T08:53:04Z</updated>
    <published>2021-03-15T08:53:04Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-03-16T00:20:26Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7956728127025472802</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7956728127025472802/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/03/i-didnt-understand-art-market-before.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7956728127025472802" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7956728127025472802" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/03/i-didnt-understand-art-market-before.html" rel="alternate" type="text/html"/>
    <title>I didn't understand The Art Market before the NFT sale, and I understand it less now</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> (This post is a sequel to my post from Feb 13, 2007 which you can find <a href="https://blog.computationalcomplexity.org/search?q=rare">here</a>. While the gap from 2007 until 2021 seems large, its not as long as the gap between Knuth Vol 3 and Knuth Vol 4, nor as long as the gap between Stan Freberg Vinyl Record History of America Part I and his CD History of America Part 2, both novelty records, and quite good.)</p><p>My 2017 post was about people posting a clip on youtube and calling it `rare footage of...' </p><p><br/></p><p>My point was: How can something be rare if its on you tube?</p><p>I also pondered: if someone can make a REALLY REALLY GOOD copy of the Mona Lisa, that is at talent that should be respected and such a person should be able to sell it for about the same price as the original (not sure if I want the copy to be worth A LOT or the original to be worth LESS than it is.)</p><p>IF Art is to-look-at-cause-its-pretty then it should not matter who the artist is. </p><p>IF Art is an investment then that could be risky since it does not have intrinsic value. </p><p>IF Art is neither to-look-at or an investment then... What is it? We'll see below that one answer might be Bragging Rights. </p><p>This is NOT a RANT, this is an admitance of my lack of understanding. (Spell check things admitance is not a word. Maybe its admitence. No, Hmmm.) </p><p>And now there is a new wrinkle in all of this: </p><p>69 million for a NFT (Non-Fungable Token) of an art work:<a href="https://variety.com/2021/digital/news/nft-craze-beeple-jpeg-artwork-69-million-1234928289/">story here</a></p><p>1) What is the buyer getting? Bragging rights?</p><p>2) Can anyone SEE the art but doesn't OWN it? I don't know..</p><p>3) If someone hacked in and got a perfect copy of the art and posted it on a website, would that be theft? Nothing was taken. </p><p>4) In the normal art world does it happen that prices go DOWN because people wake up and say WHAT? Why did I EVER think that White on White was worth 10 million dollars? </p><p>5) Might this happen here also? </p><p>6) Is My Feb 13 blog, which is in a diff format (or I didn't know how to use the blogger interface then) going to one day be worth something?</p><p><br/></p></div>
    </content>
    <updated>2021-03-15T05:52:00Z</updated>
    <published>2021-03-15T05:52:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-03-15T19:57:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=18335</id>
    <link href="https://rjlipton.wordpress.com/2021/03/14/the-value-of-pi/" rel="alternate" type="text/html"/>
    <title>The Value of Pi</title>
    <summary>A post for Pi Day—but should it be a different day? Unilad story source Emma Haruka Iwao set an official Guinness world record in 2019 by calculating pi to 31,415,926,535,897 digits. If she had calculated it to 62,831,853,071,795 digits, she might still hold that record today. Today, Pi Day (3/14), we ask why was affixed […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>A post for Pi Day—but should it be a different day?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2021/03/14/the-value-of-pi/pi-day-thumb/" rel="attachment wp-att-18337"><img alt="" class="alignright wp-image-18337" height="105" src="https://rjlipton.files.wordpress.com/2021/03/pi-day-thumb.jpg?w=200&amp;h=105" width="200"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Unilad story <a href="https://www.unilad.co.uk/technology/google-employee-breaks-record-by-calculating-pi-to-31-4-trillion-digits/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Emma Haruka Iwao set an official Guinness world record in 2019 by calculating pi to <b>31,415,926,535,897</b> digits. If she had calculated it to <b>62,831,853,071,795</b> digits, she might still hold that <a href="https://www.guinnessworldrecords.com/world-records/66179-most-accurate-value-of-pi">record</a> today.</p>
<p>
Today, Pi Day (3/14), we ask why <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> was affixed to the value <b>3.141592653589793…</b></p>
<p>
The main alternatives are the values we currently call <img alt="{2\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{\frac{\pi}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B%5Cpi%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Neither would have caused any extra difficulty for Iwao. The methods she used, including the <a href="http://www.numberworld.org/y-cruncher/">y-cruncher</a> implementation of the fast <a href="https://en.wikipedia.org/wiki/Chudnovsky_algorithm">algorithm</a> of David and Gregory Chudnovsky, could adapt immediately to a factor of <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> either way. </p>
<p>
Two things that stand out to us from Iwao’s <a href="https://blog.google/products/google-cloud/most-calculated-digits-pi/">story</a> told on Google’s blogs, besides her commanding the power of Google’s cloud services to manage 170 terabytes of data over 121 days for the calculation, are:</p>
<ul>
<li>She was inspired while growing up in Japan by the current record holders being Japanese professors, one of whom she later worked for as a student.
</li><li>There was a quicker checking phase for the final product—in particular, for the 8,956,768,817,536 new digits. This used a mixture of two versions of the <a href="https://en.wikipedia.org/wiki/Bailey-Borwein-Plouffe_formula">BBP</a> method, which we <a href="https://rjlipton.wordpress.com/2010/07/14/making-an-algorithm-an-algorithm-bbp/">covered</a> a <a href="https://rjlipton.wordpress.com/2009/03/15/cooks-class-contains-pi/">few</a> <a href="https://rjlipton.wordpress.com/2012/10/16/one-mans-floor-is-another-mans-ceiling/">times</a>.
</li></ul>
<p>
The new <a href="https://blog.timothymullican.com/calculating-pi-my-attempt-breaking-pi-record">record</a> of 50 trillion digits by Timothy Mullican have been added to Iwao’s available for <a href="https://pi.delivery/">delivery</a> by Google. We do not know the extent to which they are <em>concretely</em> pseudorandom, despite coming from a simple rule, but that extent would be shared equally by <img alt="{2\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{\frac{\pi}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B%5Cpi%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p/><h2> Why This Value? </h2><p/>
<p>
Giorgia Fortuna in 2015 wrote a long <a href="https://blog.wolfram.com/2015/06/28/2-pi-or-not-2-pi/">article</a> on the Wolfram blog about <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> versus <img alt="{\tau}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, where <img alt="{\tau}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a suggested symbol for <img alt="{2\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which equals <b>6.2831853071795…</b> Her extensive analysis of formulas in the literature shows that the benefit of simplifying mathematical and scientific formulas that involve <img alt="{2\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> by the single symbol <img alt="{\tau}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> would be minimal, and more than offset by formulas that would incur <img alt="{\tau/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Our blogging friend Bill Gasarch has <a href="https://blog.computationalcomplexity.org/2007/08/is-pi-defined-in-best-way.html">written</a> <a href="https://blog.computationalcomplexity.org/2009/07/2pi-day-other-holiday-possibilities.html">about</a> the value of <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and expressed opinions in support of <img alt="{2\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as “the” value.</p>
<p>
We want to pose a different question, one suggested to me today by a reference to the 3rd-century <a href="https://en.wikipedia.org/wiki/Liu_Hui's_pi_algorithm">algorithm</a> of the Chinese mathematician Liu Hui, which efficiently generated values far more precise than what was known in the west: </p>
<blockquote><p><b> </b> <em> Why did several separate cultures fix upon the ratio of the circumference to the diameter, rather than the ratio of the circumference to the radius, or the diameter to half the circumference? </em>
</p></blockquote>
<p>
The last ratio, <b>1.5707963267948966…</b>, strikes us as the most natural to think of in the great outdoors: You have a choice of rowing across a circular pond or walking around. How much more distance does the latter involve?</p>
<p>
We don’t know of a name for partisans of <img alt="{2\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, but those of <img alt="{\frac{\pi}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B%5Cpi%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> would have a natural moniker:</p>
<blockquote><p><b> </b> <em> Sesqui<b>pi</b>dalians. </em>
</p></blockquote>
<p>
This branches off the word <a href="https://www.merriam-webster.com/dictionary/sesquipedalian">sesquipedalian</a> in an appropriate way, since <em>sesqui-</em> is Latin for one-and-a-half (as in “sesquicentennial”) and <img alt="{\frac{\pi}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B%5Cpi%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is near <img alt="{1.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. But that line of thinking led us to wonder about a possible answer to the historical puzzle:</p>
<blockquote><p><b> </b> <em> Did the ancients favor 3.14… because it was the closest to an integer of three main options? </em>
</p></blockquote>
<p/><h2> Open Problems </h2><p/>
<p>
Is there any merit to our historical question? We leave it as a riddle until the next Pi Day—or at least until 6/28/2021.  Note also our previous <a href="https://rjlipton.wordpress.com/2014/06/15/honor-thy-fathers-correctly/">query</a> about whether the Indian mathematician Aryabhata favored <img alt="{2\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as the number of note.</p>
<p>
[some word and format tweaks, added note on Aryabhata]</p></font></font></div>
    </content>
    <updated>2021-03-15T04:58:05Z</updated>
    <published>2021-03-15T04:58:05Z</published>
    <category term="All Posts"/>
    <category term="fast"/>
    <category term="News"/>
    <category term="People"/>
    <category term="BBP algorithm"/>
    <category term="Chudnovsky algorithm"/>
    <category term="Emma Haruka Iwao"/>
    <category term="Liu Hui"/>
    <category term="Pi"/>
    <category term="Pi Day"/>
    <category term="y-cruncher algorithm"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2021-03-16T00:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2103.07459</id>
    <link href="http://arxiv.org/abs/2103.07459" rel="alternate" type="text/html"/>
    <title>On Mixing of Markov Chains: Coupling, Spectral Independence, and Entropy Factorization</title>
    <feedworld_mtime>1615766400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blanca:Antonio.html">Antonio Blanca</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Caputo:Pietro.html">Pietro Caputo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Zongchen.html">Zongchen Chen</a>, Daniel Parisi, Daniel Štefankovič, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vigoda:Eric.html">Eric Vigoda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2103.07459">PDF</a><br/><b>Abstract: </b>For general spin systems, we prove that a contractive coupling for any local
Markov chain implies optimal bounds on the mixing time and the modified
log-Sobolev constant for a large class of Markov chains including the Glauber
dynamics, arbitrary heat-bath block dynamics, and the Swendsen-Wang dynamics.
This reveals a novel connection between probabilistic techniques for bounding
the convergence to stationarity and analytic tools for analyzing the decay of
relative entropy. As a corollary of our general results, we obtain
$O(n\log{n})$ mixing time and $\Omega(1/n)$ modified log-Sobolev constant of
the Glauber dynamics for sampling random $q$-colorings of an $n$-vertex graph
with constant maximum degree $\Delta$ when $q &gt; (11/6 - \epsilon_0)\Delta$ for
some fixed $\epsilon_0&gt;0$. We also obtain $O(\log{n})$ mixing time and
$\Omega(1)$ modified log-Sobolev constant of the Swendsen-Wang dynamics for the
ferromagnetic Ising model on an $n$-vertex graph of constant maximum degree
when the parameters of the system lie in the tree uniqueness region. At the
heart of our results are new techniques for establishing spectral independence
of the spin system and block factorization of the relative entropy. On one hand
we prove that a contractive coupling of a local Markov chain implies spectral
independence of the Gibbs distribution. On the other hand we show that spectral
independence implies factorization of entropy for arbitrary blocks,
establishing optimal bounds on the modified log-Sobolev constant of the
corresponding block dynamics.
</p></div>
    </summary>
    <updated>2021-03-15T22:38:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-03-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2103.07445</id>
    <link href="http://arxiv.org/abs/2103.07445" rel="alternate" type="text/html"/>
    <title>Efficient reconstruction of depth three circuits with top fan-in two</title>
    <feedworld_mtime>1615766400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sinha:Gaurav.html">Gaurav Sinha</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2103.07445">PDF</a><br/><b>Abstract: </b>We develop efficient randomized algorithms to solve the black-box
reconstruction problem for polynomials over finite fields, computable by depth
three arithmetic circuits with alternating addition/multiplication gates, such
that output gate is an addition gate with in-degree two. These circuits compute
polynomials of form $G\times(T_1 + T_2)$, where $G,T_1,T_2$ are product of
affine forms, and polynomials $T_1,T_2$ have no common factors. Rank of such a
circuit is defined as dimension of vector space spanned by all affine factors
of $T_1$ and $T_2$. For any polynomial $f$ computable by such a circuit,
$rank(f)$ is defined to be the minimum rank of any such circuit computing it.
Our work develops randomized reconstruction algorithms which take as input
black-box access to a polynomial $f$ (over finite field $\mathbb{F}$),
computable by such a circuit. Here are the results.
</p>
<p>1 [Low rank]: When $5\leq rank(f) = O(\log^3 d)$, it runs in time
$(nd^{\log^3d}\log |\mathbb{F}|)^{O(1)}$, and, with high probability, outputs a
depth three circuit computing $f$, with top addition gate having in-degree
$\leq d^{rank(f)}$.
</p>
<p>2 [High rank]: When $rank(f) = \Omega(\log^3 d)$, it runs in time $(nd\log
|\mathbb{F}|)^{O(1)}$, and, with high probability, outputs a depth three
circuit computing $f$, with top addition gate having in-degree two.
</p>
<p>Ours is the first blackbox reconstruction algorithm for this circuit class,
that runs in time polynomial in $\log |\mathbb{F}|$. This problem has been
mentioned as an open problem in [GKL12] (STOC 2012)
</p></div>
    </summary>
    <updated>2021-03-15T22:37:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-03-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2103.07367</id>
    <link href="http://arxiv.org/abs/2103.07367" rel="alternate" type="text/html"/>
    <title>Randomized Scheduling for the Online Car-sharing Problem</title>
    <feedworld_mtime>1615766400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Kuan-Yun Lai, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liang:Ya=Chun.html">Ya-Chun Liang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Ho=Lin.html">Ho-Lin Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iwama:Kazuo.html">Kazuo Iwama</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liao:Chung=Shou.html">Chung-Shou Liao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2103.07367">PDF</a><br/><b>Abstract: </b>The car-sharing problem, proposed by Luo, Erlebach and Xu in 2018, mainly
focuses on an online model in which there are two locations: 0 and 1, and $k$
total cars. Each request which specifies its pick-up time and pick-up location
(among 0 and 1, and the other is the drop-off location) is released in each
stage a fixed amount of time before its specified start (i.e. pick-up) time.
The time between the booking (i.e. released) time and the start time is enough
to move empty cars between 0 and 1 for relocation if they are not used in that
stage. The model, called $k$S2L-F, assumes requests in each stage arrive
sequentially regardless of the same booking time and the decision (accept or
reject) must be made immediately. The goal is to accept as many requests as
possible. The model is surprisingly not easy even for only two locations. The
previous algorithm achieves a (tight) competitive ratio of $\frac{3}{2}$ only
when $k$ is a multiple of three. In this paper, we aim at better algorithms
under the assumption that all the requests with the same booking time arrive
simultaneously. Indeed, we propose a randomized algorithm which can achieve a
competitive ratio of $\frac{4}{3}$ for any value of $k$. In particular, the
randomized algorithm can be extended to achieve a ratio of $\frac{2+R}{3}$ if
the number of requests in each stage is at most $Rk$, where $R$ is a constant
and $1 \le R \le 2$. Both ratios are tight. Our algorithm can also accommodate
the original $k$S2L-F without changing its basic structure.
</p></div>
    </summary>
    <updated>2021-03-15T22:39:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-03-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2103.07360</id>
    <link href="http://arxiv.org/abs/2103.07360" rel="alternate" type="text/html"/>
    <title>Sampling from the low temperature Potts model through a Markov chain on flows</title>
    <feedworld_mtime>1615766400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jeroen Huijben, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patel:Viresh.html">Viresh Patel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Regts:Guus.html">Guus Regts</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2103.07360">PDF</a><br/><b>Abstract: </b>In this paper we consider the algorithmic problem of sampling from the Potts
model and computing its partition function at low temperatures. Instead of
directly working with spin configurations, we consider the equivalent problem
of sampling flows. We show, using path coupling, that a simple and natural
Markov chain on the set of flows is rapidly mixing. As a result we find a
$\delta$-approximate sampling algorithm for the Potts model at low enough
temperatures, whose running time is bounded by $O(m^2\log(m\delta^{-1}))$ for
graphs $G$ with $m$ edges.
</p></div>
    </summary>
    <updated>2021-03-15T22:42:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-03-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2103.07353</id>
    <link href="http://arxiv.org/abs/2103.07353" rel="alternate" type="text/html"/>
    <title>Computing Zigzag Persistence on Graphs in Near-Linear Time</title>
    <feedworld_mtime>1615766400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dey:Tamal_K=.html">Tamal K. Dey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hou:Tao.html">Tao Hou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2103.07353">PDF</a><br/><b>Abstract: </b>Graphs model real-world circumstances in many applications where they may
constantly change to capture the dynamic behavior of the phenomena. Topological
persistence which provides a set of birth and death pairs for the topological
features is one instrument for analyzing such changing graph data. However,
standard persistent homology defined over a growing space cannot always capture
such a dynamic process unless shrinking with deletions is also allowed. Hence,
zigzag persistence which incorporates both insertions and deletions of
simplices is more appropriate in such a setting. Unlike standard persistence
which admits nearly linear-time algorithms for graphs, such results for the
zigzag version improving the general $O(m^\omega)$ time complexity are not
known, where $\omega&lt; 2.37286$ is the matrix multiplication exponent. In this
paper, we propose algorithms for zigzag persistence on graphs which run in
near-linear time. Specifically, given a filtration with $m$ additions and
deletions on a graph with $n$ vertices and edges, the algorithm for
$0$-dimension runs in $O(m\log^2 n+m\log m)$ time and the algorithm for
1-dimension runs in $O(m\log^4 n)$ time. The algorithm for $0$-dimension draws
upon another algorithm designed originally for pairing critical points of Morse
functions on $2$-manifolds. The algorithm for $1$-dimension pairs a negative
edge with the earliest positive edge so that a $1$-cycle containing both edges
resides in all intermediate graphs. Both algorithms achieve the claimed time
complexity via dynamic graph data structures proposed by Holm et al. In the
end, using Alexander duality, we extend the algorithm for $0$-dimension to
compute the $(p-1)$-dimensional zigzag persistence for $\mathbb{R}^p$-embedded
complexes in $O(m\log^2 n+m\log m+n\log n)$ time.
</p></div>
    </summary>
    <updated>2021-03-15T22:47:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-03-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2103.07344</id>
    <link href="http://arxiv.org/abs/2103.07344" rel="alternate" type="text/html"/>
    <title>Search of fractal space-filling curves with minimal dilation</title>
    <feedworld_mtime>1615766400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Malykhin:Yuri.html">Yuri Malykhin</a>, Evgeny Shchepin <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2103.07344">PDF</a><br/><b>Abstract: </b>We introduce an algorithm for a search of extremal fractal curves in large
curve classes. It heavily uses SAT-solvers -- heuristic algorithms that find
models for CNF boolean formulas. Our algorithm was implemented and applied to
the search of fractal surjective curves $\gamma\colon[0,1]\to[0,1]^d$ with
minimal dilation
$$\sup_{t_1&lt;t_2}\frac{\|\gamma(t_2)-\gamma(t_1)\|^d}{t_2-t_1}.$$
</p>
<p>We report new results of that search in the case of Euclidean norm.
</p>
<p>One of the results is a new curve that we call "YE", a self-similar
(monofractal) plain curve of genus $5\times 5$ with dilation
$5\frac{43}{73}=5.5890\ldots$, which is best-known among plain monofractals.
Moreover, the YE-curve is the unique minimal curve among monofractals of genus
$\le 6\times 6$. We give a proof of minimality, which relies both on
computations and theoretical results.
</p>
<p>We notice that the classes of facet-gated multifractals are rigid enough to
allow an efficient search, and contain many curves with small dilation. In
dimension $3$ we have found facet-gated bifractals (that we call "Spring") of
genus $2\times2\times 2$ with dilation $&lt;17$. In dimension $4$ we obtained that
there is a curve with dilation $&lt;62$.
</p>
<p>Some lower bounds on the dilation for wider classes of cubically decomposable
curves are proved.}
</p></div>
    </summary>
    <updated>2021-03-15T22:52:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-03-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2103.07258</id>
    <link href="http://arxiv.org/abs/2103.07258" rel="alternate" type="text/html"/>
    <title>Packing Squares into a Disk with Optimal Worst-Case Density</title>
    <feedworld_mtime>1615766400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fekete:S=aacute=ndor_P=.html">Sándor P. Fekete</a>, Vijaykrishna Gurunathan, Kushagra Juneja, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Keldenich:Phillip.html">Phillip Keldenich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kleist:Linda.html">Linda Kleist</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scheffer:Christian.html">Christian Scheffer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2103.07258">PDF</a><br/><b>Abstract: </b>We provide a tight result for a fundamental problem arising from packing
squares into a circular container: The critical density of packing squares into
a disk is $\delta=\frac{8}{5\pi}\approx 0.509$. This implies that any set of
(not necessarily equal) squares of total area $A \leq \frac{8}{5}$ can always
be packed into a disk with radius 1; in contrast, for any $\varepsilon&gt;0$ there
are sets of squares of total area $\frac{8}{5}+\varepsilon$ that cannot be
packed, even if squares may be rotated. This settles the last (and arguably,
most elusive) case of packing circular or square objects into a circular or
square container: The critical densities for squares in a square
$\left(\frac{1}{2}\right)$, circles in a square
$\left(\frac{\pi}{(3+2\sqrt{2})}\approx 0.539\right)$ and circles in a circle
$\left(\frac{1}{2}\right)$ have already been established, making use of
recursive subdivisions of a square container into pieces bounded by straight
lines, or the ability to use recursive arguments based on similarity of objects
and container; neither of these approaches can be applied when packing squares
into a circular container. Our proof uses a careful manual analysis,
complemented by a computer-assisted part that is based on interval arithmetic.
Beyond the basic mathematical importance, our result is also useful as a
blackbox lemma for the analysis of recursive packing algorithms. At the same
time, our approach showcases the power of a general framework for
computer-assisted proofs, based on interval arithmetic.
</p></div>
    </summary>
    <updated>2021-03-15T22:42:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-03-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2103.07257</id>
    <link href="http://arxiv.org/abs/2103.07257" rel="alternate" type="text/html"/>
    <title>An FPTAS for the $\Delta$-modular multidimensional knapsack problem</title>
    <feedworld_mtime>1615766400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>D. V. Gribanov <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2103.07257">PDF</a><br/><b>Abstract: </b>It is known that there is no EPTAS for the $m$-dimensional knapsack problem
unless $W[1] = FPT$. It is true already for the case, when $m = 2$. But an
FPTAS still can exist for some other particular cases of the problem.
</p>
<p>In this note we show that the $m$-dimensional knapsack problem with a
$\Delta$-modular constraints matrix admits an FPTAS with the arithmetical
complexity $$O(T_{LP} \cdot (1/\varepsilon)^{m+3} \cdot (2m)^{2m + 6} \cdot
\Delta),$$ where $T_{LP}$ is the linear programming complexity bound. In
particular, for fixed $m$ the arithmetical complexity bound becomes $$ O(n
\cdot (1/\varepsilon)^{m+3} \cdot \Delta). $$ Our algorithm is actually a
generalisation of the classical FPTAS for the $1$-dimensional case.
</p>
<p>The goal of the paper is only to prove the existence of an FPTAS, and more
accurate analysis can give better constants in exponents. Moreover, we are not
worry to much about memory usage, it can be roughly estimated as $O( n \cdot
(1/\varepsilon)^{m+3} \cdot (2m)^{2m+6} \cdot \Delta)$.
</p></div>
    </summary>
    <updated>2021-03-15T22:37:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-03-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2103.07027</id>
    <link href="http://arxiv.org/abs/2103.07027" rel="alternate" type="text/html"/>
    <title>Robust Lower Bounds for Graph Problems in the Blackboard Model of Communication</title>
    <feedworld_mtime>1615766400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Konrad:Christian.html">Christian Konrad</a>, Peter Robinson, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zamaraev:Viktor.html">Viktor Zamaraev</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2103.07027">PDF</a><br/><b>Abstract: </b>We give lower bounds on the communication complexity of graph problems in the
multi-party blackboard model. In this model, the edges of an $n$-vertex input
graph are partitioned among $k$ parties, who communicate solely by writing
messages on a shared blackboard that is visible to every party. We show that
any non-trivial graph problem on $n$-vertex graphs has blackboard communication
complexity $\Omega(n)$ bits, even if the edges of the input graph are randomly
assigned to the $k$ parties. We say that a graph problem is non-trivial if the
output cannot be computed in a model where every party holds at most one edge
and no communication is allowed. Our lower bound thus holds for essentially all
key graph problems relevant to distributed computing, including Maximal
Independent Set (MIS), Maximal Matching, ($\Delta+1$)-coloring, and Dominating
Set. In many cases, e.g., MIS, Maximal Matching, and $(\Delta+1)$-coloring, our
lower bounds are optimal, up to poly-logarithmic factors.
</p></div>
    </summary>
    <updated>2021-03-15T22:41:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-03-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2103.06942</id>
    <link href="http://arxiv.org/abs/2103.06942" rel="alternate" type="text/html"/>
    <title>Imagined-Trailing-Whitespace-Agnostic Levenshtein Distance For Plaintext Table Detection</title>
    <feedworld_mtime>1615766400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Kartik Vempala <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2103.06942">PDF</a><br/><b>Abstract: </b>The standard algorithm for Levenshtein distance, treats trailing whitespace
the same as any other letter or symbol. However, when humans compare 2 strings,
we implicitly assume that both strings are padded by infinite trailing
whitespace. This informs our expectations for what the costs for insertion,
deletion and replacement, should be. This violation of our expectations results
in non-intuitive edit distance values. To account for this specific human
intuition, a naive approach which considers "all possible" substrings of
trailing whitespace would yield an $O(n^3)$ algorithm. In this work, we provide
an efficient $O(n^2)$ algorithm to compute the same. Keywords: Imagined
Infinite Trailing Whitespace, Human Friendly, Intuitive Edit Distance, Table
Detection, Table Alignment
</p></div>
    </summary>
    <updated>2021-03-15T22:42:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-03-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2103.06931</id>
    <link href="http://arxiv.org/abs/2103.06931" rel="alternate" type="text/html"/>
    <title>After 100 Years, Can We Finally Crack Post's Problem of Tag? A Story of Computational Irreducibility, and More</title>
    <feedworld_mtime>1615766400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolfram:Stephen.html">Stephen Wolfram</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2103.06931">PDF</a><br/><b>Abstract: </b>Empirical, theoretical and historical aspects of Post's "problem of tag" from
1921 are explored. Evidence of strong computational irreducibility is found.
Despite their deterministic origin, the lengths of successive sequences
generated seem to closely approximate random walks. All 10^25 smallest initial
conditions are found to eventually halt, although sometimes in &gt; 6*10^11 steps.
Implications of the Principle of Computational Equivalence are discussed, along
with examples of identifiable computational capabilities of tag systems.
Various minimal examples of complex behavior are found, including a less-biased
analog of the 3n+1 Collatz problem. There is also discussion of the history of
Emil Post and of tag systems in the context of ideas about the foundations of
mathematics and computation.
</p></div>
    </summary>
    <updated>2021-03-15T22:37:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-03-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2103.06916</id>
    <link href="http://arxiv.org/abs/2103.06916" rel="alternate" type="text/html"/>
    <title>Polygon-Universal Graphs</title>
    <feedworld_mtime>1615766400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ophelders:Tim.html">Tim Ophelders</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rutter:Ignaz.html">Ignaz Rutter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Speckmann:Bettina.html">Bettina Speckmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Verbeek:Kevin.html">Kevin Verbeek</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2103.06916">PDF</a><br/><b>Abstract: </b>We study a fundamental question from graph drawing: given a pair $(G,C)$ of a
graph $G$ and a cycle $C$ in $G$ together with a simple polygon $P$, is there a
straight-line drawing of $G$ inside $P$ which maps $C$ to $P$? We say that such
a drawing of $(G,C)$ respects $P$. We fully characterize those instances
$(G,C)$ which are polygon-universal, that is, they have a drawing that respects
$P$ for any simple (not necessarily convex) polygon $P$. Specifically, we
identify two necessary conditions for an instance to be polygon-universal. Both
conditions are based purely on graph and cycle distances and are easy to check.
We show that these two conditions are also sufficient. Furthermore, if an
instance $(G,C)$ is planar, that is, if there exists a planar drawing of $G$
with $C$ on the outer face, we show that the same conditions guarantee for
every simple polygon $P$ the existence of a planar drawing of $(G,C)$ that
respects $P$. If $(G,C)$ is polygon-universal, then our proofs directly imply a
linear-time algorithm to construct a drawing that respects a given polygon $P$.
</p></div>
    </summary>
    <updated>2021-03-15T22:48:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-03-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2103.06914</id>
    <link href="http://arxiv.org/abs/2103.06914" rel="alternate" type="text/html"/>
    <title>Classifying Complexity with the ZX-Calculus: Jones Polynomials and Potts Partition Functions</title>
    <feedworld_mtime>1615766400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Alex Townsend-Teague, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meichanetzidis:Konstantinos.html">Konstantinos Meichanetzidis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2103.06914">PDF</a><br/><b>Abstract: </b>The ZX-calculus is a graphical language which allows for reasoning about
suitably represented tensor networks - namely ZX-diagrams - in terms of rewrite
rules. Here, we focus on problems which amount to exactly computing a scalar
encoded as a closed tensor network. In general, such problems are #P-hard.
However, there are families of such problems which are known to be in P when
the dimension is below a certain value. By expressing problem instances from
these families as ZX-diagrams, we see that the easy instances belong to the
stabilizer fragment of the ZX-calculus. Building on previous work on efficient
simplification of qubit stabilizer diagrams, we present simplifying rewrites
for the case of qutrits, which are of independent interest in the field of
quantum circuit optimisation. Finally, we look at the specific examples of
evaluating the Jones polynomial and of counting graph-colourings. Our
exposition further champions the ZX-calculus as a suitable and unifying
language for studying the complexity of a broad range of classical and quantum
problems.
</p></div>
    </summary>
    <updated>2021-03-15T22:38:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-03-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/037</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/037" rel="alternate" type="text/html"/>
    <title>TR21-037 |  Separating ABPs and Some Structured Formulas in the Non-Commutative Setting | 

	Prerona Chatterjee</title>
    <summary>The motivating question for this work is a long standing open problem, posed by Nisan (1991), regarding the relative powers of algebraic branching programs (ABPs) and formulas in the non-commutative setting. Even though the general question continues to remain open, we make some progress towards its resolution. To that effect, we generalise the notion of ordered polynomials in the non-commutative setting (defined by Hrubes, Wigderson and Yehudayoff (2011)) to define abecedarian polynomials and models that naturally compute them.
		
Our main contribution is a possible new approach towards separating formulas and ABPs in the non-commutative setting, via lower bounds against abecedarian formulas. In particular, we show the following.
	
There is an explicit $n$-variate degree $d$ abecedarian polynomial $f_{n,d}(x)$ such that 
1. $f_{n, d}(x)$ can be computed by an abecedarian ABP of size O(nd);
2. any abecedarian formula computing $f_{n, \log n}(x)$ must have size that is super-polynomial in $n$.

We also show that a  super-polynomial lower bound against abecedarian formulas for $f_{\log n, n}(x)$ would separate the powers of formulas and ABPs in the non-commutative setting.</summary>
    <updated>2021-03-14T17:44:44Z</updated>
    <published>2021-03-14T17:44:44Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-03-16T00:20:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/036</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/036" rel="alternate" type="text/html"/>
    <title>TR21-036 |  Ideal-theoretic Explanation of Capacity-achieving Decoding | 

	Mrinal Kumar, 

	Madhu Sudan, 

	Siddharth Bhandari, 

	Prahladh Harsha</title>
    <summary>In this work, we present an abstract framework for some algebraic error-correcting codes with the aim of capturing codes that are list-decodable to capacity, along with their decoding algorithm. In the polynomial ideal framework, a code is specified by some ideals in a polynomial ring, messages are polynomials and their encoding is the residue modulo the ideals. We present an alternate way of viewing this class of codes in terms of linear operators, and show that this alternate view makes their algorithmic list-decodability amenable to analysis.

Our framework leads to a new class of codes that we call {\em affine Folded Reed-Solomon codes} (which are themselves a special case of the broader class we explore). These codes are common generalizations of the well-studied Folded Reed-Solomon codes and Multiplicity codes, while also capturing the less-studied Additive Folded Reed-Solomon codes as well as a large family of codes that were not previously known/studied. 

More significantly our framework also captures the algorithmic list-decodability of the constituent codes. Specifically, we present a unified view of the decoding algorithm for ideal-theoretic codes and show that the decodability reduces to the analysis of the distance of some related codes. We show that good bounds on this distance lead to capacity-achieving performance of the underlying code, providing a unifying explanation of known capacity-achieving results. In the specific case of affine Folded Reed-Solomon codes, our framework shows that they are list-decodable up to capacity (for appropriate setting of the parameters), thereby unifying the previous results for Folded Reed-Solomon, Multiplicity and Additive Folded Reed-Solomon codes.</summary>
    <updated>2021-03-14T17:42:17Z</updated>
    <published>2021-03-14T17:42:17Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-03-16T00:20:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5683</id>
    <link href="https://adamsheffer.wordpress.com/2021/03/13/the-2021-polymath-jr-program/" rel="alternate" type="text/html"/>
    <title>The 2021 Polymath Jr Program</title>
    <summary>Summer Opportunity: Polymath Jr Research Experience for Undergraduates. The goal of this remote program is to provide opportunities to undergraduates who wish to explore research mathematics. The program consists of research projects on a wide variety of mathematical topics. Each project is guided by an active researcher with experience in undergraduate mentoring. All undergraduates who […]</summary>
    <updated>2021-03-13T18:45:03Z</updated>
    <published>2021-03-13T18:45:03Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2021-03-16T00:21:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=18306</id>
    <link href="https://rjlipton.wordpress.com/2021/03/13/hilberts-tenth-again/" rel="alternate" type="text/html"/>
    <title>Hilbert’s Tenth Again</title>
    <summary>I think it’s never too late to start anything, except maybe being a ballerina. — Wendy Liebman Mujeres Con Ciencia source Marta Sved was a Hungarian mathematician who in 1930 moved to Down Under and became a teacher of math at the University of Adelaide. Over fifty years later, in 1985, Sved got a PhD. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>I think it’s never too late to start anything, except maybe being a ballerina. — Wendy Liebman</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2021/03/13/hilberts-tenth-again/ms/" rel="attachment wp-att-18308"><img alt="" class="alignright wp-image-18308" height="160" src="https://rjlipton.files.wordpress.com/2021/03/ms.png?w=180&amp;h=160" width="180"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Mujeres Con Ciencia <a href="https://twitter.com/mujerconciencia/status/1257679058084728833">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Marta Sved was a Hungarian mathematician who in 1930 moved to Down Under and became a teacher of math at the University of Adelaide. Over fifty years later, in 1985, Sved got a PhD. Clearly Liebman’s quote applies to Sved’s pursuit of a PhD. </p>
<p>
Today I cannot resist talking about a particular <a href="https://web.archive.org/web/20160304191325/http://www.maa.org/sites/default/files/Sved50816668.pdf">paper</a> of hers in the Mathematics Magazine—Volume 63 Number 1, February 1990: </p>
<p><a href="https://rjlipton.wordpress.com/2021/03/13/hilberts-tenth-again/mm/" rel="attachment wp-att-18312"><img alt="" class="aligncenter  wp-image-18312" src="https://rjlipton.files.wordpress.com/2021/03/mm.png?w=200" width="200"/></a><br/>
<span id="more-18306"/></p>
<p>
Mathematics Magazine is a reviewed journal that focuses on exposition, history, and connections to other parts of math. I am a longtime reader of this journal. I have been getting this and other similar math mag’s for years. I am sure I saw this paper and the theorem. I did not see any reason to be overly excited by the result. However, the theorem plays a critical role in solving a long time open problem.</p>
<p>
Note, this paper did not make the cover, but I believe it should have. To see why we must look at the famous Hilbert Tenth Problem. </p>
<p/><h2> Hilbert’s Tenth </h2><p/>
<p>
Recall this is the problem: Given a polynomial equation 	</p>
<p align="center"><img alt="\displaystyle  P(x_1,x_2,x_3,\dots) = 0 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P%28x_1%2Cx_2%2Cx_3%2C%5Cdots%29+%3D+0+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>over the integers, decide if there is a solution over the integers. This was famously proved to be <a href="https://en.wikipedia.org/wiki/Hilbert%27s_tenth_problem">undecidable</a> by the combined work of Martin Davis, Hilary Putnam, and Julia Robinson, and was completed by Yuri Matiyasevich in 1970. </p>
<p>
Davis, Putnam, and Robinson proved this first for exponential equations—they allowed <img alt="{x^y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Ey%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Later, Matiyasevich showed how to express exponentiation in by polynomials—this completed the proof. </p>
<p>
Solving a famous open problem only increases our interest in related questions. One class of questions involved replacing the integers by other rings. One of the major questions is what happens if we ask for solutions to </p>
<p align="center"><img alt="\displaystyle  P(x_1,x_2,x_3,\dots) = 0 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P%28x_1%2Cx_2%2Cx_3%2C%5Cdots%29+%3D+0+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>over the rationals? This is currently open—see our <a href="https://rjlipton.wordpress.com/2010/08/07/hilberts-tenth-over-the-rationals/">posted</a> on this and two <a href="https://rjlipton.wordpress.com/2011/07/19/hilberts-10-5th-problem/">related</a> <a href="https://rjlipton.wordpress.com/2019/06/19/diophantine-equations/">ones</a>, plus a topical <a href="https://math.mit.edu/~poonen/papers/subrings.pdf">paper</a> by Bjorn Poonen, for some comments. </p>
<p/><h2> Hilbert Tenth Over Rationals </h2><p/>
<p>
Following the history of the classic version of Hilbert’s Tenth, Mihai Prunescu proved: </p>
<blockquote><p><b>Theorem 1</b> <em> It is undecidable to determine whether an exponential equation in many variables is solvable over the rationals. </em>
</p></blockquote>
<p>
This just appeared as <a href="https://www.cambridge.org/core/journals/journal-of-symbolic-logic/issue/E4FD92AFC9B9DE3E9855EEAFAF14A924"> The Exponential Diophantine Problem For Rationals</a> in the current issue of the JSL: </p>
<p>
<a href="https://rjlipton.wordpress.com/2021/03/13/hilberts-tenth-again/jsl/" rel="attachment wp-att-18309"><img alt="" class="aligncenter  wp-image-18309" src="https://rjlipton.files.wordpress.com/2021/03/jsl.jpg?w=200" width="200"/></a></p>
<p>
It is a short paper—two pages. The key is it shows that it is possible to define the integers by an exponential equation over the rationals. Is there a Matiyasevich out there who will remove the need for exponentials? </p>
<p/><h2> Using Exponentials over the Rationals </h2><p/>
<p>
Prunescu uses the following equation: 	</p>
<p align="center"><img alt="\displaystyle  x^y = y^x. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5Ey+%3D+y%5Ex.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>The solutions of this equation form a single parameterized family, and allow one to achieve the needed task:</p>
<blockquote><p><b> </b> <em> <i>Define the natural numbers from the rational solutions to this equation.</i> </em>
</p></blockquote>
<blockquote><p><b>Lemma 2</b> <em> Suppose that <img alt="{0 &lt; x &lt; y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%3C+x+%3C+y%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> are rationals so that <img alt="{x^y = y^x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Ey+%3D+y%5Ex%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Then for some integer <img alt="{n&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3E0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> 	</em></p><em>
<p align="center"><img alt="\displaystyle  x = (1+1/n)^n \text{ and } y = (1+1/n)^{n+1}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+%281%2B1%2Fn%29%5En+%5Ctext%7B+and+%7D+y+%3D+%281%2B1%2Fn%29%5E%7Bn%2B1%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</em><p><em>Moreover, every <img alt="{n&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3E0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> arises this way. </em>
</p></blockquote>
<p>
His proof outline is to suppose that <img alt="{x^y = y^x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Ey+%3D+y%5Ex%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for rationals <img alt="{0 &lt; x &lt; y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%3C+x+%3C+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Then by the lemma we can recover the <i>integer</i> <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> using only addition and multiplication. 	</p>
<p align="center"><img alt="\displaystyle  y/x = 1 + 1/n, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y%2Fx+%3D+1+%2B+1%2Fn%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>for some <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Thus, 	</p>
<p align="center"><img alt="\displaystyle  n = \frac{x}{y-x}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++n+%3D+%5Cfrac%7Bx%7D%7By-x%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>This is an amazing trick—in my opinion. </p>
<p>
Prunescu deserves a tip-of-the-hat for this insight. At the high level he is using this: Suppose that <img alt="{x,y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> rationals satisfy an equation 	</p>
<p align="center"><img alt="\displaystyle  f(x,y) = 0. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28x%2Cy%29+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>Then there is a rational operation on <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that recovers a unique integer <img alt="{n&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Moreover, for any <img alt="{n&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> there are rational solutions <img alt="{x,y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that yield <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. This allows him to prove that exponential equations over the rationals is undecidable. </p>
<p/><h2> The Lemma </h2><p/>
<p>
Prunescu needs the above lemma. He does not prove it, but says: </p>
<blockquote><p><b> </b> <em> The equation <img alt="{x^y = y^x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Ey+%3D+y%5Ex%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> for rationals was studied by Christian Goldbach and Leonhard Euler—as stated in Leonhard Dickson’s <a href="https://www.amazon.com/History-Theory-Numbers-Vol-Diophantine/dp/0821819356">book</a>. </em>
</p></blockquote>
<p>
The results had been available for a long time—the book was published over a hundred years ago in 1920.</p>
<p>
It is interesting to ask why it took so long to realize the connection? I looked at Dickson’s book and found the reference not so clean. I then did a Google search for results on the equation: 	</p>
<p align="center"><img alt="\displaystyle  x^y = y^x. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5Ey+%3D+y%5Ex.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>The search found that Sved proved in the <a href="https://web.archive.org/web/20160304191325/http://www.maa.org/sites/default/files/Sved50816668.pdf">paper</a> in the Mathematics Magazine—Volume 63 Number 1, February 1990 the following: </p>
<blockquote><p><b>Lemma 3</b> <em> Suppose that <img alt="{0 &lt; x &lt; y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%3C+x+%3C+y%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> are rationals so that <img alt="{x^y = y^x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Ey+%3D+y%5Ex%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Then for some integer <img alt="{n&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3E0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> 	</em></p><em>
<p align="center"><img alt="\displaystyle  x = (1+1/n)^n \text{ and } y = (1+1/n)^{n+1}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+%281%2B1%2Fn%29%5En+%5Ctext%7B+and+%7D+y+%3D+%281%2B1%2Fn%29%5E%7Bn%2B1%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</em><p><em>Moreover, every <img alt="{n&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3E0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> arises this way. </em>
</p></blockquote>
<p>
That is, Sved proved the key lemma in full detail in 1990. Thus over thirty years ago, in an available journal, the exact lemma needed was available. </p>
<blockquote><p><b> </b> <em> Why did so all of us miss that Sved’s analysis of the equation <img alt="{x^y=y^x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Ey%3Dy%5Ex%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> could be used to solve an open problem. One that was open for decades? </em>
</p></blockquote>
<p>
Perhaps it says that Prunescu’s insight was indeed surprising. Perhaps. It does raise questions about improving his theorem. For example: Can a similar theorem be proved with only exponentials of the form 	</p>
<p align="center"><img alt="\displaystyle  2^x, 3^x, \dots? " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++2%5Ex%2C+3%5Ex%2C+%5Cdots%3F+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>This would improve the undecidability theorem a bit.</p>
<p/><h2> Open Problems </h2><p/>
<p>
Perhaps we also should look at results from not top “professional” journals. Hmmm I think I will start looking at them with a new eye. How about you?</p>
<p>
Perhaps we also should look at results from not top “professional” journals. Hmmm I think I will start looking at them with a new eye. How about you?</p>
<p>
[some layout improvements]</p></font></font></div>
    </content>
    <updated>2021-03-13T13:47:40Z</updated>
    <published>2021-03-13T13:47:40Z</published>
    <category term="History"/>
    <category term="News"/>
    <category term="Oldies"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Diophantine"/>
    <category term="exponential arrows"/>
    <category term="Hilbert Tenth"/>
    <category term="open"/>
    <category term="trick"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2021-03-16T00:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/035</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/035" rel="alternate" type="text/html"/>
    <title>TR21-035 |  Amortized Circuit Complexity, Formal Complexity Measures, and Catalytic Algorithms | 

	Robert Robere, 

	Jeroen Zuiddam</title>
    <summary>We study the amortized circuit complexity of boolean functions.
	
Given a circuit model $\mathcal{F}$ and a boolean function $f : \{0,1\}^n \rightarrow \{0,1\}$, the $\mathcal{F}$-amortized circuit complexity is defined to be the size of the smallest circuit that outputs $m$ copies of $f$ (evaluated on the same input), divided by $m$, as $m \rightarrow \infty$. We prove a general duality theorem that characterizes the amortized circuit complexity in terms of "formal complexity measures". More precisely, we prove that the amortized circuit complexity in any circuit model composed out of gates from a finite set is equal to the pointwise maximum of the family of "formal complexity measures" associated with $\mathcal{F}$. Our duality theorem captures many of the formal complexity measures that have been previously studied in the literature for proving lower bounds (such as formula complexity measures, submodular complexity measures, and branching program complexity measures), and thus gives a characterization of formal complexity measures in terms of circuit complexity. We also introduce and investigate a related notion of catalytic circuit complexity, which we show is "intermediate" between amortized circuit complexity and standard circuit complexity, and which we also characterize (now, as the best integer solution to a linear program). 

Finally, using our new duality theorem as a guide, we strengthen the known upper bounds for non-uniform catalytic space, introduced by Buhrman et. al (this is related to, but not the same as, as our notion of catalytic circuit size). Potechin proved that for any boolean function $f:\{0,1\}^n \rightarrow \{0,1\}$, there is a catalytic branching program computing $m = 2^{2^n}-1$ copies of $f$ with total size $O(mn)$ --- that is, linear size per copy --- refuting a conjecture of Girard, Koucky and McKenzie. Potechin then asked if the number of copies $m$ can be reduced while retaining the amortized upper bound. We show that the answer is yes: if $f$ has degree $d$ when represented as polynomial over $\mathbb{F}_2$, then there is a catalytic branching program computing $m = 2^{n \choose \leq d}$ copies of $f$ with total size $O(mn)$.</summary>
    <updated>2021-03-13T02:04:24Z</updated>
    <published>2021-03-13T02:04:24Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-03-16T00:20:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2021/03/13/quarterly-theory-workshop-algorithms-and-their-social-impact/</id>
    <link href="https://cstheory-events.org/2021/03/13/quarterly-theory-workshop-algorithms-and-their-social-impact/" rel="alternate" type="text/html"/>
    <title>Quarterly Theory Workshop: Algorithms and their Social Impact</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">March 19, 2021 Virtual (on Gather.town and Zoom) https://theory.cs.northwestern.edu/events/quarterly-theory-workshop-algorithms-and-their-social-impact/ The focus of this workshop will be on the societal impacts of algorithms. From designing self-driving cars to selecting the order of news posts on Facebook to automating credit checks, the use of algorithms for decision making is now commonplace. Hence it is more important than … <a class="more-link" href="https://cstheory-events.org/2021/03/13/quarterly-theory-workshop-algorithms-and-their-social-impact/">Continue reading <span class="screen-reader-text">Quarterly Theory Workshop: Algorithms and their Social Impact</span></a></div>
    </summary>
    <updated>2021-03-13T01:36:26Z</updated>
    <published>2021-03-13T01:36:26Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2021-03-16T00:21:46Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-9044150569954177517</id>
    <link href="https://blog.computationalcomplexity.org/feeds/9044150569954177517/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/03/cake-cutting-in-overtime.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9044150569954177517" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9044150569954177517" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/03/cake-cutting-in-overtime.html" rel="alternate" type="text/html"/>
    <title>Cake Cutting in Overtime</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>There's a new <a href="https://www.foxsports.com/stories/nfl/baltimore-ravens-coach-john-harbaugh-overtime-rule">proposal out of Baltimore</a> for a new way to handle overtime in National Football League games. This post is about American Football, soccer has its own overtime issues we won't talk about here.</p><p>Instead of randomly choosing who gets the ball, which gives an advantage to the team on offense, the Raven's coach John Harbaugh suggests a "spot and choose" rule based on cake cutting. One team picks a starting position and the other team decides whether to be on offense or defense.</p><p>Sounds intriguing but there's a problem. In cake cutting, if you cut off a crumb, everyone would definitely choose the rest of the cake. But in football suppose the spotting team chose the offensive's team one-yard line (99 yards needed for a touchdown). For spot and choose to work the one-yard line would have to be an obvious choice for defense. But many teams might still choose starting at the one-year line on offense. There's a chance you can march down the field and if not you can always punt it away. So the team that gets to choose whether to be on offense could get an advantage no matter what the spotting team did.</p><p>I still like the idea of "spot and choose". Maybe you let the first team choose not only the yard line but what down to start. Because no one would start at their one yard line at 4th down.</p><p>Are there variations for spot and choose in other sports? I like using game theory to figure out how to play actual games. </p></div>
    </content>
    <updated>2021-03-12T15:12:00Z</updated>
    <published>2021-03-12T15:12:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-03-15T19:57:14Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2021/03/12/beyondlogconcave3/</id>
    <link href="http://offconvex.github.io/2021/03/12/beyondlogconcave3/" rel="alternate" type="text/html"/>
    <title>Beyond log-concave sampling (Part 3)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In the <a href="http://www.offconvex.org/2020/09/19/beyondlogconvavesampling">first post</a> of this series, we introduced the challenges of sampling distributions beyond log-concavity. In <a href="http://www.offconvex.org/2021/03/01/beyondlogconcave2/">Part 2</a> we tackled sampling from <em>multimodal</em> distributions: a typical obstacle occuring in problems involving statistical inference and posterior sampling in generative models. In this (final) post of the series, we consider sampling in the presence of <em>manifold structure in the level sets of the distribution</em> – which also frequently manifests in the same settings. It will cover the paper <a href="https://arxiv.org/abs/2002.05576">Fast convergence for Langevin diffusion with matrix manifold structure</a> by Ankur Moitra and Andrej Risteski .</p>

<h1 id="sampling-with-matrix-manifold-structure">Sampling with matrix manifold structure</h1>

<p>The structure on the distribution we consider in this post is <em>manifolds</em> of equiprobable points: this is natural, for instance, in the presence of invariances in data (e.g. rotations of images). It can also appear in neural-network based probabilistic models due to natural invariances they encode (e.g., scaling invariances in ReLU-based networks).</p>

<center>
<img src="http://www.andrew.cmu.edu/user/aristesk/manifold.jpg" width="400"/>
</center>

<!--[HL: would it be better to start with the decomposition theorem, to parallel the first section?]
[AR: let me try this first, we can reorganize. I think this is better to motivate the assumption somewhat]-->

<p>At the level of techniques, the starting point for our results is a close connection between the geometry, more precisely <em>Ricci curvature</em> of a manifold, and the mixing time of Brownian motion on a manifold. The following theorem holds:</p>

<blockquote>
  <p><strong>Theorem (Bakry and Émery ‘85, informal)</strong>: If the manifold $M$ has  positive Ricci curvature, Brownian motion on the manifold mixes rapidly in $\chi^2$ divergence.</p>
</blockquote>

<p>We will explain the notions from differential geometry shortly, but first we sketch our results, and how they use this machinery. We present two results: the first is a “meta”-theorem that provides a generic decomposition framework, and the second is an instantiation of this framework for a natural family of problems that exhibit manifold structure: posteriors for matrix factorization, sensing, and completion. 
<!--a sampling version of matrix factorization--></p>

<h2 id="a-general-manifold-decomposition-framework">A general manifold decomposition framework</h2>

<p>Our first result is a general decomposition framework for analyzing mixing time of Langevin in the presence of manifolds of equiprobable points.</p>

<p>To motivate the result, note that if we consider the distribution $p_{\beta}(x) \propto e^{-\beta f(x)}$, for large (but finite) $\beta$, the Langevin chain corresponding to that distribution, started close to a manifold of local minima, will tend to stay close to (but not on!) it for a long time. See the figure below for an illustration. This, we will state a “robust” version of the above manifold result, for a chain that’s allowed to go off the manifold.</p>

<center>
<img src="http://www.andrew.cmu.edu/user/aristesk/single_manifold.gif" width="300"/>
</center>

<p>We show the following statement. (Recall that a bounded Poincaré constant corresponds to rapid mixing for Langevin. See the <a href="http://www.offconvex.org/2020/09/19/beyondlogconvavesampling">first post</a> for a refresher.)</p>

<blockquote>
  <p><strong>Theorem 1 (Moitra and Risteski ‘20, informal)</strong>: 
Suppose the Langevin chain corresponding to $p(x) \propto e^{-f(x)}$ is initialized close to a manifold $M$ satisfying the following two properties: 
<br/><br/>
(1) It stays in some neighborhood $D$ of the manifold $M$ with large probability for a long time. 
<br/><br/>
(2) $D$ can be partitioned into manifolds $M^{\Delta}$ satisfying: 
<br/><br/>
(2.1) The conditional distribution of $p$ restricted to $M^{\Delta}$ has a upper bounded Poincare constant. 
<br/><br/>
(2.2) The marginal distribution over $\Delta$ has a upper bounded Poincare constant. 
<br/><br/>
(2.3) The conditional probability distribution over $M^{\Delta}$ does not “change too quickly” as $\Delta$ changes.
<br/><br/>
Then Langevin mixes quickly to a distribution close to the conditional distribution of $p$ restricted to $D$.</p>
</blockquote>

<center>
<img src="http://www.andrew.cmu.edu/user/aristesk/partition_illustration.gif"/>
</center>

<p>While the above theorem is a bit of a mouthful (even very informally stated) and requires a choice of partitioning of $D$ to be “instantiated”, it’s quite natural to think of it as an analogue of local convergence results for gradient descent in optimization. Namely, it gives geometric conditions under which Langevin started near a manifold mixes to the “local” stationary distribution (i.e. the conditional distribution $p$ restricted to $D$).</p>

<p>The proof of the theorem uses similar decomposition ideas as result on sampling multimodal distributions from the <a href="http://www.offconvex.org/2021/03/01/beyondlogconcave2/">previous post</a>, albeit is complicated by measure theoretic arguments. Namely, the manifolds $M^{\Delta}$ have technically zero measure under the distribution $p$, so care must be taken with how the “projected” and “restricted” chain are defined—the key tool for this is the so-called <a href="https://en.wikipedia.org/wiki/Smooth_coarea_formula#:~:text=In%20Riemannian%20geometry%2C%20the%20smooth,with%20integrals%20over%20their%20codomains.&amp;text=%2C%20i.e.%20the%20determinant%20of%20the,orthogonal%20complement%20of%20its%20kernel.">co-area formula</a>.</p>

<p>The challenge in using the above framework is instantiating the decomposition: namely, the choice of the partition of $D$ into manifolds $M^{\Delta}$. In the next section, we show how this can be done for posteriors in problems like matrix factorization/sensing/completion.</p>

<h2 id="matrix-factorization-and-relatives">Matrix factorization (and relatives)</h2>

<p>To instantiate the above framework in a natural setting, we consider distributions exhibiting invariance under orthogonal transformations. Namely, we consider distributions of the type</p>

\[p: \mathbb{R}^{d \times k} \to \mathbb{R}, \hspace{0.5cm} p(X) \propto e^{-\beta \| \mathcal{A}(XX^T) - b \|^2_2}\]

<p>where $b \in \mathbb{R}^{m}$ is a fixed vector and $\mathcal{A}$ is an operator that returns a $m$-dimensional vector given a $d \times d$ matrix. For this distribution, we have $p(X) = p(XO)$ for any orthogonal matrix $O$, since $XX^T = XO (XO)^T$ . Depending on the choice of $\mathcal{A}$, we can easily recover some familiar functions inside the exponential: e.g. the $l_2$ losses for (low-rank) matrix factorization, matrix sensing and matrix completion. These losses received a lot of attention as simple examples of objectives that are non-convex but can still be optimized using gradient descent. (See e.g. <a href="https://arxiv.org/abs/1704.00708">Ge et al. ‘17</a>.)</p>

<p>These distributions also have a very natural statistical motivation. Namely, consider the distribution over $m$-dimensional vectors, such that</p>

\[b = \mathcal{A}(XX^T) + n, \hspace{0.5cm} n \sim N\left(0,\frac{1}{\sqrt{\beta}}I\right).\]

<p>Then, the distribution $p(X) \propto e^{-\beta  | \mathcal{A}(XX^T) - b |^2_2 }$ can be viewed as the posterior distribution over $X$ with a uniform prior. Thus, sampling from these distributions can be seen as the distributional analogue of problems like matrix factorization/sensing/completion, the difference being that we are not merely trying to find the <em>most likely</em> matrix $X$, but also trying to sample from the posterior.</p>

<p>We will consider the case when $\beta$ is sufficiently large (in particular, $\beta = \Omega(\mbox{poly}(d))$: in this case, the distribution $p$ will concentrate over two (separated) manifolds: $E_1 = \{X_0 R: R \mbox{ is orthogonal with det 1}\}$ and $E_2 = \{X_0 R: R \mbox{ is orthogonal with det }-1\}$, where $X_0$ is any fixed minimizer of $| \mathcal{A}(XX^T) - b |^2_2$. Hence, when started near one of these manifolds, we expect Langevin to stay close to it for a long time (see figure below).</p>

<center>
<img src="http://www.andrew.cmu.edu/user/aristesk/langevin_matrix.gif" width="500"/>
</center>

<p>We show:</p>

<blockquote>
  <p><strong>Theorem 2 (Moitra and Risteski ‘20, informal)</strong>: Let $\mathcal{A}$ correspond to matrix factorization, sensing or completion under standard parameter assumptions for these problems. Let $\beta = \Omega(\mbox{poly}(d))$. 
If initialized close to one of $E_i, i \in \{1, 2\}$, after a polynomial number of steps the discretized Langevin dynamics will converge to a distribution that is close in total variation distance
to p(X) when restricted to a neighborhood of $E_i$.</p>
</blockquote>

<!--Let $\beta=\Omega(\mbox{poly}(d), \log (1/\delta)⁡)$ and let $p^i(X) \propto p(𝑋)$, if $\|X −\Pi_{E_i}(𝑋)\|_2<\|X − \Pi_{E_{2−i}}(X)\|_2$ and $p^i (X)=0$ otherwise. 
Then, Langevin diffusion initialized $O(\sigma_{\min}(M)⁡/k)$ close to $E_i$ run for t steps samples from distribution $p_t$, s.t. 
$$ \chi^2(p_t, p^i ) \leq \delta + e^{−𝑡/C}, 𝐶=O\left(\frac{\beta}{(k \sigma_{\min}⁡(M))}\right) $$-->

<p>We remark that the closeness condition for the first step is easy to ensure using existing results on gradient-descent based optimization for these objectives. It’s also easy to use the above result to sample approximately from the distribution $p$ itself, rather than only the “local” distributions $p^i$ – this is due to the fact that the distribution $p$ looks like the “disjoint union” of the distributions $p^1$ and $p^2$.</p>

<p>Before we describe the main elements of the proof, we review some concepts from differential geometry.</p>

<h2 id="extremely-brief-intro-to-differential-geometry">(Extremely) brief intro to differential geometry</h2>

<p>We won’t do a full primer on differential geometry in this blog post, but we will briefly informally describe some of the relevant concepts. See Section 5 of <a href="https://arxiv.org/abs/2002.05576">our paper</a> for an intro to differential geometry (written with a computer science reader in mind, so more easy-going than a differential geometry textbook).</p>

<p>Recall, the <em>tangent</em> space at $x$, denoted by $T_x M$, is the set of all derivatives $v$ of a curve passing through $x$.<!-- the exponential map at a point $x$ in direction $v \in T_x M$, denoted by $\exp_x(v)$ is the movement of $x$ along the *geodesic* (i.e. shortest path curve) at $x$ for one unit of time (note this curve is unique). See the left part of the figure below.--><!-- To explain Ricci curvature, consider first the intuitive concept of curvature: Euclidean space has zero curvature, while the sphere has positive curvature because it "folds into itself." One way to capture this is by looking at the volume of a geodesic ball around a point: the sphere's positive curvature causes the volume to be *less* than the volume in Euclidean space. We can take this change in volume as the *definition* of curvature.--> The <em>Ricci curvature</em> at a point $x$, in direction $v \in T_x M$, denoted $\mbox{Ric}_x(v)$, captures the second-order term in the rate of change of volumes of sets in a small neighborhood around $x$, as the points in the set are moved along the geodesic (i.e. shortest path curve) in direction $v$ (or more precisely, each point $y$ in the set is moved along the geodesic in the direction of the parallel transport of $v$ at $y$; see the right part of the figure below from <a href="https://projecteuclid.org/euclid.aspm/1543086328">(Ollivier 2010)</a>). A Ricci curvature of $0$ preserves volumes (think: a plane), a Ricci curvature $&gt;0$ shrinks volume (think: a sphere), and a Ricci curvature $&lt;0$ expands volume (think: a hyperbola).</p>

<center>
<img src="http://www.andrew.cmu.edu/user/aristesk/tangent.jpg" width="800"/>
</center>

<!--Slightly more mathematically, it's relatively easy to understand the Ricci curvature when we have a parametrized manifold. The curvature of the manifold should be intuitively captured by the second-order behavior of the parametrization. Namely, consider a manifold parametrized locally as
$$\phi: T_x M \to T_x M \times N_x M, \phi(z) = x + (z, g(z))$$ 
where $N_xM$ is the *normal* space at $x$, the subspace orthogonal to $T_xM$. 
Then, the Hessian viewed as the quadratic form $\nabla^2 g: T_x M \times T_x M \to N_x M$ is called the *second fundamental form* and denoted as $\mathrm{I\!I}_x$. If $\{e_i\}$ is an orthonormal basis of $T_x M$, the Ricci curvature in a direction $v \in T_x M$ is then:
$$\mbox{Ric}(v) = \sum_i \langle \mathrm{I\!I}(u,u), \mathrm{I\!I}(e_i, e_i) \rangle - \|\mathrm{I\!I}(u,e_i)\|^2$$ 
-->

<p>The connections between curvature and mixing time of diffiusions is rather deep and we won’t attempt to convey it fully in a blog post - the definitive reference is <a href="https://link.springer.com/book/10.1007/978-3-319-00227-9">Analysis and Geometry of Markov Diffusion Operators</a> by Bakry, Gentil and Ledoux. The main idea is that mixing time can be bounded by how long it takes for random walks starting at different locations to “join together,” and positive curvature brings them together faster.
<!-- A small gesture towards these connections can be conveyed through a popular coupling for Brownian motion called a *reflection coupling*.--></p>

<p>To make this formal, we define a <em>coupling</em> of two random variables $X, Y$ to be any random variable $W = (X’,Y’)$ such that the marginal distribution of the coordinates $X’$ and $Y’$ are the same as the distributions of $X$ and $Y$. It’s well known that the convergence time of a random walk in total variation distance can be upper bounded by the expected time until two coupled copies of the walk join. On the plane, a canonical coupling (the <em>reflection coupling</em>) between two Brownian motions can be constructed by reflecting the move of the second process through the perpendicular bisector between the locations of the two processes (see figure below). On a positively curved manifold (like a sphere), an analogous reflection can be defined, and the curvature only brings the two processes closer faster.</p>

<center>
<img src="http://www.andrew.cmu.edu/user/aristesk/reflection.jpg" width="500"/>
</center>

<p>As a final tool, our proof uses a very important theorem due to <a href="https://www.sciencedirect.com/science/article/pii/S0001870876800023">Milnor</a> about manifolds with algebraic structure:</p>

<blockquote>
  <p><strong>Theorem (Milnor ‘76, informal)</strong>: The Ricci curvature of a Lie group equipped with a left-invariant metric is non-negative.</p>
</blockquote>

<p>In a pinch, a Lie group is a group that also is a smooth manifold, and furthermore, the group operations result in a smooth transformation on the manifold - so that the “geometry” and “algebra” combine together. A metric is left-invariant for the group if acting on the left by any group element leaves the metric “unchanged”.</p>

<h2 id="implementing-the-decomposition-framework">Implementing the decomposition framework</h2>

<p>To apply the framework we sketched out as part of Theorem 1, we need to verify the conditions of the Theorem.</p>

<p>To prove <strong>Condition 1</strong>, we need to show that for large $\beta$, the random walk stays near to the manifold it’s been initialized close to. The main tools for this are <a href="https://en.wikipedia.org/wiki/It%C3%B4%27s_lemma">Ito’s lemma</a>, local convexity of the function $| \mathcal{A}(XX^T) - b |_2^2$ and basic results in the theory of <a href="https://en.wikipedia.org/wiki/Cox%E2%80%93Ingersoll%E2%80%93Ross_model">Cox-Ingersoll-Ross</a> processes. Namely, Ito’s lemma (which can be viewed as a “change-of-variables” formula for random variables) allows us to write down a stochastic differential equation for the evolution of the distance of $X$ from the manifold, which turns out to have a “bias” towards small values, due to the local convexity of $| \mathcal{A}(XX^T) - b |_2^2$. This can in turn be analyzed approximately as Cox-Ingersoll-Ross process - a well-studied type of non-negative stochastic process.</p>

<p>To prove <strong>Condition 2</strong>, we need to specify the partition of the space around the manifolds $E_i$. Describing the full partition is somewhat technical, but importantly, the manifolds $M^{\Delta}$ have the form $M^{\Delta} = \{\Delta U: U \mbox{ is an orthogonal matrix with det 1}\}$ for some matrix $\Delta \in \mathbb{R}^{n \times k}$.</p>

<p>The proof that $M^{\Delta}$ has a good Poincare constant (i.e. Condition 2.1) relies on two ideas: first, $M^{\Delta}$ is a Lie group with group operation $\circ$ defined such that $(\Delta U)   \circ (\Delta V) := \Delta (UV)$, along with a corresponding left-invariant metric - thus, by Milnor’s theorem, it has a non-negative Ricci curvature; second, we can relate the Ricci curvatures with the Euclidean metric to the curvature with the left-invariant metric. The proof that the marginal distribution over $\Delta$ has a good Poincaré constant involves showing that this distribution is approximately log-concave. Finally, the “change-of-conditional-probability” condition (Condition 2.3) can be proved by explicit calculation.</p>

<h1 id="closing-remarks">Closing remarks</h1>

<p>In this series of posts, we surveyed two recent approaches to analyzing Langevin-like sampling algorithms <em>beyond log-concavity</em> - the most natural analogue to non-convexity in the world of sampling/inference. The structures we considered, <em>multi-modality</em> and <em>invariant manifolds</em>, are common in practice in modern machine learning.</p>

<p>Unlike non-convex optimization, provable guarantees for sampling beyond log-concavity is still under-studied and we hope our work will inspire and excite further efforts. For instance, how do we handle modes of different “shape”? Can we handle an exponential number of modes, if they have further structure (e.g., posteriors in concrete latent-variable models like Bayesian networks)? Can we handle more complex manifold structure (e.g. the matrix distributions we considered for <em>any</em> $\beta$)?</p></div>
    </summary>
    <updated>2021-03-12T14:00:00Z</updated>
    <published>2021-03-12T14:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2021-03-15T22:53:30Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/flavoursofdelta/</id>
    <link href="https://differentialprivacy.org/flavoursofdelta/" rel="alternate" type="text/html"/>
    <title>What is δ, and what δifference does it make?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>There are many variants or flavours of differential privacy (DP) some weaker than others: often, a given variant comes with own guarantees and “conversion theorems” to the others. As an example, “pure” DP has a single parameter \(\varepsilon\), and corresponds to a very stringent notion of DP:</p>

<blockquote>
  <p>An algorithm \(M\) is \(\varepsilon\)-DP if, for all neighbouring inputs \(D,D'\) and all measurable \(S\), \( \Pr[ M(D) \in S ] \leq e^\varepsilon\Pr[ M(D’) \in S ] \).</p>
</blockquote>

<p>By relaxing this a little, one obtains the standard definition of approximate DP, a.k.a. \((\varepsilon,\delta)\)-DP:</p>

<blockquote>
  <p>An algorithm \(M\) is \((\varepsilon,\delta)\)-DP if, for all neighbouring inputs \(D,D'\) and all measurable \(S\), \( \Pr[ M(D) \in S ] \leq e^\varepsilon\Pr[ M(D’) \in S ]+\delta \).</p>
</blockquote>

<p>This definition is very useful, as in many settings achieving the stronger \(\varepsilon\)-DP guarantee (i.e., \(\delta=0\)) is impossible, or comes at a very high utility cost. But how to interpret it? The above definition, on its face, doesn’t preclude what one may call “<em>catastrophic failures of privacy</em> 💥:” most of the time, things are great, but with some small probability \(\delta\) all hell breaks loose. For instance, the following algorithm is \((\varepsilon,\delta)\)-DP:</p>

<ul>
  <li>Get a sensitive database \(D\) of \(n\) records</li>
  <li>Select uniformly at random a fraction \(\delta\) of the database (\(\delta n\) records)</li>
  <li>Output that subset of records in the clear 💥</li>
</ul>

<p>(actually, this is even \((0,\delta)\)-DP!). This sounds preposterous, and obviously something that one would want to avoid in practice (lest one wants to face very angry customers or constituents). This is one of the rules of thumb for picking \(\delta\) small enough (or even “cryptographically small”), typically \(\delta \ll 1/n\), so that the records are safe (hard to disclose \(\delta n \ll 1\) records).</p>

<p>So: good privacy most of the time, but with probably \(\delta\) then all bets are off.</p>

<p>However, those catastrophic failure of privacy, while technically allowed by the definition of \((\varepsilon,\delta)\)-DP, <strong>are not something that can really happen with the DP algorithms and techniques used both in practice and in theoretical work.</strong> Before explaining why, let’s see what is the kind of desirable behaviour one would expect: a <em>“smooth, manageable tradeoff of privacy parameters.”</em> For that discussion, let’s introduce the <em>privacy loss random variable</em>: given an algorithm M and two neighbouring inputs D,D’, let \(f(y)\) be defined as
\[
	f(y) = \log\frac{\Pr[M(D)=y]}{\Pr[M(D’)=y]}
\]
for every possible output \(y\in\Omega\). Now, define the random variable \(Z := f(M(D))\) (implicitly, \(Z\) depends on \(D,D',M\)). This random variable quantifies how much observing the output of the algorithm \(M\) helps distinguishing between \(D\) and \(D'\).</p>

<p>Now, going a little bit fast, you can check that saying that \(M\) is \(\varepsilon\)-DP corresponds to the guarantee “<em>\(\Pr[Z &gt; \varepsilon] = 0\) for all neighbouring inputs \(D,D'\).</em>”
Similarly, \(M\) being \((\varepsilon,\delta)\)-DP is the guarantee \(\Pr[Z &gt; \varepsilon] \leq \delta\).\({}^{(\dagger)}\) For instance, the “catastrophic failure of privacy” corresponds to the scenario below, which depicts a possible distribution for \(Z\): \(Z\leq \varepsilon\) with probability \(1-\delta\), but then with probability \(\delta\) we have \(Z\gg 1\).</p>

<p><img alt="The type of (bad) distribution of Z corresponding to 'our catastrophic failure of privacy'" src="https://differentialprivacy.org/images/flavours-delta-fig1.png" style="margin: auto; display: block;" width="600"/></p>

<p>What we would like is a smoother thing, where even when \(Z&gt;\varepsilon\) is still remains reasonable and doesn’t immediately become large. A nice behaviour of the tails, ideally something like this:</p>

<p><img alt="A distribution for Z with nice tails, leading to smooth tradeoffs between &#x3B5; and &#x3B4;" src="https://differentialprivacy.org/images/flavours-delta-fig2.png" style="margin: auto; display: block;" width="600"/></p>

<p>For instance, if we had a bound on \(\mathbb{E}[|Z|]\), we could use Markov’s inequality to get, well, <em>something</em>. For instance, imagine we had \(\mathbb{E}[|Z|]\leq \varepsilon\delta\): then 
\[
	\Pr[ |Z| &gt; \varepsilon ] \leq \frac{\mathbb{E}[|Z|]}{\varepsilon }\leq \delta
\]
<em>(great! We have \((\varepsilon,\delta)\)-DP)</em>; but also  \(\Pr[ |Z| &gt; 10\varepsilon ] \leq \frac{\delta}{10}\). Privacy violations do not blow up out of proporxtion immediately, we can trade \(\varepsilon\) for \(\delta\). That seems like the type of behaviour we would like our algorithms to exhibit.</p>

<p><img alt="The type of privacy guarantees a Markov-type tail bound would give" src="https://differentialprivacy.org/images/flavours-delta-fig3.png" style="margin: auto; display: block;" width="600"/></p>

<p>But why stop at Markov’s inequality then, which gives some nice but still weak tail bounds? Why not ask for <em>stronger</em>: Chebyshev’s inequality? Subexponential tail bounds? Hell, <em>subgaussian</em> tail bounds? This is, basically, what some stronger notions of differential privacy than approximate DP give.</p>

<ul>
  <li>
    <p><strong>Rényi DP</strong> <a href="https://arxiv.org/abs/1702.07476" title="Ilya Mironov. Renyi Differential Privacy. CSF 2017"><strong>[Mironov17]</strong></a>, for instance, is a guarantee on the moment-generating function (MGF) of the privacy random variable \(Z\): it has two parameters, \(\alpha&gt;1\) and \(\tau\), and requires that \(\mathbb{E}[e^{(\alpha-1)Z}] \leq e^{(\alpha-1)\tau}\) for all neighbouring \(D,D'\). In turn, by applying for instance Markov’s inequality to the MGF of \(Z\), we can control the tail bounds, and get a nice, smooth tradeoff in terms of \((\varepsilon,\delta)\)-DP.</p>
  </li>
  <li>
    <p><strong>Concentrated DP</strong> (CDP)  <a href="https://arxiv.org/abs/1605.02065" title="Mark Bun and Thomas Steinke. Concentrated Differential Privacy: Simplifications, Extensions, and Lower Bounds. TCC 2016"><strong>[BS16]</strong></a> is an even stronger requirement, which roughly speaking requires the algorithm to be Rényi DP <em>simultaneously</em> for all \(1&lt; \alpha \leq \infty\). More simply, this is “morally” a requirement on the MGF of \(Z\) which asks it to be subgaussian.</p>
  </li>
</ul>

<p>The above two examples are not just fun but weird variants of DP: they actually capture the behaviour of many well-known differentially private algorithms, and in particular that of the Gaussian mechanism. While the guarantees they provide are less easy to state and interpret than \(\varepsilon\)-DP or \((\varepsilon,\delta)\)-DP, they are incredibly useful to analyze those algorithms, and enjoy very nice composition properties… and, of course, lead to that smooth tradeoff between \(\varepsilon\) and \(\delta\) for \((\varepsilon,\delta)\)-DP.</p>

<p><strong>To summarize:</strong></p>
<ul>
  <li>\(\varepsilon\)-DP gives great guarantees, but is a very stringent requirement. Corresponds to the privacy loss random variable supported on \([-\varepsilon,\varepsilon]\) (no tails!)</li>
  <li>\((\varepsilon,\delta)\)-DP gives guarantees easy to parse, but on its face allows for very bad behaviours. Corresponds to the privacy loss random variable in \([-\varepsilon,\varepsilon]\) with probability \(1-\delta\) (but outside, all bets are off!)</li>
  <li>Rényi DP and Concentrated DP correspond to something in between, controlling the tails of the privacy loss random variable by a guarantee on its MGF. A bit harder to interpret, but capture the behaviour of many DP building blocks can be converted to \((\varepsilon,\delta)\)-DP (with nice trade-offs between \(\varepsilon\) and \(\delta\).</li>
</ul>

<hr/>
<p>\({}^{(\dagger)}\) The astute reader may notice that this is not <em>quite</em> true. Namely, the guarantee \(\Pr[Z &gt; \varepsilon] \leq \delta\) on the privacy loss random variable (PLRV) does imply \((\varepsilon,\delta)\)-differential privacy, but the converse does not hold. See, for instance, Lemma 9 of <a href="https://arxiv.org/abs/2004.00010" title="Cl&#xE9;ment L. Canonne, Gautam Kamath, Thomas Steinke. The Discrete Gaussian for Differential Privacy. NeurIPS 2020"><strong>[CKS20]</strong></a> for an exact characterization of \((\varepsilon,\delta)\)-DP in terms of the PLRV.</p></div>
    </summary>
    <updated>2021-03-12T01:00:00Z</updated>
    <published>2021-03-12T01:00:00Z</published>
    <author>
      <name>Clément Canonne</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2021-03-15T22:54:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=535</id>
    <link href="https://tcsplus.wordpress.com/2021/03/11/tcs-talk-wednesday-march-17-avishay-tal-uc-berkeley/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, March 17 — Avishay Tal, UC Berkeley</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, March 17th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 18:00 Central European Time, 17:00 UTC). Avishay Tal from UC Berkeley will speak about “Junta Distance Approximation with Sub-Exponential Queries” (abstract below). You can reserve a spot as an individual or a group to […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, March 17th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 18:00 Central European Time, 17:00 UTC). <a href="http://www.avishaytal.org/"><strong>Avishay Tal</strong></a> from UC Berkeley will speak about “<em>Junta Distance Approximation with Sub-Exponential Queries</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The recorded talk will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our website</a> afterwards, so people who did not sign up will still be able to watch the talk.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: Joint Work with Vishnu Iyer and Michael Whitmeyer.</p>
<p>A Boolean function <img alt="f\colon \{0,1\}^n \to \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f%5Ccolon+%5C%7B0%2C1%5C%7D%5En+%5Cto+%5C%7B0%2C1%5C%7D&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> is called a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-junta if it depends only on <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> out of the <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> input bits. Junta testing is the task of distinguishing between <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-juntas and functions that are far from <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-juntas. A long line of work settled the query complexity of testing <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-juntas, which is <img alt="O(k log(k))" class="latex" src="https://s0.wp.com/latex.php?latex=O%28k+log%28k%29%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> [Blais, STOC 2009; Saglam, FOCS 2018]. Suppose, however, that <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> is not a perfect <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-junta but rather correlated with a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-junta. How well can we estimate this correlation? This question was asked by De, Mossel, and Neeman [FOCS 2019], who gave an algorithm for the task making <img alt="\sim\exp(k)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csim%5Cexp%28k%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> queries. We present an improved algorithm that makes <img alt="\sim\exp(\sqrt{k})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csim%5Cexp%28%5Csqrt%7Bk%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> many queries. Along the way, we also give an algorithm, making <img alt="\mathrm{poly}(k)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bpoly%7D%28k%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> queries, that provides “implicit oracle access” to the underlying <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-junta. Our techniques are Fourier analytical and introduce the notion of “normalized influences” that might be of independent interest.</p>
<p>Paper: <a href="https://eccc.weizmann.ac.il/report/2021/004/" rel="nofollow">https://eccc.weizmann.ac.il/report/2021/004/</a></p></blockquote></div>
    </content>
    <updated>2021-03-11T23:11:23Z</updated>
    <published>2021-03-11T23:11:23Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2021-03-16T00:21:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5382</id>
    <link href="https://www.scottaaronson.com/blog/?p=5382" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5382#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5382" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Long-delayed UT Austin Quantum Complexity Theory Student Project Showcase!</title>
    <summary xml:lang="en-US">Back at MIT, whenever I taught my graduate course on Quantum Complexity Theory (see here for lecture notes), I had a tradition of showcasing the student projects on this blog: see here (Fall 2010), here (Fall 2012), here (Fall 2014). I was incredibly proud that, each time I taught, at least some of the projects […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Back at MIT, whenever I taught my graduate course on Quantum Complexity Theory (<a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-845-quantum-complexity-theory-fall-2010/lecture-notes/">see here</a> for lecture notes), I had a tradition of showcasing the student projects on this blog: see <a href="https://www.scottaaronson.com/blog/?p=515">here (Fall 2010)</a>, <a href="https://www.scottaaronson.com/blog/?p=1181">here (Fall 2012)</a>, <a href="https://www.scottaaronson.com/blog/?p=2109">here (Fall 2014)</a>.  I was incredibly proud that, each time I taught, at least some of the projects led to publishable original research—sometimes highly significant research, like Paul Christiano’s work on quantum money (which led to my later <a href="https://arxiv.org/abs/1203.4740">paper with him</a>), Shelby Kimmel’s <a href="https://arxiv.org/abs/1101.0797">work</a> on quantum query complexity, Jenny Barry’s <a href="https://arxiv.org/abs/1406.2858">work</a> on quantum partially observable Markov decision processes (“QOMDPs”), or Matt Coudron and Henry Yuen’s work on randomness expansion (which led to their later <a href="https://arxiv.org/abs/1310.6755">breakthrough</a> in the subject).</p>



<p>Alas, after I moved to UT Austin, for some reason I discontinued the tradition of these blog-showcases—and inexcusably, I did this even though the wonderful new research results continued!  Now that I’m teaching Quantum Complexity Theory at UT for the third time (via Zoom, of course), I decided that it was finally time to remedy this.  To keep things manageable, this time I’m going to limit myself to research projects that began their lives in my course <em>and that are already public on the arXiv</em> (or in one case, that will soon be).</p>



<p>So please enjoy the following smorgasbord, from 2016 and 2019 iterations of my course!  And if you have any questions about any of the projects—well, I’ll try to get the students to answer in the comments section!  Thanks so much and congratulations to the students for their work.</p>



<h2>From the Fall 2016 iteration of the course</h2>



<p>William Hoza (project turned into a joint paper with Cole Graham), <strong><a href="https://arxiv.org/abs/1612.05680">Universal Bell Correlations Do Not Exist</a></strong>.</p>



<blockquote class="wp-block-quote"><p>We prove that there is no finite-alphabet nonlocal box that generates exactly those correlations that can be generated using a maximally entangled pair of qubits. More generally, we prove that if some finite-alphabet nonlocal box is strong enough to simulate arbitrary local projective measurements of a maximally entangled pair of qubits, then that nonlocal box cannot itself be simulated using any finite amount of entanglement. We also give a quantitative version of this theorem for approximate simulations, along with a corresponding upper bound.</p></blockquote>



<p>Patrick Rall, <strong><a href="https://arxiv.org/abs/1702.06990">Signed quantum weight enumerators characterize qubit magic state distillation</a></strong>.</p>



<blockquote class="wp-block-quote"><p>Many proposals for fault-tolerant quantum computation require injection of ‘magic states’ to achieve a universal set of operations. Some qubit states are above a threshold fidelity, allowing them to be converted into magic states via ‘magic state distillation’, a process based on stabilizer codes from quantum error correction.<br/>We define quantum weight enumerators that take into account the sign of the stabilizer operators. These enumerators completely describe the magic state distillation behavior when distilling T-type magic states. While it is straightforward to calculate them directly by counting exponentially many operator weights, it is also an NP-hard problem to compute them in general. This suggests that finding a family of distillation schemes with desired threshold properties is at least as hard as finding the weight distributions of a family of classical codes.<br/>Additionally, we develop search algorithms fast enough to analyze all useful 5 qubit codes and some 7 qubit codes, finding no codes that surpass the best known threshold.</p></blockquote>



<h2>From the Spring 2019 iteration of the course</h2>



<p>Ying-Hao Chen, <strong><a href="https://arxiv.org/abs/1909.03787">2-Local Hamiltonian with Low Complexity is QCMA-complete</a></strong>.</p>



<blockquote class="wp-block-quote"><p>We prove that 2-Local Hamiltonian (2-LH) with Low Complexity problem is QCMA-complete by combining the results from the QMA-completeness of 2-LH and QCMA-completeness of 3-LH with Low Complexity. The idea is straightforward. It has been known that 2-LH is QMA-complete. By putting a low complexity constraint on the input state, we make the problem QCMA. Finally, we use similar arguments as in [Kempe, Kitaev, Regev] to show that all QCMA problems can be reduced to our proposed problem.</p></blockquote>



<p>Jeremy Cook, <strong><a href="https://arxiv.org/abs/1907.11368">On the relationships between Z-, C-, and H-local unitaries</a></strong>.</p>



<blockquote class="wp-block-quote"><p>Quantum walk algorithms can speed up search of physical regions of space in both the discrete-time [<a href="https://arxiv.org/abs/quant-ph/0402107">arXiv:quant-ph/0402107</a>] and continuous-time setting [<a href="https://arxiv.org/abs/quant-ph/0306054">arXiv:quant-ph/0306054</a>], where the physical region of space being searched is modeled as a connected graph. In such a model, Aaronson and Ambainis [<a href="https://arxiv.org/abs/quant-ph/0303041">arXiv:quant-ph/0303041</a>] provide three different criteria for a unitary matrix to act locally with respect to a graph, called <em>Z</em>-local, <em>C</em>-local, and <em>H</em>-local unitaries, and left the open question of relating these three locality criteria. Using a correspondence between continuous- and discrete-time quantum walks by Childs [<a href="https://arxiv.org/abs/0810.0312">arXiv:0810.0312</a>], we provide a way to approximate <em>N</em>×<em>N H</em>-local unitaries with error <em>δ</em> using <em>O</em>(1/<em>√δ,√N</em>) <em>C</em>-local unitaries, where the comma denotes the maximum of the two terms.</p></blockquote>



<p>Joshua A. Cook, <strong><a href="https://arxiv.org/abs/1906.10495">Approximating Unitary Preparations of Orthogonal Black Box States</a></strong>.</p>



<blockquote class="wp-block-quote"><p>In this paper, I take a step toward answering the following question: for m different small circuits that compute m orthogonal n qubit states, is there a small circuit that will map m computational basis states to these m states without any input leaving any auxiliary bits changed. While this may seem simple, the constraint that auxiliary bits always be returned to 0 on any input (even ones besides the m we care about) led me to use sophisticated techniques. I give an approximation of such a unitary in the m = 2 case that has size polynomial in the approximation error, and the number of qubits n.</p></blockquote>



<p>Sabee Grewal (project turned into a joint paper with me), <strong><a href="https://arxiv.org/abs/2102.10458">Efficient Learning of Non-Interacting Fermion Distributions</a></strong>.</p>



<blockquote class="wp-block-quote"><p>We give an efficient classical algorithm that recovers the distribution of a non-interacting fermion state over the computational basis. For a system of <em>n</em> non-interacting fermions and <em>m</em> modes, we show that <em>O</em>(<em>m</em><sup>2</sup><em>n</em><sup>4</sup>log(<em>m</em>/<em>δ</em>)/<em>ε</em><sup>4</sup>) samples and <em>O</em>(<em>m</em><sup>4</sup><em>n</em><sup>4</sup>log(<em>m</em>/<em>δ</em>)/<em>ε</em><sup>4</sup>) time are sufficient to learn the original distribution to total variation distance <em>ε</em> with probability 1−<em>δ</em>. Our algorithm empirically estimates the one- and two-mode correlations and uses them to reconstruct a succinct description of the entire distribution efficiently.</p></blockquote>



<p>Sam Gunn and Niels Kornerup, <strong><a href="https://arxiv.org/abs/1906.07673">Review of a Quantum Algorithm for Betti Numbers</a></strong>.</p>



<blockquote class="wp-block-quote"><p>We looked into the algorithm for calculating Betti numbers presented by Lloyd, Garnerone, and Zanardi (LGZ). We present a new algorithm in the same spirit as LGZ with the intent of clarifying quantum algorithms for computing Betti numbers. Our algorithm is simpler and slightly more efficient than that presented by LGZ. We present a thorough analysis of our algorithm, pointing out reasons that both our algorithm and that presented by LGZ do not run in polynomial time for most inputs. However, the algorithms do run in polynomial time for calculating an approximation of the Betti number to polynomial multiplicative error, when applied to some class of graphs for which the Betti number is exponentially large.</p></blockquote>



<p>William Kretschmer, <strong><a href="https://arxiv.org/abs/1907.06731">Lower Bounding the AND-OR Tree via Symmetrization</a></strong>.</p>



<blockquote class="wp-block-quote"><p>We prove a simple, nearly tight lower bound on the approximate degree of the two-level AND-OR tree using symmetrization arguments. Specifically, we show that ~deg(AND<em>m</em>∘OR<em>n</em>)=Ω(~<em>√</em>(<em>mn</em>)). To our knowledge, this is the first proof of this fact that relies on symmetrization exclusively; most other proofs involve the more complicated formulation of approximate degree as a linear program [BT13, She13, BDBGK18]. Our proof also demonstrates the power of a symmetrization technique involving Laurent polynomials (polynomials with negative exponents) that was previously introduced by Aaronson, Kothari, Kretschmer, and Thaler [AKKT19].</p></blockquote>



<p>Jiahui Liu and Ruizhe Zhang (project turned into a joint paper with me, Mark Zhandry, and Qipeng Liu), <br/><strong><a href="https://arxiv.org/abs/2004.09674">New Approaches for Quantum Copy-Protection</a></strong>.</p>



<blockquote class="wp-block-quote"><p>Quantum copy protection uses the unclonability of quantum states to construct quantum software that provably cannot be pirated. Copy protection would be immensely useful, but unfortunately little is known about how to achieve it in general. In this work, we make progress on this goal, by giving the following results:<br/>– We show how to copy protect any program that cannot be learned from its input/output behavior, relative to a classical oracle. This improves on Aaronson [CCC’09], which achieves the same relative to a quantum oracle. By instantiating the oracle with post-quantum candidate obfuscation schemes, we obtain a heuristic construction of copy protection.<br/>– We show, roughly, that any program which can be watermarked can be copy detected, a weaker version of copy protection that does not prevent copying, but guarantees that any copying can be detected. Our scheme relies on the security of the assumed watermarking, plus the assumed existence of public key quantum money. Our construction is general, applicable to many recent watermarking schemes.</p></blockquote>



<p>John Kallaugher, <strong>Triangle Counting in the Quantum Streaming Model</strong>.  Not yet available but coming soon to an arXiv near you!</p>



<blockquote class="wp-block-quote"><p>We give a quantum algorithm for counting triangles in graph streams that uses less space than the best possible classical algorithm.</p></blockquote></div>
    </content>
    <updated>2021-03-11T20:31:03Z</updated>
    <published>2021-03-11T20:31:03Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-03-15T04:21:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5376</id>
    <link href="https://www.scottaaronson.com/blog/?p=5376" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5376#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5376" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Sayonara Majorana?</title>
    <summary xml:lang="en-US">Many of you have surely already seen the news that the Kouwenhoven group in Delft—which in 2018 published a paper in Nature claiming to have detected Majorana particles, a type of nonabelian anyon—have retracted the paper and apologized for “insufficient scientific rigour.” This work was considered one of the linchpins of Microsoft’s experimental effort toward […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Many of you have surely <a href="https://www.wired.com/story/microsoft-retracts-disputed-quantum-computing-paper/">already</a> <a href="https://www.nature.com/articles/d41586-021-00612-z">seen</a> the news that the Kouwenhoven group in Delft—which in 2018 published a paper in <em>Nature</em> claiming to have detected <a href="https://en.wikipedia.org/wiki/Majorana_fermion">Majorana particles</a>, a type of nonabelian <a href="https://en.wikipedia.org/wiki/Anyon">anyon</a>—have <a href="https://www.nature.com/articles/s41586-021-03373-x?utm_medium=affiliate&amp;utm_source=commission_junction&amp;utm_campaign=3_nsn6445_deeplink_PID100095187&amp;utm_content=deeplink">retracted the paper</a> and apologized for “insufficient scientific rigour.”  This work was considered one of the linchpins of Microsoft’s experimental effort toward building topological quantum computers.</p>



<p>Like most quantum computing theorists, I guess, I’m thrilled if Majorana particles can be created using existing technology, I’m sad if they can’t be, but I don’t have any special investment in or knowledge of the topic, beyond what I read in the news or hear from colleagues.  Certainly Majorana particles seem neither necessary nor sufficient for building a scalable quantum computer, although they’d be a step forward for the topological approach to QC.</p>



<p>The purpose of this post is to invite <em>informed scientific discussion</em> of the relevant issues—first and foremost so that I can learn something, and second so that my readers can!  I’d be especially interested to understand:</p>



<ol><li>Weren’t there, like, several <em>other</em> claims to have produced Majoranas?  What of those then?</li><li>If, today, no one has convincingly demonstrated the existence of Majoranas, then do people think it more likely that they were produced but not detected, or that they weren’t even produced?</li><li>How credible are the explanations as to what went wrong?</li><li>Are there any broader implications for the prospects of topological QC, or Microsoft’s path to topological QC, or was this just an isolated mistake?</li></ol>



<p/></div>
    </content>
    <updated>2021-03-10T22:29:51Z</updated>
    <published>2021-03-10T22:29:51Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-03-15T04:21:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=21347</id>
    <link href="https://gilkalai.wordpress.com/2021/03/10/amazing-feng-pan-and-pan-zhang-announced-a-way-to-spoof-classically-simulate-the-googles-quantum-supremacy-circuit/" rel="alternate" type="text/html"/>
    <title>Amazing: Feng Pan and Pan Zhang Announced a Way to “Spoof” (Classically Simulate) the Google’s Quantum Supremacy Circuit!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Feng Pan and Pan Zhang uploaded a new paper on the arXive  “Simulating the Sycamore supremacy circuits.” with an amazing announcement. Abstract: We propose a general tensor network method for simulating quantum circuits. The method is massively more efficient in … <a href="https://gilkalai.wordpress.com/2021/03/10/amazing-feng-pan-and-pan-zhang-announced-a-way-to-spoof-classically-simulate-the-googles-quantum-supremacy-circuit/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Feng Pan and Pan Zhang uploaded a new paper on the arXive  <a href="https://arxiv.org/abs/2103.03074">“Simulating the Sycamore supremacy circuits.”</a> with an amazing announcement.</p>
<blockquote><p><span style="color: #0000ff;"><em><strong> Abstract:</strong> We propose a general tensor network method for simulating quantum circuits. The method is massively more efficient in computing a large number of correlated bitstring amplitudes and probabilities than existing methods. As an application, we study the sampling problem of Google’s Sycamore circuits, which are believed to be beyond the reach of classical supercomputers and have been used to demonstrate quantum supremacy. Using our method, employing a small computational cluster containing 60 graphical processing units (GPUs), we have generated one million correlated bitstrings with some entries fixed, from the Sycamore circuit with 53 qubits and 20 cycles, with linear cross-entropy benchmark (XEB) fidelity equals 0.739, which is much higher than those in Google’s quantum supremacy experiments.</em></span></p></blockquote>
<p><strong><span style="color: #ff0000;">Congratulations to Feng Pan and Pan Zhang for this remarkable breakthrough!</span></strong></p>
<p>Of course, we can expect that in the weeks and months to come, the community will learn, carefully check, and digest this surprising result and will ponder about its meaning and interpretation. Stay tuned!</p>
<p><span style="color: #993366;">Here is a technical matter I am puzzled about: the paper claims the ability to compute precisely the amplitudes for a large number of bitstrings. (Apparently computing the amplitudes is even more difficult computational task than sampling.) But then, it is not clear to me where the upper bound of 0.739 comes from? If you have the precise amplitudes it seems that you can sample with close to perfect fidelity. (And, if you wish, you can get a F_XEB score larger than 1.)<br/>
</span></p>
<p><span style="color: #993366;">Update: This is explained just before the discussion part of the paper. The crucial thing is that the probabilities for the 2^21 strings are distributed close to Porter-Thomas (exponentials). If you take samples for them indeed you can get samples with F_XEB between -1 and 15. Picking the highest 10^6  strings from 2^21 get you 0.739 (so this value has no special meaning.) Probably by using Metropolis sampling you can get (smaller, unless you enlarge 2^21 to 2^25, say) samples with F_XEB close to 1 and size-biased distribution (the distribution of probabilities of sampled strings) that fits the theoretical size biased distribution.  And you can also use metropolis sampling to get a sample of size 10^6 with the correct distribution of probabilities for somewhat smaller fidelity. </span></p>
<p>The paper mentions several earlier papers in this direction, including an earlier result by Johnnie Gray and Stefanos Kourtis in the paper <a href="https://arxiv.org/abs/2002.01935">Hyper-optimized tensor network contraction</a> and another earlier result in the paper <a href="https://arxiv.org/abs/2005.06787">Classical Simulation of Quantum Supremacy Circuits</a> by a group of researchers Cupjin Huang, Fang Zhang, Michael Newman, Junjie Cai, Xun Gao, Zhengxiong Tian, Junyin Wu, Haihong Xu, Huanjun Yu, Bo Yuan, Mario Szegedy, Yaoyun Shi, and Jianxin Chen, from Alibaba co.  Congratulations to them as well.</p>
<p>I am thankful to colleagues who told me about this paper.</p>
<h3>Some links:</h3>
<p><a href="https://thequantumdaily.com/2021/03/05/scientists-say-they-used-classical-computers-to-outperform-googles-sycamore-qc/"><span dir="ltr">Scientists Say They Used Classical Approach to outperform Google’s Sycamore QC</span></a> (“The Quantum” Written by Matt Swayne with interesting quotes from the paper. )</p>
<p><a href="https://www.scottaaronson.com/blog/?p=5371" rel="bookmark" title="Permanent Link: Another axe swung at the Sycamore">Another axe swung at the Sycamore</a> (Shtetl-Optimized; with interesting preliminary thoughts by Scott;  )</p>
<p><a href="https://gilkalai.files.wordpress.com/2021/03/pan-zhang.png"><img alt="" class="alignnone size-full wp-image-21373" height="396" src="https://gilkalai.files.wordpress.com/2021/03/pan-zhang.png?w=640&amp;h=396" width="640"/></a></p></div>
    </content>
    <updated>2021-03-10T13:07:14Z</updated>
    <published>2021-03-10T13:07:14Z</published>
    <category term="Computer Science and Optimization"/>
    <category term="Physics"/>
    <category term="Quantum"/>
    <category term="Feng Pan"/>
    <category term="Pan Zhang"/>
    <category term="Quantum computation"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2021-03-16T00:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=18282</id>
    <link href="https://rjlipton.wordpress.com/2021/03/10/making-algorithms-fair/" rel="alternate" type="text/html"/>
    <title>Making Algorithms Fair</title>
    <summary>We don’t need to be good. But let’s try to be fair. —Holly Black FairVis source/personal website Jamie Morgenstern is an assistant professor in Computer Science and Engineering at the University of Washington. Previously she was at the School of Computer Science at Georgia Tech—a place where I, Dick, spent some time too. We were […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>We don’t need to be good. But let’s try to be fair. —Holly Black</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2021/03/jamie-morgenstern.jpg"><img alt="" class="alignright wp-image-18297" height="150" src="https://rjlipton.files.wordpress.com/2021/03/jamie-morgenstern.jpg?w=150&amp;h=150" width="150"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">FairVis <a href="https://fredhohman.com/papers/fairvis">source</a>/personal <a href="http://jamiemorgenstern.com">website</a> </font></td>
</tr>
</tbody>
</table>
<p>
Jamie Morgenstern is an assistant professor in Computer Science and Engineering at the University of Washington. Previously she was at the School of Computer Science at Georgia Tech—a place where I, Dick, spent some time too. We were sad when Jamie left to go west.</p>
<p>
Today we thought we would talk about making algorithms fair.<br/>
<span id="more-18282"/></p>
<p>
We will focus on an aspect that first seems like something you would never think of.  Then, when you think of it, getting fairness seems impossible.  So when I thought of it, Ken and I thought maybe no one else had, and Ken came up only with one maybe-relevant paper that used <i>blockchain</i>.  Then I found that some people have thought of it—including Jamie.</p>
<p>
You can kind-of just make it out in the “elevator pitch” description of her work at the very top of her personal <a href="https://jamiemorgenstern.com">website</a>:</p>
<blockquote><p><b> </b> <em> How should machine learning be made robust to behavior of the people generating training or test data for it? How should ensure that the models we design do not exacerbate inequalities already present in society? </em>
</p></blockquote>
<p>
It’s in the word “generating.”  Often we generate or select test data <i>randomly</i>.  Or at least we say we do.  How can we assure that our use of randomness is <i>fair</i>?  Is that even a question?  After all, randomness doesn’t intend bias.  The epitome of randomness is something we call “flipping a <i>fair</i> coin” to begin with.</p>
<p>
</p><h2> Never Thought of It </h2><p/>
<p>
I believe that one of the issues that delayed the rise of fairness as a property of algorithms must be that it is not an obvious property. </p>
<p>
First, what makes a Turing machine <i>efficient?</i> Complexity theory is based on time and space which was first defined for Turing machines. This started with the famous 1965  <a href="https://en.wikipedia.org/wiki/Juris_Hartmanis">paper</a>, “On the Computational Complexity of Algorithms” by Juris Hartmanis and Richard Stearns. The notion of <i>time</i> is clear—just count each step of the Turing machine. <i>Space</i> is more complicated—just counting squares of the tapes is too simple, one must allow the input tape to be different from the work tape.  A workable definition is counting the tape cells that are ever <i>changed</i>.</p>
<p>
Next, what makes a Turing machine <i>fair?</i> It seems impossible to imagine a universal definition like the above paper—fairness requires domain-specific information. There is no definition that looks just at the structure of a Turing machine.</p>
<p>
So we went past the turn of the millennium without considering fairness, and missed a concept that has been around for millennia more.  As stated in last June’s <a href="https://www.simonsfoundation.org/2020/06/18/foundation-announces-simons-collaboration-on-the-theory-of-algorithmic-fairness/">announcement</a> of a Simons collaboration directed by Omer Reingold:</p>
<blockquote><p><b> </b> <em> The study of fairness is ancient and multidisciplinary: philosophers, legal experts, economists, statisticians, social scientists and others have been concerned with fairness for as long as these fields have existed. Nevertheless, the scale of decision-making in the age of big data, the computational complexities of algorithmic decision-making and simple professional responsibility mandate that computer scientists contribute to this research endeavor. </em></p></blockquote>
<p>
Indeed we could quote many others on why fairness is important. </p>
<p>
One of the embarrassments is that computer scientists did not study fairness earlier. I must admit I never did too. I was concerned about being “good”: about making algorithms faster and making them use less space. But not being fair.</p>
<p>
</p><h2> In Search of Fairness </h2><p/>
<p>
Okay, fairness requires domain-specific information. But are there some cases that could be defined in a way that avoids specialized knowledge? A more general definition would allow results to have more applications. And one domain that should naturally be more generic is the use of randomness.</p>
<p>
The <a href="https://arxiv.org/pdf/1906.03284.pdf">paper</a> that caught my eye is titled, “Equalized odds post processing under imperfect group information,” by Morgenstern with Pranjal Awasthi and Matthaus Kleindessner. They say: </p>
<blockquote><p><b> </b> <em> Most approaches aiming to ensure a model’s fairness with respect to a protected attribute (such as gender or race) assume to know the true value of the attribute for every data point. In this paper, we ask to what extent fairness interventions can be effective even when only imperfect information about the protected attribute is available. </em>
</p></blockquote>
<p>
At the high level the result is about how the ability to achieveness depends on the amount of information one has about values of the attribute <img alt="{A};" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D%3B&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that one is trying to protect against bias.  The result states that even having imperfect information yields nontrivial improvements in fairness. But at the low level are techniques for equalizing conditional probabilities on values of <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and a long technical appendix employing random variables.</p>
<p>
Another area that yields a reasonably generic definition of fairness is algorithms for games of chance. The insight is: These all invoke randomness and the algorithms must not cheat. That is the generation and use of randomness must be fair—no cheating. 	</p>
<table style="margin: auto;">
<tbody><tr>
<td>
<p>
<a href="https://rjlipton.files.wordpress.com/2021/03/blockchainbullets.jpg"><img alt="" class="aligncenter wp-image-18298" height="290" src="https://rjlipton.files.wordpress.com/2021/03/blockchainbullets.jpg?w=550&amp;h=290" width="550"/></a>
</p></td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from CasinosBlockchain.io <a href="https://casinosblockchain.io/provably-fair-gambling/">source</a></font>
</td>
</tr>
</tbody></table>
<p>
There are two different types of approaches to making the randomness fair. One uses blockchain technology, as presented in the <a href="https://casinosblockchain.io/provably-fair-gambling/">article</a> accompanying the above picture.</p>
<blockquote><p><b> </b> <em> In a contest system on hybrid blockchain Dragonchain, a future hash of Bitcoin and Ethereum that has not been created yet, combined with an algorithm anyone can execute themselves, a provably fair random selection and revealing occurs, which is near impossible to profitably manipulate, as it is backed by hundreds of millions of dollars worth of proof from decentralized blockchains that Interchain with Dragonchain. </em>
</p></blockquote>
<p>
Another uses a more standard way to make the randomness secure. Here is one such <a href="https://en.wikipedia.org/wiki/Provably_fair_algorithm#Benefits_And_Drawbacks_of_Provable_Fairness">paper</a>.</p>
<blockquote><p><b> </b> <em> In a provably fair gambling system, a player places bets on games offered by the service operator. The service operator will publish a method for verifying each transaction in the game. This is usually done by using open source algorithms for random seed generation, hashing, and for the random number generator.</em></p><em>
<p>
Once a game has been played, the player can use these algorithms to test the game’s response to their in-game decisions, and evaluate the outcome by only using the published algorithms, the seeds, hashes, and the events which transpired during the game.</p>
</em><p><em>
In a simplified way, players can always check that the outcome of every game round is fair and wasn’t tampered with, and so can the game’s operators. As such, cheating is arguably impossible. </em>
</p></blockquote>
<p>
</p><h2> In Search of Correctness </h2><p/>
<p>
Let’s look at fairness from a complexity point of view. We are interested in seeing if NP gives us some insight to how to define fairness, at lest for games.</p>
<p>
Consider an algorithm <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that given a graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> must output a coloring of the vertices with <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> colors. The algorithm outputs a map from <img alt="{V(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to <img alt="{\{1,2,3\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C2%2C3%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>: from vertices of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to the colors <img alt="{1,2,3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2C2%2C3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The algorithm may output a legal coloring or not. We are left with two choices: </p>
<ol>
<li>Check for each edge <img alt="{(a, b)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28a%2C+b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> have different colors.
</li><li>Prove that the algorithm <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is always correct.
</li></ol>
<p>
We argue that there is a similar situation with an algorithm <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that claims that it is fair. The algorithm leaves us with one choice: Prove that the algorithm <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> always satisfies our definition of fair. Recall the famous <a href="https://en.wikipedia.org/wiki/Trust,_but_verify">saying</a>: </p>
<blockquote><p><b> </b> <em> Trust, but verify. </em>
</p></blockquote>
<p>
In the above we can either trust the algorithm <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> or it can check that its output is a three coloring. What we want to know is can we also avoid trusting that the algorithm <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is fair? We believe that it is possible in some situations to have the fairness of an algorithm be checkable. That is we will not have to prove the algorithm is fair, but can look at the output of the algorithm and conclude that it is fair.</p>
<p>
Let’s look at this next.</p>
<p>
</p><h2> A Fairness Problem </h2><p/>
<p>
The question we consider is this: Imagine that <img alt="{Total}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BTotal%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> people apply to our department of Computer Science for the PhD program. We have some reasonable criterion that will select the eligible applicants and yields <img alt="{{\mathbb N} \le Total}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+N%7D+%5Cle+Total%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Among the <img alt="{{\mathbb N}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> we must choose randomly say <img alt="{Accept}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAccept%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>—no other criterion can be used. How can we be sure that this actually is what happens?</p>
<p>
One possible solution is to have an algorithm that operates like this: </p>
<ol>
<li>Let us input the <img alt="{Total}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BTotal%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> people with their properties.
</li><li>Then use the acceptance criterion to reduce this to a set <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> people that meet all the criteria.
</li><li>Finally randomly select <img alt="{Accept}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAccept%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> from the set <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.
</li></ol>
<p>
Note: Any choice of <img alt="{Accept}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAccept%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> from the <img alt="{{\mathbb N}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> could be fair. But what if it was based on some decision that was biased? What if we select further from the <img alt="{{\mathbb N}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> based on race or gender or some other criterion? This is the problem. The algorithm could claim that it is fair, but it could cheat. If the criteria are complex the code that checks them could be messy. We could hide the fact that we then “randomly” selected as required. </p>
<p>
</p><h2> A Solution </h2><p/>
<p>
Here is a solution that uses a protocol between the selection algorithm and <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> other players. </p>
<ol>
<li>It is a protocol that uses several players <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.
</li><li>Only by having all <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> cheat can the protocol be defeated.
</li><li>It is public and can be checked after the fact.
</li><li>Its correctness assumes standard crypto methods are safe.
</li></ol>
<p>
The protocol assume that <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> object must be selected from <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> total objects. Note the general case follows the same method. For each <img alt="{j=1,\dots,P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%3D1%2C%5Cdots%2CP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> objects a bit commitment <img alt="{B_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is sent to the <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> player. This encodes either a <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> or a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as usual. The <img alt="{j^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> player then randomly flips a coin and sends back <img alt="{r_j \in \{0,1\}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br_j+%5Cin+%5C%7B0%2C1%5C%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> Let <img alt="{s_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be equal to <img alt="{r_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> if the bit committed <img alt="{B_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{1-r_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1-r_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> otherwise. Then compute 	</p>
<p align="center"><img alt="\displaystyle  s_1 + \dots + s_P \bmod 2. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s_1+%2B+%5Cdots+%2B+s_P+%5Cbmod+2.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>If it is <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> then pick object <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> else pick object <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>
The claim is that unless the bit method is unsafe or all the players are cheating this is correct.</p>
<p>
</p><h2> Open Problems </h2><p/>
<p>
Does making coin flips fair solve any real problem? Does it help make some algorithms easier to show that they are fair?</p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2021/03/10/making-algorithms-fair/pd/" rel="attachment wp-att-18287"><img alt="" class="alignright size-full wp-image-18287" height="405" src="https://rjlipton.files.wordpress.com/2021/03/pd.jpg?w=600&amp;h=405" width="600"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table></font></font></div>
    </content>
    <updated>2021-03-10T12:38:09Z</updated>
    <published>2021-03-10T12:38:09Z</published>
    <category term="Ideas"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="domain specific"/>
    <category term="fair"/>
    <category term="fairness"/>
    <category term="games"/>
    <category term="random"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2021-03-16T00:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=86</id>
    <link href="https://dstheory.wordpress.com/2021/03/09/thursday-march-18-tim-roughgarden-from-columbia-university/" rel="alternate" type="text/html"/>
    <title>Thursday March 18 — Tim Roughgarden  from Columbia University</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The next Foundations of Data Science virtual talk will take place on Thursday, March 18th at 11:00 AM Pacific Time (14:00 Eastern Time, 20:00 Central European Time, 19:00 UTC).  Tim Roughgarden from Columbia Univeristy will speak about “Data-Driven Algorithm Design.” Please register here to join the virtual talk. Abstract: The best algorithm for a computational problem<a class="more-link" href="https://dstheory.wordpress.com/2021/03/09/thursday-march-18-tim-roughgarden-from-columbia-university/">Continue reading <span class="screen-reader-text">"Thursday March 18 — Tim Roughgarden  from Columbia University"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next <a href="https://sites.google.com/view/dstheory/home" rel="noreferrer noopener" target="_blank">Foundations of Data Science</a> virtual talk will take place on <strong>Thursday, March 18</strong>th at <strong>11:00 AM Pacific Time</strong> (14:00 Eastern Time, 20:00 Central European Time, 19:00 UTC).  <strong>Tim Roughgarden</strong> from <strong>Columbia Univeristy</strong> will speak about “<strong>Data-Driven Algorithm Design</strong>.”</p>



<p><a href="https://sites.google.com/view/dstheory" rel="noreferrer noopener" target="_blank">Please register here to join the virtual talk.</a></p>



<p class="has-text-align-justify"><strong>Abstract</strong>: The best algorithm for a computational problem generally depends on the “relevant inputs”, a concept that depends on the application domain and often defies formal articulation. While there is a large literature on empirical approaches to selecting the best algorithm for a given application domain, there has been surprisingly little theoretical analysis of the problem.</p>



<p class="has-text-align-justify">We adapt concepts from statistical and online learning theory to reason about application-specific algorithm selection. Our models are straightforward to understand, but also expressive enough to capture several existing approaches in the theoretical computer science and AI communities, ranging from self-improving algorithms to empirical performance models. We present one framework that models algorithm selection as a statistical learning problem, and our work here shows that dimension notions from statistical learning theory, historically used to measure the complexity of classes of binary- and real-valued functions, are relevant in a much broader algorithmic context. We also study the online version of the algorithm selection problem, and give possibility and impossibility results for the existence of no-regret learning algorithms.</p>



<p>Joint work with Rishi Gupta.</p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>
    </content>
    <updated>2021-03-09T20:00:23Z</updated>
    <published>2021-03-09T20:00:23Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2021-03-16T00:22:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1823</id>
    <link href="https://theorydish.blog/2021/03/09/automated-design-of-error-correcting-codes-part-2/" rel="alternate" type="text/html"/>
    <title>Automated Design of Error-Correcting Codes, Part 2</title>
    <summary>In our previous post, we discussed the automation of error correcting codes and how formal methods are quite helpful toward this goal. In this post, we will discuss machine learning techniques as well as possible directions for future research. Machine Learning. The use of machine-learning techniques to study ECCs has increased exponentially in recent years. The main strength of machine learning methods is that they can adapt well to a variety of conditions (c.f., this paper), unlike the codes produced by formal methods which are often designed for a rigid application. On the other hand, it is much more difficult to give any formal guarantees for error-correcting codes designed with machine learning, although such an obstacle may be overcome in the future (see the conclusion).  Error-correcting output codes. One interface between machine learning and error correcting codes which has been studied for decades is the construction of error correcting codes for multiclass learning. Multiclass learning is classifying a group of objects into a number of categories. Instead of trying to distinguish the categories all up front, one can instead try to do a binary classification of some subset of the categories from another subset of the categories.” If an error [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In our <a href="https://theorydish.blog/2021/03/02/automated-design-of-error-correcting-codes-part-1/">previous post</a>, we discussed the automation of error correcting codes and how formal methods are quite helpful toward this goal. In this post, we will discuss machine learning techniques as well as possible directions for future research.</p>



<p><strong>Machine Learning. </strong>The use of machine-learning techniques to study ECCs has increased exponentially in recent years. The main strength of machine learning methods is that they can adapt well to a variety of conditions (c.f., <a href="https://arxiv.org/pdf/1911.03038.pdf">this paper</a>), unlike the codes produced by formal methods which are often designed for a rigid application. On the other hand, it is much more difficult to give any formal guarantees for error-correcting codes designed with machine learning, although such an obstacle may be overcome in the future (see the conclusion). </p>



<p><strong>Error-correcting output codes. </strong>One interface between machine learning and error correcting codes which has been studied for decades is the construction of error correcting codes for multiclass learning. Multiclass learning is classifying a group of objects into a number of categories. Instead of trying to distinguish the categories all up front, one can instead try to do a binary classification of some subset of the categories from another subset of the categories.” If an error correcting code (called an error-correcting output code–ECOC) is used for the distinguishing, it can provide a more robust classification.</p>



<p>This technique was studied theoretically for a preset error-correcting code (e.g., <a href="https://dl.acm.org/doi/pdf/10.1145/307400.307429">[Guruswami, Sahai, 1999]</a>). There are also works which synthesize an ECOC for multiclass learning. For example, the work of <a href="https://ieeexplore.ieee.org/abstract/document/1624364">Pujol, Radeva, and Vitria [2006]</a> used a heuristic which tries to find tests which reveal the highest amount of information (subject to a prior that each class is a <a href="https://en.wikipedia.org/wiki/Mixture_of_gaussians#Gaussian_mixture_model">mixture of gaussians</a>).</p>



<p>A related recent work <a href="https://arxiv.org/pdf/1808.01942.pdf">[Xiang, Wang, Kitani, 2018]</a> uses the technique of <em>deep hashing</em> to hash images so that images of a similar class have hashes which are close in Hamming distance, while images of different classes have hashes which are far in edit distance.</p>



<p><strong>Deep Learning. </strong>The bulk of recent machine learning research on the automation of ECCs has been using <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a> techniques; that is, training a constructed deep learning network to either encode–given a message as input, output a robust encoding–or decode–given a noisy transmission, recover the original message. As deep neural networks pass messages from earlier neurons to deeper neurons, the commonly referred to benchmark is that of <em>belief propagation</em>.</p>



<p>In brief (see also <a href="https://arxiv.org/pdf/1607.04793.pdf">Nachmani, et. al, 2016</a>), the <a href="https://en.wikipedia.org/wiki/Belief_propagation">belief propagation</a> (BP) algorithm starts by taking the parity-check matrix defining a given linear code and converts it into a bipartite graph–one side of the vertices are the symbols of the code and the other vertices are the parity checks. Each vertex starts with a prior (i.e., probability that the vertex should be a 0 or 1) based on the received transmission, and then messages are passed back and forth. In odd-numbered rounds, the symbols give their confidence levels to the parity checks, which then update probabilities based on being satisfied or not. In even-numbered rounds the parity checks inform the symbols if they should change their prior to better satisfy the parity checks. After some number of rounds, a decoding is deduced.</p>



<p>Some of the earlier papers using deep learning to automate ECCs [<a href="https://arxiv.org/pdf/1607.04793.pdf">Nachmani, et. al, 2016</a>, <a href="https://arxiv.org/pdf/1706.07043.pdf">2018</a>; <a href="https://arxiv.org/pdf/1702.06901.pdf">Crammerer, et.al., 2017</a>; <a href="https://arxiv.org/pdf/1701.07738.pdf">Gruber, et.al., 2017</a>] tried to generalize a belief propagation algorithm for decoding ECCs. At a high level, the works of Nachmani, et.al. “unroll” the belief propagation into a deep neural network with many layers. Unlike BP which has a fixed weight for the value of each message in each stage, they have trainable weights which allow one to obtain a lower BER than plain BP. Both Nachmani, et.al., and the works of Crammerer, et.al., and Gruber, et.al., consider more complex neural architectures which use BP as a subroutine. The latter two works show success in these methods for <a href="https://en.wikipedia.org/wiki/Polar_code_(coding_theory)">polar codes</a> and random linear codes. Note that all of these works are only training a decoder, as the encodings are fixed.</p>



<p>A later group of papers [<a href="https://arxiv.org/pdf/1807.00801.pdf">Kim, et.al. 2020</a>; <a href="https://arxiv.org/pdf/1903.02295.pdf">Jiang, et.al., 2019a</a>, <a href="https://arxiv.org/pdf/1911.03038.pdf">2019b</a>, <a href="https://ieeexplore.ieee.org/abstract/document/9053254">2020</a>] (see also <a href="https://deepcomm.github.io/">their blog</a>) introduce what is known as DeepCode. Unlike previous work, the initial DeepCode paper [Kim, et.al., 2020] builds both a custom encoder and decoder. A particular tool which the authors utilized is that of <em>feedback</em>–after each bit is transmitted the noisy received bit is sent back (possibly with more noise added). Intuitively, feedback allows for the encoder to have an approximate understanding of what the decoder doesn’t know, allowing for on-the-fly adjustments to the encoding. The encoder sends the original message in plain-text and then incorporates the feedback with <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">RNN</a> units to add two redundant bits per message bit (and thus the rate is one-third). The decoder incorporates the noisy plain text and these redundant bits using bidirectional-<a href="https://en.wikipedia.org/wiki/Gated_recurrent_unit">GRU</a>s. Their methods can get a BER of as low as <img alt="10^{-7}" class="latex" src="https://s0.wp.com/latex.php?latex=10%5E%7B-7%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for a block length of 50 bits.</p>



<p>Follow-up work [Jiang, et.al., 2019a, 2019b, 2020] consider variants of the model. In [Jiang, et.al., 2019a], the encoder is fixed to be a <a href="https://en.wikipedia.org/wiki/Turbo_code">turbo code</a> (a type of <a href="https://en.wikipedia.org/wiki/Convolutional_code">convolutional code</a>), a “standard” code in many applications, but the goal is to train a deep net to beat the <a href="https://en.wikipedia.org/wiki/BCJR_algorithm">standard decoder</a> in a “non-Gaussian noise” model. The work [Jiang, et.al., 2019b] tries to beat the turbo code at its own game by constructing a turbo code-like deep net where a commonly used finite automata is replaced by a deep net (and a corresponding decoder is constructed as well). Finally, the work [Jiang, et.al, 2020] generalized [Jiang, et.al., 2019b] by also using feedback, like in DeepCode.</p>



<p>Outside of deep learning, <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> techniques have also been used to construct a decoder (e.g., <a href="https://arxiv.org/pdf/2009.09277.pdf">[Liao, et.al., 2020]</a>).</p>



<p><strong>Conclusion and Future Directions</strong>. Although the technology is still in its infancy, the automation of error correction codes is an exciting domain which could have a variety of applications in the future. As we have seen in this post, both formal methods and machine learning allow for powerful methods for obtaining automating various aspects of ECCs, whether it be constructing error correcting codes with provable guarantees or designing non-standard decodes which are robust to a variety of conditions. Looking ahead, there are a number of exciting directions which could be ripe for theoretical and practical contributions.</p>



<ol><li>A very active field of research currently is DNA storage–that is, synthesizing DNA molecules which encode data (rather than biological life). The primary theoretical challenge of DNA storage is that data loss is no longer a “bit flip,” rather nucleotides can be inserted, deleted, replicated, etc. Very recently, convolutional codes have proved successful in this setting <a href="https://www.biorxiv.org/content/10.1101/2019.12.20.871939v2.full">[Chandak, et.al., 2020]</a>, but an analogue to DeepCode does not currently exist in this setting. One barrier is that it is difficult for a fixed-architecture neural network to easily accommodate “index shifting” taking place during insertions and deletions. Automated techniques have been used to give lower bounds on how much redundancy is needed for such codes <a href="https://publish.illinois.edu/kiyavash/files/2015/06/Kulkarni_it_trans_2013.pdf">[Kulkarni, Kiyavash, 2013]</a>.</li><li>One potential theoretical contribution in this space is understanding how these automation techniques relate to <a href="https://en.wikipedia.org/wiki/Augmented_learning"><em>augmented learning</em></a>. An example of augmented learning is the problem of picking the “best” algorithm from a class of algorithms for a given problem. A theoretical framework for understanding such questions has recently been developed by <a href="https://theory.stanford.edu/~tim/papers/features.pdf">Gupta and Roughgarden</a>. Such a framework seems natural in the context of error-correcting codes, as there are many different kinds of codes, and even within one family of codes, such as Reed-Solomon codes, there are many parameter choices whose optimal values can vary significantly from application to application. </li><li>As a final thought, the use of “Formal Methods” in contrast to “Machine Learning” for automating ECCs has been largely separate. Recently, outside the context of ECCs, there have been a number of works (e.g., <a href="https://arxiv.org/pdf/1705.01320.pdf">[Ehlers, 2017]</a>, <a href="https://arxiv.org/abs/1811.01057">[Raghunathan, Steinhardt, Liang, 2018]</a>) which use formal methods to <em>provably verify</em> that a machine learning model such as a deepnet runs correctly under given conditions. It would be exciting if such methods could be extended to ECCs by showing that machine learning encoders/decoders like DeepCode can be utilized correctly. </li></ol>



<p>Are there other directions for which you would like to see the automation of ECCs extended? If so, please leave a comment.</p>



<p><strong>Acknowledgments. </strong>I would like to thank my quals committee, Aviad Rubinstein, Moses Charikar, and Mary Wootters for valuable feedback. I would also like to thank Sivakanth Gopi and Sergey Yekhanin for insightful discussion on the relationship between automation of ECCs and DNA storage as well as Ofir Geri for discussion on augmented learning.</p></div>
    </content>
    <updated>2021-03-09T16:00:00Z</updated>
    <published>2021-03-09T16:00:00Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Joshua Brakensiek</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2021-03-16T00:21:48Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2021-03-09-good-case-latency-of-byzantine-broadcast-the-synchronous-case/</id>
    <link href="https://decentralizedthoughts.github.io/2021-03-09-good-case-latency-of-byzantine-broadcast-the-synchronous-case/" rel="alternate" type="text/html"/>
    <title>Good-case Latency of Byzantine Broadcast: the Synchronous Case</title>
    <summary>In our first post, we presented a summary of our good-case latency results for Byzantine broadcast (BB) and state machine replication (SMR), where the good case measures the latency to commit given that the broadcaster or leader is honest. In our second post, we discussed our results for partial synchrony,...</summary>
    <updated>2021-03-09T16:00:00Z</updated>
    <published>2021-03-09T16:00:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2021-03-15T22:54:12Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/034</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/034" rel="alternate" type="text/html"/>
    <title>TR21-034 |  Robust Self-Ordering versus Local Self-Ordering | 

	Oded Goldreich</title>
    <summary>We study two notions that refers to asymmetric graphs, which we view as graphs having a unique ordering that can be reconstructed by looking at an unlabeled version of the graph.

A {\em local self-ordering} procedure for a graph $G$ is given oracle access to an arbitrary isomorphic copy of $G$, denoted $G'$, and a vertex $v$ in $G'$, and is required to identify the name (or location) of $v$ in $G$, while making few (i.e., polylogarithmically many) queries to $G'$.
A graph $G=(V,E)$ is {\em robustly self-ordered} if the size of the symmetric difference between $E$ and the edge-set of the graph obtained by permuting $V$ using any permutation $\pi:V\to V$ is proportional to the number of non-fixed-points of $\pi$ and to the maximal degree of $G$; that is, any permutation of the vertices that displaces $t$ vertices must ``displace'' $\Omega(t\cdot d)$ edges, where $d$ is the maximal degree of the graph. 

We consider the relation between these two notions in two regimes: The bounded-degree graph regime, where oracle access to a graph means oracle access to its incidence function, and the dense graph regime, where oracle access to the graph means access to its adjacency predicate. 

We show that, {\em in the bounded-degree regime}, robustly self-ordering and local self-ordering are almost orthogonal; that is, even extremely strong versions of one notion do not imply very weak versions of the other notion. 
Specifically, we present very efficient local self-ordering procedures for graphs that possess derangements that are almost automorphisms (i.e., a single incidence is violated).  
One the other hand, we show robustly self-ordered graphs having no local self-ordering procedures even when allowing a number of queries that is a square root of the graph's size. 

{\em In the dense graph regime}, local self-ordering procedures are shown to yield a quantitatively weaker version of the robust self-ordering condition, in which the said proportion is off by a factor that is related to the query complexity of the local self-ordering procedure. Furthermore, we show that this quantitatively loss is inherent.
On the other hand, we show how to transform any robustly self-ordered graph 
into one having a local self-ordering procedure, while preserving the robustness condition. Combined with prior work, this yields explicit constructions of graphs that are both robustly and locally self-ordered, and an application to property testing.</summary>
    <updated>2021-03-09T09:13:43Z</updated>
    <published>2021-03-09T09:13:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-03-16T00:20:26Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/03/08/more-mathematics-books</id>
    <link href="https://11011110.github.io/blog/2021/03/08/more-mathematics-books.html" rel="alternate" type="text/html"/>
    <title>More mathematics books by women</title>
    <summary>A year ago, for International Women’s Day, I made a list of mathematics books by women covered by then-new Wikipedia articles. I thought it would be worthwhile to revisit the same topic and list several more mathematics books with at least one female author, at many different levels of audience, and again covered by new Wikipedia articles. They are (alphabetical by title):</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A year ago, for International Women’s Day, I made <a href="https://11011110.github.io/blog/2020/03/08/mathematics-books-women.html">a list of mathematics books by women covered by then-new Wikipedia articles</a>. I thought it would be worthwhile to revisit the same topic and list several more mathematics books with at least one female author, at many different levels of audience, and again covered by new Wikipedia articles. They are (alphabetical by title):</p>

<ul>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Algorithmic_Combinatorics_on_Partial_Words">Algorithmic Combinatorics on Partial Words</a></em> (2008), Francine Blanchet-Sadri. Partial words are strings with “don’t care” symbols; Blanchet-Sadri looks at the combinatorics of repeated patterns within these strings.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Algorithmic_Geometry">Algorithmic Geometry</a></em> (1995), Jean-Daniel Boissonnat and Mariette Yvinec. One of several standard computational geometry textbooks; this is the French one, but it has also been published in translation into English.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Algorithmic_Puzzles">Algorithmic Puzzles</a></em> (2011), Anany and Maria Levitin. A nice collection of classic logic puzzles involving algorithmic thinking.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Braids,_Links,_and_Mapping_Class_Groups">Braids, Links, and Mapping Class Groups</a></em> (1975), Joan Birman. A classic research monograph on the topology of braid groups.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Code_of_the_Quipu">Code of the Quipu</a></em> (1981), Marcia and Robert Ascher. A general-audience book on how the Inca used knotted strings to record numbers and other information.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Combinatorics:_The_Rota_Way">Combinatorics: The Rota Way</a></em> (2009), Joseph P. S. Kung, Catherine Yan, and (posthumously) Gian-Carlo Rota. A graduate textbook on algebraic combinatorics.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Combinatorics_of_Experimental_Design">Combinatorics of Experimental Design</a></em> (1987), Anne Penfold Street and her daughter Deborah Street. A textbook on the design of experiments, an area that crosses between statistics and combinatorics.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Computability_in_Analysis_and_Physics">Computability in Analysis and Physics</a></em> (1989), Marian Pour-El and J. Ian Richards. A research monograph on problems involving differential equations including the wave equation whose initial conditions are continuous and computable, but that evolve to states whose values cannot be computed.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Diophantus_and_Diophantine_Equations">Diophantus and Diophantine Equations</a></em> (1972), Isabella Bashmakova. A somewhat idiosyncratic history based on the idea that Diophantus knew some very general techniques for finding rational-number solutions to equations, that can be inferred from the much more specific solutions to individual equations that have survived to us.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Elementary_Number_Theory,_Group_Theory_and_Ramanujan_Graphs">Elementary Number Theory, Group Theory, and Ramanujan Graphs</a></em> (2003), Giuliana Davidoff, Peter Sarnak, and Alain Valette. An attempt to make the construction of expander graphs accessible to undergraduate mathematics students.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Equivalents_of_the_Axiom_of_Choice">Equivalents of the Axiom of Choice</a></em> (1963, updated 1985), Herman and Jean Rubin. A large catalog of problems in mathematics whose solution is equivalent to the axiom of choice, from a time when the independence of choice from ZF set theory had not been proven.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Erd%C5%91s_on_Graphs">Erdős on Graphs: His Legacy of Unsolved Problems</a></em> (1998), 
Fan Chung and Ronald Graham. The open problems in graph theory from this book have been further collected and updated on a web site, <a href="http://www.math.ucsd.edu/~erdosproblems/">Erdős’s Problems on Graphs</a>, maintained by Chung.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Extensions_of_First_Order_Logic">Extensions of First Order Logic</a></em> (1996), María Manzano. Attempts to unify second-order logic, modal logic, and dynamic logic, by translating them all into many-sorted logic.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Fat_Chance:_Probability_from_0_to_1">Fat Chance: Probability from 0 to 1</a></em> (2019), Benedict Gross, Joe Harris, and Emily Riehl. A general-audience undergraduate textbook on probability theory based on a metaphor of games of chance.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Fractal_Dimension_of_Architecture">The Fractal Dimension of Architecture</a></em> (2016), Michael J. Ostwald and Josephine Vaughan. Studies the fractal dimension of floor plans as a way to model the changing demands on the complexity of housing structures and to classify buildings by architect and style.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Geometry_of_Numbers">The Geometry of Numbers</a></em> (2000), Carl D. Olds, Anneli Cahn Lax, and Giuliana Davidoff. A textbook on connections between number theory and integer grids, rescued twice from the posthumous works of its first two coauthors.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_History_of_Mathematical_Tables">The History of Mathematical Tables: from Sumer to Spreadsheets</a></em> (2003), Martin Campbell-Kelly, Mary Croarken, Raymond Flood, and Eleanor Robson. An edited volume with chapters on tables from many different periods in mathematical history.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Incidence_and_Symmetry_in_Design_and_Architecture">Incidence and Symmetry in Design and Architecture</a></em> (1983), Jenny Baglivo and Jack E. Graver. A textbook on graph theory and symmetry aimed at architecture students, also including interesting material on structural rigidity.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Introduction_to_the_Theory_of_Error-Correcting_Codes">Introduction to the Theory of Error-Correcting Codes</a></em> (1982, updated 1989 and 1998), Vera Pless. An advanced undergraduate textbook centered on algebraic constructions of linear block codes.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Introduction_to_3-Manifolds">Introduction to 3-Manifolds</a></em> (2014), Jennifer Schultens. An introductory graduate textbook on low-dimensional topology, leading up to the use of normal surfaces and Heegard splittings.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Journey_into_Geometries">Journey into Geometries</a></em> (1991), Márta Svéd. A conversational Alice-in-wonderland-inspired tour of non-Euclidean geometry.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Knots_Unravelled">Knots Unravelled: From String to Mathematics</a></em> (2011), Meike Akveld and Andrew Jobbings. Knot theory for schoolchildren, centered on knot invariants.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Lectures_in_Geometric_Combinatorics">Lectures in Geometric Combinatorics</a></em> (2006), Rekha R. Thomas. An advanced undergraduate or introductory graduate textbook on the combinatorics of convex polytopes and their connections to abstract algebra through secondary polytopes and toric varieties.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Making_Mathematics_with_Needlework">Making Mathematics with Needlework: Ten Papers and Ten Projects</a></em> (2008), sarah-marie belcastro and Carolyn Yackel. The projects come from eight different contributors and include photos, instructions, mathematical analyses, and teaching activities.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Mathematical_Excursions">Mathematical Excursions: Side Trips along Paths Not Generally Traveled in Elementary Courses in Mathematics</a></em> (1933), Helen Abbot Merrill. An early book on recreational mathematics, aimed at getting high school students interested in mathematics.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Mathematics_in_India">Mathematics in India: 500 BCE–1800 CE</a></em> (2009), Kim Plofker. Organized chronologically, this has become the standard overview of this large topic. It also includes material on the history of astronomy in India, which was often tied to the mathematics of its era.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Mathematics_of_Chip-Firing">The Mathematics of Chip-Firing</a></em> (2018), Caroline Klivans. A textbook on chip-firing games and abelian sandpile models.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Markov_Chains_and_Mixing_Times">Markov Chains and Mixing Times</a></em> (2009, 2017), David A. Levin and Yuval Peres, with contributions by Elizabeth Wilmer. A graduate-level text and research reference on how quickly random walks converge to their stable distributions.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Mirrors_and_Reflections">Mirrors and Reflections: The Geometry of Finite Reflection Groups</a></em> (2009), Alexandre V. and Anna Borovik. An undergraduate textbook on the classification of finite reflection groups and their associated root systems.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Pioneering_Women_in_American_Mathematics">Pioneering Women in American Mathematics: The Pre-1940 PhD’s</a></em> (2009), Judy Green and Jeanne LaDuke. Biographical profiles of over 200 women who earned doctorates in mathematics in the US before 1940, with some background material on what it was like for women to work in mathematics in those times.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Playing_with_Infinity">Playing with Infinity: Mathematical Explorations and Excursions</a></em> (1955, translated into English 1961), Rózsa Péter. An attempt to explain the nature of mathematics and of the infinite in mathematics to non-mathematicians, based on a series of letters from Péter to a literary friend.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Point_Processes">Point Processes</a></em> (1980), David Cox and Valerie Isham. A research reference on processes that randomly place points on the real line or other geometric spaces.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Power_in_Numbers:_The_Rebel_Women_of_Mathematics">Power in Numbers: The Rebel Women of Mathematics</a></em> (2018), Talithia Williams. A selection of profiles of famous women mathematicians, aimed at motivating young women to become mathematicians.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Primality_Testing_for_Beginners">Primality Testing for Beginners</a></em> (2009, translated into English 2014), Lasse Rempe-Gillen and Rebecca Waldecker. An undergraduate text on primality testing algorithms, based on a course from a summer research program for undergraduates.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Quantum_Computing:_A_Gentle_Introduction">Quantum Computing: A Gentle Introduction</a></em> (2011), Eleanor Rieffel and Wolfgang Polak. One of many texts on this fast-moving subject.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Robust_Regression_and_Outlier_Detection">Robust Regression and Outlier Detection</a></em> (1987), Peter Rousseeuw and Annick M. Leroy. A monograph on statistical methods that can tolerate the total corruption of a large fraction of the data points that they analyze, and still produce meaningful results.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Two-Sided_Matching">Two-Sided Matching: A Study in Game-Theoretic Modeling and Analysis</a></em> (1990), Alvin E. Roth and Marilda Sotomayor. A survey of methods related to stable matching, aimed at economics practitioners and focused on applications.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/When_Topology_Meets_Chemistry">When Topology Meets Chemistry: A Topological Look At Molecular Chirality</a></em> (2000), Erica Flapan. Many biomolecules are different than their mirror images; classical examples include sugars, whose mirrored molecules may taste different and have different effects. This undergraduate-level text studies how to model this effect using a combination of graph theory and knot theory.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Women_in_Mathematics">Women in Mathematics</a></em> (1974), Lynn Osen. This is the one that based its coverage of Hypatia on an early-20th-century children’s book that gave her a made-up backstory and attributed made-up modern rationalist quotes to her. Not recommended, and included mainly as a warning not to use this as a reference.</p>
  </li>
</ul>

<p>To keep from ending on a sour note, I’ll add one more, that I found recently on Wikipedia (although the article there is very old) and I think is worthy of expansion: <em><a href="https://en.wikipedia.org/wiki/Logic_Made_Easy">Logic Made Easy: How to Know When Language Deceives You</a></em> (2004), Deborah J. Bennett, a popular-audience book on how to translate English phrases into logical formalisms and use that translation to understand more clearly what they mean.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/105857580884627445">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2021-03-08T18:28:00Z</updated>
    <published>2021-03-08T18:28:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-03-09T02:55:58Z</updated>
    </source>
  </entry>
</feed>
