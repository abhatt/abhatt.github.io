<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-02-23T07:22:03Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15657</id>
    <link href="https://rjlipton.wordpress.com/2019/02/22/making-a-mapping-injective/" rel="alternate" type="text/html"/>
    <title>Making A Mapping Injective</title>
    <summary>Finding a set of nearly independent objects Wikipedia bio source Giuseppe Vitali was the mathematician who famously used the Axiom of Choice, in 1905, to give the first example of a non-measurable subset of the real numbers. Today I want to discuss another of his results that is a powerful tool. The existence of a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Finding a set of nearly independent objects</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/02/330px-giuseppe_vitali.jpg"><img alt="" class="alignright size-thumbnail wp-image-15658" height="150" src="https://rjlipton.files.wordpress.com/2019/02/330px-giuseppe_vitali.jpg?w=118&amp;h=150" width="118"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Wikipedia bio <a href="https://en.wikipedia.org/wiki/Giuseppe_Vitali">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Giuseppe Vitali was the mathematician who famously used the Axiom of Choice, in 1905, to give the first example of a non-measurable subset of the real numbers.</p>
<p>
Today I want to discuss another of his results that is a powerful tool.</p>
<p>
The existence of a set that cannot properly be assigned a measure was a surprise at the time, and still is a surprise. It is a wonderful example of the power of the Axiom of Choice. See <a href="https://en.wikipedia.org/wiki/Vitali_set">this</a> for details. </p>
<p>
We are interested in another of his results that is more a theorem about coverings. It is the Vitali covering theorem–see <a href="https://en.wikipedia.org/wiki/Vitali_covering_lemma">this</a>. The theorem shows that a certain type of covering—ah, we will explain the theorem in a moment.</p>
<p>
The power of this theorem is that it can be used to construct various objects in analysis. There are now many applications of this theorem. It is a powerful tool that can be used to prove many nice results. I do not know of any—many?—applications of the existence of a non-measurable set. Do you know any?</p>
<p>
</p><p/><h2> Making A Mapping Injective </h2><p/>
<p/><p>
Let’s look at an application of the Vitali theorem that may be new. But in any case it may help explain what the Vitali theorem is all about.</p>
<p>
Suppose that <img alt="{F:X \rightarrow Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%3AX+%5Crightarrow+Y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F:X \rightarrow Y}"/>. We can make the map surjective if we restrict <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> to be equal to <img alt="{F(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(X)}"/>. It is not so simple to make the map injective, but we can in general do that also. </p>
<blockquote><p><b>Theorem 1</b> <em><a name="choice"/> Let <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> be a surjective function from <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{X}"/> to <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{Y}"/>. Then there is a subset <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{X}"/> so that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> is injective from <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> to <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{Y}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  For each <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> in <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> select one <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> from the set <img alt="{F^{-1}(y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%5E%7B-1%7D%28y%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F^{-1}(y)}"/> and place it into <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. Recall <img alt="{F^{-1}(y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%5E%7B-1%7D%28y%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F^{-1}(y)}"/> is the set of <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/> so that <img alt="{F(z)=y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28z%29%3Dy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(z)=y}"/>.This of course uses the Axiom of Choice to make the choices of which <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> to choose. Then clearly <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> is the required set. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
The difficulty with this trivial theorem is that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> cannot be controlled easily if it is constructed via the Axiom of Choice. It could be a very complicated set. Our goal is to see how well we can control <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> if we assume that the mapping <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is smooth. </p>
<p>
How can we do better? The answer is quite a bit better if we assume that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is a “nice” function. We give up surjectivity onto <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> but only by a null set.</p>
<blockquote><p><b>Theorem 2</b> <em><a name="injective"/> Suppose that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> is a surjective smooth map from <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{X}"/> to <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{Y}"/> where <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{X}"/> and <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{Y}"/> are open subsets of <img alt="{{\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\mathbb R}}"/>. Also suppose that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> locally is invertible. Then there is a subset <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{X}"/> so that </em></p><em>
<ol>
<li>
The complement of <img alt="{F(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28S%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F(S)}"/> is a null set. <p/>
</li><li>
The map <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> is injective from <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> to <img alt="{F(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28S%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F(S)}"/>.
</li></ol>
</em><p><em>That is that for all distinct points <img alt="{\boldsymbol{a}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cboldsymbol%7Ba%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\boldsymbol{a}}"/> and <img alt="{\boldsymbol{b}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cboldsymbol%7Bb%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\boldsymbol{b}}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/>, <img alt="{F(\boldsymbol{a}) \neq F(\boldsymbol{b})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28%5Cboldsymbol%7Ba%7D%29+%5Cneq+F%28%5Cboldsymbol%7Bb%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F(\boldsymbol{a}) \neq F(\boldsymbol{b})}"/>. Moreover the map from <img alt="{F(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28S%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F(S)}"/> to <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> is smooth. </em>
</p></blockquote>
<p>
</p><p/><h2> Set Coverings </h2><p/>
<p/><p>
How can we prove this theorem? An obvious idea is to do the following. Pick an open interval <img alt="{U=[a,b]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%3D%5Ba%2Cb%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U=[a,b]}"/> in <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> so that <img alt="{F(U) = V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28U%29+%3D+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(U) = V}"/> for an open set in <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/> and so that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is injective from <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> to <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/>. Setting <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> to <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> clearly works: the map <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is injective on <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. This is far from the large set that we wish to have, but it is a start. The intuition is to select another open interval <img alt="{U'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U'}"/> that is disjoint from <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> so that again <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is injective from <img alt="{U'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U'}"/> to <img alt="{V'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V'}"/>. We can then add <img alt="{U'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U'}"/> to our <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. </p>
<p>
We can continue in this way and collect many open sets that we add to <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. Can we arrange that the union of these sets yield a <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> so that <img alt="{F(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(S)}"/> is most of <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>? In general the answer is no. Suppose that the intervals are the following: 	</p>
<p align="center"><img alt="\displaystyle  [k,k+1.1] " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Bk%2Ck%2B1.1%5D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  [k,k+1.1] "/></p>
<p>for <img alt="{k=0,1,2,\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D0%2C1%2C2%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k=0,1,2,\dots}"/> Roughly we can only get about half of the space that the intervals cover and keep the chosen intervals disjoint. If we select <img alt="{ [k,k+1.1] }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Bk%2Ck%2B1.1%5D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ [k,k+1.1] }"/> then we cannot select <img alt="{[k+1,k+1+1.1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bk%2B1%2Ck%2B1%2B1.1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[k+1,k+1+1.1]}"/> since 	</p>
<p align="center"><img alt="\displaystyle  [k,k+1.1] \cap [k+1,k+1+1.1] \neq \emptyset. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Bk%2Ck%2B1.1%5D+%5Ccap+%5Bk%2B1%2Ck%2B1%2B1.1%5D+%5Cneq+%5Cemptyset.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  [k,k+1.1] \cap [k+1,k+1+1.1] \neq \emptyset. "/></p>
<p>Vitali’s theorem comes to the rescue. It allows us to avoid his problem, by insisting that intervals have an additional property.</p>
<p>
</p><p/><h2> The Vitali Covering Theorem </h2><p/>
<p/><p>
The trick is to use a refinement of a set cover that allows a disjoint cover to exist for almost all of the target set. The next definition is critical to the Vitali covering theorem. </p>
<blockquote><p><b>Definition 3</b> <em> Let <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> be a subset of <img alt="{{\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\mathbb R}}"/>. Let <img alt="{[a_{\lambda},b_{\lambda}]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ba_%7B%5Clambda%7D%2Cb_%7B%5Clambda%7D%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{[a_{\lambda},b_{\lambda}]}"/> be intervals over <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\lambda}"/> in some index set <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{I}"/>. We say these intervals are a <b>cover</b> of <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> proved <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> is a subset of the union of all the intervals. Say the intervals also are a <b>Vitali</b> cover of <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> provided for all points <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x}"/> in <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> and all <img alt="{\epsilon &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\epsilon &gt; 0}"/>, there is an interval <img alt="{[c,d]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bc%2Cd%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{[c,d]}"/> that contains <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{0 &lt; d-c &lt; \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%3C+d-c+%3C+%5Cepsilon%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{0 &lt; d-c &lt; \epsilon}"/>. </em>
</p></blockquote>
<p/><p>
The Vitali theorem is the following: </p>
<blockquote><p><b>Theorem 4</b> <em> Let <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> be a subset of <img alt="{{\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\mathbb R}}"/>. Let <img alt="{[a_{\lambda},b_{\lambda}]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ba_%7B%5Clambda%7D%2Cb_%7B%5Clambda%7D%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{[a_{\lambda},b_{\lambda}]}"/> be intervals for <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\lambda}"/> in some index set <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{I}"/>. Assume that the family is a Vitali cover of <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/>. Then there is a countable subfamily of disjoints intervals in the family so that they cover all of <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> except for possibly a null set. </em>
</p></blockquote>
<p/><p>
The Vitali theorem can be extended to any finite dimensional space <img alt="{{\mathbb R}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb R}^{n}}"/>. Then intervals become disks and so on.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Do you see how to prove Theorem <a href="https://rjlipton.wordpress.com/feed/#injective">2</a> from Vitali’s theorem? The insight is now one can set up a Vitali covering of the space <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>. </p></font></font></div>
    </content>
    <updated>2019-02-23T04:58:34Z</updated>
    <published>2019-02-23T04:58:34Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Proofs"/>
    <category term="analysis"/>
    <category term="axiom of choice"/>
    <category term="Giuseppe Vitali"/>
    <category term="set coverings"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-02-23T07:20:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/022</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/022" rel="alternate" type="text/html"/>
    <title>TR19-022 |  Circuit Lower Bounds for MCSP from Local Pseudorandom Generators | 

	Valentine Kabanets, 

	Mahdi Cheraghchi, 

	Zhenjian Lu, 

	Dimitrios Myrisiotis</title>
    <summary>The Minimum Circuit Size Problem (MCSP) asks if a given truth table of a Boolean function $f$ can be computed by a Boolean circuit of size at most $\theta$, for a given parameter $\theta$. We improve several circuit lower bounds for MCSP, using pseudorandom generators (PRGs) that are local; a PRG is called local if its output bit strings, when viewed as the truth table of a Boolean function, can be computed by a Boolean circuit of small size. We get new and improved lower bounds for MCSP that almost match the best-known lower bounds against several circuit models. 

Specifically, we show that computing MCSP, on functions with a truth table of length $N$, requires

   $N^{3-o(1)}$-size de Morgan formulas, improving the recent $N^{2-o(1)}$ lower bound by Hirahara and Santhanam (CCC, 2017),
 $N^{2-o(1)}$-size formulas over an arbitrary basis or general branching programs (no non-trivial lower bound was known for MCSP against these models), and 
    $2^{\Omega\left(N^{1/(d+2.01)}\right)}$-size depth-$d$ $AC^0$ circuits, improving the superpolynomial lower bound by Allender et al. (SICOMP, 2006).

 
    	The $AC^0$ lower bound stated above matches the best-known $AC^0$ lower bound (for PARITY) up to a small additive constant in the depth. Also, for the special case of depth-$2$ circuits (i.e., CNFs or DNFs), we get an almost optimal lower bound of \(2^{N^{1-o(1)}}\) for MCSP.</summary>
    <updated>2019-02-23T01:22:32Z</updated>
    <published>2019-02-23T01:22:32Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-23T07:20:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.08179</id>
    <link href="http://arxiv.org/abs/1902.08179" rel="alternate" type="text/html"/>
    <title>Online Sampling from Log-Concave Distributions</title>
    <feedworld_mtime>1550793600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Holden.html">Holden Lee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mangoubi:Oren.html">Oren Mangoubi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vishnoi:Nisheeth_K=.html">Nisheeth K. Vishnoi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.08179">PDF</a><br/><b>Abstract: </b>Given a sequence of convex functions $f_0, f_1, \ldots, f_T$, we study the
problem of sampling from the Gibbs distribution $\pi_t \propto e^{-\sum_{k=0}^t
f_k}$ for each epoch $t$ in an online manner. This problem occurs in
applications to machine learning, Bayesian statistics, and optimization where
one constantly acquires new data, and must continuously update the
distribution. Our main result is an algorithm that generates independent
samples from a distribution that is a fixed $\varepsilon$ TV-distance from
$\pi_t$ for every $t$ and, under mild assumptions on the functions, makes
poly$\log(T)$ gradient evaluations per epoch. All previous results for this
problem imply a bound on the number of gradient or function evaluations which
is at least linear in $T$. While we assume the functions have bounded second
moment, we do not assume strong convexity. In particular, we show that our
assumptions hold for online Bayesian logistic regression, when the data satisfy
natural regularity properties. In simulations, our algorithm achieves accuracy
comparable to that of a Markov chain specialized to logistic regression. Our
main result also implies the first algorithm to sample from a $d$-dimensional
log-concave distribution $\pi_T \propto e^{-\sum_{k=0}^T f_k}$ where the
$f_k$'s are not assumed to be strongly convex and the total number of gradient
evaluations is roughly $T\log(T)+\mathrm{poly}(d),$ as opposed to $T\cdot
\mathrm{poly}(d)$ implied by prior works. Key to our algorithm is a novel
stochastic gradient Langevin dynamics Markov chain that has a carefully
designed variance reduction step built-in with fixed constant batch size.
Technically, lack of strong convexity is a significant barrier to the analysis,
and, here, our main contribution is a martingale exit time argument showing the
chain is constrained to a ball of radius roughly poly$\log(T)$ for the duration
of the algorithm.
</p></div>
    </summary>
    <updated>2019-02-22T23:23:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.08091</id>
    <link href="http://arxiv.org/abs/1902.08091" rel="alternate" type="text/html"/>
    <title>On the qubit routing problem</title>
    <feedworld_mtime>1550793600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Alexander Cowtan, Silas Dilkes, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Duncan:Ross.html">Ross Duncan</a>, Alexandre Krajenbrink, Will Simmons, Seyon Sivarajah <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.08091">PDF</a><br/><b>Abstract: </b>We introduce a new architecture-agnostic methodology for mapping abstract
quantum circuits to realistic quantum computing devices with restricted qubit
connectivity, as implemented by Cambridge Quantum Computing's tket compiler. We
present empirical results showing the effectiveness of this method in terms of
reducing two-qubit gate depth and two-qubit gate count, compared to other
implementations.
</p></div>
    </summary>
    <updated>2019-02-22T23:22:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.08086</id>
    <link href="http://arxiv.org/abs/1902.08086" rel="alternate" type="text/html"/>
    <title>The Arboricity Captures the Complexity of Sampling Edges</title>
    <feedworld_mtime>1550793600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eden:Talya.html">Talya Eden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ron:Dana.html">Dana Ron</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rosenbaum:Will.html">Will Rosenbaum</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.08086">PDF</a><br/><b>Abstract: </b>In this paper, we revisit the problem of sampling edges in an unknown graph
$G = (V, E)$ from a distribution that is (pointwise) almost uniform over $E$.
We consider the case where there is some a priori upper bound on the arboriciy
of $G$. Given query access to a graph $G$ over $n$ vertices and of average
degree $d$ and arboricity at most $\alpha$, we design an algorithm that
performs $O\!\left(\frac{\alpha}{d} \cdot \frac{\log^3 n}{\varepsilon}\right)$
queries in expectation and returns an edge in the graph such that every edge $e
\in E$ is sampled with probability $(1 \pm \varepsilon)/m$. The algorithm
performs two types of queries: degree queries and neighbor queries. We show
that the upper bound is tight (up to poly-logarithmic factors and the
dependence in $\varepsilon$), as $\Omega\!\left(\frac{\alpha}{d} \right)$
queries are necessary for the easier task of sampling edges from any
distribution over $E$ that is close to uniform in total variational distance.
We also prove that even if $G$ is a tree (i.e., $\alpha = 1$ so that
$\frac{\alpha}{d}=\Theta(1)$), $\Omega\left(\frac{\log n}{\log\log n}\right)$
queries are necessary to sample an edge from any distribution that is pointwise
close to uniform, thus establishing that a $\mathrm{poly}(\log n)$ factor is
necessary for constant $\alpha$. Finally we show how our algorithm can be
applied to obtain a new result on approximately counting subgraphs, based on
the recent work of Assadi, Kapralov, and Khanna (ITCS, 2019).
</p></div>
    </summary>
    <updated>2019-02-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.08069</id>
    <link href="http://arxiv.org/abs/1902.08069" rel="alternate" type="text/html"/>
    <title>With Great Speed Come Small Buffers: Space-Bandwidth Tradeoffs for Routing</title>
    <feedworld_mtime>1550793600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Miller:Avery.html">Avery Miller</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patt=Shamir:Boaz.html">Boaz Patt-Shamir</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rosenbaum:Will.html">Will Rosenbaum</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.08069">PDF</a><br/><b>Abstract: </b>We consider the Adversarial Queuing Theory (AQT) model, where packet arrivals
are subject to a maximum average rate $0\le\rho\le1$ and burstiness
$\sigma\ge0$. In this model, we analyze the size of buffers required to avoid
overflows in the basic case of a path. Our main results characterize the space
required by the average rate and the number of distinct destinations: we show
that $O(k d^{1/k})$ space suffice, where $d$ is the number of distinct
destinations and $k=\lfloor 1/\rho \rfloor$; and we show that $\Omega(\frac 1 k
d^{1/k})$ space is necessary. For directed trees, we describe an algorithm
whose buffer space requirement is at most $1 + d' + \sigma$ where $d'$ is the
maximum number of destinations on any root-leaf path.
</p></div>
    </summary>
    <updated>2019-02-22T23:26:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.08053</id>
    <link href="http://arxiv.org/abs/1902.08053" rel="alternate" type="text/html"/>
    <title>On the hardness of computing an average curve</title>
    <feedworld_mtime>1550793600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Buchin:Kevin.html">Kevin Buchin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Driemel:Anne.html">Anne Driemel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Struijs:Martijn.html">Martijn Struijs</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.08053">PDF</a><br/><b>Abstract: </b>We study the complexity of clustering curves under $k$-median and $k$-center
objectives in the metric space of the Fr\'echet distance and related distance
measures. The $k$-center problem has recently been shown to be NP-hard, even in
the case where $k=1$, i.e. the minimum enclosing ball under the Fr\'echet
distance. We extend these results by showing that also the $k$-median problem
is NP-hard for $k=1$. Furthermore, we show that the $1$-median problem is
W[1]-hard with the number of curves as parameter. We show this under the
discrete and continuous Fr\'echet and Dynamic Time Warping (DTW) distance. Our
result generalizes an earlier result by Bulteau et al. from 2018 for a variant
of DTW that uses squared distances. Moreover, closing some gaps in the
literature, we show positive results for a variant where the center curve may
have complexity at most $\ell$ under the discrete Fr\'echet distance. In
particular, for fixed $k,\ell$ and $\varepsilon$, we give
$(1+\varepsilon)$-approximation algorithms for the $(k,\ell)$-median and
$(k,\ell)$-center objectives and a polynomial-time exact algorithm for the
$(k,\ell)$-center objective.
</p></div>
    </summary>
    <updated>2019-02-22T23:30:13Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.08042</id>
    <link href="http://arxiv.org/abs/1902.08042" rel="alternate" type="text/html"/>
    <title>Fault Tolerant Gradient Clock Synchronization</title>
    <feedworld_mtime>1550793600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bund:Johannes.html">Johannes Bund</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lenzen:Christoph.html">Christoph Lenzen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rosenbaum:Will.html">Will Rosenbaum</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.08042">PDF</a><br/><b>Abstract: </b>Synchronizing clocks in distributed systems is well-understood, both in terms
of fault-tolerance in fully connected systems and the dependence of local and
global worst-case skews (i.e., maximum clock difference between neighbors and
arbitrary pairs of nodes, respectively) on the diameter of fault-free systems.
However, so far nothing non-trivial is known about the local skew that can be
achieved in topologies that are not fully connected even under a single
Byzantine fault. Put simply, in this work we show that the most powerful known
techniques for fault-tolerant and gradient clock synchronization are
compatible, in the sense that the best of both worlds can be achieved
simultaneously.
</p>
<p>Concretely, we combine the Lynch-Welch algorithm [Welch1988] for
synchronizing a clique of $n$ nodes despite up to $f&lt;n/3$ Byzantine faults with
the gradient clock synchronization (GCS) algorithm by Lenzen et al.
[Lenzen2010] in order to render the latter resilient to faults. As this is not
possible on general graphs, we augment an input graph $\mathcal{G}$ by
replacing each node by $3f+1$ fully connected copies, which execute an instance
of the Lynch-Welch algorithm. We then interpret these clusters as supernodes
executing the GCS algorithm, where for each cluster its correct nodes'
Lynch-Welch clocks provide estimates of the logical clock of the supernode in
the GCS algorithm. By connecting clusters corresponding to neighbors in
$\mathcal{G}$ in a fully bipartite manner, supernodes can inform each other
about (estimates of) their logical clock values. This way, we achieve
asymptotically optimal local skew, granted that no cluster contains more than
$f$ faulty nodes, at factor $O(f)$ and $O(f^2)$ overheads in terms of nodes and
edges, respectively. Note that tolerating $f$ faulty neighbors trivially
requires degree larger than $f$, so this is asymptotically optimal as well.
</p></div>
    </summary>
    <updated>2019-02-22T23:26:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07928</id>
    <link href="http://arxiv.org/abs/1902.07928" rel="alternate" type="text/html"/>
    <title>Locality</title>
    <feedworld_mtime>1550793600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iacono:John.html">John Iacono</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jayapaul:Varunkumar.html">Varunkumar Jayapaul</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karsin:Ben.html">Ben Karsin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07928">PDF</a><br/><b>Abstract: </b>The performance of modern computation is characterized by locality of
reference, that is, it is cheaper to access data that has been accessed
recently than a random piece of data. This is due to many architectural
features including caches, lookahead, address translation and the physical
properties of a hard disk drive; attempting to model all the components that
constitute the performance of a modern machine is impossible, especially for
general algorithm design purposes. What if one could prove an algorithm is
asymptotically optimal on all systems that reward locality of reference, no
matter how it manifests itself within reasonable limits? We show that this is
possible, and that algorithms that are asymptotically optimal in the
cache-oblivious model are asymptotically optimal in any reasonable
locality-of-reference rewarding setting. This is surprising as the
cache-oblivious model envisions a particular architectural model involving
blocked memory transfer into a multi-level hierarchy of caches of varying
sizes, and was not designed to directly model locality-of-reference correlated
performance.
</p></div>
    </summary>
    <updated>2019-02-22T23:24:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07856</id>
    <link href="http://arxiv.org/abs/1902.07856" rel="alternate" type="text/html"/>
    <title>The Markovian Price of Information</title>
    <feedworld_mtime>1550793600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Anupam.html">Anupam Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Haotian.html">Haotian Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scully:Ziv.html">Ziv Scully</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singla:Sahil.html">Sahil Singla</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07856">PDF</a><br/><b>Abstract: </b>Suppose there are $n$ Markov chains and we need to pay a per-step
\emph{price} to advance them. The "destination" states of the Markov chains
contain rewards; however, we can only get rewards for a subset of them that
satisfy a combinatorial constraint, e.g., at most $k$ of them, or they are
acyclic in an underlying graph. What strategy should we choose to advance the
Markov chains if our goal is to maximize the total reward \emph{minus} the
total price that we pay?
</p>
<p>In this paper we introduce a Markovian price of information model to capture
settings such as the above, where the input parameters of a combinatorial
optimization problem are given via Markov chains. We design
optimal/approximation algorithms that jointly optimize the value of the
combinatorial problem and the total paid price. We also study \emph{robustness}
of our algorithms to the distribution parameters and how to handle the
\emph{commitment} constraint.
</p>
<p>Our work brings together two classical lines of investigation: getting
optimal strategies for Markovian multi-armed bandits, and getting exact and
approximation algorithms for discrete optimization problems using combinatorial
as well as linear-programming relaxation ideas.
</p></div>
    </summary>
    <updated>2019-02-22T23:28:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07823</id>
    <link href="http://arxiv.org/abs/1902.07823" rel="alternate" type="text/html"/>
    <title>Stable and Fair Classification</title>
    <feedworld_mtime>1550793600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Lingxiao.html">Lingxiao Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vishnoi:Nisheeth_K=.html">Nisheeth K. Vishnoi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07823">PDF</a><br/><b>Abstract: </b>Fair classification has been a topic of intense study in machine learning,
and several algorithms have been proposed towards this important task. However,
in a recent study, Friedler et al. observed that fair classification algorithms
may not be stable with respect to variations in the training dataset -- a
crucial consideration in several real-world applications. Motivated by their
work, we study the problem of designing classification algorithms that are both
fair and stable. We propose an extended framework based on fair classification
algorithms that are formulated as optimization problems, by introducing a
stability-focused regularization term. Theoretically, we prove a stability
guarantee, that was lacking in fair classification algorithms, and also provide
an accuracy guarantee for our extended framework. Our accuracy guarantee can be
used to inform the selection of the regularization parameter in our framework.
To the best of our knowledge, this is the first work that combines stability
and fairness in automated decision-making tasks. We assess the benefits of our
approach empirically by extending several fair classification algorithms that
are shown to achieve the best balance between fairness and accuracy over the
Adult dataset. Our empirical results show that our framework indeed improves
the stability at only a slight sacrifice in accuracy.
</p></div>
    </summary>
    <updated>2019-02-22T23:23:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07812</id>
    <link href="http://arxiv.org/abs/1902.07812" rel="alternate" type="text/html"/>
    <title>Finding big matchings in planar graphs quickly</title>
    <feedworld_mtime>1550793600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Therese Biedl <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07812">PDF</a><br/><b>Abstract: </b>It is well-known that every $n$-vertex planar graph with minimum degree 3 has
a matching of size at least $\frac{n}{3}$. But all proofs of this use the
Tutte-Berge-formula for the size of a maximum matching. Hence these proofs are
not directly algorithmic, and to find such a matching one must apply a
general-purposes maximum matching algorithm, which has run-time
$O(n^{1.5}\alpha(n))$ for planar graphs. In contrast to this, this paper gives
a linear-time algorithm that finds a matching of size at least $\frac{n}{3}$ in
any planar graph with minimum degree 3.
</p></div>
    </summary>
    <updated>2019-02-22T23:27:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07785</id>
    <link href="http://arxiv.org/abs/1902.07785" rel="alternate" type="text/html"/>
    <title>Counting basic-irreducible factors mod $p^k$ in deterministic poly-time and $p$-adic applications</title>
    <feedworld_mtime>1550793600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dwivedi:Ashish.html">Ashish Dwivedi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mittal:Rajat.html">Rajat Mittal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saxena:Nitin.html">Nitin Saxena</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07785">PDF</a><br/><b>Abstract: </b>Finding an irreducible factor, of a polynomial $f(x)$ modulo a prime $p$, is
not known to be in deterministic polynomial time. Though there is such a
classical algorithm that {\em counts} the number of irreducible factors of
$f\bmod p$. We can ask the same question modulo prime-powers $p^k$. The
irreducible factors of $f\bmod p^k$ blow up exponentially in number; making it
hard to describe them. Can we count those irreducible factors $\bmod~p^k$ that
remain irreducible mod $p$? These are called {\em basic-irreducible}. A simple
example is in $f=x^2+px \bmod p^2$; it has $p$ many basic-irreducible factors.
Also note that, $x^2+p \bmod p^2$ is irreducible but not basic-irreducible!
</p>
<p>We give an algorithm to count the number of basic-irreducible factors of
$f\bmod p^k$ in deterministic poly(deg$(f),k\log p$)-time. This solves the open
questions posed in (Cheng et al, ANTS'18 \&amp; Kopp et al, Math.Comp.'19). In
particular, we are counting roots $\bmod\ p^k$; which gives the first
deterministic poly-time algorithm to compute Igusa zeta function of $f$. Also,
our algorithm efficiently partitions the set of all basic-irreducible factors
(possibly exponential) into merely deg$(f)$-many disjoint sets, using a compact
tree data structure and {\em split} ideals.
</p></div>
    </summary>
    <updated>2019-02-22T23:22:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.06749</id>
    <link href="http://arxiv.org/abs/1902.06749" rel="alternate" type="text/html"/>
    <title>A Quantum IP Predictor-Corrector Algorithm for Linear Programming</title>
    <feedworld_mtime>1550793600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>P. A. M. Casares, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Martin=Delgado:M=_A=.html">M. A. Martin-Delgado</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.06749">PDF</a><br/><b>Abstract: </b>We introduce a new quantum optimization algorithm for Linear Programming (LP)
problems based on Interior Point (IP) Predictor-Corrector (PC) methods whose
(worst case) time complexity is $O(\sqrt{n}Ls^3 k \epsilon^{-1}\epsilon_s^{-1})
$. This represents a quantum speed-up in the number $n$ of variables in the
cost function with respect to the comparable classical Interior Point (IP)
algorithms that behave as $O((n+m)\sqrt{nk}L
s^3\log(\epsilon^{-1})\epsilon_s^{-1})$ or $O(\sqrt{n}(n+m)L)$ depending on the
technique employed, where $m$ is the number of constraints and the rest of the
variables are defined in the introduction. The average time complexity of our
algorithm is $O(\sqrt{n}s^3 k \epsilon^{-1}\epsilon_s^{-1})$, which equals the
behaviour on $n$ of quantum Semidefinite Programming (SDP) algorithms based on
multiplicative weight methods when restricted to LP problems and heavily
improves on the precision $\epsilon^{-1}$ of the algorithm. Unlike the quantum
SDP algorithm, the quantum PC algorithm does not depend on size parameters of
the primal and dual LP problems ($R,r$), and outputs a feasible and optimal
solution whenever it exists.
</p></div>
    </summary>
    <updated>2019-02-22T23:28:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors</id>
    <link href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html" rel="alternate" type="text/html"/>
    <title>Mutual nearest neighbors versus closest pairs</title>
    <summary>In the 1990s I published a series of papers on data structures for closest pairs. As long as you already know how to maintain dynamic sets of objects of some type, and answer nearest-neighbor queries among them, you can also keep track of the closest pair, and this can be used as a subroutine in many other computational geometry algorithms. But it turns out that many of those algorithms can now be simplified and sped up by using mutual nearest neighbors (pairs of objects that are each other’s nearest neighbors) instead of closest pairs.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In the 1990s I published a series of papers on data structures for closest pairs. As long as you already know how to maintain dynamic sets of objects of some type, and answer nearest-neighbor queries among them, you can also keep track of the closest pair, and this can be used as a subroutine in many other
computational geometry algorithms. But it turns out that many of those algorithms can now be simplified and sped up by using mutual nearest neighbors (pairs of objects that are each other’s nearest neighbors) instead of closest pairs.</p>

<p>My original motivation for studying these types of problems was to maintain minimum spanning trees of dynamic point sets, using closest red-blue pairs of Euclidean points,<sup id="fnref:aem"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:aem">1</a></sup> <sup id="fnref:ebf"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:ebf">2</a></sup> and I later found more applications in hierarchical clustering, greedy matching, traveling salesperson heuristics,<sup id="fnref:fhc"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:fhc">3</a></sup> <sup id="fnref:lazy"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:lazy">4</a></sup> and (with Jeff Erickson) motorcycle graphs and <a href="https://en.wikipedia.org/wiki/Straight_skeleton">straight skeletons</a>.<sup id="fnref:ee"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:ee">5</a></sup> But to use these closest pair data structures, you have to pay two logarithmic factors in time complexity over the time for the underlying nearest-neighbor data structure. So they’re not competitive with (uncolored) Euclidean closest pair data structures, which take only logarithmic time in any fixed dimension. Instead they make more sense to use with other distances than Euclidean, with objects more complicated than single points, or with variations like the red-blue closest pair for which the logarithmic-time solution doesn’t work.</p>

<p>For several variations of hierarchical clustering, an alternative and simpler technique has been known for quite a bit longer, based on finding mutual nearest neighbors (pairs of objects that are nearer to each other than to anything else) rather than closest pairs.<sup id="fnref:ben"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:ben">6</a></sup> <sup id="fnref:juan"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:juan">7</a></sup> It’s called the <a href="https://en.wikipedia.org/wiki/Nearest-neighbor_chain_algorithm">nearest neighbor chain algorithm</a>, but really it’s a data structure rather than an algorithm, one that allows you to maintain a dynamic point set and find pairs of mutual nearest neighbors, again based on calls to an underlying nearest neighbor data structure. The idea is to maintain a stack of shorter and shorter pairs of nearest neighbors, until the two objects whose distance is on the top of the stack have nothing nearer – they are mutual nearest neighbors. Whenever you want a pair of neighbors, you look at the top pair, an object  and its nearest neighbor , and ask whether ’s nearest neighbor is . If so, you have found a mutual nearest neighbor pair, and if not you have a new shorter distance to push onto the stack.</p>

<p>One can this in a hierarchical clustering algorithm that repeatedly finds and merges the nearest two clusters, whenever the distance between clusters has a special property: a merged cluster is never closer to other clusters than the closer of the two clusters that was merged. This property implies both that the stack of distances remains valid after the merge, and that mutual nearest neighbors are always safe to merge. If two clusters are mutual nearest neighbors, then the closest-pair clustering algorithm will eventually merge them, because none of its actions can cause them to stop being mutual nearest neighbors. So we might as well merge them immediately once we discover them to be mutual nearest neighbors. (One way to formulate this mathematically is that the set of mutual nearest neighbor pairs merged by the clustering algorithm forms an <a href="https://en.wikipedia.org/wiki/Antimatroid">antimatroid</a>). When this works, you get a clustering algorithm that uses a linear number of nearest neighbor queries, instead of the  queries that you would get using my closest-pair data structures.</p>

<p>In more recent research with UCI student Nil Mamano (finishing his doctorate this year; hire him for a postdoc, he’s good!) we noticed that the nearest neighbor chain algorithm can also be applied to certain <a href="https://11011110.github.io/blog/2017/04/11/stable-grid-matching.html">stable marriage problems with preferences coming from geometric distances</a>.<sup id="fnref:egm"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:egm">8</a></sup> Our latest preprint, “Euclidean TSP, Motorcycle Graphs, and Other New Applications of Nearest-Neighbor Chains” (with Efrat, Frishberg, Goodrich, Kobourov, Mamano, Matias, and Polishchuk, <a href="https://arxiv.org/abs/1902.06875">arXiv:1902.06875</a>) extends this to a much broader set of applications. As well as simplifying and speeding up my previous work on motorcycle graphs and TSP heuristics, we also use nearest neighbor chains in a bigger class of stable matching problems and in an approximate geometric set cover problem. In each case, we need to show either that the problem has an antimatroid-like property (so using mutual nearest neighbors produces the same solution as closest pairs) or that, even when varying from the same solution, it achieves the same quality. It’s not quite true that anything closest pairs can do, mutual nearest neighbors can do better, but it’s close.</p>

<p>Another idea in the paper is that to find (exact!) mutual nearest neighbor pairs one can sometimes get away with using approximate near neighbor structures. This is important if you’re using Euclidean distance, because the time bounds for exact nearest neighbors have the form  for constants  that get very small as  gets large, while approximate nearest neighbors are logarithmic in all dimensions. The idea is to build the stack of shorter distances by asking for a constant number of approximate near neighbors, the th of which is within a constant factor of the distance to the actual th nearest neighbor. By a packing argument for points in Euclidean space, either some two of these points are closer to each other than the distance on the current stack top (in which case you can build the stack one more level) or these approximate neighbors are guaranteed to contain the actual nearest neighbor (in which case you can either detect a mutual nearest neighbor pair or again build the stack).
This idea leads, for instance, to an algorithm for the <a href="https://en.wikipedia.org/wiki/Multi-fragment_algorithm">multi-fragment TSP heuristic</a> that takes time  in Euclidean spaces of any bounded dimension; the best previous time appears to be an -time algorithm (valid in any metric space) from one of my previous papers.<sup id="fnref:fhc:1"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:fhc">3</a></sup></p>

<div class="footnotes">
  <ol>
    <li id="fn:aem">
      <p>Agarwal, P. K., Eppstein, D., and Matoušek, J., “<a href="https://www.ics.uci.edu/~eppstein/pubs/AgaEppMat-FOCS-92.pdf">Dynamic algorithms for half-space reporting, proximity problems, and geometric minimum spanning trees</a>”, <em>FOCS</em>, 1992, pp. 80–89. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:aem">↩</a></p>
    </li>
    <li id="fn:ebf">
      <p>Eppstein, D., “<a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-DCG-95.pdf">Dynamic Euclidean minimum spanning trees and extrema of binary functions</a>”, <em>Discrete Comput. Geom.</em> 13: 111–122, 1995. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:ebf">↩</a></p>
    </li>
    <li id="fn:fhc">
      <p>Eppstein, D., “Fast hierarchical clustering and other applications of dynamic closest pairs”, <em>SODA</em>, 1998, pp. 619–628, <a href="https://arxiv.org/abs/cs.DS/9912014">arXiv:cs.DS/9912014</a>, <em>J. Experimental Algorithmics</em> 5 (1): 1–23, 2000. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:fhc">↩</a> <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:fhc:1">↩<sup>2</sup></a></p>
    </li>
    <li id="fn:lazy">
      <p>Cardinal, J., and Eppstein, D., “<a href="https://www.siam.org/meetings/alenex04/abstacts/JCardinal.pdf">Lazy algorithms for dynamic closest pair with arbitrary distance measures</a>”, <em>ALENEX</em>, 2004, pp. 112–119. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:lazy">↩</a></p>
    </li>
    <li id="fn:ee">
      <p>Eppstein, D., and Erickson, J., “<a href="http://jeffe.cs.illinois.edu/pubs/pdf/cycles.pdf">Raising roofs, crashing cycles, and playing pool: applications of a data structure for finding pairwise interactions</a>”, <em>SoCG</em>, 1998, pp. 58–67, <em>Discrete Comput. Geom.</em> 22 (4): 569–592, 1999. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:ee">↩</a></p>
    </li>
    <li id="fn:ben">
      <p>Benzécri, J.-P. (1982), “<a href="http://www.numdam.org/item?id=CAD_1982__7_2_209_0">Construction d’une classification ascendante hiérarchique par la recherche en chaîne des voisins réciproques</a>”, Les Cahiers de l’Analyse des Données, 7 (2): 209–218. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:ben">↩</a></p>
    </li>
    <li id="fn:juan">
      <p>Juan, J. (1982), “<a href="http://www.numdam.org/item?id=CAD_1982__7_2_219_0">Programme de classification hiérarchique par l’algorithme de la recherche en chaîne des voisins réciproques</a>”, <em>Les Cahiers de l’Analyse des Données</em>, 7 (2): 219–225. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:juan">↩</a></p>
    </li>
    <li id="fn:egm">
      <p>Eppstein, D., Goodrich, M. T., and Mamano, N., “Algorithms for stable matching and clustering in a grid”, <a href="https://arxiv.org/abs/1704.02303">arXiv:1704.02303</a>, <em>IWCIA</em> 2017, LNCS 10256 (2017), pp. 117–131. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:egm">↩</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/101634032916499158">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-02-21T21:06:00Z</updated>
    <published>2019-02-21T21:06:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-02-22T05:13:03Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4944416293302133989</id>
    <link href="https://blog.computationalcomplexity.org/feeds/4944416293302133989/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/extra-extra-read-all-about-it.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4944416293302133989" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4944416293302133989" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/extra-extra-read-all-about-it.html" rel="alternate" type="text/html"/>
    <title>Extra! Extra! Read all about it!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Last weekend I saw the documentary <a href="https://www.imdb.com/title/tt7428030/">Joseph Pulitzer: Voice of the People</a>. Pulitzer, as you probably know from the prize named after him, was a major newspaper publisher in the late 19th and early 20th century. He ran two papers, the St. Louis Post-Dispatch and The New York World. The World at one point took on massive proportions, including sheet music of the latest tunes and dress patterns of new fashion that one could make at home. The World was the Internet of the turn of the 20th century.<br/>
<br/>
The movie mentioned the many editions of the paper during the day, including the extra edition. An extra edition came out because of some major breaking news story. Back then newspapers would drum up minor stories to sell extra editions but they tended to disappear over time.<br/>
<br/>
Which brings me to Monday, August 19, 1991. Hard-line members of the communist party of the USSR <a href="https://en.wikipedia.org/wiki/1991_Soviet_coup_d%27%C3%A9tat_attempt">attempted a coup</a> to take over the government from Mikhail Gorbachev. To us in the US, this seemed like the cold war which appeared to be coming to an end might rekindle. At the time I lived in Chicago and on that Monday the Chicago Tribune ran an extra afternoon edition talking about the coup. The return to the cold war didn't happen. Within a couple of days the coup failed and if anything hastened the dissolution of the Soviet Republic.<br/>
<br/>
That was probably the last of the extra editions. By the time of the next major historical event, ten years and twenty-three days later, we had the Internet and cell phones and one no longer needed a newspaper to tell you the world has changed.</div>
    </content>
    <updated>2019-02-21T12:42:00Z</updated>
    <published>2019-02-21T12:42:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-23T07:12:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/021</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/021" rel="alternate" type="text/html"/>
    <title>TR19-021 |  $AC^0[p]$ Lower Bounds and NP-Hardness for Variants of MCSP | 

	Rahul Ilango</title>
    <summary>The Minimum Circuit Size Problem (MCSP) asks whether a (given) Boolean function has a circuit of at most a (given) size. Despite over a half-century of study, we know relatively little about the computational complexity of MCSP. We do know that questions about the complexity of MCSP have significant ramifications on longstanding open problems. In a recent development, Golovnev et al. [11] improves the status of unconditional lower bounds for MCSP, showing that MCSP is not in $AC^0[p]$ for any prime $p$. While their results generalize to most "typical" circuit classes, it fails to generalize to the circuit minimization problem for depth-d formulas, denoted ($AC^0_d$)-MCSP. In particular, their result relies on a Lipchitz hypothesis that is unknown (and possibly false) in the case of ($AC^0_d$)-MCSP. Despite this, we show that ($AC^0_d$)-MCSP is not in $AC^0[p]$ by proving even the failure of the Lipchitzness for $AC^0_d$ formulas implies that MAJORITY reduces to ($AC^0_d$)-MCSP under $AC^0$ truth table reductions. Somewhat remarkably, our proof (in the case of non-Lipchitzness) uses completely different techniques than [11]. To our knowledge, this is the first MCSP reduction that uses modular properties of a function's circuit complexity.

We also define MOCSP, an oracle version of MCSP that takes as input a Boolean function $f$, a size threshold $s$, and oracle Boolean functions $f_1, ..., f_t$, and determines whether there is an oracle circuit of size at most $s$ that computes $f$ when given access to $f_1, ... , f_t$. We prove that MOCSP is $NP$-complete under non-uniform $AC^0$ many-one reductions as well as (uniform) $ZPP$ truth table reductions. We also observe that improving this $ZPP$ reduction to a deterministic polynomial-time reduction requires showing $EXP \neq ZPP$ (using theorems of Hitchcock and Pavan [17] and Murray and Williams [22]). Optimistically, these MOCSP results could be a first step towards $NP$-hardness results for MCSP. At the very least, we believe MOCSP clarifies the barriers towards proving hardness for MCSP and provides a useful "testing ground" for questions about MCSP.</summary>
    <updated>2019-02-19T18:24:23Z</updated>
    <published>2019-02-19T18:24:23Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-23T07:20:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/020</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/020" rel="alternate" type="text/html"/>
    <title>TR19-020 |  On Tseitin formulas, read-once branching programs and treewidth | 

	Ludmila Glinskih, 

	Dmitry Itsykson</title>
    <summary>We show that any nondeterministic read-once branching program that computes a satisfiable Tseitin formula based on an $n\times n$ grid graph has size at least $2^{\Omega(n)}$. Then using the Excluded Grid Theorem by Robertson and Seymour we show that for arbitrary graph $G(V,E)$ any nondeterministic read-once branching program that computes a satisfiable Tseitin formula based on $G$ has size at least $2^{\Omega(tw(G)^\delta)}$ for all $\delta &lt;1/36$, where $tw(G)$ is the treewidth of $G$ (for planar graphs and some other classes of graphs the statement holds for $\delta=1$). We also show an upper bound $O(|E| 2^{pw(G)})$, where $pw(G)$ is the pathwidth of $G$.

We apply the mentioned results in the analysis of the complexity of derivation in the proof system $OBDD(\land, reordering)$ and show that any $OBDD(\land, reordering)$-refutation of an unsatisfiable Tseitin formula based on a graph $G$ has size at least $2^{\Omega(tw(G)^\delta)}$.</summary>
    <updated>2019-02-19T18:23:06Z</updated>
    <published>2019-02-19T18:23:06Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-23T07:20:43Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-6555947.post-267883685398120378</id>
    <link href="http://blog.geomblog.org/feeds/267883685398120378/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.geomblog.org/2019/02/openai-ai-threats-and-norm-building-for.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/6555947/posts/default/267883685398120378" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/6555947/posts/default/267883685398120378" rel="self" type="application/atom+xml"/>
    <link href="http://feedproxy.google.com/~r/TheGeomblog/~3/5TqtLogn5Gg/openai-ai-threats-and-norm-building-for.html" rel="alternate" type="text/html"/>
    <title>OpenAI, AI threats, and norm-building for responsible (data) science</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">All of twitter is .... atwitter?... over the <a href="https://blog.openai.com/better-language-models/">OpenAI announcement</a> and partial non-release of code/documentation for a language model that purports to generate realistic-sounding text from simple prompts. The system actually addresses many NLP tasks, but the one that's drawing the most attention is the deepfakes-like generation of plausible news copy (<a href="https://blog.openai.com/better-language-models/#sample3">here's one sample</a>).<br/><br/>Most consternation is over the rapid PR buzz around the announcement, including somewhat breathless headlines (that OpenAI is not responsible for) like<br/><br/><blockquote class="tr_bq"><a href="https://techcrunch.com/2019/02/17/openai-text-generator-dangerous/">OpenAI built a text generator so good, it’s considered too dangerous to release</a></blockquote>or<br/><blockquote class="tr_bq"><a href="https://arstechnica.com/information-technology/2019/02/researchers-scared-by-their-own-work-hold-back-deepfakes-for-text-ai/">Researchers, scared by their own work, hold back “deepfakes for text” AI</a></blockquote>There are concerns that OpenAI is overhyping solid but incremental work, that they're disingenuously allowing for overhyped coverage in the way they released the information, or worse that they're deliberately controlling hype as a publicity stunt.<br/><br/>I have nothing useful to add to the discussion above: indeed, see posts by <a href="https://anima-ai.org/2019/02/18/an-open-and-shut-case-on-openai/">Anima Anandkumar,</a> <a href="https://towardsdatascience.com/should-i-open-source-my-model-1c109188b164">Rob Munro</a>, <a href="http://approximatelycorrect.com/2019/02/17/openai-trains-language-model-mass-hysteria-ensues/">Zachary Lipton</a>  and <a href="https://medium.com/@lowe.ryan.t/openais-gpt-2-the-model-the-hype-and-the-controversy-1109f4bfd5e8?sk=bc319cebc22fe0459574544828c84c6d">Ryan Lowe</a> for a comprehensive discussion of the issues relating to OpenAI.  Jack Clark from OpenAI has been engaging in a lot of twitter discussion on this as well.<br/><br/>But what I do want to talk about is the larger issues around responsible science that this kerfuffle brings up. Caveat, as Margaret Mitchell puts it in this searing thread.<br/><blockquote class="twitter-tweet"><div dir="ltr" lang="en">It's really hard to watch the GPT-2 conversations unfold like so much else in tech. 1/</div>— MMitchell (@mmitchell_ai) <a href="https://twitter.com/mmitchell_ai/status/1097626427048964098?ref_src=twsrc%5Etfw">February 18, 2019</a></blockquote><br/>To understand the kind of "norm-building" that needs to happen here, let's look at two related domains.<br/><br/>In computer security, there's a fairly well-established model for finding weaknesses in systems. An exploit is discovered, the vulnerable entity is given a chance to fix it, and then the exploit is revealed , often simultaneously with patches that rectify it. Sometimes the vulnerability isn't easily fixed (see <a href="https://meltdownattack.com/">Meltdown and Spectre</a>). But it's still announced.<br/><br/>A defining characteristic of security exploits is that they are targeted, specific and usually suggest a direct patch. The harms might be theoretical, but are still considered with as much seriousness as the exploit warrants.<br/><br/>Let's switch to a different domain: biology. Starting from the sequencing of the human genome through the <a href="https://allofus.nih.gov/">million-person precision medicine project </a>to CRISPR and cloning babies, genetic manipulation has provided both invaluable technology for curing disease as well as grave ethical concerns about misuse of the technology. And professional organizations as well as the NIH have (sometimes slowly) risen to the challenge of articulating norms around the use and misuse of such technology.<br/><br/>Here, the harms are often more diffuse, and the harms are harder to separate from the benefits. But the harm articulation is often focused on the individual patient, especially given the shadow of abuse that darkens the history of medicine.<br/><br/>The harms with various forms of AI/ML technology are myriad and diffuse. They can cause structural damage to society - in the concerns over bias, the ways in which automation affects labor, the way in which fake news can erode trust and a common frame of truth, and so many others - and they can cause direct harm to individuals. And the scale at which these harms can happen is immense.<br/><br/>So where are the professional groups, the experts in thinking about the risks of democratization of ML, and all the folks concerned about the harms associated with AI tech? Why don't we have the equivalent of the <a href="https://en.wikipedia.org/wiki/Asilomar_Conference_on_Recombinant_DNA">Asilomar conference on recombinant DNA</a>?<br/><br/>I appreciate that OpenAI has at least raised the issue of thinking through the ethical ramifications of releasing technology. But as the furore over their decision has shown, no single imperfect actor can really claim to be setting the guidelines for ethical technology release, and "starting the conversation" doesn't count when (again as Margaret Mitchell points out) these kinds of discussions have been going on in different settings for many years already.<br/><br/>Ryan Lowe suggests workshops at major machine learning conferences. That's not a bad idea. But it will attract the people who go to machine learning conferences. It won't bring in the journalists, the people getting SWAT'd (and one case <a href="https://en.wikipedia.org/wiki/2017_Wichita_swatting">killed</a>) by fake news, the women being harassed by trolls online with deep-fake porn images. <br/><br/>News is driven by news cycles. Maybe OpenAI's announcement will lead to us thinking more about issues of responsible data science. But let's not pretend these are new, or haven't been studied for a long time, or need to have a discussion "started".<br/><br/><br/><img alt="" height="1" src="http://feeds.feedburner.com/~r/TheGeomblog/~4/5TqtLogn5Gg" width="1"/></div>
    </content>
    <updated>2019-02-19T16:00:00Z</updated>
    <published>2019-02-19T16:00:00Z</published>
    <category scheme="http://www.blogger.com/atom/ns#" term="ethics"/><feedburner:origlink xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0">http://blog.geomblog.org/2019/02/openai-ai-threats-and-norm-building-for.html</feedburner:origlink>
    <author>
      <name>Suresh Venkatasubramanian</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/112165457714968997350</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-6555947</id>
      <category term="research"/>
      <category term="community"/>
      <category term="miscellaneous"/>
      <category term="soda"/>
      <category term="conferences"/>
      <category term="data-mining"/>
      <category term="socg"/>
      <category term="blogosphere"/>
      <category term="publishing"/>
      <category term="clustering"/>
      <category term="teaching"/>
      <category term="jobs"/>
      <category term="funding"/>
      <category term="humor"/>
      <category term="awards"/>
      <category term="outreach"/>
      <category term="stoc"/>
      <category term="cs.CG"/>
      <category term="focs"/>
      <category term="nsf"/>
      <category term="reviewing"/>
      <category term="socg-2010"/>
      <category term="fairness"/>
      <category term="academy"/>
      <category term="latex"/>
      <category term="stoc2017"/>
      <category term="theoryfest"/>
      <category term="workshops"/>
      <category term="acm"/>
      <category term="conf-blogs"/>
      <category term="writing"/>
      <category term="cs.DS"/>
      <category term="cs.LG"/>
      <category term="geometry"/>
      <category term="p-vs-nc"/>
      <category term="advising"/>
      <category term="sabbatical"/>
      <category term="simons foundation"/>
      <category term="announcement"/>
      <category term="big-data"/>
      <category term="deadline"/>
      <category term="jeff phillips"/>
      <category term="streaming"/>
      <category term="books"/>
      <category term="large-data"/>
      <category term="p-vs-np"/>
      <category term="cra"/>
      <category term="cstheory"/>
      <category term="focs2010"/>
      <category term="icdm"/>
      <category term="math.PR"/>
      <category term="memorial"/>
      <category term="personal"/>
      <category term="posters"/>
      <category term="potd"/>
      <category term="rajeev motwani"/>
      <category term="shonan"/>
      <category term="socg2012"/>
      <category term="software"/>
      <category term="stoc2012"/>
      <category term="GIA"/>
      <category term="SDM"/>
      <category term="alenex"/>
      <category term="alenex2011"/>
      <category term="arxiv"/>
      <category term="career"/>
      <category term="complexity"/>
      <category term="cs.CC"/>
      <category term="deolalikar"/>
      <category term="distributions"/>
      <category term="madalgo"/>
      <category term="nips"/>
      <category term="sdm2011"/>
      <category term="shape"/>
      <category term="talks"/>
      <category term="technology"/>
      <category term="theory.SE"/>
      <category term="travel"/>
      <category term="video"/>
      <category term="8f-cg"/>
      <category term="DBR"/>
      <category term="ICS"/>
      <category term="LISPI"/>
      <category term="acceptances"/>
      <category term="bibtex"/>
      <category term="bregman"/>
      <category term="cfp"/>
      <category term="clustering-book"/>
      <category term="column"/>
      <category term="combinatorial geometry"/>
      <category term="current-distance"/>
      <category term="ecml-pkdd"/>
      <category term="empirical"/>
      <category term="esa"/>
      <category term="fat*"/>
      <category term="focs2012"/>
      <category term="focs2014"/>
      <category term="fwcg"/>
      <category term="game theory"/>
      <category term="godel"/>
      <category term="graphs"/>
      <category term="implementation"/>
      <category term="journals"/>
      <category term="kernels"/>
      <category term="misc"/>
      <category term="models"/>
      <category term="obituary"/>
      <category term="productivity"/>
      <category term="programming"/>
      <category term="society"/>
      <category term="soda2011"/>
      <category term="topology"/>
      <category term="turing"/>
      <category term="tv"/>
      <category term="women-in-theory"/>
      <category term=".02"/>
      <category term="IMA"/>
      <category term="MOOC"/>
      <category term="PPAD"/>
      <category term="accountability"/>
      <category term="active-learning"/>
      <category term="aggregator"/>
      <category term="algorithms"/>
      <category term="ams"/>
      <category term="analco"/>
      <category term="barriers"/>
      <category term="beamer"/>
      <category term="blogging"/>
      <category term="candes"/>
      <category term="civil rights"/>
      <category term="classification"/>
      <category term="coding-theory"/>
      <category term="coffee"/>
      <category term="conjecture"/>
      <category term="cosmos"/>
      <category term="counting"/>
      <category term="cricket"/>
      <category term="cs.DC"/>
      <category term="dagstuhl"/>
      <category term="databuse"/>
      <category term="dimacs"/>
      <category term="dimensionality-reduction"/>
      <category term="distributed-learning"/>
      <category term="double-blind review"/>
      <category term="duality"/>
      <category term="eda"/>
      <category term="embarrassing"/>
      <category term="ethics"/>
      <category term="expanders"/>
      <category term="experiments"/>
      <category term="fake-news"/>
      <category term="fatml"/>
      <category term="fellowships"/>
      <category term="focs2013"/>
      <category term="fonts"/>
      <category term="gct"/>
      <category term="ggplot"/>
      <category term="gpu"/>
      <category term="graph minors"/>
      <category term="gt.game-theory"/>
      <category term="guest-post"/>
      <category term="guitar"/>
      <category term="hangouts"/>
      <category term="hirsch"/>
      <category term="history"/>
      <category term="ipe"/>
      <category term="ita"/>
      <category term="jmm"/>
      <category term="k-12"/>
      <category term="knuth"/>
      <category term="machine-learning"/>
      <category term="massive"/>
      <category term="math.ST"/>
      <category term="media"/>
      <category term="memes"/>
      <category term="metoo"/>
      <category term="metrics"/>
      <category term="morris"/>
      <category term="movies"/>
      <category term="multicore"/>
      <category term="music"/>
      <category term="narrative"/>
      <category term="networks"/>
      <category term="nih"/>
      <category term="parallelism"/>
      <category term="partha niyogi"/>
      <category term="polymath"/>
      <category term="polymath research"/>
      <category term="polytopes"/>
      <category term="postdocs"/>
      <category term="privacy"/>
      <category term="quant-ph"/>
      <category term="quantum"/>
      <category term="randomness"/>
      <category term="review"/>
      <category term="sampling"/>
      <category term="seminars"/>
      <category term="social-networking"/>
      <category term="soda2014"/>
      <category term="students"/>
      <category term="sublinear"/>
      <category term="submissions"/>
      <category term="summer-school"/>
      <category term="superbowl"/>
      <category term="surveys"/>
      <category term="svn"/>
      <category term="television"/>
      <category term="traffic"/>
      <category term="twitter"/>
      <category term="utah"/>
      <category term="wads"/>
      <category term="white elephant"/>
      <category term="xkcd"/>
      <author>
        <name>Suresh Venkatasubramanian</name>
        <email>noreply@blogger.com</email>
      </author>
      <link href="http://blog.geomblog.org/" rel="alternate" type="text/html"/>
      <link href="http://www.blogger.com/feeds/6555947/posts/default?alt=atom&amp;start-index=26&amp;max-results=25&amp;redirect=false" rel="next" type="application/atom+xml"/>
      <link href="http://feeds.feedburner.com/TheGeomblog" rel="self" type="application/atom+xml"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <subtitle>Ruminations on computational geometry, algorithms, theoretical computer science and life</subtitle>
      <title>The Geomblog</title>
      <updated>2019-02-19T16:00:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/019</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/019" rel="alternate" type="text/html"/>
    <title>TR19-019 |  Towards Optimal Depth Reductions for Syntactically Multilinear Circuits | 

	Mrinal Kumar, 

	Rafael Mendes de Oliveira, 

	Ramprasad Saptharishi</title>
    <summary>We show that any $n$-variate polynomial computable by a syntactically multilinear circuit of size $\mathop{poly}(n)$ can be computed by a depth-$4$ syntactically multilinear ($\Sigma\Pi\Sigma\Pi$) circuit of size at most $\exp\left({O\left(\sqrt{n\log n}\right)}\right)$. For degree $d = \omega(n/\log n)$, this improves upon the upper bound of $\exp\left({O(\sqrt{d}\log n)}\right)$ obtained by Tavenas (MFCS 2015) for general circuits, and is known to be asymptotically optimal in the exponent when $d &lt; n^{\epsilon}$ for a small enough constant $\epsilon$. Our upper bound matches the lower bound of $\exp\left({\Omega\left(\sqrt{n\log n}\right)}\right)$ proved by Raz and Yehudayoff (CC 2009), and thus cannot be improved further in the exponent. Our results hold over all fields and also generalize to circuits of small individual degree.  

More generally, we show that an $n$-variate polynomial computable by a syntactically multilinear circuit of size $\mathop{poly}(n)$ can be computed by a syntactically multilinear circuit of product-depth $\Delta$ of size at most $\exp\left(O\left(\Delta \cdot (n/\log n)^{1/\Delta} \cdot \log n\right)\right)$. It follows from the lower bounds of Raz and Yehudayoff (CC 2009) that in general, for constant $\Delta$, the exponent in this upper bound is tight and cannot be improved to $o\left(\left(n/\log n\right)^{1/\Delta}\cdot \log n\right)$.</summary>
    <updated>2019-02-19T14:27:13Z</updated>
    <published>2019-02-19T14:27:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-23T07:20:43Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-335110421348004475</id>
    <link href="https://blog.computationalcomplexity.org/feeds/335110421348004475/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/using-who-will-be-dem-vp-choice-article.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/335110421348004475" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/335110421348004475" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/using-who-will-be-dem-vp-choice-article.html" rel="alternate" type="text/html"/>
    <title>Using `who will be the dem VP choice' article in class</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I recently read an absurd article that speculated on who the Democratic VICE prez nominees will be. Yes, you read that right, VICE Prez. Gee, wouldn't knowing who the Prez nominees was first help. But leave it to Nate Silver and company to have a fascinating yet... premature article on this. Here is the link: <a href="https://fivethirtyeight.com/features/our-very-first-2020-vice-presidential-draft/">article on who will be Dem VP nominee</a>.  Its hard enough to pick the VP when the Prez is known! I did a blog on how badly intrade would do on predicting VP, <a href="https://blog.computationalcomplexity.org/2008/09/i-would-be-on-intrade-that-intrade-will.html">here</a>. I didn't predict that intrade would go out of business (`intrade' was short hand for `betting markets' just like `Uber' is shorthand for `hailing a car with your phone'- I wonder if the term `Uber' will still be used if they go out of business?)<br/>
<br/>
After reading I thought<br/>
<br/>
<i>Wow- there are so many If-Then clauses in this that I could make half a lecture about it for my Discrete Math class where we are talking about Prop. Logic.</i><br/>
<i><br/></i>
I emailed the students to read it, and we had a lively discussion. I made sure it was a non-partisan discussion. Realize that a statement like:<br/>
<br/>
<i>If the Prez is a female then the VP will likely be a male because it is thought, righly or wrongly, that all-female ticket can't win</i><br/>
<br/>
is not partisan or sexist, it is stating an opinion about how voters would go. It may be incorrect, but its not offensive.<br/>
<br/>
Here is what the class thought the article was saying (and I think they are right) expressed in Logic.<br/>
<br/>
Note one other thing-- the Prez nominees  might not be the choice of the party (Trump wasn't the choice of the Rep party in 2016, though not clear who was, see <a href="https://blog.computationalcomplexity.org/2015/05/the-law-of-excluded-middle-of-road.html">here</a>) but the VP really will be since (I think) the party has more control over that.<br/>
<br/>
If the Prez Nominees is female then the Vice Prez nominee will be male. (I agree)<br/>
<br/>
If the Prez Nominees is white mail then the Vice Prez nominee will be either female or non-white but not both. (Great question to express that as symbols. Not sure what I think- the thought is that two white males will be odd since so many of the candidates are female or non-white. Having said that, in recent years the VP has NOT been someone else who ran:  Clinton-Keane, Keane had not been a candidate, Trump-Pence, Pence had not been a candidate, Romney-Ryan, Ryan had not been a candidate, Obama-Biden, Biden had been a candidate briefly in 2008, but this was not one of these `lets unite the party by picking by OPPONENT to be VP', McCain-Palin, Palin had not been a candidate. Kerry-Edwards. YES- Edwards had been a serious candidate in 2004, though some think he was running for VP all along since he never said an unkind word about his opponents)<br/>
<br/>
Prez from one of the coasts IFF VP from the center. (I won't go over the list again, but this has been less of a thing since Clinton-Gore were both from flyover states.)<br/>
<br/>
Ideology- If Prez is establishment then VP is leftists. (Not sure these terms are so well defined to say this, and their are other ideologies as well, not sure how they fit in.)<br/>
<br/>
If Prez lacks Fed Experience then VP should have Fed Exp. (Quite common: Obama-Biden, Romney-Ryan, Clinton-Gore, Bush-Cheney)<br/>
<br/>If Prez has fed experience than nothing can be deduced about VP Fed Exp.<br/>
<br/>
If Prez lacks gravitas then VP should have gravitas (tricky! Don't want the VP to outshine the Prez!)<br/>
<br/>
Absolute statement: VP should not outshine prez. A Kangaroo ticket is when the people prefer the VP to the Prez (Dukakis-Bentsen had this problem. Kerry-Edwards might have).<br/>
<br/>
If Prez is boring then VP should be exciting. But again tricky! (I think that was why McCain picked Palin. And she was exciting, but not really in a good way. Couldn't he have picked someone exciting, and perhaps female who was, you know, Qualified?)<br/>
<br/>
VP's like doctors: do no harm.<br/>
<br/>
VP from Swing state helpful but not necc.<br/>
<br/>
Bad to have a VP who is a senator from a state where the Governor is republican and picks the replacement senator.<br/>
<br/>
VP should be someone who the country can picture being president without laughing. I am not talking ideology I am talking about seriousness and experience. Palin was the only one in recent memory who even voters of her party worried that she was not up to being president. One pundit defending the choice talked about how McCain was healthy and hence Palin wouldn't become prez so don't worry about it. NOT reassuring! Quayle was also not seen as serious, though not as much as Palin.<br/>
<br/>
If Prez is old then VP mattes more(?)<br/>
<br/>
Many of the above depend on who the Prez is. And that is one of the points: one can write down a long prop formula with many IF-THEN's to determine who properties the VP will have, and then<br/>
<br/>
1) When the Prez is picked many of the variables are set and hence the formula becomes much easeier and<br/>
<br/>
2) Could STILL be wrong!<br/>
<br/>
MY prediction: my last two predictions have been wrong so I am reluctant go predict anything. But I will tell you my WRONG predictions and then my current one<br/>
<br/>
I predicted Paul Ryan would be the Prez Nominee in 2016. He didn't even run.<br/>
<br/>
I predicted that Al Franken would be the Prez Nominess in 2020- he understands TV and was an entertainer, so he could match Trump. Whoops.<br/>
<br/>
So with that sterling record I predict: Prez: Cory Booker, VP: Beto<br/>
<br/>
I am NOT a pundit- so what I predict is not what I hope happens.  What do I hope? In the interest of full disclosure (gee, shouldn't that have come at the beginning) I admit that I want to see Trump lose but I have no idea what makes someone `electable' nowadays.<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-02-19T13:27:00Z</updated>
    <published>2019-02-19T13:27:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-23T07:12:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/018</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/018" rel="alternate" type="text/html"/>
    <title>TR19-018 |  AC0[p] Lower Bounds against MCSP via the Coin Problem | 

	Valentine Kabanets, 

	Alexander Golovnev, 

	Rahul Ilango, 

	Russell Impagliazzo, 

	Antonina Kolokolova, 

	Avishay Tal</title>
    <summary>Minimum Circuit Size Problem (MCSP) asks to decide if a given truth table of an $n$-variate boolean function has circuit complexity less than a given parameter $s$. We prove that MCSP is hard for constant-depth circuits with mod $p$ gates, for any prime $p\geq 2$ (the circuit class $AC^0[p])$. Namely, we show that MCSP requires $d$-depth $AC^0[p]$ circuits of size at least $exp(N^{0.49/d})$, where $N=2^n$ is the size of an input truth table of an $n$-variate boolean function.  Our circuit lower bound proof shows that MCSP can solve the coin problem: distinguish uniformly random $N$-bit strings from those generated using independent samples from a biased random coin which is $1$ with probability $1/2+N^{-0.49}$, and $0$ otherwise. Solving the coin problem with such parameters is known to require exponentially large $AC^0[p]$ circuits. Moreover, this also implies that MAJORITY is computable by a non-uniform $AC^0$ circuit of polynomial size that also has MCSP-oracle gates. The latter has a few other consequences for the complexity of MCSP, e.g., we get that any boolean function in $NC^1$ (i.e., computable by a polynomial-size formula) can also be computed by a non-uniform polynomial-size $AC^0$ circuit with MCSP-oracle gates.</summary>
    <updated>2019-02-18T21:30:49Z</updated>
    <published>2019-02-18T21:30:49Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-23T07:20:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15645</id>
    <link href="https://rjlipton.wordpress.com/2019/02/18/have-ten-years-brought-us-closer/" rel="alternate" type="text/html"/>
    <title>Have Ten Years Brought Us Closer?</title>
    <summary>To solving the big questions, that is Cropped from Device Plus source Tetsuya Miyamoto is a mathematics teacher who divides his time between Tokyo and Manhattan. He is known for creating in 2004 the popular KenKen puzzle, which the New York Times started running ten years ago. As with its sister puzzles Sudoku and Kakuro, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>To solving the big questions, that is</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/02/miyamotodeviceplus.png"><img alt="" class="alignright size-thumbnail wp-image-15646" height="150" src="https://rjlipton.files.wordpress.com/2019/02/miyamotodeviceplus.png?w=150&amp;h=150" width="150"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Device Plus <a href="https://www.deviceplus.com/inspire/interviews/kenken-puzzle-inventors-tips-for-engineers/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Tetsuya Miyamoto is a mathematics teacher who divides his time between Tokyo and Manhattan. He is known for creating in 2004 the popular <a href="https://en.wikipedia.org/wiki/KenKen">KenKen</a> puzzle, which the New York Times started running ten years ago. As with its sister puzzles Sudoku and Kakuro, unlimited-size versions of it are <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/>-complete.</p>
<p>
Today we observe the 10th anniversary of this blog and ask what progress has been made on the <img alt="{\mathsf{P=NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P=NP}}"/> question.<br/>
<span id="more-15645"/></p>
<p>
The <img alt="{\mathsf{P=NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P=NP}}"/> is a question about <em>asymptotic</em> complexity. From time to time we have tried to raise corresponding questions about <em>concrete</em> complexity that might yield more progress. What catches our eye about the KenKen puzzles is that their generation is a full-blown application within concrete complexity. The NYT’s KenKen puzzles are all generated using software by David Levy that can tailor their hardness. Quoting the NYT anniversary <a href="https://www.nytimes.com/2019/02/09/reader-center/kenken-puzzle-10th-anniversary.html">article</a> by Will Shortz:</p>
<blockquote><p><b> </b> <em>[Levy’s] program knows every possible method for solving a KenKen, which he has rated in difficulty from easy to hard. Thus, when a KenKen has been made, the computer knows exactly how hard it is. </em>
</p></blockquote>
<p/><p>
This seems to say there is a hardness measure that is objective—quite apart from the idea of having human testers try the puzzle and say how hard they found it to be. We surmise that it is lower for instances that have more forced plays at the start. We wonder whether Levy’s criteria can be generalized.</p>
<p>
Incidentally, this is the same Levy who won a challenge chess match in 1978 against the computer Chess 4.7 to complete his win of a famous ten-year $1,000+ <a href="https://en.wikipedia.org/wiki/David_Levy_(chess_player)#Computer_chess_bet">bet</a>. He lost $1,000 back when he was defeated by Deep Thought in 1989. He later became president of the International Computer Games Association (<a href="https://en.wikipedia.org/wiki/International_Computer_Games_Association">ICGA</a>), whose <a href="https://icga.org/?page_id=26"><em>Journal</em></a> published a nice <a href="https://www.cs.wmich.edu/elise/courses/cs431/icga2008.pdf">paper</a> on the <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/>-completess of the aforementioned puzzles and many others.</p>
<p>
</p><p/><h2> GLL’s Tenth Anniversary </h2><p/>
<p/><p>
GLL’s first <a href="https://rjlipton.wordpress.com/2009/02/12/bait-and-switch-why-lower-bounds-are-so-hard/">post</a>, on 12 Feb. 2009, featured Stephen Rudich and his work on the “<a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/natural.pdf">Natural</a> <a href="https://en.wikipedia.org/wiki/Natural_proof">Proofs</a>.” <a href="https://rjlipton.wordpress.com/2009/02/12/is-np-too-big-or-p-too-small/">Two</a> other <a href="https://rjlipton.wordpress.com/2009/02/12/a-nightmare-about-sat/">posts</a> that day covered other aspects of why the <img alt="{\mathsf{P=NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P=NP}}"/> question is hard. Our question, dear readers, is:</p>
<blockquote><p><b> </b> <em> Has anything happened in the past ten years to make any part of those posts out-of-date in the slightest way? </em>
</p></blockquote>
<p/><p>
We won’t claim any such progress, though we have tried to stir ideas. In the meantime, we have written 806 other posts:</p>
<ul>
<li>
Some have featured our own work and ideas (considering Ken’s chess research in a separate vein); <p/>
</li><li>
some have featured others’ direct attempts at breakthrough lower and upper bounds (with a few successes); <p/>
</li><li>
many have featured other kinds of results by others; <p/>
</li><li>
many have pulled “idea nuggets” from the past; <p/>
</li><li>
many have been humor and social commentary.
</li></ul>
<p>
To date, we’ve had 18,575 comments plus trackbacks on these posts and just over 2.1 million views. We are less able to quantify impacts, beyond occasionally seeing citations of articles on the blog as sources. We try for precision as well as readability and are grateful for reader comments with fixes when we slip up on the former.</p>
<p>
</p><p/><h2> P vs NP </h2><p/>
<p/><p>
There continue to be claims of proofs that <img alt="{\mathsf{P \neq NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P \neq NP}}"/> and some that <img alt="{\mathsf{P=NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P=NP}}"/> While these proofs do not seem to be correct, there is something that we wish to remark about them. Many argue as follows: </p>
<blockquote><p><b> </b> <em> There is some problem say <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> that seems to require a search of exponentially many objects. Then the proof states that any algorithm for <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> must actually look at all or most of the exponentially many objects. This of course is where the proof is not complete. </em>
</p></blockquote>
<p/><p>
There is some sense to these proofs. They seem related to the oracle proofs that for example show that for some oracle set <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> it is the case that 	</p>
<p align="center"><img alt="\displaystyle  \mathsf{P}^{A} \neq \mathsf{NP}^{A}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BP%7D%5E%7BA%7D+%5Cneq+%5Cmathsf%7BNP%7D%5E%7BA%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{P}^{A} \neq \mathsf{NP}^{A}. "/></p>
<p>we have discussed these types of proofs before—we even said that we did not like them.</p>
<p>
The trouble with these results that are rigorous is that they change <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/> vs <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> in a central manner, and this seems to make the results much less interesting. Roughly here is how they argue: Imagine that for each <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> we either put a string of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> into <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> or we do not. The point is that if we do this in a <i>unpredictable</i> manner then a polynomial time machine will not be able to decide whether for <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> there is or is not a string of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> in <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>. But a nondeterministic machine with just use its power and guess. This shows, essentially, that 	</p>
<p align="center"><img alt="\displaystyle  \mathsf{P}^{A} \neq \mathsf{NP}^{A} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BP%7D%5E%7BA%7D+%5Cneq+%5Cmathsf%7BNP%7D%5E%7BA%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{P}^{A} \neq \mathsf{NP}^{A} "/></p>
<p>is true.</p>
<p>
There is some relationship to many attempts to show <img alt="{\mathsf{P} \neq \mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D+%5Cneq+%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P} \neq \mathsf{NP}}"/>. The proofs often argue that one must look at all the objects. The counterpart here is that a polynomial time machine will not have enough time to check the <img alt="{2^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{n}}"/> strings of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> to see if they are in <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>. But this works in the oracle case because we allow the rule that decides whether or not a string is in <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> to be very complicated. In the real world, in the world where we study the real <img alt="{\mathsf{P} \neq \mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D+%5Cneq+%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P} \neq \mathsf{NP}}"/> question, we cannot assume that <img alt="{NP}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BNP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{NP}"/>-complete problems use a complicated rule. <i>That is precisely what we are trying to prove</i>.</p>
<p>
</p><p/><h2> State of the Game </h2><p/>
<p/><p>
What can we say? Mostly the big open questions remain. We still have no non-linear lower bounds on circuit complexity and no progress of any definite kind on <img alt="{\mathsf{P}=\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%3D%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}=\mathsf{NP}}"/>. What do you think?</p>
<p>
What is commonly hailed as one of the two biggest results in our field last year was a positive solution to what is intuitively a slightly weaker form of the Unique Games Conjecture (UGC). For UGC we can refer you to Wikipedia’s <a href="https://en.wikipedia.org/wiki/Unique_games_conjecture">article</a>:</p>
<p/><p><br/>
<a href="https://rjlipton.files.wordpress.com/2019/02/uniquegameswikipedia.png"><img alt="" class="aligncenter wp-image-15648" height="106" src="https://rjlipton.files.wordpress.com/2019/02/uniquegameswikipedia.png?w=400&amp;h=106" width="400"/></a></p>
<p/><p><br/>
The note [2] is in turn a reference to a 2010 <a href="https://rjlipton.wordpress.com/2010/05/05/unique-games-a-three-act-play/">post</a> here. The new <a href="https://eccc.weizmann.ac.il/report/2018/006/">paper</a> proves hardness for the relaxed situation where, roughly speaking, a trial assignment to a node in a constraint graph limits the other node on any connecting edge to at most two possible values, rather than a unique value as in UGC. This relaxation retains many properties that had caused disbelief in the original UGC, yet it was proved—in that sense a big deal. </p>
<p>
Nevertheless we note that UGC, at its core, is just asserting that for arbitrarily small <img alt="{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon}"/>, with our power to make other parameter(s) as large as desired, we can execute an <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/>-hardness proof. We have been executing <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/>-hardness proofs for almost fifty years. That is something we in the field have proven good at. True, these hardness results becomes lower bound proofs if and when <img alt="{\mathsf{NP \neq P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP+%5Cneq+P%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP \neq P}}"/> is proved, and true, we have been as vocal as any on the standpoint that significant lower bounds will come from constructions that are usually thought of as being for upper bounds. But the new proof from a year ago doesn’t feel like that. We invite readers to tell us connections from UGC to the possibility of actually constructing lower bounds.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We at GLL thank you all for your help and support these ten years. Ken and I plan to continue doing what we have done in the past. Plan on a visit from our special friend on St. Patrick’s day, for example. Thanks again and let us know how we are doing.</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2019/02/dickken.png"><img alt="" class="aligncenter wp-image-15649" height="112" src="https://rjlipton.files.wordpress.com/2019/02/dickken.png?w=400&amp;h=112" width="400"/></a></p>
<p>
[fixed date of first GLL post]</p></font></font></div>
    </content>
    <updated>2019-02-18T21:14:51Z</updated>
    <published>2019-02-18T21:14:51Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="Teaching"/>
    <category term="anniversary"/>
    <category term="Kenken"/>
    <category term="NP-complete"/>
    <category term="puzzles"/>
    <category term="Tetsuya Miyamoto"/>
    <category term="Unique Games Conjecture"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-02-23T07:20:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-8365773040093923059</id>
    <link href="http://processalgebra.blogspot.com/feeds/8365773040093923059/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=8365773040093923059" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/8365773040093923059" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/8365773040093923059" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/02/three-questions-to-three-junior-female.html" rel="alternate" type="text/html"/>
    <title>Three questions to three junior female computer scientists for the International Day of Women in Science</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Last Monday, 11 February, was the <a href="http://www.un.org/en/events/women-and-girls-in-science-day/" target="_blank">International Day of Women in Science</a>. I planned to post the answers I received from three junior female computer scientists to three questions I asked them. However, being a computer scientist who is short of time like everyone else, I asked for a one-week deadline extension to do so.<br/><br/>The questions were <br/><ol><li>When did you become interested in science?</li><li>Why did you choose computer science?</li><li>Which advice would you give to a high-school student who is thinking about pursuing a career in science?  </li></ol>Here are the (unedited) answers in the order in which I received them, in case they might be of interest to (female) students of all ages. I have anonymized the answers as the message is more important than the messengers. <br/><br/>Colleague #1<br/><br/><ol><li>I never had a sentence like "I am interested in science" in my mind, it  was just that I always in one way or another enjoyed learning about  things, school and education, and I wanted to continue being in that  type of surroundings after graduating from university. </li><li>I actually studied mathematics, I was not interested in computer  science. I had some algorithms and programming classes during my  studies, which I found cute but not much more than that. I started being  seriously interested in computer science only when I took a class on  mathematical theory of computation. This class combined the  mathematical/theoretical/<div>philosophical approach I liked so much with (for me) a new and refreshing set of questions. </div></li><li> Try it and see how it goes. </li></ol>Colleague #2<br/><br/><ol><li>My interest in science started when visiting the SMAU that is an     event where companies, investors and startups aim to promote the     Made in Italy Research and Innovation. It was simply amazing to     learn about startups, laboratories, research centres, universities     and small companies showing so many novel ideas and technologies in     one day, it really impressed me a lot. </li><li>Computer science was the alternative to Math (my preferred subject     at the scientific high school) but I thought it was too abstract and     full of theories, demonstrations and proofs, maybe too much.     Computer science has the theoretical part that is fascinating but it     also has some more practical implications, it is somehow more     concrete, and I like both sides. </li><li>Don't be afraid to fail, be afraid not to try. I think it is     worthwhile to try if you have any inclination to science because you     are exposed to problem solving reasoning, and these efforts can be     helpful for building a better society.<span class="im"/> </li></ol>Colleague #3<br/><br/><ol><li style="margin-left: 15px;">From the junior secondary school, scientific subjects were my favorites, together with history.</li><li style="margin-left: 15px;">During the high school, I started to study computer science and also  laboratory of computer science where it was applied to other subjects  such as Math and Business Economics. I was really passionate of this  subject, which was among my favorite. When it was time to choose for the  University, computer science was naturally the first in the list. I  also had other alternatives but in the end I quickly decided to apply  for computer science.</li><li style="margin-left: 15px;">My advice is simply to do whatever he/she really likes and for which  he/she is good and has obtained good results, without thinking too much  about work opportunities or what other people (e.g., parents) want for  them. For each career, in science or not, passion is the main ingredient  to reach good results. Then, I also think that one can change his/her  mind and do something completely different after the university. The  important is to study what one really likes.</li></ol><br/><br/></div>
    </content>
    <updated>2019-02-18T13:11:00Z</updated>
    <published>2019-02-18T13:11:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-02-18T13:11:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16238</id>
    <link href="https://gilkalai.wordpress.com/2019/02/16/attila-pors-universality-result-for-tverberg-partitions/" rel="alternate" type="text/html"/>
    <title>Attila Por’s Universality Result for Tverberg Partitions</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In this post  I would like to tell you about three papers and three theorems. I am thankful to Moshe White and Imre Barany for helpful discussions. a) Universality of vector sequences and universality of Tverberg partitions, by Attila Por; Theorem … <a href="https://gilkalai.wordpress.com/2019/02/16/attila-pors-universality-result-for-tverberg-partitions/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h2/>
<p>In this post  I would like to tell you about three papers and three theorems. I am thankful to Moshe White and Imre Barany for helpful discussions.</p>
<p><strong><a href="https://arxiv.org/abs/1805.07197">a) Universality of vector sequences and universality of Tverberg partitions,</a> by Attila Por;</strong></p>
<p><strong>Theorem (Por’s universality result, 2018):</strong> Every long enough sequence of points in general position in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/>  contains a subsequence of length <em><span class="MathJax" id="MathJax-Element-16-Frame"><span class="math" id="MathJax-Span-98"><span class="mrow" id="MathJax-Span-99"><span class="mi" id="MathJax-Span-100">n</span></span></span></span></em> whose Tverberg partitions are exactly the so called rainbow partitions.</p>
<p class="title mathjax"><strong><a href="https://arxiv.org/abs/1611.01078">b) Classifying unavoidable Tverberg partitions</a>, by <a href="http://www.borisbukh.org/">Boris Bukh</a>, <a href="http://www.math.cmu.edu/~ploh/">Po-Shen Loh</a>, <a href="http://www.gabrielnivasch.org/">Gabriel Nivasch</a></strong></p>
<p><strong>Theorem (Bukh, Loh, and Nivasch, 2017):</strong> Let <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> be a tree-like <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/>-uniform simple hypergraph with <img alt="d+1" class="latex" src="https://s0.wp.com/latex.php?latex=d%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d+1"/> edges and <img alt="n=(d+1)(r-1)+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%3D%28d%2B1%29%28r-1%29%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n=(d+1)(r-1)+1"/> edges. It is possible to associate to the vertices of each such hypergraph H a set X of n points in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/> so that the Tverberg partitions of X correspond precisely to rainbow coloring of the hypergraph H. Moreover, the number of rainbow coloring is <img alt="(r-1)!^d" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29%21%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)!^d"/>. (Here, we consider two colorings as the same if they differ by a permutation of the colors.)</p>
<p><strong><a href="https://arxiv.org/abs/1508.07262">c) On Tverberg partitions</a>, by Moshe White</strong></p>
<p><strong>Theorem (White, 2015):</strong> For any partition <img alt="a_1,a_2,\dots ,a_r: 1 \le a_i\le d+1" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ca_2%2C%5Cdots+%2Ca_r%3A+1+%5Cle+a_i%5Cle+d%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,a_2,\dots ,a_r: 1 \le a_i\le d+1"/> of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, there exists a set <img alt="X \subset \mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=X+%5Csubset+%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X \subset \mathbb R^d"/> of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>  points, such that every Tverberg partition of <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/>  induces the same partition on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> given by the parts <img alt="a_1,\dots,a_r" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2C%5Cdots%2Ca_r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,\dots,a_r"/>. Moreover, the number of Tverberg’s partitions of <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> is <img alt="(r-1)!^d" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29%21%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)!^d"/></p>
<p>See the original abstracts for the papers at the end of the post.</p>
<h2>Radon’s and Tverberg’s theorems and Sierksma’s conjecture</h2>
<p>Recall the beautiful theorem of Tverberg: (We devoted two posts (<a href="https://gilkalai.wordpress.com/2008/11/24/sarkarias-proof-of-tverbergs-theorem-1/" rel="noopener noreferrer" target="_blank" title="Tverberg 1">I</a>, <a href="https://gilkalai.wordpress.com/2008/11/26/sarkarias-proof-of-tverbergs-theorem-2/" rel="noopener noreferrer" target="_blank" title="Tverberg 2">II</a>) to its background and proof.)</p>
<p><strong>Tverberg Theorem (1965): </strong>Let <img alt="x_1,x_2,\dots, x_m" class="latex" src="https://s0.wp.com/latex.php?latex=x_1%2Cx_2%2C%5Cdots%2C+x_m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1,x_2,\dots, x_m"/> be points in <img alt="R^d" class="latex" src="https://s0.wp.com/latex.php?latex=R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^d"/>, <img alt="m \ge (r-1)(d+1)+1" class="latex" src="https://s0.wp.com/latex.php?latex=m+%5Cge+%28r-1%29%28d%2B1%29%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m \ge (r-1)(d+1)+1"/>. Then there is a partition <img alt="S_1,S_2,\dots, S_r" class="latex" src="https://s0.wp.com/latex.php?latex=S_1%2CS_2%2C%5Cdots%2C+S_r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S_1,S_2,\dots, S_r"/> of <img alt="\{1,2,\dots,m\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots%2Cm%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{1,2,\dots,m\}"/> such that <img alt="\cap _{j=1}^rconv (x_i: i \in S_j) \ne \emptyset" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccap+_%7Bj%3D1%7D%5Erconv+%28x_i%3A+i+%5Cin+S_j%29+%5Cne+%5Cemptyset&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cap _{j=1}^rconv (x_i: i \in S_j) \ne \emptyset"/>.</p>
<p>The (much easier) case <img alt="r=2" class="latex" src="https://s0.wp.com/latex.php?latex=r%3D2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r=2"/> of Tverberg’s theorem is <strong>Radon’s theorem</strong>.</p>
<p>We devoted a post to <a href="https://gilkalai.wordpress.com/2008/12/23/seven-problems-around-tverbergs-theorem/">seven open problems related to Tverberg’s theorem</a>, and one of them was:</p>
<p><strong>Sierksma Conjecture:</strong> The number of Tverberg’s <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/>-partitions of a set of <img alt="(r-1)(d+1)+1" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29%28d%2B1%29%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)(d+1)+1"/> points in <img alt="R^d" class="latex" src="https://s0.wp.com/latex.php?latex=R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^d"/> is at least <img alt="((r-1)!)^d" class="latex" src="https://s0.wp.com/latex.php?latex=%28%28r-1%29%21%29%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="((r-1)!)^d"/>.</p>
<p>Gerard Sierksma’s construction with <img alt="(r-1)!^d" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29%21%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)!^d"/> Tverberg’s partition is obtained by taking <img alt="(r-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)"/> copies of each vertex of a simplex containing the origin in its interior, and adding the origin itself. A configuration of <img alt="(r-1)(d+1)+1" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29%28d%2B1%29%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)(d+1)+1"/> points in <img alt="R^d" class="latex" src="https://s0.wp.com/latex.php?latex=R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^d"/> with precisely <img alt="((r-1)!)^d" class="latex" src="https://s0.wp.com/latex.php?latex=%28%28r-1%29%21%29%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="((r-1)!)^d"/> Tverberg partitions to <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/> parts is called a <strong>Sierksma Configuration</strong>.</p>
<h2>White’s Theorem</h2>
<p>In 2015 Moshe White proved the following theorem which was an open problem for many years. White’s construction was surprisingly simple.</p>
<p><strong>Theorem 1 (White, 2015):</strong>  For any partition <img alt="a_1,a_2,\dots ,a_r: 1 \le a_i\le d+1" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ca_2%2C%5Cdots+%2Ca_r%3A+1+%5Cle+a_i%5Cle+d%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,a_2,\dots ,a_r: 1 \le a_i\le d+1"/> of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>, there exists a set <img alt="X \subset \mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=X+%5Csubset+%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X \subset \mathbb R^d"/> of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>  points, such that every Tverberg partition of <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/>  induces the same partition on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> given by the parts <img alt="a_1,\dots,a_r" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2C%5Cdots%2Ca_r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,\dots,a_r"/>. Moreover, the number of Tverberg’s partitions of <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> is <img alt="(r-1)!^d" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29%21%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)!^d"/></p>
<h2>Bukh, Loh, and Nivasch’s  examples via staircase convexity.</h2>
<h2><a href="https://gilkalai.files.wordpress.com/2019/02/cascade-tverberg.png"><img alt="" class="alignnone size-full wp-image-16844" height="463" src="https://gilkalai.files.wordpress.com/2019/02/cascade-tverberg.png?w=640&amp;h=463" width="640"/></a></h2>
<p><strong><span style="color: #ff0000;">Five tree-like simple hypergraphs that correspond to configurations of 11 points in 4-dimensional space.</span></strong></p>
<p>Start with a tree-like hypergraph H of d+1 blocks of size r like the five examples in the Figure above. The intersection of every two blocks has at most one element. The union of all blocks has n=(d+1)(r-1)+1 elements.</p>
<p>A <strong>rainbow coloring</strong> of a r-uniform hypergraph H is a coloring of the vertices of H with r colors so that the vertices of every edge is colored by all r colors.</p>
<p><strong>Theorem 2 (Bukh, Loh, and Nivasch):</strong> It is possible to associate to the vertices of each such hypergraph H a set X of n points in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/> so that the Tverberg partitions of X correspond precisely to rainbow coloring of the hypergraph H. Moreover, the number of rainbow coloring is <img alt="(r-1)!^d" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29%21%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)!^d"/>. (Here, we consider two colorings as the same if they differ by a permutation of the colors.)</p>
<p>For a star-like hypergraph where all blocks have a vertex in common we get the original Sierksma’s example. (Example (d) above.) White’s examples are obtained by considering such hypergraphs where there exists an edge <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> such that all edges have non empty intersection with <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>. (Examples (c), (d), and (e) above).</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png"><img alt="" class="alignnone size-full wp-image-16899" height="463" src="https://gilkalai.files.wordpress.com/2019/02/rainbow-1.png?w=640&amp;h=463" width="640"/></a></p>
<p><strong><span style="color: #ff0000;">Rainbow colorings of our five examples </span></strong></p>
<h2>Tverberg’s partitions for stretched points on the moment curve</h2>
<p>It is natural to consider $n$ points on the moment curve <img alt="x(t)=(t,t^2,\dots, t^d)" class="latex" src="https://s0.wp.com/latex.php?latex=x%28t%29%3D%28t%2Ct%5E2%2C%5Cdots%2C+t%5Ed%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x(t)=(t,t^2,\dots, t^d)"/>. It turns out that the set of Tverberg’s partitions for points on the moment curve depend on the precise location of the points. By stretched points on the moment curve I mean that  you take the points <img alt="x(t_1), x(t_2), \dots x(t_n)" class="latex" src="https://s0.wp.com/latex.php?latex=x%28t_1%29%2C+x%28t_2%29%2C+%5Cdots+x%28t_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x(t_1), x(t_2), \dots x(t_n)"/> where <img alt="t_1 &lt;&lt; t_2 &lt;&lt; \dots t_n" class="latex" src="https://s0.wp.com/latex.php?latex=t_1+%3C%3C+t_2+%3C%3C+%5Cdots+t_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_1 &lt;&lt; t_2 &lt;&lt; \dots t_n"/>, namely $t_2$ is much much larger than <img alt="t_1" class="latex" src="https://s0.wp.com/latex.php?latex=t_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_1"/> and <img alt="t_3" class="latex" src="https://s0.wp.com/latex.php?latex=t_3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_3"/> is much much much much larger than <img alt="t_2" class="latex" src="https://s0.wp.com/latex.php?latex=t_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t_2"/>, etc. etc. In this case, the configuration corresponds to a <strong>path</strong> <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>: you let the vertices be <img alt="\{1,2,\dots,n\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots%2Cn%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{1,2,\dots,n\}"/> and the edges are sets of the form <img alt="\{(k-1)(r-1)+1, (k-1)(r-1)+2,\dots , k(r-1)+1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28k-1%29%28r-1%29%2B1%2C+%28k-1%29%28r-1%29%2B2%2C%5Cdots+%2C+k%28r-1%29%2B1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(k-1)(r-1)+1, (k-1)(r-1)+2,\dots , k(r-1)+1\}"/>. A stretched configuration of points on the moment curve has the property that every subset is also a stretched configuration of points on the moment curve.</p>
<p>The importance of Tverberg’s partitions for stretched points on the moment curve was realized by Barany and Por, by Bukh, Loh, and Nivasch, and by Perles and Sidron (See their paper <a href="https://link.springer.com/article/10.1007/s00454-016-9813-3">Tverberg Partitions of Points on the Moment Curve</a>), and perhaps by others as well.</p>
<h2>Por’s universality result</h2>
<p>Por’s universality theorem asserts that in terms of Tverberg partitions every large enough configuration of points in general position in <img alt="R^d" class="latex" src="https://s0.wp.com/latex.php?latex=R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^d"/> contains a configuration whose Tverberg partitions are those of a stretched configuration of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> points on the moment curve! Por’s  universality result was conjectured independently by Bukh, Loh, and Nivasch, (and they gave some partial results) and by Por himself.</p>
<p><strong>Theorem 3 (Por’s universality result, 2018):</strong> Every long enough sequence of points in <span class="MathJax" id="MathJax-Element-15-Frame"><span class="math" id="MathJax-Span-91"><span class="mrow" id="MathJax-Span-92"><span class="msubsup" id="MathJax-Span-93"><span class="mi" id="MathJax-Span-97"><img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/></span></span></span></span></span> in general position contains a subsequence  of length <em><span class="MathJax" id="MathJax-Element-16-Frame"><span class="math" id="MathJax-Span-98"><span class="mrow" id="MathJax-Span-99"><span class="mi" id="MathJax-Span-100">n</span></span></span></span></em> whose Tverberg partitions are exactly the so called rainbow partitions.</p>
<p><span style="color: #000000;">Por actually proved an apparently stronger statement: We can find a subsequence <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> so the conclusion holds not only for <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> but also for every subsequence <img alt="Z" class="latex" src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Z"/> of <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/>. </span></p>
<h2>Staircase Convexity</h2>
<p>The work of Bukh, Loh, and Nivasch relied on an important method of “staircase convexity”. An earlier 2001 application of the method (where it was introduced) was for lower bounds on weak epsilon nets by Bukh, Matousek, and Nivasch (Here are links to the paper, and to <a href="http://www.borisbukh.org/geomselthms_talk.pdf">slides from a talk by Boris Bukh</a>. See also <a href="https://terrytao.wordpress.com/2007/04/22/gil-kalai-the-weak-epsilon-net-problem/">this post</a> and <a href="https://gilkalai.wordpress.com/2018/04/05/nathan-rubin-improved-the-bound-for-planar-weak-%CE%B5-nets-and-other-news-from-ein-gedi/">this one</a> of the weak epsilon net problem.) Roughly the idea is this: consider a stretched grid where the sequence of coordinates are very very fast growing. When you choose configuration of points in such a grid, questions regarding their convex hulls translate to purely combinatorial problems.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/staircase-convexity.png"><img alt="" class="alignnone size-full wp-image-16867" src="https://gilkalai.files.wordpress.com/2019/02/staircase-convexity.png?w=640"/></a></p>
<p><span style="color: #ff0000;"><strong>Stairconvex sets explained by Boris Bukh</strong></span></p>
<h2>Erdos Szekeres in the plane and higher dimensions</h2>
<h3>The planar case</h3>
<p>Let <em><span class="MathJax" id="MathJax-Element-1-Frame"><span class="math" id="MathJax-Span-1"><span class="mrow" id="MathJax-Span-2"><span class="mi" id="MathJax-Span-3">E</span><span class="mi" id="MathJax-Span-4">S</span><span class="mo" id="MathJax-Span-5">(</span><span class="mi" id="MathJax-Span-6">n</span><span class="mo" id="MathJax-Span-7">)</span></span></span></span></em> be the smallest integer such that any set of <em><span class="MathJax" id="MathJax-Element-2-Frame"><span class="math" id="MathJax-Span-8"><span class="mrow" id="MathJax-Span-9"><span class="mi" id="MathJax-Span-10">E</span><span class="mi" id="MathJax-Span-11">S</span><span class="mo" id="MathJax-Span-12">(</span><span class="mi" id="MathJax-Span-13">n</span><span class="mo" id="MathJax-Span-14">)</span></span></span></span></em> points in the plane in general position contains <em><span class="MathJax" id="MathJax-Element-3-Frame"><span class="math" id="MathJax-Span-15"><span class="mrow" id="MathJax-Span-16"><span class="mi" id="MathJax-Span-17">n</span></span></span></span></em> points in convex position. In their <a href="http://archive.numdam.org/ARCHIVE/CM/CM_1935__2_/CM_1935__2__463_0/CM_1935__2__463_0.pdf">seminal 1935 paper</a>, Erdős and Szekeres showed that <em>ES(n)</em> is finite.</p>
<p>The finiteness of ES(n) can be stated as follows: Given a sequence of N points in general position in the plane <img alt="x_1,x_2, \dots , x_N" class="latex" src="https://s0.wp.com/latex.php?latex=x_1%2Cx_2%2C+%5Cdots+%2C+x_N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_1,x_2, \dots , x_N"/>  there is a subsequence <img alt="1_i,x_2, \dots , x_n" class="latex" src="https://s0.wp.com/latex.php?latex=1_i%2Cx_2%2C+%5Cdots+%2C+x_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_i,x_2, \dots , x_n"/> such that the line segments <img alt="[x_i,x_k]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bx_i%2Cx_k%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[x_i,x_k]"/> and <img alt="[x_j,x_\ell ]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bx_j%2Cx_%5Cell+%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[x_j,x_\ell ]"/> intersect. With this statement, the Erdős and Szekeres’ theorem can be seen as identifying a universal set of points in term of its <em>Radon partitions </em>(or equivalently in terms of its <em>order type</em>).</p>
<h3>In high dimensions</h3>
<p>In higher dimensions we can define <img alt="ES_d(n)" class="latex" src="https://s0.wp.com/latex.php?latex=ES_d%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="ES_d(n)"/> and replace “in convex position” by “in cyclic position”. The finiteness of <img alt="ES_d(n)" class="latex" src="https://s0.wp.com/latex.php?latex=ES_d%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="ES_d(n)"/> (with terrible bounds) follows easily from various Ramsey results. In a series of papers very good lower and upper bounds where obtained:  <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Barany%2C+I">Imre Barany</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Matousek%2C+J">Jiri Matousek</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Por%2C+A">Attila Por</a>: <a href="https://arxiv.org/abs/1309.1147">Curves in R^d intersecting every hyperplane at most d+1 times</a>;  <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Eli%C3%A1%C5%A1%2C+M">Marek Eliáš</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Matou%C5%A1ek%2C+J">Jiří Matoušek</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Rold%C3%A1n-Pensado%2C+E">Edgardo Roldán-Pensado</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Safernov%C3%A1%2C+Z">Zuzana Safernová</a>:<a href="https://arxiv.org/abs/1307.5157"> Lower bounds on geometric Ramsey functions</a>; Marek Elias, Jiri Matousek: <a href="https://arxiv.org/abs/1111.3824">Higher-order Erdos–Szekeres theorems </a><a href="https://arxiv.org/abs/1111.3824">.</a></p>
<h3>Por’s result</h3>
<p>Por’s result can be seen as a far-reaching strengthening of the finiteness of <img alt="ES_d(n)" class="latex" src="https://s0.wp.com/latex.php?latex=ES_d%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="ES_d(n)"/>.</p>
<h2>Further Discussion:</h2>
<h3>High order order types?</h3>
<p>Can you base a higher-order notion of “order types” on Tverberg partitions?</p>
<p>The <strong>order type</strong> of a sequence of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> points affinely spanning <img alt="R^d" class="latex" src="https://s0.wp.com/latex.php?latex=R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^d"/>, is the described by the vector of signs (0, 1 or -1) of volume of simplices described by subsequences of length <img alt="d+1" class="latex" src="https://s0.wp.com/latex.php?latex=d%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d+1"/>. Equivalently the order type can be described by the minimal Radon partitions of the points.</p>
<ol>
<li>We can first ask if we can base a notion of higher order types on Tverberg’s partitions to <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/> parts where <img alt="r&gt;2" class="latex" src="https://s0.wp.com/latex.php?latex=r%3E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r&gt;2"/>.</li>
<li>Next we can ask for an associated notion of “higher order oriented matroids.” (Oriented matroids in the usual sense are abstract order types which coincide with Euclidean order types for every subsequence of <img alt="d+3" class="latex" src="https://s0.wp.com/latex.php?latex=d%2B3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d+3"/> points.)</li>
<li>A natural question regarding these “higher order types is: If a sequence of points in strong general position is Tverberg-equivalent to stretched points on the moment curve, does it apply to all of its subsequences?</li>
</ol>
<p>Another way to consider “higher” order types is to enlarge the family by to start with a family of points add to it all Radon points of minimal Radon’s partition and consider the order type of the new configuration. (This operation can be repeated <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r"/> times.) See <a href="https://link.springer.com/article/10.1007/BF00147418">this paper of Michael Kallay on point sets which contain their Radon points</a>.</p>
<h3>Staircase convexity order types</h3>
<p>Understanding order types of configuration of points on stretched grids of Bukh et al. is a very interesting problem. It is interesting to understand such configurations that are not in general position as well. (In particular, which matroids are supported on the stretched grid?) Of course, the method may well have many more applications.</p>
<h3>Fantastically strong forms of Sierksma’s conjecture</h3>
<p>Is the following true: For every sequence <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> of <img alt="n=(r-1)(d+1)+1" class="latex" src="https://s0.wp.com/latex.php?latex=n%3D%28r-1%29%28d%2B1%29%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n=(r-1)(d+1)+1"/> points in <img alt="R^d" class="latex" src="https://s0.wp.com/latex.php?latex=R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^d"/> there is a Sierksma’s configuration <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> of $n$ points so that every Tverberg’s partition of  <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> is a Tverberg’s partition of <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/>?</p>
<p>An even stronger version is:</p>
<p>Does every sequence <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> of <img alt="(r-1)(d+1)+1" class="latex" src="https://s0.wp.com/latex.php?latex=%28r-1%29%28d%2B1%29%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(r-1)(d+1)+1"/> points in <img alt="R^d" class="latex" src="https://s0.wp.com/latex.php?latex=R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^d"/> there is a tree-like simple hypergraph so that all the rainbow coloring of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> correspond to Tverberg partitions of the sequence? If true this will be a fantastically strong version of Sierksma’s conjecture.</p>
<h3>Is the Erdős-Szekeres’ conjecture outrageous?</h3>
<p>Erdős and Szekeres proved in 1935 that <img alt="ES(n)\le {{2n-4}\choose{n-2}}+1=4^{n-o(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=ES%28n%29%5Cle+%7B%7B2n-4%7D%5Cchoose%7Bn-2%7D%7D%2B1%3D4%5E%7Bn-o%28n%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="ES(n)\le {{2n-4}\choose{n-2}}+1=4^{n-o(n)}"/>, and in 1960, they showed that <img alt="ES(n) \ge 2^{n-2}+1" class="latex" src="https://s0.wp.com/latex.php?latex=ES%28n%29+%5Cge+2%5E%7Bn-2%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="ES(n) \ge 2^{n-2}+1"/>, and conjectured this to be optimal. Despite the efforts of many researchers, until recently no improvement in the order of magnitude has ever been made on the upper bound over  81 years. A  recent breakthrough result by Andrew Suk (Here are links<a href="http://arxiv.org/abs/1604.08657"> to the paper</a>, and to<a href="https://gilkalai.wordpress.com/2016/05/04/the-erdos-szekeres-polygon-problem-solved-asymptotically-by-andrew-suk/"> our post discussing the result</a>) asserts that <img alt="ES(n)=2^{n+o(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=ES%28n%29%3D2%5E%7Bn%2Bo%28n%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="ES(n)=2^{n+o(n)}"/>. <a href="https://mathoverflow.net/questions/259844/the-most-outrageous-or-ridiculous-conjectures-in-mathematics">Sometime ago I asked over MO a question on outrageous mathematical conjectures</a> and perhaps the conjecture that  <img alt="ES(n) = 2^{n-2}+1" class="latex" src="https://s0.wp.com/latex.php?latex=ES%28n%29+%3D+2%5E%7Bn-2%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="ES(n) = 2^{n-2}+1"/> on the nose is an example.</p>
<h2>Original Abstracts</h2>
<p><span id="more-16238"/></p>
<p><strong><a href="https://arxiv.org/abs/1805.07197">Universality of vector sequences and universality of Tverberg partitions,</a> by Attila Por;</strong></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/abstract-por.png"><img alt="" class="alignnone size-full wp-image-16870" src="https://gilkalai.files.wordpress.com/2019/02/abstract-por.png?w=640"/></a></p>
<p class="title mathjax"><strong><a href="https://arxiv.org/abs/1611.01078">Classifying unavoidable Tverberg partitions</a>, by Boris Bukh, Po-Shen Loh, Gabriel Nivasch</strong></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/bln-abstract.png"><img alt="" class="alignnone size-full wp-image-16871" src="https://gilkalai.files.wordpress.com/2019/02/bln-abstract.png?w=640"/></a></p>
<p><strong><a href="https://arxiv.org/abs/1508.07262">On Tverberg partitions</a>, by Moshe White</strong></p>
<p> </p>
<h2><a href="https://gilkalai.files.wordpress.com/2019/02/white-abstract.png"><img alt="" class="alignnone size-full wp-image-16872" src="https://gilkalai.files.wordpress.com/2019/02/white-abstract.png?w=640"/></a></h2></div>
    </content>
    <updated>2019-02-16T16:06:16Z</updated>
    <published>2019-02-16T16:06:16Z</published>
    <category term="Combinatorics"/>
    <category term="Convexity"/>
    <category term="Attila Por"/>
    <category term="Boris Bukh"/>
    <category term="Gabriel Nivasch"/>
    <category term="Moshe White"/>
    <category term="Po-Shen Loh"/>
    <category term="Sierksma's conjecture"/>
    <category term="Staircase convexity"/>
    <category term="Tverberg's theorem"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-02-23T07:20:47Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/02/15/linkage</id>
    <link href="https://11011110.github.io/blog/2019/02/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Beware the Ides of February.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Beware the Ides of February.</p>

<ul>
  <li>
    <p>Holes and their reflections (<a href="https://mathstodon.xyz/@11011110/101517910934422997"/>). (The reflections are in the curved surface of an espresso portafilter.)</p>

    <p style="text-align: center;"><img alt="Holes and their reflections" src="https://www.ics.uci.edu/~eppstein/pix/reflected-holes/reflected-holes-m.jpg" style="border-style: solid; border-color: black;"/></p>
  </li>
  <li>
    <p><a href="http://gallery.bridgesmathart.org/exhibitions/2019-joint-mathematics-meetings">The 2019 Bridges mathematical art gallery is online!</a> (<a href="https://mathstodon.xyz/@11011110/101526999074315478"/>). <a href="https://twitter.com/bit_player/status/1086463227154915329">Brian Hayes lists</a> his favorites as being the <a href="http://gallery.bridgesmathart.org/exhibitions/2019-joint-mathematics-meetings/unsolvedmre">warped notepaper of Matt Enlow</a> and the <a href="http://gallery.bridgesmathart.org/exhibitions/2019-joint-mathematics-meetings/burkholderd">Penrose quilt of Douglas G. Burkholder</a>.</p>
  </li>
  <li>
    <p>Some of my own favorites from this year’s Bridges mathematical art gallery (<a href="https://mathstodon.xyz/@11011110/101530712079779913"/>): <a href="http://gallery.bridgesmathart.org/exhibitions/2019-joint-mathematics-meetings/fieldingbrown">Fielding Brown’s 3d Lissajous wood ribbon sculpture</a>, <a href="http://gallery.bridgesmathart.org/exhibitions/2019-joint-mathematics-meetings/ddavis">Diana Davis’s periodic pentagonal billiards patterns</a>, <a href="http://gallery.bridgesmathart.org/exhibitions/2019-joint-mathematics-meetings/stephen-kenney">Stephen Kenney’s illustration of triangle geometry</a>, <a href="http://gallery.bridgesmathart.org/exhibitions/2019-joint-mathematics-meetings/espaley">Elizabeth Paley’s stoneware Klein bottle</a>, and <a href="http://gallery.bridgesmathart.org/exhibitions/2019-joint-mathematics-meetings/anduriel-s-widmark">Anduriel Widmark’s knotted glasswork</a>.</p>
  </li>
  <li>
    <p><a href="https://www.radionz.co.nz/national/programmes/ourchangingworld/audio/2018667030/mathematician-wins-top-science-award">Rod Downey, a New Zealand-based theoretical computer scientist who co-founded the theory of parameterized complexity, has won the Rutherford Medal, New Zealand’s highest science award</a> (<a href="https://mathstodon.xyz/@11011110/101537786624226744"/>). Somehow I missed this when it came around last October.</p>
  </li>
  <li>
    <p><a href="http://ad-publications.informatik.uni-freiburg.de/ESA_experiment_Bast_2018.pdf">Hannah Bast’s slides on the European Symposium on Algorithms 2018 Track B experiment</a> (<a href="https://mathstodon.xyz/@11011110/101543698645665393"/>).  (two independent program committees decided on the same set of papers and then the conference accepted the union of their acceptances). Some conclusions: the initial scoring is remarkably consistent, and per-paper discussions to reconcile differences of scoring are useful, but the final decision on which “gray zone” papers to keep is random and could be replaced by a simple threshold.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/the-sum-product-problem-shows-how-addition-and-multiplication-constrain-each-other-20190206/"><em>Quanta</em> writes up recent progress</a> on the <a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Szemer%C3%A9di_theorem">Erdős–Szemerédi sum-product problem</a>, that any set of numbers must either have many distinct pairwise sums or many distinct products (<a href="https://mathstodon.xyz/@11011110/101549376500085965"/>). Progress: “many” increased from  to .</p>
  </li>
  <li>
    <p><a href="https://retractionwatch.com/2019/02/07/the-case-of-the-reviewer-who-said-cite-me-or-i-wont-recommend-acceptance-of-your-work/">How to handle journal referees who ask authors to add unjustified citations to their own papers?</a> (<a href="https://mathstodon.xyz/@11011110/101552010373686789"/>).  Is their misbehavior protected by the anonymity of peer review or can they be publicly named and shamed?</p>
  </li>
  <li>
    <p>The Cal Poly ag students have started selling these blood oranges at the local farmer’s market, as they do every year around this time, only $1 for five. In the summer they sell sweet corn on the cob. (<a href="https://mathstodon.xyz/@11011110/101557509103586528"/>).</p>

    <p style="text-align: center;"><img alt="Blood oranges" src="https://www.ics.uci.edu/~eppstein/pix/bloodoranges/bloodoranges-m.jpg" style="border-style: solid; border-color: black;"/></p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/ancient-turing-pattern-builds-feathers-hair-and-now-shark-skin-20190102/">Turing patterns in shark skin</a> (<a href="https://mathstodon.xyz/@11011110/101570379158959818"/>, <a href="http://doi.org/10.1126/sciadv.aau5484">original paper</a>). Researchers at the University of Florida led by Gareth Fraser and his student Rory Cooper used reaction-diffusion patterns (also named <a href="https://en.wikipedia.org/wiki/Turing_pattern">Turing patterns</a> after Turing’s early work) to model the distribution of scales on sharks, and performed knockdown experiments to validate their model in vivo.</p>
  </li>
  <li>
    <p>Did you know that two different graphs with 81 vertices and 20 edges/vertex are famous enough to have Wikipedia articles? (<a href="https://mathstodon.xyz/@11011110/101578088028534617"/>).  The strongly regular <a href="https://en.wikipedia.org/wiki/Brouwer%E2%80%93Haemers_graph">Brouwer–Haemers graph</a> connects elements of GF(81) that differ by a fourth power. The <a href="https://en.wikipedia.org/wiki/Sudoku_graph">Sudoku graph</a> connects cells of a Sudoku grid that should be unequal. Sudoku puzzles are instances of precoloring extension on this graph. Unfortunately the natural graphs on the 81 cards of Set have degree ≠ 20…</p>
  </li>
  <li>
    <p><a href="http://joshmillard.com/sgmenger/">Josh “cortex” Millard describes how he made a stained glass Menger sponge</a> (<a href="https://mastodon.social/@joshmillard/101580889806746340"/>).</p>
  </li>
  <li>
    <p>Jacob Siehler labels cubic graphs with binary strings of length 5 so that all labels appear once and each vertex is the xor of its neighbors (<a href="https://mathstodon.xyz/@jsiehler/101586101859381152"/>). He can do three vertex-transitive 32-vertex graphs: the Dyck graph, an expansion of the vertices of  into four cycles, and another one I don’t know.</p>
  </li>
  <li>
    <p>Four of <a href="https://oeis.org/A248380/a248380.pdf">Conway’s five $1000-prize problems</a> remain unsolved (<a href="https://mathstodon.xyz/@11011110/101592412607547272"/>): the dead fly problem on spacing of <a href="https://en.wikipedia.org/wiki/Danzer_set">point sets that touch all large convex sets</a>, <a href="https://en.wikipedia.org/wiki/Conway%27s_99-graph_problem">existence of a 99-vertex graph</a> with each edge in a unique triangle and each non-edge the diagonal of a unique quadrilateral, the <a href="https://en.wikipedia.org/wiki/Thrackle">thrackle conjecture</a>, on graphs drawn so all edges cross once, and who wins <a href="https://en.wikipedia.org/wiki/Sylver_coinage">Sylver coinage</a> after move 16?</p>
  </li>
  <li>
    <p><a href="http://eecs.oregonstate.edu/socg19/accepted.html">The list of accepted papers</a> from this year’s Symposium on Computational Geometry just came out (<a href="https://mathstodon.xyz/@11011110/101600288486356446"/>).</p>
  </li>
</ul></div>
    </content>
    <updated>2019-02-15T10:45:00Z</updated>
    <published>2019-02-15T10:45:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-02-22T05:13:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16854</id>
    <link href="https://gilkalai.wordpress.com/2019/02/15/henry-cohn-abhinav-kumar-stephen-d-miller-danylo-radchenko-and-maryna-viazovska-universal-optimality-of-the-e8-and-leech-lattices-and-interpolation-formulas/" rel="alternate" type="text/html"/>
    <title>Henry Cohn, Abhinav Kumar, Stephen D. Miller, Danylo Radchenko, and Maryna Viazovska: Universal optimality of the E8 and Leech lattices and interpolation formulas</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Henry Cohn A follow up paper on the tight bounds for sphere packings in eight and 24 dimensions. (Thanks, again, Steve, for letting me know.) For the 2016 breakthroughs see this post, this post of John Baez, this article by Erica Klarreich on … <a href="https://gilkalai.wordpress.com/2019/02/15/henry-cohn-abhinav-kumar-stephen-d-miller-danylo-radchenko-and-maryna-viazovska-universal-optimality-of-the-e8-and-leech-lattices-and-interpolation-formulas/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/02/hlc.jpg"><img alt="" class="alignnone size-full wp-image-16863" height="641" src="https://gilkalai.files.wordpress.com/2019/02/hlc.jpg?w=640&amp;h=641" width="640"/></a></p>
<p><span style="color: #ff0000;"><strong>Henry Cohn</strong></span></p>
<p>A follow up paper on the tight bounds for sphere packings in eight and 24 dimensions. (Thanks, again, Steve, for letting me know.)</p>
<p>For the 2016 breakthroughs see <a href="https://gilkalai.wordpress.com/2016/03/23/a-breakthrough-by-maryna-viazovska-lead-to-the-long-awaited-solutions-for-the-densest-packing-problem-in-dimensions-8-and-24/">this post</a>,<a href="https://golem.ph.utexas.edu/category/2016/03/e8_is_the_best.html"> this post of John Baez</a>, this <a href="https://www.quantamagazine.org/20160330-sphere-packing-solved-in-higher-dimensions/">article by Erica Klarreich on Quanta Magazine, </a>and a Notices AMS article by  Henry Cohn   <a href="http://www.ams.org/publications/journals/notices/201702/rnoti-p102.pdf" rel="nofollow">A conceptual breakthrough in sphere packing</a>. See also, Henry Cohn’s 2010 paper <a href="https://arxiv.org/abs/1003.3053">Order and disorder in energy minimization</a>, and <a href="https://www.youtube.com/watch?v=8y-uqcyRZ1M">Maryna Viazovska’s ICM 2018 videotaped lecture.</a></p>
<h3>Henry Cohn, Abhinav Kumar, Stephen D. Miller, Danylo Radchenko, and Maryna Viazovska: <a href="https://arxiv.org/abs/1902.05438">Universal optimality of the E8 and Leech lattices and interpolation formulas</a></h3>
<p><strong>Abstract: </strong>We prove that the <img alt="E_8" class="latex" src="https://s0.wp.com/latex.php?latex=E_8&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="E_8"/> root lattice and the Leech lattice are universally optimal among point configurations in Euclidean spaces of dimensions 8 and 24, respectively. In other words, they minimize energy for every potential function that is a completely monotonic function of squared distance (for example, inverse power laws or Gaussians), which is a strong form of robustness not previously known for any configuration in more than one dimension. This theorem implies their recently shown optimality as sphere packings, and broadly generalizes it to allow for long-range interactions.</p>
<p>The proof uses sharp linear programming bounds for energy. To construct the optimal auxiliary functions used to attain these bounds, we prove a new interpolation theorem, which is of independent interest. It reconstructs a radial Schwartz function <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> from the values and radial derivatives of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> and its Fourier transform <img alt="\hat f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat+f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\hat f"/> at the radii √2π for integers <em>n ≥ 1</em> in <img alt="R^8" class="latex" src="https://s0.wp.com/latex.php?latex=R%5E8&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^8"/> and <em>n ≥ 2</em> in <img alt="R^{24}" class="latex" src="https://s0.wp.com/latex.php?latex=R%5E%7B24%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R^{24}"/>. To prove this theorem, we construct an interpolation basis using integral transforms of quasimodular forms, generalizing Viazovska’s work on sphere packing and placing it in the context of a more conceptual theory.</p></div>
    </content>
    <updated>2019-02-15T07:17:39Z</updated>
    <published>2019-02-15T07:17:39Z</published>
    <category term="Algebra and Number Theory"/>
    <category term="Combinatorics"/>
    <category term="Geometry"/>
    <category term="sphere packing in eight dimensions"/>
    <category term="sphere packing in 24 dimensions"/>
    <category term="Maryna Viazovska"/>
    <category term="Henry Cohn"/>
    <category term="Abhinav Kumar"/>
    <category term="Sphere packing"/>
    <category term="Stephen D. Miller"/>
    <category term="Danylo Radchenko"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-02-23T07:20:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=336</id>
    <link href="https://tcsplus.wordpress.com/2019/02/14/tcs-talk-wednesday-february-20th-sepehr-assadi-princeton/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, February 20th, Sepehr Assadi, Princeton</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, February 20th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Sepehr Assadi from Princeton University will speak about “A Simple Sublinear-Time Algorithm for Counting Arbitrary Subgraphs via Edge Sampling” (abstract below). Please make sure you reserve a spot […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, February 20th at<br/>
1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European<br/>
Time, 18:00 UTC). <strong>Sepehr Assadi</strong> from Princeton University will speak about “<em>A Simple Sublinear-Time Algorithm for Counting Arbitrary Subgraphs via Edge Sampling</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: In the subgraph counting problem, we are given a (large) graph <img alt="G(V, E)" class="latex" src="https://s0.wp.com/latex.php?latex=G%28V%2C+E%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="G(V, E)"/> and a (small) graph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/> (e.g., a triangle), and the goal is to estimate the number of occurrences of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/> in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0" title="G"/>. Our focus in this talk is on designing sublinear-time algorithms for approximately computing number of occurrences of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/> in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0" title="G"/> in the setting where the algorithm is given query access to <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0" title="G"/>. This problem has been studied in several recent work which primarily focused on specific families of graphs H such as triangles, cliques, and stars. However, not much is known about approximate counting of arbitrary graphs <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/> in the literature. This is in sharp contrast to the closely related subgraph enumeration problem in which the goal is to list all copies of the subgraph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/> in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0" title="G"/>. The AGM bound shows that the maximum number of occurrences of any arbitrary subgraph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/> in a graph <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0" title="G"/> with <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=fff&amp;fg=444444&amp;s=0" title="m"/> edges is <img alt="O(m^{p(H)})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28m%5E%7Bp%28H%29%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="O(m^{p(H)})"/>, where <img alt="p(H)" class="latex" src="https://s0.wp.com/latex.php?latex=p%28H%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="p(H)"/> is the fractional edge cover number of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/>, and enumeration algorithms with matching runtime are known for every <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/>.</p>
<p>In this talk, we bridge this gap between the subgraph counting and subgraph enumeration problems and present a simple sublinear-time algorithm that estimates the number of occurrences of any arbitrary graph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/> in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0" title="G"/>, denoted by <img alt="\#H" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%23H&amp;bg=fff&amp;fg=444444&amp;s=0" title="\#H"/>, to within a <img alt="(1 \pm \varepsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=%281+%5Cpm+%5Cvarepsilon%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="(1 \pm \varepsilon)"/>-approximation factor with high probability in <img alt="O(m^{p(H)} /\#H)\cdot \text{poly}(\log n,1/\varepsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28m%5E%7Bp%28H%29%7D+%2F%5C%23H%29%5Ccdot+%5Ctext%7Bpoly%7D%28%5Clog+n%2C1%2F%5Cvarepsilon%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="O(m^{p(H)} /\#H)\cdot \text{poly}(\log n,1/\varepsilon)"/> time. Our algorithm is allowed the standard set of queries for general graphs, namely degree queries, pair queries and neighbor queries, plus an additional edge-sample query that returns an edge chosen uniformly at random. The performance of our algorithm matches those of Eden et al. [FOCS 2015, STOC 2018] for counting triangles and cliques and extend them to all choices of subgraph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/> under the additional assumption of edge-sample queries. Our results are also applicable to the more general problem of database join size estimation problem and for this slightly more general problem achieve optimal bounds for every choice of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0" title="H"/>.</p>
<p>Joint work with Michael Kapralov and Sanjeev Khanna.</p></blockquote></div>
    </content>
    <updated>2019-02-15T00:03:08Z</updated>
    <published>2019-02-15T00:03:08Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2019-02-23T07:21:39Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5151224614999297675</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5151224614999297675/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/the-iphonification-of-everything.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5151224614999297675" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5151224614999297675" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/the-iphonification-of-everything.html" rel="alternate" type="text/html"/>
    <title>The iPhonification of Everything</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">So you've got an iPhone XS in Space Grey. Congrats, so do 20 million other people. Maybe you have different cases but otherwise the hardware in all these phones are virtually identical. Yet you can tell with a glance that this is your phone. You can personalize apps and other elements of the home screen. It's your calendar and email and music.<br/>
<br/>
What? You've dropped your phone over Niagara falls. Luckily you've backed up your data. So you go back to Apple and buy another Space Grey iPhone XS and restore your data. Physically it's a completely different phone but for all practical purposes it's though you still had the original phone. Your phone is not defined by the device but the data that resides on it.<br/>
<br/>
It's not just phones. I can log into Google on anyone's Chrome browser and it will feel like my machine.<br/>
<br/>
Now we've all heard about a future world where nobody owns cars and we get driven around in self-driving Ubers, Lyfts and Waymos. One argument against this world is that people feel connected to their cars and unwilling to commute in some generic vehicle. But one can also imagine the car knows who you are, knows how you like your music, your lighting, how you adjust your seats even how your car drives. It becomes your car. Maybe even has electronic bumper stickers that change to support your political party.<br/>
<br/>
You can imagine the same for hotel rooms, your office, maybe even your apartment. It won't replicate your dog (or will it?) but as we get define more by our data than our things, do our things matter at all?</div>
    </content>
    <updated>2019-02-14T12:52:00Z</updated>
    <published>2019-02-14T12:52:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-23T07:12:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4121</id>
    <link href="https://www.scottaaronson.com/blog/?p=4121" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4121#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4121" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Four updates</title>
    <summary xml:lang="en-US">A few weeks ago, I was at QIP’2019 in Boulder, CO. This week I was at SQuInT’2019 in Albuquerque, NM. There were lots of amazing talks—feel free to ask in the comments section. There’s an interview with me at the website “GigaOm,” conducted by Byron Reese and entitled Quantum Computing: Capabilities and Limits. I didn’t […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>A few weeks ago, I was at <a href="http://jila.colorado.edu/qip2019/">QIP’2019</a> in Boulder, CO.  This week I was at <a href="http://physics.unm.edu/SQuInT/2019/index.php">SQuInT’2019</a> in Albuquerque, NM.  There were lots of amazing talks—feel free to ask in the comments section.</p>



<p>There’s an interview with me at the website “GigaOm,” conducted by Byron Reese and entitled <a href="https://gigaom.com/2019/01/17/quantum-computing-capabilities-and-limits-an-interview-with-scott-aaronson/">Quantum Computing: Capabilities and Limits</a>.  I didn’t proofread the transcript and it has some errors in it, but hopefully the meaning comes through.  In other interview news, if you were interested in my podcast with Adam Ford in Melbourne but don’t like YouTube, Adam has helpfully prepared transcripts of the two longest segments: <a href="http://www.scifuture.org/the-ghost-in-the-quantum-turing-machine-scott-aaronson/">The Ghost in the Quantum Turing Machine</a> and <a href="http://www.scifuture.org/the-winding-road-to-quantum-supremacy-scott-aaronson/">The Winding Road to Quantum Supremacy</a>.</p>



<p>The <em>New York Times</em> ran an article entitled <a href="https://www.nytimes.com/2019/01/24/technology/computer-science-courses-college.html">The Hard Part of Computer Science? Getting Into Class</a>, about the surge in computer science majors all over the US, and the shortage of professors to teach them.  The article’s go-to example of a university where this is happening is UT Austin, and there’s extensive commentary from my department chair, Don Fussell.</p>



<p>The <a href="http://acm-stoc.org/stoc2019/STOC%202019%20accepted%20papers.html">STOC’2019 accepted papers list</a> is finally out.  Lots of cool stuff!</p></div>
    </content>
    <updated>2019-02-13T04:43:23Z</updated>
    <published>2019-02-13T04:43:23Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-02-13T04:44:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5768393804446188224</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5768393804446188224/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/i-think-ze-was-confused-in-favor-of.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5768393804446188224" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5768393804446188224" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/i-think-ze-was-confused-in-favor-of.html" rel="alternate" type="text/html"/>
    <title>I think ze was confused  -- in favor of genderless pronouns</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">You've probably heard the following:<br/>
<br/>
<br/>
               At first I didn't want to get an X but now that I have it, I can't imagine life without one.<br/>
<br/>
X could be telegraph, radio, TV, color TV, VCR, CD player, streaming, Netflix, Amazon prime, an uber account, Washer and Dryer, Car Phones (remember those), Cell Phones. If you go back in history  wrist watches or sun dials (or wrist-sun-dials!).<br/>
<br/>
This has happened to me recently though not with an object. I read an article someplace saying that ze can be used instead of he or she. It was referring to nonbinaries (using `they' never quite sounded right) but actually it would be great if this was a general genderless pronoun. I am not making a political statement here (although I doubt I have any readers who are against genderless pronouns).<br/>
<br/>
Once I came across the term ze I found places to use it and now I can't imagine not using it.<br/>
<br/>
In a recent article I wrote I needed to say that someone was probably confused, but I did not know their gender. I used<br/>
<br/>
                                                         Ze was probably confused<br/>
<br/>
which is much better than<br/>
<br/>
                                                         S/he was probably confused<br/>
<br/>
                                                         He or she was probably confused<br/>
<br/>
                                                         The student was probably confused<br/>
<br/>
                                                         They were probably confused.<br/>
<br/>
Note that the first two leave out nonbinaries.<br/>
<br/>
0) In the article I put in a footnote saying what ze meant. In the future I may not have to.<br/>
<br/>
1) Will ze catch on? This blog post is an attempt to hasten the practice.<br/>
<br/>
2) Is there a term for his/her that is non-gendered? If not then maybe zer.<br/>
<br/>
3) Will there be political pushback on this usage? If its phrased as a way to include nonbinaries than unfortunately yes. If its phrased as above as when you don't know the gender, what do you do, then no.<br/>
<br/>
4) Is <i> nonbinary </i>the correct term? If not then please politely correct me in the comments.<br/>
<br/>
5) Has Ms replaced Miss and Mrs?<br/>
<br/>
I have used the term ze several times since then- often when I get email from a student such that I can't tell from the first name what their gender is, and I need to forward the email, such as<br/>
<br/>
                   Ze wants to take honors discrete math but does not have the prerequisite, but<br/>
                   since ze placed in the top five in the math olympiad, we'll let zer take it.<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-02-11T19:43:00Z</updated>
    <published>2019-02-11T19:43:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-23T07:12:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/02/11/parameterized-approximation-algorithms-workshop-paaw-2019/</id>
    <link href="https://cstheory-events.org/2019/02/11/parameterized-approximation-algorithms-workshop-paaw-2019/" rel="alternate" type="text/html"/>
    <title>Parameterized Approximation Algorithms Workshop (PAAW) 2019</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 8, 2019 Patras, Greece https://sites.google.com/site/aefeldmann/parameterized-approximation-algorithms-workshop-paaw-2019 Submission deadline: April 26, 2019 Registration deadline: April 30, 2019 The 2019 edition of the Parameterized Approximation Algorithms Workshop (PAAW) will take place as a satellite workshop of ICALP 2019 in Patras, Greece, on Monday July 8th 2019. — Topics of interest — – Parameterized approximation algorithms – Lossy … <a class="more-link" href="https://cstheory-events.org/2019/02/11/parameterized-approximation-algorithms-workshop-paaw-2019/">Continue reading <span class="screen-reader-text">Parameterized Approximation Algorithms Workshop (PAAW) 2019</span></a></div>
    </summary>
    <updated>2019-02-11T15:31:13Z</updated>
    <published>2019-02-11T15:31:13Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-02-23T07:21:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://bit-player.org/?p=2137</id>
    <link href="http://bit-player.org/2019/divisive-factorials" rel="alternate" type="text/html"/>
    <link href="http://bit-player.org/2019/divisive-factorials#comments" rel="replies" type="text/html"/>
    <link href="http://bit-player.org/2019/divisive-factorials/feed/atom" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Divisive factorials!</title>
    <summary type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml">The other day I was derailed by this tweet from Fermat’s Library: The moment I saw it, I had to stop in my tracks, grab a scratch pad, and check out the formula. The result made sense in a rough-and-ready … <a href="http://bit-player.org/2019/divisive-factorials">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>The other day I was derailed by this tweet from Fermat’s Library:</p>
<p><img alt="Inverse factorial tweet" border="0" class="aligncenter" height="385" src="http://bit-player.org/wp-content/uploads/2019/02/inverse-factorial-tweet.png" width="592"/></p>
<p class="undent">The moment I saw it, I had to stop in my tracks, grab a scratch pad, and check out the formula. The result made sense in a rough-and-ready sort of way. Since the multiplicative version of \(n!\) goes to infinity as \(n\) increases, the “divisive” version should go to zero. And \(\frac{n^2}{n!}\) does exactly that; the polynomial function \(n^2\) grows slower than the exponential function \(n!\) for large enough \(n\):</p>
<p>\[\frac{1}{1}, \frac{4}{2}, \frac{9}{6}, \frac{16}{24}, \frac{25}{120}, \frac{36}{720}, \frac{49}{5040}, \frac{64}{40320}, \frac{81}{362880}, \frac{100}{3628800}.\]</p>
<p class="undent">But why does the quotient take the particular form \(\frac{n^2}{n!}\)? Where does the \(n^2\) come from?</p>
<p>To answer that question, I had to revisit the long-ago trauma of learning to divide fractions, but I pushed through the pain. Proceeding from left to right through the formula in the tweet, we first get \(\frac{n}{n-1}\). Then, dividing that quantity by \(n-2\) yields</p>
<p>\[\cfrac{\frac{n}{n-1}}{n-2} = \frac{n}{(n-1)(n-2)}.\]</p>
<p class="undent">Continuing in the same way, we ultimately arrive at:</p>
<p>\[n \mathbin{/} (n-1) \mathbin{/} (n-2) \mathbin{/} (n-3) \mathbin{/} \cdots \mathbin{/} 1 = \frac{n}{(n-1) (n-2) (n-3) \cdots 1} = \frac{n}{(n-1)!}\]</p>
<p class="undent">To recover the tweet’s stated result of \(\frac{n^2}{n!}\), just multiply numerator and denominator by \(n\). (To my taste, however, \(\frac{n}{(n-1)!}\) is the more perspicuous expression.)</p>
<hr/>
<p>I am a card-carrying factorial fanboy. You can keep your fancy Fibonaccis; <em>this</em> is my favorite function. Every time I try out a new programming language, my first exercise is to write a few routines for calculating factorials. Over the years I have pondered several variations on the theme, such as replacing \(\times\) with \(+\) in the definition (which produces triangular numbers). But I don’t think I’ve ever before considered substituting \(\mathbin{/}\) for \(\times\). It’s messy. Because multiplication is commutative and associative, you can define \(n!\) simply as the product of all the integers from \(1\) through \(n\), without worrying about the order of the operations. With division, order can’t be ignored. In general, \(x \mathbin{/} y \ne y \mathbin{/}x\), and \((x \mathbin{/} y) \mathbin{/} z \ne x \mathbin{/} (y \mathbin{/} z)\).</p>
<p>The Fermat’s Library tweet puts the factors in descending order: \(n, n-1, n-2, \ldots, 1\). The most obvious alternative is the ascending sequence \(1, 2, 3, \ldots, n\). What happens if we define the divisive factorial as \(1 \mathbin{/} 2 \mathbin{/}  3 \mathbin{/} \cdots \mathbin{/} n\)? Another visit to the schoolroom algorithm for dividing fractions yields this simple answer:</p>
<p>\[1 \mathbin{/} 2 \mathbin{/}  3 \mathbin{/} \cdots \mathbin{/} n = \frac{1}{2 \times 3 \times 4 \times \cdots \times n} = \frac{1}{n!}.\]</p>
<p class="undent">In other words, when we repeatedly divide while counting up from \(1\) to \(n\), the final quotient is the reciprocal of \(n!\).  (I wish I could put an exclamation point at the end of that sentence!) If you’re looking for a canonical answer to the question, “What do you get if you divide instead of multiplying in \(n!\)?” I would argue that \(\frac{1}{n!}\) is a better candidate than \(\frac{n}{(n - 1)!}\). Why not embrace the symmetry between \(n!\) and its inverse?</p>
<p>Of course there are many other ways to arrange the <em>n</em> integers in the set \(\{1 \ldots n\}\). How many ways? As it happens, \(n!\) of them! Thus it would seem there are \(n!\) distinct ways to define the divisive \(n!\) function. However, looking at the answers for the two permutations discussed above suggests there’s a simpler pattern at work. Whatever element of the sequence happens to come first winds up in the numerator of a big fraction, and the denominator is the product of all the other elements. As a result, there are really only \(n\) different outcomes—assuming we stick to performing the division operations from left to right. For any integer \(k\) between \(1\) and \(n\), putting \(k\) at the head of the queue creates a divisive \(n!\) equal to \(k\) divided by all the other factors. We can write this out as:</p>
<p>\[\cfrac{k}{\frac{n!}{k}}, \text{ which can be rearranged as } \frac{k^2}{n!}.\]</p>
<p class="undent">And thus we also solve the minor mystery of how \(\frac{n}{(n-1)!}\) became \(\frac{n^2}{n!}\) in the tweet.</p>
<p>It’s worth noting that all of these functions converge to zero as \(n\) goes to infinity. Asymptotically speaking, \(\frac{1^2}{n!}, \frac{2^2}{n!}, \ldots, \frac{n^2}{n!}\) are all alike.</p>
<hr/>
<p>Ta dah! Mission accomplished. Problem solved. Done and dusted. Now we know everything there is to know about divisive factorials, right?</p>
<p>Well, maybe there’s one more question. What does the computer say? If you take your favorite factorial algorithm, and do as the tweet suggests, replacing any appearance of the \(\times\) (or <code>*</code>) operator with <code>/</code>, what happens? Which of the \(n\) variants of divisive \(n!\) does the program produce?</p>
<p>Here’s <em>my</em> favorite algorithm for computing factorials, in the form of a <a href="https://julialang.org/">Julia</a> program:</p>
<pre class="language-julia"><code>function mul!(n)
    if n == 1
        return 1
    else
        return n * mul!(n - 1)
    end
end
</code></pre>
<p>This is the algorithm that has introduced generations of nerds to the concept of recursion. In narrative form it says: If \(n\) is \(1\), then \(mul!(n)\) is \(1\). Otherwise, evaluate the function \(mul!(n-1)\), then multiply the result by \(n\). You might ask what happens if \(n\) is zero or negative. You might ask, but please don’t. For present purposes, \(n \in \mathbb{N}\).Starting with any positive \(n\), the sequence of recursive calls must eventually bottom out with \(n = 1\).</p>
<p>The function can be written more tersely using Julia’s one-liner style of definition:.</p>
<pre class="language-julia"><code>mul!(n)  =  n == 1 ? 1 : n * mul!(n - 1)</code></pre>
<p>The right side of the assignment statement is a conditional expression, or ternary operator, which has the form <code>a ? b : c</code>. Here <code>a</code> is a boolean test clause, which must return a value of either <code>true</code> or <code>false</code>. If <code>a</code> is <code>true</code>, clause <code>b</code> is evaluated, and the result becomes the value of the entire expression. Otherwise clause <code>c</code> is evaluated.</p>
<p>Just to be sure I’ve got this right, here are the first 10 factorials, as calculated by this program:</p>
<pre class="language-julia"><code>[mul!(n) for n in 1:10]
10-element Array{Int64,1}:
       1
       2
       6
      24
     120
     720
    5040
   40320
  362880
 3628800</code></pre>
<p class="indent">Now let’s edit that definition and convert the single occurence of <code>*</code> to a <code>/</code>, leaving everything else (except the name of the function) unchanged.</p>
<pre class="language-julia"><code>div!(n)  =  n == 1 ? 1 : n / div!(n - 1)</code></pre>
<p>And here’s what comes back when we run the program for values of \(n\) from \(1\) through \(20\):</p>
<pre class="language-julia"><code>[div!(n) for n in 1:20]
20-element Array{Real,1}:
 1                 
 2.0               
 1.5               
 2.6666666666666665
 1.875             
 3.2               
 2.1875            
 3.657142857142857 
 2.4609375         
 4.063492063492063 
 2.70703125        
 4.432900432900433 
 2.9326171875      
 4.773892773892774 
 3.14208984375     
 5.092152292152292 
 3.338470458984375 
 5.391690662278897 
 3.523941040039063 
 5.675463855030418 </code></pre>
<p>Huh? That sure doesn’t look like it’s converging to zero—not as \(\frac{1}{n!}\) or as \(\frac{n}{n - 1}\). As a matter of fact, it doesn’t look like it’s going to converge at all. The graph below suggests the sequence is made up of two alternating components, both of which appear to be slowly growing toward infinity as well as diverging from one another.</p>
<p><img alt="Div" border="0" class="aligncenter" height="" src="http://bit-player.org/wp-content/uploads/2019/02/div.svg" width=""/></p>
<p class="indent">In trying to make sense of what we’re seeing here, it helps to change the output type of the <code>div!</code> function. Instead of applying the division operator <code>/</code>, which returns the quotient as a floating-point number, we can substitute the  <code>//</code> operator, which returns an exact rational quotient, reduced to lowest terms.</p>
<pre class="language-julia"><code>div!(n)  =  n == 1 ? 1 : n // div!(n - 1)</code></pre>
<p class="undent">Here’s the sequence of values for <code>n in 1:20</code>:</p>
<pre class="language-julia"><code>20-element Array{Real,1}:
       1      
      2//1    
      3//2    
      8//3    
     15//8    
     16//5    
     35//16   
    128//35   
    315//128  
    256//63   
    693//256  
   1024//231  
   3003//1024 
   2048//429  
   6435//2048 
  32768//6435 
 109395//32768
  65536//12155
 230945//65536
 262144//46189 </code></pre>
<p>The list is full of curious patterns. It’s a double helix, with even numbers and odd numbers zigzagging in complementary strands. The even numbers are not just even; they are all powers of \(2\). Also, they appear in pairs—first in the numerator, then in the denominator—and their sequence is nondecreasing. But there are gaps; not all powers of \(2\) are present. The odd strand looks even more complicated, with various small prime factors flitting in and out of the numbers. (The primes <em>have</em> to be small—smaller than \(n\), anyway.)</p>
<p>This outcome took me by surprise. I had really expected to see a much tamer sequence, like those I worked out with pencil and paper. All those jagged, jitterbuggy ups and downs made no sense. Nor did the overall trend of unbounded growth in the ratio. How could you keep dividing and dividing, and wind up with bigger and bigger numbers?</p>
<p>At this point you may want to pause before reading on, and try to work out your own theory of where these zigzag numbers are coming from. If you need a hint, you can get a strong one—almost a spoiler—by looking up the sequence of numerators or the sequence of denominators in the <a href="http://oeis.org">Online Encyclopedia of Integer Sequences</a>.</p>
<hr/>
<p>Here’s another hint. A small edit to the <code>div!</code> program completely transforms the output. Just flip the final clause, changing <code>n // div!(n - 1)</code> into <code>div!(n - 1) // n</code>. </p>
<pre class="language-julia"><code>div!(n)  =  n == 1 ? 1 : div!(n - 1) // n</code></pre>
<p class="undent">Now the results look like this:</p>
<pre class="language-julia"><code>10-element Array{Real,1}:
  1                    
 1//2                  
 1//6                  
 1//24                 
 1//120                
 1//720                
 1//5040               
 1//40320              
 1//362880             
 1//3628800</code></pre>
<p>This is the inverse factorial function we’ve already seen, the series of quotients generated when you march left to right through an ascending sequence of divisors \(1 \mathbin{/} 2 \mathbin{/}  3 \mathbin{/} \cdots \mathbin{/} n\). </p>
<p>It’s no surprise that flipping the final clause in the procedure alters the outcome. After all, we know that division is not commutative or associative. What’s not so easy to see is why the sequence of quotients generated by the original program takes that weird zigzag form. What mechanism is giving rise to those paired powers of 2 and the alternation of odd and even?</p>
<p>I have found that it’s easier to explain what’s going on in the zigzag sequence when I describe an iterative version of the procedure, rather than the recursive one. (This is an embarrassing admission for someone who has argued that recursive definitions are easier to reason about, but there you have it.) Here’s the program:</p>
<pre class="language-julia"><code>function div!_iter(n)
    q = 1
    for i in 1:n
        q = i // q
    end
    return q
end</code></pre>
<p>I submit that this looping procedure is operationally identical to the recursive function, in the sense that if <code>div!(n)</code> and <code>div!_iter(n)</code> both return a result for some positive integer <code>n</code>, it will always be the same result. Here’s my evidence: </p>
<pre class="language-julia"><code>[div!(n) for n in 1:20]    [div!_iter(n) for n in 1:20]
            1                         1//1    
           2//1                       2//1    
           3//2                       3//2    
           8//3                       8//3    
          15//8                      15//8    
          16//5                      16//5    
          35//16                     35//16   
         128//35                    128//35   
         315//128                   315//128  
         256//63                    256//63   
         693//256                   693//256  
        1024//231                  1024//231  
        3003//1024                 3003//1024 
        2048//429                  2048//429  
        6435//2048                 6435//2048 
       32768//6435                32768//6435 
      109395//32768              109395//32768
       65536//12155               65536//12155
      230945//65536              230945//65536
      262144//46189              262144//46189</code></pre>
<p>To understand the process that gives rise to these numbers, consider the successive values of the variables \(i\) and \(q\) each time the loop is executed. Initially, \(i\) and \(q\) are both set to \(1\); hence, after the first passage through the loop, the statement <code>q = i // q</code> gives \(q\) the value \(\frac{1}{1}\). Next time around, \(i = 2\) and \(q = \frac{1}{1}\), so \(q\)’s new value is \(\frac{2}{1}\). On the third iteration, \(i = 3\) and \(q = \frac{2}{1}\), yielding \(\frac{i}{q} \rightarrow \frac{3}{2}\). If this is still confusing, try thinking of \(\frac{i}{q}\) as \(i \times \frac{1}{q}\). The crucial observation is that on every passage through the loop, \(q\) is inverted, becoming \(\frac{1}{q}\).</p>
<p>If you unwind these operations, and look at the multiplications and divisions that go into each element of the series, a pattern emerges:</p>
<p>\[\frac{1}{1}, \quad \frac{2}{1}, \quad \frac{1 \cdot 3}{2}, \quad \frac{2 \cdot 4}{1 \cdot 3}, \quad \frac{1 \cdot 3 \cdot 5}{2 \cdot 4} \quad \frac{2 \cdot 4 \cdot 6}{1 \cdot 3 \cdot 5}\]</p>
<p class="undent">The general form is:</p>
<p>\[\frac{1 \cdot 3 \cdot 5 \cdot \cdots \cdot n}{2 \cdot 4 \cdot \cdots \cdot (n-1)} \quad (\text{odd } n) \qquad  \frac{2 \cdot 4 \cdot 6 \cdot \cdots \cdot n}{1 \cdot 3 \cdot 5 \cdot \cdots \cdot (n-1)} \quad (\text{even } n).<br/>
\]</p>
<hr/>
<p>The functions \(1 \cdot 3 \cdot 5 \cdot \cdots \cdot n\) for odd \(n\) and \(2 \cdot 4 \cdot 6 \cdot \cdots \cdot n\) for even \(n\) have a name! They are known as double factorials, with the notation \(n!!\). Terrible terminology, no? Better to have named them “semi-factorials.” And if I didn’t know better, I would read \(n!!\) as “the factorial of the factorial.” The double factorial of <em>n</em> is defined as the product of <em>n</em> and all smaller positive integers of the same parity. Thus our peculiar sequence of zigzag quotients is simply \(\frac{n!!}{(n-1)!!}\).</p>
<p>A <a href="https://www.tandfonline.com/doi/abs/10.4169/math.mag.85.3.177">2012 article</a> by Henry W. Gould and Jocelyn Quaintance (behind a paywall, regrettably) surveys the applications of double factorials. They turn up more often than you might guess. In the middle of the 17th century John Wallis came up with this identity:</p>
<p>\[\frac{\pi}{2} = \frac{2 \cdot 2 \cdot 4 \cdot 4 \cdot 6 \cdot 6 \cdots}{1 \cdot 3 \cdot 3 \cdot 5 \cdot 5 \cdot 7 \cdots} = \lim_{n \rightarrow \infty} \frac{((2n)!!)^2}{(2n + 1)!!(2n - 1)!!}\]</p>
<p class="undent">An even weirder series, involving the cube of a quotient of double factorials, sums to \(\frac{2}{\pi}\). That one was discovered by (who else?) Srinivasa Ramanujan.</p>
<p>Gould and Quaintance also discuss the double factorial counterpart of binomial coefficients. The standard binomial coefficient is defined as:</p>
<p>\[\binom{n}{k} = \frac{n!}{k! (n-k)!}.\]</p>
<p class="undent">The double version is:</p>
<p>\[\left(\!\binom{n}{k}\!\right) = \frac{n!!}{k!! (n-k)!!}.\]</p>
<p class="undent">Note that our zigzag numbers fit this description and therefore qualify as double factorial binomial coefficients. Specifically, they are the numbers:</p>
<p>\[\left(\!\binom{n}{1}\!\right) = \left(\!\binom{n}{n - 1}\!\right) = \frac{n!!}{1!! (n-1)!!}.\]</p>
<p class="undent">The regular binomial \(\binom{n}{1}\) is not very interesting; it is simply equal to \(n\). But the doubled version \(\left(\!\binom{n}{1}\!\right)\), as we’ve seen, dances a livelier jig. And, unlike the single binomial, it is not always an integer. (The only integer values are \(1\) and \(2\).)</p>
<p>Seeing the zigzag numbers as ratios of double factorials explains quite a few of their properties, starting with the alternation of evens and odds. We can also see why all the even numbers in the sequence are powers of 2. Consider the case of \(n = 6\). The numerator of this fraction is \(2 \cdot 4 \cdot 6 = 48\), which acquires a factor of \(3\) from the \(6\). But the denominator is \(1 \cdot 3 \cdot 5 = 15\). The \(3\)s above and below cancel, leaving \(\frac{16}{5}\). Such cancelations will happen in every case. Whenever an odd factor \(m\) enters the even sequence, it must do so in the form \(2 \cdot m\), but at that point \(m\) itself must already be present in the odd sequence.</p>
<hr/>
<p>Is the sequence of zigzag numbers a reasonable answer to the question, “What happens when you divide instead of multiply in \(n!\)?” Or is the computer program that generates them just a buggy algorithm? My personal judgment is that \(\frac{1}{n!}\) is a more intuitive answer, but \(\frac{n!!}{(n - 1)!!}\) is more interesting.</p>
<p>Furthermore, the mere existence of the zigzag sequence broadens our horizons. As noted above, if you insist that the division algorithm must always chug along the list of \(n\) factors in order, at each stop dividing the number on the left by the number on the right, then there are only \(n\) possible outcomes, and they all look much alike. But the zigzag solution suggests wilder possibilities. We can formulate the task as follows. Take the set of factors \(\{1 \dots n\}\), select a subset, and invert all the elements of that subset; now multiply all the factors, both the inverted and the upright ones. If the inverted subset is empty, the result is the ordinary factorial \(n!\). If <em>all</em> of the factors are inverted, we get the inverse \(\frac{1}{n!}\). And if every second factor is inverted, starting with \(n - 1\), the result is an element of the zigzag sequence.</p>
<p>These are only a few among the many possible choices; in total there are \(2^n\) subsets of \(n\) items. For example, you might invert every number that is prime or a power of a prime \((2, 3, 4, 5, 7, 8, 9, 11, \dots)\). For small \(n\), the result jumps around but remains consistently less than \(1\):</p>
<p><img alt="Prime powers" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/prime-powers.svg" width=""/></p>
<p class="undent">If I were to continue this plot to larger \(n\), however, it would take off for the stratosphere. Prime powers get sparse farther out on the number line.</p>
<hr/>
<p>Here’s a question. We’ve seen factorial variants that go to zero as \(n\) goes to infinity, such as \(1/n!\). We’ve seen other variants grow without bound as \(n\) increases, including \(n!\) itself, and the zigzag numbers. Are there any versions of the factorial process that converge to a finite bound other than zero?</p>
<p>My first thought was this algorithm:</p>
<pre class="language-julia"><code>function greedy_balance(n)
    q = 1
    while n &gt; 0
        q = q &gt; 1 ? q /= n : q *= n
        n -= 1
    end
    return q
end</code></pre>
<p class="undent">We loop through the integers from \(n\) down to \(1\), calculating the running product/quotient \(q\) as we go. At each step, if the current value of \(q\) is greater than \(1\), we divide by the next factor; otherwise, we multiply. This scheme implements a kind of feedback control or target-seeking behavior. If \(q\) gets too large, we reduce it; too small and we increase it. I conjectured that as \(n\) goes to infinity, \(q\) would settle into an ever-narrower range of values near \(1\).</p>
<p>Running the experiment gave me another surprise:</p>
<p><img alt="Greedy balance linear" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/greedy_balance_linear.svg" width=""/></p>
<p class="undent">That sawtooth wave is not quite what I expected. One minor peculiarity is that the curve is not symmetric around \(1\); the excursions above have higher amplitude than those below. But this distortion is more visual than mathematical. Because \(q\) is a ratio, the distance from \(1\) to \(10\) is the same as the distance from \(1\) to \(\frac{1}{10}\), but it doesn’t look that way on a linear scale. The remedy is to plot the log of the ratio:</p>
<p><img alt="Greedy balance" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/greedy_balance.svg" width=""/></p>
<p>Now the graph is symmetric, or at least approximately so, centered on \(0\), which is the logarithm of \(1\). But a larger mystery remains. The sawtooth waveform is very regular, with a period of \(4\), and it shows no obvious signs of shrinking toward the expected limiting value of \(\log q = 0\). Numerical evidence suggests that as \(n\) goes to infinity the peaks of this curve converge on a value just above \(q = \frac{5}{3}\), and the troughs approach a value just below \(q = \frac{3}{5}\). (The corresponding base-\(10\) logarithms are roughly \(\pm0.222\). I have not worked out why this should be so. Perhaps someone will explain it to me.</p>
<p>The failure of this greedy algorithm doesn’t mean we can’t find a divisive factorial that converges to \(q = 1\). If we work with the logarithms of the factors, this procedure becomes an instance of a well-known compu­tational problem called the number partitioning problem. You are given a set of real numbers and asked to divide it into two sets whose sums are equal, or as close to equal as possible. It’s a certifiably hard problem, but it has also been called (<a href="http://bit-player.org/bph-publications/AmSci-2002-03-Hayes-NPP.pdf">PDF</a>) “the easiest hard problem.”For any given \(n\), we might find that inverting some other subset of the factors gives a better approximation to \(n! = 1\). For small \(n\), we can solve the problem by brute force: Just look at all \(2^n\) subsets and pick the best one.</p>
<p>I have computed the optimal partitionings up to \(n = 30\), where there are a billion possibilities to choose from.</p>
<p><img alt="Optimum balance graph" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/optimum_balance_graph.svg" width=""/></p>
<p class="undent">The graph is clearly flatlining. You could use the same method to force convergence to any other value between \(0\) and \(n!\).</p>
<p>And thus we have yet another answer to the question in the tweet that launched this adventure. What happens when you divide instead of multiply in n!? Anything you want.</p></div>
    </content>
    <updated>2019-02-10T08:48:33Z</updated>
    <published>2019-02-10T08:48:33Z</published>
    <category scheme="http://bit-player.org" term="computing"/>
    <category scheme="http://bit-player.org" term="mathematics"/>
    <author>
      <name>Brian Hayes</name>
      <uri>http://bit-player.org</uri>
    </author>
    <source>
      <id>http://bit-player.org/feed/atom</id>
      <link href="http://bit-player.org" rel="alternate" type="text/html"/>
      <link href="http://bit-player.org/feed/atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">An amateur's outlook on computation and mathematics</subtitle>
      <title xml:lang="en-US">bit-player</title>
      <updated>2019-02-18T20:39:20Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra</id>
    <link href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html" rel="alternate" type="text/html"/>
    <title>Big convex polyhedra in grids</title>
    <summary>I recently wrote here about big convex polygons in grids, a problem for which we know very precise answers. This naturally raises the question: what about higher dimensions? How many vertices can be part of a convex polyhedron in an grid, or more generally a convex polytope in a -dimensional grid of side length ? Here we do still know some pretty good answers, at least up to constant factors in spaces of constant dimension.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I recently wrote here about <a href="https://11011110.github.io/blog/2018/09/05/big-convex-polygons.html">big convex polygons in grids</a>, a problem for which we know very precise answers. This naturally raises the question: what about higher dimensions? How many vertices can be part of a convex polyhedron in an  grid, or more generally a convex polytope in a -dimensional grid of side length ? Here we do still know some pretty good answers, at least up to constant factors in spaces of constant dimension.</p>

<p>The problem is included in a 2008 survey by Imre Bárány,<sup id="fnref:bar"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bar">1</a></sup> according to whom the maximum number of vertices is</p>



<p>For instance, in three dimensional  grids the maximum number of vertices is .</p>

<p>One way to find polyhedra with this many vertices is to take the convex hull of the points in a ball,<sup id="fnref:bl"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bl">2</a></sup> <sup id="fnref:bd"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bd">3</a></sup> or in scaled copies of any fixed smooth convex body. Another way, which should generate polyhedra with a somewhat less irregular appearance and (up to constant factors) the same number of vertices, is to take the <a href="https://en.wikipedia.org/wiki/Minkowski_addition">Minkowski sum</a> of all line segments (up to scaling and translation) that will fit into a smaller grid, of side length . For instance, the <a href="https://en.wikipedia.org/wiki/Truncated_rhombicuboctahedron">truncated rhombicuboctahedron</a> below<sup id="fnref:ruen"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:ruen">4</a></sup> is the Minkowski sum of all the line segments that fit into a unit cube. Its 96 vertices lie in a  grid. In general, this method produces a <a href="https://en.wikipedia.org/wiki/Zonohedron">zonohedron</a> whose complexity can be analyzed in terms of a -dimensional arrangement of  hyperplanes. As long as this arrangement is not too degenerate (which it appears not to be, but I haven’t worked out the details carefully) this should give
a number of vertices within a constant factor of the number coming from the convex hull construction.</p>

<p style="text-align: center;"><img alt="Truncated rhombicuboctahedron" src="https://11011110.github.io/blog/assets/2019/truncated-rhombicuboctahedron2.png"/></p>

<p>A matching upper bound comes from a 1963 paper by G. K. Andrews,<sup id="fnref:and"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:and">5</a></sup> and Bárány writes that although several more proofs have been published none of them is easy. I’m not sure whether the difficulty is in getting the exact bound or in the fact that Andrews and the later proofs allow more general shapes with volume  that don’t fit into a grid, but it’s not hard to get close to the right bound simply by counting the number of possible facets of a given volume . By using <a href="https://en.wikipedia.org/wiki/Lenstra%E2%80%93Lenstra%E2%80%93Lov%C3%A1sz_lattice_basis_reduction_algorithm">lattice basis reduction</a> the integer vectors in the hyperplane through any facet have a nearly-orthogonal basis whose product of lengths is proportional to . By considering how this product of lengths can be broken down into factors of different scales, and counting how many integer vectors of those lengths exist, it follows that the number of possible facets of volume  is . Combining this with the  surface area of a grid polytope gives the correct upper bound on the number of vertices up to a polylog factor.</p>

<p>What about when the dimension is not constant? An easy construction for high dimensions is to take all points with a fixed distance  from the grid center. There are  possible values for the distance, so this construction produces a convex polytope with  vertices. It comes from a 1946 paper by Behrend, who uses this idea to find <a href="https://en.wikipedia.org/wiki/Salem%E2%80%93Spencer_set">dense sets of integers with no arithmetic progressions</a>.<sup id="fnref:beh"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:beh">6</a></sup>
It is never worse to use the convex hull of the ball than the points on a sphere,
and a celebrated paper by Elkin from 2011 (in the appendix of the published version) gives another proof of the  bound for convex hulls of balls (for ) in which the constant factor of the  is universal, not depending on . So when  is singly exponential in ,  becomes constant and the convex hull technique produces  vertices, improving Behrend’s construction for progression-free sets by the same  factor.<sup id="fnref:elk"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:elk">7</a></sup></p>

<div class="footnotes">
  <ol>
    <li id="fn:bar">
      <p>Bárány, Imre (2008), “Extremal problems for convex lattice polytopes: a survey”, <em>Surveys on Discrete and Computational Geometry</em>, Contemporary Mathematics 453, Amer. Math. Soc., pp. 87–103, <a href="https://doi.org/10.1090/conm/453/08796">doi:10.1090/conm/453/08796</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=2405678">MR2405678</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bar">↩</a></p>
    </li>
    <li id="fn:bl">
      <p>Bárány, Imre and Larman, David (1998), “The convex hull of the integer points in a large ball”, <em>Math. Ann.</em> 312 (1), pp. 167–181, <a href="https://doi.org/10.1007/s002080050217">doi:10.1007/s002080050217</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=1645957">MR1645957</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bl">↩</a></p>
    </li>
    <li id="fn:bd">
      <p>Balog, Antal and Deshouillers, Jean-Marc (1999), “On some convex lattice polytopes”. <em>Number Theory in Progress</em>, Vol. 2 (Zakopane-Kościelisko, 1997), de Gruyter, pp. 591–606, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=1689533">MR1689533</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bd">↩</a></p>
    </li>
    <li id="fn:ruen">
      <p>Ruen, Tom (2014), “Truncated rhombicuboctahedron”, CC-BY-SA 4.0, <a href="https://commons.wikimedia.org/wiki/File:Truncated_rhombicuboctahedron2.png">File:Truncated rhombicuboctahedron2.png</a> on Wikimedia commons. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:ruen">↩</a></p>
    </li>
    <li id="fn:and">
      <p>Andrews, George E. (1963), “A lower bound for the volume of strictly convex bodies with many boundary lattice points”, <em>Trans. Amer. Math. Soc.</em> 106, pp. 270–279, <a href="https://doi.org/10.2307/1993769">doi:10.2307/1993769</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=0143105">MR0143105</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:and">↩</a></p>
    </li>
    <li id="fn:beh">
      <p>Behrend, F. A. (1946), “On sets of integers which contain no three terms in arithmetical progression”, <em>Proc. Nat. Acad. Sci.</em> 32 (12), pp. 331–332, <a href="https://doi.org/10.1073/pnas.32.12.331">doi:10.1073/pnas.32.12.331</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=0018694">MR0018694</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:beh">↩</a></p>
    </li>
    <li id="fn:elk">
      <p>Elkin, Michael (2011), “An improved construction of progression-free sets”, <em>Israel J. Math.</em> 184, pp. 93–128, <a href="https://arxiv.org/abs/0801.4310">arXiv:0801.4310</a>, <a href="https://doi.org/10.1007%2Fs11856-011-0061-1">doi:10.1007/s11856-011-0061-1</a>, <a href="https://www.ams.org/mathscinet-getitem?mr=2823971">MR2823971</a>. The paragraph describing Elkin’s results was updated from an earlier more tentative version in the original post. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:elk">↩</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/101564963348879092">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-02-09T15:07:00Z</updated>
    <published>2019-02-09T15:07:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-02-22T05:13:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1087</id>
    <link href="https://ptreview.sublinear.info/?p=1087" rel="alternate" type="text/html"/>
    <title>News for January 2019</title>
    <summary>Minimax Testing of Identity to a Reference Ergodic Markov Chain, by Geoffrey Wolfer and Aryeh Kontorovich (arXiv). This work studies distributional identity testing on Markov chains from a single trajectory, as recently introduced by Daskalakis, Dikkala, and Gravin: we wish to test whether a Markov chain is equal to some reference chain, or far from […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Minimax Testing of Identity to a Reference Ergodic Markov Chain</strong>, by Geoffrey Wolfer and Aryeh Kontorovich (<a href="https://arxiv.org/abs/1902.00080">arXiv</a>). This work studies distributional identity testing on Markov chains from a single trajectory, as recently introduced by <a href="https://arxiv.org/abs/1704.06850">Daskalakis, Dikkala, and Gravin</a>: we wish to test whether a Markov chain is equal to some reference chain, or far from it. This improves on previous work by considering a stronger distance measure than before, and showing that the sample complexity only depends on properties of the reference chain (which we are trying to test identity to). It additionally proves instance-by-instance bounds (where the sample complexity depends on properties of the specific chain we wish to test identity to).</p>



<p><strong>Almost Optimal Distribution-free Junta Testing</strong>, by Nader H. Bshouty (<a href="https://arxiv.org/abs/1901.00717">arXiv</a>). This paper provides a \(\tilde O(k/\varepsilon)\)-query algorithm with two-sided error for testing if a Boolean function is a \(k\)-junta (that is, its value depends only on \(k\) of its variables) in the distribution-free model (where distance is measured with respect to an unknown distribution from which we can sample). This complexity is a quadratic improvement over the \(\tilde O(k^2)/\varepsilon\)-query algorithm of <a href="https://arxiv.org/abs/1802.04859">Chen, Liu, Servedio, Sheng, and Xie</a>. This complexity is also near-optimal, as shown in a lower bound by Saglam (which we covered back in <a href="https://ptreview.sublinear.info/?p=1030">August</a>).</p>



<p><strong>Exponentially Faster Massively Parallel Maximal Matching</strong>, by Soheil Behnezhad, MohammadTaghi Hajiaghayi, and David G. Harris (<a href="https://arxiv.org/abs/1901.03744">arXiv</a>). The authors consider maximal matching in the Massively Parallel Computation (MPC) model. They show that one can compute a maximal matching in \(O(\log \log \Delta)\)-rounds, with \(O(n)\) space per machine. This is an exponential improvement over the previous works, which required either \(\Omega(\log n)\) rounds or \(n^{1 + \Omega(1)}\) space per machine. Corollaries of their result include approximation algorithms for vertex cover, maximum matching, and weighted maximum matching. </p></div>
    </content>
    <updated>2019-02-08T18:30:54Z</updated>
    <published>2019-02-08T18:30:54Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-02-22T23:32:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3379</id>
    <link href="https://agtb.wordpress.com/2019/02/08/acm-sigecom-elections/" rel="alternate" type="text/html"/>
    <title>ACM SIGecom Elections</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The following message just went out to ACM SIGecom members: ———- Forwarded message ——— From: Monique Chang &lt;chang@hq.acm.org&gt; Date: Mon, Feb 4, 2019 at 2:20 PM Subject: 2019 ACM SIGecom Election: Candidate Slate Announcement To: &lt;SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org&gt; Dear ACM SIGecom Member, The ACM SIGecom Nominating Committee has proposed the following candidates for the 2019 ACM SIGecom election. Chair … … <a href="https://agtb.wordpress.com/2019/02/08/acm-sigecom-elections/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><span style="font-weight: 400;">The following message just went out to ACM SIGecom members:</span></p>
<blockquote><p>———- Forwarded message ———<br/>
From: <strong>Monique Chang</strong> &lt;<a href="mailto:chang@hq.acm.org">chang@hq.acm.org</a>&gt;<br/>
Date: Mon, Feb 4, 2019 at 2:20 PM<br/>
Subject: 2019 ACM SIGecom Election: Candidate Slate Announcement<br/>
To: &lt;<a href="mailto:SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org">SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org</a>&gt;</p>
<p>Dear ACM SIGecom Member,</p>
<p>The ACM SIGecom Nominating Committee has proposed the following candidates for the 2019 ACM SIGecom election.</p>
<p><strong><u>Chair</u></strong><br/>
(Running Unopposed)</p>
<p>Nicole Immorlica</p>
<p><strong><u>Vice-Chair</u></strong></p>
<p>Scott Kominers</p>
<p>Ariel Procaccia</p>
<p><strong><u>Secretary-Treasurer</u></strong></p>
<p>Hu Fu</p>
<p>Katrina Ligett</p>
<p>In accordance with the ACM SIG Bylaws, additional candidates may be placed on the ballot by petition. All candidates must be ACM Professional Members, as well as members of the SIG. Anyone interested in petitioning must inform ACM Headquarters, Pat Ryan (<a href="mailto:ryanp@hq.acm.org">ryanp@hq.acm.org</a>), and SIGecom’s Secretary-Treasurer, Jenn Wortman Vaughan (<a href="mailto:jenn@microsoft.com">jenn@microsoft.com</a>), of their intent to petition by <strong>15 March 2019</strong>. Petitions must be submitted to ACM Headquarters for verification by <strong>2 April 2019</strong>.</p>
<p>Monique Chang</p>
<p>ACM SIG Elections Coordinator</p>
<p>Office of Policy and Administration</p></blockquote>
<p><span style="font-weight: 400;">Three things for members of our community to note:</span></p>
<ol>
<li style="font-weight: 400;">It’s important vote (once the link goes out; note that the current email is just an announcement and an invitation for additional candidates to petition to be included on the ballot). The SIG leadership is very important for the ongoing direction of our organization. Your vote makes a difference, because our elections are often decided by small margins.</li>
</ol>
<ol start="2">
<li style="font-weight: 400;">If you didn’t get this email, you’re likely not registered as a member of our SIG. Membership costs only $5 for students and $10 for others; AFAIK, you don’t have to be an ACM member to be a SIG member. Our number of members is an important signal to the ACM about the strength of our community (which is why we have set our fees so low). Votes like this one are also restricted to members! If your membership has lapsed, or if you’ve never taken the plunge, this might be a good occasion to do so, by clicking on the link below:</li>
</ol>
<p style="font-weight: 400;"><a href="https://www.acm.org/special-interest-groups/sigs/sigecom">https://www.acm.org/special-interest-groups/sigs/sigecom</a></p>
<ol start="3">
<li style="font-weight: 400;">Thanks to our nominations chair, David Parkes, who put together the slate of candidates just listed, and also to all of the candidates who agreed to serve. Our community is really lucky to have such a strong and deep pool of volunteers, and this is one more example. Indeed, in advance, I’d particularly like to thank those candidates who *don’t* win, whoever they turn out to be: it’s thankless to stick one’s neck out for an election only to see someone else get chosen (often by a small margin; see #1), but your willingness to serve is much appreciated.</li>
</ol></div>
    </content>
    <updated>2019-02-08T02:44:19Z</updated>
    <published>2019-02-08T02:44:19Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Kevin Leyton-Brown</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-02-23T07:20:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/017</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/017" rel="alternate" type="text/html"/>
    <title>TR19-017 |  Fourier bounds and pseudorandom generators for product tests | 

	Chin Ho Lee</title>
    <summary>We study the Fourier spectrum of functions $f\colon \{0,1\}^{mk} \to \{-1,0,1\}$ which can be written as a product of $k$ Boolean functions $f_i$ on disjoint $m$-bit inputs.  We prove that for every positive integer $d$,
\[
  \sum_{S \subseteq [mk]: |S|=d} |\hat{f_S}| = O(m)^d .
\]
Our upper bound is tight up to a constant factor in the $O(\cdot)$.  Our proof builds on a new "level-$d$ inequality" that bounds above $\sum_{|S|=d} \hat{f_S}^2$ for any $[0,1]$-valued function $f$ in terms of its expectation, which may be of independent interest.

As a result, we construct pseudorandom generators for such functions with seed length $\tilde O(m + \log(k/\varepsilon))$, which is optimal up to polynomial factors in $\log m$, $\log\log k$ and $\log\log(1/\varepsilon)$.  Our generator in particular works for the well-studied class of combinatorial rectangles, where in addition we allow the bits to be read in any order.  Even for this special case, previous generators have an extra $\tilde O(\log(1/\varepsilon))$ factor in their seed lengths. 

Using Schur-convexity, we also extend our results to functions $f_i$ whose range is $[-1,1]$.</summary>
    <updated>2019-02-07T14:59:22Z</updated>
    <published>2019-02-07T14:59:22Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-23T07:20:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/016</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/016" rel="alternate" type="text/html"/>
    <title>TR19-016 |  The hardest halfspace | 

	Alexander A. Sherstov</title>
    <summary>We study the approximation of halfspaces $h:\{0,1\}^n\to\{0,1\}$ in the infinity norm by polynomials and rational functions of any given degree.  Our main result is an explicit construction of the "hardest" halfspace, for which we prove polynomial and rational approximation lower bounds that match the trivial upper bounds achievable for all halfspaces.  This completes a lengthy line of work started by Myhill and Kautz (1961).

As an application, we construct a communication problem with essentially the largest possible gap, of $n$ versus $2^{-\Omega(n)},$ between the sign-rank and discrepancy. Equivalently, our problem exhibits a gap of $\log n$ versus $\Omega(n)$ between the communication complexity with unbounded versus weakly unbounded error, improving quadratically on previous constructions and completing a line of work started by Babai, Frankl, and Simon (FOCS 1986). Our results further generalize to the $k$-party number-on-the-forehead model, where we obtain an explicit separation of $\log n$ versus $\Omega(n/4^{n})$ for communication with unbounded versus weakly unbounded error. This gap is a quadratic improvement on previous work and matches the state of the art for number-on-the-forehead lower bounds.</summary>
    <updated>2019-02-07T14:57:13Z</updated>
    <published>2019-02-07T14:57:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-23T07:20:43Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-971154734717743655</id>
    <link href="https://blog.computationalcomplexity.org/feeds/971154734717743655/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/an-immerman-szelepcsenyi-story.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/971154734717743655" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/971154734717743655" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/an-immerman-szelepcsenyi-story.html" rel="alternate" type="text/html"/>
    <title>An Immerman-Szelepcsényi Story</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">As a grad student in the late 80's I had the opportunity to witness many great and often surprising theorems in computational complexity. Let me tell you about one of them, the Immerman-Szelepcsényi result that <a href="https://blog.computationalcomplexity.org/2003/06/foundations-of-complexity-lesson-19.html">nondeterministic space is closed under complement</a>. I wish I had the original emails for this story but instead I'm working from memory and apologies if I get some of the details wrong. I'm expanding from a <a href="https://blog.computationalcomplexity.org/2002/08/last-spring-i-saw-copenhagen-great.html">short version</a> from the early days of this blog.<br/>
<br/>
I started my graduate work at UC Berkeley in 1985 and then moved to MIT in the summer of '86, following my advisor Michael Sipser. In the summer of 1987, Neil Immerman, then at Yale, proved his famous result building on his work in <a href="https://en.wikipedia.org/wiki/Descriptive_complexity_theory">descriptive complexity</a> In those days you didn't email papers, he made copies and sent them by US postal mail to several major researchers in complexity including Sipser. But Sipser was away for the summer, I believe in Russia, and the paper sat in his office.<br/>
<br/>
Immerman also sent the paper to a Berkeley professor, probably Manuel Blum, who gave it to one of his students who decided to speak about the result in a student-led seminar. I forgot who was the student, maybe Moni Naor. I was still on the Berkeley email list so I got the talk announcement and went into complexity ecstasy over the news. I asked Moni (or whomever was giving the talk) if he could tell me details and he sent me a nice write-up of the proof. Given the importance of the result, I sent the proof write-up out to the MIT theory email list.<br/>
<br/>
Guess who was on the MIT theory list? Neil Immerman. Neil wrote back with his own explanation of the proof. Neil explained how it came out of descriptive complexity but as a pure write-up of a proof of the theorem, Moni did an excellent job.<br/>
<br/>
We found out about Robert Szelepcsényi when his paper showed up a few months later in the Bulletin of the European Association for Theoretical Computer Science. Szelepcsényi came to the problem from formal languages, whether context-sensitive languages (nondeterministic linear space) was closed under complement. Szelepcsényi, an undergrad in Slovakia at the time, heard about the problem in a class he took. Szelepcsényi's proof was very similar to Immerman. Szelepcsényi's paper took longer to get to US researchers but likely was proven and written about the same time as Immerman.<br/>
<br/>
Even though both papers were <a href="https://doi.org/10.1137/0217058">published</a> <a href="https://doi.org/10.1007/BF00299636">separately</a> we refer to the result as Immerman-Szelepcsényi and is now just some old important theorem you see in introductory theory classes.</div>
    </content>
    <updated>2019-02-07T12:47:00Z</updated>
    <published>2019-02-07T12:47:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-23T07:12:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/015</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/015" rel="alternate" type="text/html"/>
    <title>TR19-015 |  QMA Lower Bounds for Approximate Counting | 

	William Kretschmer</title>
    <summary>We prove a query complexity lower bound for $QMA$ protocols that solve approximate counting: estimating the size of a set given a membership oracle. This gives rise to an oracle $A$ such that $SBP^A \not\subset QMA^A$, resolving an open problem of Aaronson [2]. Our proof uses the polynomial method to derive a lower bound for the $SBQP$ query complexity of the $AND$ of two approximate counting instances. We use Laurent polynomials as a tool in our proof, showing that the "Laurent polynomial method" can be useful even for problems involving ordinary polynomials.</summary>
    <updated>2019-02-07T08:16:08Z</updated>
    <published>2019-02-07T08:16:08Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-23T07:20:43Z</updated>
    </source>
  </entry>
</feed>
