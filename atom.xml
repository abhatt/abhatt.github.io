<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-02-12T19:21:38Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04045</id>
    <link href="http://arxiv.org/abs/1902.04045" rel="alternate" type="text/html"/>
    <title>Geometric Multicut</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abrahamsen:Mikkel.html">Mikkel Abrahamsen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Giannopoulos:Panos.html">Panos Giannopoulos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/L=ouml=ffler:Maarten.html">Maarten Löffler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rote:G=uuml=nter.html">Günter Rote</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04045">PDF</a><br/><b>Abstract: </b>We study the following separation problem: Given a collection of colored
objects in the plane, compute a shortest "fence" $F$, i.e., a union of curves
of minimum total length, that separates every two objects of different colors.
Two objects are separated if $F$ contains a simple closed curve that has one
object in the interior and the other in the exterior. We refer to the problem
as GEOMETRIC $k$-CUT, where $k$ is the number of different colors, as it can be
seen as a geometric analogue to the well-studied multicut problem on graphs. We
first give an $O(n^4\log^3 n)$-time algorithm that computes an optimal fence
for the case where the input consists of polygons of two colors and $n$ corners
in total. We then show that the problem is NP-hard for the case of three
colors. Finally, we give a $(2-4/3k)$-approximation algorithm.
</p></div>
    </summary>
    <updated>2019-02-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.04023</id>
    <link href="http://arxiv.org/abs/1902.04023" rel="alternate" type="text/html"/>
    <title>Computing Extremely Accurate Quantiles Using t-Digests</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dunning:Ted.html">Ted Dunning</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ertl:Otmar.html">Otmar Ertl</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.04023">PDF</a><br/><b>Abstract: </b>We present on-line algorithms for computing approximations of rank-based
statistics that give high accuracy, particularly near the tails of a
distribution, with very small sketches. Notably, the method allows a quantile
$q$ to be computed with an accuracy relative to $\max(q, 1-q)$ rather than
absolute accuracy as with most other methods. This new algorithm is robust with
respect to skewed distributions or ordered datasets and allows separately
computed summaries to be combined with no loss in accuracy.
</p>
<p>An open-source Java implementation of this algorithm is available from the
author. Independent implementations in Go and Python are also available.
</p></div>
    </summary>
    <updated>2019-02-12T02:55:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03950</id>
    <link href="http://arxiv.org/abs/1902.03950" rel="alternate" type="text/html"/>
    <title>Equivalent Polyadic Decompositions of Matrix Multiplication Tensors</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berger:Guillaume_O=.html">Guillaume O. Berger</a>, P.-A. Absil, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lathauwer:Lieven_De.html">Lieven De Lathauwer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jungers:Rapha=euml=l_M=.html">Raphaël M. Jungers</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barel:Marc_Van.html">Marc Van Barel</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03950">PDF</a><br/><b>Abstract: </b>Invariance transformations of polyadic decompositions of matrix
multiplication tensors define an equivalence relation on the set of such
decompositions. In this paper, we present an algorithm to efficiently decide
whether two polyadic decompositions of a given matrix multiplication tensor are
equivalent. With this algorithm, we analyze the equivalence classes of
decompositions of several matrix multiplication tensors. This analysis is
relevant for the study of fast matrix multiplication as it relates to the
question of how many essentially different fast matrix multiplication
algorithms there exist. This question has been first studied by de~Groote, who
showed that for the multiplication of $2\times2$ matrices with $7$ active
multiplications, all algorithms are essentially equivalent to Strassen's
algorithm. In contrast, the results of our analysis show that for the
multiplication of larger matrices, (e.g., $2\times3$ by $3\times2$ or
$3\times3$ by $3\times3$ matrices), two decompositions are very likely to be
essentially different. We further provide a necessary criterion for a polyadic
decomposition to be equivalent to a polyadic decomposition with integer
entries. Decompositions with specific integer entries, e.g., powers of two,
provide fast matrix multiplication algorithms with better efficiency and
stability properties. This condition can be tested algorithmically and we
present the conclusions obtained for the decompositions of small/medium matrix
multiplication tensors.
</p></div>
    </summary>
    <updated>2019-02-12T02:34:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03883</id>
    <link href="http://arxiv.org/abs/1902.03883" rel="alternate" type="text/html"/>
    <title>A Turing machine simulation by P systems without charges</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leporati:Alberto.html">Alberto Leporati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manzoni:Luca.html">Luca Manzoni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mauri:Giancarlo.html">Giancarlo Mauri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Porreca:Antonio_E=.html">Antonio E. Porreca</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zandron:Claudio.html">Claudio Zandron</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03883">PDF</a><br/><b>Abstract: </b>It is well known that the kind of P systems involved in the definition of the
P conjecture is able to solve problems in the complexity class $\mathbf{P}$ by
leveraging the uniformity condition. Here we show that these systems are indeed
able to simulate deterministic Turing machines working in polynomial time with
a weaker uniformity condition and using only one level of membrane nesting.
This allows us to embed this construction into more complex membrane
structures, possibly showing that constructions similar to the one performed in
[1] for P systems with charges can be carried out also in this case.
</p></div>
    </summary>
    <updated>2019-02-12T02:22:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03879</id>
    <link href="http://arxiv.org/abs/1902.03879" rel="alternate" type="text/html"/>
    <title>Solving QSAT in sublinear depth</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leporati:Alberto.html">Alberto Leporati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manzoni:Luca.html">Luca Manzoni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mauri:Giancarlo.html">Giancarlo Mauri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Porreca:Antonio_E=.html">Antonio E. Porreca</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zandron:Claudio.html">Claudio Zandron</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03879">PDF</a><br/><b>Abstract: </b>Among $\mathbf{PSPACE}$-complete problems, QSAT, or quantified SAT, is one of
the most used to show that the class of problems solvable in polynomial time by
families of a given variant of P systems includes the whole $\mathbf{PSPACE}$.
However, most solutions require a membrane nesting depth that is linear with
respect to the number of variables of the QSAT instance under consideration.
While a system of a certain depth is needed, since depth 1 systems only allows
to solve problems in $\mathbf{P^{\boldsymbol#P}}$, it was until now unclear if
a linear depth was, in fact, necessary. Here we use P systems with active
membranes with charges, and we provide a construction that proves that QSAT can
be solved with a sublinear nesting depth of order $\frac{n}{\log n}$, where $n$
is the number of variables in the quantified formula given as input.
</p></div>
    </summary>
    <updated>2019-02-12T02:28:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03852</id>
    <link href="http://arxiv.org/abs/1902.03852" rel="alternate" type="text/html"/>
    <title>The word problem of the Brin-Thompson groups is coNP-complete</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>J. C. Birget <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03852">PDF</a><br/><b>Abstract: </b>We prove that the word problem of the Brin-Thompson group nV over a finite
generating set is coNP-complete for every n \ge 2. It is known that the groups
$n V$ are an infinite family of infinite, finitely presented, simple groups. We
also prove that the word problem of the Thompson group V over a certain
infinite set of generators, related to boolean circuits, is coNP-complete.
</p></div>
    </summary>
    <updated>2019-02-12T02:34:23Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03820</id>
    <link href="http://arxiv.org/abs/1902.03820" rel="alternate" type="text/html"/>
    <title>Fixed-Parameter Tractable Algorithms for Corridor Guarding Problems</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Remi Raman, R Subashini, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Methirumangalath:Subhasree.html">Subhasree Methirumangalath</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03820">PDF</a><br/><b>Abstract: </b>Given an orthogonal connected arrangement of line-segments, Minimum Corridor
Guarding(MCG) problem asks for an optimal tree/closed walk such that, if a
guard moves through the tree/closed walk, all the line-segments are visited by
the guard. This problem is referred to as Corridor-MST/Corridor-TSP (CMST/CTSP)
for the cases when the guarding walk is a tree/closed walk, respectively. The
corresponding decision version of MCG is shown to be NP-Complete[1]. The
parameterized version of CMST/CTSP referred to as k-CMST/k-CTSP, asks for an
optimal tree/closed walk on at most k vertices, that visits all the
line-segments. Here, vertices correspond to the endpoints and intersection
points of the input line-segments. We show that k-CMST/k-CTSP is
fixed-parameter tractable (FPT) with respect to the parameter k. Next, we
propose a variant of CTSP referred to as Minimum Link CTSP(MLC), in which the
link-distance of the closed walk has to be minimized. Here, link-distance
refers to the number of links or connected line-segments with same orientation
in the walk. We prove that the decision version of MLC is NP-Complete, and show
that the parameterized version, namely b-MLC, is FPT with respect to the
parameter b, where b corresponds to the link-distance. We also consider another
related problem, the Minimum Corridor Connection (MCC). Given a rectilinear
polygon partitioned into rectilinear components or rooms, MCC asks for a
minimum length tree along the edges of the partitions, such that every room is
incident to at least one vertex of the tree. The decision version of MCC is
shown to be NP-Complete[2]. We prove the fixed parameter tractability of the
parameterized version of MCC, namely k-MCC with respect to the parameter k,
where k is the number of rooms.
</p></div>
    </summary>
    <updated>2019-02-12T03:02:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03702</id>
    <link href="http://arxiv.org/abs/1902.03702" rel="alternate" type="text/html"/>
    <title>A Simple Gap-producing Reduction for the Parameterized Set Cover Problem</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Bingkai.html">Bingkai Lin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03702">PDF</a><br/><b>Abstract: </b>Given an $n$-vertex bipartite graph $I=(S,U,E)$, the goal of set cover
problem is to find a minimum sized subset of $S$ such that every vertex in $U$
is adjacent to some vertex of this subset. It is NP-hard to approximate set
cover to within a $(1-o(1))\ln n$ factor. If we use the size of the optimum
solution $k$ as the parameter, then it can be solved in $n^{k+o(1)}$ time. A
natural question is: can we approximate set cover to within an $o(\ln n)$
factor in $n^{k-\epsilon}$ time?
</p>
<p>In a recent breakthrough result, Karthik, Laekhanukit and Manurangsi showed
that assuming the Strong Exponential Time Hypothesis (SETH), for any computable
function $f$, no $f(k)\cdot n^{k-\epsilon}$-time algorithm can approximate set
cover to a factor below $(\log n)^{\frac{1}{poly(k,e(\epsilon))}}$ for some
function $e$.
</p>
<p>This paper presents a simple gap-producing reduction which, given a set cover
instance $I=(S,U,E)$ and two integers $k&lt;h\le (1-o(1))\sqrt[k]{\log
|S|/\log\log |S|}$, outputs a new set cover instance $I'=(S,U',E')$ with
$|U'|=|U|^{h^k}|S|^{O(1)}$ in $|U|^{h^k}\cdot |S|^{O(1)}$ time such that:
</p>
<p>(1) if $I$ has a $k$-sized solution, then so does $I'$;
</p>
<p>(2) if $I$ has no $k$-sized solution, then every solution of $I'$ must
contain at least $h$ vertices.
</p>
<p>Setting $h=(1-o(1))\sqrt[k]{\log |S|/\log\log |S|}$, we show that assuming
SETH, for any computable function $f$, no $f(k)\cdot n^{k-\epsilon}$-time
algorithm can distinguish between a set cover instance with $k$-sized solution
and one whose minimum solution size is at least $(1-o(1))\cdot
\sqrt[k]{\frac{\log n}{\log\log n}}$. This improves the result of Karthik,
Laekhanukit and Manurangsi.
</p></div>
    </summary>
    <updated>2019-02-12T02:22:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03660</id>
    <link href="http://arxiv.org/abs/1902.03660" rel="alternate" type="text/html"/>
    <title>Quantum distinguishing complexity, zero-error algorithms, and statistical zero knowledge</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ben=David:Shalev.html">Shalev Ben-David</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kothari:Robin.html">Robin Kothari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03660">PDF</a><br/><b>Abstract: </b>We define a new query measure we call quantum distinguishing complexity,
denoted QD(f) for a Boolean function f. Unlike a quantum query algorithm, which
must output a state close to |0&gt; on a 0-input and a state close to |1&gt; on a
1-input, a "quantum distinguishing algorithm" can output any state, as long as
the output states for any 0-input and 1-input are distinguishable.
</p>
<p>Using this measure, we establish a new relationship in query complexity: For
all total functions f, Q_0(f)=O~(Q(f)^5), where Q_0(f) and Q(f) denote the
zero-error and bounded-error quantum query complexity of f respectively,
improving on the previously known sixth power relationship.
</p>
<p>We also define a query measure based on quantum statistical zero-knowledge
proofs, QSZK(f), which is at most Q(f). We show that QD(f) in fact lower bounds
QSZK(f) and not just Q(f). QD(f) also upper bounds the (positive-weights)
adversary bound, which yields the following relationships for all f: Q(f) &gt;=
QSZK(f) &gt;= QS(f) = Omega(Adv(f)). This sheds some light on why the adversary
bound proves suboptimal bounds for problems like Collision and Set Equality,
which have low QSZK complexity.
</p>
<p>Lastly, we show implications for lifting theorems in communication
complexity. We show that a general lifting theorem for either zero-error
quantum query complexity or for QSZK would imply a general lifting theorem for
bounded-error quantum query complexity.
</p></div>
    </summary>
    <updated>2019-02-12T02:27:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03568</id>
    <link href="http://arxiv.org/abs/1902.03568" rel="alternate" type="text/html"/>
    <title>Balancing Straight-Line Programs</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ganardi:Moses.html">Moses Ganardi</a>, Artur Jeż, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lohrey:Markus.html">Markus Lohrey</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03568">PDF</a><br/><b>Abstract: </b>It is shown that a context-free grammar of size $m$ that produces a single
string $w$ (such a grammar is also called a string straight-line program) can
be transformed in linear time into a context-free grammar for $w$ of size
$\mathcal{O}(m)$, whose unique derivation tree has depth $\mathcal{O}(\log
|w|)$. This solves an open problem in the area of grammar-based compression.
Similar results are shown for two formalism for grammar-based tree compression:
top dags and forest straight-line programs. These balancing results are all
deduced from a single meta theorem stating that the depth of an algebraic
circuit over an algebra with a certain finite base property can be reduced to
$\mathcal{O}(\log n)$ with the cost of a constant multiplicative size increase.
Here, $n$ refers to the size of the unfolding (or unravelling) of the circuit.
</p></div>
    </summary>
    <updated>2019-02-12T02:36:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03560</id>
    <link href="http://arxiv.org/abs/1902.03560" rel="alternate" type="text/html"/>
    <title>On the Complexity of Exact Pattern Matching in Graphs: Determinism and Zig-Zag Matching</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Equi:Massimo.html">Massimo Equi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grossi:Roberto.html">Roberto Grossi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tomescu:Alexandru_I=.html">Alexandru I. Tomescu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/M=auml=kinen:Veli.html">Veli Mäkinen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03560">PDF</a><br/><b>Abstract: </b>Exact pattern matching in labeled graphs is the problem of searching paths of
a graph $G=(V,E)$ that spell the same string as the given pattern $P[1..m]$.
This basic problem can be found at the heart of more complex operations on
variation graphs in computational biology, query operations in graph databases,
and analysis of heterogeneous networks, where the nodes of some paths must
match a sequence of labels or types. In our recent work we described a
conditional lower bound stating that the exact pattern matching problem in
labeled graphs cannot be solved in less than quadratic time, namely, $O(|E|^{1
- \epsilon} \, m)$ time or $O(|E| \, m^{1 - \epsilon})$ time for any constant
$\epsilon&gt;0$, unless the Strong Exponential Time Hypothesis (SETH) is false.
The result holds even if node labels and pattern $P$ are drawn from a binary
alphabet, and $G$ is restricted to undirected graphs of maximum degree three or
directed acyclic graphs of maximum sum of indegree and outdegree three. It was
left open what happens on undirected graphs of maximum degree two, i.e., when
the pattern can have a zig-zag match in a (cyclic) bidirectional string. Also,
the reduction created a non-determistic directed acyclic graph, and it was left
open if determinism would make the problem easier. In this work, we show
through the Orthogonal Vectors hypothesis (OV) that the same conditional lower
bound holds even for these restricted cases.
</p></div>
    </summary>
    <updated>2019-02-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03549</id>
    <link href="http://arxiv.org/abs/1902.03549" rel="alternate" type="text/html"/>
    <title>On modeling hard combinatorial optimization problems as linear programs: Refutations of the "unconditional impossibility" claims</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diaby:Moustapha.html">Moustapha Diaby</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karwan:Mark_H=.html">Mark H. Karwan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Lei.html">Lei Sun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03549">PDF</a><br/><b>Abstract: </b>There has been a series of developments in the recent literature (by
essentially a same "circle" of authors) with the absolute/unconditioned
(implicit or explicit) claim that there exists no abstraction of an NP-Complete
combinatorial optimization problem in which the defining combinatorial
configurations (such as "tours" in the case of the traveling salesman problem
(TSP) for example) can be modeled by a polynomial-sized system of linear
constraints. The purpose of this paper is to provide general as well as
specific refutations for these recent claims.
</p></div>
    </summary>
    <updated>2019-02-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03548</id>
    <link href="http://arxiv.org/abs/1902.03548" rel="alternate" type="text/html"/>
    <title>Approximating $k$-connected $m$-dominating sets</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nutov:Zeev.html">Zeev Nutov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03548">PDF</a><br/><b>Abstract: </b>A subset $S$ of nodes in a graph $G$ is a $k$-connected $m$-dominating set
($(k,m)$-cds) if the subgraph $G[S]$ induced by $S$ is $k$-connected and every
$v \in V \setminus S$ has at least $m$ neighbors in $S$. In the $k$-Connected
$m$-Dominating Set ($(k,m)$-CDS) problem the goal is to find a minimum weight
$(k,m)$-cds in a node-weighted graph. For $m \geq k$ we obtain the following
approximation ratios. For general graphs our ratio $O(k \ln n)$ improves the
previous best ratio $O(k^2 \ln n)$ and matches the best known ratio for unit
weights. For unit disc graphs we improve the ratio $O(k \ln k)$ to
$\min\left\{\frac{m}{m-k},k^{2/3}\right\} \cdot O(\ln^2 k)$ -- this is the
first sublinear ratio for the problem, and the first polylogarithmic ratio
$O(\ln^2 k)/\epsilon$ when $m \geq (1+\epsilon)k$; furthermore, we obtain ratio
$\min\left\{\frac{m}{m-k},\sqrt{k}\right\} \cdot O(\ln^2 k)$ for uniform
weights. These results are obtained by showing the same ratios for the Subset
$k$-Connectivity problem when the set $T$ of terminals is an $m$-dominating set
with $m \geq k$.
</p></div>
    </summary>
    <updated>2019-02-12T02:49:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03534</id>
    <link href="http://arxiv.org/abs/1902.03534" rel="alternate" type="text/html"/>
    <title>Set Cover in Sub-linear Time</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Indyk:Piotr.html">Piotr Indyk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahabadi:Sepideh.html">Sepideh Mahabadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rubinfeld:Ronitt.html">Ronitt Rubinfeld</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vakilian:Ali.html">Ali Vakilian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yodpinyanee:Anak.html">Anak Yodpinyanee</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03534">PDF</a><br/><b>Abstract: </b>We study the classic set cover problem from the perspective of sub-linear
algorithms. Given access to a collection of $m$ sets over $n$ elements in the
query model, we show that sub-linear algorithms derived from existing
techniques have almost tight query complexities.
</p>
<p>On one hand, first we show an adaptation of the streaming algorithm presented
in Har-Peled et al. [2016] to the sub-linear query model, that returns an
$\alpha$-approximate cover using $\tilde{O}(m(n/k)^{1/(\alpha-1)} + nk)$
queries to the input, where $k$ denotes the value of a minimum set cover. We
then complement this upper bound by proving that for lower values of $k$, the
required number of queries is $\tilde{\Omega}(m(n/k)^{1/(2\alpha)})$, even for
estimating the optimal cover size. Moreover, we prove that even checking
whether a given collection of sets covers all the elements would require
$\Omega(nk)$ queries. These two lower bounds provide strong evidence that the
upper bound is almost tight for certain values of the parameter $k$.
</p>
<p>On the other hand, we show that this bound is not optimal for larger values
of the parameter $k$, as there exists a $(1+\varepsilon)$-approximation
algorithm with $\tilde{O}(mn/k\varepsilon^2)$ queries. We show that this bound
is essentially tight for sufficiently small constant $\varepsilon$, by
establishing a lower bound of $\tilde{\Omega}(mn/k)$ query complexity.
</p></div>
    </summary>
    <updated>2019-02-12T02:56:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03522</id>
    <link href="http://arxiv.org/abs/1902.03522" rel="alternate" type="text/html"/>
    <title>Multi-Dimensional Balanced Graph Partitioning via Projected Gradient Descent</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Dmitrii Avdiukhin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pupyrev:Sergey.html">Sergey Pupyrev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yaroslavtsev:Grigory.html">Grigory Yaroslavtsev</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03522">PDF</a><br/><b>Abstract: </b>Motivated by performance optimization of large-scale graph processing systems
that distribute the graph across multiple machines, we consider the balanced
graph partitioning problem. Compared to the previous work, we study the
multi-dimensional variant when balance according to multiple weight functions
is required. As we demonstrate by experimental evaluation, such
multi-dimensional balance is important for achieving performance improvements
for typical distributed graph processing workloads. We propose a new scalable
technique for the multidimensional balanced graph partitioning problem. The
method is based on applying randomized projected gradient descent to a
non-convex continuous relaxation of the objective. We show how to implement the
new algorithm efficiently in both theory and practice utilizing various
approaches for projection. Experiments with large-scale social networks
containing up to hundreds of billions of edges indicate that our algorithm has
superior performance compared with the state-of-the-art approaches.
</p></div>
    </summary>
    <updated>2019-02-12T02:52:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03519</id>
    <link href="http://arxiv.org/abs/1902.03519" rel="alternate" type="text/html"/>
    <title>Scalable Fair Clustering</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Backurs:Arturs.html">Arturs Backurs</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Indyk:Piotr.html">Piotr Indyk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Onak:Krzysztof.html">Krzysztof Onak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schieber:Baruch.html">Baruch Schieber</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vakilian:Ali.html">Ali Vakilian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wagner:Tal.html">Tal Wagner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03519">PDF</a><br/><b>Abstract: </b>We study the fair variant of the classic $k$-median problem introduced by
Chierichetti et al. [2017]. In the standard $k$-median problem, given an input
pointset $P$, the goal is to find $k$ centers $C$ and assign each input point
to one of the centers in $C$ such that the average distance of points to their
cluster center is minimized.
</p>
<p>In the fair variant of $k$-median, the points are colored, and the goal is to
minimize the same average distance objective while ensuring that all clusters
have an "approximately equal" number of points of each color.
</p>
<p>Chierichetti et al. proposed a two-phase algorithm for fair $k$-clustering.
In the first step, the pointset is partitioned into subsets called fairlets
that satisfy the fairness requirement and approximately preserve the $k$-median
objective. In the second step, fairlets are merged into $k$ clusters by one of
the existing $k$-median algorithms. The running time of this algorithm is
dominated by the first step, which takes super-quadratic time.
</p>
<p>In this paper, we present a practical approximate fairlet decomposition
algorithm that runs in nearly linear time. Our algorithm additionally allows
for finer control over the balance of resulting clusters than the original
work. We complement our theoretical bounds with empirical evaluation.
</p></div>
    </summary>
    <updated>2019-02-12T02:59:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03513</id>
    <link href="http://arxiv.org/abs/1902.03513" rel="alternate" type="text/html"/>
    <title>Computational Complexity and the Nature of Quantum Mechanics (Extended version)</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Benavoli:Alessio.html">Alessio Benavoli</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Facchini:Alessandro.html">Alessandro Facchini</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zaffalon:Marco.html">Marco Zaffalon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03513">PDF</a><br/><b>Abstract: </b>Quantum theory (QT) has been confirmed by numerous experiments, yet we still
cannot fully grasp the meaning of the theory. As a consequence, the quantum
world appears to us paradoxical. Here we shed new light on QT by having it
follow from two main postulates (i) the theory should be logically consistent;
(ii) inferences in the theory should be computable in polynomial time. The
first postulate is what we require to each well-founded mathematical theory.
The computation postulate defines the physical component of the theory. We show
that the computation postulate is the only true divide between QT, seen as a
generalised theory of probability, and classical probability. All quantum
paradoxes, and entanglement in particular, arise from the clash of trying to
reconcile a computationally intractable, somewhat idealised, theory (classical
physics) with a computationally tractable theory (QT) or, in other words, from
regarding physics as fundamental rather than computation.
</p></div>
    </summary>
    <updated>2019-02-12T02:36:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03438</id>
    <link href="http://arxiv.org/abs/1902.03438" rel="alternate" type="text/html"/>
    <title>Metric Curvatures and their Applications 2: Metric Ricci Curvature and Flow</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saucan:Emil.html">Emil Saucan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03438">PDF</a><br/><b>Abstract: </b>In this second part of our overview of the different metric curvatures and
their various applications, we concentrate on the Ricci curvature and flow for
polyhedral surfaces and higher dimensional manifolds, and we largely review our
previous studies on the subject, based upon Wald's curvature. In addition to
our previous metric approaches to the discretization of Ricci curvature, we
consider yet another one, based on the Haantjes curvature, interpreted as a
geodesic curvature. We also try to understand the mathematical reasons behind
the recent proliferation of discretizations of Ricci curvature. Furthermore, we
propose another approach to the metrization of Ricci curvature, based on
Forman's discretization, and in particular we propose on that uses our graph
version of Forman's Ricci curvature.
</p></div>
    </summary>
    <updated>2019-02-12T03:05:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03428</id>
    <link href="http://arxiv.org/abs/1902.03428" rel="alternate" type="text/html"/>
    <title>Linear Time Algorithms for Multiple Cluster Scheduling and Multiple Strip Packing</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jansen:Klaus.html">Klaus Jansen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rau:Malin.html">Malin Rau</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03428">PDF</a><br/><b>Abstract: </b>We study the Multiple Cluster Scheduling problem and the Multiple Strip
Packing problem. For both problems, there is no algorithm with approximation
ratio better than $2$ unless $P = NP$. In this paper, we present an algorithm
with approximation ratio $2$ and running time $O(n)$ for both problems. While a
$2$ approximation was known before, the running time of the algorithm is at
least $\Omega(n^{256})$ in the worst case. Therefore, an $O(n)$ algorithm is
surprising and the best possible. We archive this result by calling an AEPTAS
with approximation guarantee $(1+\varepsilon)OPT +p_{\max}$ and running time of
the form $O(n\log(1/\varepsilon)+ f(1/\varepsilon))$ with a constant
$\varepsilon$ to schedule the jobs on a single cluster. This schedule is then
distributed on the $N$ clusters in $O(n)$. Moreover, this distribution
technique can be applied to any variant of of Multi Cluster Scheduling for
which there exists an AEPTAS with additive term $p_{\max}$.
</p>
<p>While the above result is strong from a theoretical point of view, it might
not be very practical due to a large hidden constant caused by calling an
AEPTAS with a constant $\varepsilon \geq 1/8$ as subroutine. Nevertheless, we
point out that the general approach of finding first a schedule on one cluster
and then distributing it onto the other clusters might come in handy in
practical approaches. We demonstrate this by presenting a practical algorithm
with running time $O(n\log(n))$, with out hidden constants, that is a
$9/4$-approximation for one third of all possible instances, i.e, all instances
where the number of clusters is dividable by $3$, and has an approximation
ratio of at most $2.3$ for all instances with at least $9$ clusters.
</p></div>
    </summary>
    <updated>2019-02-12T02:45:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03422</id>
    <link href="http://arxiv.org/abs/1902.03422" rel="alternate" type="text/html"/>
    <title>Fast Approximation Schemes for Bin Packing</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Divakaran:Srikrishnan.html">Srikrishnan Divakaran</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03422">PDF</a><br/><b>Abstract: </b>We present new approximation schemes for bin packing based on the following
two approaches: (1) partitioning the given problem into mostly identical
sub-problems of constant size and then construct a solution by combining the
solutions of these constant size sub-problems obtained through PTAS or exact
methods; (2) solving bin packing using irregular sized bins, a generalization
of bin packing, that facilitates the design of simple and efficient recursive
algorithms that solve a problem in terms of smaller sub-problems such that the
unused space in bins used by an earlier solved sub-problem is available to
subsequently solved sub-problems.
</p></div>
    </summary>
    <updated>2019-02-12T02:50:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03297</id>
    <link href="http://arxiv.org/abs/1902.03297" rel="alternate" type="text/html"/>
    <title>Probably the Best Itemsets</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03297">PDF</a><br/><b>Abstract: </b>One of the main current challenges in itemset mining is to discover a small
set of high-quality itemsets. In this paper we propose a new and general
approach for measuring the quality of itemsets. The method is solidly founded
in Bayesian statistics and decreases monotonically, allowing for efficient
discovery of all interesting itemsets. The measure is defined by connecting
statistical models and collections of itemsets. This allows us to score
individual itemsets with the probability of them occuring in random models
built on the data.
</p>
<p>As a concrete example of this framework we use exponential models. This class
of models possesses many desirable properties. Most importantly, Occam's razor
in Bayesian model selection provides a defence for the pattern explosion. As
general exponential models are infeasible in practice, we use decomposable
models; a large sub-class for which the measure is solvable. For the actual
computation of the score we sample models from the posterior distribution using
an MCMC approach.
</p>
<p>Experimentation on our method demonstrates the measure works in practice and
results in interpretable and insightful itemsets for both synthetic and
real-world data.
</p></div>
    </summary>
    <updated>2019-02-12T02:56:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03285</id>
    <link href="http://arxiv.org/abs/1902.03285" rel="alternate" type="text/html"/>
    <title>Fast Sequence Segmentation using Log-Linear Models</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03285">PDF</a><br/><b>Abstract: </b>Sequence segmentation is a well-studied problem, where given a sequence of
elements, an integer K, and some measure of homogeneity, the task is to split
the sequence into K contiguous segments that are maximally homogeneous. A
classic approach to find the optimal solution is by using a dynamic program.
Unfortunately, the execution time of this program is quadratic with respect to
the length of the input sequence. This makes the algorithm slow for a sequence
of non-trivial length. In this paper we study segmentations whose measure of
goodness is based on log-linear models, a rich family that contains many of the
standard distributions. We present a theoretical result allowing us to prune
many suboptimal segmentations. Using this result, we modify the standard
dynamic program for one-dimensional log-linear models, and by doing so reduce
the computational time. We demonstrate empirically, that this approach can
significantly reduce the computational burden of finding the optimal
segmentation.
</p></div>
    </summary>
    <updated>2019-02-12T02:45:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03274</id>
    <link href="http://arxiv.org/abs/1902.03274" rel="alternate" type="text/html"/>
    <title>Faster Repetition-Aware Compressed Suffix Trees based on Block Trees</title>
    <feedworld_mtime>1549929600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Manuel Cáceres, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Navarro:Gonzalo.html">Gonzalo Navarro</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03274">PDF</a><br/><b>Abstract: </b>Suffix trees are a fundamental data structure in stringology, but their space
usage, though linear, is an important problem for its applications. We design
and implement a new compressed suffix tree targeted to highly repetitive texts,
such as large genomic collections of the same species. Our suffix tree tree
builds on Block Trees, a recent Lempel-Ziv-bounded data structure that captures
the repetitiveness of its input. We use Block Trees to compress the topology of
the suffix tree, and augment the Block Tree nodes with data that speeds up
suffix tree navigation.
</p>
<p>Our compressed suffix tree is slightly larger than previous repetition-aware
suffix trees based on grammars, but outperforms them in time, often by orders
of magnitude. The component that represents the tree topology achieves a speed
comparable to that of general-purpose compressed trees, while using 2.3--10
times less space, and might be of interest in other scenarios.
</p></div>
    </summary>
    <updated>2019-02-12T02:38:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5768393804446188224</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5768393804446188224/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/i-think-ze-was-confused-in-favor-of.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5768393804446188224" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5768393804446188224" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/i-think-ze-was-confused-in-favor-of.html" rel="alternate" type="text/html"/>
    <title>I think ze was confused  -- in favor of genderless pronouns</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">You've probably heard the following:<br/>
<br/>
<br/>
               At first I didn't want to get an X but now that I have it, I can't imagine life without one.<br/>
<br/>
X could be telegraph, radio, TV, color TV, VCR, CD player, streaming, Netflix, Amazon prime, an uber account, Washer and Dryer, Car Phones (remember those), Cell Phones. If you go back in history  wrist watches or sun dials (or wrist-sun-dials!).<br/>
<br/>
This has happened to me recently though not with an object. I read an article someplace saying that ze can be used instead of he or she. It was referring to nonbinaries (using `they' never quite sounded right) but actually it would be great if this was a general genderless pronoun. I am not making a political statement here (although I doubt I have any readers who are against genderless pronouns).<br/>
<br/>
Once I came across the term ze I found places to use it and now I can't imagine not using it.<br/>
<br/>
In a recent article I wrote I needed to say that someone was probably confused, but I did not know their gender. I used<br/>
<br/>
                                                         Ze was probably confused<br/>
<br/>
which is much better than<br/>
<br/>
                                                         S/he was probably confused<br/>
<br/>
                                                         He or she was probably confused<br/>
<br/>
                                                         The student was probably confused<br/>
<br/>
                                                         They were probably confused.<br/>
<br/>
Note that the first two leave out nonbinaries.<br/>
<br/>
0) In the article I put in a footnote saying what ze meant. In the future I may not have to.<br/>
<br/>
1) Will ze catch on? This blog post is an attempt to hasten the practice.<br/>
<br/>
2) Is there a term for his/her that is non-gendered? If not then maybe zer.<br/>
<br/>
3) Will there be political pushback on this usage? If its phrased as a way to include nonbinaries than unfortunately yes. If its phrased as above as when you don't know the gender, what do you do, then no.<br/>
<br/>
4) Is <i> nonbinary </i>the correct term? If not then please politely correct me in the comments.<br/>
<br/>
5) Has Ms replaced Miss and Mrs?<br/>
<br/>
I have used the term ze several times since then- often when I get email from a student such that I can't tell from the first name what their gender is, and I need to forward the email, such as<br/>
<br/>
                   Ze wants to take honors discrete math but does not have the prerequisite, but<br/>
                   since ze placed in the top five in the math olympiad, we'll let zer take it.<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-02-11T19:43:00Z</updated>
    <published>2019-02-11T19:43:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-12T15:55:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/02/11/parameterized-approximation-algorithms-workshop-paaw-2019/</id>
    <link href="https://cstheory-events.org/2019/02/11/parameterized-approximation-algorithms-workshop-paaw-2019/" rel="alternate" type="text/html"/>
    <title>Parameterized Approximation Algorithms Workshop (PAAW) 2019</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 8, 2019 Patras, Greece https://sites.google.com/site/aefeldmann/parameterized-approximation-algorithms-workshop-paaw-2019 Submission deadline: April 26, 2019 Registration deadline: April 30, 2019 The 2019 edition of the Parameterized Approximation Algorithms Workshop (PAAW) will take place as a satellite workshop of ICALP 2019 in Patras, Greece, on Monday July 8th 2019. — Topics of interest — – Parameterized approximation algorithms – Lossy … <a class="more-link" href="https://cstheory-events.org/2019/02/11/parameterized-approximation-algorithms-workshop-paaw-2019/">Continue reading <span class="screen-reader-text">Parameterized Approximation Algorithms Workshop (PAAW) 2019</span></a></div>
    </summary>
    <updated>2019-02-11T15:31:13Z</updated>
    <published>2019-02-11T15:31:13Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-02-12T19:21:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03164</id>
    <link href="http://arxiv.org/abs/1902.03164" rel="alternate" type="text/html"/>
    <title>Detecting mixed-unitary quantum channels is NP-hard</title>
    <feedworld_mtime>1549843200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Colin Do-Yan Lee, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Watrous:John.html">John Watrous</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03164">PDF</a><br/><b>Abstract: </b>A quantum channel is said to be a mixed-unitary channel if it can be
expressed as a convex combination of unitary channels. We prove that, given the
Choi representation of a quantum channel, it is NP-hard with respect to
polynomial-time Turing reductions to determine whether or not that channel is a
mixed-unitary channel. This hardness result holds even under the assumption
that the channel is not within an inverse-polynomial distance (in the dimension
of the space upon which it acts) of the boundary of the mixed-unitary channels.
</p></div>
    </summary>
    <updated>2019-02-11T23:21:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.03102</id>
    <link href="http://arxiv.org/abs/1902.03102" rel="alternate" type="text/html"/>
    <title>Using Background Knowledge to Rank Itemsets</title>
    <feedworld_mtime>1549843200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mampaey:Michael.html">Michael Mampaey</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.03102">PDF</a><br/><b>Abstract: </b>Assessing the quality of discovered results is an important open problem in
data mining. Such assessment is particularly vital when mining itemsets, since
commonly many of the discovered patterns can be easily explained by background
knowledge. The simplest approach to screen uninteresting patterns is to compare
the observed frequency against the independence model. Since the parameters for
the independence model are the column margins, we can view such screening as a
way of using the column margins as background knowledge.
</p>
<p>In this paper we study techniques for more flexible approaches for infusing
background knowledge. Namely, we show that we can efficiently use additional
knowledge such as row margins, lazarus counts, and bounds of ones. We
demonstrate that these statistics describe forms of data that occur in practice
and have been studied in data mining.
</p>
<p>To infuse the information efficiently we use a maximum entropy approach. In
its general setting, solving a maximum entropy model is infeasible, but we
demonstrate that for our setting it can be solved in polynomial time.
Experiments show that more sophisticated models fit the data better and that
using more information improves the frequency prediction of itemsets.
</p></div>
    </summary>
    <updated>2019-02-11T23:23:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02967</id>
    <link href="http://arxiv.org/abs/1902.02967" rel="alternate" type="text/html"/>
    <title>Generic reductions for in-place polynomial multiplication</title>
    <feedworld_mtime>1549843200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Giorgi:Pascal.html">Pascal Giorgi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grenet:Bruno.html">Bruno Grenet</a>, Daniel Roche <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02967">PDF</a><br/><b>Abstract: </b>The polynomial multiplication problem has attracted considerable attention
since the early days of computer algebra, and several algorithms have been
designed to achieve the best possible time complexity. More recently, efforts
have been made to improve the space complexity, developing modified versions of
a few specific algorithms to use no extra space while keeping the same
asymptotic running time. In this work, we broaden the scope in two regards.
First, we ask whether an arbitrary multiplication algorithm can be performed
in-place generically. Second, we consider two important variants which produce
only part of the result (and hence have less space to work with), the so-called
middle and short products, and ask whether these operations can also be
performed in-place. To answer both questions in (mostly) the affirmative, we
provide a series of reductions starting with any linear-space multiplication
algorithm. For full and short product algorithms these reductions yield
in-place versions with the same asymptotic time complexity as the out-of-place
version. For the middle product, the reduction incurs an extra logarithmic
factor in the time complexity only when the algorithm is quasi-linear.
</p></div>
    </summary>
    <updated>2019-02-11T23:20:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02921</id>
    <link href="http://arxiv.org/abs/1902.02921" rel="alternate" type="text/html"/>
    <title>Are your Items in Order?</title>
    <feedworld_mtime>1549843200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02921">PDF</a><br/><b>Abstract: </b>Items in many datasets can be arranged to a natural order. Such orders are
useful since they can provide new knowledge about the data and may ease further
data exploration and visualization. Our goal in this paper is to define a
statistically well-founded and an objective score measuring the quality of an
order. Such a measure can be used for determining whether the current order has
any valuable information or can it be discarded.
</p>
<p>Intuitively, we say that the order is good if dependent attributes are close
to each other. To define the order score we fit an order-sensitive model to the
dataset. Our model resembles a Markov chain model, that is, the attributes
depend only on the immediate neighbors. The score of the order is the BIC score
of the best model. For computing the measure we introduce a fast dynamic
program. The score is then compared against random orders: if it is better than
the scores of the random orders, we say that the order is good. We also show
the asymptotic connection between the score function and the number of free
parameters of the model. In addition, we introduce a simple greedy approach for
finding an order with a good score. We evaluate the score for synthetic and
real datasets using different spectral orders and the orders obtained with the
greedy method.
</p></div>
    </summary>
    <updated>2019-02-11T23:23:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02889</id>
    <link href="http://arxiv.org/abs/1902.02889" rel="alternate" type="text/html"/>
    <title>Space-efficient merging of succinct de Bruijn graphs</title>
    <feedworld_mtime>1549843200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Egidi:Lavinia.html">Lavinia Egidi</a>, Felipe A. Louza, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manzini:Giovanni.html">Giovanni Manzini</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02889">PDF</a><br/><b>Abstract: </b>We propose a new algorithm for merging succinct representations of de Bruijn
graphs introduced in [Bowe et al. WABI 2012]. Our algorithm is inspired by the
approach introduced by Holt and McMillan [Bionformatics 2014, ACM-BCB 2014] for
merging Burrow-Wheeler transforms. In addition to its input, our algorithm uses
only four bitvectors of working space and all data is accessed sequentially
making the algorithm suitable for external memory execution. Our algorithm can
also merge Colored succinct de Bruijn graphs, and can compute the Variable
Order succinct representation from the plain representation of the input
graphs.
</p>
<p>Combining our merging algorithm with recent results on de Bruijn graph
construction, we provide a space efficient procedure for building succinct
representations of de Bruijn graphs for very large collections.
</p></div>
    </summary>
    <updated>2019-02-11T23:21:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02861</id>
    <link href="http://arxiv.org/abs/1902.02861" rel="alternate" type="text/html"/>
    <title>Discovering Descriptive Tile Trees by Mining Optimal Geometric Subtiles</title>
    <feedworld_mtime>1549843200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vreeken:Jilles.html">Jilles Vreeken</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02861">PDF</a><br/><b>Abstract: </b>When analysing binary data, the ease at which one can interpret results is
very important. Many existing methods, however, discover either models that are
difficult to read, or return so many results interpretation becomes impossible.
Here, we study a fully automated approach for mining easily interpretable
models for binary data. We model data hierarchically with noisy
tiles-rectangles with significantly different density than their parent tile.
To identify good trees, we employ the Minimum Description Length principle.
</p>
<p>We propose STIJL, a greedy any-time algorithm for mining good tile trees from
binary data. Iteratively, it finds the locally optimal addition to the current
tree, allowing overlap with tiles of the same parent. A major result of this
paper is that we find the optimal tile in only $\Theta(NM\min(N, M))$ time.
STIJL can either be employed as a top-$k$ miner, or by MDL we can identify the
tree that describes the data best.
</p>
<p>Experiments show we find succinct models that accurately summarise the data,
and, by their hierarchical property are easily interpretable.
</p></div>
    </summary>
    <updated>2019-02-11T23:22:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.02834</id>
    <link href="http://arxiv.org/abs/1902.02834" rel="alternate" type="text/html"/>
    <title>The Long and the Short of It: Summarising Event Sequences with Serial Episodes</title>
    <feedworld_mtime>1549843200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vreeken:Jilles.html">Jilles Vreeken</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02834">PDF</a><br/><b>Abstract: </b>An ideal outcome of pattern mining is a small set of informative patterns,
containing no redundancy or noise, that identifies the key structure of the
data at hand. Standard frequent pattern miners do not achieve this goal, as due
to the pattern explosion typically very large numbers of highly redundant
patterns are returned.
</p>
<p>We pursue the ideal for sequential data, by employing a pattern set mining
approach-an approach where, instead of ranking patterns individually, we
consider results as a whole. Pattern set mining has been successfully applied
to transactional data, but has been surprisingly under studied for sequential
data.
</p>
<p>In this paper, we employ the MDL principle to identify the set of sequential
patterns that summarises the data best. In particular, we formalise how to
encode sequential data using sets of serial episodes, and use the encoded
length as a quality score. As search strategy, we propose two approaches: the
first algorithm selects a good pattern set from a large candidate set, while
the second is a parameter-free any-time algorithm that mines pattern sets
directly from the data. Experimentation on synthetic and real data demonstrates
we efficiently discover small sets of informative patterns.
</p></div>
    </summary>
    <updated>2019-02-11T23:21:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://bit-player.org/?p=2137</id>
    <link href="http://bit-player.org/2019/divisive-factorials" rel="alternate" type="text/html"/>
    <link href="http://bit-player.org/2019/divisive-factorials#comments" rel="replies" type="text/html"/>
    <link href="http://bit-player.org/2019/divisive-factorials/feed/atom" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Divisive factorials!</title>
    <summary type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml">The other day I was derailed by this tweet from Fermat’s Library: The moment I saw it, I had to stop in my tracks, grab a scratch pad, and check out the formula. The result made sense in a rough-and-ready … <a href="http://bit-player.org/2019/divisive-factorials">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>The other day I was derailed by this tweet from Fermat’s Library:</p>
<p><img alt="Inverse factorial tweet" border="0" class="aligncenter" height="385" src="http://bit-player.org/wp-content/uploads/2019/02/inverse-factorial-tweet.png" width="592"/></p>
<p class="undent">The moment I saw it, I had to stop in my tracks, grab a scratch pad, and check out the formula. The result made sense in a rough-and-ready sort of way. Since the multiplicative version of \(n!\) goes to infinity as \(n\) increases, the “divisive” version should go to zero. And \(\frac{n^2}{n!}\) does exactly that; the polynomial function \(n^2\) grows slower than the exponential function \(n!\) for large enough \(n\):</p>
<p>\[\frac{1}{1}, \frac{4}{2}, \frac{9}{6}, \frac{16}{24}, \frac{25}{120}, \frac{36}{720}, \frac{49}{5040}, \frac{64}{40320}, \frac{81}{362880}, \frac{100}{3628800}.\]</p>
<p class="undent">But why does the quotient take the particular form \(\frac{n^2}{n!}\)? Where does the \(n^2\) come from?</p>
<p>To answer that question, I had to revisit the long-ago trauma of learning to divide fractions, but I pushed through the pain. Proceeding from left to right through the formula in the tweet, we first get \(\frac{n}{n-1}\). Then, dividing that quantity by \(n-2\) yields</p>
<p>\[\cfrac{\frac{n}{n-1}}{n-2} = \frac{n}{(n-1)(n-2)}.\]</p>
<p class="undent">Continuing in the same way, we ultimately arrive at:</p>
<p>\[n \mathbin{/} (n-1) \mathbin{/} (n-2) \mathbin{/} (n-3) \mathbin{/} \cdots \mathbin{/} 1 = \frac{n}{(n-1) (n-2) (n-3) \cdots 1} = \frac{n}{(n-1)!}\]</p>
<p class="undent">To recover the tweet’s stated result of \(\frac{n^2}{n!}\), just multiply numerator and denominator by \(n\). (To my taste, however, \(\frac{n}{(n-1)!}\) is the more perspicuous expression.)</p>
<hr/>
<p>I am a card-carrying factorial fanboy. You can keep your fancy Fibonaccis; <em>this</em> is my favorite function. Every time I try out a new programming language, my first exercise is to write a few routines for calculating factorials. Over the years I have pondered several variations on the theme, such as replacing \(\times\) with \(+\) in the definition (which produces triangular numbers). But I don’t think I’ve ever before considered substituting \(\mathbin{/}\) for \(\times\). It’s messy. Because multiplication is commutative and associative, you can define \(n!\) simply as the product of all the integers from \(1\) through \(n\), without worrying about the order of the operations. With division, order can’t be ignored. In general, \(x \mathbin{/} y \ne y \mathbin{/}x\), and \((x \mathbin{/} y) \mathbin{/} z \ne x \mathbin{/} (y \mathbin{/} z)\).</p>
<p>The Fermat’s Library tweet puts the factors in descending order: \(n, n-1, n-2, \ldots, 1\). The most obvious alternative is the ascending sequence \(1, 2, 3, \ldots, n\). What happens if we define the divisive factorial as \(1 \mathbin{/} 2 \mathbin{/}  3 \mathbin{/} \cdots \mathbin{/} n\)? Another visit to the schoolroom algorithm for dividing fractions yields this simple answer:</p>
<p>\[1 \mathbin{/} 2 \mathbin{/}  3 \mathbin{/} \cdots \mathbin{/} n = \frac{1}{2 \times 3 \times 4 \times \cdots \times n} = \frac{1}{n!}.\]</p>
<p class="undent">In other words, when we repeatedly divide while counting up from \(1\) to \(n\), the final quotient is the reciprocal of \(n!\).  (I wish I could put an exclamation point at the end of that sentence!) If you’re looking for a canonical answer to the question, “What do you get if you divide instead of multiplying in \(n!\)?” I would argue that \(\frac{1}{n!}\) is a better candidate than \(\frac{n}{(n - 1)!}\). Why not embrace the symmetry between \(n!\) and its inverse?</p>
<p>Of course there are many other ways to arrange the <em>n</em> integers in the set \(\{1 \ldots n\}\). How many ways? As it happens, \(n!\) of them! Thus it would seem there are \(n!\) distinct ways to define the divisive \(n!\) function. However, looking at the answers for the two permutations discussed above suggests there’s a simpler pattern at work. Whatever element of the sequence happens to come first winds up in the numerator of a big fraction, and the denominator is the product of all the other elements. As a result, there are really only \(n\) different outcomes—assuming we stick to performing the division operations from left to right. For any integer \(k\) between \(1\) and \(n\), putting \(k\) at the head of the queue creates a divisive \(n!\) equal to \(k\) divided by all the other factors. We can write this out as:</p>
<p>\[\cfrac{k}{\frac{n!}{k}}, \text{ which can be rearranged as } \frac{k^2}{n!}.\]</p>
<p class="undent">And thus we also solve the minor mystery of how \(\frac{n}{(n-1)!}\) became \(\frac{n^2}{n!}\) in the tweet.</p>
<p>It’s worth noting that all of these functions converge to zero as \(n\) goes to infinity. Asymptotically speaking, \(\frac{1^2}{n!}, \frac{2^2}{n!}, \ldots, \frac{n^2}{n!}\) are all alike.</p>
<hr/>
<p>Ta dah! Mission accomplished. Problem solved. Done and dusted. Now we know everything there is to know about divisive factorials, right?</p>
<p>Well, maybe there’s one more question. What does the computer say? If you take your favorite factorial algorithm, and do as the tweet suggests, replacing any appearance of the \(\times\) (or <code>*</code>) operator with <code>/</code>, what happens? Which of the \(n\) variants of divisive \(n!\) does the program produce?</p>
<p>Here’s <em>my</em> favorite algorithm for computing factorials, in the form of a <a href="https://julialang.org/">Julia</a> program:</p>
<pre class="language-julia"><code>function mul!(n)
    if n == 1
        return 1
    else
        return n * mul!(n - 1)
    end
end
</code></pre>
<p>This is the algorithm that has introduced generations of nerds to the concept of recursion. In narrative form it says: If \(n\) is \(1\), then \(mul!(n)\) is \(1\). Otherwise, evaluate the function \(mul!(n-1)\), then multiply the result by \(n\). You might ask what happens if \(n\) is zero or negative. You might ask, but please don’t. For present purposes, \(n \in \mathbb{N}\).Starting with any positive \(n\), the sequence of recursive calls must eventually bottom out with \(n = 1\).</p>
<p>The function can be written more tersely using Julia’s one-liner style of definition:.</p>
<pre class="language-julia"><code>mul!(n)  =  n == 1 ? 1 : n * mul!(n - 1)</code></pre>
<p>The right side of the assignment statement is a conditional expression, or ternary operator, which has the form <code>a ? b : c</code>. Here <code>a</code> is a boolean test clause, which must return a value of either <code>true</code> or <code>false</code>. If <code>a</code> is <code>true</code>, clause <code>b</code> is evaluated, and the result becomes the value of the entire expression. Otherwise clause <code>c</code> is evaluated.</p>
<p>Just to be sure I’ve got this right, here are the first 10 factorials, as calculated by this program:</p>
<pre class="language-julia"><code>[mul!(n) for n in 1:10]
10-element Array{Int64,1}:
       1
       2
       6
      24
     120
     720
    5040
   40320
  362880
 3628800</code></pre>
<p class="indent">Now let’s edit that definition and convert the single occurence of <code>*</code> to a <code>/</code>, leaving everything else (except the name of the function) unchanged.</p>
<pre class="language-julia"><code>div!(n)  =  n == 1 ? 1 : n / div!(n - 1)</code></pre>
<p>And here’s what comes back when we run the program for values of \(n\) from \(1\) through \(20\):</p>
<pre class="language-julia"><code>[div!(n) for n in 1:20]
20-element Array{Real,1}:
 1                 
 2.0               
 1.5               
 2.6666666666666665
 1.875             
 3.2               
 2.1875            
 3.657142857142857 
 2.4609375         
 4.063492063492063 
 2.70703125        
 4.432900432900433 
 2.9326171875      
 4.773892773892774 
 3.14208984375     
 5.092152292152292 
 3.338470458984375 
 5.391690662278897 
 3.523941040039063 
 5.675463855030418 </code></pre>
<p>Huh? That sure doesn’t look like it’s converging to zero—not as \(\frac{1}{n!}\) or as \(\frac{n}{n - 1}\). As a matter of fact, it doesn’t look like it’s going to converge at all. The graph below suggests the sequence is made up of two alternating components, both of which appear to be slowly growing toward infinity as well as diverging from one another.</p>
<p><img alt="Div" border="0" class="aligncenter" height="" src="http://bit-player.org/wp-content/uploads/2019/02/div.svg" width=""/></p>
<p class="indent">In trying to make sense of what we’re seeing here, it helps to change the output type of the <code>div!</code> function. Instead of applying the division operator <code>/</code>, which returns the quotient as a floating-point number, we can substitute the  <code>//</code> operator, which returns an exact rational quotient, reduced to lowest terms.</p>
<pre class="language-julia"><code>div!(n)  =  n == 1 ? 1 : n // div!(n - 1)</code></pre>
<p class="undent">Here’s the sequence of values for <code>n in 1:20</code>:</p>
<pre class="language-julia"><code>20-element Array{Real,1}:
       1      
      2//1    
      3//2    
      8//3    
     15//8    
     16//5    
     35//16   
    128//35   
    315//128  
    256//63   
    693//256  
   1024//231  
   3003//1024 
   2048//429  
   6435//2048 
  32768//6435 
 109395//32768
  65536//12155
 230945//65536
 262144//46189 </code></pre>
<p>The list is full of curious patterns. It’s a double helix, with even numbers and odd numbers zigzagging in complementary strands. The even numbers are not just even; they are all powers of \(2\). Also, they appear in pairs—first in the numerator, then in the denominator—and their sequence is nondecreasing. But there are gaps; not all powers of \(2\) are present. The odd strand looks even more complicated, with various small prime factors flitting in and out of the numbers. (The primes <em>have</em> to be small—smaller than \(n\), anyway.)</p>
<p>This outcome took me by surprise. I had really expected to see a much tamer sequence, like those I worked out with pencil and paper. All those jagged, jitterbuggy ups and downs made no sense. Nor did the overall trend of unbounded growth in the ratio. How could you keep dividing and dividing, and wind up with bigger and bigger numbers?</p>
<p>At this point you may want to pause before reading on, and try to work out your own theory of where these zigzag numbers are coming from. If you need a hint, you can get a strong one—almost a spoiler—by looking up the sequence of numerators or the sequence of denominators in the <a href="http://oeis.org">Online Encyclopedia of Integer Sequences</a>.</p>
<hr/>
<p>Here’s another hint. A small edit to the <code>div!</code> program completely transforms the output. Just flip the final clause, changing <code>n // div!(n - 1)</code> into <code>div!(n - 1) // n</code>. </p>
<pre class="language-julia"><code>div!(n)  =  n == 1 ? 1 : div!(n - 1) // n</code></pre>
<p class="undent">Now the results look like this:</p>
<pre class="language-julia"><code>10-element Array{Real,1}:
  1                    
 1//2                  
 1//6                  
 1//24                 
 1//120                
 1//720                
 1//5040               
 1//40320              
 1//362880             
 1//3628800</code></pre>
<p>This is the inverse factorial function we’ve already seen, the series of quotients generated when you march left to right through an ascending sequence of divisors \(1 \mathbin{/} 2 \mathbin{/}  3 \mathbin{/} \cdots \mathbin{/} n\). </p>
<p>It’s no surprise that flipping the final clause in the procedure alters the outcome. After all, we know that division is not commutative or associative. What’s not so easy to see is why the sequence of quotients generated by the original program takes that weird zigzag form. What mechanism is giving rise to those paired powers of 2 and the alternation of odd and even?</p>
<p>I have found that it’s easier to explain what’s going on in the zigzag sequence when I describe an iterative version of the procedure, rather than the recursive one. (This is an embarrassing admission for someone who has argued that recursive definitions are easier to reason about, but there you have it.) Here’s the program:</p>
<pre class="language-julia"><code>function div!_iter(n)
    q = 1
    for i in 1:n
        q = i // q
    end
    return q
end</code></pre>
<p>I submit that this looping procedure is operationally identical to the recursive function, in the sense that if <code>div!(n)</code> and <code>div!_iter(n)</code> both return a result for some positive integer <code>n</code>, it will always be the same result. Here’s my evidence: </p>
<pre class="language-julia"><code>[div!(n) for n in 1:20]    [div!_iter(n) for n in 1:20]
            1                         1//1    
           2//1                       2//1    
           3//2                       3//2    
           8//3                       8//3    
          15//8                      15//8    
          16//5                      16//5    
          35//16                     35//16   
         128//35                    128//35   
         315//128                   315//128  
         256//63                    256//63   
         693//256                   693//256  
        1024//231                  1024//231  
        3003//1024                 3003//1024 
        2048//429                  2048//429  
        6435//2048                 6435//2048 
       32768//6435                32768//6435 
      109395//32768              109395//32768
       65536//12155               65536//12155
      230945//65536              230945//65536
      262144//46189              262144//46189</code></pre>
<p>To understand the process that gives rise to these numbers, consider the successive values of the variables \(i\) and \(q\) each time the loop is executed. Initially, \(i\) and \(q\) are both set to \(1\); hence, after the first passage through the loop, the statement <code>q = i // q</code> gives \(q\) the value \(\frac{1}{1}\). Next time around, \(i = 2\) and \(q = \frac{1}{1}\), so \(q\)’s new value is \(\frac{2}{1}\). On the third iteration, \(i = 3\) and \(q = \frac{2}{1}\), yielding \(\frac{i}{q} \rightarrow \frac{3}{2}\). If this is still confusing, try thinking of \(\frac{i}{q}\) as \(i \times \frac{1}{q}\). The crucial observation is that on every passage through the loop, \(q\) is inverted, becoming \(\frac{1}{q}\).</p>
<p>If you unwind these operations, and look at the multiplications and divisions that go into each element of the series, a pattern emerges:</p>
<p>\[\frac{1}{1}, \quad \frac{2}{1}, \quad \frac{1 \cdot 3}{2}, \quad \frac{2 \cdot 4}{1 \cdot 3}, \quad \frac{1 \cdot 3 \cdot 5}{2 \cdot 4} \quad \frac{2 \cdot 4 \cdot 6}{1 \cdot 3 \cdot 5}\]</p>
<p class="undent">The general form is:</p>
<p>\[\frac{1 \cdot 3 \cdot 5 \cdot \cdots \cdot n}{2 \cdot 4 \cdot \cdots \cdot (n-1)} \quad (\text{odd } n) \qquad  \frac{2 \cdot 4 \cdot 6 \cdot \cdots \cdot n}{1 \cdot 3 \cdot 5 \cdot \cdots \cdot (n-1)} \quad (\text{even } n).<br/>
\]</p>
<hr/>
<p>The functions \(1 \cdot 3 \cdot 5 \cdot \cdots \cdot n\) for odd \(n\) and \(2 \cdot 4 \cdot 6 \cdot \cdots \cdot n\) for even \(n\) have a name! They are known as double factorials, with the notation \(n!!\). Terrible terminology, no? Better to have named them “semi-factorials.” And if I didn’t know better, I would read \(n!!\) as “the factorial of the factorial.” The double factorial of <em>n</em> is defined as the product of <em>n</em> and all smaller positive integers of the same parity. Thus our peculiar sequence of zigzag quotients is simply \(\frac{n!!}{(n-1)!!}\).</p>
<p>A <a href="https://www.tandfonline.com/doi/abs/10.4169/math.mag.85.3.177">2012 article</a> by Henry W. Gould and Jocelyn Quaintance (behind a paywall, regrettably) surveys the applications of double factorials. They turn up more often than you might guess. In the middle of the 17th century John Wallis came up with this identity:</p>
<p>\[\frac{\pi}{2} = \frac{2 \cdot 2 \cdot 4 \cdot 4 \cdot 6 \cdot 6 \cdots}{1 \cdot 3 \cdot 3 \cdot 5 \cdot 5 \cdot 7 \cdots} = \lim_{n \rightarrow \infty} \frac{((2n)!!)^2}{(2n + 1)!!(2n - 1)!!}\]</p>
<p class="undent">An even weirder series, involving the cube of a quotient of double factorials, sums to \(\frac{2}{\pi}\). That one was discovered by (who else?) Srinivasa Ramanujan.</p>
<p>Gould and Quaintance also discuss the double factorial counterpart of binomial coefficients. The standard binomial coefficient is defined as:</p>
<p>\[\binom{n}{k} = \frac{n!}{k! (n-k)!}.\]</p>
<p class="undent">The double version is:</p>
<p>\[\left(\!\binom{n}{k}\!\right) = \frac{n!!}{k!! (n-k)!!}.\]</p>
<p class="undent">Note that our zigzag numbers fit this description and therefore qualify as double factorial binomial coefficients. Specifically, they are the numbers:</p>
<p>\[\left(\!\binom{n}{1}\!\right) = \left(\!\binom{n}{n - 1}\!\right) = \frac{n!!}{1!! (n-1)!!}.\]</p>
<p class="undent">The regular binomial \(\binom{n}{1}\) is not very interesting; it is simply equal to \(n\). But the doubled version \(\left(\!\binom{n}{1}\!\right)\), as we’ve seen, dances a livelier jig. And, unlike the single binomial, it is not always an integer. (The only integer values are \(1\) and \(2\).)</p>
<p>Seeing the zigzag numbers as ratios of double factorials explains quite a few of their properties, starting with the alternation of evens and odds. We can also see why all the even numbers in the sequence are powers of 2. Consider the case of \(n = 6\). The numerator of this fraction is \(2 \cdot 4 \cdot 6 = 48\), which acquires a factor of \(3\) from the \(6\). But the denominator is \(1 \cdot 3 \cdot 5 = 15\). The \(3\)s above and below cancel, leaving \(\frac{16}{5}\). Such cancelations will happen in every case. Whenever an odd factor \(m\) enters the even sequence, it must do so in the form \(2 \cdot m\), but at that point \(m\) itself must already be present in the odd sequence.</p>
<hr/>
<p>Is the sequence of zigzag numbers a reasonable answer to the question, “What happens when you divide instead of multiply in \(n!\)?” Or is the computer program that generates them just a buggy algorithm? My personal judgment is that \(\frac{1}{n!}\) is a more intuitive answer, but \(\frac{n!!}{(n - 1)!!}\) is more interesting.</p>
<p>Furthermore, the mere existence of the zigzag sequence broadens our horizons. As noted above, if you insist that the division algorithm must always chug along the list of \(n\) factors in order, at each stop dividing the number on the left by the number on the right, then there are only \(n\) possible outcomes, and they all look much alike. But the zigzag solution suggests wilder possibilities. We can formulate the task as follows. Take the set of factors \(\{1 \dots n\}\), select a subset, and invert all the elements of that subset; now multiply all the factors, both the inverted and the upright ones. If the inverted subset is empty, the result is the ordinary factorial \(n!\). If <em>all</em> of the factors are inverted, we get the inverse \(\frac{1}{n!}\). And if every second factor is inverted, starting with \(n - 1\), the result is an element of the zigzag sequence.</p>
<p>These are only a few among the many possible choices; in total there are \(2^n\) subsets of \(n\) items. For example, you might invert every number that is prime or a power of a prime \((2, 3, 4, 5, 7, 8, 9, 11, \dots)\). For small \(n\), the result jumps around but remains consistently less than \(1\):</p>
<p><img alt="Prime powers" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/prime-powers.svg" width=""/></p>
<p class="undent">If I were to continue this plot to larger \(n\), however, it would take off for the stratosphere. Prime powers get sparse farther out on the number line.</p>
<hr/>
<p>Here’s a question. We’ve seen factorial variants that go to zero as \(n\) goes to infinity, such as \(1/n!\). We’ve seen other variants grow without bound as \(n\) increases, including \(n!\) itself, and the zigzag numbers. Are there any versions of the factorial process that converge to a finite bound other than zero?</p>
<p>My first thought was this algorithm:</p>
<pre class="language-julia"><code>function greedy_balance(n)
    q = 1
    while n &gt; 0
        q = q &gt; 1 ? q /= n : q *= n
        n -= 1
    end
    return q
end</code></pre>
<p class="undent">We loop through the integers from \(n\) down to \(1\), calculating the running product/quotient \(q\) as we go. At each step, if the current value of \(q\) is greater than \(1\), we divide by the next factor; otherwise, we multiply. This scheme implements a kind of feedback control or target-seeking behavior. If \(q\) gets too large, we reduce it; too small and we increase it. I conjectured that as \(n\) goes to infinity, \(q\) would settle into an ever-narrower range of values near \(1\).</p>
<p>Running the experiment gave me another surprise:</p>
<p><img alt="Greedy balance linear" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/greedy_balance_linear.svg" width=""/></p>
<p class="undent">That sawtooth wave is not quite what I expected. One minor peculiarity is that the curve is not symmetric around \(1\); the excursions above have higher amplitude than those below. But this distortion is more visual than mathematical. Because \(q\) is a ratio, the distance from \(1\) to \(10\) is the same as the distance from \(1\) to \(\frac{1}{10}\), but it doesn’t look that way on a linear scale. The remedy is to plot the log of the ratio:</p>
<p><img alt="Greedy balance" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/greedy_balance.svg" width=""/></p>
<p>Now the graph is symmetric, or at least approximately so, centered on \(0\), which is the logarithm of \(1\). But a larger mystery remains. The sawtooth waveform is very regular, with a period of \(4\), and it shows no obvious signs of shrinking toward the expected limiting value of \(\log q = 0\). Numerical evidence suggests that as \(n\) goes to infinity the peaks of this curve converge on a value just above \(q = \frac{5}{3}\), and the troughs approach a value just below \(q = \frac{3}{5}\). (The corresponding base-\(10\) logarithms are roughly \(\pm0.222\). I have not worked out why this should be so. Perhaps someone will explain it to me.</p>
<p>The failure of this greedy algorithm doesn’t mean we can’t find a divisive factorial that converges to \(q = 1\). If we work with the logarithms of the factors, this procedure becomes an instance of a well-known compu­tational problem called the number partitioning problem. You are given a set of real numbers and asked to divide it into two sets whose sums are equal, or as close to equal as possible. It’s a certifiably hard problem, but it has also been called (<a href="http://bit-player.org/bph-publications/AmSci-2002-03-Hayes-NPP.pdf">PDF</a>) “the easiest hard problem.”For any given \(n\), we might find that inverting some other subset of the factors gives a better approximation to \(n! = 1\). For small \(n\), we can solve the problem by brute force: Just look at all \(2^n\) subsets and pick the best one.</p>
<p>I have computed the optimal partitionings up to \(n = 30\), where there are a billion possibilities to choose from.</p>
<p><img alt="Optimum balance graph" border="0" class="centered" height="" src="http://bit-player.org/wp-content/uploads/2019/02/optimum_balance_graph.svg" width=""/></p>
<p class="undent">The graph is clearly flatlining. You could use the same method to force convergence to any other value between \(0\) and \(n!\).</p>
<p>And thus we have yet another answer to the question in the tweet that launched this adventure. What happens when you divide instead of multiply in n!? Anything you want.</p></div>
    </content>
    <updated>2019-02-10T08:48:33Z</updated>
    <published>2019-02-10T08:48:33Z</published>
    <category scheme="http://bit-player.org" term="computing"/>
    <category scheme="http://bit-player.org" term="mathematics"/>
    <author>
      <name>Brian Hayes</name>
      <uri>http://bit-player.org</uri>
    </author>
    <source>
      <id>http://bit-player.org/feed/atom</id>
      <link href="http://bit-player.org" rel="alternate" type="text/html"/>
      <link href="http://bit-player.org/feed/atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">An amateur's outlook on computation and mathematics</subtitle>
      <title xml:lang="en-US">bit-player</title>
      <updated>2019-02-10T20:48:43Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra</id>
    <link href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html" rel="alternate" type="text/html"/>
    <title>Big convex polyhedra in grids</title>
    <summary>I recently wrote here about big convex polygons in grids, a problem for which we know very precise answers. This naturally raises the question: what about higher dimensions? How many vertices can be part of a convex polyhedron in an grid, or more generally a convex polytope in a -dimensional grid of side length ? Here we do still know some pretty good answers, at least up to constant factors in spaces of constant dimension.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I recently wrote here about <a href="https://11011110.github.io/blog/2018/09/05/big-convex-polygons.html">big convex polygons in grids</a>, a problem for which we know very precise answers. This naturally raises the question: what about higher dimensions? How many vertices can be part of a convex polyhedron in an  grid, or more generally a convex polytope in a -dimensional grid of side length ? Here we do still know some pretty good answers, at least up to constant factors in spaces of constant dimension.</p>

<p>The problem is included in a 2008 survey by Imre Bárány,<sup id="fnref:bar"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bar">1</a></sup> according to whom the maximum number of vertices is</p>



<p>For instance, in three dimensional  grids the maximum number of vertices is .</p>

<p>One way to find polyhedra with this many vertices is to take the convex hull of the points in a ball,<sup id="fnref:bl"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bl">2</a></sup> <sup id="fnref:bd"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bd">3</a></sup> or in scaled copies of any fixed smooth convex body. Another way, which should generate polyhedra with a somewhat less irregular appearance and (up to constant factors) the same number of vertices, is to take the <a href="https://en.wikipedia.org/wiki/Minkowski_addition">Minkowski sum</a> of all line segments (up to scaling and translation) that will fit into a smaller grid, of side length . For instance, the <a href="https://en.wikipedia.org/wiki/Truncated_rhombicuboctahedron">truncated rhombicuboctahedron</a> below<sup id="fnref:ruen"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:ruen">4</a></sup> is the Minkowski sum of all the line segments that fit into a unit cube. Its 96 vertices lie in a  grid. In general, this method produces a <a href="https://en.wikipedia.org/wiki/Zonohedron">zonohedron</a> whose complexity can be analyzed in terms of a -dimensional arrangement of  hyperplanes. As long as this arrangement is not too degenerate (which it appears not to be, but I haven’t worked out the details carefully) this should give
a number of vertices within a constant factor of the number coming from the convex hull construction.</p>

<p style="text-align: center;"><img alt="Truncated rhombicuboctahedron" src="https://11011110.github.io/blog/assets/2019/truncated-rhombicuboctahedron2.png"/></p>

<p>A matching upper bound comes from a 1963 paper by G. K. Andrews,<sup id="fnref:and"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:and">5</a></sup> and Bárány writes that although several more proofs have been published none of them is easy. I’m not sure whether the difficulty is in getting the exact bound or in the fact that Andrews and the later proofs allow more general shapes with volume  that don’t fit into a grid, but it’s not hard to get close to the right bound simply by counting the number of possible facets of a given volume . By using <a href="https://en.wikipedia.org/wiki/Lenstra%E2%80%93Lenstra%E2%80%93Lov%C3%A1sz_lattice_basis_reduction_algorithm">lattice basis reduction</a> the integer vectors in the hyperplane through any facet have a nearly-orthogonal basis whose product of lengths is proportional to . By considering how this product of lengths can be broken down into factors of different scales, and counting how many integer vectors of those lengths exist, it follows that the number of possible facets of volume  is . Combining this with the  surface area of a grid polytope gives the correct upper bound on the number of vertices up to a polylog factor.</p>

<p>What about when the dimension is not constant? An easy construction for high dimensions is to take all points with a fixed distance  from the grid center. There are  possible values for the distance, so this construction produces a convex polytope with  vertices. It comes from a 1946 paper by Behrend, who uses this idea to find <a href="https://en.wikipedia.org/wiki/Salem%E2%80%93Spencer_set">dense sets of integers with no arithmetic progressions</a>.<sup id="fnref:beh"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:beh">6</a></sup>
It is never worse to use the convex hull of the ball than the points on a sphere,
and a celebrated paper by Elkin from 2011 (in the appendix of the published version) gives another proof of the  bound for convex hulls of balls (for ) in which the constant factor of the  is universal, not depending on . So when  is singly exponential in ,  becomes constant and the convex hull technique produces  vertices, improving Behrend’s construction for progression-free sets by the same  factor.<sup id="fnref:elk"><a class="footnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:elk">7</a></sup></p>

<div class="footnotes">
  <ol>
    <li id="fn:bar">
      <p>Bárány, Imre (2008), “Extremal problems for convex lattice polytopes: a survey”, <em>Surveys on Discrete and Computational Geometry</em>, Contemporary Mathematics 453, Amer. Math. Soc., pp. 87–103, <a href="https://doi.org/10.1090/conm/453/08796">doi:10.1090/conm/453/08796</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=2405678">MR2405678</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bar">↩</a></p>
    </li>
    <li id="fn:bl">
      <p>Bárány, Imre and Larman, David (1998), “The convex hull of the integer points in a large ball”, <em>Math. Ann.</em> 312 (1), pp. 167–181, <a href="https://doi.org/10.1007/s002080050217">doi:10.1007/s002080050217</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=1645957">MR1645957</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bl">↩</a></p>
    </li>
    <li id="fn:bd">
      <p>Balog, Antal and Deshouillers, Jean-Marc (1999), “On some convex lattice polytopes”. <em>Number Theory in Progress</em>, Vol. 2 (Zakopane-Kościelisko, 1997), de Gruyter, pp. 591–606, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=1689533">MR1689533</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bd">↩</a></p>
    </li>
    <li id="fn:ruen">
      <p>Ruen, Tom (2014), “Truncated rhombicuboctahedron”, CC-BY-SA 4.0, <a href="https://commons.wikimedia.org/wiki/File:Truncated_rhombicuboctahedron2.png">File:Truncated rhombicuboctahedron2.png</a> on Wikimedia commons. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:ruen">↩</a></p>
    </li>
    <li id="fn:and">
      <p>Andrews, George E. (1963), “A lower bound for the volume of strictly convex bodies with many boundary lattice points”, <em>Trans. Amer. Math. Soc.</em> 106, pp. 270–279, <a href="https://doi.org/10.2307/1993769">doi:10.2307/1993769</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=0143105">MR0143105</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:and">↩</a></p>
    </li>
    <li id="fn:beh">
      <p>Behrend, F. A. (1946), “On sets of integers which contain no three terms in arithmetical progression”, <em>Proc. Nat. Acad. Sci.</em> 32 (12), pp. 331–332, <a href="https://doi.org/10.1073/pnas.32.12.331">doi:10.1073/pnas.32.12.331</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=0018694">MR0018694</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:beh">↩</a></p>
    </li>
    <li id="fn:elk">
      <p>Elkin, Michael (2011), “An improved construction of progression-free sets”, <em>Israel J. Math.</em> 184, pp. 93–128, <a href="https://arxiv.org/abs/0801.4310">arXiv:0801.4310</a>, <a href="https://doi.org/10.1007%2Fs11856-011-0061-1">doi:10.1007/s11856-011-0061-1</a>, <a href="https://www.ams.org/mathscinet-getitem?mr=2823971">MR2823971</a>. The paragraph describing Elkin’s results was updated from an earlier more tentative version in the original post. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:elk">↩</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/101564963348879092">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-02-09T15:07:00Z</updated>
    <published>2019-02-09T15:07:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-02-11T18:35:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1087</id>
    <link href="https://ptreview.sublinear.info/?p=1087" rel="alternate" type="text/html"/>
    <title>News for January 2019</title>
    <summary>Minimax Testing of Identity to a Reference Ergodic Markov Chain, by Geoffrey Wolfer and Aryeh Kontorovich (arXiv). This work studies distributional identity testing on Markov chains from a single trajectory, as recently introduced by Daskalakis, Dikkala, and Gravin: we wish to test whether a Markov chain is equal to some reference chain, or far from […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Minimax Testing of Identity to a Reference Ergodic Markov Chain</strong>, by Geoffrey Wolfer and Aryeh Kontorovich (<a href="https://arxiv.org/abs/1902.00080">arXiv</a>). This work studies distributional identity testing on Markov chains from a single trajectory, as recently introduced by <a href="https://arxiv.org/abs/1704.06850">Daskalakis, Dikkala, and Gravin</a>: we wish to test whether a Markov chain is equal to some reference chain, or far from it. This improves on previous work by considering a stronger distance measure than before, and showing that the sample complexity only depends on properties of the reference chain (which we are trying to test identity to). It additionally proves instance-by-instance bounds (where the sample complexity depends on properties of the specific chain we wish to test identity to).</p>



<p><strong>Almost Optimal Distribution-free Junta Testing</strong>, by Nader H. Bshouty (<a href="https://arxiv.org/abs/1901.00717">arXiv</a>). This paper provides a \(\tilde O(k/\varepsilon)\)-query algorithm with two-sided error for testing if a Boolean function is a \(k\)-junta (that is, its value depends only on \(k\) of its variables) in the distribution-free model (where distance is measured with respect to an unknown distribution from which we can sample). This complexity is a quadratic improvement over the \(\tilde O(k^2)/\varepsilon\)-query algorithm of <a href="https://arxiv.org/abs/1802.04859">Chen, Liu, Servedio, Sheng, and Xie</a>. This complexity is also near-optimal, as shown in a lower bound by Saglam (which we covered back in <a href="https://ptreview.sublinear.info/?p=1030">August</a>).</p>



<p><strong>Exponentially Faster Massively Parallel Maximal Matching</strong>, by Soheil Behnezhad, MohammadTaghi Hajiaghayi, and David G. Harris (<a href="https://arxiv.org/abs/1901.03744">arXiv</a>). The authors consider maximal matching in the Massively Parallel Computation (MPC) model. They show that one can compute a maximal matching in \(O(\log \log \Delta)\)-rounds, with \(O(n)\) space per machine. This is an exponential improvement over the previous works, which required either \(\Omega(\log n)\) rounds or \(n^{1 + \Omega(1)}\) space per machine. Corollaries of their result include approximation algorithms for vertex cover, maximum matching, and weighted maximum matching. </p></div>
    </content>
    <updated>2019-02-08T18:30:54Z</updated>
    <published>2019-02-08T18:30:54Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-02-11T23:25:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3379</id>
    <link href="https://agtb.wordpress.com/2019/02/08/acm-sigecom-elections/" rel="alternate" type="text/html"/>
    <title>ACM SIGecom Elections</title>
    <summary>The following message just went out to ACM SIGecom members: ———- Forwarded message ——— From: Monique Chang &lt;chang@hq.acm.org&gt; Date: Mon, Feb 4, 2019 at 2:20 PM Subject: 2019 ACM SIGecom Election: Candidate Slate Announcement To: &lt;SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org&gt; Dear ACM SIGecom Member, The ACM SIGecom Nominating Committee has proposed the following candidates for the 2019 ACM SIGecom election. Chair […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><span style="font-weight: 400;">The following message just went out to ACM SIGecom members:</span></p>
<blockquote><p>———- Forwarded message ———<br/>
From: <strong>Monique Chang</strong> &lt;<a href="mailto:chang@hq.acm.org">chang@hq.acm.org</a>&gt;<br/>
Date: Mon, Feb 4, 2019 at 2:20 PM<br/>
Subject: 2019 ACM SIGecom Election: Candidate Slate Announcement<br/>
To: &lt;<a href="mailto:SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org">SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org</a>&gt;</p>
<p>Dear ACM SIGecom Member,</p>
<p>The ACM SIGecom Nominating Committee has proposed the following candidates for the 2019 ACM SIGecom election.</p>
<p><strong><u>Chair</u></strong><br/>
(Running Unopposed)</p>
<p>Nicole Immorlica</p>
<p><strong><u>Vice-Chair</u></strong></p>
<p>Scott Kominers</p>
<p>Ariel Procaccia</p>
<p><strong><u>Secretary-Treasurer</u></strong></p>
<p>Hu Fu</p>
<p>Katrina Ligett</p>
<p>In accordance with the ACM SIG Bylaws, additional candidates may be placed on the ballot by petition. All candidates must be ACM Professional Members, as well as members of the SIG. Anyone interested in petitioning must inform ACM Headquarters, Pat Ryan (<a href="mailto:ryanp@hq.acm.org">ryanp@hq.acm.org</a>), and SIGecom’s Secretary-Treasurer, Jenn Wortman Vaughan (<a href="mailto:jenn@microsoft.com">jenn@microsoft.com</a>), of their intent to petition by <strong>15 March 2019</strong>. Petitions must be submitted to ACM Headquarters for verification by <strong>2 April 2019</strong>.</p>
<p>Monique Chang</p>
<p>ACM SIG Elections Coordinator</p>
<p>Office of Policy and Administration</p></blockquote>
<p><span style="font-weight: 400;">Three things for members of our community to note:</span></p>
<ol>
<li style="font-weight: 400;">It’s important vote (once the link goes out; note that the current email is just an announcement and an invitation for additional candidates to petition to be included on the ballot). The SIG leadership is very important for the ongoing direction of our organization. Your vote makes a difference, because our elections are often decided by small margins.</li>
</ol>
<ol start="2">
<li style="font-weight: 400;">If you didn’t get this email, you’re likely not registered as a member of our SIG. Membership costs only $5 for students and $10 for others; AFAIK, you don’t have to be an ACM member to be a SIG member. Our number of members is an important signal to the ACM about the strength of our community (which is why we have set our fees so low). Votes like this one are also restricted to members! If your membership has lapsed, or if you’ve never taken the plunge, this might be a good occasion to do so, by clicking on the link below:</li>
</ol>
<p style="font-weight: 400;"><a href="https://www.acm.org/special-interest-groups/sigs/sigecom">https://www.acm.org/special-interest-groups/sigs/sigecom</a></p>
<ol start="3">
<li style="font-weight: 400;">Thanks to our nominations chair, David Parkes, who put together the slate of candidates just listed, and also to all of the candidates who agreed to serve. Our community is really lucky to have such a strong and deep pool of volunteers, and this is one more example. Indeed, in advance, I’d particularly like to thank those candidates who *don’t* win, whoever they turn out to be: it’s thankless to stick one’s neck out for an election only to see someone else get chosen (often by a small margin; see #1), but your willingness to serve is much appreciated.</li>
</ol></div>
    </content>
    <updated>2019-02-08T02:44:19Z</updated>
    <published>2019-02-08T02:44:19Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Kevin Leyton-Brown</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-02-12T19:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/017</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/017" rel="alternate" type="text/html"/>
    <title>TR19-017 |  Fourier bounds and pseudorandom generators for product tests | 

	Chin Ho Lee</title>
    <summary>We study the Fourier spectrum of functions $f\colon \{0,1\}^{mk} \to \{-1,0,1\}$ which can be written as a product of $k$ Boolean functions $f_i$ on disjoint $m$-bit inputs.  We prove that for every positive integer $d$,
\[
  \sum_{S \subseteq [mk]: |S|=d} |\hat{f_S}| = O(m)^d .
\]
Our upper bound is tight up to a constant factor in the $O(\cdot)$.  Our proof builds on a new "level-$d$ inequality" that bounds above $\sum_{|S|=d} \hat{f_S}^2$ for any $[0,1]$-valued function $f$ in terms of its expectation, which may be of independent interest.

As a result, we construct pseudorandom generators for such functions with seed length $\tilde O(m + \log(k/\varepsilon))$, which is optimal up to polynomial factors in $\log m$, $\log\log k$ and $\log\log(1/\varepsilon)$.  Our generator in particular works for the well-studied class of combinatorial rectangles, where in addition we allow the bits to be read in any order.  Even for this special case, previous generators have an extra $\tilde O(\log(1/\varepsilon))$ factor in their seed lengths. 

Using Schur-convexity, we also extend our results to functions $f_i$ whose range is $[-1,1]$.</summary>
    <updated>2019-02-07T14:59:22Z</updated>
    <published>2019-02-07T14:59:22Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-12T19:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/016</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/016" rel="alternate" type="text/html"/>
    <title>TR19-016 |  The hardest halfspace | 

	Alexander A. Sherstov</title>
    <summary>We study the approximation of halfspaces $h:\{0,1\}^n\to\{0,1\}$ in the infinity norm by polynomials and rational functions of any given degree.  Our main result is an explicit construction of the "hardest" halfspace, for which we prove polynomial and rational approximation lower bounds that match the trivial upper bounds achievable for all halfspaces.  This completes a lengthy line of work started by Myhill and Kautz (1961).

As an application, we construct a communication problem with essentially the largest possible gap, of $n$ versus $2^{-\Omega(n)},$ between the sign-rank and discrepancy. Equivalently, our problem exhibits a gap of $\log n$ versus $\Omega(n)$ between the communication complexity with unbounded versus weakly unbounded error, improving quadratically on previous constructions and completing a line of work started by Babai, Frankl, and Simon (FOCS 1986). Our results further generalize to the $k$-party number-on-the-forehead model, where we obtain an explicit separation of $\log n$ versus $\Omega(n/4^{n})$ for communication with unbounded versus weakly unbounded error. This gap is a quadratic improvement on previous work and matches the state of the art for number-on-the-forehead lower bounds.</summary>
    <updated>2019-02-07T14:57:13Z</updated>
    <published>2019-02-07T14:57:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-12T19:20:28Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-971154734717743655</id>
    <link href="https://blog.computationalcomplexity.org/feeds/971154734717743655/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/an-immerman-szelepcsenyi-story.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/971154734717743655" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/971154734717743655" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/an-immerman-szelepcsenyi-story.html" rel="alternate" type="text/html"/>
    <title>An Immerman-Szelepcsényi Story</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">As a grad student in the late 80's I had the opportunity to witness many great and often surprising theorems in computational complexity. Let me tell you about one of them, the Immerman-Szelepcsényi result that <a href="https://blog.computationalcomplexity.org/2003/06/foundations-of-complexity-lesson-19.html">nondeterministic space is closed under complement</a>. I wish I had the original emails for this story but instead I'm working from memory and apologies if I get some of the details wrong. I'm expanding from a <a href="https://blog.computationalcomplexity.org/2002/08/last-spring-i-saw-copenhagen-great.html">short version</a> from the early days of this blog.<br/>
<br/>
I started my graduate work at UC Berkeley in 1985 and then moved to MIT in the summer of '86, following my advisor Michael Sipser. In the summer of 1987, Neil Immerman, then at Yale, proved his famous result building on his work in <a href="https://en.wikipedia.org/wiki/Descriptive_complexity_theory">descriptive complexity</a> In those days you didn't email papers, he made copies and sent them by US postal mail to several major researchers in complexity including Sipser. But Sipser was away for the summer, I believe in Russia, and the paper sat in his office.<br/>
<br/>
Immerman also sent the paper to a Berkeley professor, probably Manuel Blum, who gave it to one of his students who decided to speak about the result in a student-led seminar. I forgot who was the student, maybe Moni Naor. I was still on the Berkeley email list so I got the talk announcement and went into complexity ecstasy over the news. I asked Moni (or whomever was giving the talk) if he could tell me details and he sent me a nice write-up of the proof. Given the importance of the result, I sent the proof write-up out to the MIT theory email list.<br/>
<br/>
Guess who was on the MIT theory list? Neil Immerman. Neil wrote back with his own explanation of the proof. Neil explained how it came out of descriptive complexity but as a pure write-up of a proof of the theorem, Moni did an excellent job.<br/>
<br/>
We found out about Robert Szelepcsényi when his paper showed up a few months later in the Bulletin of the European Association for Theoretical Computer Science. Szelepcsényi came to the problem from formal languages, whether context-sensitive languages (nondeterministic linear space) was closed under complement. Szelepcsényi, an undergrad in Slovakia at the time, heard about the problem in a class he took. Szelepcsényi's proof was very similar to Immerman. Szelepcsényi's paper took longer to get to US researchers but likely was proven and written about the same time as Immerman.<br/>
<br/>
Even though both papers were <a href="https://doi.org/10.1137/0217058">published</a> <a href="https://doi.org/10.1007/BF00299636">separately</a> we refer to the result as Immerman-Szelepcsényi and is now just some old important theorem you see in introductory theory classes.</div>
    </content>
    <updated>2019-02-07T12:47:00Z</updated>
    <published>2019-02-07T12:47:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-12T15:55:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/015</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/015" rel="alternate" type="text/html"/>
    <title>TR19-015 |  QMA Lower Bounds for Approximate Counting | 

	William Kretschmer</title>
    <summary>We prove a query complexity lower bound for $QMA$ protocols that solve approximate counting: estimating the size of a set given a membership oracle. This gives rise to an oracle $A$ such that $SBP^A \not\subset QMA^A$, resolving an open problem of Aaronson [2]. Our proof uses the polynomial method to derive a lower bound for the $SBQP$ query complexity of the $AND$ of two approximate counting instances. We use Laurent polynomials as a tool in our proof, showing that the "Laurent polynomial method" can be useful even for problems involving ordinary polynomials.</summary>
    <updated>2019-02-07T08:16:08Z</updated>
    <published>2019-02-07T08:16:08Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-12T19:20:28Z</updated>
    </source>
  </entry>
</feed>
