<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-06-27T22:48:41Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7756</id>
    <link href="https://windowsontheory.org/2020/06/26/stoc-2020-slack-channel-open-from-madhur-tulsiani/" rel="alternate" type="text/html"/>
    <title>STOC 2020 slack channel open (from Madhur Tulsiani)</title>
    <summary>Madhur writes: Thanks to all who participated in STOC 2020! Since the discussions on some of the topics from the business meeting, on SafeToC, and  on the papers/workshops are still ongoing, we will keep the Slack workspace open till July 31st (instead of just one week after the conference, as announced earlier). Also, if any […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Madhur writes:</p>



<p>Thanks to all who participated in STOC 2020! Since the discussions on some of the topics from the business meeting, on SafeToC, and  on the papers/workshops are still ongoing, we will keep the Slack workspace open till <strong>July 31st</strong> (instead of just one week after the conference, as announced earlier). Also, if any members of the community are interested in joining the discussions, they are welcome to email us (<a>stoc2020@ttic.edu</a>) and we can send them an invitation to join the workspace.</p>



<p>Of course the organizers may not always be able to quickly respond to help messages during the next month. However, all members are welcome to participate in discussions, create new topics or channels as needed, and use the workspace as they prefer.</p>



<p>TheoryFest organization team (<a href="mailto:stoc2020@ttic.edu" rel="noreferrer noopener" target="_blank">stoc2020@ttic.edu</a>)</p></div>
    </content>
    <updated>2020-06-27T01:37:25Z</updated>
    <published>2020-06-27T01:37:25Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-06-27T22:47:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14571</id>
    <link href="http://arxiv.org/abs/2006.14571" rel="alternate" type="text/html"/>
    <title>Sparse Convex Optimization via Adaptively Regularized Hard Thresholding</title>
    <feedworld_mtime>1593216000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Axiotis:Kyriakos.html">Kyriakos Axiotis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sviridenko:Maxim.html">Maxim Sviridenko</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14571">PDF</a><br/><b>Abstract: </b>The goal of Sparse Convex Optimization is to optimize a convex function $f$
under a sparsity constraint $s\leq s^*\gamma$, where $s^*$ is the target number
of non-zero entries in a feasible solution (sparsity) and $\gamma\geq 1$ is an
approximation factor. There has been a lot of work to analyze the sparsity
guarantees of various algorithms (LASSO, Orthogonal Matching Pursuit (OMP),
Iterative Hard Thresholding (IHT)) in terms of the Restricted Condition Number
$\kappa$. The best known algorithms guarantee to find an approximate solution
of value $f(x^*)+\epsilon$ with the sparsity bound of $\gamma =
O\left(\kappa\min\left\{\log \frac{f(x^0)-f(x^*)}{\epsilon},
\kappa\right\}\right)$, where $x^*$ is the target solution. We present a new
Adaptively Regularized Hard Thresholding (ARHT) algorithm that makes
significant progress on this problem by bringing the bound down to
$\gamma=O(\kappa)$, which has been shown to be tight for a general class of
algorithms including LASSO, OMP, and IHT. This is achieved without significant
sacrifice in the runtime efficiency compared to the fastest known algorithms.
We also provide a new analysis of OMP with Replacement (OMPR) for general $f$,
under the condition $s &gt; s^* \frac{\kappa^2}{4}$, which yields Compressed
Sensing bounds under the Restricted Isometry Property (RIP). When compared to
other Compressed Sensing approaches, it has the advantage of providing a strong
tradeoff between the RIP condition and the solution sparsity, while working for
any general function $f$ that meets the RIP condition.
</p></div>
    </summary>
    <updated>2020-06-27T22:27:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14552</id>
    <link href="http://arxiv.org/abs/2006.14552" rel="alternate" type="text/html"/>
    <title>Practical Trade-Offs for the Prefix-Sum Problem</title>
    <feedworld_mtime>1593216000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pibiri:Giulio_Ermanno.html">Giulio Ermanno Pibiri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Venturini:Rossano.html">Rossano Venturini</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14552">PDF</a><br/><b>Abstract: </b>Given an integer array A, the prefix-sum problem is to answer sum(i) queries
that return the sum of the elements in A[0..i], knowing that the integers in A
can be changed. It is a classic problem in data structure design with a wide
range of applications in computing from coding to databases. In this work, we
propose and compare several and practical solutions to this problem, showing
that new trade-offs between the performance of queries and updates can be
achieved on modern hardware.
</p></div>
    </summary>
    <updated>2020-06-27T22:33:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14449</id>
    <link href="http://arxiv.org/abs/2006.14449" rel="alternate" type="text/html"/>
    <title>Augmenting the Algebraic Connectivity of Graphs</title>
    <feedworld_mtime>1593216000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Bogdan-Adrian Manghiuc, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Pan.html">Pan Peng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:He.html">He Sun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14449">PDF</a><br/><b>Abstract: </b>For any undirected graph $G=(V,E)$ and a set $E_W$ of candidate edges with
$E\cap E_W=\emptyset$, the $(k,\gamma)$-spectral augmentability problem is to
find a set $F$ of $k$ edges from $E_W$ with appropriate weighting, such that
the algebraic connectivity of the resulting graph $H=(V,E\cup F)$ is least
$\gamma$. Because of a tight connection between the algebraic connectivity and
many other graph parameters, including the graph's conductance and the mixing
time of random walks in a graph, maximising the resulting graph's algebraic
connectivity by adding a small number of edges has been studied over the past
15 years.
</p>
<p>In this work we present an approximate and efficient algorithm for the
$(k,\gamma)$-spectral augmentability problem, and our algorithm runs in
almost-linear time under a wide regime of parameters. Our main algorithm is
based on the following two novel techniques developed in the paper, which might
have applications beyond the $(k,\gamma)$-spectral augmentability problem.
</p>
<p>(1) We present a fast algorithm for solving a feasibility version of an SDP
for the algebraic connectivity maximisation problem from [GB06]. Our algorithm
is based on the classic primal-dual framework for solving SDP, which in turn
uses the multiplicative weight update algorithm. We present a novel approach of
unifying SDP constraints of different matrix and vector variables and give a
good separation oracle accordingly.
</p>
<p>(2) We present an efficient algorithm for the subgraph sparsification
problem, and for a wide range of parameters our algorithm runs in almost-linear
time, in contrast to the previously best known algorithm running in at least
$\Omega(n^2mk)$ time [KMST10]. Our analysis shows how the randomised BSS
framework can be generalised in the setting of subgraph sparsification, and how
the potential functions can be applied to approximately keep track of different
subspaces.
</p></div>
    </summary>
    <updated>2020-06-27T22:27:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14403</id>
    <link href="http://arxiv.org/abs/2006.14403" rel="alternate" type="text/html"/>
    <title>Approximation Algorithms for Clustering with Dynamic Points</title>
    <feedworld_mtime>1593216000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deng:Shichuan.html">Shichuan Deng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jian.html">Jian Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rabani:Yuval.html">Yuval Rabani</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14403">PDF</a><br/><b>Abstract: </b>In many classic clustering problems, we seek to sketch a massive data set of
$n$ points in a metric space, by segmenting them into $k$ categories or
clusters, each cluster represented concisely by a single point in the metric
space. Two notable examples are the $k$-center/$k$-supplier problem and the
$k$-median problem. In practical applications of clustering, the data set may
evolve over time, reflecting an evolution of the underlying clustering model.
In this paper, we initiate the study of a dynamic version of clustering
problems that aims to capture these considerations. In this version there are
$T$ time steps, and in each time step $t\in\{1,2,\dots,T\}$, the set of clients
needed to be clustered may change, and we can move the $k$ facilities between
time steps. More specifically, we study two concrete problems in this
framework: the Dynamic Ordered $k$-Median and the Dynamic $k$-Supplier problem.
We first consider the Dynamic Ordered $k$-Median problem, where the objective
is to minimize the weighted sum of ordered distances over all time steps, plus
the total cost of moving the facilities between time steps. We present one
constant-factor approximation algorithm for $T=2$ and another approximation
algorithm for fixed $T \geq 3$. Then we consider the Dynamic $k$-Supplier
problem, where the objective is to minimize the maximum distance from any
client to its facility, subject to the constraint that between time steps the
maximum distance moved by any facility is no more than a given threshold. When
the number of time steps $T$ is 2, we present a simple constant factor
approximation algorithm and a bi-criteria constant factor approximation
algorithm for the outlier version, where some of the clients can be discarded.
We also show that it is NP-hard to approximate the problem with any factor for
$T \geq 3$.
</p></div>
    </summary>
    <updated>2020-06-27T22:34:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14312</id>
    <link href="http://arxiv.org/abs/2006.14312" rel="alternate" type="text/html"/>
    <title>New Approximations and Hardness Results for Submodular Partitioning Problems</title>
    <feedworld_mtime>1593216000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santiago:Richard.html">Richard Santiago</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14312">PDF</a><br/><b>Abstract: </b>We consider the following class of submodular k-multiway partitioning
problems: (Sub-$k$-MP) $\min \sum_{i=1}^k f(S_i): S_1 \uplus S_2 \uplus \cdots
\uplus S_k = V \mbox{ and } S_i \neq \emptyset \mbox{ for all }i\in [k]$. Here
$f$ is a non-negative submodular function, and $\uplus$ denotes the union of
disjoint sets. Hence the goal is to partition $V$ into $k$ non-empty sets
$S_1,S_2,\ldots,S_k$ such that $\sum_{i=1}^k f(S_i)$ is minimized. These
problems were introduced by Zhao et al. partly motivated by applications to
network reliability analysis, VLSI design, hypergraph cut, and other
partitioning problems.
</p>
<p>In this work we revisit this class of problems and shed some light onto their
hardness of approximation in the value oracle model. We provide new
unconditional hardness results for Sub-$k$-MP in the special settings where the
function $f$ is either monotone or symmetric. For symmetric functions we show
that given any $\epsilon &gt; 0$, any algorithm achieving a $(2 -
\epsilon)$-approximation requires exponentially many queries in the value
oracle model. For monotone objectives we show that given any $\epsilon &gt; 0$,
any algorithm achieving a $(4/3 - \epsilon)$-approximation requires
exponentially many queries in the value oracle model.
</p>
<p>We then extend Sub-$k$-MP to a larger class of partitioning problems, where
the functions $f_i(S_i)$ can now be all different, and there is a more general
partitioning constraint $ S_1 \uplus S_2 \uplus \cdots \uplus S_k \in
\mathcal{F}$ for some family $\mathcal{F} \subseteq 2^V$ of feasible sets. We
provide a black box reduction that allows us to leverage several existing
results from the literature; leading to new approximations for this class of
problems.
</p></div>
    </summary>
    <updated>2020-06-27T22:27:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14309</id>
    <link href="http://arxiv.org/abs/2006.14309" rel="alternate" type="text/html"/>
    <title>Reconfiguration of Spanning Trees with Many or Few Leaves</title>
    <feedworld_mtime>1593216000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bousquet:Nicolas.html">Nicolas Bousquet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ito:Takehiro.html">Takehiro Ito</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobayashi:Yusuke.html">Yusuke Kobayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mizuta:Haruka.html">Haruka Mizuta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ouvrard:Paul.html">Paul Ouvrard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suzuki:Akira.html">Akira Suzuki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wasa:Kunihiro.html">Kunihiro Wasa</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14309">PDF</a><br/><b>Abstract: </b>Let $G$ be a graph and $T_1,T_2$ be two spanning trees of $G$. We say that
$T_1$ can be transformed into $T_2$ via an edge flip if there exist two edges
$e \in T_1$ and $f$ in $T_2$ such that $T_2= (T_1 \setminus e) \cup f$. Since
spanning trees form a matroid, one can indeed transform a spanning tree into
any other via a sequence of edge flips, as observed by Ito et al.
</p>
<p>We investigate the problem of determining, given two spanning trees $T_1,T_2$
with an additional property $\Pi$, if there exists an edge flip transformation
from $T_1$ to $T_2$ keeping property $\Pi$ all along.
</p>
<p>First we show that determining if there exists a transformation from $T_1$ to
$T_2$ such that all the trees of the sequence have at most $k$ (for any fixed
$k \ge 3$) leaves is PSPACE-complete.
</p>
<p>We then prove that determining if there exists a transformation from $T_1$ to
$T_2$ such that all the trees of the sequence have at least $k$ leaves (where
$k$ is part of the input) is PSPACE-complete even restricted to split,
bipartite or planar graphs. We complete this result by showing that the problem
becomes polynomial for cographs, interval graphs and when $k=n-2$.
</p></div>
    </summary>
    <updated>2020-06-27T22:26:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14298</id>
    <link href="http://arxiv.org/abs/2006.14298" rel="alternate" type="text/html"/>
    <title>An Efficient, Practical Algorithm and Implementation for Computing Multiplicatively Weighted Voronoi Diagrams</title>
    <feedworld_mtime>1593216000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Held:Martin.html">Martin Held</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lorenzo:Stefan_de.html">Stefan de Lorenzo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14298">PDF</a><br/><b>Abstract: </b>We present a simple wavefront-like approach for computing multiplicatively
weighted Voronoi diagrams of points and straight-line segments in the Euclidean
plane. If the input sites may be assumed to be randomly weighted points then
the use of a so-called overlay arrangement [Har-Peled&amp;Raichel, Discrete Comput.
Geom. 53:547-568, 2015] allows to achieve an expected runtime complexity of
$O(n\log^4 n)$, while still maintaining the simplicity of our approach. We
implemented the full algorithm for weighted points as input sites, based on
CGAL. The results of an experimental evaluation of our implementation suggest
$O(n\log^2 n)$ as a practical bound on the runtime. Our algorithm can be
extended to handle also additive weights in addition to multiplicative weights,
and it yields a truly simple $O(n\log n)$ solution for solving the
one-dimensional version of this problem.
</p></div>
    </summary>
    <updated>2020-06-27T22:43:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14182</id>
    <link href="http://arxiv.org/abs/2006.14182" rel="alternate" type="text/html"/>
    <title>A linear time algorithm for constructing orthogonal floor plans with minimum number of bends</title>
    <feedworld_mtime>1593216000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Pinki, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shekhawat:Krishnendra.html">Krishnendra Shekhawat</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14182">PDF</a><br/><b>Abstract: </b>Let G = (V, E) be a planar triangulated graph (PTG) having every face
triangular. A rectilinear dual or an orthogonal floor plan (OFP) of G is
obtained by partitioning a rectangle into \mid V \mid rectilinear regions
(modules) where two modules are adjacent if and only if there is an edge
between the corresponding vertices in G. In this paper, a linear-time algorithm
is presented for constructing an OFP for a given G such that the obtained OFP
has B_{min} bends, where a bend in a concave corner in an OFP. Further, it has
been proved that at least B_{min} bends are required to construct an OFP for G,
where \rho - 2 \leq B_{min} \leq \rho + 1 and \rho is the sum of the number of
leaves of the containment tree of G and the number of K_4 (4-vertex complete
graph) in G.
</p></div>
    </summary>
    <updated>2020-06-27T22:46:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14093</id>
    <link href="http://arxiv.org/abs/2006.14093" rel="alternate" type="text/html"/>
    <title>A Linear-Time Algorithm for Discrete Radius Optimally Augmenting Paths in a Metric Space</title>
    <feedworld_mtime>1593216000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Haitao.html">Haitao Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhao:Yiming.html">Yiming Zhao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14093">PDF</a><br/><b>Abstract: </b>Let $P$ be a path graph of $n$ vertices embedded in a metric space. We
consider the problem of adding a new edge to $P$ so that the radius of the
resulting graph is minimized, where any center is constrained to be one of the
vertices of $P$. Previously, the "continuous" version of the problem where a
center may be a point in the interior of an edge of the graph was studied and a
linear-time algorithm was known. Our "discrete" version of the problem has not
been studied before. We present a linear-time algorithm for the problem.
</p></div>
    </summary>
    <updated>2020-06-27T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14059</id>
    <link href="http://arxiv.org/abs/2006.14059" rel="alternate" type="text/html"/>
    <title>Distance bounds for high dimensional consistent digital rays and 2-D partially-consistent digital rays</title>
    <feedworld_mtime>1593216000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chiu:Man=Kwun.html">Man-Kwun Chiu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Korman:Matias.html">Matias Korman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suderland:Martin.html">Martin Suderland</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tokuyama:Takeshi.html">Takeshi Tokuyama</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14059">PDF</a><br/><b>Abstract: </b>We consider the problem of digitalizing Euclidean segments. Specifically, we
look for a constructive method to connect any two points in $\mathbb{Z}^d$. The
construction must be {\em consistent} (that is, satisfy the natural extension
of the Euclidean axioms) while resembling them as much as possible. Previous
work has shown asymptotically tight results in two dimensions with $\Theta(\log
N)$ error, where resemblance between segments is measured with the Hausdorff
distance, and $N$ is the $L_1$ distance between the two points. This
construction was considered tight because of a $\Omega(\log N)$ lower bound
that applies to any consistent construction in $\mathbb{Z}^2$.
</p>
<p>In this paper we observe that the lower bound does not directly extend to
higher dimensions. We give an alternative argument showing that any consistent
construction in $d$ dimensions must have $\Omega(\log^{1/(d-1)} N)$ error. We
tie the error of a consistent construction in high dimensions to the error of
similar {\em weak} constructions in two dimensions (constructions for which
some points need not satisfy all the axioms). This not only opens the
possibility for having constructions with $o(\log N)$ error in high dimensions,
but also opens up an interesting line of research in the tradeoff between the
number of axiom violations and the error of the construction. In order to show
our lower bound, we also consider a colored variation of the concept of
discrepancy of a set of points that we find of independent interest.
</p></div>
    </summary>
    <updated>2020-06-27T22:44:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14029</id>
    <link href="http://arxiv.org/abs/2006.14029" rel="alternate" type="text/html"/>
    <title>Small Longest Tandem Scattered Subsequences</title>
    <feedworld_mtime>1593216000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Russo:Lu=iacute=s_M=_S=.html">Luís M. S. Russo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Francisco:Alexandre_P=.html">Alexandre P. Francisco</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14029">PDF</a><br/><b>Abstract: </b>We consider the problem of identifying tandem scattered subsequences within a
string. Our algorithm identifies a longest subsequence which occurs twice
without overlap in a string. This algorithm is based on the Hunt-Szymanski
algorithm, therefore its performance improves if the string is not self
similar. This occurs naturally on strings over large alphabets. Our algorithm
relies on new results for data structures that support dynamic longest
increasing sub-sequences. In the process we also obtain improved algorithms for
the decremental string comparison problem.
</p></div>
    </summary>
    <updated>2020-06-27T22:32:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14015</id>
    <link href="http://arxiv.org/abs/2006.14015" rel="alternate" type="text/html"/>
    <title>Vector-Matrix-Vector Queries for Solving Linear Algebra, Statistics, and Graph Problems</title>
    <feedworld_mtime>1593216000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rashtchian:Cyrus.html">Cyrus Rashtchian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhu:Hanlin.html">Hanlin Zhu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14015">PDF</a><br/><b>Abstract: </b>We consider the general problem of learning about a matrix through
vector-matrix-vector queries. These queries provide the value of
$\boldsymbol{u}^{\mathrm{T}}\boldsymbol{M}\boldsymbol{v}$ over a fixed field
$\mathbb{F}$ for a specified pair of vectors $\boldsymbol{u},\boldsymbol{v} \in
\mathbb{F}^n$. To motivate these queries, we observe that they generalize many
previously studied models, such as independent set queries, cut queries, and
standard graph queries. They also specialize the recently studied matrix-vector
query model. Our work is exploratory and broad, and we provide new upper and
lower bounds for a wide variety of problems, spanning linear algebra,
statistics, and graphs. Many of our results are nearly tight, and we use
diverse techniques from linear algebra, randomized algorithms, and
communication complexity.
</p></div>
    </summary>
    <updated>2020-06-27T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14009</id>
    <link href="http://arxiv.org/abs/2006.14009" rel="alternate" type="text/html"/>
    <title>Discrepancy Minimization via a Self-Balancing Walk</title>
    <feedworld_mtime>1593216000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alweiss:Ryan.html">Ryan Alweiss</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Yang_P=.html">Yang P. Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sawhney:Mehtaab.html">Mehtaab Sawhney</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14009">PDF</a><br/><b>Abstract: </b>We study discrepancy minimization for vectors in $\mathbb{R}^n$ under various
settings. The main result is the analysis of a new simple random process in
multiple dimensions through a comparison argument. As corollaries, we obtain
bounds which are tight up to logarithmic factors for several problems in online
vector balancing posed by Bansal, Jiang, Singla, and Sinha (STOC 2020), as well
as linear time algorithms for logarithmic bounds for the Koml\'{o}s conjecture.
</p></div>
    </summary>
    <updated>2020-06-27T22:43:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19925</id>
    <link href="https://gilkalai.wordpress.com/2020/06/26/to-cheer-you-up-in-difficult-times-6-play-rani-sharims-two-player-games-of-life-read-maya-bar-hillel-presentation-on-catching-lies-with-statistics-and-more/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 6:  Play Rani Sharim’s two-player games of life,  read Maya Bar-Hillel presentation on catching lies with statistics, and more.</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Sorry for the long blog silence. In this post I wish to give a few links each of which probably deserves a full post. I will start with Rani Sharim’s two-player variants of John Conway’s game-of-life Here is a web-page … <a href="https://gilkalai.wordpress.com/2020/06/26/to-cheer-you-up-in-difficult-times-6-play-rani-sharims-two-player-games-of-life-read-maya-bar-hillel-presentation-on-catching-lies-with-statistics-and-more/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Sorry for the long blog silence. In this post I wish to give a few links each of which probably deserves a full post. I will start with</p>
<h2>Rani Sharim’s two-player variants of John Conway’s game-of-life</h2>
<p><a href="https://ranisharim.github.io/game_of_life_2_players/">Here is a web-page</a> by a student in my “Game Theory” course where you can play several two-players variants of John Conway’s game-of-life.  (A couple of variants were considered before. See, e.g. <a href="https://arxiv.org/abs/cond-mat/0207679">this  paper</a>.)</p>
<p>I really enjoyed playing Rani’s games and it can certainly cheer you up in difficult times. Questions about the game, remarks, and suggestions for improvements and for new features, are most welcome.</p>
<h2>How to catch lies with statistics, a 2006  presentation by Maya Bar-Hillel</h2>
<p><a href="https://gilkalai.files.wordpress.com/2020/06/mayesther.png"><img alt="" class="alignnone size-full wp-image-19929" src="https://gilkalai.files.wordpress.com/2020/06/mayesther.png?w=640"/></a></p>
<p>Maya Bar-Hillel (left) and Ester Samuel-Cahn</p>
<p>Here is an interesting 2006 <a href="https://gilkalai.files.wordpress.com/2020/06/ester.ppt">power point presentation entitled <strong><em>How to detect lies with statistics</em></strong> by Maya Bar-Hillel.</a>  This was a talk given by Maya at the <a href="http://www.esterconference.huji.ac.il/">conference</a> honoring Prof. Ester Samuel- Cahn , Jerusalem, December 18-20, 2006, and it described a planned research project of Maya Bar-Hillel with Yossi Rinott, David Budescu and myself. At the end we did not pursue it, mainly because each of us was involved in various other projects (but also because we were skeptical about some aspects of it.)  Ester Samuel-Cahn (1933-2015) was a famous Israeli statistician. (Here is a <a href="http://www.sci-princess.info/archives/291">post by Yosi Levy in Hebrew</a> about the conference and about Ester.)</p>
<p>The lecture starts with “Last year, <em>Statistical Science</em> celebrated 50 years for `How to Lie with Statistics’ the book [by Durell Huff] whose title inspired this talk.”</p>
<p>And here are a few other quotes from Maya’s presentation</p>
<p>“We are not sure a general toolkit for detecting lies with statistics can be developed. Perhaps that explains why none yet exists.  We have shown just a collection of anecdotes. But they can be classified and categorized. Some do seem generalizeable, at least to some extent.”</p>
<p>and the conclusion</p>
<blockquote><p>A famous quip by Fred Mosteller: “It is easy to lie with statistics, but easier to lie without them.”</p>
<p>Likewise, we should say:  “It is possible to detect (some) lies with statistics, but easier to detect them with other means”.</p></blockquote>
<h2>New bounds for Ryser’s conjecture and related problems</h2>
<p>Peter Keevash, Alexey Pokrovskiy, Benny Sudakov, and Liana Yepremyan’s paper  <a href="https://arxiv.org/abs/2005.00526">New bounds for Ryser’s conjecture and related problems,</a> describes remarkable progress very old questions regarding transversals in Latin square.</p>
<h2>Topological Tverberg news</h2>
<p>I came across a very interesting paper <a href="https://arxiv.org/abs/2005.05251">The topological Tverberg problem beyond <span class="search-hit mathjax">prime</span> powers</a> by Florian Frick and Pablo Soberón with new bounds and a new method for topological Tverberg theorem in the non prime-power case.</p>
<h2>Jeager’s conjecture refuted</h2>
<p>A year ago I came across <a href="https://www.facebook.com/photo.php?fbid=2114324995342352&amp;set=a.507523926022475&amp;type=3&amp;theater">this cool facebook post</a> by Rupei Xu</p>
<blockquote><p>OMG! Just learned that Jaeger’s conjecture is false for every t&gt;=3. An interesting consequence of it is that a specific version of Goddyn’s conjecture on thin spanning trees is false, which shows some negative evidence that the thin spanning tree approaches may fail to lead to a constant factor approximation algorithm for ATSP!</p></blockquote>
<h2>A cool rainbow post <a href="http://matroidunion.org/?p=2541">Short rainbow cycles in graphs and matroids</a> by Tony Huynh</h2>
<h2>More on the game of life</h2>
<p>Let me mention two problems I posted 6-7 years ago about Conway’s game of life. <a class="question-hyperlink" href="https://mathoverflow.net/questions/132402/conways-game-of-life-for-random-initial-position">Conway’s game of life for random initial position</a> and <a class="question-hyperlink" href="https://cstheory.stackexchange.com/questions/17914/does-a-noisy-version-of-conways-game-of-life-support-universal-computation">Does a noisy version of Conway’s game of life support universal computation?</a></p>
<div class="left-sidebar js-pinned-left-sidebar ps-relative" id="left-sidebar">
<div class="left-sidebar--sticky-container js-sticky-leftnav"/>
</div>
<p> </p>
<p> </p></div>
    </content>
    <updated>2020-06-25T21:21:45Z</updated>
    <published>2020-06-25T21:21:45Z</published>
    <category term="Combinatorics"/>
    <category term="Games"/>
    <category term="Rationality"/>
    <category term="Maya Bar Hillel"/>
    <category term="Rani Sharim"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-06-27T22:46:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=775</id>
    <link href="https://emanueleviola.wordpress.com/2020/06/25/we-dont-need-no-education/" rel="alternate" type="text/html"/>
    <title>We don’t need no education</title>
    <summary>Around us, educational systems whose primary emphasis is on social rather than intellectual skills are simply disintegrating. Unequipped for content delivery, teachers spray parents with a mixture of links and credentials whose collection is a complete waste of everybody’s time. Suggestion: What about assigning homework and let teachers provide feedback? To all the school-age kids […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Around us, educational systems whose primary emphasis is on social rather than intellectual skills are simply disintegrating.  Unequipped for content delivery, teachers spray parents with a mixture of links and credentials whose collection is a complete waste of everybody’s time.  Suggestion: What about assigning <em>homework </em>and let teachers provide <em>feedback</em>?</p>



<p>To all the school-age kids stuck at home doing some fun coding, <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwio8MDa4JvqAhWfVhUIHSAIABgQyCkwAHoECBUQBw&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYR5ApYxkU-U&amp;usg=AOvVaw0s6Ai-o5-CNtyqFC7uHT_4">this immortal song is for you</a>.</p></div>
    </content>
    <updated>2020-06-25T10:29:13Z</updated>
    <published>2020-06-25T10:29:13Z</published>
    <category term="Uncategorized"/>
    <category term="Utopia"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-06-27T22:47:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/25/postdoc-in-experimental-algorithms-at-national-university-of-singapore-apply-by-august-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/25/postdoc-in-experimental-algorithms-at-national-university-of-singapore-apply-by-august-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc in Experimental Algorithms at National University of Singapore (apply by August 15, 2020)</title>
    <summary>A one-year postdoc position (with a possibility of extension for another year) in experimental (/practical) algorithms is available at NUS. The position will be jointly hosted by Diptarka Chakraborty and Kuldeep S. Meel. Applications are invited from candidates who have solid background in algorithm design/formal methods, mathematics. A prior experience in programming would be a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A one-year postdoc position (with a possibility of extension for another year) in experimental (/practical) algorithms is available at NUS. The position will be jointly hosted by Diptarka Chakraborty and Kuldeep S. Meel. Applications are invited from candidates who have solid background in algorithm design/formal methods, mathematics. A prior experience in programming would be a plus.</p>
<p>Website: <a href="https://sites.google.com/view/diptarka/postdoc-advertisement">https://sites.google.com/view/diptarka/postdoc-advertisement</a><br/>
Email: diptarka@comp.nus.edu.sg</p></div>
    </content>
    <updated>2020-06-25T06:10:01Z</updated>
    <published>2020-06-25T06:10:01Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-27T22:47:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020-2/</id>
    <link href="https://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020-2/" rel="alternate" type="text/html"/>
    <title>Postdoc in TCS at National University of Singapore (apply by August 15, 2020)</title>
    <summary>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics. Website: https://sites.google.com/view/diptarka/postdoc-advertisement Email: diptarka@comp.nus.edu.sg</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics.</p>
<p>Website: <a href="https://sites.google.com/view/diptarka/postdoc-advertisement">https://sites.google.com/view/diptarka/postdoc-advertisement</a><br/>
Email: diptarka@comp.nus.edu.sg</p></div>
    </content>
    <updated>2020-06-25T06:05:34Z</updated>
    <published>2020-06-25T06:05:34Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-27T22:47:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc in TCS at National University of Singapore (apply by August 15, 2020)</title>
    <summary>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics. Website: https://sites.google.com/view/diptarka/postdoc-advertisement Email: diptarka@comp.nus.edu.sg</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics.</p>
<p>Website: <a href="https://sites.google.com/view/diptarka/postdoc-advertisement">https://sites.google.com/view/diptarka/postdoc-advertisement</a><br/>
Email: diptarka@comp.nus.edu.sg</p></div>
    </content>
    <updated>2020-06-25T06:05:03Z</updated>
    <published>2020-06-25T06:05:03Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-27T22:47:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/</id>
    <link href="https://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/" rel="alternate" type="text/html"/>
    <title>IDEAL Workshop on Computational vs Statistical Tradeoffs in Network Inference</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">June 29, 2020 Virtual https://www.ideal.northwestern.edu/events/workshop-computational-vs-statistical-tradeoffs-in-network-inference/ Network models have been used as a tool to understand the role of interconnections between entities in multiple research areas like sociology, biology, meteorology, economics, and computer science. Moreover emerging technological developments allow collecting data on increasingly larger networks. This leads to both computational and statistical challenges when inferring or … <a class="more-link" href="https://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/">Continue reading <span class="screen-reader-text">IDEAL Workshop on Computational vs Statistical Tradeoffs in Network Inference</span></a></div>
    </summary>
    <updated>2020-06-24T23:53:00Z</updated>
    <published>2020-06-24T23:53:00Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-06-27T22:47:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/096</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/096" rel="alternate" type="text/html"/>
    <title>TR20-096 |  On the asymptotic complexity of sorting | 

	Igor Sergeev</title>
    <summary>We investigate the number of pairwise comparisons sufficient to sort $n$ elements chosen from a linearly ordered set. This number is shown to be $\log_2(n!) + o(n)$ thus improving over the previously known upper bounds of the form $\log_2(n!) + \Theta(n)$. The new bound is achieved by the proposed group insertion sorting algorithm.</summary>
    <updated>2020-06-24T17:41:11Z</updated>
    <published>2020-06-24T17:41:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-27T22:46:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/095</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/095" rel="alternate" type="text/html"/>
    <title>TR20-095 |  On Basing Auxiliary-Input Cryptography on NP-hardness via Nonadaptive Black-Box Reductions | 

	Mikito Nanashima</title>
    <summary>A black-box (BB) reduction is a central proof technique in theoretical computer science. However, the limitations on BB reductions have been revealed for several decades, and the series of previous work gives strong evidence that we should avoid a nonadaptive BB reduction to base cryptography on NP-hardness (e.g., Akavia et al., 2006). Then should we also give up such a familiar proof technique even for an intermediate step towards cryptography?

In this paper, we continue to explore the capability of nonadaptive BB reductions and extend our knowledge on such a central technique out of the current (worst-to-average) framework. In particular, we investigate the attempt to base weaker cryptographic notions allowed to take auxiliary-input via nonadaptive BB reductions. As a result, we prove the following theorems: (1) if we base an auxiliary-input pseudorandom generator (AIPRG) on NP-hardness via a nonadaptive BB reduction, then the polynomial hierarchy collapses; (2) if we base an auxiliary-input one-way function (AIOWF) or auxiliary-input hitting set generator (AIHSG) on NP-hardness via a nonadaptive BB reduction, then an (i.o.-)one-way function also exists based on NP-hardness (via an adaptive BB reduction).

The first result gives new evidence that nonadaptive BB reductions are insufficient to base AIPRG. The second result also yields a weaker but still surprising consequence of nonadaptive BB reductions, that is, a one-way function based on NP-hardness. In fact, the second result is interpreted as the following two opposite ways. Pessimistically, it shows that basing AIOWF or AIHSG via nonadaptive BB reductions is harder than constructing a one-way function based on NP-hardness, which can be regarded as a negative result. Note that AIHSG is a weak primitive implied even by the hardness of learning; thus, this pessimistic view gives conceptually stronger limitations than the currently known limitations on nonadaptive BB reductions. Optimistically, our result gives a new hope: a breakthrough construction of auxiliary-input primitives might also be useful to construct standard cryptographic primitives. This optimistic view enhances the significance of further investigation on constructing auxiliary-input or other intermediate cryptographic primitives instead of standard cryptographic primitives.</summary>
    <updated>2020-06-24T16:44:42Z</updated>
    <published>2020-06-24T16:44:42Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-27T22:46:41Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2020/06/24/equilibrium-min-max/</id>
    <link href="http://offconvex.github.io/2020/06/24/equilibrium-min-max/" rel="alternate" type="text/html"/>
    <title>An equilibrium in nonconvex-nonconcave min-max optimization</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>While there has been incredible progress in convex and nonconvex minimization, a multitude of problems in ML today are in need of efficient algorithms to solve min-max optimization problems. 
 Unlike minimization, where algorithms can always be shown to converge to some local minimum, there is no notion of a local equilibrium in min-max optimization that exists for general nonconvex-nonconcave functions.
    In two recent papers, we give  two notions of local equilibria that are guaranteed to exist and efficient algorithms to compute them.
In this post we present the key ideas behind a second-order notion of local min-max equilibrium from <a href="https://arxiv.org/abs/2006.12363">this paper</a> and in the next we will talk about a different notion along with the algorithm and show its implications to GANs from <a href="https://arxiv.org/abs/2006.12376">this paper</a>.</p>

<h2 id="min-max-optimization">Min-max optimization</h2>

<p>Min-max optimization of an objective function $f:\mathbb{R}^d \times \mathbb{R}^d \rightarrow \mathbb{R}$</p>



<p>is a powerful framework in optimization, economics, and ML as it allows one to model learning in the presence of multiple agents with competing objectives.
In ML applications, such as <a href="https://arxiv.org/abs/1406.2661">GANs</a> and <a href="https://adversarial-ml-tutorial.org">adversarial robustness</a>, the min-max objective function may be nonconvex-nonconcave.
We know that min-max optimization is at least as hard as minimization, hence, we cannot hope to find a globally optimal solution to min-max problems for general functions.</p>

<h2 id="approximate-local-minima-for-minimization">Approximate local minima for minimization</h2>

<p>Let us first revisit the special case of minimization, where there is a natural notion of an approximate second-order local minimum.</p>

<blockquote>
  <p>$x$ is a second-order $\varepsilon$-local minimum of $\mathcal{L}:\mathbb{R}^d\rightarrow \mathbb{R}$ if
</p>
</blockquote>

<p>Now suppose we just wanted to minimize a function $\mathcal{L}$, and we start from any point which is <em>not</em> at an $\varepsilon$-local minimum of $\mathcal{L}$.
Then we can always find a direction to travel in along which either $\mathcal{L}$ decreases rapidly, or the second derivative of $\mathcal{L}$ is large.
 By searching in such a direction we can easily find a new point which has a smaller value of $\mathcal{L}$ using only local information about the gradient and Hessian of $\mathcal{L}$.
 This means that we can keep decreasing $\mathcal{L}$ until we reach an $\varepsilon$-local minimum (see <a href="https://www.researchgate.net/profile/Boris_Polyak2/publication/220589612_Cubic_regularization_of_Newton_method_and_its_global_performance/links/09e4150dd2f0320879000000/Cubic-regularization-of-Newton-method-and-its-global-performance.pdf">Nesterov and Polyak</a>,  <a href="https://dl.acm.org/doi/10.1145/3055399.3055464">here</a>,  <a href="http://proceedings.mlr.press/v40/Ge15.pdf">here</a>,  and also an earlier <a href="https://www.offconvex.org/2016/03/22/saddlepoints">blog post</a> for how to do this with only access to gradients of $\mathcal{L}$).
 If $\mathcal{L}$ is Lipschitz smooth and bounded, we will reach an $\varepsilon$-local minimum in polynomial time from any starting point.</p>

<blockquote>
  <p>Is there an analogous definition with similar properties for min-max optimization?</p>
</blockquote>

<h2 id="problems-with-current-local-optimality-notions">Problems with current local optimality notions</h2>
<p>There has been much recent work on extending theoretical results in nonconvex minimization to min-max optimization (see <a href="https://arxiv.org/abs/1906.00331">here</a>, <a href="https://papers.nips.cc/paper/9430-efficient-algorithms-for-smooth-minimax-optimization">here</a>, <a href="https://arxiv.org/pdf/1807.02629.pdf">here</a>,  <a href="https://papers.nips.cc/paper/9631-solving-a-class-of-non-convex-min-max-games-using-iterative-first-order-methods.pdf">here</a>, <a href="https://arxiv.org/abs/1910.07512">here</a>.
One way to extend the notion of local minimum to the min-max setting is to seek a solution point called a “local saddle”–a point $(x,y)$ where 1) $y$ is a local maximum for $f(x, \cdot)$ and 2) $x$ is a local minimum for $f(\cdot, y).$</p>

<p>For instance,
 this is used  <a href="https://arxiv.org/abs/1706.08500">here</a>, <a href="https://arxiv.org/pdf/1901.00838.pdf">here</a>, <a href="https://arxiv.org/pdf/1705.10461.pdf">here</a>, and <a href="http://proceedings.mlr.press/v89/adolphs19a.html">here</a>.
But, there are very simple examples of two-dimensional bounded functions where a local saddle does not exist.</p>

<blockquote>
  <p>For instance, consider $f(x,y) = sin(x+y)$ from <a href="https://arxiv.org/abs/1902.00618">here</a>. Check that none of the points on this function are simultaneously a local minimum for $x$ and local maximum for $y$.</p>
</blockquote>

<p>The fact that no local saddle exists may be surprising, since an $\varepsilon$-global solution to a min-max optimization problem <em>is</em> guaranteed to exist as long as the objective function is uniformly bounded.
Roughly, this is because, in a global min-max setting, the max-player is empowered to globally maximize the function $f(x,\cdot)$, and the min-player is empowered to minimize the “global max” function $\max_y(f(x, \cdot))$.</p>

<p>The ability to compute the global max  allows the min-player to  predict the max-player’s response.
If $x$ is a global minimum of $\max_y(f(x, \cdot))$, the min-player is aware of this fact and will have no incentive to update $x$.
On the other hand, if the min-player can only simulate the max-player’s updates locally (as in local saddle),
then the min-player may try to update her strategy even when it leads to a net increase in $f$.
This can happen because the min-player is not powerful enough to accurately simulate the max-player’s response. (See  a  <a href="https://arxiv.org/abs/1902.00618">related notion</a> of local optimality with similar issues due to vanishingly small updates.)</p>

<p>The fact that players who can only make local predictions are
unable to predict their opponents’ responses can lead to convergence problems in many popular algorithms such as<br/>
gradient descent ascent (GDA). This non-convergence behavior can occur if the function has no local saddle point (e.g. the function $sin(x+y)$  mentioned above), and can even happen on some functions, like $f(x,y) = xy$ which do have a local saddle point.</p>

<div style="text-align: center;">
<img alt="" src="http://www.offconvex.org/assets/GDA_spiral_fast.gif"/>
<br/>
<b>Figure 1.</b> GDA spirals off to infinity from almost every starting point on the objective function $f(x,y) = xy$. 
</div>
<p><br/></p>

<h2 id="greedy-max-a-computationally-tractable-alternative-to-global-max">Greedy max: a computationally tractable alternative to global max</h2>

<p>To allow for a more stable min-player, and a more stable notion of local optimality, we would like to empower the min-player to more effectively simulate the max-player’s response. 
While the notion of global min-max does exactly this by having the min-player compute the global max function $\max_y(f(\cdot,y))$, computing the global maximum may be intractable.</p>

<p>Instead, we replace the global max function $\max_y (f(\cdot ,y))$ with a computationally tractable alternative. 
Towards this end, we restrict the max-player’s response, and the min-player’s simulation of this response, to updates which can be computed using any algorithm from a class of second-order optimization algorithms.
More specifically, we restrict the max-player to updating $y$ by traveling along continuous paths which start at the current value of $y$ and along which either $f$ is increasing or the second derivative of $f$ is positive.  We refer to such paths as greedy paths since they model a class of second-order “greedy” optimization algorithms.</p>

<blockquote>
  <p><strong>Greedy path:</strong> A unit-speed path $\varphi:[0,\tau] \rightarrow \mathbb{R}^d$ is greedy if $f$ is non-decreasing over this path, and for every $t\in[0,\tau]$
</p>
</blockquote>

<p>Roughly speaking, when restricted to updates obtained from greedy paths, the max-player will always be able to reach a point which is an approximate local maximum for $f(x,\cdot)$, although there may not be a greedy path which leads the max-player to a global maximum.</p>

<div style="text-align: center;">
<img alt="" src="http://www.offconvex.org/assets/greedy_region_omega_t.png" style="width: 400px;"/> <img alt="" src="http://www.offconvex.org/assets/global_max_path_no_axes_t.png" style="width: 400px;"/> 
<br/>
 <b>Figure 2.</b> <i>Left:</i> The light-colored region $\Omega$ is reachable from the initial point $A$ by a greedy path; the dark region is not reachable. <i>Right:</i> There is always a greedy path from any point $A$ to a local maximum ($B$), but a global maximum ($C$) may not be reachable by any greedy path.
</div>
<p><br/></p>

<p>To define an alternative to $\max_y(f(\cdot,y))$, we consider the local maximum point with the largest value of $f(x,\cdot)$ attainable from a given starting point $y$ by any greedy path.
We refer to the value of $f$ at this point as the <em>greedy max function</em>, and denote this value by $g(x,y)$.</p>

<blockquote>
  <p><strong>Greedy max function:</strong> 
    $g(x,y) = \max_{z \in \Omega} f(x,z),$
where $\Omega$ is points reachable from $y$ by greedy path.</p>
</blockquote>

<h2 id="our-greedy-min-max-equilibrium">Our greedy min-max equilibrium</h2>
<p>We use the greedy max function to define a new second-order notion of local optimality for min-max optimization, which we refer to as a greedy min-max equilibrium.
Roughly speaking, we say that $(x,y)$ is a greedy min-max equilibrium if 
1) $y$ is a local maximum for $f(x,\cdot)$ (and hence the endpoint of a greedy path), and 
2) if $x$ is a local minimum of the greedy max function $g(\cdot,y)$.</p>

<p>In other words, $x$ is a local minimum of $\max_y f(\cdot, y)$ under the constraint that the maximum is computed only over the set of greedy paths starting at $y$.
Unfortunately, even if $f$ is smooth, the greedy max function may not be differentiable with respect to $x$ and may even be discontinuous.</p>

<div style="text-align: center;">
<img alt="" src="http://www.offconvex.org/assets/discontinuity2_grid_t.png" width="400"/> <img alt="" src="http://www.offconvex.org/assets/discontinuity2g_grid_t.png" width="400"/> 
<br/>
 <b>Figure 3.</b> <i>Left:</i> If we change $x$ from one value $x$ to a very close value $\hat{x}$, the largest value of $f$ reachable by greedy path undergoes a discontinuous change.  <i>Right:</i>  This means the greedy max function $g(x,y)$ is discontinuous in $x$.</div>
<p><br/></p>

<p>This creates a problem, since the definition of $\varepsilon$-local minimum only applies to smooth functions.</p>

<p>To solve this problem we would ideally like to smooth $g$ by convolution with a Gaussian.
Unfortunately, convolution can cause the local minima of a function to “shift”– a point which is a local minimum for $g$ may no longer be a local minimum for the convolved version of $g$ (to see why, try convolving the function $f(x) = x - 3x I(x\leq 0) + I(x \leq 0)$ with a Gaussian $N(0,\sigma^2)$ for any $\sigma&gt;0$).
To avoid this, we instead consider a “truncated” version of $g$, and then convolve this function in the $x$ variable with a Gaussian to obtain our smoothed version of $g$.</p>

<p>This allows us to define a notion of greedy min-max equilibrium.  We say that a point $(x^\star, y^\star)$ is a greedy min-max equilibrium if $y^\star$ is an approximate local maximum of $f(x^\star, \cdot)$, and $x^\star$ is an $\varepsilon$-local minimum of this smoothed version of $g(\cdot, y^\star)$.</p>

<blockquote>
  <p><b>Greedy min-max equilibrium:</b>
$(x^{\star}, y^{\star})$ is a greedy min-max equilibrium if

 
where $S(x,y):= \mathrm{smooth}_x(\mathrm{truncate}(g(x, y))$.</p>
</blockquote>

<p>Any point which is a local saddle point (talked about earlier) also satisifeis our equilibrium conditions. The converse, however, cannot be true as a local saddle point may not always exist. Further, for compactly supported convex-concave functions a point is a greedy min-max equilibrium (in an appropriate sense) if and only if it is a global min-max point. (See Section 7 and Appendix A respectively in <a href="https://arxiv.org/abs/2006.12363">our paper</a>.)</p>

<h2 id="greedy-min-max-equilibria-always-exist-and-can-be-found-efficiently">Greedy min-max equilibria always exist! (And can be found efficiently)</h2>
<p>In <a href="https://arxiv.org/abs/2006.12363">this paper</a> we show: A greedy min-max equilibrium is always guaranteed to exist provided that $f$ is uniformly bounded with Lipschitz Hessian. We do so by providing an algorithm which converges to a greedy min-max equilibrium, and, moreover, we show that it is able to do this in polynomial time from any initial point:</p>

<blockquote>
  <p><b>Main theorem:</b> Suppose that we are given access to a smooth function $f:\mathbb{R}^d \times \mathbb{R}^d \rightarrow \mathbb{R}$ and to its gradient and Hessian.  And suppose that $f$ is unformly bounded by $b&gt;0$ and has $L$-Lipschitz Hessian.
Then given any initial point, our algorithm returns an $\varepsilon$-greedy min-max equilibrium $(x^\star,y^\star)$ of $f$ in $\mathrm{poly}(b, L, d, \frac{1}{\varepsilon})$ time.</p>
</blockquote>

<p>There are a number of difficulties that our algorithm and proof must overcome:
One difficulty in designing an algorithm is that the greedy max function may be discontinuous. 
To find an approximate local minimum of a discontinuous function, our algorithm combines a Monte-Carlo hill climbing algorithm with a <a href="https://arxiv.org/abs/cs/0408007">zeroth-order optimization version</a> of stochastic gradient descent.
Another difficulty is that, while one can easily compute a greedy path from any starting point, there may be many different greedy paths which end up at different local maxima.
Searching for the greedy path which leads to the local maximum point with the largest value of $f$ may be infeasible.
In other words the greedy max function $g$ may be intractable to compute.</p>

<div style="text-align: center;">
<img alt="" src="http://www.offconvex.org/assets/greedy_paths_no_axes_t.png" width="400"/> 
<br/>
 <b>Figure 4.</b>There are many different greedy paths that start at the same point $A$.  They can end up at different local maxima ($B$, $D$), with different values of $f$.  In many cases it may be intractable to search over all these paths to compute the greedy max function.
 </div>
<p><br/></p>

<p>To get around this problem, rather than computing the exact value of $g(x,y)$, we instead compute a lower bound $h(x,y)$ for the greedy max function. Since we are able to obtain this lower bound by computing only a <em>single</em> greedy path, it is much easier to compute than greedy max function.</p>

<p>In our paper, we prove that if 1) $x^\star$ is an approximate local minimum for the this lower bound $h(\cdot, y^\star)$, and  2) $y^\star$ is a an approximate local maximum for $f(x^\star, \cdot)$, then $x^\star$ is also an approximate local minimum for the greedy max $g(\cdot, y^\star)$.
This allows us to design an algorithm which obtains a greedy min-max point by minimizing the computationally tractable lower bound $h$, instead of the greedy max function which may be intractable to compute.</p>

<h2 id="to-conclude">To conclude</h2>

<p>In this post we have shown how to extend a notion of second-order equilibrium for minimization to min-max optimization which is guaranteed to exist for any function which is bounded and Lipschitz, with Lipschitz gradient and Hessian.
We have also shown that our algorithm is able to find this equilibrium in  polynomial time from any initial point.</p>

<blockquote>
  <p>Our results do not require any additional assumptions such as convexity, monotonicity, or sufficient bilinearity.</p>
</blockquote>

<p>In an upcoming blog post we will show how one can use some of the ideas from here to obtain a new min-max optimization algorithm with applications to stably training GANs.</p></div>
    </summary>
    <updated>2020-06-24T10:00:00Z</updated>
    <published>2020-06-24T10:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2020-06-27T22:47:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/094</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/094" rel="alternate" type="text/html"/>
    <title>TR20-094 |  Is it possible to improve Yao’s XOR lemma using reductions that exploit the efficiency of their oracle? | 

	Ronen Shaltiel</title>
    <summary>Yao's XOR lemma states that for every function $f:\set{0,1}^k \ar \set{0,1}$, if $f$ has hardness $2/3$ for $P/poly$ (meaning that for every circuit $C$ in $P/poly$, $\Pr[C(X)=f(X)] \le 2/3$ on a uniform input $X$), then the task of computing $f(X_1) \oplus \ldots \oplus f(X_t)$ for sufficiently large $t$ has hardness $\half +\epsilon$ for $P/poly$.

Known proofs of this lemma cannot achieve $\epsilon=\frac{1}{k^{\omega(1)}}$, and even for $\epsilon=\frac{1}{k}$, we do not know how to replace
$P/poly$ by AC$^0[\textsc{parity}]$ (the class of constant depth circuits with the gates $\set{\textsc{and,or,not,parity}}$ of unbounded fan-in).

Recently, Grinberg, Shaltiel and Viola (FOCS 2018) (building on a sequence of earlier works) showed that these limitations cannot be circumvented by \emph{black-box reductions}. Namely, by reductions $\Red^{(\cdot)}$ that given oracle access to a function $D$ that violates the conclusion of Yao's XOR lemma, implement a circuit that violates the assumption of Yao's XOR lemma.

There are a few known reductions in the related literature on worst-case to average case reductions that are \emph{non-black box}. Specifically, the reductions of Gutfreund, Shaltiel and Ta Shma (Computational Complexity 2007) and  Hirahara (FOCS 2018)) are ``class reductions'' that are only guaranteed to succeed when given oracle access to an oracle $D$ from some efficient class of algorithms. These works seem to circumvent some black-box impossibility results.

In this paper we extend the previous limitations of Grinberg, Shaltiel and Viola to class reductions, giving evidence that class reductions cannot yield the desired improvements in Yao's XOR lemma.  To the best of our knowledge, this is the first limitation on reductions for hardness amplification that applies to class reductions.

Our technique imitates the previous lower bounds for black-box reductions, replacing the inefficient oracle used in that proof, with an efficient one that is based on limited independence, and developing tools to deal with the technical difficulties that arise following this replacement.</summary>
    <updated>2020-06-24T05:25:21Z</updated>
    <published>2020-06-24T05:25:21Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-27T22:46:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/093</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/093" rel="alternate" type="text/html"/>
    <title>TR20-093 |  Reduction From Non-Unique Games To Boolean Unique Games | 

	Dana Moshkovitz, 

	Ronen Eldan</title>
    <summary>We reduce the problem of proving a "Boolean Unique Games Conjecture" (with gap $1-\delta$ vs. $1-C\delta$, for any $C&gt; 1$, and sufficiently small $\delta&gt;0$) to the problem of proving a PCP Theorem for a certain non-unique game.
In a previous work, Khot and Moshkovitz suggested an inefficient candidate reduction (i.e., without a proof of soundness). 
The current work is the first to provide an efficient reduction along with a proof of soundness. 
The non-unique game we reduce from is similar to non-unique games for which PCP theorems are known.
Our proof relies on a new concentration theorem for functions in Gaussian space that are restricted to a random hyperplane. We bound the typical Euclidean distance between the low degree part of the restriction of the function to the hyperplane and the restriction to the hyperplane of the low degree part of the function.</summary>
    <updated>2020-06-23T14:41:45Z</updated>
    <published>2020-06-23T14:41:45Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-27T22:46:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/22/postdoc-at-technion-israel-institute-of-technology-apply-by-august-1-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/22/postdoc-at-technion-israel-institute-of-technology-apply-by-august-1-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at Technion Israel Institute of Technology (apply by August 1, 2020)</title>
    <summary>Looking for excellent CS theory graduates for a postdoctoral position at the Computer Science Faculty of Technion Israel Institute of Technology, in Prof. Nir Ailon’s group. Research topics include theory of learning, optimization, information theory and their intersection. Website: https://nailon.net.technion.ac.il/ Email: mayasidis@cs.technion.ac.il</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Looking for excellent CS theory graduates for a postdoctoral position at the Computer Science Faculty of Technion Israel Institute of Technology, in Prof. Nir Ailon’s group. Research topics include theory of learning, optimization, information theory and their intersection.</p>
<p>Website: <a href="https://nailon.net.technion.ac.il/">https://nailon.net.technion.ac.il/</a><br/>
Email: mayasidis@cs.technion.ac.il</p></div>
    </content>
    <updated>2020-06-22T08:35:15Z</updated>
    <published>2020-06-22T08:35:15Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-27T22:47:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1791</id>
    <link href="https://theorydish.blog/2020/06/21/free-registeration-to-tcs-women-rising-star-talks/" rel="alternate" type="text/html"/>
    <title>(Free) Registeration to TCS Women Rising Star talks</title>
    <summary>TCS Women Rising Star talks are happening as part of TCS Women STOC Spotlight Workshop. Seven Rising Star speakers are lined up, all of whom are planning to be on the job market this year. In addition, Shafi Goldwasser will give a longer talk. Everybody is invited, but (free) registration is required. (Attendees don’t even have to pay the STOC registration fee.) More information is on the website:https://sigact.org/tcswomen/.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>TCS Women Rising Star talks are happening as part of TCS Women STOC Spotlight Workshop. Seven Rising Star speakers are lined up, all of whom are planning to be <em><strong>on the job market this year</strong></em>. In addition, Shafi Goldwasser will give a longer talk. Everybody is invited, but (free) registration is required. (Attendees don’t even have to pay the STOC registration fee.) More information is on the website:<br/><a href="https://sigact.org/tcswomen/" rel="noreferrer noopener" target="_blank">https://sigact.org/tcswomen/</a>. </p></div>
    </content>
    <updated>2020-06-22T04:16:26Z</updated>
    <published>2020-06-22T04:16:26Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-06-27T22:48:02Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2020/06/22/virtual-conferences/</id>
    <link href="http://benjamin-recht.github.io/2020/06/22/virtual-conferences/" rel="alternate" type="text/html"/>
    <title>The Uncanny Valley of Virtual Conferences</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We wrapped up two amazing days of <a href="http://www.l4dc.org/">L4DC 2020</a> last Friday. It’s pretty wild to watch this community grow so quickly: starting as a <a href="https://kgatsis.github.io/learning_for_control_workshop_CDC2018/">workshop</a> at <a href="https://kgatsis.github.io/learning_for_control_workshop_CDC2018/">CDC 2018</a>, the conference organizers put together an <a href="https://l4dc.mit.edu/">inaugural event at MIT</a> in only a few months and were overwhelmed by nearly 400 attendees. Based on a groundswell of support from the participants, we decided to add contributed talks and papers this year. We had passionate volunteers for our <a href="https://sites.google.com/berkeley.edu/l4dc/organizers-pc">70-person program committee</a>, and they did heroic work of reviewing 135 submissions for this year’s program.</p>

<p>Then, of course, the pandemic hit forcing us to cancel our in-person event. As most conferences in a similar situation as ours, we decided to move to a virtual setting. I think that had we not had contributed papers, we would have simply canceled this year (I’ll return to this later). But to respect the passion and hard-work of our contributors, we tried to come up with a reasonable plan for running this conference virtually.</p>

<p>When we started planning to go virtual, there were too many options to sort through: Zoom webinars and breakout rooms? Sli.do Q&amp;As? Google Hangouts? Slack channels? We had so many tools for virtual community building, each with their own pluses and minuses. Our main constraints were that we wanted to highlight the best contributed papers as talks in some way, to give visibility to the wonderful set of accepted papers without burdening the authors with more work, to be inclusive to the broader community of folks interested in learning and automation, and, importantly, to not charge registration fees.</p>

<p>We eventually settled on the following scheme:</p>
<ol>
  <li>We had a Zoom room for invited and contributed speakers and moderators.</li>
  <li>This Zoom was <a href="https://www.youtube.com/watch?v=b_sJb1k9dVY">live streamed to Youtube</a>.</li>
  <li>Questions were gathered by grad student moderators who scanned the YouTube live chat and then relayed inquiries back to the speakers.</li>
  <li>We tried to keep the live part under four hours per day and to provide ample breaks. We recognize how hard it is to sit in front of a live stream for much more than that.</li>
  <li>Further discussion was then done on <a href="https://openreview.net/group?id=L4DC.org/2020/Conference">OpenReview</a>, where we hosted all accepted papers of the conference.</li>
  <li>The proceedings of the conference were subsequently archived by <a href="http://proceedings.mlr.press/">Proceedings of Machine Learning Research</a>.</li>
</ol>

<p>Though it took a lot of work to tie all these pieces together, everything went super smoothly in the end. I was basically able to run the entire AV setup from my garage.</p>

<p class="center"><img alt="where the magic happens" src="http://www.argmin.net/assets/command_station.jpg" width="250px"/></p>

<p>The only thing that cost money here was the Zoom account (20 dollars/month, though subsidized by Berkeley) and my home internet connection. I know that Zoom and YouTube have well documented issues, and I think it’s imperative that they continue to strive to fix these problems, but I also think it’s easy to forget how empowering this technology is. This format opens up conferences to those who can’t travel for financial or logistical reasons, and lowers the energy to engage with cutting edge research. Being able to sit in my garage and run a virtual conference with speakers spanning 10 time zones and nearly 2000 viewers is a wonder of modern times.</p>

<h2 id="second-life-still-has-a-long-way-to-go">Second Life still has a long way to go.</h2>

<p>There are still many parts of the online conference that felt cheated and incomplete. I still don’t know how to run a virtual poster session effectively. Most of our papers have not yet received any comments on <a href="https://openreview.net/group?id=L4DC.org/2020/Conference">OpenReview</a>, though comments are still open and I’d encourage you to drop by and ask questions! Partially, I think this lack of engagement stems from the considerable amount of effort required to participate, especially when it is compared to somewhat aimlessly ambling through a poster session.</p>

<p>Indeed, many aspects of live conferences are simply not replicable with our current tools, whether they be chance encounters or meetings with friends from far away. On the other hand, maybe we shouldn’t try to replicate this experience! Maybe we need to think harder about what opportunities our technology has for building communities and how we can better support these facets of academic interaction. When I think back on the decades of conferences I’ve attended, I can think of only a few posters that really got me interested in reading a paper, and <a href="https://papers.nips.cc/paper/3323-the-tradeoffs-of-large-scale-learning.pdf">one later won a test of time award at NeurIPS</a>. Poster sessions always felt like an anachronistic means to justify a work travel expense rather than an effective means of academic knowledge dissemination. Is there a better way forward that uses our current technological constraints to amplify the voices of young scholars with cutting edge ideas? I don’t have great ideas for how to do this yet, but new interaction structures may emerge as we deal with at least one more year without meetings with hundreds of people.</p>

<h2 id="how-much-should-conferences-cost">How much should conferences cost?</h2>

<p>We were able to do L4DC, with the proceedings and all, for free. Obviously, the program committee put in tons of work in reviewing and organizing the logistics. But reviewing labor isn’t compensated by any conference. All peer reviewed conferences rely on the volunteer service labor of a dedicated program committee. The main line items we expected for L4DC were for renting physical space, paying an AV crew, and food. But in the virtual world, these expenses drop to near zero.</p>

<p>I’m supposed to give a plenary talk at the <a href="https://www.ifac2020.org/">Virtual IFAC Congress</a> in July. I have to say, I am troubled: IFAC is charging <a href="https://www.ifac2020.org/registration/">380 euros per person</a> for registration. What does one get for this sum? Access to video streams and the ability to publish papers. This seems exorbitantly expensive. Why would anyone watch a talk I give at IFAC when I promise to just release it on YouTube at the same time? What value is IFAC providing back to the academic community?</p>

<h2 id="decoupling-papers-from-talks">Decoupling papers from talks</h2>

<p>One of the main things the registration fee at many conferences provides is a stamp of academic approval. It is a de facto publication fee. Led by computer science, conferences in engineering are replacing journals as the archives where CV-building work is cataloged. Though this wasn’t the initial purpose of conferences in computer science, conferences do have many attractive features over journals for rapidly evolving fields: Conferences have speedy turn-around times and clearly delineated submission and decision dates. This archival aspect of conferences, however, has nothing to do with community building or scholarly dissemination. Why do we need to couple a talk to a publication? Can’t we separate these two as is done in every other academic field?</p>

<p>Our collective pandemic moment gives us an opportunity not only to rethink community-building but also our publication model. With 10000-person mega-conferences like <a href="http://icml.cc">AI Summer</a> and <a href="http://neurips.cc">AI Winter</a>, why can’t we keep all of the deadlines the same but remove all of the talks? We’d still have the same reviewing architecture, which has been wholly virtual for over a decade. And we could still publish all of the proceedings online for free, which has been done for multiple decades.</p>

<p>The decoupling proposal here would have effectively zero overhead on our communities: the deadlines, CMTs, program committees, and proceedings could all function exactly the same way (though, to be fair, these systems all have warts worth improving upon). New archival, fast-turnaround journals could easily start using the same tools. Indeed, I’ve always been enamored with the idea of an arxiv-overlay journal that simply is a table of contents that points towards particular versions of arxiv papers as “accepted.” And a really radical idea would be to solicit <em>talks</em>—not papers—for virtual conferences where potential speakers would submit slides or videos to demonstrate proficiency in the medium in which they’d present.</p>

<p>I tend to dismiss most of the bloviation about how coronavirus permanently changes everything about how we live our lives. But it does provide us an opportunity to pause and assess whether current systems are functioning well. I’d argue that the current conference system hasn’t been functioning well for a while, but this simple decoupling of papers and talks might clear up a lot of the issues currently facing the hard-charging computing world.</p>

<p><em>Many thanks to my dedicated, passionate L4DC Co-organizers: Alex Bayen, Ali Jadbababie, George Pappas, Pablo Parrilo, Claire Tomlin, and Melanie Zeilinger. I’d also like to thank Rediet Abebe, Jordan Ellenberg, Eric Jonas, Angjoo Kanazawa, Adam Klivans, Nik Matni, Chris Re, and Tom Ristenpart for their helpful feedback on this post.</em></p></div>
    </summary>
    <updated>2020-06-22T00:00:00Z</updated>
    <published>2020-06-22T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2020-06-27T22:48:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17214</id>
    <link href="https://rjlipton.wordpress.com/2020/06/21/some-real-and-some-virtual-news/" rel="alternate" type="text/html"/>
    <title>Some Real and Some Virtual News</title>
    <summary>Gossip and more. Composite of , src1, src3 Jessica Deters, Izabel Aguiar, and Jacqueline Feuerborn are the authors of the paper, “The Mathematics of Gossip.” They use infection models—specifically the Susceptible-Infected-Recovered (SIR) model—to discuss gossip. Their work was done before the present pandemic, in 2017–2019. It is also described in a nice profile of Aguiar. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Gossip and more.</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/06/detersaguiarfeuerborn-1.png"><img alt="" class="alignright size-full wp-image-17221" src="https://rjlipton.files.wordpress.com/2020/06/detersaguiarfeuerborn-1.png?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite of <a href="https://jessicadeters.wordpress.com/">, </a><a href="https://izabelpaguiar.com/about/">src1</a>, <a href="https://www.linkedin.com/in/jacqueline-feuerborn-87b7b3106/">src3</a></font></td>
</tr>
</tbody>
</table>
<p>
Jessica Deters, Izabel Aguiar, and Jacqueline Feuerborn are the authors of the <a href="https://scholarship.claremont.edu/cgi/viewcontent.cgi?article=1036&amp;context=codee">paper</a>, “The Mathematics of Gossip.” They use infection models—specifically the Susceptible-Infected-Recovered (<a href="https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology#The_SIR_model">SIR</a>) model—to discuss gossip. Their work was done <em>before</em> the present pandemic, in 2017–2019.  It is also described in a nice <a href="https://sciencebuffs.org/2018/05/14/to-gossip-is-human-to-math-divine/">profile</a> of Aguiar. Their analogy is expressed by a drawing in their paper: </p>
<p><a href="https://rjlipton.files.wordpress.com/2020/06/gossipcough.jpg"><img alt="" class="aligncenter wp-image-17218" height="125" src="https://rjlipton.files.wordpress.com/2020/06/gossipcough.jpg?w=400&amp;h=125" width="400"/></a></p>
<p/><p><br/>
Not just for today, but for the summer at least, Ken and I want to share some gossip, share some problems, and ask our readers a question.</p>
<p>
The question first. Ken and I wonder if GLL should start a virtual theory “lunch” meeting, that would meet periodically via Zoom. It would be like meeting for a theory lunch in the old days—just not all in the same room. Some topic might be agreed on, perhaps a short presentation, and always a chance to swap some gossip. Plus maybe ask the group for advice on a problem.</p>
<p>
I do miss the old meetings: </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/06/meet.png"><img alt="" class="aligncenter size-medium wp-image-17219" height="224" src="https://rjlipton.files.wordpress.com/2020/06/meet.png?w=300&amp;h=224" width="300"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">AcademicKeys #78 <a href="https://www.academickeys.com/all/cartoon.php?dothis=display&amp;cartoon[IDX]=78">source</a></font>
</td>
</tr>
</tbody></table>
<p>
What do you think? Should we have such meetings?</p>
<p>
</p><p/><h2> Some Gossip </h2><p/>
<p/><p>
The study of gossip feeds into other issues of the spread of information and misinformation during an election year. Ken’s Buffalo colleague Kenny Joseph has <a href="https://kennyjoseph.github.io/">research</a> on the spread of fake news and Twitter sentiment using mathematical tools adjacent to those of the trio above. Ken and I still intend to say more about epidemiology models ourselves when we get time. But no, here by “gossip” we just mean actual pieces of gossip—just as at a conference or other kind of in-person meeting.</p>
<p>
Here are two examples of the kind of gossip we might exchange. </p>
<p>
Anna Gilbert is moving from Michigan math to Yale math and statistics. She will be the John C. Malone Professor of Mathematics, Professor of Statistics &amp; Data Science. Pretty impressive. She was at Michigan math for <img alt="{2^{4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{4}}"/> years. She told me that she could not wait for the next power of <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>, and thus had to try a new place, with new challenges. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/06/gilbert-1.png"><img alt="" class="aligncenter wp-image-17233" height="163" src="https://rjlipton.files.wordpress.com/2020/06/gilbert-1.png?w=127&amp;h=163" width="127"/></a></p>
<p>
Rich DeMillo is a long time friend who is at Georgia Institute of Technology and is not moving. He continues working on making voting fair, secure, and efficient. He is referenced in a recent article on voting issues in Georgia. See <a href="https://www.voanews.com/usa/us-politics/activists-cite-tabulation-flaw-georgia-mail-ballots">here</a> for details. </p>
<p>
<a href="https://rjlipton.files.wordpress.com/2020/06/demillo-1.jpg"><img alt="" class="aligncenter wp-image-17234" height="138" src="https://rjlipton.files.wordpress.com/2020/06/demillo-1.jpg?w=149&amp;h=138" width="149"/></a></p>
<p>
Note: we have in mind pleasant and factual gossip. The most useful kind is about probable directions and emphases to make projects attractive to pursue. This leads into our other component.</p>
<p>
</p><p/><h2> Possible Problems To Present </h2><p/>
<p/><p>
Here are a problem from each of us as examples of what could be discussed in these meetings and why that might give advantage over just hunting the literature. Both are about factoring—always factoring…</p>
<p>
</p><p/><h3> Factoring: Ken </h3><p/>
<p/><p>
I, Ken, would like to know about field tests of approximative methods in quantum computing, specifically of shortcuts to Shor’s Algorithm. The approximations I have in mind are rougher than those I find in the literature and need not be physically natural.</p>
<p>
To explain, the way Shor’s algorithm is proven correct in Shor’s paper and all textbooks we know—including ours—uses an exact analysis involving the quantum Fourier transform, in which exponentially fine phase angles appear in terms. Approximation can be argued in several ways. Circuits of Hadamard, CNOT, and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>-gates, in which no phase angle finer than <img alt="{\pi/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi/4}"/> appears, can approximate arbitrary quantum circuits to exponential precision with polynomial overhead. With just Hadamard and Toffoli gates, hence <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> and <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi}"/> as the only phases, one can approximate the data returned by measurements in the algorithm, though without approximating the algorithm’s result vectors in complex Hilbert space. There are other ways to approximate those vectors while eliding the finer phase components. We would like to see more attention to the concrete overheads of all these methods.</p>
<p>
What I would really like to discuss, however, is efforts toward more-brusque approximations that could yield new classical attempts on factoring. For a broad example, note that not only does <img alt="{\mathsf{BQP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BBQP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{BQP}}"/> reduce to <img alt="{\mathsf{\#P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5C%23P%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{\#P}}"/> but also individual steps in Shor’s algorithm can be broken down as reductions to counting. Now suppose we apply approximate counting heuristics to those steps. The stock answer for why this doesn’t work to approximate quantum measurement properties <em>globally</em> is that those probabilities have the form </p>
<p align="center"><img alt="\displaystyle  p = \frac{f_1(x) - f_2(x)}{D} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p+%3D+%5Cfrac%7Bf_1%28x%29+-+f_2%28x%29%7D%7BD%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  p = \frac{f_1(x) - f_2(x)}{D} "/></p>
<p>where <img alt="{f_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_1}"/> and <img alt="{f_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2}"/> are <img alt="{\mathsf{\#P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5C%23P%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{\#P}}"/> functions and <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is something like <img alt="{2^{n/2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{n/2}}"/>. Note the knowledge beforehand that <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> is between <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> and <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. The point is that <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is exponential yet smaller than the additive approximations possible in polynomial time for <img alt="{f_1(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_1(x)}"/> and <img alt="{f_2(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2(x)}"/> individually, so the approximation gives no help to the difference. </p>
<p>
However, this does not prevent using approximations of magnitudes that are not differences at intermediate steps. For a vein of more particular examples, I raise the translation from quantum gates to Boolean formulas in my 2018 <a href="https://link.springer.com/chapter/10.1007/978-3-662-56499-8_4">paper</a> with Amlan Chakrabarti and my recent PhD graduate Chaowen Guan. This translation can encode the state <img alt="{\Phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi}"/> at any intermediate stage of an execution of Shor’s algorithm by a Boolean formula <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/>. The size of <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> stays linear in the size of the quantum circuit being simulated—the exponential explosion happens only when we try to count solutions to <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/>. The formula <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> encodes all the information in <img alt="{\Phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi}"/>, including the implicit presence of fine phase angles. Now suppose we alter <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> to a <img alt="{\phi'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi'}"/> whose corresponding <img alt="{\Phi'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi'}"/> is a simplified approximation of <img alt="{\Phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi}"/>. The kicker is that <img alt="{\Phi'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi'}"/> might not need to be a legal quantum state. The transformations in our paper for later stages of the circuit will still apply building on <img alt="{\phi'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi'}"/>. </p>
<p>
Is there any chance of this working? Heuristic approaches applying SAT to factoring have been tried and found to be <a href="https://toughsat.appspot.com/">tough</a>. The nice site <a href="http://beyondnp.org/">BeyondNP</a> includes <a href="http://beyondnp.org/pages/solvers/model-counters-exact/">links</a> to #SAT counters such as <a href="https://sites.google.com/site/marcthurley/sharpsat">sharpSAT</a> and <a href="https://www.cs.rochester.edu/u/kautz/Cachet/index.htm">Cachet</a>. Thus we are not asking anything outlandish. Leveraging Shor’s algorithm might be a new approach. Has anyone tried it? That’s the kind of question I would visit a conference to ask, where wider arity might work better than asking people individually. Thus also for raising it in a meeting.</p>
<p>
</p><p/><h3> Factoring: Dick </h3><p/>
<p/><p>
I have recently been thinking about the power of weak sub-theories of Peano Arithmetic. There are many proofs known that there are an infinite number of prime numbers. The usual proofs use this:</p>
<blockquote><p><b> </b> <em> For all <img alt="{x&gt;1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%3E1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x&gt;1}"/> there is some prime <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{p}"/> that divides <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x}"/>. </em>
</p></blockquote>
<p>Given this it is not hard to prove, in many ways, that there are an infinite number of primes. Euclid’s original proof uses it in the step: Let <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> divide <img alt="{p_{1}\cdots p_{n} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_%7B1%7D%5Ccdots+p_%7Bn%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_{1}\cdots p_{n} + 1}"/>. The idea is suppose some weak theory can prove the above. This means that it can prove: 	</p>
<p align="center"><img alt="\displaystyle  \forall x&gt;1 \ \exists y \ y|x \text{ and } \mathsf{prime}(y). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+x%3E1+%5C+%5Cexists+y+%5C+y%7Cx+%5Ctext%7B+and+%7D+%5Cmathsf%7Bprime%7D%28y%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \forall x&gt;1 \ \exists y \ y|x \text{ and } \mathsf{prime}(y). "/></p>
<p>	 I believe that this shows that if the theory is weak enough that this implies that factoring is in polynomial time. Is this known? Is it true? </p>
<p>
Once again, we can hunt for literature on this. We can ask individual people, such as Avi Wigderson and various co-authors of his. But our hunch is that this topic was explored in the 1990s without a definitive resolution. It could be more effective to get up to speed on it and share ideas in a meeting.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Should we start a virtual theory lunch? Would you attend?</p>
<p>
<b>Added 6/21:</b> Getting back to gossip, we wonder if the all-to-all nature of a Zoom meeting, versus few-to-few in a conference hallway, would filter out the badder kinds of gossip.</p></font></font></div>
    </content>
    <updated>2020-06-21T15:17:56Z</updated>
    <published>2020-06-21T15:17:56Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Factoring"/>
    <category term="Gossip"/>
    <category term="infection models"/>
    <category term="Izabel Aguiar"/>
    <category term="Jacqueline Feuerborn"/>
    <category term="Jessica Deters"/>
    <category term="Logic"/>
    <category term="meetings"/>
    <category term="quantum"/>
    <category term="Shor's algorithm"/>
    <category term="videoconferencing"/>
    <category term="witness functions"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-06-27T22:47:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7753</id>
    <link href="https://windowsontheory.org/2020/06/19/stoc-2020-information-guest-post-by-madhur-tulsiani/" rel="alternate" type="text/html"/>
    <title>STOC 2020 information (guest post by Madhur Tulsiani)</title>
    <summary>Dear fellow theorists, As you already know, STOC 2020 this year will be a virtual conference. If you are interested in attending the conference, but haven’t registered yet, please do so soon (students: $25, regular: $50). This will help us ensure we have capacity for various online events.  Upon registration, you should receive a confirmation […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Dear fellow theorists,</p>



<p>As you already know, STOC 2020 this year will be a virtual conference. If you are interested in attending the conference, but haven’t registered yet, <a href="http://www.cvent.com/events/52nd-annual-acm-symposium-on-theory-of-computing-stoc-2020-/event-summary-ea5fa7861d1a476d82bc10f667a1c0f4.aspx" rel="noreferrer noopener" target="_blank">please do so soon</a> (students: $25, regular: $50). This will help us ensure we have capacity for various online events. </p>



<p>Upon registration, you should receive a confirmation email from CVENT, also containing access information for various conference events. Also, if you are a student looking to register for STOC but the cost is a burden, please email us at <a>stoc2020@ttic.edu</a>.</p>



<p><strong>How will the conference work?</strong></p>



<ul><li><strong>Videos</strong>: The videos for all conference talks are now available on YouTube, and can be accessed through the links in the <a href="http://acm-stoc.org/stoc2020/STOCprogram.html" rel="noreferrer noopener" target="_blank">conference program</a>. Registration is <em>not required</em> to view the talks on Youtube.</li></ul>



<ul><li>Slack: The conference has a Slack workspace, with one channel for every paper and workshop, and additional channels for information, announcements, social events, help, etc. The invitations for the Slack workspace will be sent to registered participants. Authors are also encouraged to monitor the channels for their papers. All access information for the conference will also be available here. The workspace is currently active, and will remain active for at least one week after the conference.</li></ul>



<ul><li><strong>Zoom sessions</strong>: The conference will feature Zoom sessions with short presentations by the speakers. The total time for each paper is 10 minutes. Given that participants have access to the full talks by the speakers on Youtube, these can be thought of as being analogues of poster sessions. The workshops will also be held as separate sessions. The links for the Zoom sessions are available via information in the registration confirmation email.</li></ul>



<ul><li><strong>Social events</strong>: The conference will include junior/senior “lunches”, breakout tables for impromptu and scheduled hangouts, and a group event using <a href="https://gather.town/" rel="noreferrer noopener" target="_blank">gather.town</a>. The timings for the events can be found in the conference program. Sign-up links for various events will be sent to all registered participants – please do sign-up soon!</li></ul>



<p>See you all at (virtual) STOC 2020. Please do let us know if you have any questions or suggestions.</p>



<p>TheoryFest organization team</p>



<p>(<a>stoc2020@ttic.edu</a>)</p></div>
    </content>
    <updated>2020-06-19T22:05:41Z</updated>
    <published>2020-06-19T22:05:41Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-06-27T22:47:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=180</id>
    <link href="https://kamathematics.wordpress.com/2020/06/19/stoc-2020-goes-virtual/" rel="alternate" type="text/html"/>
    <title>STOC 2020 Goes Virtual!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Starting on Monday, STOC is joining the trend of conferences going online, I believe the biggest theory conference to do so thus far. Given my experience with TCS+, I volunteered to lend a hand with the organization and logistics. It’s been a journey (with some unusual technical challenges), but I think we have something which … <a class="more-link" href="https://kamathematics.wordpress.com/2020/06/19/stoc-2020-goes-virtual/">Continue reading<span class="screen-reader-text"> "STOC 2020 Goes Virtual!"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Starting on Monday, STOC is joining the trend of conferences going online, I believe the biggest theory conference to do so thus far. Given my experience with <a href="https://sites.google.com/site/plustcs/">TCS+</a>, I volunteered to lend a hand with the organization and logistics. It’s been a journey (with some <a href="https://twitter.com/thegautamkamath/status/1273055827092549634">unusual technical challenges</a>), but I think we have something which I hope will be engaging and generally a lot of fun. In addition to the typical academic component, we also have a social component planned as well. We learnt from the work of others, including the <a href="https://www.acm.org/virtual-conferences">ACM virtual conferences guide</a>, <a href="https://iclr.cc/Conferences/2020">ICLR 2020</a>, and <a href="https://www.daniellitt.com/blog/2020/4/20/wagon-lessons-learned">WAGON</a>. I may make some version of our logistics docs available to others after the conference, so others can learn from our experience as well. Anyway, read on for an announcement from me and the other General Chairs, Konstantin Makarychev, Yury Makarychev, and Madhur Tulsiani. See also the <a href="http://acm-stoc.org/stoc2020/">main STOC page</a> for a more complete list of credits.</p>



<hr class="wp-block-separator"/>



<p>Dear fellow theorists,</p>



<p>As you already know, STOC 2020 this year will be a virtual conference. If you are interested in attending the conference, but haven’t registered yet, <a href="http://www.cvent.com/events/52nd-annual-acm-symposium-on-theory-of-computing-stoc-2020-/event-summary-ea5fa7861d1a476d82bc10f667a1c0f4.aspx">please do so soon</a> (students: $25, regular: $50). This will help us ensure we have capacity for various online events. </p>



<p>Upon registration, you should receive a confirmation email from CVENT, also containing access information for various conference events. Also, if you are a student looking to register for STOC but the cost is a burden, please email us at <a href="mailto:stoc2020@ttic.edu">stoc2020@ttic.edu</a>.</p>



<p><strong>How will the conference work?</strong></p>



<ul><li><strong>Videos</strong>: The videos for all conference talks are now available on YouTube, and can be accessed through the links in the <a href="http://acm-stoc.org/stoc2020/STOCprogram.html">conference program</a>. Registration is <em>not required</em> to view the talks on Youtube.</li></ul>



<ul><li><strong>Slack</strong>: The conference has a Slack workspace, with one channel for every paper and workshop, and additional channels for information, announcements, social events, help, etc. The invitations for the Slack workspace will be sent to registered participants. Authors are also encouraged to monitor the channels for their papers. All access information for the conference will also be available here. The workspace is currently active, and will remain active for at least one week after the conference.</li></ul>



<ul><li><strong>Zoom sessions</strong>: The conference will feature Zoom sessions with short presentations by the speakers. The total time for each paper is 10 minutes. Given that participants have access to the full talks by the speakers on Youtube, these can be thought of as being analogues of poster sessions. The workshops will also be held as separate sessions. The links for the Zoom session via information in the confirmation email.</li></ul>



<ul><li><strong>Social events</strong>: The conference will include junior/senior “lunches”, breakout tables for impromptu and scheduled hangouts, and a group event using <a href="https://gather.town">gather.town</a>. The timings for the events can be found in the conference program. Sign-up links for various events will be sent to all registered participants – please do sign-up soon!</li></ul>



<p>See you all at (virtual) STOC 2020. Please do let us know if you have any questions or suggestions.</p></div>
    </content>
    <updated>2020-06-19T20:20:16Z</updated>
    <published>2020-06-19T20:20:16Z</published>
    <category term="Events"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2020-06-27T22:48:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/19/postdoc-phd-student-at-ben-gurion-university-apply-by-november-20-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/19/postdoc-phd-student-at-ben-gurion-university-apply-by-november-20-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc, PhD student at Ben-Gurion University (apply by November 20, 2020)</title>
    <summary>Excellent students with a strong background in Theoretical Computer Science and Mathematics, interested to conduct research in Error-Correcting Codes, Information Theory, or Learning Theory, are welcome to apply to postdoctoral and PhD student positions. The position includes a generous salary, as well as funding for equipment and travel. Website: https://www.cs.bgu.ac.il/~klim/Links/Call Email: klim@bgu.ac.il</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Excellent students with a strong background in Theoretical Computer Science and Mathematics, interested to conduct research in Error-Correcting Codes, Information Theory, or Learning Theory, are welcome to apply to postdoctoral and PhD student positions. The position includes a generous salary, as well as funding for equipment and travel.</p>
<p>Website: <a href="https://www.cs.bgu.ac.il/~klim/Links/Call">https://www.cs.bgu.ac.il/~klim/Links/Call</a><br/>
Email: klim@bgu.ac.il</p></div>
    </content>
    <updated>2020-06-19T13:47:44Z</updated>
    <published>2020-06-19T13:47:44Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-27T22:47:08Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-785371757594389601</id>
    <link href="http://processalgebra.blogspot.com/feeds/785371757594389601/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=785371757594389601" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/785371757594389601" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/785371757594389601" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2020/06/an-interview-with-hans-huttel-concur.html" rel="alternate" type="text/html"/>
    <title>An interview with Hans Hüttel, CONCUR Test-of-Time Award recipient</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">This post is devoted to the fourth, and last, interview with the <a href="https://concur2020.forsyte.at/test-of-time/index.html">colleagues</a> who were selected for the first edition of the CONCUR  Test-of-Time Award. (See <a href="https://processalgebra.blogspot.com/2020/04/an-interview-with-davide-sangiorgi.html">here</a> for the interview with <a href="http://www.cs.unibo.it/~sangio/">Davide Sangiorgi</a>,  <a href="https://processalgebra.blogspot.com/2020/04/an-interview-with-nancy-lynch-and.html">here</a> for the interview with <a href="https://people.csail.mit.edu/lynch/">Nancy Lynch</a> and <a href="http://profs.sci.univr.it/~segala/">Roberto Segala</a>, and <a href="https://processalgebra.blogspot.com/2020/04/an-interview-with-rob-van-glabbeek.html">here</a> for the interview with </span></span></span></span></span></span><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><a href="http://theory.stanford.edu/~rvg/">Rob van Glabbeek</a></span></span></span></span></span></span>.) In keeping with my previous interviews, I asked  <a href="http://people.cs.aau.dk/~hans/index-eng.html">Hans  Hüttel</a> (Aalborg University, Denmak) a few questions via email and you can find his answers below. </span></span></span></span></span></span><br/><br/><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Hans receives the award for his paper</span></span></span></span></span></span><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"> "Bisimulation Equivalence is Decidable for all Context-Free Processes", which he wrote  with S</span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">ø</span></span></span><span><span style="font-size: x-small;"><span lang="en-US">ren Christensen and Colin Stirling. </span></span></span></span></span></span></span></span></span></span></span></span><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">S</span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">ø</span></span></span><span><span style="font-size: x-small;"><span lang="en-US">ren moved to industry after finishing his PhD. Colin is now retired.  </span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><br/><br/><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: You receive one of the two CONCUR ToT Awards for the period 1990-1993 for the paper</span></span></span><span><span style="font-size: x-small;">  </span></span><span><span style="font-size: x-small;"><span lang="en-US">"<a href="https://www.lfcs.inf.ed.ac.uk/reports/92/ECS-LFCS-92-218/">Bisimulation Equivalence is Decidable for all Context-Free Processes</a>" you published with S</span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">ø</span></span></span><span><span style="font-size: x-small;"><span lang="en-US">ren Christensen and Colin Stirling at CONCUR 1992. Could you tell us briefly what the context for that work was and how it came about? </span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: I was working on my PhD which was on the topic of decidability of behavioural equivalences for process calculi that allow processes to have infinite state spaces. Baeten, Bergstra and Klop had proved that strong bisimilarity is in fact decidable for the BPA calculus even though the class of trace languages for BPA is exactly the class of context-free languages. The result only held for normed BPA processes, that is, processes that could always terminate. Colin was my supervisor in Edinburgh, and he suggested that I try to find a simpler proof of that result (much can be said about the original proof, but simple it was not!). This turned out to be really interesting; I met Didier Caucal from IRISA who had found a nice, much shorter proof that relied on finite characterizations and I was able to use his notion of self-bisimilarity to prove that a tableau system for bisimilarity was sound and complete wrt. bisimilary. Jan Friso Groote, who was a PhD student at the CWI at the time, and myself proved that all other known equivalences are undecidable for normed BPA (and therefore </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>a fortiori</i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">also for full, unnormed BPA). But one problem that Colin and I were never able to solve was if the decidability result also held for the full BPA calculus.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Søren arrived in Edinburgh in 1990 and we shared a flat there, in St Leonards Bank just across from Holyrood Park. We hung out with the same people in the LFCS, many of whom were clever Italians such as Davide Sangiorgi and clever quasi-Italians such as Marcelo Fiore. It is no surprise that Søren and I often discussed our work or that he, given that Colin was also his supervisor, moved on to study decidability problems as well, the only difference being that Søren was mostly interested in the BPP calculus that has parallel composition instead of sequential composition.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">When I left Edinburgh at the end of August of 1991, Colin and I had managed to make some progress on the decidability problem for unnormed BPA. We realised that a finite characterization of the maximal bisimulation </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>á la</i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">Caucal was the way ahead but the actual characterization escaped us. When I returned for my viva in December, Søren had found an important lemma on finite characterizations and everything fell into place. The decidability result relied on proving that bisimilarity is semi-decidable using the finite characterization; non-bisimilarity was already known to be semi-decidable. </span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: Both S</span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">ø</span></span></span><span><span style="font-size: x-small;"><span lang="en-US">ren Christensen and you wrote the award-winning paper as PhD students in Edinburgh. Could you tell us about the research environment in Edinburgh at that time, and the influence it had on you then and in the rest of your career? </span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: The LFCS in Edinburgh was a great place to be at the time. Robin Milner was still around and busy working on the pi-calculus together with Davide Sangiorgi, who was his student at the time. Watching them at the blackboard was interesting, even though the rest of us often could not follow their discussions! Gordon Plotkin was there (and still is, fortunately). Rod Burstall was still active, and so was Mike Fourman. Plus many, many others. There was always someone to talk to, and it was perfectly legitimate to have an interest in basic research. Unlike the other professors, Colin had no background in maths – he was originally a philosopher! – and maybe that was why he was trying to avoid heavy mathematical lingo, trying to be simple and precise in his writing at the same time. I learned a lot from him, also in that respect.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">After Søren returned to Denmark, he left academia and got a job in the private sector. He still lives near Aarhus. Sadly we lost touch with each other, in all likelihood because our lives turned out so different. We got back in touch recently, when we were told about the reward and we look forward to finally meeting each other again. Colin retired recently, and I really hope to see him again, when I am able to travel to Scotland again some day.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: medium none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: How much of your later work has built on your award-winning paper? What follow-up results of yours are you most proud of and why?</span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: I worked on decidability issues for another few years after that but there was no-one to talk to in Aalborg, or rather, there was no-one there that shared my interest in the area at the time. What is more, the open problems that remained were major challenges. Some were only solved much later (such as the decidability of bisimilarity for pushdown automata, a result due to Sénizergues, the proof later greatly simplified by Colin) or remain open (such as the decidability of weak bisimilarity for BPA). Eventually I drifted down the slippery slope and became interested in other, related topics, and focused somewhat more directly on program properties. The follow-up result that most directly relates to my paper with Søren and Colin is the result from 1994 that bisimilarity is also the only equivalence that is decidable for BPP. This is a result that I am also quite proud of. It grew out of discussions with Javier Esparza and Yoram Hirshfeld, when I was back in Edinburgh for a while in 1993. Ironically, there was a subtle flaw in the proof that Naoki Kobayashi discovered many years later. Naoki and one of his student found out how to repair the proof, and the three of us co-authored the journal version that came out many years later. The reason why Naoki became interested in BPP was that he was trying to use the calculus as a behavioural type system for a pi-calculus. As it happened, this was also the route that I had taken.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Those of my later results that I am most proud of have to do with this area: My work on type systems for psi-calculus (CONCUR 2011 and later) and a session type system for bounded name use in the pi-calculus (Acta Informatica 2019). The latter paper also has a CONCUR connection; it grew out of attending a talk by Roland Meyer at CONCUR 2013 and wondering why they were not trying to characterize notions of name-boundedness in the pi-calculus by means of a type system. It turned out that Meyer et al. were not familiar with type systems at all. It took me an awful long time to work out a type-based characterization (using session types), as you can probably tell.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">As you can tell, I have not worked on bisimulation for quite some time. Not that there is anything wrong with bisimulation, of course, but if one wants results that are applicable for automated reasoning about program behaviour, decidability is important. One can then either choose to go for a less expressive model of computation (which is what researchers in the model checking community do) or keep the model of computation and go for sound, but incomplete characterizations of program properties (which is what researchers interested in type systems and related static analysis methods do). I ended up in the latter camp.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: To your mind, what are the most interesting or unexpected uses in the literature of the notions and techniques you developed in "Bisimulation Equivalence is Decidable for all Context-Free Processes"? </span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: BPA, BPP and similar process calculi can be used as the basis of behavioural type systems, and I am thrilled that my old research interests and my current research interests are so directly related. </span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">In 2018 I discovered that Vasco Vasconcelos and Peter Thiemann had devised a session type system for a functional programming language in which session types were not regular expressions (which is essentially what they are in the original work by Honda, Kubo and Vasconcelos) but BPA processes. Vasco and Peter knew that type equivalence should be decidable but they were not so familiar with our results from the early 1990s. At POPL 2019 I attended a talk by Andreia Mordido, one of Vasco’s collaborators, and she mentioned our paper from CONCUR 1992! Later that day, I ended up talking to Andreia and Vasco about my work on BPA from all those years ago.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: The last forty years have seen a huge amount of work on process algebra and process calculi. However, the emphasis on that field of research within concurrency theory seems to have diminished over the last few years, even in Europe. What advice would you give to a young researcher interested in working on process calculi today? </span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: That they should still work on process calculi! There remains a lot of interesting work to be done. One reason why research topics drift in and out of focus is simply that researchers lose interest; it is hardly ever the case that a topic runs out of interesting research questions. Another reason is rather grim: Basic research is nowhere near as well-respected as it used to be. If you look at the funding schemes that we have today, only the very successful few can get funding for basic research; I am not among them and it does get frustrating quite often. Most topics these days deal with applied research. There is nothing wrong with applied research per se; some of what I do is on that side of things, but there has to be more to research than that. </span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: medium none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: What are the research topics that currently excite you the most?</span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: I have slowly become more and more interested in programming language theory, and some of my current collaborators have taken a similar route, beginning in concurrency theory, drifting into the world of behavioural type systems and finally wanting to apply all of their skills to actual programming languages. Right now Mario Bravetti, Adrian Francalanza, António Ravara and myself are involved in working on a behavioural type system related to the Mungo tool for a subset of Java. I am fortunately enough to have had three exceptionally clever and productive MSc students involved as well, and this has been extremely helpful. Mungo is in many ways the work of Simon Gay and Ornela Dardha at Glasgow University, and they, too, began their careers working on process calculi.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: medium none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: You have a keen interest in teaching at university level. Is there anything you think we should do better in conveying the beauty and usefulness of theoretical computer science in general, and concurrency theory in particular, to our students today? Do you have any thoughts you'd like to share with us on how to combine digital resources and in-person meetings in the teaching of subjects in the theory of computing?</span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: Personally I think there is a tendency to present any academic topic – and in particular topics in the mathematical sciences, broadly speaking – in such a way that the definitions and theorems appear as if they fell from the heavens, fully formed. As any researcher will know, that is certainly </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>not </i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">how they came about. In this way, we focus a lot on what Imre Lakatos and Karl Popper called the </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>context of justification. </i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">A well-honed presentation of a theory may appear to be beautiful, but in my opinion the actual beauty is the one that one experiences when one has finally understood the theory and understands why the definitions and theorem turned out the way they did – that is, one must understand the </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>context of discovery.</i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">I think problem-based learning (which is something that we talk about a lot at Aalborg University and at Roskilde University) is the key here, because it puts the focus on student-centered active learning.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">I have lectured a lot over the years but since 2013 I have drifted away from traditional lectures towards flipped teaching in which I use pre-recorded podcasts (of my own making) that students can watch whenever they want; I then use the plenary sessions for activities that focus on active learning. I by far prefer having a dialogue with students that focuses on the problems that they encounter to the monologue style of a lecture. All my teaching activities are now flipped and I am happy to say that some of my colleagues are now thinking along similar lines. It is always good to have someone to talk to. </span></span></span></span></span></span><br/><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK"> </span></span></span></span></span></span></div></div>
    </content>
    <updated>2020-06-18T21:29:00Z</updated>
    <published>2020-06-18T21:29:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2020-06-21T21:12:58Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://gradientscience.org/background/</id>
    <link href="https://gradientscience.org/background/" rel="alternate" type="text/html"/>
    <title>Noise or Signal&amp;#58; The Role of Backgrounds in Image Classification</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="bbutton" href="http://arxiv.org/abs/2006.09994" style="float: left;">
<i class="fas fa-file-pdf"/>
    Read the paper
</a>
<a class="bbutton" href="https://github.com/MadryLab/backgrounds_challenge" style="float: right;">
<i class="fab fa-github"/>
   Download the datasets
</a></p>

<p><em>We discuss our recent <a href="https://arxiv.org/abs/2006.09994">paper</a> 
on identifying the role of backgrounds in image classification. Along with our
results, we’re releasing our code and datasets <a href="https://github.com/MadryLab/backgrounds_challenge">as a benchmark</a>.</em></p>

<p>As we discussed in our <a href="https://gradientscience.org/benchmarks">last post</a>, quantitative
benchmarks are key drivers of progress across many computer vision tasks. 
On tasks like image classification, state of the art is often determined by models’
accuracies on standard datasets, such as CIFAR-10 and ImageNet. 
Still, model accuracy isn’t all that matters, as evidenced by investigations into
robustness (e.g., <a href="https://gradientscience.org/intro_adversarial">[1]</a>), 
reliability (e.g., <a href="https://arxiv.org/abs/1903.12261">[2]</a>), 
and out-of-distribution performance (e.g., <a href="https://arxiv.org/abs/1706.02690">[3]</a>). 
These properties are governed not only by models’ predictions on test data, but
also by the specific set of correlations models use, and by how these
correlations are combined to make predictions. 
For example, previous work has shown that model predictions can behave
unexpectedly due to reliance on correlations that we humans 
don’t rely on (e.g. <a href="https://arxiv.org/abs/1711.11561">[4]</a>,
<a href="https://arxiv.org/abs/1807.04200">[5]</a>,
<a href="https://arxiv.org/abs/1905.02175">[6]</a>, 
<a href="https://arxiv.org/abs/1811.00401">[7]</a>); or due to overusing even
human-recognizable correlations such as texture (e.g., 
<a href="https://arxiv.org/abs/1811.12231">[8]</a>,
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6306249/">[9]</a>) or color 
(e.g., <a href="https://journals.sagepub.com/doi/10.1068/p3376">[10]</a>). 
So it follows that if we want to understand these more complex properties of
machine learning models, we must first be able to characterize the correlations
that these models leverage.</p>

<p>Needless to say, a full characterization of the features and signals exploited
by deep neural networks is far beyond the scope of any single paper. In our
<a href="https://arxiv.org/abs/2006.09994">latest paper</a>, 
we thus take a deep dive into one specific kind of signal: <em>image backgrounds</em>.</p>

<p>Backgrounds are an established source of correlation between images and
their labels in object detection: ML models may use backgrounds in
classification (cf.
<a href="https://hal.archives-ouvertes.fr/hal-00171412/file/ZhangMarszalekLazebnikSchmid-IJCV07-ClassificationStudy.pdf">[11]</a>,
<a href="https://arxiv.org/abs/1602.04938">[12]</a>, 
<a href="https://arxiv.org/abs/1611.06596">[13]</a>,
<a href="https://arxiv.org/abs/1911.08731">[14]</a>), and even human
vision can make use of image context (cf.
<a href="http://people.csail.mit.edu/torralba/IJCVobj.pdf">[15]</a> and references). 
We thus want to understand better how current
state-of-the-art image classifiers rely on image backgrounds. 
Specifically, we investigate the extent of this reliance, its implications, and how models’ use of
backgrounds has evolved over time.</p>

<h2 id="a-new-dataset-or-seven">A new dataset (or seven)</h2>

<p>Our main tool for understanding how models use background signals is a set of
synthetic datasets that we refer to as ImageNet-9 (IN9). These datasets aim
to disentangle images’ foreground and background signals and thus enable us
to study their relative effects.</p>

<p>To generate ImageNet-9, we start by organizing a subset of ImageNet into nine
coarse-grained classes based on common ancestry in the <a href="https://wordnet.princeton.edu">WordNet hierarchy</a>: the
resulting “super-classes” are dog, bird, vehicle, reptile, carnivore, insect, 
instrument, primate, and fish. We call the 9-class dataset of unmodified images
Original.
We then use a combination of the bounding boxes
provided by ImageNet and the computer vision library <a href="https://opencv.org">OpenCV</a> to separate the
foreground and background in each imagewe deleted any images where this
process was unsuccessful (e.g., if there is no bounding box provided by ImageNet, or the bounding box takes up the entirety of the image).</p>

<p>Once we’ve separated the foreground and background signals, we introduce
 <em>seven</em> new datasets, falling into three categories:</p>

<ul>
  <li>Background-only datasets
    <ul>
      <li><strong>Only-BG-B</strong>: Black out the bounding boxes given by ImageNet annotations,
leaving only the background.</li>
      <li><strong>Only-BG-T</strong>: Take Only-BG-B and replace the blacked-out region with a
tiled version of the rest of the image (the background).</li>
      <li><strong>No-FG</strong>: Use OpenCV to extract the exact shape of the foreground, and
replace it with black.</li>
    </ul>
  </li>
  <li>Foreground-only datasets
    <ul>
      <li><strong>Only-FG</strong>: The exact complement of No-FG—rather than removing
the foreground, remove everything else.</li>
    </ul>
  </li>
  <li>Mixed datasets
    <ul>
      <li><strong>Mixed-Rand</strong>: For each image, overlay the foreground (extracted using
OpenCV) onto the background from a different random image (again,
extracted using OpenCV).</li>
      <li><strong>Mixed-Next</strong>: Assign each class a number from 1 to 9. For each image of
class $y$, add the background from a random image of class $y+1$ (or $1$, if
$y=9$).</li>
      <li><strong>Mixed-Same</strong>: For each image, add the background from a random image of
the same class.</li>
    </ul>
  </li>
</ul>

<div class="widget" style="display: flex;">
    <div class="choices_one" id="left_in9">
	<span class="widgetheading">Choose an Image</span>
    </div>
    <div class="selected_one" id="in9_selected"/>
</div>
<div style="clear: both;"/>
<div class="footnote">
        8 versions of the same image, with each version capturing a different
        combination of foreground and background signals.
</div>

<h2 id="putting-imagenet-9-to-work">Putting ImageNet-9 to work</h2>

<p>It turns out that these proposed ImageNet-9 datasets allow us to ask (and
answer) a variety of questions about the role of background signals in image
classification.</p>

<h3 id="1-is-background-signal-enough-for-classification">1. Is background signal enough for classification?</h3>

<p>Before we look at the behaviour of standard ML models, we first double-check
that background signals are exploitable in the first place—i.e., that models
can learn reasonably accurate classifiers for natural images while being trained
on backgrounds alone. 
We are not the first ones to consider this question (e.g.,
<a href="https://arxiv.org/abs/1611.06596">[13]</a>) but it serves as a useful sanity 
check and gives us a baseline to compare the rest of our experiments to.</p>

<p>We train models on the Only-BG-T, Only-BG-B, and No-FG datasets; the models
generalize reasonably well to both their corresponding test sets <em>and</em> the Original
test set (each model gets around 40-50% accuracy: a random classifier would get
11%). Thus, image backgroundsInterestingly, the No-FG model doesn't do
significantly better than the others, despite having access to the shape of the
foregrounds in the training set. <em>do</em> contain signal that
models can use to classify images.</p>

<p><img alt="The results of training models on background-only datasets and testing on the original." src="https://gradientscience.org/images/background/bg_only_train.png" style="width: 70%;"/></p>

<h3 id="2-do-models-actually-use-background-signals">2. Do models actually use background signals?</h3>

<p>So, backgrounds are indeed a useable signal for deep learning classifiers.
That’s not necessarily bad, or even different to humans: if you see an
occluded picture with an underwater background, you’d (hopefully) say that the
pictured object is more likely to be a fish than a dog.
On the other hand, humans are still able to call a dog a dog when it’s
underwater, i.e., a misleading/irrelevant background usually does not preclude us from
making the correct predictions. Is the same true for models?</p>

<p>To answer this question, we study model accuracies on the Mixed-Rand dataset,
where image backgrounds are randomized and thus provide no information 
about the correct label. 
Specifically, we compare model performance on Mixed-Rand and Mixed-Same: the
latter maintains the foreground-background correlation (since the background is
from the correct class), while controlling for artifactsSee
Appendix D of our paper for more details! from image
splicing process.</p>

<p>We denote the accuracy gap between Mixed-Same and Mixed-Rand as the BG-Gap,
i.e., the drop in model accuracy due to changing the class signal from the
background. The table below summarizes our observations: the BG-Gap is
13-22% and 6-14% for models trained on IN-9 and ImageNet, respectively,
suggesting that backgrounds often mislead state-of-the-art models even
when the correct foreground is present. (As we discuss in Appendix B of <a href="https://arxiv.org/abs/2006.09994">our
paper</a>, ImageNet-trained models do seem to be
more robust in this sense, but the reason for this robustness is hard to pin down.)</p>

<p><img alt="Evaluating pretrained models on Imagenet, Mixed-Rand, and Mixed-Same to compute the BG-Gap." src="https://gradientscience.org/images/background/table.png" style="width: 100%;"/></p>

<h3 id="3-ok-but-how-bad-can-it-get">3. Ok, but how bad can it get?</h3>

<p>The BG-Gap introduced in the previous experiment measures, in some sense,
models’ average robustness to misleading backgrounds. What does the worst case
look like? To diagnose just how large of an issue background over-reliance
can be, we search for the worst extracted background corresponding for each
extracted foreground. It turns out that a ResNet-50 model can be fooled on
87.5% of foregrounds by overlaying them on a corresponding “adversarial background.”</p>

<p>In fact, there also turn out to exist backgrounds that consistently affect the
prediction of the classifier <em>regardless</em> of what foreground is overlaid onto
them. The backgrounds below (extracted from insect images) fool our model into
predicting “insect” on up to 52\% of non-insect foregrounds:
<img alt="Adversarial Backgrounds" src="https://gradientscience.org/images/background/insect_result.png" style="width: 100%;"/></p>
<div class="footnote">
        The 5 most fooling backgrounds from the insect class, as well as the percent of non-insect foregrounds that they individually fool.
</div>

<p>Further, we can make the classifier predict “insect” on over 2/3 of the
foregrounds in the ImageNet-9 dataset, just by combining the foregrounds with
different insect backgrounds.</p>

<h3 id="4-what-is-the-effect-of-the-training-dataset">4. What is the effect of the training dataset?</h3>

<p>So far, all of the models that we’ve looked at have been trained on natural
data, i.e., either on the Original dataset from IN9, or on ImageNet itself.
We now want to test whether the previously-observed dependence on backgrounds
can be reduced (or removed altogether) by appropriately altering the training data.</p>

<p>To this end, we train models on Mixed-Rand, where background signals have been
decorrelated from class labels. 
We find these models perform only slightly better than
random on datasets with no foregrounds (e.g., a ResNet-50 trained on Mixed-Rand
achieves 15% accuracy on Only-BG-T and Only-BG-B).
They also perform better in the presence of misleading backgrounds:
training on Mixed-Rand improves accuracy on Mixed-Rand by 17%, and improves
accuracy on Mixed-NextRecall that Mixed-Next
images have foregrounds from class $y$ mixed with backgrounds from class $y+1$,
labeled as class $y$. by 22%. The model trained on
Mixed-Rand also has very little variation in accuracy across all five test sets
that contain the correct foreground (providing more evidence for its invariance
to other factors).</p>

<p><img alt="Training on Mixed-Rand and evaluating on other datasets" src="https://gradientscience.org/images/background/mixed_rand_results.png" style="width: 100%;"/></p>

<p>Qualitatively, the Mixed-Rand model also appears to place more relative
importance on foreground pixels than its original counterpart, as demonstrated
by the saliency maps below:</p>

<p><img alt="Saliency maps for models trained on original versus on Mixed-Rand" src="https://gradientscience.org/images/background/saliency_other.png" style="width: 100%;"/></p>

<h3 id="5-are-we-really-making-progress">5. Are we really making progress?</h3>

<p>We’ve now shown that models can exploit backgrounds, do exploit backgrounds, and
may actually do so to a fault. Considering that the development of these models
is driven by standard computer vision benchmarks, our results beg the question: to
what extent have improvements on ImageNet come with (or resulted from)
improvements in leveraging background correlations? And relatedly, how has
model robustness
to misleading background signals evolved over time?</p>

<p>As a first step towards answering these questions, we study the progress made by
ImageNet models on our proposed synthetic datasets. Below, we plot accuracy on
these datasets against ImageNet accuracy for a variety of different
network architectures:</p>

<p><img alt="ImageNet accuracy plotted against accuracy on synthetic datasets" src="https://gradientscience.org/images/background/in_vs_bg.png" style="width: 100%;"/></p>

<p>The plot indicates that accuracy increases on ImageNet generally correspond to
accuracy increases on all of the synthetic datasets that we consider. 
This includes the datasets that only contain background signals (Only-BG-T
in the graph above), which means that models <em>do</em> improve at extracting correlations
from image backgrounds. The fact that better models are also better at
classifying background-only images suggests that the use of background
signals might be inherent to the current training paradigm, and may
not disappearThough again, this might not be a bad
thing! on its own (i.e., without explicit regularization
or training).</p>

<p>Still, models’ <em>relative</em> improvement in accuracy across dataset variants is
promising—accuracy on background-only datasets is improving slower than
accuracy on datasets where the background is misleading, such as Mixed-Rand or
Mixed-Next. Another promising sign is that the
performance gap between the Mixed-Rand and Mixed-Same dataset (which we
previously referred to as the BG-Gap) trends towards closing, indicating that
models are not only better at using foreground features, but also more
robust to misleading background features.</p>

<p>Overall, our analysis reveals that better models in terms of ImageNet accuracy
are (a) increasingly capable of exploiting background correlations, but at the
same time (b) becoming more robust to changes in background, suggesting that
over-reliance on background features may not be necessary to maximize the
benchmark accuracy.</p>

<h3 id="conclusions">Conclusions</h3>

<p>In this post, we saw how computer vision models tend to over-rely on image
backgrounds in image classification. On one hand, our findings provide more
evidence that our models are not fully aligned with the human vision system. On the
other hand, we have shown that advances in computer vision models, such as new
architectures and training methods, have led to models that tend to use the
foreground more effectively and are more robust to misleading backgrounds.
We hope that the datasets and findings in this work provide a way to monitor
progress towards reliable, human-aligned machine learning.</p>

<p>For more detailed information about the <a href="https://github.com/MadryLab/backgrounds_challenge">datasets</a> we created, full
experimental results, and additional analysis, see <a href="https://gradientscience.org/background.pdf">our paper</a>!</p></div>
    </summary>
    <updated>2020-06-18T00:00:00Z</updated>
    <published>2020-06-18T00:00:00Z</published>
    <source>
      <id>https://gradientscience.org/</id>
      <author>
        <name>Gradient Science</name>
      </author>
      <link href="https://gradientscience.org/" rel="alternate" type="text/html"/>
      <link href="https://gradientscience.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Research highlights and perspectives on machine learning and optimization from MadryLab.</subtitle>
      <title>gradient science</title>
      <updated>2020-06-27T22:47:13Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-2271116647104476479</id>
    <link href="http://processalgebra.blogspot.com/feeds/2271116647104476479/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=2271116647104476479" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2271116647104476479" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2271116647104476479" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2020/06/logic-mentoring-workshop-2020.html" rel="alternate" type="text/html"/>
    <title>Logic Mentoring Workshop 2020</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="_5pbx userContent _3576" id="js_k"><a href="https://www2.csc.liv.ac.uk/~lehtinen/">Karoliina Lehtinen</a> asked me to encourage young researchers of all ages to attend this year's edition of the Logic Mentoring Workshop. (See <a href="https://lmw.mpi-sws.org/">here</a> for information.) The <a href="https://lmw.mpi-sws.org/speakers.html">set of speakers</a> is top class, registration is  free and I am sure that attending the event would be beneficial  to  many. Spread the news!<br/><br/>FWIW, I gave a talk at the <a href="https://lics.siglog.org/lics17/lmw.html">2017 edition</a> of the event and thoroughly enjoyed it. Even though the event is targeted at students, from senior undergraduates to graduates, I feel that I always learn something new from attending this kind of workshops/talks. </div></div>
    </content>
    <updated>2020-06-17T16:10:00Z</updated>
    <published>2020-06-17T16:10:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2020-06-21T21:12:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17204</id>
    <link href="https://rjlipton.wordpress.com/2020/06/16/pnp/" rel="alternate" type="text/html"/>
    <title>P&lt;NP</title>
    <summary>Some thoughts on P versus NP Norbert Blum is a computer science theorist at the University of Bonn, Germany. He has made important contributions to theory over his career. Another claim to fame is he was a student of Kurt Mehlhorn, indeed the third of Mehlhorn’s eighty-eight listed students. Today I wish to discuss a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Some thoughts on P versus NP</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/?attachment_id=17188" rel="attachment wp-att-17188"><img alt="" class="alignright size-full wp-image-17188" src="https://rjlipton.files.wordpress.com/2020/06/unknown.jpeg?w=600"/></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p>
Norbert Blum is a computer science theorist at the University of Bonn, Germany. He has made important contributions to theory over his career. Another claim to fame is he was a student of Kurt Mehlhorn, indeed the <a href="https://www.genealogy.math.ndsu.nodak.edu/id.php?id=35475&amp;fChrono=1">third</a> of Mehlhorn’s eighty-eight listed students.</p>
<p>
Today I wish to discuss a new paper by Blum.</p>
<p><span id="more-17204"/></p>
<p>
No, it does not solve the P versus NP problem. The title of his paper is: <i>On the Approximation Method and the P versus NP Problem</i>. Its is available <a href="https://arxiv.org/pdf/1708.03486.pdf">here</a>.</p>
<p>
Blum. like most complexity theorists, believes that P is weaker than NP. This is usually stated as P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/>NP. The staff at GLL have the idea that we should state this as 	</p>
<p align="center"><img alt="\displaystyle  P &lt; NP. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P+%3C+NP.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  P &lt; NP. "/></p>
<p>This is clearer, more to the point, and logically what P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/>NP actually says. We will soon have T-shirts, mugs, and other stuff available in our web store at https:donotgotothisaddressplease.com. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/06/16/pnp/mug2-2/" rel="attachment wp-att-17207"><img alt="" class="aligncenter size-medium wp-image-17207" height="257" src="https://rjlipton.files.wordpress.com/2020/06/mug2-1.png?w=300&amp;h=257" width="300"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
</p><p/><h2> Three Years Ago </h2><p/>
<p/><p>
In 2017 Blum released a <a href="https://arxiv.org/abs/1708.03486">paper</a> that tried to prove P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. It caused a sensation—it was discussed on the complexity blogs such as <a href="https://lucatrevisan.wordpress.com/2017/08/15/on-norbert-blums-claimed-proof-that-p-does-not-equal-np/">In theory</a> and <a href="https://www.scottaaronson.com/blog/?p=3409">Shtetl-Optimized</a>. And also at <a href="https://rjlipton.wordpress.com/2017/08/17/on-the-edge-of-eclipses-and-pnp/">GLL</a>. Blum’s paper got thousands of Twitter mentions. Unfortunately he had to retract it, since it is wrong: He said: </p>
<blockquote><p><b> </b> <em> The proof is wrong. I shall elaborate precisely what the mistake is. For doing this, I need some time. I shall put the explanation on my homepage </em>
</p></blockquote>
<p>Look at <a href="https://johncarlosbaez.wordpress.com/2017/08/15/norbert-blum-on-p-versus-np/">here</a> for more comments that were made after his paper was released. </p>
<p>
He did, months later in 2017, post a two-page retraction<br/>
<a href="http://theory.cs.uni-bonn.de/blum/PvsNP/mistake.pdf">here</a>. His original paper’s abstract: </p>
<blockquote><p><b> </b> <em> Berg and Ulfberg and Amano and Maruoka have used CNF-DNF-approximators to prove exponential lower bounds for the monotone network complexity of the clique function and of Andreev’s function. We show that these approximators can be used to prove the same lower bound for their non-monotone network complexity. This implies P not equal NP. </em>
</p></blockquote>
<p>This approach is what we will discuss.</p>
<p>
</p><p/><h2> Today </h2><p/>
<p/><p>
Blum’s new paper does not claim to prove P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP, but gives his thoughts on P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. I think he has earned our attention. It must have been difficult to go from thinking you have solved <i>the problem</i> to retracting your paper. I have thought, privately, that I had solved some neat problems. Only later to discover that I was wrong. I cannot imagine how tough it was to do this in public. </p>
<p>
</p><p/><h2> The Idea </h2><p/>
<p/><p>
Blum’s work on proving lower bounds began with his dissertation under Mehlhorn, which included a 1985 <a href="https://www.sciencedirect.com/science/article/pii/0304397585900301">paper</a> on monotone network complexity for convolutions. Earlier in 1984 Blum <a href="https://reader.elsevier.com/reader/sd/pii/0304397583900294? which was improved token=1F67F05B416D89618750BC409200E17D536C46207555E1A9FD524B2592630E400FC2C597EA81F7190D2A747A4B82F28B">proved</a> a lower bound of order <img alt="{3n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3n}"/>. This stood for thirty years until in 2015 Magnus Find, Alexander Golovnev, Edward Hirsch, and Alexander Kulikov <a href="https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=919494">improved</a> it to order <img alt="{3.011n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3.011n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3.011n}"/>. A long way from super-polynomial lower bounds. See also a <a href="https://simons.berkeley.edu/sites/default/files/docs/3815/20151001gateelimination.pdf">talk</a> about this work. </p>
<p>
Blum’s new paper discusses an old approach to prove boolean circuit lower bounds. The methods he used in 1984 and those improved in 2015 do not seem to be on track to prove even non-linear circuit lower bounds. </p>
<p>
Let’s look at his comments at a high level. See his paper for details. </p>
<p>
Suppose that one has a boolean function <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> that is monotone: recall this means that if <img alt="{f(x)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)=1}"/>, then changing some input <img alt="{x_{k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bk%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{k}}"/> from <img alt="{0 \rightarrow 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%5Crightarrow+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0 \rightarrow 1}"/> does not change the value of <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/>. Then it is always possible to compute <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> without using any negations: only and/or operations are needed. Sometimes one can prove that the number of such operations is super-linear, sometimes even super-polynomial. Even bounds in this restricted model can be deep.</p>
<p>
The idea that has tempted Blum and many other complexity theorists is: Can we extend the proofs for lower bounds without negations to ones with negations? One problem is there is a function <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> so that the following are true: </p>
<ol>
<li>
The function is monotone; <p/>
</li><li>
The function can be computed in polynomial time; <p/>
</li><li>
Any monotone circuit for computing the function requires exponential size
</li></ol>
<p>This is the famous <a href="https://en.wikipedia.org/wiki/Tardos_function">Tardos function</a> due to Éva Tardos. The existence of this function sunk Blum’s original paper. And it makes life hard for this general program—this is an instance of what our previous <a href="https://rjlipton.wordpress.com/2020/06/13/proof-checking-not-line-by-line/">post</a> meant by a proof attempt running up against a fundamental law. Negations can help tremendously in computing a function. </p>
<p>
</p><p/><h2> Blum’s Paper </h2><p/>
<p/><p>
In his new <a href="https://arxiv.org/pdf/1708.03486.pdf">paper</a> he surveys boolean complexity ideas—especially those linked to monotone complexity. He begins by trying to argue that the largeness feature of the <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">natural proofs</a> barrier, which applies to combinatorial properties defined via sub-additive circuit complexity measures, does not constrain approximation complexity measures of the kind he envisions. He then proceeds to define <em>CNF-DNF approximators</em> and further what he calls <em>sunflower approximators</em>. He does enough development to highlight a missing piece of information about monomial representations of <em>non-</em>approximated pieces of the Boolean function one is trying to prove hard. He concludes that without this information, his methods cannot even prove super-<em>linear</em> size lower bounds on general circuits.</p>
<p>
He ends with this assessment: </p>
<blockquote><p><b> </b> <em> How to proceed the work with respect to the P versus NP problem? Currently, I am convinced that we are far away to prove a super-polynomial lower bound for the non-monotone complexity of any explicit Boolean function. On the other hand, the strongest barrier towards proving P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP could be that it holds P = NP. To ensure that the whole time spent for working on the P versus NP problem is not used to prove an impossible theorem, I would switch to the try to develop a polynomial algorithm for the solution of an NP-complete problem. </em>
</p></blockquote>
<p/><p>
Note, we have changed his P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/>NP to P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. Ken and I agree with him on trying to work both on P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP and P=NP. However, see our comments below. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I applaud Blum for thinking about P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. We need people to be fearless if it is ever going to be solved. However, I personally believe that his approach may be wrong:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> I am not as sure as he is that P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. I do think that P=NP is possible, especially if algorithms are allowed to be <a href="https://en.wikipedia.org/wiki/Galactic_algorithm">galactic</a>. Recall these are algorithms that run in polynomial time, but in polynomials of astronomical degree.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Also I am not sure if the boolean approach to P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP is the right one. Suppose there is a <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> so that SAT has boolean circuits of size <img alt="{n^{C}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^{C}}"/> where 	</p>
<p align="center"><img alt="\displaystyle  C = 2^{2^{2^{10000}}}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%3D+2%5E%7B2%5E%7B2%5E%7B10000%7D%7D%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C = 2^{2^{2^{10000}}}. "/></p>
<p>It still could be the case that P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP, since there may be no uniform algorithm for SAT.</p>
<p>
Restating the last point: I believe we should try to prove what is needed, and not any more. The approach to P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP based on boolean circuit complexity is trying to prove too much. A proof that SAT has super-polynomial circuits does imply more than P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. A proof that SAT cannot be solved in time <img alt="o(n\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28n%5Clog+n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="o(n\log n)"/> on a multitape Turing machine would imply much less than P &lt; NP, yet still be a breakthrough</p>
<p>
Be cheap, prove the least possible. </p>
<p/></font></font></div>
    </content>
    <updated>2020-06-16T20:40:41Z</updated>
    <published>2020-06-16T20:40:41Z</published>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-06-27T22:47:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/092</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/092" rel="alternate" type="text/html"/>
    <title>TR20-092 |  Computing Igusa&amp;#39;s local zeta function of univariates in deterministic polynomial-time | 

	Ashish Dwivedi, 

	Nitin Saxena</title>
    <summary>Igusa's local zeta function $Z_{f,p}(s)$ is the generating function that counts the number of integral roots, $N_{k}(f)$, of $f(\mathbf x) \bmod p^k$, for all $k$. It is a famous result, in analytic number theory, that $Z_{f,p}$ is a rational function in $\mathbb{Q}(p^s)$. We give an elementary proof of this fact for a univariate polynomial $f$. Our proof is constructive as it gives a closed-form expression for the number of roots $N_{k}(f)$. 

Our proof, when combined with the recent root-counting algorithm of (Dwivedi, Mittal, Saxena, CCC, 2019), yields the first deterministic poly($|f|, \log p$) time algorithm to compute $Z_{f,p}(s)$. Previously, an algorithm was known only in the case when $f$ completely splits over $\mathbb{Q_p}$; it required the rational roots to use the concept of generating function of a tree (Zuniga-Galindo, J.Int.Seq., 2003).</summary>
    <updated>2020-06-16T08:32:14Z</updated>
    <published>2020-06-16T08:32:14Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-27T22:46:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/15/postdoc-positions-in-tcs-at-university-of-copenhagen-apply-by-july-6-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/15/postdoc-positions-in-tcs-at-university-of-copenhagen-apply-by-july-6-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc positions in TCS at University of Copenhagen (apply by July 6, 2020)</title>
    <summary>The CS department at the University of Copenhagen invites applications for postdoc positions in TCS. The application deadline is July 6, 2020. See https://employment.ku.dk/faculty/?show=151975 for the full announcement with more information and instructions for how to apply. Informal enquiries are welcome and may be sent to mthorup@di.ku.dk or jn@di.ku.dk. Website: https://employment.ku.dk/faculty/?show=151975 Email: jn@di.ku.dk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The CS department at the University of Copenhagen invites applications for postdoc positions in TCS. The application deadline is July 6, 2020. See <a href="https://employment.ku.dk/faculty/?show=151975">https://employment.ku.dk/faculty/?show=151975</a> for the full announcement with more information and instructions for how to apply. Informal enquiries are welcome and may be sent to mthorup@di.ku.dk or jn@di.ku.dk.</p>
<p>Website: <a href="https://employment.ku.dk/faculty/?show=151975">https://employment.ku.dk/faculty/?show=151975</a><br/>
Email: jn@di.ku.dk</p></div>
    </content>
    <updated>2020-06-15T21:51:22Z</updated>
    <published>2020-06-15T21:51:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-27T22:47:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/091</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/091" rel="alternate" type="text/html"/>
    <title>TR20-091 |  Randomized polynomial-time equivalence between determinant and trace-IMM equivalence tests | 

	Janaky Murthy, 

	vineet nair, 

	Chandan Saha</title>
    <summary>Equivalence testing for a polynomial family $\{g_m\}_{m \in \mathbb{N}}$ over a field F is the following problem: Given black-box access to an $n$-variate polynomial $f(\mathbb{x})$, where $n$ is the number of variables in $g_m$ for some $m \in \mathbb{N}$, check if there exists an $A \in \text{GL}(n,\text{F})$ such that $f(\mathbb{x}) = g_m(A\mathbb{x})$. If yes, then output such an $A$. The complexity of equivalence testing has been studied for a number of important polynomial families, including the determinant (Det) and the family of iterated matrix multiplication polynomials. Two popular variants of the iterated matrix multiplication polynomial are: IMM$_{w,d}$ (the $(1,1)$ entry of the product of $d$ many $w\times w$  symbolic matrices) and Tr-IMM$_{w,d}$ (the trace of the product of $d$ many $w\times w$ symbolic matrices). The families - Det, IMM and Tr-IMM - are VBP-complete under $p$-projections, and so, in this sense, they have the same complexity. But, do they have the same equivalence testing complexity? We show that the answer is 'yes' for Det and Tr-IMM (modulo the use of randomness). 

The above result may appear a bit surprising as the complexity of equivalence testing for IMM and that for Det are quite different over rationals: a randomized polynomial-time equivalence testing for IMM over rationals is known [Kayal,Nair,Saha,Tavenas 2019], whereas [Garg,Gupta,Kayal,Saha 2019] showed that equivalence testing for Det over rationals is integer factoring hard (under randomized reductions and assuming GRH). To our knowledge, the complexity of equivalence testing for Tr-IMM was not known before this work. We show that, despite the syntactic similarity between IMM and Tr-IMM, equivalence testing for Tr-IMM and that for Det are randomized polynomial-time Turing reducible to each other over any field of characteristic zero or sufficiently large. The result is obtained by connecting the two problems via another well-studied problem in computer algebra, namely the full matrix algebra isomorphism problem (FMAI). In particular, we prove the following: 

1.Testing equivalence of polynomials to Tr-IMM$_{w,d}$, for $d\geq 3$ and $w\geq 2$, is randomized polynomial-time Turing reducible to testing equivalence of polynomials to Det$_w$, the determinant of the $w \times w$ matrix of formal variables. (Here, $d$ need not be a constant.)

2. FMAI is randomized polynomial-time Turing reducible to equivalence testing (in fact, to tensor isomorphism testing) for the family of matrix multiplication tensors $\{$Tr-IMM$_{w,3}\}_{w \in \mathbb{N}}$.

These results, in conjunction with the randomized poly-time reduction (shown in [GGKS19]) from determinant equivalence testing to FMAI, imply that the four problems - FMAI, equivalence testing for Tr-IMM and for Det, and the $3$-tensor isomorphism problem for the family of matrix multiplication tensors - are randomized poly-time equivalent under Turing reductions.</summary>
    <updated>2020-06-14T13:41:43Z</updated>
    <published>2020-06-14T13:41:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-27T22:46:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17191</id>
    <link href="https://rjlipton.wordpress.com/2020/06/13/proof-checking-not-line-by-line/" rel="alternate" type="text/html"/>
    <title>Proof Checking: Not Line by Line</title>
    <summary>Proofs and perpetual motion machines Leonardo da Vinci is, of course, famous for his paintings and drawings, but was also interested in inventions, and in various parts of science including mathematics and engineering. It is hard to imagine that he died over 500 years ago, given his continued impact on our world. He invented practical […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Proofs and perpetual motion machines</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2020/06/picture.png"><img alt="" class="alignright  wp-image-17193" height="150" src="https://rjlipton.files.wordpress.com/2020/06/picture.png?w=200&amp;h=150" width="200"/></a></p>
<p>
Leonardo da Vinci is, of course, famous for his paintings and drawings, but was also interested in inventions, and in various parts of science including mathematics and engineering. It is hard to imagine that he died over 500 years ago, given his continued impact on our world. He invented practical and impractical <a href="https://en.wikipedia.org/wiki/Leonardo_da_Vinci">inventions</a>: musical instruments, a mechanical knight, hydraulic pumps, reversible crank mechanisms, finned mortar shells, and a steam cannon.</p>
<p>
Today I wish to discuss proofs and perpetual motion machines.</p>
<p>
You might ask: <i>What do proofs and perpetual motion machines have in common?</i> Proofs refer to math proofs that claim to solve open problems like P <img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/> NP. Ken and I get such claims all time. I take a look at them, not because I think they are likely to be correct. Rather because I am interested in understanding how people think. </p>
<p>
I started to work on discussing such proofs when I realized that such “proofs” are related to claims about perpetual motion machines. Let’s see how.</p>
<p>
</p><p/><h2> Perpetual Motion Machines </h2><p/>
<p/><p>
A perpetual motion <a href="https://en.wikipedia.org/wiki/Perpetual_motion">machine</a> is a machine that operates indefinitely without an energy source. This kind of machine is impossible, as da Vinci knew already:</p>
<blockquote><p><b> </b> <em> Oh ye seekers after perpetual motion, how many vain chimeras have you pursued? Go and take your place with the alchemists. <br/>
—da Vinci, 1494 </em>
</p></blockquote>
<p/><p>
I like this statement about applying for US patents on such machines: </p>
<blockquote><p><b> </b> <em> Proposals for such inoperable machines have become so common that the United States Patent and Trademark Office (USPTO) has made an official policy of refusing to grant patents for perpetual motion machines without a working model. </em>
</p></blockquote>
<p/><p>
Here is a classic attempt at perpetual motion: The motion goes on “forever” since the right side floats up and the left side falls down. </p>
<p><a href="https://rjlipton.files.wordpress.com/2020/06/float.png"><img alt="" class="aligncenter size-full wp-image-17194" src="https://rjlipton.files.wordpress.com/2020/06/float.png?w=600"/></a></p>
<p>
The analogy of proofs and to perpetual motion machines is: The debunking such a machine is not done by looking carefully at each gear and lever to see why the machine fails to work. Rather is done like this: </p>
<blockquote><p><b> </b> <em> Your machine violates the fundamental laws of thermodynamics and is thus impossible. </em>
</p></blockquote>
<p>Candidate machines are not studied to find the exact flaw in their design. The force of fundamental laws allows a sweeping, simple, and powerful argument against them. There are similar ideas in checking a proof. Let’s take a look at them.</p>
<p>
</p><p/><h2> Proofs </h2><p/>
<p/><p>
Claims are made about proofs of open problems all the time. Often these are made for solutions to famous open problems, like P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/>NP or the Riemann Hypothesis (RH).</p>
<p>
Math proofs are used to try to get to the <i>truth</i>. As we said <a href="https://rjlipton.wordpress.com/2019/04/24/why-check-a-proof/">before</a> proofs are only as good as the assumptions made and the rules invoked. The beauty of the proof concept is that arguments can be checked, even long and complex ones. If the assumptions and the rules are correct, then no matter how strange the conclusion is, it must be true.</p>
<p>
For <a href="https://math.stackexchange.com/questions/2949/which-one-result-in-mathematics-has-surprised-you-the-most">example</a>:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The Riemann rearrangement <a href="https://en.wikipedia.org/wiki/Ri emann_series_theorem#Statement_of_the_theorem">theorem</a>. A sum 	</p>
<p align="center"><img alt="\displaystyle  a_{1} + a_{2} + a_{3} + \dots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a_%7B1%7D+%2B+a_%7B2%7D+%2B+a_%7B3%7D+%2B+%5Cdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  a_{1} + a_{2} + a_{3} + \dots "/></p>
<p>that is conditionally convergent can be reordered to yield any number. Thus there is series 	</p>
<p align="center"><img alt="\displaystyle  b_{1} + b_{2} + b_{3} + \dots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++b_%7B1%7D+%2B+b_%7B2%7D+%2B+b_%7B3%7D+%2B+%5Cdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  b_{1} + b_{2} + b_{3} + \dots "/></p>
<p>that sums conditionally to your favorite number <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> and yet the <img alt="{b_{1},b_{2},\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb_%7B1%7D%2Cb_%7B2%7D%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b_{1},b_{2},\dots}"/> is just a arrangement of the <img alt="{a_{1},a_{2},\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_%7B1%7D%2Ca_%7B2%7D%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_{1},a_{2},\dots}"/>. This says that addition is not commutative for infinite series.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Cover the largest triangle by two <a href="https://www2.stetson.edu/~efriedma/squcotri/">unit squares</a>: what is the best? The following shows that it is unexpected: </p>
<p/><p/>
<p><a href="https://rjlipton.files.wordpress.com/2020/06/cover.png"><img alt="" class="aligncenter size-full wp-image-17195" src="https://rjlipton.files.wordpress.com/2020/06/cover.png?w=600"/></a></p>
<p/><p><br/>
The point of a proof is that it is a series of small steps. If each step is correct, then the whole is correct. But in practice proofs are often checked in other ways.</p>
<p>
</p><p/><h2> Checking Proofs </h2><p/>
<p/><p>
The starting point for my thoughts—joined here with Ken’s—are these two issues:</p>
<ol>
<li>
A proof that <em>only</em> has many small steps but no global picture is hard to motivate. <p/>
</li><li>
A proof with complex logic at the high level is hard to understand.
</li></ol>
<p>
Note that a deep, hard theorem can still have straightforward logic. A famous <a href="https://en.wikipedia.org/wiki/Riemann_hypothesis#Littlewood's_theorem">theorem</a> of Littlewood has for its proof the structure:</p>
<ul>
<li>
Case the RH is false: Then <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/> <p/>
</li><li>
Case the RH is true: Then <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/>
</li></ul>
<p>
The RH-false case takes under a page. The benefit with this logic is that one gets to assume RH for the rest. The strategy for the famous proof by Andrew Wiles of Fermat’s Last Theorem (FLT)—incorporating the all-important fix by Richard Taylor—has this structure:</p>
<ul>
<li>
If <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> then <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>. <p/>
</li><li>
If not-<img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> then <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>. <p/>
</li><li>
<img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> implies FLT. <p/>
</li><li>
<img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/> implies FLT.
</li></ul>
<p>
Wiles had done the last step long before but had put aside since he didn’t know how to get <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>. The key was framing <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> so that it enabled bridged the gap in his originally-announced proof while its negation enabled the older proof.</p>
<p>
Thus what we should seek are proofs with simple logic at the high level that breaks into cases or into sequential sub-goals so that the proof is a chain or relatively few of those goals. </p>
<p>
</p><p/><h2> Shapes and Barriers </h2><p/>
<p/><p>
This makes Ken and I think again about an old <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.73.7682">paper</a> by Juris Hartmanis with his students Richard Chang, Desh Ranjan, and Pankaj Rohatgi in the May 1990 <em>Bulletin of the EATCS</em> titled, “On IP=PSPACE and Theorems With Narrow Proofs.” Ken’s <a href="https://rjlipton.wordpress.com/2015/05/17/the-shapes-of-computations/">post</a> on it included this nice diagram of what the paper calls “shapes of proofs”:</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/06/proofshapes.png"><img alt="" class="aligncenter  wp-image-17197" height="252" src="https://rjlipton.files.wordpress.com/2020/06/proofshapes.png?w=400&amp;h=252" width="400"/></a></p>
<p/><p><br/>
Ken’s thought now is that this taxonomy needs to be augmented with a proof shape corresponding to certain classes believed to be properly below polynomial time—classes within the <a href="https://en.wikipedia.org/wiki/NC_(complexity)">NC</a> hierarchy. Those proofs branch at the top into manageable-size subcases, and/or have a limited number of sequential stages, where each stage may be wide but is shallow in its chains of dependencies. Call this shape a “macro-tree.”</p>
<p>
The difference between the macro-tree shape and the sequential shapes pictured above is neatly captured by Ashley Ahlin on a <a href="http://www.math.wichita.edu/~pparker/classes/thms.htm">page</a> about “Reading Theorems”:</p>
<blockquote><p><b> </b> <em> Note that, in some ways, the easiest way to read a proof is to check that each step follows from the previous ones. This is a bit like following a game of chess by checking to see that each move was legal, or like running a spell-checker on an essay. It’s important, and necessary, but it’s not really the point. … The problem with this is that you are unlikely to remember anything about how to prove the theorem, if you’ve only read in this manner. Once you’re read a theorem and its proof, you can go back and ask some questions to help synthesize your understanding. </em>
</p></blockquote>
<p/><p>
The other high-level structure that a proof needs to make evident—before seeing it is reasonable to expend the effort to check it—is shaped by <em>barriers</em>. We have <a href="https://rjlipton.wordpress.com/2012/11/29/barriers-to-pnp-proofs/">touched</a> on <a href="https://rjlipton.wordpress.com/2013/03/13/no-go-theorems/">this</a> topic <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">several</a> <a href="https://rjlipton.wordpress.com/2019/04/18/a-reason-why-circuit-lower-bounds-are-hard/">times</a> but maybe have not stated it full on for P versus NP. A recent <a href="http://theory.stanford.edu/~liyang/teaching/projects/formal-barriers-to-proving-P-ne-NP.pdf">essay</a> for a course led by Li-Yang Tan at Stanford does so in just a few pages. A proof should state up front how it works around barriers, and this alone makes its strategy easier to follow.</p>
<p>
The idea of barriers extends outside P versus NP, of course. Peter Scholze seems to be invoking it in a <a href="https://www.math.columbia.edu/~woit/wordpress/?p=11709&amp;cpage=1#comment-235940">comment</a> two months ago in a <a href="https://www.math.columbia.edu/~woit/wordpress/?p=11709">post</a> by Peter Woit in April on the status of Shinichi Mochizuki’s claimed proof of the ABC conjecture:</p>
<blockquote><p><b> </b> <em> I may have not expressed this clearly enough in my manuscript with Stix, but there is just no way that anything like what Mochizuki does can work. … The reason it cannot work is a[nother] theorem of Mochizuki himself. … If the above claims [which are negated by the theorem] would have been true, I would see how Mochizuki’s strategy might have a nonzero chance of succeeding. … </em>
</p></blockquote>
<p/><p>
Thus what Ken and I conclude is that in order for a proof to be checkable <em>chunk by chunk</em>—not line by line—it needs to have:</p>
<ol>
<li>
A top-level decomposition into a relatively small number of components and stages—like legs in a sailing race—and <p/>
</li><li>
A demonstration of how the stages navigate around known barriers.
</li></ol>
<p>
Lack of a clear plan in the first already says the proof attempt cannot avoid being snagged on a barrier, as surely as natural laws prevent building a perpetual-motion machine.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Does this help in ascertaining what shape a proof that resolves the P versus NP problem must have?</p>
<p/></font></font></div>
    </content>
    <updated>2020-06-14T01:33:31Z</updated>
    <published>2020-06-14T01:33:31Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="P=NP"/>
    <category term="Proofs"/>
    <category term="Teaching"/>
    <category term="barriers"/>
    <category term="Leonardo da Vinci"/>
    <category term="perpetual motion"/>
    <category term="proof checking"/>
    <category term="shapes of proofs"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-06-27T22:47:04Z</updated>
    </source>
  </entry>
</feed>
