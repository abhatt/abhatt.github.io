<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-06-13T08:21:44Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.05266</id>
    <link href="http://arxiv.org/abs/1906.05266" rel="alternate" type="text/html"/>
    <title>The Tandem Duplication Distance is NP-hard</title>
    <feedworld_mtime>1560384000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lafond:Manuel.html">Manuel Lafond</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhu:Binhai.html">Binhai Zhu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zou:Peng.html">Peng Zou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.05266">PDF</a><br/><b>Abstract: </b>In computational biology, tandem duplication is an important biological
phenomenon which can occur either at the genome or at the DNA level. A tandem
duplication takes a copy of a genome segment and inserts it right after the
segment - this can be represented as the string operation $AXB \Rightarrow
AXXB$. For example, Tandem exon duplications have been found in many species
such as human, fly or worm, and have been largely studied in computational
biology. The Tandem Duplication (TD) distance problem we investigate in this
paper is defined as follows: given two strings $S$ and $T$ over the same
alphabet, compute the smallest sequence of tandem duplications required to
convert $S$ to $T$. The natural question of whether the TD distance can be
computed in polynomial time was posed in 2004 by Leupold et al. and had
remained open, despite the fact that tandem duplications have received much
attention ever since. In this paper, we prove that this problem is NP-hard. We
further show that this hardness holds even if all characters of $S$ are
distinct. This is known as the exemplar TD distance, which is of special
relevance in bioinformatics. One of the tools we develop for the reduction is a
new problem called the Cost-Effective Subgraph, for which we obtain
W[1]-hardness results that might be of independent interest. We finally show
that computing the exemplar TD distance between $S$ and $T$ is fixed-parameter
tractable. Our results open the door to many other questions, and we conclude
with several open problems.
</p></div>
    </summary>
    <updated>2019-06-13T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.05208</id>
    <link href="http://arxiv.org/abs/1906.05208" rel="alternate" type="text/html"/>
    <title>Sorted Top-k in Rounds</title>
    <feedworld_mtime>1560384000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Braverman:Mark.html">Mark Braverman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mao:Jieming.html">Jieming Mao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peres:Yuval.html">Yuval Peres</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.05208">PDF</a><br/><b>Abstract: </b>We consider the sorted top-$k$ problem whose goal is to recover the top-$k$
items with the correct order out of $n$ items using pairwise comparisons. In
many applications, multiple rounds of interaction can be costly. We restrict
our attention to algorithms with a constant number of rounds $r$ and try to
minimize the sample complexity, i.e. the number of comparisons.
</p>
<p>When the comparisons are noiseless, we characterize how the optimal sample
complexity depends on the number of rounds (up to a polylogarithmic factor for
general $r$ and up to a constant factor for $r=1$ or 2). In particular, the
sample complexity is $\Theta(n^2)$ for $r=1$, $\Theta(n\sqrt{k} + n^{4/3})$ for
$r=2$ and $\tilde{\Theta}\left(n^{2/r} k^{(r-1)/r} + n\right)$ for $r \geq 3$.
</p>
<p>We extend our results of sorted top-$k$ to the noisy case where each
comparison is correct with probability $2/3$. When $r=1$ or 2, we show that the
sample complexity gets an extra $\Theta(\log(k))$ factor when we transition
from the noiseless case to the noisy case.
</p>
<p>We also prove new results for top-$k$ and sorting in the noisy case. We
believe our techniques can be generally useful for understanding the trade-off
between round complexities and sample complexities of rank aggregation
problems.
</p></div>
    </summary>
    <updated>2019-06-13T01:23:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.05170</id>
    <link href="http://arxiv.org/abs/1906.05170" rel="alternate" type="text/html"/>
    <title>Efficient Graph Rewriting</title>
    <feedworld_mtime>1560384000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Campbell:Graham.html">Graham Campbell</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.05170">PDF</a><br/><b>Abstract: </b>Graph transformation is the rule-based modification of graphs, and is a
discipline dating back to the 1970s. The declarative nature of graph rewriting
rules comes at a cost. In general, to match the left-hand graph of a fixed rule
within a host graph requires polynomial time. To improve matching performance,
D\"orr proposed to equip rules and host graphs with distinguished root nodes.
This model was implemented by Plump and Bak, but unfortunately, is not
invertible. We address this problem by defining rootedness using a partial
function onto a two-point set rather than pointing graphs with root nodes. We
show a new result that the graph class of trees can be recognised by a rooted
GT system in linear time, given an input graph of bounded degree. Finally, we
define a new notion of confluence modulo garbage and non-garbage critical
pairs, showing it is sufficient to require strong joinability of only the
non-garbage critical pairs to establish confluence modulo garbage.
</p></div>
    </summary>
    <updated>2019-06-13T01:20:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-06-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.05005</id>
    <link href="http://arxiv.org/abs/1906.05005" rel="alternate" type="text/html"/>
    <title>Approximating the Orthogonality Dimension of Graphs and Hypergraphs</title>
    <feedworld_mtime>1560384000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haviv:Ishay.html">Ishay Haviv</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.05005">PDF</a><br/><b>Abstract: </b>A $t$-dimensional orthogonal representation of a hypergraph is an assignment
of nonzero vectors in $\mathbb{R}^t$ to its vertices, such that every hyperedge
contains two vertices whose vectors are orthogonal. The orthogonality dimension
of a hypergraph $H$, denoted by $\overline{\xi}(H)$, is the smallest integer
$t$ for which there exists a $t$-dimensional orthogonal representation of $H$.
In this paper we study computational aspects of the orthogonality dimension of
graphs and hypergraphs. We prove that for every $k \geq 4$, it is
$\mathsf{NP}$-hard (resp. quasi-$\mathsf{NP}$-hard) to distinguish $n$-vertex
$k$-uniform hypergraphs $H$ with $\overline{\xi}(H) \leq 2$ from those
satisfying $\overline{\xi}(H) \geq \Omega(\log^\delta n)$ for some constant
$\delta&gt;0$ (resp. $\overline{\xi}(H) \geq \Omega(\log^{1-o(1)} n)$). For
graphs, we relate the $\mathsf{NP}$-hardness of approximating the orthogonality
dimension to a variant of a long-standing conjecture of Stahl. We also consider
the algorithmic problem in which given a graph $G$ with $\overline{\xi}(G) \leq
3$ the goal is to find an orthogonal representation of $G$ of as low dimension
as possible, and provide a polynomial time approximation algorithm based on
semidefinite programming.
</p></div>
    </summary>
    <updated>2019-06-13T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04899</id>
    <link href="http://arxiv.org/abs/1906.04899" rel="alternate" type="text/html"/>
    <title>Prophet Inequalities on the Intersection of a Matroid and a Graph</title>
    <feedworld_mtime>1560384000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jackie Baek, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Ma:Will.html">Will Ma</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04899">PDF</a><br/><b>Abstract: </b>We consider prophet inequalities in a setting where agents correspond to both
elements in a matroid and vertices in a graph. A set of agents is feasible if
they form both an independent set in the matroid and an independent set in the
graph. Our main result is an ex-ante 1/(2d+2)-prophet inequality, where d is a
graph parameter upper-bounded by the maximum size of an independent set in the
neighborhood of any vertex.
</p>
<p>We establish this result through a framework that sets both dynamic prices
for elements in the matroid (using the method of balanced thresholds), and
static but discriminatory prices for vertices in the graph (motivated by recent
developments in approximate dynamic programming). The threshold for accepting
an agent is then the sum of these two prices.
</p>
<p>We show that for graphs induced by a certain family of interval-scheduling
constraints, the value of d is 1. Our framework thus provides the first
constant-factor prophet inequality when there are both matroid-independence
constraints and interval-scheduling constraints. It also unifies and improves
several results from the literature, leading to a 1/2-prophet inequality when
agents have XOS valuation functions over a set of items and use them for a
finite interval duration, and more generally, a 1/(d+1)-prophet inequality when
these items each require a bundle of d resources to procure.
</p></div>
    </summary>
    <updated>2019-06-13T01:28:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04897</id>
    <link href="http://arxiv.org/abs/1906.04897" rel="alternate" type="text/html"/>
    <title>Prefix Block-Interchanges on Binary and Ternary Strings</title>
    <feedworld_mtime>1560384000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rahman:Md=_Khaledur.html">Md. Khaledur Rahman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rahman:M=_Sohel.html">M. Sohel Rahman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04897">PDF</a><br/><b>Abstract: </b>The genome rearrangement problem computes the minimum number of operations
that are required to sort all elements of a permutation. A block-interchange
operation exchanges two blocks of a permutation which are not necessarily
adjacent and in a prefix block-interchange, one block is always the prefix of
that permutation. In this paper, we focus on applying prefix block-interchanges
on binary and ternary strings. We present upper bounds to group and sort a
given binary/ternary string. We also provide upper bounds for a different
version of the block-interchange operation which we refer to as the `restricted
prefix block-interchange'. We observe that our obtained upper bound for
restricted prefix block-interchange operations on binary strings is better than
that of other genome rearrangement operations to group fully normalized binary
strings. Consequently, we provide a linear-time algorithm to solve the problem
of grouping binary normalized strings by restricted prefix block-interchanges.
We also provide a polynomial time algorithm to group normalized ternary strings
by prefix block-interchange operations. Finally, we provide a classification
for ternary strings based on the required number of prefix block-interchange
operations.
</p></div>
    </summary>
    <updated>2019-06-13T01:27:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04845</id>
    <link href="http://arxiv.org/abs/1906.04845" rel="alternate" type="text/html"/>
    <title>Discrepancy, Coresets, and Sketches in Machine Learning</title>
    <feedworld_mtime>1560384000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Zohar Karnin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liberty:Edo.html">Edo Liberty</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04845">PDF</a><br/><b>Abstract: </b>This paper defines the notion of class discrepancy for families of functions.
It shows that low discrepancy classes admit small offline and streaming
coresets. We provide general techniques for bounding the class discrepancy of
machine learning problems. As corollaries of the general technique we bound the
discrepancy (and therefore coreset complexity) of logistic regression, sigmoid
activation loss, matrix covariance, kernel density and any analytic function of
the dot product or the squared distance. Our results prove the existence of
epsilon-approximation O(sqrt{d}/epsilon) sized coresets for the above problems.
This resolves the long-standing open problem regarding the coreset complexity
of Gaussian kernel density estimation. We provide two more related but
independent results. First, an exponential improvement of the widely used
merge-and-reduce trick which gives improved streaming sketches for any low
discrepancy problem. Second, an extremely simple deterministic algorithm for
finding low discrepancy sequences (and therefore coresets) for any positive
semi-definite kernel. This paper establishes some explicit connections between
class discrepancy, coreset complexity, learnability, and streaming algorithms.
</p></div>
    </summary>
    <updated>2019-06-13T01:22:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04842</id>
    <link href="http://arxiv.org/abs/1906.04842" rel="alternate" type="text/html"/>
    <title>Similarity Problems in High Dimensions</title>
    <feedworld_mtime>1560384000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Johan von Tangen Sivertsen <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04842">PDF</a><br/><b>Abstract: </b>The main contribution of this dissertation is the introduction of new or
improved approximation algorithms and data structures for several similarity
search problems. We examine the furthest neighbor query, the annulus query,
distance sensitive membership, nearest neighbor preserving embeddings and set
similarity queries in the large-scale, high-dimensional setting.
</p></div>
    </summary>
    <updated>2019-06-13T01:22:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04840</id>
    <link href="http://arxiv.org/abs/1906.04840" rel="alternate" type="text/html"/>
    <title>Weighted, Bipartite, or Directed Stream Graphs for the Modeling of Temporal Networks</title>
    <feedworld_mtime>1560384000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Latapy:Matthieu.html">Matthieu Latapy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Magnien:Cl=eacute=mence.html">Clémence Magnien</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Viard:Tiphaine.html">Tiphaine Viard</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04840">PDF</a><br/><b>Abstract: </b>We recently introduced a formalism for the modeling of temporal networks,
that we call stream graphs. It emphasizes the streaming nature of data and
allows rigorous definitions of many important concepts generalizing classical
graphs. This includes in particular size, density, clique, neighborhood,
degree, clustering coefficient, and transitivity. In this contribution, we show
that, like graphs, stream graphs may be extended to cope with bipartite
structures, with node and link weights, or with link directions. We review the
main bipartite, weighted or directed graph concepts proposed in the literature,
we generalize them to the cases of bipartite, weighted, or directed stream
graphs, and we show that obtained concepts are consistent with graph and stream
graph ones. This provides a formal ground for an accurate modeling of the many
temporal networks that have one or several of these features.
</p></div>
    </summary>
    <updated>2019-06-13T01:22:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04832</id>
    <link href="http://arxiv.org/abs/1906.04832" rel="alternate" type="text/html"/>
    <title>UnLimited TRAnsfers for Multi-Modal Route Planning: An Efficient Solution</title>
    <feedworld_mtime>1560384000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Baum:Moritz.html">Moritz Baum</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Buchhold:Valentin.html">Valentin Buchhold</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sauer:Jonas.html">Jonas Sauer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wagner:Dorothea.html">Dorothea Wagner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Z=uuml=ndorf:Tobias.html">Tobias Zündorf</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04832">PDF</a><br/><b>Abstract: </b>We study a multi-modal route planning scenario consisting of a public transit
network and a transfer graph representing a secondary transportation mode
(e.g., walking or taxis). The objective is to compute all journeys that are
Pareto-optimal with respect to arrival time and the number of required
transfers. While various existing algorithms can efficiently compute optimal
journeys in either a pure public transit network or a pure transfer graph,
combining the two increases running times significantly. As a result, even
walking between stops is typically limited by a maximal duration or distance,
or by requiring the transfer graph to be transitively closed. To overcome these
shortcomings, we propose a novel preprocessing technique called ULTRA
(UnLimited TRAnsfers): Given a complete transfer graph (without any
limitations, representing an arbitrary non-schedule-based mode of
transportation), we compute a small number of transfer shortcuts that are
provably sufficient for computing all Pareto-optimal journeys. We demonstrate
the practicality of our approach by showing that these transfer shortcuts can
be integrated into a variety of state-of-the-art public transit algorithms,
establishing the ULTRA-Query algorithm family. Our extensive experimental
evaluation shows that ULTRA is able to improve these algorithms from limited to
unlimited transfers without sacrificing query speed, yielding the fastest known
algorithms for multi-modal routing. This is true not just for walking, but also
for other transfer modes such as cycling or driving.
</p></div>
    </summary>
    <updated>2019-06-13T01:24:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15989</id>
    <link href="https://rjlipton.wordpress.com/2019/06/12/how-to-make-a-polynomial-map-nicer/" rel="alternate" type="text/html"/>
    <title>How To Make A Polynomial Map Nicer</title>
    <summary>Stability theory and polynomials [ Essen ] Arno van den Essen is the author of the book on the Jacobian Conjecture. Today I want to highlight one of the ideas he presents in his book. The theory is sometimes called stabilization methods. Or K-theory methods. It is often used in connection with the famous Jacobian […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Stability theory and polynomials</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/06/12/how-to-make-a-polynomial-map-nicer/essen/" rel="attachment wp-att-15990"><img alt="" class="alignright size-full wp-image-15990" src="https://rjlipton.files.wordpress.com/2019/06/essen.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Essen ]</font></td>
</tr>
</tbody>
</table>
<p>
Arno van den Essen is the author of <b>the</b> book on the Jacobian Conjecture.</p>
<p>
Today I want to highlight one of the ideas he presents in his <a href="https://www.springer.com/gp/book/9783764363505">book</a>.</p>
<p>
The theory is sometimes called stabilization methods. Or K-theory methods. It is often used in connection with the famous Jacobian conjecture (JC). I will not say any more about JC now—see <a href="https://rjlipton.wordpress.com/2014/01/29/progress-on-the-jacobian-conjecture/">this</a> for some comments we made a while ago. </p>
<p>
</p><p/><h2> The Stability Philosophy </h2><p/>
<p/><p>
Essen states that the philosophy of stability theory is: </p>
<blockquote><p><b> </b> <em> <i>It is possible to change a map <img alt="{F: \mathbb{K}^{n} \rightarrow \mathbb{K}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%3A+%5Cmathbb%7BK%7D%5E%7Bn%7D+%5Crightarrow+%5Cmathbb%7BK%7D%5E%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F: \mathbb{K}^{n} \rightarrow \mathbb{K}^{n}}"/> and make it “nicer” provided we allow <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> to be increased</i>.<img alt="{^{\dagger}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5E%7B%5Cdagger%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{^{\dagger}}"/> </em>
</p></blockquote>
<p/><p>
<img alt="\rule{0.4\textwidth}{0.4pt}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crule%7B0.4%5Ctextwidth%7D%7B0.4pt%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rule{0.4\textwidth}{0.4pt}"/></p>
<p>
<img alt="{(\dagger)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cdagger%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\dagger)}"/> Not a direct quote.</p>
<p>
That is provided we can change <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> to 	</p>
<p align="center"><img alt="\displaystyle  \tilde{F} : \mathbb{K}^{N} \rightarrow \mathbb{K}^{N} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctilde%7BF%7D+%3A+%5Cmathbb%7BK%7D%5E%7BN%7D+%5Crightarrow+%5Cmathbb%7BK%7D%5E%7BN%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \tilde{F} : \mathbb{K}^{N} \rightarrow \mathbb{K}^{N} "/></p>
<p>where <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> is larger than <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. The whole method is based on a simple observation. Suppose that <img alt="{F: \mathbb{K}^{n} \rightarrow \mathbb{K}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%3A+%5Cmathbb%7BK%7D%5E%7Bn%7D+%5Crightarrow+%5Cmathbb%7BK%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F: \mathbb{K}^{n} \rightarrow \mathbb{K}^{n}}"/> and define <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> by 	</p>
<p align="center"><img alt="\displaystyle  G(x_{1},\dots,x_{n},u_{1},\dots,u_{N-n}) = (F(x_{1},\dots,x_{n}), u_{1},\dots,u_{N-n}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++G%28x_%7B1%7D%2C%5Cdots%2Cx_%7Bn%7D%2Cu_%7B1%7D%2C%5Cdots%2Cu_%7BN-n%7D%29+%3D+%28F%28x_%7B1%7D%2C%5Cdots%2Cx_%7Bn%7D%29%2C+u_%7B1%7D%2C%5Cdots%2Cu_%7BN-n%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  G(x_{1},\dots,x_{n},u_{1},\dots,u_{N-n}) = (F(x_{1},\dots,x_{n}), u_{1},\dots,u_{N-n}). "/></p>
<p>Then <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is injective if and only if <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is injective. This is trivial—really trivial. From trivial observations sometimes important methods are created. </p>
<p>
I will now explain how why this is useful by presenting an example. </p>
<p>
</p><p/><h2> The Method: By Example </h2><p/>
<p/><p>
Suppose that 	</p>
<p align="center"><img alt="\displaystyle  F: \mathbb{K}^{2} \rightarrow \mathbb{K}^{2} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F%3A+%5Cmathbb%7BK%7D%5E%7B2%7D+%5Crightarrow+%5Cmathbb%7BK%7D%5E%7B2%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  F: \mathbb{K}^{2} \rightarrow \mathbb{K}^{2} "/></p>
<p>is a polynomial mapping where 	</p>
<p align="center"><img alt="\displaystyle  F(x,y) = (f(x,y),g(x,y)). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F%28x%2Cy%29+%3D+%28f%28x%2Cy%29%2Cg%28x%2Cy%29%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  F(x,y) = (f(x,y),g(x,y)). "/></p>
<p>We wish to show that we can replace <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> by another polynomial map <img alt="{\tilde F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde F}"/> that has degree at most <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/>. Moreover, the new polynomial map is injective if and only if the original polynomial map is injective. The method can be used to preserve other properties of the polynomial mapping, but being injective is a important example. </p>
<p>
There seems to be no way to lower the degree of <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> without destroying its structure. But if we use the stability philosophy and allow extra dimensions we can succeed. That is we replace <img alt="{F(x,y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(x,y)}"/> by the function 	</p>
<p align="center"><img alt="\displaystyle  \tilde{F}(x,y,u,v) = (f(x,y),g(x,y),u,v). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctilde%7BF%7D%28x%2Cy%2Cu%2Cv%29+%3D+%28f%28x%2Cy%29%2Cg%28x%2Cy%29%2Cu%2Cv%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \tilde{F}(x,y,u,v) = (f(x,y),g(x,y),u,v). "/></p>
<p>Why does this work? The idea is that the extra two dimensions can be used as extra <i>registers</i>. These registers can be used to simplify the computation, and reduce the degree of <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/>. </p>
<p>
Let <img alt="{f(x,y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x,y)}"/> have one term that we wish to remove. To be concrete, let’s assume the term is 	</p>
<p align="center"><img alt="\displaystyle  x^{3}y. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7B3%7Dy.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x^{3}y. "/></p>
<p>Start with the input 	</p>
<p align="center"><img alt="\displaystyle  (x,y,u,v). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28x%2Cy%2Cu%2Cv%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (x,y,u,v). "/></p>
<p>Now change this to 	</p>
<p align="center"><img alt="\displaystyle  (x,y,u+P,v+Q), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28x%2Cy%2Cu%2BP%2Cv%2BQ%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (x,y,u+P,v+Q), "/></p>
<p>where 	</p>
<p align="center"><img alt="\displaystyle  P=x^{2} \text{ and } Q=xy. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P%3Dx%5E%7B2%7D+%5Ctext%7B+and+%7D+Q%3Dxy.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  P=x^{2} \text{ and } Q=xy. "/></p>
<p>This is an invertible transformation. Note this is only possible because we have two extra dimensions or registers. Otherwise, we could not compute <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> and <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> without messing up the rest of the computation. Now map this to 	</p>
<p align="center"><img alt="\displaystyle  (f(x,y),g(x,y),u+P,v+Q). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28f%28x%2Cy%29%2Cg%28x%2Cy%29%2Cu%2BP%2Cv%2BQ%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (f(x,y),g(x,y),u+P,v+Q). "/></p>
<p>This is nothing more than computing the original function and ignoring the new registers. </p>
<p>
The next step is to go to 	</p>
<p align="center"><img alt="\displaystyle  (f-(u+P)(v+Q),g,u+Pv+Q). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28f-%28u%2BP%29%28v%2BQ%29%2Cg%2Cu%2BPv%2BQ%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (f-(u+P)(v+Q),g,u+Pv+Q). "/></p>
<p>The last point is that 	</p>
<p align="center"><img alt="\displaystyle  f- (u+P)(v+Q), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f-+%28u%2BP%29%28v%2BQ%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f- (u+P)(v+Q), "/></p>
<p>cancels the term <img alt="{x^{3}y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7B3%7Dy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^{3}y}"/> we wished to remove. 	</p>
<p align="center"><img alt="\displaystyle  f- PQ -uQ -vP-uv = f-x^{2}xy -uxy - vx^{2}-uv. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f-+PQ+-uQ+-vP-uv+%3D+f-x%5E%7B2%7Dxy+-uxy+-+vx%5E%7B2%7D-uv.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f- PQ -uQ -vP-uv = f-x^{2}xy -uxy - vx^{2}-uv. "/></p>
<p>The price we pay is that new terms have been added, but they have at most degree <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/>. </p>
<p>
</p><p/><h2> The Method: General Case </h2><p/>
<p/><p>
We can prove by induction the following general theorem: </p>
<blockquote><p><b>Theorem 1</b> <em> Suppose <img alt="{F: \mathbb{K}^{n} \rightarrow \mathbb{K}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%3A+%5Cmathbb%7BK%7D%5E%7Bn%7D+%5Crightarrow+%5Cmathbb%7BK%7D%5E%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F: \mathbb{K}^{n} \rightarrow \mathbb{K}^{n}}"/> is polynomial map where <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{K}"/> is a field. Then we can construct a polynomial map of degree at most <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{3}"/> denoted by <img alt="{\tilde F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde+F%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\tilde F}"/> so that it is injective precisely when <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> is injective. </em>
</p></blockquote>
<p/><p>
Even stronger theorems are possible. For example, the polynomial map <img alt="{\tilde F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde F}"/> can be required to be cubic linear: </p>
<blockquote><p><b>Definition 2</b> <em> Suppose that <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> is in <img alt="{n \times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Ctimes+n%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n \times n}"/> matrix over the field <img alt="{\mathbb{K}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BK%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathbb{K}}"/>. The <img alt="{F_{A}(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF_%7BA%7D%28X%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F_{A}(X)}"/> is the <b>cubic linear</b> map for the matrix <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> is defined to be the map <img alt="{F_{A}: \mathbb{K}^{n} \rightarrow \mathbb{K}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF_%7BA%7D%3A+%5Cmathbb%7BK%7D%5E%7Bn%7D+%5Crightarrow+%5Cmathbb%7BK%7D%5E%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F_{A}: \mathbb{K}^{n} \rightarrow \mathbb{K}^{n}}"/> 	</em></p><em>
<p align="center"><img alt="\displaystyle  X \rightarrow X + (AX)^{*3}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X+%5Crightarrow+X+%2B+%28AX%29%5E%7B%2A3%7D%2C+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  X \rightarrow X + (AX)^{*3}, "/></p>
</em><p><em>where <img alt="{Y^{*3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%5E%7B%2A3%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{Y^{*3}}"/> is defined to be the vector <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{Z}"/> so that <img alt="{Z_{k} = Y_{k}^{3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ_%7Bk%7D+%3D+Y_%7Bk%7D%5E%7B3%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{Z_{k} = Y_{k}^{3}}"/> for all coordinates <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k}"/>. </em>
</p></blockquote>
<p/><p>
See Essen’s book for more details. Note a cubic linear map when <img alt="{n=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=2}"/> is of the form: 	</p>
<p align="center"><img alt="\displaystyle  ( x + ( ax + by)^{3}, y + (cx + dy)^{3} ) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28+x+%2B+%28+ax+%2B+by%29%5E%7B3%7D%2C+y+%2B+%28cx+%2B+dy%29%5E%7B3%7D+%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  ( x + ( ax + by)^{3}, y + (cx + dy)^{3} ) "/></p>
<p>where <img alt="{a,b,c,d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%2Cd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a,b,c,d}"/> are constants. This reduction to cubic linear maps is quite pretty, and requires a clever application of the stabilization method.</p>
<p>
</p><p/><h2> A Limit of The Method </h2><p/>
<p/><p>
The reduction in degree is possible only to degree <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/>. It cannot be reduced to degree <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> in general. Let’s look at the intuition why this is true. The last step is 	</p>
<p align="center"><img alt="\displaystyle  f- (u+P)(v+Q) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f-+%28u%2BP%29%28v%2BQ%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f- (u+P)(v+Q) "/></p>
<p>which is 	</p>
<p align="center"><img alt="\displaystyle  f- PQ -uQ -vP. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f-+PQ+-uQ+-vP.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f- PQ -uQ -vP. "/></p>
<p>Suppose <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> has a leading term of degree <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/>. Also suppose that <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> has degree <img alt="{d_{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_{P}}"/> and <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> has degree <img alt="{d_{Q}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7BQ%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_{Q}}"/>. Then 	</p>
<p align="center"><img alt="\displaystyle  d = d_{P} + d_{Q} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d+%3D+d_%7BP%7D+%2B+d_%7BQ%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  d = d_{P} + d_{Q} "/></p>
<p>since the leading term goes away. But <img alt="{uQ}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BuQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{uQ}"/> and <img alt="{vP}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BvP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{vP}"/> have degrees <img alt="{d_{P}+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7BP%7D%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_{P}+1}"/> and <img alt="{d_{Q}+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7BQ%7D%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_{Q}+1}"/> respectively. So to keep <img alt="{d_{P}+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7BP%7D%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_{P}+1}"/> and <img alt="{d_{Q}+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7BQ%7D%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_{Q}+1}"/> both <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> or less, it follows that <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> can be at most <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>. However, in this case a term of degree <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> is removed and other terms of degree <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> are added. This is not a formal proof that the method cannot reduce the degree to <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>. I do believe that formalized properly it is a theorem that reduction to degree <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> is in general impossible. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I like this technology. I wonder if it might be possible to use it on some of our favorite problems. I do like that it conserves invertibility. This seems like it could be related to quantum computing, because of the reversible nature of quantum computing. </p>
<p/></font></font></div>
    </content>
    <updated>2019-06-12T20:31:41Z</updated>
    <published>2019-06-12T20:31:41Z</published>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Proofs"/>
    <category term="cubic"/>
    <category term="cubic linear"/>
    <category term="jacobian conjecture"/>
    <category term="polynomial maps"/>
    <category term="redcution"/>
    <category term="stable"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-06-13T08:20:40Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8019500166163846173</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8019500166163846173/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/compressing-in-moscow.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8019500166163846173" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8019500166163846173" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/compressing-in-moscow.html" rel="alternate" type="text/html"/>
    <title>Compressing in Moscow</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="separator" style="clear: both; text-align: center;">
</div>
<div class="separator" style="clear: both; text-align: center;">
<a href="https://1.bp.blogspot.com/-Bisdr756vxM/XQDylk3YrYI/AAAAAAABozI/M1FgKQZyX08bscqjoy9wmF8BxtXG86RLACLcBGAs/s1600/Vereshchagin.jpg" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img border="0" src="https://1.bp.blogspot.com/-Bisdr756vxM/XQDylk3YrYI/AAAAAAABozI/M1FgKQZyX08bscqjoy9wmF8BxtXG86RLACLcBGAs/s1600/Vereshchagin.jpg"/></a><a href="https://1.bp.blogspot.com/-G6yjxH8R1pU/XQDylvxG2aI/AAAAAAABozE/P54lQPWWEa46pTgyDEi6QWQOsaWLxP5zwCLcBGAs/s1600/Shen.jpg" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img border="0" src="https://1.bp.blogspot.com/-G6yjxH8R1pU/XQDylvxG2aI/AAAAAAABozE/P54lQPWWEa46pTgyDEi6QWQOsaWLxP5zwCLcBGAs/s1600/Shen.jpg"/></a></div>
<br/>
This week finds me in Moscow for a pair of workshops, the <a href="https://mipt.ru/education/chairs/dm/conferences/workshop-june-9-11-moscow-2019.php">Russian Workshop on Complexity and Model Theory</a> and a workshop on <a href="https://www.poncelet.ru/conference/ric">Randomness, Information and Complexity</a>. The latter celebrates the lives of Alexander Shen and Nikolay Vereshchagin on their 60th birthdays.<br/>
<br/>
Alexander Shen might be best known in computational complexity for his <a href="https://doi.org/10.1145/146585.146613">alternate proof</a> of IP = PSPACE. In 1989, Lund, Fortnow, Karloff and Nisan gave an interactive proof for the permanent, which got the entire polynomial-time hierarchy by Toda's theorem. But we didn't know how to push the protocol to PSPACE, we had a problem keeping degrees of polynomials low. Shamir had the first proof by looking at a specific protocol for PSPACE. Shen had the brilliant but simple idea to use a degree reducing operator, taking the polynomial modulo x<sup>2</sup>-x. The three papers appeared <a href="https://dl.acm.org/citation.cfm?id=146585#prox">back-to-back-to-back</a> in JACM.<br/>
<br/>
Shen and Vereshchagin though made their careers with their extensive work on Kolmogorov complexity and entropy, often together. Vereshchagin and I have co-authored some papers together during our mutual trips to Amsterdam, including on <a href="http://doi.org/10.1007/11672142_10">Kolmogorov Complexity with Errors</a> and how to <a href="http://doi.org/10.1007/b106485">increase Kolmogorov Complexity</a>. My <a href="https://doi.org/10.1006/jcss.1999.1677">favorite work</a> of Shen and Vereshchagin, which they did with Daniel Hammer and Andrei Romashchenko showed that every linear inequality that holds for entropy also holds for Kolmogorov complexity and vice-versa, the best argument that the two notions of information, one based on distributions, the other based on strings, share strong connections.<br/>
<br/>
Today is <a href="https://en.wikipedia.org/wiki/Russia_Day">Russia Day</a> that celebrates the reestablishment of Russia out of the Soviet Union in 1990. Just like how the British celebrate their succession from the US in 1776 I guess. But I'm celebrating Russia day by honoring these two great Russians. Congrats Sasha and Kolya!</div>
    </content>
    <updated>2019-06-12T16:27:00Z</updated>
    <published>2019-06-12T16:27:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-06-13T02:34:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04709</id>
    <link href="http://arxiv.org/abs/1906.04709" rel="alternate" type="text/html"/>
    <title>Communication and Memory Efficient Testing of Discrete Distributions</title>
    <feedworld_mtime>1560297600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diakonikolas:Ilias.html">Ilias Diakonikolas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gouleakis:Themis.html">Themis Gouleakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kane:Daniel_M=.html">Daniel M. Kane</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rao:Sankeerth.html">Sankeerth Rao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04709">PDF</a><br/><b>Abstract: </b>We study distribution testing with communication and memory constraints in
the following computational models: (1) The {\em one-pass streaming model}
where the goal is to minimize the sample complexity of the protocol subject to
a memory constraint, and (2) A {\em distributed model} where the data samples
reside at multiple machines and the goal is to minimize the communication cost
of the protocol. In both these models, we provide efficient algorithms for
uniformity/identity testing (goodness of fit) and closeness testing (two sample
testing). Moreover, we show nearly-tight lower bounds on (1) the sample
complexity of any one-pass streaming tester for uniformity, subject to the
memory constraint, and (2) the communication cost of any uniformity testing
protocol, in a restricted `one-pass' model of communication.
</p></div>
    </summary>
    <updated>2019-06-12T23:36:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04661</id>
    <link href="http://arxiv.org/abs/1906.04661" rel="alternate" type="text/html"/>
    <title>Faster Algorithms for High-Dimensional Robust Covariance Estimation</title>
    <feedworld_mtime>1560297600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheng:Yu.html">Yu Cheng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diakonikolas:Ilias.html">Ilias Diakonikolas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ge:Rong.html">Rong Ge</a>, David Woodruff <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04661">PDF</a><br/><b>Abstract: </b>We study the problem of estimating the covariance matrix of a
high-dimensional distribution when a small constant fraction of the samples can
be arbitrarily corrupted. Recent work gave the first polynomial time algorithms
for this problem with near-optimal error guarantees for several natural
structured distributions. Our main contribution is to develop faster algorithms
for this problem whose running time nearly matches that of computing the
empirical covariance.
</p>
<p>Given $N = \tilde{\Omega}(d^2/\epsilon^2)$ samples from a $d$-dimensional
Gaussian distribution, an $\epsilon$-fraction of which may be arbitrarily
corrupted, our algorithm runs in time
$\tilde{O}(d^{3.26})/\mathrm{poly}(\epsilon)$ and approximates the unknown
covariance matrix to optimal error up to a logarithmic factor. Previous robust
algorithms with comparable error guarantees all have runtimes
$\tilde{\Omega}(d^{2 \omega})$ when $\epsilon = \Omega(1)$, where $\omega$ is
the exponent of matrix multiplication. We also provide evidence that improving
the running time of our algorithm may require new algorithmic techniques.
</p></div>
    </summary>
    <updated>2019-06-12T23:38:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04572</id>
    <link href="http://arxiv.org/abs/1906.04572" rel="alternate" type="text/html"/>
    <title>Study of Compressed Randomized UTV Decompositions for Low-Rank Matrix Approximations in Data Science</title>
    <feedworld_mtime>1560297600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>M. Kaloorazi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lamare:R=_C=_de.html">R. C. de Lamare</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04572">PDF</a><br/><b>Abstract: </b>In this work, a novel rank-revealing matrix decomposition algorithm termed
Compressed Randomized UTV (CoR-UTV) decomposition along with a CoR-UTV variant
aided by the power method technique is proposed. CoR-UTV computes an
approximation to a low-rank input matrix by making use of random sampling
schemes. Given a large and dense matrix of size $m\times n$ with numerical rank
$k$, where $k \ll \text{min} \{m,n\}$, CoR-UTV requires a few passes over the
data, and runs in $O(mnk)$ floating-point operations. Furthermore, CoR-UTV can
exploit modern computational platforms and can be optimized for maximum
efficiency. CoR-UTV is also applied for solving robust principal component
analysis problems. Simulations show that CoR-UTV outperform existing
approaches.
</p></div>
    </summary>
    <updated>2019-06-12T23:35:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04523</id>
    <link href="http://arxiv.org/abs/1906.04523" rel="alternate" type="text/html"/>
    <title>A Linear Algorithm for Minimum Dominator Colorings of Orientations of Paths</title>
    <feedworld_mtime>1560297600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cary:Michael.html">Michael Cary</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04523">PDF</a><br/><b>Abstract: </b>In this paper we present an algorithm for finding a minimum dominator
coloring of orientations of paths. To date this is the first algorithm for
dominator colorings of digraphs in any capacity. We prove that the algorithm
always provides a minimum dominator coloring of an oriented path and show that
it runs in $\mathcal{O}(n)$ time. The algorithm is available at
\url{https://github.com/cat-astrophic/MDC-orientations_of_paths/}.
</p></div>
    </summary>
    <updated>2019-06-12T23:40:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04468</id>
    <link href="http://arxiv.org/abs/1906.04468" rel="alternate" type="text/html"/>
    <title>Rearrangement operations on unrooted phylogenetic networks</title>
    <feedworld_mtime>1560297600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Janssen:Remie.html">Remie Janssen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klawitter:Jonathan.html">Jonathan Klawitter</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04468">PDF</a><br/><b>Abstract: </b>Rearrangement operations transform a phylogenetic tree into another one and
hence induce a metric on the space of phylogenetic trees. Popular operations
for unrooted phylogenetic trees are NNI (nearest neighbour interchange), SPR
(subtree prune and regraft), and TBR (tree bisection and reconnection).
Recently, these operations have been extended to unrooted phylogenetic
networks, which are generalisations of phylogenetic trees that can model
reticulated evolutionary relationships. Here, we study global and local
properties of spaces of phylogenetic networks under these three operations. In
particular, we prove connectedness and asymptotic bounds on the diameters of
spaces of different classes of phylogenetic networks, including tree-based and
level-$k$ networks. We also examine the behaviour of shortest TBR-sequence
between two phylogenetic networks in a class, and whether the TBR-distance
changes if intermediate networks from other classes are allowed: for example,
the space of phylogenetic trees is an isometric subgraph of the space of
phylogenetic networks under TBR. Lastly, we show that computing the
TBR-distance and the PR-distance of two phylogenetic networks is NP-hard.
</p></div>
    </summary>
    <updated>2019-06-12T23:36:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04449</id>
    <link href="http://arxiv.org/abs/1906.04449" rel="alternate" type="text/html"/>
    <title>Almost Optimal Semi-streaming Maximization for k-Extendible Systems</title>
    <feedworld_mtime>1560297600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldman:Moran.html">Moran Feldman</a>, Ran Haba <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04449">PDF</a><br/><b>Abstract: </b>In this paper we consider the problem of finding a maximum weight set subject
to a $k$-extendible constraint in the data stream model. The only non-trivial
algorithm known for this problem to date---to the best of our knowledge---is a
semi-streaming $k^2(1 + \varepsilon)$-approximation algorithm (Crouch and
Stubbs, 2014), but semi-streaming $O(k)$-approximation algorithms are known for
many restricted cases of this general problem. In this paper, we close most of
this gap by presenting a semi-streaming $O(k \log k)$-approximation algorithm
for the general problem, which is almost the best possible even in the offline
setting (Feldman et al., 2017).
</p></div>
    </summary>
    <updated>2019-06-12T23:31:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04401</id>
    <link href="http://arxiv.org/abs/1906.04401" rel="alternate" type="text/html"/>
    <title>Bipartite and Series-Parallel Graphs Without Planar Lombardi Drawings</title>
    <feedworld_mtime>1560297600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eppstein:David.html">David Eppstein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04401">PDF</a><br/><b>Abstract: </b>We find a family of planar bipartite graphs all of whose Lombardi drawings
(drawings with circular arcs for edges, meeting at equal angles at the
vertices) are nonplanar. We also find families of embedded series-parallel
graphs and apex-trees (graphs formed by adding one vertex to a tree) for which
there is no planar Lombardi drawing consistent with the given embedding.
</p></div>
    </summary>
    <updated>2019-06-12T23:42:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-06-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04356</id>
    <link href="http://arxiv.org/abs/1906.04356" rel="alternate" type="text/html"/>
    <title>Ultra Fast Medoid Identification via Correlated Sequential Halving</title>
    <feedworld_mtime>1560297600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Tavor Z. Baharav, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tse:David_N=.html">David N. Tse</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04356">PDF</a><br/><b>Abstract: </b>The medoid of a set of $n$ points is the point in the set that minimizes the
sum of distances to other points. Computing the medoid can be solved exactly in
$O(n^2)$ time by computing the distances between all pairs of points. Previous
work shows that one can significantly reduce the number of distance
computations needed by adaptively querying distances. The resulting randomized
algorithm is obtained by a direct conversion of the computation problem to a
multi-armed bandit statistical inference problem. In this work, we show that we
can better exploit the structure of the underlying computation problem by
modifying the traditional bandit sampling strategy and using it in conjunction
with a suitably chosen multi-armed bandit algorithm. Four to five orders of
magnitude gains over exact computation are obtained on real data, in terms of
both number of distance computations needed and wall clock time. Theoretical
results are obtained to quantify such gains in terms of data parameters. Our
code is publicly available online at
https://github.com/NEURIPS-anonymous-2019/Correlated-Sequential-Halving.
</p></div>
    </summary>
    <updated>2019-06-12T23:28:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04321</id>
    <link href="http://arxiv.org/abs/1906.04321" rel="alternate" type="text/html"/>
    <title>Efficiently escaping saddle points on manifolds</title>
    <feedworld_mtime>1560297600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Chris Criscitiello, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Boumal:Nicolas.html">Nicolas Boumal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04321">PDF</a><br/><b>Abstract: </b>Smooth, non-convex optimization problems on Riemannian manifolds occur in
machine learning as a result of orthonormality, rank or positivity constraints.
First- and second-order necessary optimality conditions state that the
Riemannian gradient must be zero, and the Riemannian Hessian must be positive
semidefinite. Generalizing Jin et al.'s recent work on perturbed gradient
descent (PGD) for optimization on linear spaces [How to Escape Saddle Points
Efficiently (2017), Stochastic Gradient Descent Escapes Saddle Points
Efficiently (2019)], we propose a version of perturbed Riemannian gradient
descent (PRGD) to show that necessary optimality conditions can be met
approximately with high probability, without evaluating the Hessian.
Specifically, for an arbitrary Riemannian manifold $\mathcal{M}$ of dimension
$d$, a sufficiently smooth (possibly non-convex) objective function $f$, and
under weak conditions on the retraction chosen to move on the manifold, with
high probability, our version of PRGD produces a point with gradient smaller
than $\epsilon$ and Hessian within $\sqrt{\epsilon}$ of being positive
semidefinite in $O((\log{d})^4 / \epsilon^{2})$ gradient queries. This matches
the complexity of PGD in the Euclidean case. Crucially, the dependence on
dimension is low, which matters for large-scale applications including PCA and
low-rank matrix completion, which both admit natural formulations on manifolds.
The key technical idea is to generalize PRGD with a distinction between two
types of gradient steps: `steps on the manifold' and `perturbed steps in a
tangent space of the manifold.' Ultimately, this distinction makes it possible
to extend Jin et al.'s analysis seamlessly.
</p></div>
    </summary>
    <updated>2019-06-12T23:26:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-06-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04304</id>
    <link href="http://arxiv.org/abs/1906.04304" rel="alternate" type="text/html"/>
    <title>Meta-Learning Neural Bloom Filters</title>
    <feedworld_mtime>1560297600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jack W Rae, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bartunov:Sergey.html">Sergey Bartunov</a>, Timothy P Lillicrap <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04304">PDF</a><br/><b>Abstract: </b>There has been a recent trend in training neural networks to replace data
structures that have been crafted by hand, with an aim for faster execution,
better accuracy, or greater compression. In this setting, a neural data
structure is instantiated by training a network over many epochs of its inputs
until convergence. In applications where inputs arrive at high throughput, or
are ephemeral, training a network from scratch is not practical. This motivates
the need for few-shot neural data structures. In this paper we explore the
learning of approximate set membership over a set of data in one-shot via
meta-learning. We propose a novel memory architecture, the Neural Bloom Filter,
which is able to achieve significant compression gains over classical Bloom
Filters and existing memory-augmented neural networks.
</p></div>
    </summary>
    <updated>2019-06-12T23:40:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04270</id>
    <link href="http://arxiv.org/abs/1906.04270" rel="alternate" type="text/html"/>
    <title>Pure entropic regularization for metrical task systems</title>
    <feedworld_mtime>1560297600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Coester:Christian.html">Christian Coester</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:James_R=.html">James R. Lee</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04270">PDF</a><br/><b>Abstract: </b>We show that on every $n$-point HST metric, there is a randomized online
algorithm for metrical task systems (MTS) that is $1$-competitive for service
costs and $O(\log n)$-competitive for movement costs. In general, these refined
guarantees are optimal up to the implicit constant. While an $O(\log
n)$-competitive algorithm for MTS on HST metrics was developed by Bubeck et
al., that approach could only establish an $O((\log n)^2)$-competitive ratio
when the service costs are required to be $O(1)$-competitive. Our algorithm can
be viewed as an instantiation of online mirror descent with the regularizer
derived from a multiscale conditional entropy.
</p>
<p>In fact, our algorithm satisfies a set of even more refined guarantees; we
are able to exploit this property to combine it with known random embedding
theorems and obtain, for any $n$-point metric space, a randomized algorithm
that is $1$-competitive for service costs and $O((\log n)^2)$-competitive for
movement costs.
</p></div>
    </summary>
    <updated>2019-06-12T23:40:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04213</id>
    <link href="http://arxiv.org/abs/1906.04213" rel="alternate" type="text/html"/>
    <title>The Demand Query Model for Bipartite Matching</title>
    <feedworld_mtime>1560297600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nisan:Noam.html">Noam Nisan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04213">PDF</a><br/><b>Abstract: </b>We introduce a `concrete complexity' model for studying algorithms for
matching in bipartite graphs. The model is based on the "demand query" model
used for combinatorial auctions. Most (but not all) known algorithms for
bipartite matching seem to be translatable into this model including exact,
approximate, sequential, parallel, and online ones. A perfect matching in a
bipartite graph can be found in this model with O(n^{3/2}) demand queries (in a
bipartite graph with n vertices on each side) and our main open problem is to
either improve the upper bound or prove a lower bound. An improved upper bound
could yield "normal" algorithms whose running time is better than the fastest
ones known, while a lower bound would rule out a faster algorithm for bipartite
matching from within a large class of algorithms. Our main result is a lower
bound for finding an approximately maximum size matching in parallel: A
deterministic algorithm that runs in n^{o(1)} rounds, where each round can make
at most n^{1.99} demand queries cannot find a matching whose size is within
n^{o(1)} factor of the maximum. This is in contrast to randomized algorithms
that can find a matching whose size is $99\%$ of the maximum in O(\log n)
rounds, each making n demand queries.
</p></div>
    </summary>
    <updated>2019-06-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1906.04178</id>
    <link href="http://arxiv.org/abs/1906.04178" rel="alternate" type="text/html"/>
    <title>Complexity phase diagram for interacting and long-range bosonic Hamiltonians</title>
    <feedworld_mtime>1560297600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Nishad Maskara, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deshpande:Abhinav.html">Abhinav Deshpande</a>, Minh C. Tran, Adam Ehrenberg, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fefferman:Bill.html">Bill Fefferman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gorshkov:Alexey_V=.html">Alexey V. Gorshkov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1906.04178">PDF</a><br/><b>Abstract: </b>Recent years have witnessed a growing interest in topics at the intersection
of many-body physics and complexity theory. Many-body physics aims to
understand and classify emergent behavior of systems with a large number of
particles, while complexity theory aims to classify computational problems
based on how the time required to solve the problem scales as the problem size
becomes large. In this work, we use insights from complexity theory to classify
phases in interacting many-body systems. Specifically, we demonstrate a
"complexity phase diagram" for the Bose-Hubbard model with long-range hopping.
This shows how the complexity of simulating time evolution varies according to
various parameters appearing in the problem, such as the evolution time, the
particle density, and the degree of locality. We find that classification of
complexity phases is closely related to upper bounds on the spread of quantum
correlations, and protocols to transfer quantum information in a controlled
manner. Our work motivates future studies of complexity in many-body systems
and its interplay with the associated physical phenomena.
</p></div>
    </summary>
    <updated>2019-06-12T23:21:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-06-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.05304</id>
    <link href="http://arxiv.org/abs/1905.05304" rel="alternate" type="text/html"/>
    <title>Computing Maximum Matchings in Temporal Graphs</title>
    <feedworld_mtime>1560297600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mertzios:George_B=.html">George B. Mertzios</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Molter:Hendrik.html">Hendrik Molter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Niedermeier:Rolf.html">Rolf Niedermeier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zamaraev:Viktor.html">Viktor Zamaraev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zschoche:Philipp.html">Philipp Zschoche</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.05304">PDF</a><br/><b>Abstract: </b>We study the computational complexity of finding maximum-cardinality temporal
matchings in temporal graphs (where the edge set may change over time while the
vertex set remains fixed). Our model of temporal matching (which seems to be
slightly more general than a previous one due to Baste et al. [Theor. Comp.
Sci., 2019]) allows capturing several real-world scenarios where (as e.g. in
social networks) relations change over time and where one also has to model the
duration of pairings between agents. In this paper we present several classic
and approximation hardness results as well as approximation and exact
fixed-parameter algorithms, thus improving several parts of previous work of
Baste et al. We show hardness already for very restricted cases and introduce
temporal line graphs as a concept of independent interest. Altogether, our
results both show the various degrees of computational intractability of
"temporal matching" and point to some islands of tractability which may give
hope for efficient solutions in relevant special cases. Our work focuses on
exploring the computational complexity landscape (tractable versus intractable)
and mainly delivers classification results.
</p></div>
    </summary>
    <updated>2019-06-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1811.04753</id>
    <link href="http://arxiv.org/abs/1811.04753" rel="alternate" type="text/html"/>
    <title>Sliding Window Temporal Graph Coloring</title>
    <feedworld_mtime>1560297600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mertzios:George_B=.html">George B. Mertzios</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Molter:Hendrik.html">Hendrik Molter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zamaraev:Viktor.html">Viktor Zamaraev</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1811.04753">PDF</a><br/><b>Abstract: </b>Graph coloring is one of the most famous computational problems with
applications in a wide range of areas such as planning and scheduling, resource
allocation, and pattern matching. So far coloring problems are mostly studied
on static graphs, which often stand in stark contrast to practice where data is
inherently dynamic and subject to discrete changes over time. A temporal graph
is a graph whose edges are assigned a set of integer time labels, indicating at
which discrete time steps the edge is active. In this paper we present a
natural temporal extension of the classical graph coloring problem. Given a
temporal graph and a natural number $\Delta$, we ask for a coloring sequence
for each vertex such that (i) in every sliding time window of $\Delta$
consecutive time steps, in which an edge is active, this edge is properly
colored (i.e. its endpoints are assigned two different colors) at least once
during that time window, and (ii) the total number of different colors is
minimized. This sliding window temporal coloring problem abstractly captures
many realistic graph coloring scenarios in which the underlying network changes
over time, such as dynamically assigning communication channels to moving
agents. We present a thorough investigation of the computational complexity of
this temporal coloring problem. More specifically, we prove strong
computational hardness results, complemented by efficient exact and
approximation algorithms. Some of our algorithms are linear-time
fixed-parameter tractable with respect to appropriate parameters, while others
are asymptotically almost optimal under the Exponential Time Hypothesis (ETH).
</p></div>
    </summary>
    <updated>2019-06-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-06-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1309.2643</id>
    <link href="http://arxiv.org/abs/1309.2643" rel="alternate" type="text/html"/>
    <title>Noisy Interactive Quantum Communication</title>
    <feedworld_mtime>1560297600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brassard:Gilles.html">Gilles Brassard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nayak:Ashwin.html">Ashwin Nayak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tapp:Alain.html">Alain Tapp</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Touchette:Dave.html">Dave Touchette</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Unger:Falk.html">Falk Unger</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1309.2643">PDF</a><br/><b>Abstract: </b>We study the problem of simulating protocols in a quantum communication
setting over noisy channels. This problem falls at the intersection of quantum
information theory and quantum communication complexity, and it will be of
importance for eventual real-world applications of interactive quantum
protocols, which can be proved to have exponentially lower communication costs
than their classical counterparts for some problems. These are the first
results concerning the quantum version of this problem, originally studied by
Schulman in a classical setting (FOCS '92, STOC '93). We simulate a length $N$
quantum communication protocol by a length $O(N)$ protocol with arbitrarily
small error. Under adversarial noise, our strategy can withstand, for
arbitrarily small $\epsilon &gt; 0$, error rates as high as $1/2 -\epsilon$ when
parties pre-share perfect entanglement, but the classical channel is noisy. We
show that this is optimal. We provide extension of these results in several
other models of communication, including when also the entanglement is noisy,
and when there is no pre-shared entanglement but communication is quantum and
noisy. We also study the case of random noise, for which we provide simulation
protocols with positive communication rates and no pre-shared entanglement over
some quantum channels with quantum capacity $C_Q=0$, proving that $C_Q$ is in
general not the right characterization of a channel's capacity for interactive
quantum communication. Our results are stated for a general quantum
communication protocol in which Alice and Bob collaborate, and these results
hold in particular in the quantum communication complexity settings of the Yao
and Cleve--Buhrman models.
</p></div>
    </summary>
    <updated>2019-06-12T23:27:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-06-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/06/11/dancing-arc-quadrilaterals</id>
    <link href="https://11011110.github.io/blog/2019/06/11/dancing-arc-quadrilaterals.html" rel="alternate" type="text/html"/>
    <title>Dancing arc-quadrilaterals</title>
    <summary>Several of my past papers concern Lombardi drawing, which I and my coauthors named after conspiracy-theory artist Mark Lombardi. In this style of drawing, edges are drawn as circular arcs, and must meet at equal angles around every vertex. Not every graph has such a drawing, but many symmetrical graphs do (example below: the smallest zero-symmetric graph with only two edge orbits).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Several of my past papers concern Lombardi drawing, which I and my coauthors named after conspiracy-theory artist <a href="https://en.wikipedia.org/wiki/Mark_Lombardi">Mark Lombardi</a>. In this style of drawing, edges are drawn as circular arcs, and must meet at equal angles around every vertex. Not every graph has such a drawing, but many symmetrical graphs do (example below: the smallest <a href="https://en.wikipedia.org/wiki/Zero-symmetric_graph">zero-symmetric graph</a> with only two edge orbits).</p>

<p style="text-align: center;"><img alt="The smallest zero-symmetric graph with only two edge orbits" src="https://11011110.github.io/blog/assets/2019/Two-edge-orbit_GRR.svg"/></p>

<p>All 2-degenerate graphs do as well; these are the graphs that can be reduced to nothing by removing vertices of degree at most two. And all 3-regular planar graphs have planar drawings in this style; I drew the one below to illustrate <a href="https://en.wikipedia.org/wiki/Grinberg%27s_theorem">Grinberg’s theorem</a>, a necessary condition for Hamiltonicity of planar graphs.</p>

<p style="text-align: center;"><img alt="Grinberg's non-Hamiltonian planar cubic graph with cyclic edge-connectivity five" src="https://11011110.github.io/blog/assets/2019/Grinberg_5CEC_Nonhamiltonian_graph.svg"/></p>

<p>So anyway, my newest arXiv preprint is “Bipartite and series-parallel graphs without planar Lombardi drawings” (<a href="https://arxiv.org/abs/1906.04401">arXiv:1906.04401</a>, to appear at <a href="https://sites.ualberta.ca/~cccg2019/">CCCG</a>). It is about some families of planar graphs that have Lombardi drawings (because they are 2-degenerate) but do not have planar Lombardi drawings. They include planar bipartite graphs like the one below (but with more edges and vertices):</p>

<p style="text-align: center;"><img alt="Construction for a family of planar bipartite graphs with no planar Lombardi drawing " src="https://11011110.github.io/blog/assets/2019/nested-K2n.svg"/></p>

<p>and embedded series-parallel graphs like the one below (again, with more edges and vertices):</p>

<p style="text-align: center;"><img alt="Construction for a family of embedded series-parallel graphs with no planar Lombardi drawing" src="https://11011110.github.io/blog/assets/2019/nonlom-serpar.svg"/></p>

<p>The key structures that makes both of these graphs hard to draw in Lombardi style are their yellow-blue quadrilateral faces.
The red parts of the graph are just filler to make these faces have the right angles. The yellow-blue quadrilaterals all share the same two yellow vertices,
and I like to think of them as forming a ring dancing hand-to-hand around these two yellow vertices like <a href="https://en.wikipedia.org/wiki/Dance_(Matisse)">Matisse’s dancers</a>.</p>

<p style="text-align: center;"><img alt="_La Danse_, Henri Matisse, 1910, from https://en.wikipedia.org/wiki/File:Matissedance.jpg" src="https://11011110.github.io/blog/assets/2019/Matisse-Dance.jpg"/></p>

<p>When I wrote about <a href="https://11011110.github.io/blog/2018/12/22/circles-crossing-equal.html">quadrilaterals with circular-arc edges meeting at equal angles at each vertex</a> last December, it was these rings of quadrilaterals I was thinking about. As I wrote in my previous post, each of these quadrilaterals has a circumscribing circle. It’s not hard to make one arc polygon with four equal angles, as sharp as you like. But when the angles get sharp and two of these polygons share two opposite vertices and are packed at a tight angle next to each other (as all the yellow-blue quadrilateral faces in these graphs do) each of the two adjacent quadrilaterals must have a deep pocket into which its neighbor reaches to touch its circumcircle, and this forces them to become quite distorted looking.</p>

<p style="text-align: center;"><img alt="Two sharp circular-arc quadrilaterals reach into each others' pockets to touch their circumscribing circles" src="https://11011110.github.io/blog/assets/2019/reacharound.svg"/></p>

<p>If we think of these two quadrilaterals as dancers, with their heads and toes at the shared points and with their hands free, then both of them have their right hands (from the perspective of the viewer) held high and their left hands held low. Extending the same picture to a complete ring of dancers, each dancer in the ring must be holding their right hand higher than their neighbor to the left. But this obviously can’t extend all the way around the ring, because when you came back to the dancer you started with their hand should be the same height as it was when you started.</p>

<p>This is all very metaphorical but fortunately this intuition can be turned into a mathematical proof that the drawing doesn’t exist. The correct tools for measuring the heights of the quadrilateral vertices turn out to be <a href="https://en.wikipedia.org/wiki/M%C3%B6bius_transformation">Möbius transformations</a> and <a href="https://en.wikipedia.org/wiki/Bipolar_coordinates">bipolar coordinates</a>, a system for assigning coordinates to points in the plane by the angle they make with two fixed points (the two yellow shared vertices of all the quadrilateral faces of our graph) and the ratio of their distances to the fixed points.</p>

<p style="text-align: center;"><img alt="Level sets for bipolar coordinates" src="https://11011110.github.io/blog/assets/2019/apollo.svg"/></p>

<p>Möbius transformations preserve the circular-arc shape of our quadrilateral sides, and the angles at which they meet. When we restrict them to the transformations that leave the two poles of the bipolar coordinate system fixed, they act very nicely on the two coordinates, essentially adding fixed amounts to each coordinate. We can use them to transform our quadrilaterals into a more canonical shape and prove that the radius-ratio coordinate increases from one quadrilateral to the next around our ring of quadrilaterals, getting the same contradiction described above and proving that no drawing exists.</p>

<p>The most obvious questions in the same direction that this paper leaves unsolved are: what about series-parallel graphs where you do not have a fixed planar embedding for the graph? And what about outerplanar graphs (either with the outerplanar embedding or without fixing an embedding)? We neither have a method for finding planar Lombardi drawings of all graphs of these types, nor a proof that these drawings do not exist.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102256946045372078">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-06-11T21:16:00Z</updated>
    <published>2019-06-11T21:16:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-06-12T05:27:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamdsmith.wordpress.com/?p=602</id>
    <link href="https://adamdsmith.wordpress.com/2019/06/11/tpdp-2019/" rel="alternate" type="text/html"/>
    <title>TPDP 2019</title>
    <summary>The call for submissions for the latest edition of TPDP (Theory and Practice of Differential Privacy) is out! https://tpdp.cse.buffalo.edu/2019/  The workshop covers work on differential privacy (of course), and more generally on rigorous modeling of, and attacks on, statistical data privacy. The intention is to be inclusive. Submissions are due June 21, 2019. Advertisements</summary>
    <updated>2019-06-11T20:52:53Z</updated>
    <published>2019-06-11T20:52:53Z</published>
    <category term="Conferences"/>
    <category term="theory"/>
    <author>
      <name>adamdsmith</name>
    </author>
    <source>
      <id>https://adamdsmith.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamdsmith.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamdsmith.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamdsmith.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamdsmith.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>An inquiry into the Nature and Causes of Stuff</subtitle>
      <title>Oddly Shaped Pegs</title>
      <updated>2019-06-13T08:20:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/087</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/087" rel="alternate" type="text/html"/>
    <title>TR19-087 |  Coin Theorems and the Fourier Expansion | 

	Rohit Agrawal</title>
    <summary>In this note we compare two measures of the complexity of a class $\mathcal F$ of Boolean functions studied in (unconditional) pseudorandomness: $\mathcal F$'s ability to distinguish between biased and uniform coins (the coin problem), and the norms of the different levels of the Fourier expansion of functions in $\mathcal F$ (the Fourier growth). We show that for coins with low bias $\varepsilon = o(1/n)$, a function's distinguishing advantage in the coin problem is essentially equivalent to $\varepsilon$ times the sum of its level $1$ Fourier coefficients, which in particular shows that known level $1$ and total influence bounds for some classes of interest (such as constant-width read-once branching programs) in fact follow as a black-box from the corresponding coin theorems, thereby simplifying the proofs of some known results in the literature. For higher levels, it is well-known that Fourier growth bounds on all levels of the Fourier spectrum imply coin theorems, even for large $\varepsilon$, and we discuss here the possibility of a converse.</summary>
    <updated>2019-06-11T14:34:45Z</updated>
    <published>2019-06-11T14:34:45Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-06-13T08:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1267</id>
    <link href="https://thmatters.wordpress.com/2019/06/11/wikipedia-edit-a-thon-at-stoc19/" rel="alternate" type="text/html"/>
    <title>Wikipedia edit-a-thon at STOC’19</title>
    <summary>CATCS is organizing a Wikipedia edit-a-thon at STOC in Phoenix this year. The goal is to create/edit Wikipedia articles on TCS topics that need improvement. (A crowdsourced list of such topics is maintained here.) The event will be held on June 24th, 2019 in West 104A, starting right after the STOC business meeting around 9-9:30 […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>CATCS is organizing a Wikipedia edit-a-thon at <a href="http://acm-stoc.org/stoc2019/">STOC</a> in Phoenix this year. The goal is to create/edit Wikipedia articles on TCS topics that need improvement. (A crowdsourced list of such topics is maintained <a href="https://docs.google.com/spreadsheets/d/1zVUdxKk9nqR5Itwc37v26aRHMqgV9qI8XexssoFq_CE/edit">here</a>.) The event will be held on June 24th, 2019 in West 104A, starting right after the STOC business meeting around 9-9:30 pm.</p>
<p>We invite members of the community to participate. Prior experience with Wikipedia is a plus, but is not necessary. If you are interested in participating, please fill out <a href="https://forms.gle/ZnPkHN1Wc2edAWhB6">this form</a>. Participants are asked to bring their own laptop or other device. Power outlets will be available. Light refreshments will be provided.</p>
<p>If you are interested in helping improve TCS coverage on Wikipedia but are unable to attend this event, please see <a href="https://thmatters.wordpress.com/2017/05/02/tcs-wikipedia-project/">this post</a> for how you can help.</p>
<p> </p></div>
    </content>
    <updated>2019-06-11T13:35:08Z</updated>
    <published>2019-06-11T13:35:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2019-06-13T08:20:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15977</id>
    <link href="https://rjlipton.wordpress.com/2019/06/10/net-zero-graphs/" rel="alternate" type="text/html"/>
    <title>Net-Zero Graphs</title>
    <summary>A new class of undirected graphs with quantum relevance Cropped from source Gustav Kirchhoff was a German physicist active in the mid-1800s. He is known for many things, especially for his “Laws” governing voltage and current in electrical circuits. Today we ask whether anything akin to Kirchhoff’s laws can be formulated for quantum circuits. What […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc">
<em>A new class of undirected graphs with quantum relevance</em>
<font color="#000000">





</font></font></p><table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/06/10/net-zero-graphs/345px-gustav_robert_kirchhoff/" rel="attachment wp-att-15978"><img alt="" class="alignright wp-image-15978" height="156" src="https://rjlipton.files.wordpress.com/2019/06/345px-gustav_robert_kirchhoff.jpg?w=102&amp;h=156" width="102"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from <a href="https://en.wikipedia.org/wiki/Gustav_Kirchhoff">source</a></font></td>
</tr>
</tbody>
</table><font color="#0044cc"><font color="#000000">



<p>
Gustav Kirchhoff was a German physicist active in the mid-1800s. He is known for many things, especially for his “Laws” governing voltage and current in electrical circuits. Today we ask whether anything akin to Kirchhoff’s laws can be formulated for quantum circuits.

</p><p>
What may be less known about Kirchhoff is that he was a pioneer in graph theory. He proved Kirchhoff’s <a href="https://en.wikipedia.org/wiki/Kirchhoff's_theorem">Theorem</a> that the number of spanning trees equals the determinant of an associated matrix. This shows that the trees can be counted in polynomial time—a cool result. Here we present a class of graphs arising from quantum circuits and associated operations more complex than determinants.

</p><p>
Our search for new graph-based laws was driven by our work on simulations of stabilizer circuits. We have discussed this recently <a href="https://rjlipton.wordpress.com/2019/06/04/a-quantum-connection-for-matrix-rank/">here</a> and <a href="https://rjlipton.wordpress.com/2019/06/07/a-rank-problem/">here</a>. The bottom line is this:

</p><p>

</p><blockquote><b> </b> <em> <i>A new class of graphs arises in a natural way and holds a key to improving certain quantum simulations.</i> </em>
</blockquote>


<p>



</p><p>
We call these <i>net-zero graphs</i>. We like to imagine that Kirchhoff would have been interested. We will say more about why after we present the graphs.<span id="more-15977"/>



</p><p>


</p><p>



</p><p>

</p><h2> Net-Zero Graphs </h2>


<p>



</p><p>
The new class of graphs comes from a natural counting problem. Consider black/white two colorings (not necessarily proper) of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> vertices of a graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>, and count the number of edges whose two nodes are both colored black, being called B-B edges. Let <img alt="{c_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_0}"/> be the count of colorings that make an even number of B-B edges and <img alt="{c_1 = 2^n - c_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_1+%3D+2%5En+-+c_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_1 = 2^n - c_0}"/> be the count of colorings that make an odd number of B-B edges. Then <img alt="{a(G) = c_0 - c_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28G%29+%3D+c_0+-+c_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(G) = c_0 - c_1}"/> divided by <img alt="{2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^n}"/>. Now we are good to define “Net-Zero” graphs as follows:

</p><p>

</p><blockquote><b> </b> <em> An undirected graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> is net-zero if <img alt="{a(G) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28G%29+%3D+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{a(G) = 0}"/>. </em>
</blockquote>


<p>



</p><p>
Furthermore, we can call <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> <em>net-positive</em> if <img alt="{a &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a &gt; 0}"/> and <em>net-negative</em> if <img alt="{a &lt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba+%3C+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a &lt; 0}"/>. By simple trial and error, the smallest net-zero graph is the triangle graph and the graph made by two triangles sharing an edge is net-zero as well. Here are some connected net-zero graphs of small size:

</p><p>



</p><p>
You might ask why study such labelings of graphs? Why is net-zero an interesting property? An equivalent formulation of <img alt="{a(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(G)}"/> was given as “<img alt="{Z_{H_2}(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ_%7BH_2%7D%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z_{H_2}(G)}"/>” (divided by <img alt="{2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^n}"/>) in a 2009 <a href="https://arxiv.org/abs/0804.1932">paper</a> by Leslie Goldberg, Martin Grohe, Mark Jerrum, and Marc Thurley, as part of a larger enumeration of polynomial-time cases. Their proof works by reduction to the problem of counting solutions to quadratic polynomials modulo 2, whose time we just <a href="https://rjlipton.wordpress.com/2019/06/04/a-quantum-connection-for-matrix-rank/">improved</a> from <img alt="{O(n^3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(n^3)}"/> to <img alt="{O(n^\omega)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%5Comega%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(n^\omega)}"/>. Their paper does not mention quantum but does involve Hadamard-type matrices. Thus the short answer is that net-zero captures a type of balancing property that is related to understanding quantum circuits. 

</p><p>
<a href="https://rjlipton.wordpress.com/2019/06/10/net-zero-graphs/netzerographs/" rel="attachment wp-att-15981"><img alt="" class="aligncenter wp-image-15981" height="70" src="https://rjlipton.files.wordpress.com/2019/06/netzerographs.png?w=550&amp;h=70" width="550"/></a>


</p><p>

</p><h2> Some Examples and Facts </h2>


<p>



</p><p>
The following elementary facts show how the theory of our graphs takes shape.

</p><p>

</p><blockquote><b>Proposition 1</b> <em> Every cycle graph <img alt="{C_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_n%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C_n}"/> with <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> odd is net-zero. </em>
</blockquote>


<p>



</p><p>
This follows because every coloring of <img alt="{C_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_n}"/> has an even number of B-W edges. Hence the number of monochrome edges is odd, and so complementing the coloring flips the parity between B-B and W-W edges. However, having an odd cycle as an induced graph does not make a graph net-zero. An example of this would be a 4-clique graph. Any subset of vertices of size 3 gives an triangle which is net-zero, but the 4-clique itself is net-negative.

</p><p>

</p><blockquote><b>Proposition 2</b> <em> A graph is net-zero if and only if one of its connected components is net-zero. </em>
</blockquote>


<p>



</p><p>
This fact is intuitive when we look at the graph as a tensor product over the connected components, so the colorings to each component are independent. Every coloring <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> on nodes outside the net-zero connected component can be easily extended to one coloring <img alt="{R'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R'}"/> for the entire graph by coloring nodes on the net-zero component, so the difference <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> restricted by <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/> is zero.

</p><p>
Now let’s deviate from net-zero graphs. What are some typical net-positive graphs?

</p><p>

</p><blockquote><b>Proposition 3</b> <em> Bipartite graphs are net-positive. </em>
</blockquote>


<p>



</p><p>
To prove this, let <img alt="{V_1, V_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV_1%2C+V_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V_1, V_2}"/> be the two disjoint vertex sets such that each edge connects one node from <img alt="{V_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V_1}"/> and one from <img alt="{V_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V_2}"/>. If all nodes in <img alt="{V_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V_1}"/> are set to be white, then there will be zero B-B edges regardless of how <img alt="{V_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V_2}"/> is acolored, and <img alt="{a &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a &gt; 0}"/> in this case. Now if any of the nodes, say <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/>, in <img alt="{V_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V_1}"/> is colored black, then the number of B-B blacks equals the number of nodes connected to <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> that are colored black, and <img alt="{a = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a = 0}"/> in this situation by straightforward combination calculation. Hence bipartite graphs are net-positive. 

</p><p>
As a consequence, since all trees are bipartite, all trees are net-positive. So is <img alt="{C_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_n}"/> for <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> even. Net-negative graphs may seem to be rarer. We invite readers to work out from Pascal’s triangle when the <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>-clique is net-negative, net-zero, and net-positive. Congruence modulo <img alt="{8}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{8}"/> is involved.

</p><p>
Other interesting examples come from allowing self-loops. The smallest net-zero graph of this kind is a single self-loop. But a 2-node graph with an edge connecting them and two self-loops is net-negative, and so is a graph of two triangles connected by one edge. Pictorially, these two graphs are: 



</p><p>
<a href="https://rjlipton.wordpress.com/2019/06/10/net-zero-graphs/localequiv/" rel="attachment wp-att-15982"><img alt="" class="aligncenter wp-image-15982" height="120" src="https://rjlipton.files.wordpress.com/2019/06/localequiv.png?w=136&amp;h=120" width="136"/></a>

</p><p>
There is a “local equivalence” between a single self-loop and a triangle: Any self-loop in a graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> can be replaced by a triangle using two new vertices, and the resulting graph <img alt="{G'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G'}"/> will be net-zero if and only if <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is.

</p><p>



</p><p>

</p><h2> The Quantum Connection </h2>


<p>

There is a special class of quantum circuits that relate closely to graphs. They use just two kinds of quantum gates: Hadamard gate and the <img alt="{\mathsf{CZ}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BCZ%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{CZ}}"/> gate. For more on quantum circuits see this elementary <a href="https://rjlipton.wordpress.com/2015/04/08/a-quantum-two-finger-exercise/">post</a> and this more involved <a href="https://rjlipton.wordpress.com/2012/07/08/grilling-quantum-circuits/">post</a>.

</p><p>

</p><blockquote><b>Definition 4</b> <em> Given a graph <img alt="{G = (V,E)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG+%3D+%28V%2CE%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G = (V,E)}"/>, the corresponding <em>graph state circuit</em> <img alt="{C_G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_G%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C_G}"/> involves <img alt="{n = |V|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+%7CV%7C%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n = |V|}"/> qubits and consists of: 

<ul> 
<li>
An initial Hadamard gate on each qubit line <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{i}"/>. 
</li><li>
For every edge <img alt="{(i,j) \in E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2Cj%29+%5Cin+E%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{(i,j) \in E}"/>, a <img alt="{\mathsf{CZ}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BCZ%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{CZ}}"/> gate connecting lines <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{i}"/> and <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{j}"/>. The order of placing the <img alt="{\mathsf{CZ}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BCZ%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{CZ}}"/> gates does not matter. 
</li><li>
A closing Hadamard gate on each line <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{i}"/>. 
</li></ul>

</em>
</blockquote>


<p>



</p><p>
These circuits are a subset of <em>stabilizer circuits</em>, which we <a href="https://rjlipton.wordpress.com/2019/06/04/a-quantum-connection-for-matrix-rank/">have</a> been <a href="https://rjlipton.wordpress.com/2019/06/07/a-rank-problem/">discussing</a>. They become equivalent to stabilizer circuits if we also allow so-called phase gates <img alt="{\mathsf{S}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BS%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{S}}"/> on single qubits, where they are analogous to a loop or “half-loop” at the corresponding vertex. We will stay with the simpler circuits here. The connection to graphs is expressed by:

</p><p>

</p><blockquote><b>Theorem 5</b> <em><a name="amplitude"/> For any graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/>, <img alt="{a(G) = \langle 0^n | C_G | 0^n\rangle}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28G%29+%3D+%5Clangle+0%5En+%7C+C_G+%7C+0%5En%5Crangle%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{a(G) = \langle 0^n | C_G | 0^n\rangle}"/>, that is, the amplitude of measuring an all-zero output given an all-zero input. In particular, <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> is net-zero if and only if <img alt="{\langle 0^n | C_G | 0^n\rangle = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+0%5En+%7C+C_G+%7C+0%5En%5Crangle+%3D+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\langle 0^n | C_G | 0^n\rangle = 0}"/>. </em>
</blockquote>


<p>



</p><p>



</p><p>

</p><h2> Recognizing Net-Zero Graphs </h2>


<p>



</p><p>
Theorem <a href="https://rjlipton.wordpress.com/feed/#amplitude">5</a> implies that whether a graph is net-zero can be decided in <img alt="{O(n^\omega)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%5Comega%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(n^\omega)}"/> time. The question is, can we improve the time to <img alt="{O(n^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(n^2)}"/>, which for dense graphs means linear in the number of edges? The reason why we want to do so is the following further theorem:

</p><p>


</p><p>

</p><blockquote><b>Theorem 6</b> <em> If net-zero graphs of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> nodes with self-loops allowed are recognizable in <img alt="{O(n^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E2%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{O(n^2)}"/> time, then computing the strong simulation probability <img alt="{|\langle 0^n | C | 0^n\rangle|^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%5Clangle+0%5En+%7C+C+%7C+0%5En%5Crangle%7C%5E2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{|\langle 0^n | C | 0^n\rangle|^2}"/> for quantum stabilizer circuits <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C}"/> is <img alt="{O(n^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E2%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{O(n^2)}"/>-time equivalent to computing <img alt="{n \times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Ctimes+n%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n \times n}"/> matrix rank over <img alt="{\mathbb{Z}_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D_2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathbb{Z}_2}"/>. </em>
</blockquote>


<p>



</p><p>
This is proved in section 5 of our <a href="https://arxiv.org/abs/1904.00101">paper</a>, which has a duality technique for eliminating the self-loops from phase gates that works for the probability but possibly not for the amplitude. Another way of stating our theorem is:

</p><p>

</p><blockquote><b>Theorem 7</b> <em> Given any <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>-vertex graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/>, we can compute <img alt="{p(G) = a(G)^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%28G%29+%3D+a%28G%29%5E2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{p(G) = a(G)^2}"/> in <img alt="{O(n^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E2%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{O(n^2)}"/> time given only the rank of the adjacency matrix of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> and the yes/no answer about whether <img alt="{a(G) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28G%29+%3D+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{a(G) = 0}"/>. </em>
</blockquote>


<p>



</p><p>
This result extends to computing the probability of any output of a stabilizer circuit given a standard-basis input. This is why the decision problem for recognizing net-zero graphs is important.

</p><p>
In upcoming posts we will connect net-zero graphs further to ideas of circuit “laws” by defining recursions for <img alt="{a(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a(G)}"/>. These recursions do not give efficient algorithms by themselves, but they connect to a wide theory involving graph polynomials and matroids. That theory includes Kirchhoff’s counting of spanning trees as a special case, and we will be interested in which other cases are polynomial-time feasible. This may position quantum computing as a meeting point for closer connections between work such as this 1997 <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.2071">paper</a> by Andrei Broder and Ernst Mayr on counting minimum-weight spanning trees in <img alt="{O(n^\omega)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%5Comega%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(n^\omega)}"/> time and the paper by Goldberg et al. mentioned above.

</p><p>


</p><p>



</p><p>

</p><h2> Open Problems </h2>


<p>



</p><p>
What is the complexity of deciding whether a given <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-vertex graph is net-zero? We know it is at worst order-<img alt="{n^\omega}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^\omega}"/>. If it is <img alt="{O(n^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(n^2)}"/>, then we obtain a really tight connection between computing matrix rank and computing a quantum simulation probability.

</p><p>
Are there further applications of net-zero graphs?

</p><p>
[gave Kirchhoff his second “h”]



</p><ul class="wp-block-gallery columns-0 is-cropped"/></font></font></div>
    </content>
    <updated>2019-06-10T22:23:56Z</updated>
    <published>2019-06-10T22:23:56Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="Results"/>
    <category term="graph theory"/>
    <category term="graphs"/>
    <category term="Gustav Kirchoff"/>
    <category term="quantum"/>
    <category term="quantum circuits"/>
    <category term="stabilizer circuits"/>
    <author>
      <name>Chaowen Guan and K.W. Regan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-06-13T08:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7515</id>
    <link href="https://windowsontheory.org/2019/06/10/intro-tcs-rebooted/" rel="alternate" type="text/html"/>
    <title>Intro-TCS rebooted</title>
    <summary>This Spring and Summer I am doing some major editing to my text on introduction to theoretical computer science. I am adding figures (176 so far and counting..), examples, exercises, simplifying explanations, reducing footnotes, and mainly trying to make it more “user friendly” and less “idiosyncratic”. I am now adding in all chapters figures such […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This Spring and Summer I am doing some major editing to my text on <a href="https://introtcs.org">introduction to theoretical computer science</a>. I am adding figures (176 so far and counting..), examples, exercises, simplifying explanations, reducing footnotes, and mainly trying to make it more “user friendly” and less “idiosyncratic”. I am now adding in all chapters figures such as the following that outline the main results and how they are connected to one another.<br/></p>



<div class="wp-block-image"><figure class="aligncenter"><img alt="Overview of the results in &quot;Code and Data&quot; chapter presenting universal circuit and the counting lower bound" class="wp-image-7519" src="https://windowsontheory.files.wordpress.com/2019/06/codedataoverview.png?w=600"/><em>Overview of the results in <a href="https://introtcs.org/public/lec_04_code_and_data.html">“Code and Data” chapter</a> presenting universal circuit and the counting lower bound</em></figure></div>



<figure class="wp-block-image"><img alt="Overview of the results in the &quot;loops and infinity&quot; chapter defining Turing Machines. A running theme in the book is the emphasis on distinguishing specification (the mathematical function being computed) from implementation (the algorithm, machine, or program doing the computation)." class="wp-image-7520" src="https://windowsontheory.files.wordpress.com/2019/06/chaploopoverview.png?w=600"/><em>Overview of the results in the <a href="https://introtcs.org/public/lec_06_loops.html">“loops and infinity” chapter</a> defining Turing Machines. A running theme in the book is the emphasis on distinguishing <strong>specification</strong> (the mathematical function being computed) from <strong>implementation</strong> (the algorithm, machine, or program doing the computation).</em></figure>



<figure class="wp-block-image"><img alt="Overview of the results in the chapter on universality and uncomputability. We use Sipser's metaphor on reductions as transforming a &quot;pig that can whistle&quot; (e.g., an algorithm for the deciding if a function halts on the zero input) into a &quot;horse that can fly&quot; (e.g., an algorithm for the general halting problem). " class="wp-image-7522" src="https://windowsontheory.files.wordpress.com/2019/06/universalchapoverview.png?w=600"/><em>Overview of the results in the chapter on <a href="https://introtcs.org/public/lec_08_uncomputability.html">universality and uncomputability</a>. We use Sipser’s metaphor on reductions as transforming a “pig that can whistle” (e.g., an algorithm for the deciding if a function halts on the zero input) into a “horse that can fly” (e.g., an algorithm for the general halting problem). </em></figure>



<p><br/><br/><br/>Specifically, in the previous version of the book I used <em>programming languages </em>as the main computational models. While I still think this is the right way if we were to “start from scratch”, these idiosyncratic models made it harder for students to use other resources such as textbooks and lecture notes. They also make it more difficult for instructors to use individual chapters in their courses without committing to using the full book.</p>



<p>Hence in the new revision the standard models of <strong>Turing Machines</strong> and <strong>Boolean Circuits</strong> are front and center. We do talk about the programming-language equivalents as well, since I think they are important for the connection to practice and some concepts such as the duality of code and data are better explained in these terms.  I also use the programming-language variants to <a href="https://github.com/boazbk/tcscode">demonstrate concepts to students in code</a> including compilers from circuits to straightline programs, various “syntactic sugar” transformations, and the Cook-Levin Theorem and NP reductions. </p>



<figure class="wp-block-image"><img alt="" class="wp-image-7521" src="https://windowsontheory.files.wordpress.com/2019/06/aoncircequiv.png?w=600"/><em>An equivalent description of a finite computation using straight-line programs and Boolean circuits. The <a href="https://nbviewer.jupyter.org/github/boazbk/tcscode/blob/master/Chap_03_Computation.ipynb">supplementary code</a> contains a Python implementation of the transformation between these two representations.</em></figure>



<p><br/><br/>One thing did not change – we still start with <em>Boolean Circuits </em>rather than automata as the initial computational model. Boolean circuits are closer to actual implementations of computing, are a finite (and hence simpler) model, but one that is non-trivial enough to allow showing some important theorems early in the course including existence of a circuit for computing every finite function, the existence of a circuit to evaluate other circuits, and the counting lower bound as well as the counting lower bound. </p>



<p>Circuits are also crucial for later material in the course since they make the proof of the Cook-Levin Theorem much simpler and cleaner,  allow talking about results such as <img alt="BPP \subseteq P_{/poly}" class="latex" src="https://s0.wp.com/latex.php?latex=BPP+%5Csubseteq+P_%7B%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="BPP \subseteq P_{/poly}"/> and Sipser-Gacs, and are crucial to be even able to state results in advanced topics such as derandomization, cryptography, and quantum computing.</p>



<figure class="wp-block-image"><img alt="" class="wp-image-7523" src="https://windowsontheory.files.wordpress.com/2019/06/3sat2isreduction.png?w=600"/><em>Reduction of SAT to independent set from <a href="https://introtcs.org/public/lec_12_NP.html">Chapter 13</a> in the book. On the right is the Python code implementing the reduction, on the left is the resulting independent set.</em></figure>



<figure class="wp-block-image"><img alt="" class="wp-image-7524" src="https://windowsontheory.files.wordpress.com/2019/06/indsetfromnandsat.png?w=600"/><em>An instance of independent set obtained by chaining together the proof of the Cook-Levin Theorem together with the reduction of 3SAT to independent set. Figure taken from <a href="https://introtcs.org/public/lec_13_Cook_Levin.html">Chapter 14</a>.</em></figure>



<p><br/><br/>We do cover automata as well, including the equivalence of regular expressions and deterministic finite automata. We also cover context-free grammars (though not pushdown automata) and the λ calculus, including its equivalence with Turing Machines and the Y combinator (see also <a href="https://nbviewer.jupyter.org/github/boazbk/tcscode/blob/master/lambda_calculus.ipynb">this notebook</a>)</p>



<p>I have also done some work on the technical side of producing the book. The book is written in markdown. Markdown has many advantages but it wasn’t designed for 600-page technical books full of equations and cross-references so I did need to use some extensions to it. I am using pandoc (and my own <a href="https://github.com/boazbk/tcs/blob/master/scripts/book-filter.py">filter</a>) to produce both the HTML and LaTeX/PDF versions of the book. </p>



<p>There is still more work to do. I plan to add a chapter on space complexity and on proofs and computation (including both interactive and zero knowledge proofs, as well as the “propositions as types” correspondence between proofs and programs). I need to add more examples and exercises. There are also still several chapters where the text is “rough around the edges”.</p>



<p>As usual, the latest version of the book is available on  <a href="https://introtcs.org/">https://introtcs.org</a>  . If you see any typo, problem, etc.., please post an issue on the <a href="https://github.com/boazbk/tcs/issues">GitHub repository</a>  (you can also make a <a href="https://github.com/boazbk/tcs/pulls">pull request</a> for small typo fixes if you prefer)</p></div>
    </content>
    <updated>2019-06-10T17:47:28Z</updated>
    <published>2019-06-10T17:47:28Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-06-13T08:20:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blogs.princeton.edu/imabandit/?p=1359</id>
    <link href="https://blogs.princeton.edu/imabandit/2019/06/10/amazing-progress-in-adversarially-robust-stochastic-multi-armed-bandits/" rel="alternate" type="text/html"/>
    <title>Amazing progress in adversarially robust stochastic multi-armed bandits</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In this post I briefly discuss some recent stunning progress on robust bandits (for more background on bandits see these two posts, part 1 and part 2, in particular what is described below gives a solution to Open Problem 3 … <a href="https://blogs.princeton.edu/imabandit/2019/06/10/amazing-progress-in-adversarially-robust-stochastic-multi-armed-bandits/">Continue reading <span class="meta-nav">→</span></a></p></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In this post I briefly discuss some recent stunning progress on robust bandits (for more background on bandits see these two posts, <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2016/05/11/bandit-theory-part-i/">part 1</a> and <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2016/05/13/bandit-theory-part-ii/">part 2</a>, in particular what is described below gives a solution to Open Problem 3 at the end of part 2).</p>
<p> </p>
<p><strong>Stochastic bandit and adversarial examples</strong></p>
<p>In multi-armed bandit problems the gold standard property, going back to <a class="lipdf" href="https://core.ac.uk/download/pdf/82425825.pdf">a seminal paper</a> of Lai and Robbins in 1985 is to have a regret upper bounded by:</p>
<p class="ql-center-displayed-equation" style="line-height: 50px;"><span class="ql-right-eqno"> (1) </span><span class="ql-left-eqno">   </span><img alt="\begin{equation*} \sum_{i \neq i^*} \frac{\log(T)}{\Delta_i} \,. \end{equation*}" class="ql-img-displayed-equation " height="50" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-2ac69fee3f1e4890b09202da232941f6_l3.png?resize=91%2C50&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="91"/></p>
<p>Let me unpack this a bit: this is for the scenario where the reward process for each action is simply an i.i.d. sequence from some fixed distribution, <img alt="i^*" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9af0b76a90462b68c1d83fca9cc6604d_l3.png?resize=12%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="12"/> is the index of the (unique) best action, and <img alt="\Delta_i" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9ca6025283881ee4c29a1f9f236d72ba_l3.png?resize=20%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> is the gap between the mean value of the best action and the one of <img alt="i" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-8511b1f6cf9db17d46ddabb67bac99f5_l3.png?resize=6%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="6"/>. Such guarantee is extremely strong, as in particular it means that actions whose average performance is a constant away from the optimal arm are very rarely played (only of order <img alt="\log(T)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b7ebb3614adc5ab9694e195d68bdbd06_l3.png?resize=49%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="49"/>). On the other hand, the price to pay for such an aggressive behavior (by this I mean focusing on good actions very quickly) is that all the classical algorithms attaining the above bound are extremely sensitive to <em>adversarial examples</em>: that is if there is some deviation from the i.i.d. assumption (even very brief in time), the algorithms can suddenly suffer linear in <img alt="T" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-58f18d11e5ffdd11dd9095c427922c8b_l3.png?resize=13%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="13"/> regret.</p>
<p> </p>
<p><strong>Adversarial bandit</strong></p>
<p>Of course there is an entirely different line of works, on <em>adversarial multi-armed bandits</em>, where the whole point is to prove regret guarantee for <em>any</em> reward process. In this case the best one can hope for is a regret of order <img alt="\sqrt{K T}" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-13ba497e024059e3674272b6a0e11809_l3.png?resize=44%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="44"/>. The classical algorithm in this model, Exp3, attains a regret of order <img alt="\sqrt{K T \log(K)}" class="ql-img-inline-formula " height="22" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-fc756065e4451f8bccc02a40b732c969_l3.png?resize=103%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="103"/>. In joint work with Jean-Yves Audibert we showed <a class="lipdf" href="http://sbubeck.com/COLT09_AB.pdf">back in 2009</a> that the following strategy, which we called PolyINF, attains the optimal <img alt="\sqrt{KT}" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3cf8321c07956bc2bd76714eabd30a0a_l3.png?resize=44%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="44"/>: view Exp3 as Mirror Descent with the (negative) entropy as a regularizer, and now replace the entropy by a simple rational function namely <img alt="- \sum_{i=1}^K x_i^p" class="ql-img-inline-formula " height="24" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ac7b6228954b4b6f9ceee99faf3d7776_l3.png?resize=77%2C24&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="77"/> with <img alt="p \in (0,1)" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-de24a5fa6badcd9e8c80a7d72640dcc6_l3.png?resize=70%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="70"/> (this mirror descent view was actually derived in <a class="liinternal" href="https://pubsonline.informs.org/doi/10.1287/moor.2013.0598">a later paper</a> with Gabor Lugosi). The proof becomes one line (given the appropriate knowledge of mirror descent and estimation in bandit games): the radius part of the bound is of the form <img alt="\frac{1}{\eta} \sum_{i=1}^K x_i^p \leq \frac{K^{p}}{\eta}" class="ql-img-inline-formula " height="27" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a3d6ffad60b5151ac3866f9fa9213b65_l3.png?resize=120%2C27&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="120"/>, while the variance is of the form (since the inverse of the Hessian of the mirror map is a diagonal matrix with entries <img alt="x_i^{2-p}" class="ql-img-inline-formula " height="23" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0b3188b0bc4d641381b7ba4be936c230_l3.png?resize=35%2C23&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/>):</p>
<p class="ql-center-displayed-equation" style="line-height: 46px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \eta \sum_{i=1} x_i^{2-p} \frac{1}{x_i} \leq \eta K^{1-p} \,. \]" class="ql-img-displayed-equation " height="46" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5356f94049f314f34752afbac2277f16_l3.png?resize=177%2C46&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="177"/></p>
<p>Thus optimizing over <img alt="\eta" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-86bde2afc6c0858d01ac505267801f02_l3.png?resize=9%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="9"/> yields <img alt="\sqrt{K T}" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-13ba497e024059e3674272b6a0e11809_l3.png?resize=44%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="44"/> for any <img alt="p \in (0,1)" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-de24a5fa6badcd9e8c80a7d72640dcc6_l3.png?resize=70%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="70"/>. Interestingly, the best numerical constant in the bound is obtained for <img alt="p=1/2" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d9aaa949f328021d5d7cbd31573c7a0e_l3.png?resize=60%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="60"/>.</p>
<p> </p>
<p><strong>Best of both worlds</strong></p>
<p>This was the state of affairs back in 2011, when with Alex Slivkins we started working on a <em>best of both worlds</em> type algorithm (which in today’s language is exactly a stochastic MAB robust to adversarial examples): namely one that gets the <img alt="\log(T)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b7ebb3614adc5ab9694e195d68bdbd06_l3.png?resize=49%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="49"/> guarantee (in fact <img alt="\log^2(T)" class="ql-img-inline-formula " height="20" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-00cc550d710d51cc64227da3b639018e_l3.png?resize=56%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="56"/> in <a class="lipdf" href="http://sbubeck.com/COLT12_BS.pdf">our original paper</a>) if the environment is the nice i.i.d. one, and also <img alt="\sqrt{K T}" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-13ba497e024059e3674272b6a0e11809_l3.png?resize=44%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="44"/> (in fact <img alt="\sqrt{K T \log^3(T)}" class="ql-img-inline-formula " height="33" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4d85e820be8841c565042231480be3ac_l3.png?resize=107%2C33&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="107"/>) in the worst case. This original best of both worlds algorithm was of the following form: be aggressive as if it was a stochastic environment, but still sample sufficiently often the bad actions to make sure there isn’t an adversary trying to hide some non-stochastic behavior on these seemingly bad performing actions. Of course the whole difficulty was to show that it is possible to implement such a defense without hurting the stochastic performance too much (remember that bad actions can only be sampled of order <img alt="\log(T)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b7ebb3614adc5ab9694e195d68bdbd06_l3.png?resize=49%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="49"/> times!). Since this COLT 2012 paper there has been many improvements to the original strategy, as well as many variants/refinements (one such variant worth mentioning are the works trying to do a smooth transition between the stochastic and adversarial models, see e.g. <a class="liinternal" href="https://arxiv.org/abs/1803.09353">here</a> and <a class="liinternal" href="https://arxiv.org/abs/1902.08647">here</a>).</p>
<p> </p>
<p><strong>A stunning twist</strong></p>
<p>The amazing development that I want to talk about in this post is the following: <a class="liinternal" href="https://arxiv.org/abs/1807.07623">about a year ago</a> Julian Zimmert and Yevgeny Seldin proved that the 2009 PolyINF (crucially with <img alt="p=1/2" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d9aaa949f328021d5d7cbd31573c7a0e_l3.png?resize=60%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="60"/>) strategy actually gets the 2012 best of both worlds bound! This is truly surprising, as in principle mirror descent does not “know” anything about stochastic environments, it does not make any sophisticated concentration reasoning (say as in Lai and Robbins), yet it seems to automatically and optimally pick up on the regularity in the data. This is really amazing to me, and of course also a total surprise that the polynomial regularizer has such strong adaptivity property, while it was merely introduced to remove a benign log term.</p>
<p>The crucial observation of Zimmert and Seldin is that a a certain <em>self-bounding</em> property of the regret implies (in a one-line calculation) the best of both worlds result:</p>
<blockquote><p><strong>Lemma 1:</strong> Consider a strategy whose regret with respect to the optimal action <img alt="i^*" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9af0b76a90462b68c1d83fca9cc6604d_l3.png?resize=12%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="12"/> is upper bounded by</p>
<p class="ql-center-displayed-equation" style="line-height: 56px;"><span class="ql-right-eqno"> (2) </span><span class="ql-left-eqno">   </span><img alt="\begin{equation*} C \sum_{t=1}^T \sum_{i \neq i^*} \sqrt{\frac{x_{i,t}}{t}} \,. \end{equation*}" class="ql-img-displayed-equation " height="56" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-58ac492ce88752df4dbc5bccc5f7c9ff_l3.png?resize=129%2C56&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="129"/></p>
<p>(Recall that for multi-armed bandit one selects a probability distribution <img alt="x_t" class="ql-img-inline-formula " height="11" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ae5b82123ba785d8c8153a037675bc56_l3.png?resize=15%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="15"/> over the actions, so <img alt="x_{i,t}" class="ql-img-inline-formula " height="14" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-65be0e3045aefe9ef0dd0bd9531c0572_l3.png?resize=24%2C14&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="24"/> denote here the probability of playing action <img alt="i" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-8511b1f6cf9db17d46ddabb67bac99f5_l3.png?resize=6%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="6"/> at time <img alt="t" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-6b97bb0f65c75b6cc0fba1868749478d_l3.png?resize=6%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="6"/>.) Then one has that the regret is in fact bounded by <img alt="2 C \sqrt{K T}" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-6dc96815294ab91f00db7fc32adcc459_l3.png?resize=68%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="68"/> (this follows trivially by Jensen on the <img alt="i" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-8511b1f6cf9db17d46ddabb67bac99f5_l3.png?resize=6%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="6"/> sum), and moreover if the environment is stochastic one has that the regret is in fact bounded by <img alt="C^2" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e4b609168e948e0de36c4f357b700408_l3.png?resize=21%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="21"/> times <img alt="(1)" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5048b7c449e02713d954071d1a80df0f_l3.png?resize=21%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/>.</p></blockquote>
<p><em>Proof:</em> Assuming that the environment is stochastic we can write the regret as <img alt="\sum_{i,t} \Delta_i x_{i,t}" class="ql-img-inline-formula " height="21" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1e451f2e1cd6b24d6f4ceb19592378a8_l3.png?resize=80%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="80"/>, so by assumption and using that <img alt="C \sqrt{\frac{x_{i,t}}{t}} \leq \frac{1}{2} \left( \Delta_i x_{i,t} + \frac{C^2}{t \Delta_i} \right)" class="ql-img-inline-formula " height="33" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-37d8baadc3f1897c077c0f1bc6da832f_l3.png?resize=205%2C33&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="205"/> one has:</p>
<p class="ql-center-displayed-equation" style="line-height: 52px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \sum_{i \neq i^*,t} \Delta_i x_{i,t} \leq \frac{1}{2} \sum_{i \neq i^*,t} \left(\Delta_i x_{i,t} + \frac{C^2}{t \Delta_i} \right) \,, \]" class="ql-img-displayed-equation " height="52" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-19259c6dbd863aa77917fbddee306ca7_l3.png?resize=295%2C52&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="295"/></p>
<p>which means that the left hand side is smaller than <img alt="\sum_{i \neq i^*,t} \frac{C^2}{t \Delta_i}" class="ql-img-inline-formula " height="26" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3a170cbde4999b8a9aaab3ebc7698acb_l3.png?resize=82%2C26&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="82"/> which is indeed smaller than <img alt="C^2" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e4b609168e948e0de36c4f357b700408_l3.png?resize=21%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="21"/> times <img alt="(1)" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5048b7c449e02713d954071d1a80df0f_l3.png?resize=21%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/>.</p>
<p> </p>
<p><strong>Yet another one-line proof (okay, maybe 5 lines)</strong></p>
<p>Zimmert and Seldin proved that PolyINF with <img alt="p=1/2" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d9aaa949f328021d5d7cbd31573c7a0e_l3.png?resize=60%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="60"/> actually satisfies the self-bounding property of Lemma 1 (and thus obtains the best of both worlds guarantee). In <a class="liinternal" href="https://arxiv.org/abs/1901.08779">another recent paper</a> by Zimmert, in joint work with Haipeng Luo and Chen-Yu Wei, they simplify the analysis by using a very mild variation of the PolyINF regularizer, namely <img alt="- \sum_{i=1}^K (\sqrt{x_i} + \sqrt{1-x_i})" class="ql-img-inline-formula " height="24" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-83b29164db23b237061cd205df4a585d_l3.png?resize=183%2C24&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="183"/>. In my view it’s the proof from the book for the best of both worlds result (or very close to it)! Here it is:</p>
<blockquote><p><strong>Lemma 2:</strong> Equation <img alt="(2)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-8a996880dc323ee4b8cf323009c02635_l3.png?resize=21%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/> with <img alt="C=10" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ae0daffd6d9302e8baf8d6432a69c5ca_l3.png?resize=56%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="56"/> is an upper bound on the regret of mirror descent with learning <img alt="\eta_t = \frac{1}{\sqrt{t}}" class="ql-img-inline-formula " height="27" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-27f9c61a5d83fe6d2fca62581c4d1b6f_l3.png?resize=57%2C27&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="57"/>, mirror map <img alt="\Phi(x) = - \sum_{i=1}^K (\sqrt{x_i} + \sqrt{1-x_i})" class="ql-img-inline-formula " height="24" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e28928d4c9de69492e5f786c52e80f3e_l3.png?resize=245%2C24&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="245"/>, and standard multi-armed bandit loss estimator.</p></blockquote>
<p><em>Proof:</em> The classical mirror descent analysis from any good book will tell you that the regret is controlled by (for <img alt="\Phi(x) = \sum_{i=1}^K \phi(x_i)" class="ql-img-inline-formula " height="24" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-f1d27d479269ff49c66d302354f84569_l3.png?resize=144%2C24&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="144"/> and with the convention <img alt="\eta_0 = + \infty" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-db68debdd0cb300a9b79aed311c05d28_l3.png?resize=71%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="71"/>):</p>
<p class="ql-center-displayed-equation" style="line-height: 54px;"><span class="ql-right-eqno"> (3) </span><span class="ql-left-eqno">   </span><img alt="\begin{equation*} \sum_{t=1}^T \left(\frac{1}{\eta_t} - \frac{1}{\eta_{t-1}}\right) (\Phi(x^*) - \Phi(x_t)) + \sum_{t=1}^T \eta_t \sum_{i=1}^K \frac{1}{x_{i,t} \phi''(x_t)} \,. \end{equation*}" class="ql-img-displayed-equation " height="54" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d3de9d0c55a8d8aca491d928972530ed_l3.png?resize=437%2C54&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="437"/></p>
<p>We now consider those terms for the specific <img alt="\Phi" class="ql-img-inline-formula " height="14" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-8581dbc45f448345dcc6bd9caed502e9_l3.png?resize=12%2C14&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="12"/> and <img alt="\eta_t" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-f489909a6f16a3b5a6ee23901d48d9b6_l3.png?resize=14%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="14"/> suggested in the lemma. First notice that <img alt="\frac{1}{\eta_t} - \frac{1}{\eta_{t-1}} \leq \eta_t" class="ql-img-inline-formula " height="25" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-7f8f2af48129af0fd204515d14d0f6f5_l3.png?resize=105%2C25&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="105"/>. Moreover <img alt="\phi(x^*_i) = - 1" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e59356dfe693c9414f1e407c034a4a4d_l3.png?resize=88%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="88"/> (since <img alt="x^*" class="ql-img-inline-formula " height="13" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b92fd5178a7e53e81d04a267f41c9d8_l3.png?resize=16%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="16"/> is integral) so that <img alt="\phi(x^*_i) - \phi(x_{i,t}) \leq \min(\sqrt{x_{i,t}}, \sqrt{1-x_{i,t}})" class="ql-img-inline-formula " height="22" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a13944e230b8362a3c996cdb9d42f634_l3.png?resize=298%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="298"/>. In other words the first term in <img alt="(3)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c9264e4ae133cc333e4e98394c7e0656_l3.png?resize=21%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/> is upper bounded by</p>
<p class="ql-center-displayed-equation" style="line-height: 57px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \sum_{t=1}^T \sum_{i=1}^K \sqrt{\frac{\min(x_{i,t}, 1-x_{i,t})}{t}} \leq 2 \sum_{t=1}^T \sum_{i \neq i^*} \sqrt{\frac{x_{i,t}}{t}} \, \]" class="ql-img-displayed-equation " height="57" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c048790fe35996074b87ea676060d91d_l3.png?resize=350%2C57&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="350"/></p>
<p>where the inequality simply comes from <img alt="\sqrt{1-x_{i^*,t}} = \sqrt{\sum_{i \neq i^*} x_{i,t}} \leq \sum_{i \neq i^*} \sqrt{x_{i,t}}" class="ql-img-inline-formula " height="33" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-01c4dcfc661631d69e71024a0340222d_l3.png?resize=307%2C33&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="307"/>.</p>
<p>Next note that <img alt="\phi''(s) = \frac{1}{4} (s^{-3/2} + (1-s)^{-3/2}) \geq \frac{1}{4 \min(s,1-s)^{3/2}}" class="ql-img-inline-formula " height="28" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-83fb6f1ccbc0d202e6020dc0884a140f_l3.png?resize=358%2C28&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="358"/>, so that the second term in <img alt="(3)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c9264e4ae133cc333e4e98394c7e0656_l3.png?resize=21%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/> is upper bounded by</p>
<p class="ql-center-displayed-equation" style="line-height: 57px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ 4 \sum_{t=1}^T \sum_{i=1}^K \sqrt{\frac{x_{i,t}}{t}} \min(1, (1-x_{i,t})/x_{i,t})^{3/2} \leq 8 \sum_{t=1}^T \sum_{i \neq i^*} \sqrt{\frac{x_{i,t}}{t}} \, \]" class="ql-img-displayed-equation " height="57" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-98a3e5f8a743148f5f6919b1dd53a8b9_l3.png?resize=442%2C57&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="442"/></p>
<p>where the inequality follows trivially by considering the two cases whether <img alt="x_{i^*,t}" class="ql-img-inline-formula " height="14" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0bcf369611e215890249a1b1bb94089d_l3.png?resize=31%2C14&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="31"/> is smaller or larger than <img alt="1/2" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1c652ece8cc629e4e659c41eeed4d410_l3.png?resize=25%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="25"/>.</p></div>
    </content>
    <updated>2019-06-10T15:16:09Z</updated>
    <published>2019-06-10T15:16:09Z</published>
    <category term="Machine learning"/>
    <category term="Optimization"/>
    <category term="Theoretical Computer Science"/>
    <author>
      <name>Sebastien Bubeck</name>
    </author>
    <source>
      <id>https://blogs.princeton.edu/imabandit</id>
      <link href="https://blogs.princeton.edu/imabandit/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blogs.princeton.edu/imabandit" rel="alternate" type="text/html"/>
      <subtitle>Random topics in optimization, probability, and statistics. By Sébastien Bubeck</subtitle>
      <title>I’m a bandit</title>
      <updated>2019-06-12T23:52:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1126</id>
    <link href="https://ptreview.sublinear.info/?p=1126" rel="alternate" type="text/html"/>
    <title>News for May 2019</title>
    <summary>We were able to find four new papers for May 2019 — as usual, please let us know if we missed any!EDIT: We did, in fact, miss one paper, which is the bottom one listed below. On Local Testability in the Non-Signaling Setting, by Alessandro Chiesa, Peter Manohar, and Igor Shinkar (ECCC). This paper studies […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We were able to find four new papers for May 2019 — as usual, please let us know if we missed any!<br/>EDIT: We did, in fact, miss one paper, which is the bottom one listed below.</p>



<p><strong>On Local Testability in the Non-Signaling Setting</strong>, by Alessandro Chiesa, Peter Manohar, and Igor Shinkar (<a href="https://eccc.weizmann.ac.il/report/2019/070/">ECCC</a>).  This paper studies testability of a certain generalization of (distributions over) functions, known as \(k\)-non-signalling functions, objects which see use in hardness of approximation and delegation of computation. Prior work by the authors show the effectiveness of the linearity test in this setting, leading to the design of PCPs. On the other hand, in this work, the authors show that two types of bivariate tests are ineffective in revealing low-degree structure of these objects.</p>



<p><strong>Computing and Testing Small Vertex Connectivity in Near-Linear Time and Queries</strong>, by Danupon Nanongkai, Thatchaphol Saranurak, and Sorrachai Yingchareonthawornchai (<a href="https://arxiv.org/abs/1905.05329">arXiv</a>). This work, apparently simultaneous with the one by Forster and Yang that we covered <a href="https://ptreview.sublinear.info/?p=1116">last month</a>, also studies the problem of locally computing cuts in a graph. The authors also go further, and study approximation algorithms for the same problems. Inspired by the connections to property testing in the work of Forster and Yang, they apply these approximation algorithms to get even more query-efficient algorithms for the problems of testing \(k\)-edge- and \(k\)-vertex-connectivity.</p>



<p><strong>Testing Graphs against an Unknown Distribution</strong>, by Lior Gishboliner and Asaf Shapira (<a href="https://arxiv.org/abs/1905.09903">arXiv</a>). This paper studies graph property testing, under the vertex-distribution-free (VDF) model, as <a href="http://www.wisdom.weizmann.ac.il/~oded/p_vdf.html">recently introduced</a> by Goldreich. In the VDF model, rather than the ability to sample a random node, the algorithm has the ability to sample a node from some unknown distribution, and must be accurate with respect to the same distribution (reminiscent of the PAC learning model). In Goldreich’s work, it was shown that every property which is testable in the VDF model is semi-hereditary. This work strengthens this statement and proves a converse, thus providing a characterization: a property is testable in the VDF model if and only if it is both hereditary and extendable. These descriptors roughly mean that the property is closed under both removal and addition of nodes (with the choice of addition of edges in the latter case). This is a far simpler characterization than that of properties which are testable in the standard model, which is a special case of the VDF model.</p>



<p><strong>Private Identity Testing for High-Dimensional Distributions</strong>, by Clément L. Canonne, Gautam Kamath, Audra McMillan, Jonathan Ullman, and Lydia Zakynthinou (<a href="https://arxiv.org/abs/1905.11947">arXiv</a>). This work continues a recent line on distribution testing under the constraint of differential privacy. The settings of interest are multivariate distributions: namely, product distributions over the hypercube and Gaussians with identity covariance. An application of a statistic of <a href="https://arxiv.org/abs/1612.03156">CDKS</a>, combined with a Lipschitz extension from the set of datasets likely to be generated by such structured distributions, gives a sample-efficient algorithm. A time-efficient version of this extension is also provided, at the cost of some loss in the sample complexity. Some tools of independent interest include reductions between Gaussian mean and product uniformity testing, balanced product identity to product uniformity testing, and an equivalence between univariate and “extreme” product identity testing. </p>



<p><strong>Testing Bipartitness in an Augmented VDF Bounded-Degree Graph Model</strong>, by Oded Goldreich (<a href="https://arxiv.org/abs/1905.03070">arXiv</a>). Another work on the vertex-distribution-free (VDF) model, as described above. In this one, Goldreich considers an augmentation of the model, where the algorithm is further allowed to query the probability of each node. With this augmentation, he gives \(\tilde O(\sqrt{n})\)-time algorithms for testing bipartiteness and cycle-free-ness, where \(n\) is the “effective support” of the distribution. That is, \(n\) is the number of nodes in the graph after discarding the nodes with minimal probability until \(\varepsilon/5\) mass is removed.</p></div>
    </content>
    <updated>2019-06-10T07:38:46Z</updated>
    <published>2019-06-10T07:38:46Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-06-12T23:53:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/086</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/086" rel="alternate" type="text/html"/>
    <title>TR19-086 |  Perfect zero knowledge for quantum multiprover interactive proofs | 

	Alex Bredariol Grilo, 

	William Slofstra, 

	Henry Yuen</title>
    <summary>In this work we consider the interplay between multiprover interactive proofs, quantum
entanglement, and zero knowledge proofs — notions that are central pillars of complexity theory,
quantum information and cryptography. In particular, we study the relationship between the
complexity class MIP$^*$ , the set of languages decidable by multiprover interactive proofs with
quantumly entangled provers, and the class PZK-MIP$^*$ , which is the set of languages decidable
by MIP$^*$ protocols that furthermore possess the perfect zero knowledge property.

Our main result is that the two classes are equal, i.e., MIP$^*$ = PZK-MIP$^*$ . This result provides
a quantum analogue of the celebrated result of Ben-Or, Goldwasser, Kilian, and Wigderson (STOC
1988) who show that MIP = PZK-MIP (in other words, all classical multiprover interactive
protocols can be made zero knowledge). We prove our result by showing that every MIP$^*$
protocol can be efficiently transformed into an equivalent zero knowledge MIP$^*$ protocol in a
manner that preserves the completeness-soundness gap. Combining our transformation with
previous results by Slofstra (Forum of Mathematics, Pi 2019) and Fitzsimons, Ji, Vidick and
Yuen (STOC 2019), we obtain the corollary that all co-recursively enumerable languages (which
include undecidable problems as well as all decidable problems) have zero knowledge MIP$^*$
protocols with vanishing promise gap.</summary>
    <updated>2019-06-09T10:46:57Z</updated>
    <published>2019-06-09T10:46:57Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-06-13T08:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3399</id>
    <link href="https://agtb.wordpress.com/2019/06/09/max-plank-summer-school-games-brains-and-distributed-computing/" rel="alternate" type="text/html"/>
    <title>Max Plank Summer School: Games, Brains, and Distributed Computing</title>
    <summary>The 20th Max Planck Advanced Course on the Foundations of Computer Science focused on “Games, Brains, and Distributed Computing” will take place on 19 – 23 August 2019, Saarbrücken, Germany.   The instructors are Christos Papadimitriou, Eva Tardos, and Pierre Fraigniaud. Advertisements</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The 20th <a href="http://resources.mpi-inf.mpg.de/conferences/adfocs/">Max Planck Advanced Course on the Foundations of Computer Science focused on “Games, Brains, and Distributed Computing”</a> will take place on 19 – 23 August 2019, Saarbrücken, Germany.</p>
<p> </p>
<p>The instructors are Christos Papadimitriou, Eva Tardos, and Pierre Fraigniaud.</p></div>
    </content>
    <updated>2019-06-09T07:10:20Z</updated>
    <published>2019-06-09T07:10:20Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>algorithmicgametheory</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-06-13T08:20:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8872438004336745499</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8872438004336745499/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/ray-miller-one-of-our-founders-passes.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8872438004336745499" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8872438004336745499" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/ray-miller-one-of-our-founders-passes.html" rel="alternate" type="text/html"/>
    <title>Ray Miller, one of our founders, Passes away at the age of 90</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Ray Miller, one of the founders of our field, passed away recently at the age of 90.<br/>
<br/>
He has associations with both GA Tech and The University of Maryland, so both Lance and I have a connection to him. As does Dick Lipton who has posted about him <a href="https://rjlipton.wordpress.com/2019/06/08/raymond-edward-miller-just-passed-away/">here</a>.<br/>
<br/>
I present two guest blog-posts about him<br/>
<br/>
<br/>
<b>Post One</b>: From<br/>
<br/>
<a href="https://www.cs.umd.edu/people/lin">Ming C Lin</a><br/>
<br/>
Elizabeth Stevinson Chair of Computer Science<br/>
<br/>
University of Maryland at College Park<br/>
<br/>
<br/>
Dear CS Alumni and Friends,<br/>
<br/>
We are deeply saddened to learn that Professor Emeritus Ray Miller passed away two nights ago around 9 pm.<br/>
<br/>
A Memorial Service at St. Andrews Lutheran Church (15300 New Hampshire Ave., Silver Spring MD  20905) for Dr. Miller will be held on Saturday, June 15th at 10:30 am.<br/>
<br/>
Dr. Ray Miller received his Ph.D. from University of Illinois in 1957.  He was a professor and the former Director of the School of Information and Computer Science at the Georgia Institute of Technology before joining our department in 1988 as the Director of the Center of Excellence in Space Data and Information Science (CESDIS).   Dr. Miller was well known for his research on communication protocols, networks, distributed systems, parallel computation, and theory.<br/>
<br/>
In 1970, he became the Fellow of IEEE for the advancement of the theoretical understanding of computation through work in switching theory and theoretical models.<br/>
<br/>
In 1997, he was elevated to be a Fellow of ACM for research contributions to the theory of parallel computation and for his distinguished service to the Computer Science community as an educator and leader.<br/>
<br/>
In 2003, Dr. Miller was designated as a Fellow by the Computer Science Accreditation Board<br/>
<br/>
<i>"in recognition of his outstanding professional volunteer contributions to computing sciences </i><i>and accreditation”.</i><br/>
<br/>
Dr. Miller was also an AAAS Fellow,  and a Charter Member of IEEE Computer Society Golden Core;he received the IEEE Third Millennium Medal in 2000 and ACM Distinguished Service Award in 2002.<br/>
<br/>
Beyond his outstanding research contribution and devotion to education, Dr. Ray Miller has been known for his kindness as a colleague, supportiveness as a mentor, and effectiveness as a leader. Dr. Miller will be forever remembered warmly by his friends, colleagues and students for his dedication and service to our department, the University, and the field of computing at large.<br/>
<br/>
<br/>
<b>Post Two</b>: From<br/>
<br/>
<a href="http://www.cs.umd.edu/users/ben/">Ben Shneiderman</a><br/>
<br/>
Emeritus Professor, University of Maryland at College Park.<br/>
<br/>
I was saddened to hear about the death of Ray Miller at age 90.  He was a dear colleague who contributed a great deal to computer science and to our department.  You can read his 84-page personal memoir at the IEEE Computer Society History Committee website: <a href="https://history.computer.org/pubs/ray-miller.pdf">here</a>.<br/>
<br/>
His memoirs tells his story in detail, describing his research collaborations in computational complexity, parallel algorithms, and program optimization and his leadership roles. You can see more about Ray’s work on his ACM author page: <a href="https://dl.acm.org/author_page.cfm?id=81332515760">here</a><br/>
<br/>
<div>
This is the best source as he had no Google Scholar page or Wikipedia article that I could find. Ray’s quiet and modest style was a valuable asset, but his contributions come through in his memoir. He describes working with Turing Awardees John Cocke, Fran Allen, John Backus, Dick Karp, and other key figures, so maybe Ray should have received that award too.  Ray was also an excellent administrator and leader, who contributed to building the institutions (conferences, ACM, IEEE, etc.) that supported the growth of computer science.</div>
<div>
<div>
<br/></div>
<div>
Ray was especially kind to me in the early 1970s, when I was working on my Phd, developing a graph theoretic model of data structures.  As Assistant Director of the IBM Mathematical Science Department at the T. J. Watson Labs in Yorktown Heights, NY. This legendary IBM Research Lab was equal to Bell Labs and filled with computing pioneers in hardware, software, and applications.<br/>
<br/></div>
<div>
Ray invited me to give a talk about my work, drawing interest from Arnold Rosenberg, who had been developing related ideas. With Ray’s support I returned for monthly visits with Arnie and Ray to refine my esoteric ideas leading to my May 1973 Phd.</div>
<div>
<br/></div>
<div>
Ray’s kindness as a colleague and supportiveness as a mentor will always be remembered warmly. Here are a few photos of Ray giving a talk in the CS Department, probably in 1985: <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/ray1.jpg">here,</a> <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/ray2.jpg">here</a>, and</div>
</div>
<div>
<a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/ray3.jpg">here</a></div></div>
    </content>
    <updated>2019-06-08T18:35:00Z</updated>
    <published>2019-06-08T18:35:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-06-13T02:34:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15969</id>
    <link href="https://rjlipton.wordpress.com/2019/06/08/raymond-edward-miller-just-passed-away/" rel="alternate" type="text/html"/>
    <title>Raymond Edward Miller Just Passed Away</title>
    <summary>Miller just passed away at 90 [ GIT ] Ray Miller just passed away. He had been a researcher and leader at IBM Research, Georgia Tech, and University of Maryland. At all he did important research and also was a leader: a group head, a director, and a chair. Today we remember Ray. For starters […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Miller just passed away at 90</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/06/08/raymond-edward-miller-just-passed-away/ray/" rel="attachment wp-att-15970"><img alt="" class="alignright size-full wp-image-15970" src="https://rjlipton.files.wordpress.com/2019/06/ray.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ GIT ]</font></td>
</tr>
</tbody>
</table>
<p>
Ray Miller just passed away. He had been a researcher and leader at IBM Research, Georgia Tech, and University of Maryland. At all he did important research and also was a leader: a group head, a director, and a chair.</p>
<p>
Today we remember Ray.</p>
<p>
For starters you can read <a href="https://cacm.acm.org/news/237370-in-memoriam-raymond-e-ray-miller-1928-2019/fulltext">this</a> or his memoir <a href="https://history.computer.org/pubs/ray-miller.pdf">here</a>. Ray started in the field with an electrical engineering PhD <a href="https://www.ideals.illinois.edu/handle/2142/5131/filter-search">thesis</a> tilted <i>Formal Analysis and Synthesis of Bilateral Switching Networks</i>. See <a href="https://ieeexplore.ieee.org/document/5222582">this</a> for his paper.</p>
<p>
Ray’s memoir does not mention tennis. But we played tennis when I visited IBM, and also when we could while at a conference. Ray was not slim, not fast, not obviously athletic. But he was the best tennis player in our group. He was miles above me. His trick was he could control the ball, especially on his serve so it was untouchable. He could spin it so that it landed and bounced at right angles. He was so good that he hardly ever had to move. When I played him in singles, we had to agree “no spinning serves”. When we played doubles there was a small chance that someone could return his ball, but not much.</p>
<p>
I think this is a fair way to summarize Ray: It was easy to underestimate him. Ray always had a smile on his face. I cannot remember him being anything but happy. This may led some to think he was not serious. But Ray was. He did wonderful research and was a leader in our field. He changed, for the better, all the places he called “home”. I can directly attest to his impact at Tech; others I believe can attest to IBM and Maryland. He was a great editor for <i>Journal of the ACM</i>, and did much more for our field. Thanks Ray.</p>
<p>
</p><p/><h2> Some Thoughts </h2><p/>
<p/><p>
Here are just a few comments from friends of Ray.</p>
<p>
<i>Rich DeMillo</i>:</p>
<blockquote><p><b> </b> <em> Ray was a quiet but strong and effective leader and a good friend to many of us. Nancy Lynch and I recruited him to be School of ICS Director, bringing immediate stature—both internal and external—to computer science at Georgia Tech. Up until that time Information and Computer Science was an odd duck interdisciplinary graduate program in a very traditional engineering school that had not invested in the field despite the early success of the School of Information and Computer Science and a world-class Burroughs installation (Georgia Tech had played a key role in Algol development in the ’60s). Ray was an engineer with impeccable credentials and was taken seriously by the administration in ways that the library scientists, linguists, philosophers, psychologists, cyberneticists, and mathematicians who founded the School never managed to achieve. </em></p><em>
<p>
Dick Lipton and I were long term collaborators on theory research with Ray, and Rays’ presence helped shine a national spotlight on the School. He was the editor-in-chief of the Journal of the ACM and palled around with luminaries like Sam Winograd and Dick Karp. </p>
<p>
In addition to his own work in switching theory and automata, Ray had co-edited the volume in which Karp’s NP-completeness paper appeared, and so his name was forever associated with that ground-breaking paper. From that point on, Atlanta became a mandatory stop on the national research circuit that was the hallmark of theory research in those days. </p>
<p>
One of his first accomplishments was snagging the Computer Science Conference, the large, research-oriented conference for the field. It gave Georgia Tech a chance to showcase its work for the rest of the world. There was a steady rise in rankings and a steady flow of visitors like Michael Rabin, Leslie Lamport, Mike Fisher, Andy Yao, Ravi Kannan, in addition to Karp, Winograd, and Lipton. Ray tried to entice Lipton to Georgia Tech with what was at the time the university’s juiciest startup package. He was ultimately successful, but it took nearly twenty years, and by that time, Tech had replaced the School of ICS with the College of Computing, and Ray was in semi-retirement in Maryland. </p>
</em><p><em>
</em>
</p></blockquote>
<p/><p>
<i>Umakishore Ramachandran</i>:</p>
<blockquote><p><b> </b> <em> I have fond memories of my early years at Tech after being recruited by Ray to join the small but vibrant group of faculty in ICS specializing in theory, systems, and AI. Ray was extremely caring and supportive in nurturing junior faculty. One could say that Ray’s leadership was instrumental in the transformation of CS at Georgia Tech and putting GT on the map to compete with other more established CS departments around the nation.</em></p><em>
<p>
Ray helped create a sense of family in the department. I recall every day he would be at lunch in the faculty club which in those days served coffee at $0.10. He would be there eating a healthy meal featuring a giant sausage and reserving an entire table for the ICS faculty to join him for lunch. It created such a friendly and amicable environment for discussing any issue.</p>
<p>
I feel compelled to share a lighter anecdote when I got hired by Ray. Those were the days of terminals connected to mini computers, DEC VAX 750 and 780, and I wanted Ray to promise me that he will give me a terminal and modem for connecting to the campus computers from home. Even as a grad student at UW-Madison I had a 2400 baud modem at home. When I arrived at Tech, Ray gave me a 300-baud acoustic coupler since I had not specified what speed modem I wanted in my startup package. Ray had a giant infectious smile all the time that made it difficult to get mad at him for anything. Note: <img alt="{300 \ll 2400}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B300+%5Cll+2400%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{300 \ll 2400}"/>.</p>
</em><p><em>
He will be missed by anyone and everyone whose lives he touched. </em>
</p></blockquote>
<p/><p>
<i>Bill Gasarch</i></p>
<p>
Here is a short quote from Bill and see his post for more details.</p>
<blockquote><p><b> </b> <em> I was saddened to hear of Ray Miller’s death. He was at University of Maryland for many years. Since he got his PhD in 1957 and was still active into the 2000’s he had a broad view of computer science. He did theory AND systems AND other things. It was great to talk to him about the early days of computer science before we had these labels. </em>
</p></blockquote>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Ray is missed. Our condolences to his family and his many friends for their loss.</p>
<p/></font></font></div>
    </content>
    <updated>2019-06-08T17:21:41Z</updated>
    <published>2019-06-08T17:21:41Z</published>
    <category term="History"/>
    <category term="News"/>
    <category term="Oldies"/>
    <category term="People"/>
    <category term="Georgia Tech"/>
    <category term="IBM"/>
    <category term="Maryland"/>
    <category term="Ray Miller"/>
    <category term="Switching theory"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-06-13T08:20:40Z</updated>
    </source>
  </entry>
</feed>
