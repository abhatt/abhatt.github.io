<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-04-04T19:21:50Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7673</id>
    <link href="https://windowsontheory.org/2020/04/04/in-defense-of-expertise/" rel="alternate" type="text/html"/>
    <title>In defense of expertise</title>
    <summary>Scott Aaronson blogged in defense of “armchair epidemiology”. Scott’s thesis is that even in a field you don’t know much about such as epidemiology, you should be open from ideas from all sources and feel qualified to judge them on their merits. Scott makes several points I agree with, but he also advocates that rather […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Scott Aaronson blogged in <a href="https://www.scottaaronson.com/blog/?p=4695">defense of “armchair epidemiology”</a>. Scott’s thesis is that even in a field you don’t know much about such as epidemiology, you should be open from ideas from all sources and feel qualified to judge them on their merits.  Scott makes several points I agree with, but he also advocates that rather than discounting ideas from “contrarians” who have no special expertise in the matter, each one of us should evaluate the input of such people on its merits.</p>



<p>I disagree. I can judge on their merits the validity of a proposed P vs NP proof or a quantum algorithm for SAT, but I have seen time and again very smart and educated non-experts misjudge such proposals. As much as I’d like to think otherwise, I would probably be fooled just as easily by a well-presented proposal in area X that “brushes under the rug” subtleties that experts in X would immediately notice.</p>



<p>This is not to say that non experts should stay completely out of the matter. Just like scientific journalists such as Erica Klarreich and Brian Hartnett of quanta can do a great job of explaining computer science topics to lay audience, so can other well-read people serve as “signal boosters” and highlight works of experts in epidemiology. Journalist Helen Branswell of <a href="https://www.statnews.com/">stat news</a> has been following the <a href="https://www.nytimes.com/2020/03/30/business/media/stat-news-boston-coronavirus.html">novel coronavirus since January 4th</a>. </p>



<p>The difference is that these journalists don’t pretend to see what the experts are missing but rather to highlight and simplify the works that experts are already doing. This is unlike “contrarians” such as Robin Hanson that do their own analysis on a spreadsheet and come up with a “home brewed” policy proposal such as <a href="http://www.overcomingbias.com/2020/02/consider-controlled-infection.html">deliberate infection</a> or <a href="http://www.overcomingbias.com/2020/03/variolation-may-cut-covid19-deaths-3-30x.html">variolation</a> (with “hero hotels” in which people go to be deliberately infected). I am not saying that such proposals are necessarily wrong, but I am saying that I (or anyone else without the experience in this field) am not qualified to judge them, and even if they did “make sense” to me (they don’t) I would not feel any more confident in judging them than I would in reviewing a paper in astronomy. There is a reason why Wikipedia has a <a href="https://en.wikipedia.org/wiki/Wikipedia:No_original_research">“no original research”</a> policy.</p>



<p>Moreover, the attitude of dismissing expertise, whether it comes in the form of <a href="https://en.wikipedia.org/wiki/Teach_the_Controversy">“teach the debate”</a> in the context of evolution, or <a href="https://en.wikipedia.org/wiki/Climatic_Research_Unit_email_controversy">“ClimateGate”</a> in the context of climate change, can actually cause damage. Unlike the narrative of few brave “dissenters” or “contrarians”, in the case of COVID-19, experts as well as the world health organization have been literally sounding the alarm (see also <a href="https://www.nytimes.com/article/coronavirus-timeline.html">timeline</a>, as well as this NPR story on the <a href="https://www.npr.org/2020/04/03/826945368/how-the-united-states-failed-to-see-the-coronavirus-crisis-coming">US response</a>). Yes, some institutions, and especially the U.S., failed in several aspects (most importantly in the early production testing . However, there is a constant sense of  <a href="https://www.nytimes.com/2020/04/03/us/politics/coronavirus-trump-medical-advisers.html">“daylight”</a>  and <a href="https://www.politico.com/news/2020/02/26/trump-backers-coronavirus-conspiracy-117781">distrust</a> between the current U.S. administration and its own medical experts. On the other hand, the opinions of people such as  <a href="https://www.newyorker.com/news/q-and-a/the-contrarian-coronavirus-theory-that-informed-the-trump-administration">law professor Richard Epstein</a> is listened to even when they are far out of their depth. It is one thing to entertain the opinion of non-expert contrarians when we have all the time in the world to debate, discuss and debunk. It’s quite another to do so in the context of a fast-moving health emergency.  It is is an emergency that has medical, social, economical, and technological aspects, but it would best be addressed if each person contributes according to their skill set and collaborates with people of complementary backgrounds.</p>



<p/>



<p/></div>
    </content>
    <updated>2020-04-04T16:54:24Z</updated>
    <published>2020-04-04T16:54:24Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-04-04T19:20:56Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-6367105878835308659</id>
    <link href="http://processalgebra.blogspot.com/feeds/6367105878835308659/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=6367105878835308659" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6367105878835308659" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6367105878835308659" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2020/04/an-interview-with-nancy-lynch-and.html" rel="alternate" type="text/html"/>
    <title>An interview with Nancy Lynch and Roberto Segala, CONCUR Test-of-Time Award recipients</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This post is devoted to the second interview with the <a href="https://concur2020.forsyte.at/test-of-time/index.html">colleagues</a> who were selected for the first edition of the CONCUR  Test-of-Time Award. (See <a href="https://processalgebra.blogspot.com/2020/04/an-interview-with-davide-sangiorgi.html">here</a> for the interview with Davide Sangiorgi.) I asked <a href="https://people.csail.mit.edu/lynch/">Nancy Lynch</a> (MIT, USA) and <a href="http://profs.sci.univr.it/~segala/">Roberto Segala</a> (University of Verona, Italy) a few questions via email and I copy their answers below. Let  me thank Nancy and Roberto for their answers. I trust that readers of this blog will find them interesting and inspiring.<br/><br/>Luca:  You receive one of the two CONCUR ToT Awards for the period 1992-1995 for your paper "<a href="https://groups.csail.mit.edu/tds/papers/Segala/CONCUR94.pdf">Probabilistic simulations for probabilistic processes</a>", presented at CONCUR 1994. Could you tell us briefly what spurred you to develop the “simple” probabilistic automaton model introduced in that paper and how the ideas underlying that notion came about?<br/><br/>Roberto: We were studying randomized distributed algorithms and we noted that several algorithms suffered from subtle errors. We were looking for a formal, rigorous way to study the correctness of those algorithms and in particular we were trying to extend the hierarchical approach used for <a href="https://en.wikipedia.org/wiki/Input/output_automaton">I/O automata</a>.  We knew that there was already an extensive literature within concurrency theory, but we were not able to use the theory to express even the simple idea that you may choose internally between flipping a fair or a biased coin; the existing approaches were extending labeled transition systems by adding probabilities to the arcs, losing the ability to distinguish between probabilistic and nondeterministic choice. The fact that the axioms for nondeterministic choice were not valid in most probabilistic calculi was further evidence of the problem. Starting from the observation that in the non-probabilistic world a step of a distributed algorithm corresponds to a transition of an I/O automaton, we tried to extend the notion of transition so that the process of flipping a coin could be represented by the "new" entity.  This led to the idea of "replacing points with measures" within ordinary automata and/or ordinary labeled transition systems. The idea worked very well for our analysis of randomized distributed algorithms, but we also wanted to validate it by checking whether it would simplify the concurrency-theoretical approach to probability. We decided to use simulation relations for our test, and indeed it worked and led to the CONCUR 1994 paper.<br/><br/>Nancy: For background for this paper, we should recall that, at the time,  there was a divergence in styles of modeling for distributed systems, between different concurrency theory research communities.   The style I had been using since the late 70s for modeling distributed algorithms involved interactive state machines, such as I/O automata, which are based on a set-theoretic foundation.  Such models are good for describing distributed algorithms, and for analyzing them for both correctness and costs.  On the other hand, the predominant style in the European concurrency community was more syntactic, based on logical languages like PCTL or various process algebras.  These were good for formal verification, and for studying expressive power of different formalisms, but not great for analyzing complicated distributed algorithms.  Our models were in the general spirit of the Labeled Transition System (LTS) models previously studied in Europe.  When Roberto came to MIT, he and I set about to extend prior modeling work for distributed systems to the probabilistic setting.  To do this, we considered both the set-theoretic and logical approaches.  We   needed to bridge the gap between them, which led us to the ideas in this paper.<br/><br/>Luca:  How much of your later work has built on your CONCUR 1994 paper? What follow-up results of yours are you most proud of and why?<br/><br/>Roberto: Besides using the results of the paper for the analysis of several randomized distributed algorithms, we worked jointly as well as independently on the study of the theory and on the analysis of security protocols. In collaboration with <a href="http://www.cs.ru.nl/~fvaan/">Frits Vaandrager</a>, we were able to discover different ways to analyze security in a hierarchical and compositional way. Furthermore, since in simple probabilistic automata probability and nondeterminism are well separated, it was easy to include computational complexity into the analysis of security protocols. This is work I did in collaboration with Andrea Turrini. The clear separation between probability and nondeterminism turned out to extend our approach to real-time models, leading to notions like Probabilistic Timed Automata and to several of the elements behind the first sketches of the probabilistic model checker <a href="https://www.prismmodelchecker.org/">PRISM</a> in collaboration with the group of <a href="https://www.cs.ox.ac.uk/people/marta.kwiatkowska/">Marta Kwiatkowska</a>.<br/><br/>Nancy: Roberto and I continued working on probabilistic models, in the set-theoretic style, for several years.  As Roberto notes, Frits Vaandrager also became  a major collaborator.  Some of our more recent papers following this direction are:<br/><ul><li><a href="https://www.sws.cs.ru.nl/publications/papers/fvaan/CPA.html">Compositionality for Probabilistic Automata</a>, CONCUR 2003, </li><li><a href="https://www.sws.cs.ru.nl/publications/papers/fvaan/LSVsiam/">Observing Branching Structure through Probabilistic Contexts</a>, SIAM  Journal of Computing 2007, </li><li><a href="https://groups.csail.mit.edu/tds/papers/Kirli/dilsun-icalp-tr.pdf">Task-Structured Probabilistic I/O Automata</a>, JCSS 2018.  </li></ul>This last  paper provides a kind of compositional foundation for combining  security protocols.  The key idea was to weaken the power of the adversary, making it more "oblivious".  In other related work, my students and I have worked extensively on  probabilistic distributed algorithms since then.  The models are similar to those developed in this early paper.  Examples include  wireless network algorithms, and more recently, biologically-inspired  algorithms, such as insect colony algorithms and neural network   algorithms.  I can't pinpoint a specific result that relies heavily on  the 1994 paper, but that paper certainly provided inspiration and foundation for the  later work.<br/><br/>Luca:  Did you imagine at the time that the CONCUR 1994 paper and its journal version would have so much impact? In your opinion, what is the most interesting or unexpected use in the literature of the notions and techniques you developed in your award-winning paper?<br/><br/>Roberto: We knew that the change of view proposed in the paper would have simplified the study and extension of several other concepts within concurrency theory, but we did not have any specific expectations. The collaboration on the PRISM project and on Probabilistic Timed Automata made more evident that there was a connection with Markov Decision Processes, which lead to a fruitful cross-fertilization between artificial intelligence, model checking, and concurrency theory.  It was a long exchange of ideas between a world interested in existential quantification, that is, find an optimal policy to achieve a goal, and universal quantification, that is to make sure that under any scheduler, policy, adversary, a system behaves correctly. The consequences of such exchange were many and unexpected.<br/><br/>Nancy: No, I did not anticipate that it would have broad impact, though of course I thought the ideas were important.  But in general, I am  bad at predicting what will appeal to others and inspire them to further work.<br/><br/>Luca:  The journal version of your paper appears in the Nordic Journal on Computing, which is not a prime venue. Did you ever regret not publishing that work somewhere else?  What is your take on the trend of using the perceived quality of a publication venue to evaluate research quality?<br/><br/>Roberto: Within semantics I know of a few technical reports that are much more influential than most journal papers; I do not think that the venue of a paper should be given much importance. On the other hand, venue as an evaluation tool is more objective, allows an evaluator to consider many papers without reading them, and protects the evaluator from any type of claim against decisions, which sometimes may have even legal consequences.  Needless to say that I do not agree with any of the ideas above.  I do not agree as well with the other emerging trend of counting papers to evaluate quality. One good paper is much better than ten mediocre papers. What worries me the most is that young researchers may have a hard time to concentrate on quality if they have to focus on venue and quantity. I feel I was lucky not to have to worry about these issues when we submitted our paper for the special issue of the Nordic Journal of Computing.<br/><br/>Nancy:   I certainly never regretted the venue for this paper.  In general, I haven't paid too much attention to choice of publication venue.  The main thing is to reach the audience you want to reach, which can be done through prestigious journals, less prestigious journals, conferences, or even ArXiv technical reports and some publicity.  It’s good to get feedback from referees, though. For evaluations, say for hiring or promotion, I think it’s fair to take many factors into account in evaluating research quality.  Venues, number of citations, special factors about different fields,… all can be discussed by hiring and promotion committees.  But I hope that those committees also take the time to actually read and consider the work itself.<br/><br/>Luca:  The last thirty years have seen a huge amount of work on probabilistic models of computation and on the development of proof techniques and tools based on them. What advice would you give to a young researcher interested in working on probabilistic models in concurrency today?<br/><br/>Roberto: My first advice would be to keep things simple and to focus on key ideas, possibly under the guidance of multiple application scenarios. When we study probabilistic concurrency, especially in contexts where the external world is governed by non-discrete laws, the interplay between different features of the model may become overwhelmingly complex. Of course it is a nice exercise to dive into all the details and see what it leads to, or to extend known results to the new scenarios, but how about checking whether some simple changes to one of the building blocks could make life easier?  Unfortunately, working on building blocks is risky. So, my second advice is to dive into details and write papers, but take some breaks and think whether there may be nicer ways to solve the same problems.<br/><br/>Nancy: Pick some particular application domain, and make sure that the models  and techniques you develop work well for that application.  Don't work  on the theory in a vacuum.  The models will turn out much better!  Perhaps simpler, as Roberto says.<br/><br/>Luca:  What are the research topics that currently excite you the most?<br/><br/>Roberto: Difficult question. There are many things I like to look at, but at the moment I am very curious about how quantum computing can fit in a nice and elementary way into a concurrency framework.<br/><br/>Nancy: Probabilistic algorithms, especially those that are flexible (work in  different environments), robust to failures and noise, and adaptive to  changes.  This includes such topics as wireless network algorithms,   robot swarms, and biologically-inspired algorithms.<br/><br/><b>Acknowledgements:</b> Many thanks to <a href="http://www-sop.inria.fr/members/Ilaria.Castellani/">Ilaria Castellani</a>, who pointed out some typos in the original version of this text.  </div>
    </content>
    <updated>2020-04-03T15:22:00Z</updated>
    <published>2020-04-03T15:22:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2020-04-04T14:46:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=2445</id>
    <link href="https://francisbach.com/computer-aided-analyses/" rel="alternate" type="text/html"/>
    <title>Computer-aided analyses in optimization</title>
    <summary>In this blog post, I want to illustrate how computers can be great allies in designing (and verifying) convergence proofs for first-order optimization methods. This task can be daunting, and highly non-trivial, but nevertheless usually unavoidable when performing complexity analyses. A notable example is probably the convergence analysis of the stochastic average gradient (SAG) [1],...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text">In this blog post, I want to illustrate how computers can be great allies in designing (and verifying) convergence proofs for first-order optimization methods. This task can be daunting, and highly non-trivial, but nevertheless usually unavoidable when performing complexity analyses. A notable example is probably the convergence analysis of the stochastic average gradient (SAG) [<a href="https://arxiv.org/pdf/1309.2388.pdf">1</a>], whose original proof was computer assisted.</p>



<p class="justify-text">To this end, we will mostly spend time on what is referred to as <em>performance estimation problems</em> (PEPs), introduced by Yoel Drori and Marc Teboulle [<a href="https://link.springer.com/article/10.1007/s10107-013-0653-0">2</a>]. Performance estimation is also closely related to the topic of <em>integral quadratic constraints</em> (IQCs), introduced in the context of optimization by Laurent Lessard, Benjamin Recht and Andrew Packard [<a href="https://epubs.siam.org/doi/abs/10.1137/15M1009597">3</a>]. In terms of presentations, IQCs  leverages control theory, whereas PEPs might seem more natural in the optimization community. This blog post essentially presents PEPs from the point of view of [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>], instantiated on a running example.</p>



<h2>Overview, motivations</h2>



<p class="justify-text">First-order methods for continuous optimization belong to the large panel of algorithms that are usually approached via worst-case analyses. In this context, analyses rely on combining inequalities (that are due to assumptions on the problem classes), in potentially long, non-intuitive, and technical, proofs. For the insiders, those proofs all look very similar. For the outsiders, those proofs all look rather repelling, technical (long pages of chained inequalities), probably not interesting, and like computer codes: usually intuitive mostly for their authors.</p>



<p class="justify-text">In what follows, I want to show how (and why) those proofs are indeed all very similar. On the way, I want to emphasize how those combinations of inequalities are related to the “true essence” of worst-case analyses (which rely on computing worst-case scenarios), and to provide examples on how to constructively obtain them.</p>



<p class="justify-text">We take the stand of illustrating the PEP approach on a single iteration of gradient descent, as it essentially contains all necessary ingredients to understand the methodology in other contexts as well. Certain details of the following text are (probably unavoidably) a bit technical. However, going through the detailed computations is not essential, and the text should contain the necessary ingredients for understanding the essence of the methodology.</p>



<h2>Running example: gradient descent</h2>



<p class="justify-text">Let us consider a naive, but standard, example: unconstrained convex minimization $$x_\star= \underset{x\in\mathbb{R}^d}{\mathrm{arg min}} f(x)$$with gradient descent: \(x_{k+1}=x_k-\gamma \nabla f(x_k)\). Let us assume \(f(\cdot)\) to be continuously differentiable, to have a \(L\)-Lipschitz gradient (a.k.a., \(L\)-smoothness), and to be \(\mu\)-strongly convex. Those functions satisfy, for all \(x,y\in\mathbb{R}^d\):<br/>– strong convexity, see e.g., [<a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">5</a>, Definition 2.1.2]: $$\tag{1}f(x) \geqslant      f(y)+\langle{\nabla f(y)}; {x-y}\rangle+\tfrac{\mu}{2} \lVert x-y\rVert^2,$$- smoothness, see e.g., [<a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">5</a>, Theorem 2.1.5]: $$\tag{2} f(x) \leqslant      f(y)+\langle{\nabla f(y)}; {x-y}\rangle+\tfrac{L}{2}\lVert x-y\rVert^2.$$Let us recall that in the case of twice continuously differentiable functions, smoothness and strong convexity amount to requiring  that $$\mu I \preccurlyeq \nabla^2 f(x) \preccurlyeq L I,$$ for some \(0&lt; \mu&lt;L&lt; \infty\) and for all \(x\in\mathbb{R}^d\) (in other words, all eigenvalues of \(\nabla^2 f(x)\) are between \(\mu\) and \(L\)). In what follows, we denote by \(\mathcal{F}_{\mu,L}\) the class of \(L\)-smooth \(\mu\)-strongly convex functions (irrespective of the dimension \(d\)).</p>



<div class="wp-block-group"><div class="wp-block-group__inner-container">
<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" height="204" src="https://www.di.ens.fr/~ataylor/BlogPost/SmoothStronglyConvex.png" width="473"/>Figure 1: the blue function is \(L\)-smooth and \(\mu\)-strongly convex (it is possible to create respectively global upper and lower quadratic bounds from every \(x\in\mathbb{R}^d\) with respectively curvatures \(L\) and \(\mu\)).</figure></div>
</div></div>



<p class="justify-text">In this context, convergence of gradient descent can be studied in many ways. Here, for the sake of the example, we will do it in terms of two base quantities: distance to optimality \(\lVert x_k-x_\star\rVert\), and function value accuracy \(f(x_k)-f(x_\star)\). There are, of course, infinitely many other possibilities, such as gradient norm \(\rVert \nabla f(x_k)\lVert\), Bregman divergence \(f(x_\star)-f(x_k)-\langle{\nabla f(x_k)};{x_\star-x_k}\rangle\), or even best function value observed throughout the iterations \(\min_{0\leq i\leq k} \{f(x_i)-f(x_\star)\}\): the reader can adapt the lines below for his/her favorite criterion. </p>



<p class="justify-text">For later reference, let us provide another inequality that is known to  hold for all \(x,y\in\mathbb{R}^d\) for any \(L\)-smooth \( \mu\)-strongly convex function: <br/>– bound on inner product, see, e.g., [<a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">5</a>,  Theorem 2.1.11]: $$\langle{\nabla f(x)-\nabla f(y)};{x-y}\rangle  \geqslant        \tfrac{1}{L+\mu} \lVert{\nabla f(x)-\nabla f(y)}\rVert^2+\tfrac{\mu  L}{L+\mu}\lVert{x-y}\rVert^2.\tag{3}$$ In the case \(\mu=0\) this inequality is known as “cocoercivity”. This (perhaps mysterious) inequality happens to play an important role in convergence proofs.</p>



<h3>A standard convergence result</h3>



<p class="justify-text">Let us start by stating two known results along with their simple proofs (see, e.g.,  [<a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">5</a>, Theorem 2.1.14] or [6, Section 1.4.2, Theorems 2 &amp; 3]):<br/>– convergence in distance:  $$\begin{array}{rl}    \rVert{x_{k+1}-x_\star}\lVert^2&amp;= \lVert{x_k-x_\star}\rVert^2+\gamma^2\lVert{\nabla f(x_k)}\rVert-2\gamma\langle{\nabla f(x_k)};{x_k-x_\star}\rangle \\ \     &amp; \leqslant      \left(1-\tfrac{2\gamma L \mu}{L+\mu}\right)\lVert{x_k-x_\star}\rVert^2+\gamma\left(\gamma-\tfrac2{L+\mu}\right)\lVert{\nabla f(x_k)}\rVert^2, \end{array} $$ where the second line follows from smoothness and strong convexity of \(f\) via the bound (3) on the inner product (with \(x=x_k\) and \(y=x_\star\)). For the particular choice \(\gamma=\tfrac2{L+\mu}\), the second term on the right hand side disappears, and we end up with<br/>     $$\lVert{x_{k+1}-x_\star}\rVert^2 \leqslant      \left(\tfrac{L-\mu}{L+\mu}\right)^2\lVert{x_k-x_\star}\rVert^2,$$ which, following from \(0&lt;\mu&lt;L&lt;\infty\), satisfies \(0&lt; \tfrac{L-\mu}{L+\mu}&lt;1\), hence proving linear convergence of gradient descent in this setup, by recursively applying the previous inequality: $$ \lVert{x_{k}-x_\star}\rVert^2 \leqslant      \left(\tfrac{L-\mu}{L+\mu}\right)^{2k}\lVert{x_0-x_\star}\rVert^2.$$ – Convergence in function values: one can simply use the result in distance along with the previous basic inequalities (1) and (2) characterizing smoothness and strong convexity (both with \(y=x_\star\)):<br/>     $$f(x_k)-f(x_\star) \leqslant \hspace{-.15cm}\tfrac{L}{2}\hspace{-.1cm}\rVert{x_k-x_\star}\lVert^2  \leqslant  \hspace{-.15cm}    \tfrac{L}{2}\hspace{-.1cm}\left(\tfrac{L-\mu}{L+\mu}\right)^{\hspace{-.1cm}2k} \rVert{x_0-x_\star}\lVert^2 \leqslant  \hspace{-.15cm}     \tfrac{L}{\mu}\hspace{-.1cm} \left(\tfrac{L-\mu}{L+\mu}\right)^{\hspace{-.1cm}2k}(f(x_0)-f(x_\star)).$$  It is also possible to directly look for convergence in terms of function values, but it is then usually unclear in the literature what inequalities to use, and I am not aware of any such proof leading to the same rate without the leading \(\tfrac{L}{\mu}\) (except the proof presented below).</p>



<p class="justify-text">At this point, even in this toy example, a few very legitimate questions can be raised:<br/>– can we improve anything? Can gradient descent really behaves like that on this class of functions?<br/>– How could we have guessed the inequality to use, and the shape of the corresponding proof? Obviously, the obscure fact is to arrive to inequality (1).  Therefore, is there a principled way for choosing the right inequalities to use, for example for studying convergence in terms of other quantities, such as  function values?<br/>– Is this the unique way to arrive to the desired result? If yes, how likely are we to find such proofs for more complicated cases (algorithms and/or function class)?</p>



<p class="justify-text">For the specific step size choice \(\gamma=\tfrac2{L+\mu}\), a partial answer to the first question is obtained by the observation that the rate is actually achieved on the quadratic function<br/> $$f(x)=\tfrac12 \, x^\top \begin{bmatrix}<br/> L &amp; 0\\ 0 &amp; \mu<br/> \end{bmatrix}x.$$ The following lines precisely target the missing answers.</p>



<h2>Worst-case analysis through worst-case scenarios</h2>



<p class="justify-text">Let us start by rephrasing our goal, and restrict ourselves to the study of a single iteration. We fix our target to finding the smallest possible value of \(\rho\) such that the inequality<br/> $$ \lVert{x_{k+1}-x_\star}\rVert^2  \leqslant       \rho^2 \lVert{x_k-x_\star}\rVert^2 $$ is valid for all \(x_k\) and \(x_{k+1}=x_k-\gamma \nabla f(x_k)\) (hence \(\rho\) is a function of \(\gamma\)). In other words, our goal is to solve<br/>$$ \rho^2(\gamma):= \sup \left\{ \frac{\lVert{x_{k+1}-x_\star}\rVert^2}{\lVert{x_k-x_\star}\rVert^2}\, \big|\, f\in\mathcal{F}_{\mu,L},\, x_{k+1}=x_k-\gamma \nabla f(x_k),\, \nabla f(x_\star)=0\right\}.$$<br/>Alternatively, we could be interested in studying convergence in other forms: for function values, we could target to solve the slightly modified problem:<br/> $$ \sup  \left\{ \frac{f(x_{k+1})-f(x_\star)}{f(x_{k})-f(x_\star)}\, \big|\, f\in\mathcal{F}_{\mu,L},\, x_{k+1}=x_k-\gamma \nabla f(x_k),\, \nabla f(x_\star)=0 \right\}.$$ It turns out that in both cases, the problem can be solved both numerically to high precision, and analytically, and that the answer is \(\rho^2(\gamma)=\max\{(1-\mu\gamma)^2,(1-L\gamma)^2\}\).</p>



<p class="justify-text">The only thing we did, so far, was to explicitly reformulate the problem of finding the best (smallest) convergence rate as the problem of finding the worst-case scenario, nothing more. In what follows, some parts might become slightly technical, but the overall idea is only to reformulate this problem of finding the worst-case scenarios, for solving it.</p>



<h3>Dealing with an infinite-dimensional variable: the function \(f\)</h3>



<p class="justify-text">The first observation is that the problem of computing \(\rho\) is stated as an infinite-dimensional optimization problem: we are looking for the worst possible problem instance (a function \(f\) and an initial point \(x_k\)) within a predefined class of problems. The first step we take to work around this is to reformulate it in the following equivalent  form (note that we maximize also over the dimension \(d\)—we discuss later how to remove it):<br/>$$\begin{array}{rl} \rho^2:= \underset{f,\, x_k,\,x_\star,\, g_k,\,d}{\sup} &amp;\displaystyle \frac{\lVert{x_{k}-\gamma g_k-x_\star}\rVert^2}{\lVert{x_k-x_\star}\rVert^2}\\<br/> \text{s.t. }    &amp; \exists f\in\mathcal{F}_{\mu,L}:\, g_k= \nabla f(x_k),\, 0=\nabla f(x_\star).<br/>\end{array}$$<br/>This problem intrinsically does not look better (it contains an  existence constraint), but it allows using mathematical tools which are referred to as  <em>interpolation,</em> or <em>extension</em>, theorems [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>, <a href="https://arxiv.org/pdf/1603.00241.pdf">7</a>, <a href="https://hal.archives-ouvertes.fr/hal-01530908/file/DHLL_appendix.pdf">8</a>]. The problem is depicted on Figure 2:</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" height="209" src="https://www.di.ens.fr/~ataylor/BlogPost/Interpolation.png" width="490"/>Figure 2: discrete interpolation (or extension) problem: given a set of triplets \(\{(\text{coordinate}, \text{gradient}, \text{function value})\}\) can we recover a function within a determined class that explains those triplets?</figure></div>



<p class="justify-text">It turns out that convex interpolation (that is, neglecting smoothness and strong convexity) is actually rather simple:</p>



<ul class="justify-text"><li>given a convex function and an index set \(I\), any set of samples \(\{(x_i,g_i,f_i)\}_{i\in I}\) of the form \(\{(\text{coordinate}, \text{(sub)gradient}, \text{function value})\}\)) satisfies, for all \(i,j\in I\): $$f_i \geqslant      f_j+\langle g_j; x_i-x_j\rangle,$$ by definition of subgradient, as illustrated on Figure 3.</li></ul>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" height="205" src="https://www.di.ens.fr/~ataylor/BlogPost/SamplingCvx.png" width="485"/>Figure 3: sampling from a convex function.</figure></div>



<ul class="justify-text"><li>In the other direction, given a set of triplets \(\{(x_i,g_i,f_i)\}_{i\in I}\) satisfying the previous inequality for all pairs \(i,j\in I\), one can simply recover a  convex function by the following construction: $$f(x)=\underset{i\in I}{\max}\{ f_i+\langle g_i;x-x_i\rangle\},$$ which is depicted on Figure 4.</li></ul>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" height="207" src="https://www.di.ens.fr/~ataylor/BlogPost/InterpolateCvx.png" width="487"/>Figure 4: some set \(\{(x_i,g_i,f_i)\}_{i\in I}\) and its piecewise affine interpolant \(f(x)=\underset{i\in I}{\max}\{ f_i+\langle g_i;x-x_i\rangle\}\).</figure></div>



<ul class="justify-text"><li>Formally, the reasoning allows arriving to the following “convex interpolation” (or “convex extension”) result, where we denote the set of (closed, proper) convex functions by \(\mathcal{F}_{0,\infty}\) (to be understood as \(L\)-smooth \(\mu\)-strongly convex functions with \(\mu=0\) and \(L=\infty\)): $$\begin{array}{c}\exists f\in\mathcal{F}_{0,\infty}: \,  g_k\in\partial f(x_k) \text{ and } f_k=f(x_k) \ \ \forall k\in  I\\ \Leftrightarrow\\ f_i \geqslant       f_j+\langle{g_j};{x_i-x_j}\rangle\quad \forall i,j\in I,\end{array}$$ where \(\partial f(x)\) denotes the subdifferential of \(f\) at \(x\).</li></ul>



<p class="justify-text">In the next section, we use a similar interpolation result for taking smoothness and strong convexity into account. The result is a bit more technical, but follows from similar constructions as those for convex interpolation—the main difference being that the interpolation is done on the Fenchel conjugate instead, in order to incorporate smoothness, see [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>, Section 2].</p>



<h3>Reformulation through convex interpolation</h3>



<p class="justify-text">Back to the problem of computing worst-case scenarios, we can now reformulate the existence constraint <em>exactly</em> using the following result (see [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>,  Theorem 4]): let \(I\) be a finite index set and let \( S=\{(x_i,g_i,f_i)\}_{i\in I}\) be a set of triplets, then<br/>  $$\begin{array}{c}\exists f\in\mathcal{F}_{\mu,L}: \,  g_i=\nabla f(x_i) \text{ and } f_i=f(x_i) \text{ for all } i\in  I\\ \Leftrightarrow\\  f_i \geqslant      f_j+\langle{g_j};{x_i-x_j}\rangle+\frac{1}{2L}\lVert{g_i-g_j}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_i-x_j-\frac{{1}}{L}(g_i-g_j)}\rVert^2  \,\,\, \forall i,j\in I.\end{array}$$ Therefore, the previous problem can be reformulated as (recalling that \(g_\star=0\))<br/>$$  \begin{array}{rl} \underset{{f_k,\,f_\star,\, x_k,\,x_\star,\, g_k,\,d}} {\sup}&amp;\displaystyle\frac{\rVert{x_{k}-\gamma  g_k-x_\star}\lVert^2}{\rVert{x_k-x_\star}\lVert^2}\\<br/>      \text{s.t. }    &amp; f_\star \geqslant      f_k+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2\\<br/>      &amp; f_k \geqslant      f_\star+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2.<br/>\end{array}$$ </p>



<h3>Quadratic reformulation</h3>



<p class="justify-text">The next step is to remove the ratio appearing in the objective function, which we do via an homogeneity argument, as follows.</p>



<p class="justify-text">Starting from a feasible point, scale \(x_k,\,x_\star,g_k\) by some \(\alpha&gt;0\) and \(f_k,\,f_\star\) by \(\alpha^2\) and observe it does not change the value of the objective, while still being a feasible point. Therefore, the problem can be reformulated as a nonconvex QCQP (quadratically constrained quadratic program): $$  \begin{array}{rl} \underset{{f_k,\,f_\star,\, x_k,\,x_\star,\, g_k,\,d}} {\sup}&amp;\displaystyle{\rVert{x_{k}-\gamma  g_k-x_\star}\lVert^2}\\<br/>       \text{s.t. }    &amp; f_\star \geqslant      f_k+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2\\<br/>       &amp; f_k \geqslant      f_\star+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2\\ &amp;{\rVert{x_k-x_\star}\lVert^2} \leqslant      1,<br/> \end{array}$$  which is quadratic in \(x_k\), \(x_\star\) and  \(g_k\), and linear in \(f_\star\) and \(f_k\). Actually, in the current form, nonconvexity comes from the term “\(\langle{g_k};{x_\star-x_k}\rangle\)” in the second constraint. It turns out that this problem can be reformulated <em>losslessly</em> using semidefinite programming (this is due to the maximization over \(d\)). </p>



<h3>Semidefinite reformulation</h3>



<p class="justify-text">At the end of this section, we will be able to compute, numerically, the values of the rate \(\rho^2(\gamma)\) for given values of the parameters \(\mu,\,L\), and \(\gamma\).</p>



<p class="justify-text">The last step in the reformulation goes as follows: the previous problem can be reformulated as a semidefinite program, as it is linear in terms of the entries of the following Gram matrix<br/>$$G = \begin{pmatrix}<br/>     \lVert{x_k-x_\star}\rVert^2 &amp; \langle{g_k};{x_k-x_\star}\rangle \\ \langle{g_k};{x_k-x_\star}\rangle &amp; \lVert{g_k}\rVert^2<br/>     \end{pmatrix}\succcurlyeq 0,$$ and in terms of the function values \(f_k\) and \(f_\star\). From those variables, one reformulate the previous problem as $$\begin{array}{rl} \underset{f_k,\,f_\star,\, G\succeq 0}{\sup} \, &amp;{\mathrm{Tr} (A_\text{num} G)}\\<br/>      \text{s.t. }    &amp; f_k-f_\star+\mathrm{Tr} (A_1 G)\leqslant 0\\<br/>      &amp;  f_\star-f_k+\mathrm{Tr} (A_2 G)\leqslant 0 \\<br/>      &amp;\mathrm{Tr} (A_\text{denom} G) \leqslant      1,\end{array}$$ which is a gentle semidefinite program where we picked matrices \(A_{\text{num}}\), \(A_{\text{denom}}\), \(A_1\) and \(A_2\) for encoding the previous terms. That is, we choose those matrices such that<br/> $$\begin{array}{rl}<br/>\mathrm{Tr}(A_{\text{denom}} G)&amp;=\lVert{x_k-x_\star}\rVert^2,\\  \mathrm{Tr}(A_{\text{num}} G)&amp;=\lVert{x_k-\gamma g_k-x_\star}\rVert^2,\\ \mathrm{Tr}(A_1G)&amp;=\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2,\\ \mathrm{Tr}(A_2G)&amp;=\tfrac{1}{2L}\lVert g_k\rVert^2+\tfrac{\mu}{2(1-\mu/L)}\lVert x_k-x_\star-\tfrac1L g_k\rVert^2.\end{array}$$ One possibility is to choose \(A_{\text{num}}\), \(A_{\text{denom}}\), \(A_1\) and \(A_2\) as symmetric matrices, as follows: $$\begin{array}{cc}<br/> A_{\text{denom}}=\begin{pmatrix}     1 &amp; 0\\ 0 &amp; 0     \end{pmatrix}, &amp; A_{\text{num}}=\begin{pmatrix}     1 &amp; -\gamma\\ -\gamma &amp; \gamma^2     \end{pmatrix}, \\ A_1=\begin{pmatrix}\tfrac{\mu}{2(1-\mu/L)} &amp; -\tfrac12-\tfrac{\mu}{2(L-\mu)} \\ -\tfrac12-\tfrac{\mu}{2(L-\mu)} &amp; \tfrac{1}{2L}+\tfrac{\mu}{2L(L-\mu)}\end{pmatrix}, &amp;  A_2=\begin{pmatrix}\tfrac{\mu}{2(1-\mu/L)} &amp; -\tfrac{\mu}{2(L-\mu)} \\ -\tfrac{\mu}{2(L-\mu)} &amp; \tfrac{1}{2L}+\tfrac{\mu}{2L(L-\mu)} \end{pmatrix}.\end{array}$$</p>



<p class="justify-text">All those steps can be carried out in the exact same way for the problem of computing the convergence rate for function values, reaching a similar problem with \(6\) inequality constraints instead—because interpolation conditions have to be imposed on all pairs of points in a set of \(3\) points: \(x_k\), \(x_{k+1}\) and \(x_\star\), instead of only \(2\) for the distance problem. The objective function is then \(f_{k+1}-f_\star\), the de-homogenization constraint (arising from the denominator of the objective function) is \(f_{k}-f_\star \leqslant     1\), and the Gram matrix is \(3\times 3\):<br/>$$G=\begin{pmatrix}<br/>     \lVert{x_k-x_\star}\rVert^2 &amp; \langle{g_k};{x_k-x_\star}\rangle&amp; \langle{g_{k+1}};{x_k-x_\star}\rangle\\ \langle{g_k};{x_k-x_\star}\rangle &amp; \lVert{g_k}\rVert^2 &amp; \langle{g_k};{g_{k+1}}\rangle \\<br/>     \langle{g_{k+1}};{x_k-x_\star}\rangle &amp; \langle{g_{k+1}};{g_k}\rangle &amp; \lVert{g_{k+1}}\rVert^2<br/>     \end{pmatrix}\succcurlyeq 0, $$ and the function values variables are \(f_k\), \(f_{k+1}\) and \(f_\star\).</p>



<p class="justify-text">We provide the numerical optimal values of those semidefinite programs on Figure 5 for both convergence in distances and in function values. </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" height="324" src="https://www.di.ens.fr/~ataylor/BlogPost/ObjectiveValues.png" width="534"/>Figure 5: worst-cases of the ratio \(\frac{\lVert{x_{k+1}-x_\star}\rVert^2}{\lVert{x_k-x_\star}\rVert^2}\) (red) and \(\frac{f(x_{k+1})-f_\star}{f(x_k)-f_\star}\) (dashed blue) as functions of the step size \(\gamma\), for the case where \(f\) is \(1\)-smooth and \(0.1\)-strongly convex. The results match exactly the expected \(\max\{(1-\gamma L)^2,(1-\gamma\mu)^2\}\) in both cases. Note that the corresponding SDPs can be solved both for “good and bad” choices of step sizes: if the step size is chosen wisely then \(\rho(\gamma)&lt;1\), and otherwise \(\rho(\gamma)\geqslant 1\). The SDP confirms the common knowledge that \(\gamma\in (0,2/L)\Rightarrow \rho(\gamma)&lt; 1\). Numerical values obtained through YALMIP [<a href="https://yalmip.github.io/">9</a>] and Mosek [<a href="https://www.mosek.com/">10</a>].</figure></div>



<p class="justify-text">As a conclusion for this section, let us note that we showed how to compute the “best” rates that are dimension independent. Technically, requiring \(x_k\) and \(g_k\) to lie in \(\mathbb{R}^d\) is equivalent to adding a rank constraint in the SDP.</p>



<h2>Duality between worst-case scenarios and combinations of inequalities</h2>



<p class="justify-text">Any feasible point to the previous SDP corresponds to a <em>lower bound</em>: a sampled version of a potentially difficult function for gradient descent. If we want to find <em>upper bounds</em> on the rate, a natural way to proceed is to go to the dual side of the previous SDPs, where any feasible point will naturally correspond to an upper bound on the convergence rate (by <em>weak duality</em>). As the primal problems were SDPs, their Lagrangian duals are SDPs as well. Let us associate one multiplier per constraint: $$ \begin{array}{rl}<br/>f_k-f_\star+\mathrm{Tr} (A_1 G)\leqslant 0&amp;:\lambda_1\\<br/>f_\star-f_k+\mathrm{Tr} (A_2 G)\leqslant 0&amp;:\lambda_2\\<br/>\mathrm{Tr}(A_\text{denom} G) \leqslant 1&amp;: \tau.<br/>\end{array}$$The dual is then<br/>$$\begin{array}{rl}<br/> \underset{\tau,\,\lambda_1,\,\lambda_2}{\min} &amp; \, \tau \\<br/> \text{s.t. } &amp; \lambda_1=\lambda_2,\\<br/> &amp; S:=A_\text{num}-\tau A_\text{denom}-\lambda_1A_1-\lambda_2A_2 \preccurlyeq 0,\\<br/> &amp;\tau,\lambda_1,\lambda_2 \geqslant  0.<br/> \end{array}$$ Hence, by weak duality, any feasible point to this last SDP corresponds to an upper bound on the rate: \(\tau \geqslant \rho^2\). A mere rephrasing of weak duality can be obtained through the following reasoning: assume we received some feasible \(\tau,\lambda_1,\lambda_2\) (and hence \(\lambda_1=\lambda_2\) and a corresponding \(S\preccurlyeq 0\)), we then get, for any primal feasible \(G\succcurlyeq0\):<br/>$$\begin{array}{rl}\mathrm{Tr}(SG)&amp;=\mathrm{Tr}(A_{\text{num}}G)-\tau\mathrm{Tr}(A_{\text{denom}}G)-\lambda_1\mathrm{Tr}(A_1G)-\lambda_2\mathrm{Tr}(A_2G)\\&amp;=\lVert x_{k+1}-x_\star\rVert^2-\tau\lVert x_{k}-x_\star\rVert^2\\ \,&amp;\,\,\,-\lambda_1[     f_k-f_\star+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2]\\ &amp;\,\,\,-\lambda_2 [f_\star-f_k+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2]\\ &amp;\geqslant \lVert x_{k+1}-x_\star\rVert^2-\tau\lVert x_{k}-x_\star\rVert^2, \end{array}$$ where the first equality follows from the definition of \(S\), the second equality corresponds to the definitions of \(A_{\text{num}}\), \(A_{\text{denom}}\), \(A_1\) and \(A_2\), and the last inequality follows from the sign of the interpolation inequalities (constraints in the primal) for any primal feasible point. Hence, we indeed have that any feasible \(\tau\) corresponds to a valid upper bound on the convergence rate, as $$S\preccurlyeq 0 \,\,\Rightarrow \,\, \mathrm{Tr}(SG)\leqslant 0\,\,\Rightarrow  \lVert x_{k+1}-x_\star\rVert^2-\tau\lVert x_{k}-x_\star\rVert^2\leqslant 0.$$ In order to obtain analytical proofs, we therefore need to find analytical dual feasible points, and numerics can of course help in this process! Let’s look at what the optimal dual solutions look like for our two running examples.</p>



<ul class="justify-text"><li> in Figure 6, we provide the numerical values for \(\lambda_1\) and \(\lambda_2\) for the distance problem.</li></ul>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" height="316" src="https://www.di.ens.fr/~ataylor/BlogPost/Multipliers_distance.png" width="467"/>Figure 6: numerical values of optimal dual variables: \(\lambda_1\) (red) and \(\lambda_2\) (dashed blue) as functions of the step size \(\gamma\), for the case where \(f\) is \(1\)-smooth and \(0.1\)-strongly convex. The results match \(\lambda_1=\lambda_2=2\gamma \rho(\gamma)\) with \(\rho(\gamma)=\max\{|1-\gamma L|,|1-\gamma\mu|\}\). Numerical values obtained with YALMIP [<a href="https://yalmip.github.io/">9</a>] and Mosek [<a href="https://www.mosek.com/">10</a>].</figure></div>



<ul class="justify-text"><li>For function values, the SDP is slightly more complicated, as more inequalities are involved (6 interpolation inequalities). We provide raw numerical values for the six multipliers in Figure 7.</li></ul>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img alt="" height="348" src="https://www.di.ens.fr/~ataylor/BlogPost/Multipliers_function.png" width="463"/>Figure 7: numerical values of optimal dual variables (for the rate in function values): \(\lambda_1,\lambda_2, …,\lambda_6\) as functions of the step size \(\gamma\), for the case where \(f\) is \(1\)-smooth and \(0.1\)-strongly convex. Numerical values obtained with YALMIP [<a href="https://yalmip.github.io/">9</a>] and Mosek [<a href="https://www.mosek.com/">10</a>].</figure></div>



<p>For those who want a bit more details, here are a few additional pointers:</p>



<ul class="justify-text"><li>Strong duality holds—a way to prove it is to show that there exists a Slater point in the primal, see e.g., [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>, Theorem 6]—, and hence primal and dual optimal values match.</li><li>There might be different ways to optimaly combine the interpolation inequalities for proving the desired results. In other words: dual optimal solutions are often not unique—which is, in fact, quite a good news: I am sure nobody want to find the analytical version of the multipliers provided in Figure 7.</li><li>It is often possible to simplify the proofs by using fewer, or weaker, inequalities. This might lead to ”cleaner” results, typically (but not always) at the cost of ”weaker” rates. This was done for designing the proof for function values, later in this text.</li></ul>



<h2>Combinations of inequalities: same proofs without SDPs</h2>



<p class="justify-text">So far, we showed that computing convergence rates can be done in a very principled way. To this end, one can solve semidefinite programs—which may have arbitrarily complicated analytical solutions. Here, I want to emphasize that the process of <em>verifying</em> a solution can be quite different to that of<em> finding</em> a solution. Put in other words, although the dual certificates (a.k.a., the proofs) might have been found by solving SDPs, they can be formulated in ways that do not require the reader to know anything about the PEP methodology, nor on any SDP material, for verifying them. This fact might actually not be very surprising to the reader, as many proofs arising in the first-order optimization literature actually “only consists” in linear combinations of (quadratic) inequalities. On the one hand, those proofs can be seen as feasible points to “dual SDPs”, although generally not explicitely proved as such. On the other hand, proofs arising from the SDPs might therefore be expected to be writable without any explicit reference to semidefinite programing and performance estimation problems.<br/></p>



<p class="justify-text">In what follows, we provide the proofs for gradient descent, using the previous numerical inspiration, but without explicitly relying on any semidefinite program. The reader is not expected to verify any of those computations, as our goal is rather to emphasize that the principles underlying both proofs are exactly the same: reformulating linear combinations of inequalities.</p>



<p class="justify-text">For both proofs below, we limit ourselves to the step size regime \(0\leq   \gamma \leq \tfrac{2}{L+\mu}\), and we prove  that, in  this regime, \(\rho(\gamma)=(1-\gamma\mu)\)—actually we only proof the upper bounds, but one can easily verify that they are <em>tight</em> on simple quadratic functions.  The complete proofs (for the proximal gradient method),  can be found in [<a href="https://arxiv.org/pdf/1705.04398.pdf">11</a>]. </p>



<h3>Example 1: distance to optimality</h3>



<p class="justify-text">Recall the notations: \(g_k:=\nabla f(x_k)\), \(f_k:= f(x_k)\), \(g_\star:=\nabla f(x_\star)\), and \(f_\star:= f(x_\star)\).</p>



<p class="justify-text">For distance to optimality, sum the following inequalities with their corresponding weights: $$\begin{array}{r}     f_\star \geqslant      f_k+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k-g_\star}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}(g_k-g_\star)}\rVert^2  :\lambda_1,  \\     f_k \geqslant      f_\star+\langle{g_\star};{x_k-x_\star}\rangle+\frac{1}{2L}\lVert{g_k-g_\star}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}(g_k-g_\star)}\rVert^2:\lambda_2.     \end{array}$$ We use the following values for the multipliers: \(\lambda_1=\lambda_2=2\gamma\rho(\gamma) \geqslant      0\) (see Figure 6). </p>



<p class="justify-text">After appropriate substitutions of \(g_\star\), \(x_{k+1}\), and \(\rho(\gamma)\), using respectively \(g_\star=0\), \(x_{k+1}=x_k-\gamma g_k\) and \(\rho(\gamma)=(1-\gamma\mu)\), and with little effort, one can check that the previous weighted sum of inequalities can be written in the form: $$ \begin{array}{rl}    \lVert{x_{k+1}-x_\star}\rVert^2  \leqslant      &amp; \left(1-\gamma \mu \right)^2\lVert{x_{k}-x_\star}\rVert^2 -\frac{\gamma(2-\gamma (L+\mu))}{L-\mu} \lVert{\mu {(x_k  -x_\star)} – g_k}\rVert^2. \end{array}$$ This statement can be checked simply by expanding both expressions (i.e., the weighted sum and its reformulation) and verifying that all terms indeed match.</p>



<p class="justify-text">Finally, using $$\gamma(2-\gamma (L+\mu)) \geqslant      0,  \text{ and } L-\mu \geqslant      0,$$ which are nonnegative by assumptions on the values of \(L\in(0,\infty)\), \(\mu\in (0,L)\) and \(\gamma\in(0,2/(L+\mu))\), we arrive to the desired $$ \lVert{x_{k+1}-x_\star}\rVert^2 \leqslant      \left(1-\gamma \mu \right)^2\lVert{x_{k}-x_\star}\rVert^2.$$</p>



<p class="justify-text">Note that, by using \(\lambda_1=\lambda_2\), the weighted sum exactly corresponds to the (scaled by a positive constant) inequality introduced in the early stage of this note for studying distance to optimality. However, the resulting expression is tight for all values of the step size here, whereas it was only tight for \(\gamma=2/(L+\mu)\) earlier, due to a different choice of weights! </p>



<p class="justify-text">The curious reader might wonder how to find such a reformulation. Actually, back in terms of SDPs, and using the expressions for the multipliers, it simply corresponds to $$\mathrm{Tr}(SG)=-\frac{\gamma(2-\gamma (L+\mu))}{L-\mu} \lVert{\mu {(x_k  -x_\star)} – g_k}\rVert^2.$$ In the example below, the reformulation is a bit more tricky—as \(\mathrm{Tr}(SG)\)  has two nonnegative terms, which were simply obtained by doing an analytical Cholesky factorization of the term \(\mathrm{Tr}(SG)\)—, but the idea is exactly the same.</p>



<h3>Example 2: function values</h3>



<p class="justify-text">For function values, we combine the following inequalities after multiplication with their respective coefficients:    </p>



<p class="justify-text">$$\scriptsize \begin{array}{lr}     f_k \geqslant      f_{k+1}+\langle{g_{k+1}};{x_k-x_{k+1}}\rangle+\frac{1}{2L}\lVert{g_k-g_{k+1}}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_{k+1}-\frac{1}{L}(g_k-g_{k+1})}\rVert^2    &amp;:\lambda_1,\\<br/>f_\star \geqslant      f_k+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k-g_\star}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{1}{L}(g_k-g_\star)}\rVert^2  &amp;:\lambda_2, \\<br/>f_\star \geqslant      f_{k+1}+\langle{g_{k+1}};{x_\star-x_{k+1}}\rangle+\frac{1}{2L}\lVert{g_\star-g_{k+1}}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_\star-x_{k+1}-\frac{1}{L}(g_\star-g_{k+1})}\rVert^2  &amp;:\lambda_3.     \end{array}$$ We use the following multipliers \(\lambda_1=\rho(\gamma)\), \(\lambda_2=(1-\rho(\gamma))\rho(\gamma)\), and  \(\lambda_3=1-\rho(\gamma)\) (obtained by greedily trying to set different combinations of multipliers to \(0\) in the SDP—see Figure 7 for the values without such simplifications).</p>



<p class="justify-text">Again, after appropriate substitutions of \(g_\star\), \(x_{k+1}\), and \(\rho(\gamma)\), using respectively \(g_\star=0\), \(x_{k+1}=x_k-\gamma g_k\) and \(\rho(\gamma)=(1-\gamma\mu)\), we obtain that the weighted sum of inequalities can be reformulated exactly as $$  \begin{array}{rl}          f(x_{k+1})-f_\star \leqslant      &amp;\left(1-\gamma \mu\right)^2 \left(f(x_k)-f_\star\right)\\&amp;-\frac{1}{2 (L-\mu)}\lVert \nabla f(x_{k+1})-(1-\gamma  (L+\mu))\nabla f(x_k) +\gamma  \mu  L (x_\star-x_k)\rVert^2\\<br/>&amp;-\frac{\gamma  L(2- \gamma  (L+\mu))}{2 (L-\mu )}\lVert \nabla f(x_k)+\mu  (x_\star-x_k)\rVert^2.\end{array}$$ Again, this statement can be checked simply by expanding both expressions (i.e., the weighted sum and its reformulation), and verifying that all terms match. The desired conclusion $$ f(x_{k+1})-f_\star \leqslant \left(1-\gamma \mu\right)^2 \left(f(x_k)-f_\star\right), $$ follows from the signs of the leading coefficients: \(\gamma(2-\gamma (L+\mu)) \geqslant      0\), and \(L-\mu \geqslant      0\).</p>



<h3>To go further</h3>



<p class="justify-text">Before finishing, let us mention that we only dealt with linear convergence through a single iteration of gradient descent.</p>



<p class="justify-text">There are quite a few ways to handle both more iterations and sublinear convergence rates. Using SDPs, probably the most natural approach is to directly incorporate several iterations in the problem by  studying, for example, ratios of the form  $$\sup_{f\in\mathcal{F}_{\mu,L},\, x_0}  \frac{f(x_{N})-f_\star}{\lVert x_0-x_\star\rVert^2}. $$ This type of approach was used in the work of Drori and Teboulle [<a href="https://arxiv.org/pdf/1206.3209.pdf">2</a>] and in most consecutive PEP-related works: it has the advantage of providing  comfortable “non-improvable results” [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>, <a href="https://arxiv.org/pdf/1512.07516.pdf">12</a>]   (by providing matching lower bounds) for any given \(N\), but requires solving larger and larger SDPs. Alternatively, simpler proofs can often be obtained through the use of  Lyapunov (or potential) functions—i.e., study a single iteration to produce recursable inequalities; a nice introduction is provided in [<a href="http://www.theoryofcomputing.org/articles/v015a004/v015a004.pdf">13</a>]. This idea can be exploited in PEPs [<a href="https://arxiv.org/pdf/1902.00947.pdf">14</a>] by enforcing the proofs to have a certain structure. Those principles are also at the heart of the related approach using integral quadratic constraints [<a href="https://epubs.siam.org/doi/abs/10.1137/15M1009597">3</a>, <a href="http://proceedings.mlr.press/v70/hu17a/hu17a.pdf">15</a>]. </p>



<h2>Take-home message and conclusions</h2>



<p class="justify-text">The overall message of this note is that first-order methods can often be studied directly using the definition of their “worst-cases” (i.e., by trying to find worst-case scenarios), along with their dual counterparts (linear combinations of inequalities), by translating them into semidefinite programs.</p>



<p class="justify-text">What we saw might look like an overkill for studying gradient descent. However, as long as we deal with Euclidean spaces, the same approach actually works beyond this simple case. In particular, the same technique applies to first-order methods performing explicit, projected, proximal, conditional, and inexact (sub)gradient steps [<a href="https://arxiv.org/pdf/1512.07516.pdf">12</a>].</p>



<p class="justify-text">Finally, let us mention a few previous works illustrating that the use of such computer-assisted proofs allowed obtaining results that are apparently too complicated for us to find bare-handed—even in apparently simple contexts.  Reasonable examples include the direct proof for convergence rates in  function values [<a href="https://arxiv.org/pdf/1705.04398.pdf">11</a>] presented above, but also proofs arising in the context of optimized numerical schemes [<a href="https://arxiv.org/pdf/1206.3209.pdf">2</a>, <a href="https://arxiv.org/abs/1409.2636">16</a>, <a href="https://arxiv.org/pdf/1406.5468.pdf">17</a>, <a href="https://arxiv.org/pdf/1803.06600.pdf">18</a>]—in particular [<a href="https://arxiv.org/pdf/1803.06600.pdf">18</a>] presents a method for minimizing the gradient norm at the last iterate, in smooth convex minimization—,  in the context of monotone inclusions,  and even for more general fixed-point problems (e.g., for Halpern iterations [<a href="http://www.optimization-online.org/DB_FILE/2017/11/6336.pdf">19</a>]).</p>



<h3>Toolbox</h3>



<p class="justify-text">The PErformance EStimation TOolbox (PESTO) [<a href="https://perso.uclouvain.be/julien.hendrickx/availablepublications/PESTO_CDC_2017.pdf">20</a>, see <a href="https://github.com/AdrienTaylor/Performance-Estimation-Toolbox/graphs/traffic">Github</a>] allows a quick access to the methodology without worrying about details of semidefinite reformulations. The toolbox contains many  examples (about 50) in different settings, and include progresses on the approach, and results, by other groups (which are much more thoroughly referenced in the <a href="https://github.com/AdrienTaylor/Performance-Estimation-Toolbox/blob/master/UserGuide.pdf">user guide</a>). In particular, we included standard classes of functions and operators, along with examples for analyzing recent optimized methods.</p>



<h2>References</h2>



<p class="justify-text">[1] Mark Schmidt, Nicolas Le Roux, Francis Bach. <a href="https://arxiv.org/pdf/1309.2388.pdf">Minimizing finite sums with the stochastic average gradient</a>. <em>Mathematical Programming</em>, <em>162</em>(1-2), 83-112, 2017.<br/>[2] Yoel Drori, Marc Teboulle. <a href="https://arxiv.org/pdf/1206.3209.pdf">Performance of first-order methods for smooth convex minimization: a novel approach</a>. <em>Mathematical Programming</em>, 145(1-2), 451-482, 2014.<br/>[3] Laurent Lessard, Benjamin Recht, Andrew Packard. <a href="https://epubs.siam.org/doi/abs/10.1137/15M1009597">Analysis and design of  optimization algorithms via integral quadratic constraints</a>. <em>SIAM Journal on Optimization</em>, 26(1), 57-95, 2016.<br/>[4] Adrien Taylor,  Julien Hendrickx, François Glineur. <a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">Smooth strongly convex interpolation and exact worst-case performance of first-order methods</a>. <em>Mathematical Programming</em>, 161(1-2), 307-345, 2017.<br/>[5] Yurii Nesterov. <a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">Introductory Lectures on Convex Optimization : a Basic Course</a>. <em>Applied optimization</em>. Kluwer Academic Publishing, 2004.<br/>[6]  Boris Polyak. Introduction to Optimization. Optimization Software New York, 1987.<br/>[7] Daniel Azagra, Carlos Mudarra. <a href="https://arxiv.org/pdf/1603.00241.pdf">An extension theorem for convex functions of class \(C^{1,1}\) on Hilbert spaces</a>. <em>Journal of Mathematical Analysis and Applications</em>, 446(2):1167–1182, 2017.<br/>[8] Aris Daniilidis, Mounir Haddou, Erwan Le Gruyer, Olivier Ley. <a href="https://hal.archives-ouvertes.fr/hal-01530908/file/DHLL_appendix.pdf">Explicit formulas for \(C^{1,1}\) Glaeser-Whitney extensions of 1-Taylor fields in Hilbert spaces</a>. <em>Proceedings of the American Mathematical Society</em>, 146(10):4487–4495, 2018.<br/>[9] Johan Löfberg. <a href="https://yalmip.github.io/">YALMIP : A toolbox for modeling and optimization in MATLAB</a>. <em>Proceedings of the CACSD Conference</em>, 2004.<br/>[10] APS Mosek. <a href="https://www.mosek.com/">The MOSEK optimization software</a>. Online at http://www.mosek.com, 54, 2010.<br/>[11] Adrien Taylor, Julien Hendrickx, François Glineur. <a href="https://arxiv.org/pdf/1705.04398.pdf">Exact worst-case convergence rates of the proximal gradient method for  composite convex minimization</a>. <em>Journal of Optimization Theory and Applications</em>, vol. 178, no 2, p. 455-476, 2018.<br/>[12] Adrien Taylor, Julien Hendrickx, François Glineur. <a href="https://arxiv.org/pdf/1512.07516.pdf">Exact worst-case performance of first-order methods for composite convex optimization</a>. <em>SIAM Journal on Optimization</em>, vol. 27, no 3, p. 1283-1313, 2017.<br/>[13] Nikhil Bansal, Anupam Gupta. <a href="http://www.theoryofcomputing.org/articles/v015a004/v015a004.pdf">Potential-Function Proofs for Gradient Methods. <em>Theory of Computing</em></a>, <em>15</em>(1), 1-32, 2019.<br/>[14] Adrien Taylor, Francis Bach. <a href="https://arxiv.org/pdf/1902.00947.pdf">Stochastic first-order methods: non-asymptotic and computer-aided analyses via potential functions</a>, <em>Proceedings of the 32nd Conference on Learning Theory (COLT)</em>, 99:2934-2992, 2019.  <br/>[15] Bin Hu, Laurent Lessard. <a href="http://proceedings.mlr.press/v70/hu17a/hu17a.pdf">Dissipativity theory for Nesterov’s accelerated method</a>, <em>Proceedings of the 34th International Conference on Machine Learning</em>, 70:1549-1557, 2017. <br/>[16] Yoel Drori, Marc Teboulle. <a href="https://arxiv.org/abs/1409.2636">An optimal variant of Kelley’s cutting-plane method</a>. <em>Mathematical Programming</em> 160.1-2: 321-351, 2016.<br/>[17] Donghwan<strong> </strong>Kim, Jeffrey Fessler. <a href="https://arxiv.org/pdf/1406.5468.pdf">Optimized first-order methods for smooth convex minimization</a>, <em>Mathematical programming</em>, <em>159</em>(1-2), 81-107, 2016.<br/>[18] Donghwan Kim, Jeffrey Fessler. <a href="https://arxiv.org/pdf/1803.06600.pdf">Optimizing the efficiency of first-order methods for decreasing the gradient of smooth convex functions</a>, <em>preprint arXiv:1803.06600</em>, 2018.   <br/>[19] Felix Lieder. <a href="http://www.optimization-online.org/DB_FILE/2017/11/6336.pdf">On the convergence rate of the Halpern-iteration</a>. Technical Report, 2019.<br/>[20] Adrien Taylor, Julien Hendrickx, François Glineur.  <a href="https://perso.uclouvain.be/julien.hendrickx/availablepublications/PESTO_CDC_2017.pdf">Performance estimation toolbox (PESTO): automated worst-case analysis of  first-order optimization methods</a>,<em> Proceedings of the 56th Annual Conference on Decision and Control (CDC)</em>, pp. 1278-1283, 2017.</p></div>
    </content>
    <updated>2020-04-03T11:37:27Z</updated>
    <published>2020-04-03T11:37:27Z</published>
    <category term="Machine learning"/>
    <category term="Tools"/>
    <author>
      <name>Adrien Taylor</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2020-04-04T19:21:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19411</id>
    <link href="https://gilkalai.wordpress.com/2020/04/03/trees-not-cubes-memories-of-boris-tsirelson/" rel="alternate" type="text/html"/>
    <title>Trees not Cubes! Memories of Boris Tsirelson</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This post is devoted to a few memories of Boris Tsirelson who passed away at the end of January. I would like to mention that a few days ago graph theorist Robin Thomas passed away after long battle with ALS. … <a href="https://gilkalai.wordpress.com/2020/04/03/trees-not-cubes-memories-of-boris-tsirelson/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This post is devoted to a few memories of Boris Tsirelson who passed away at the end of January. I would like to mention that a few days ago graph theorist Robin Thomas passed away after long battle with ALS. I hope  to tell about Robin’s stunning mathematics in a future post.</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/tsirelson_boris.jpg"><img alt="" class="alignnone size-full wp-image-19552" height="480" src="https://gilkalai.files.wordpress.com/2020/03/tsirelson_boris.jpg?w=640&amp;h=480" width="640"/></a></p>
<p>Boris Tsirelson (1950 – 2020); <a href="http://www.math.tau.ac.il/~tsirel/">Boris’ home-page</a>, and <a href="https://en.wikipedia.org/wiki/Boris_Tsirelson">Wikipedia</a>. (More links, below.)</p>
<p>The title of the post is taken from the title of a very interesting 1999 paper by Boris Tsirelson and Oded Schramm: <a href="https://arxiv.org/abs/math/9902116">Trees, not cubes: hypercontractivity, cosiness, and noise stability</a></p>
<p>I was very sad and shocked to hear that Boris Tsirelson had passed away. Boris was one of the greatest Israeli mathematicians, and since 1997 or so we established mathematical connections surrounding several matters of common interest.  Here are a few memories.</p>
<h3>Love for coding</h3>
<p>1) One thing that Boris told me was that he loves to code. Being a “refusnik”, he could not get into Academia and (luckily) he could work as a programmer. And he told me that afterwards deciding what he liked more – programming or doing mathematical research – was no longer a trivial question for him.  Boris chose to go back to mathematical research, but he continued to enjoy programming, and when he needed it in his mathematical research, he could easily program.</p>
<h3>Love for quantum</h3>
<p>2) Another thing that Boris loved is “quantum”, the mathematics and physics of quantum mechanics and various connections to mathematics. Early on he proved his famous Tsirelson’s bound related to Bell’s inequalities, and later he was enthusiastic about the area of quantum computing. (And he learned it quickly, taught a course about it in 1997, and his 1997 lecture notes are still considered very useful.)</p>
<h3>Black Noise and noise sensitivity</h3>
<p>3) Perhaps the most significant mathematical connection between us was in the late 90s, and was centered around the theory of noise stability and noise sensitivity by Benjamini, Schramm and myself, which was closely related to a theory initiated by Boris Tsirelson and Anatoly Vershik. The translation between the different languages that we used and that Boris used was awkward, since the analog of Boolean functions that we studied was the “noise” that Boris studied, and the analog of noise sensitive Boolean functions in our language was “black noise” in Boris’s language. In any case, we had email discussions and we also met a few times with Itai and Oded regarding this connection.</p>
<h3>Black Noise and noise sensitivity II</h3>
<p>4)  Boris developed a very rich theory of black noise with relations to various areas of probability theory and operator algebras. He also found hypercontractivity that we used in our work quite useful to his applications, and also in this theory, he considered both classical and quantum aspects. I know only a little about Boris Tsirelson’s theory and its applications, but as far as tangent points with our Boolean interests are concerned, I can mention that Boris was enthusiastic by the <a href="https://arxiv.org/abs/1101.5820">result</a> of Schramm and Stas Smirnov that percolation is a “black noise” and also that, in 1999, Boris and Oded Schramm wrote a paper whose title started with “Trees not cubes!”, presenting a different angle on this theory.</p>
<p>Tsirelson saw white noise (what we call noise stability) as manifesting “linearity” while “black noise” (what we call noise sensitivity) as manifesting “non-linearity”. Over the years, I often asked him to explain this to me.</p>
<h3>Tsireslon’s Banach spaces</h3>
<p>5) Geometry of Banach spaces is a very strong area in Israel so naturally I heard as a graduate student about “Tsirelson’s space” from 1974 and some subsequent developments in the 80s. Boris Tsirelson constructed a  Banach space that does not contain an imbedding of <img alt="\ell_p" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_p"/> or <img alt="c_0" class="latex" src="https://s0.wp.com/latex.php?latex=c_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c_0"/>.</p>
<h3>Bible codes</h3>
<p>6) My first personal connection with Boris was related to claims regarding a hidden Bible Code, and a 1994 paper claiming a statistical proof of the existence of these Bible codes. For many years my attitude was that these claims should be ignored, but around 1997, I changed my mind and did some work to see what was going on. Now, Boris kept a site linked in his homepage devoted to developments regarding the Bible Code claims. In this site Boris kindly reported about my first 1997 paper on the topic, my observation that the proximity of two reported p-values for the two Bible code experiments was “too good to be true”, and my interpretation that this suggests that the claimed results manifest naïve statistical expectations rather than scientific reality.  A few weeks later, Boris reported about a much stronger evidence (by McKay and Bar Nathan) against the Bible Code claims (they demonstrated codes of similar quality in Tolstoy’s “War and Peace”) and subsequently after some time he lost interest in this topic.</p>
<h3>Quantum computing skepticism</h3>
<p>6) In 2005 we had some correspondence and meetings regarding my quantum computing skepticism. In his first email he told me that my reference to “decoherence” seemed strange and I realized that I consistently referred to “entanglement” as “decoherence” and to “decoherence” as “entanglement”.</p>
<p>7) In his 1997 lecture notes on quantum computing (that I cannot find on the web, so I count on my memory), Boris addressed the concerns of early quantum computers skeptics like Rolf Landauer. He did not accept the analogy between quantum computing and analog computation, but he also regarded the analogy with digital computation as problematic. Rather, he regarded quantum information based on qubits as something (at least a priori) different from both these examples. (Update: I found one non-broken link to the lecture notes; indeed the subtitle of Chapter 9 is “neither analog nor digital”.)</p>
<p>A joke that I heard from Boris at that time</p>
<p>8) I remember that once when I asked him about some aspects of quantum fault tolerance he told me the following joke: A student is entitled to a special exam, he arrives at the professor’s office, is given three questions to answer and he fails to do so. He request and is granted a make-up exam two weeks later. When the student shows up at the office two weeks later the professor, who forgot all about it, gave him the same three questions. “This is extremely unfair”, said the student “you ask me questions that you already know that I cannot answer.”</p>
<h3>Noise sensitivity and high energy physics</h3>
<p>9) In 2006 I came up with the idea that noise sensitivity might be a great idea for physics. Knowing very little physics, I wrote a little manifesto with this idea and tried it, among other people, on Boris. As it turned out, Boris had the idea that noise sensitivity could add a useful modeling power to physics (especially high energy physics) well before that time. (And by 2006 he was already a bit skeptical regarding his own idea.) He also told me that one of the motivations of his 1998 paper with Tolya Vershik came from some mathematical ideas related to physics of the big bang. When I asked him if this was written somewhere in the paper itself, he answered: “Of course, not!”</p>
<h3>Boris Tsirelson’s lecture at Oded’s memorial school</h3>
<p>10) in 2009 we organized a meeting in memory of Oded Schramm and Boris gave a lecture related to the Schramm-Smirnov “percolation is black noise” result with a single theorem. And what was remarkable about it that it was that he presented a classical theorem with a quantum proof. You can find the videotaped lecture here  (And here are the slides. Boris never wrote up this result.) Following this lecture we had a short correspondence with Scott A. and Greg K. about quantum proofs to classical theorems. (Namely theorems that do not mention quantum in the statement).</p>
<h3>Tsirelson’s problem</h3>
<p>11) Our last correspondence in 2019 was about Thomas Vidick’s  Notices AMS article about Tsirelson’s problem. (This was a couple of months before the announcement of the solution.) Boris was pleased to hear about these developments, as he was regarding earlier developments in this area. He humorously refers to the history of his problem on his homepage and this interview.</p>
<p>12) People who knew Boris regarded him as a genius from a very early age, and former students have fond memories of his classes.</p>
<p> </p>
<h3>More resources:</h3>
<p>Boris’s <a href="http://www.math.tau.ac.il/~tsirel/">home page</a> contains  “Museum to my courses” with many useful lecture notes; link to a small <a href="http://www.math.tau.ac.il/~tsirel/Research/qcomp/main.html">page on quantum computation</a> with a link to Boris’ <a href="http://www.math.tau.ac.il/~tsirel/Courses/QuantInf/syllabus.html">1997 lecture notes on quantum computing</a>.  Links to comments on some of Tsirelson’s famous papers. <a href="http://www.math.tau.ac.il/~tsirel/Research/mybound/main.html">Tsirelson’s 1980 bound</a>. Boris <a href="http://www.math.tau.ac.il/~tsirel/Research/refereed.html">published papers</a>, and his “<a href="http://www.math.tau.ac.il/~tsirel/Research/self-publ.html">self-published</a>” papers.</p>
<p>Boris was a devoted Wikipedian and his Wikipidea <a href="https://en.wikipedia.org/wiki/User:Tsirel">user page</a> is now devoted to his memory; Here is <a href="https://www.iqoqi-vienna.at/en/blog/article/boris-tsirelson/?fbclid=IwAR1PrVvK0u5XmnFLLoPMzMN3x9rY1WIdp1wrYZ_yYPlqSGRpXDkollYTCR0">a great interview</a> with Boris; A very nice <a href="https://www.scottaaronson.com/blog/?p=4626">memorial post</a> on Freeman Dyson and Boris Tsirelson on the Shtetl Optimized;</p>
<p>Below the fold some emails of interest from Boris, mainly where he explained to me various mathematics. (More can be found in this page.)</p>
<p><span id="more-19411"/></p>
<h2>Some email correspondence</h2>
<h3>Oct. 2019 Vidick’s paper</h3>
<p>Dear Boris<br/>
<a href="https://www.ams.org/journals/notices/201910/rnoti-p1618.pdf">This paper</a> by Thomas Vidick may interest you,<br/>
best regards and shana tova Gil</p>
<p>Oh yes, sure!<br/>
Thank you.<br/>
Shana metuka, Boris</p>
<p>(Remark: “metuka” means “sweet” in Hebrew.)</p>
<h3>Dec 2006 (about noise sensitivity and physics)</h3>
<p>(Dec 2006) My very first idea in this field (inspired by conversations with Vershik) was<br/>
rather physical (that Big Bang could be a natural occurrence of black noise),<br/>
and in fact the main example of “Tsirelson and Vershik 1998” follows this line<br/>
(not explicitly, of course).</p>
<p>In local (not Big Bang related) physics, I think, nonlinearity could produce<br/>
such effect. And then the very idea of `the field operator at a point’ (on<br/>
the level of operator-valued Schwartz distributions or something like that)<br/>
will fail. However, physicists do not want to consider this possibility<br/>
without very serious indications that it really is used by the nature. And<br/>
they are right…</p>
<h3>2005 quantum computer skepticism</h3>
<p>Subject: Re: Noise and more</p>
<p>Dear Gil:<br/>
Yes, of course, we can meet and speak.</p>
<p>For now, I am not much bothered. I am not an expert in quantum error<br/>
correction, but anyway, my feeling is that all physically reasonable<br/>
“attacks” of Nature are repelled. Especially, your three-qubit attack<br/>
looks to me not dangerous. And, “der Herr Gott is raffiniert, aber<br/>
boschaft ist er nicht”; Nature never attacks like an enemy.</p>
<p>Yours, Boris.</p>
<h3>Quick 2000 comments on a (sloppy) draft of my survey paper</h3>
<p>Dear Gil:</p>
<p>Thank you for the text; I am reading it.<br/>
For now, only a trivial remark: “Tsilerson” should be “Tsirelson” in<br/>
[133] and [134]; and in [132] “” should be “Tsirelson”…</p>
<p>Shabat shalom,<br/>
Yours, Boris.</p>
<h3>November 1998: Noise sensitivity and black noise</h3>
<p>Dear Gil,</p>
<p>I am reading your (with Itai and Oded) paper. Thanks.</p>
<p>Moreover, I am thinking about changing the title of my future talk in<br/>
Vien accordingly: from “The five noises” to “The six noises” (or even<br/>
more).<br/>
To this end, however, I need to answer the following question.</p>
<p>Is there a mesh refinement limit for the percolation?</p>
<p>That is, take the lattice with a small pitch \eps. Choose two<br/>
“electrodes”, say, two vertical intervals on two parallel vertical<br/>
lines, and ask about the probability that they are connected (via the<br/>
bond percolation on the whole band between the two vertical lines).<br/>
Let the electrodes be macroscopic; that is, they do not depend on<br/>
\eps. Does the probability of the event have a limit for \eps \to 0 ?<br/>
If it does, then one more question: what about the joint distribution<br/>
for a finite collection of such events? That is, I want to see a weak<br/>
limit of these “discrete” random processes. It seems to me, the<br/>
question is well-known and was discussed. However, do you know the<br/>
answer?</p>
<p>Yours, Boris.</p>
<p>Dear Itai, Oded, and Gil,</p>
<p>Thank you for the information. I see that for now we have a<br/>
conditional result: if there exists “the noise of percolation”, then<br/>
it is not a white noise.<br/>
Yours, Boris.</p>
<p>Dear Gil:<br/>
&gt; I dont understand yet the concept of “noise” precisely</p>
<p>One of ways is this. A noise is a scaling limit for coin tossing.<br/>
You choose a class of “macroscopic observables” and look, whether<br/>
their joint distribution converges, when n\to\infty. If it does, you<br/>
get a noise. (For percolation we do not know, does it or not.)<br/>
Now, if all “macroscopic observables” are noise insensitive, it means<br/>
that the noise is white. For a white noise, there is only one<br/>
invariant, its dimension (or multiplicity).<br/>
If all “macroscopic observables” are noise sensitive, the noise is<br/>
black. Probably, there are a lot of black noises, but for now we have<br/>
only two examples, without knowing, whether they are isomorphic, or<br/>
not. Spectra may be used for classifying black noises. Say, it may<br/>
happen that for each “macroscopic observable”, its spectrum is<br/>
concentrated on sets having Hausdorf dimension less than something.<br/>
If some “macroscopic observables” are noise sensitive but some others<br/>
are not (except for constants, of course), then the noise is neither<br/>
white nor black. It may happen that it is a direct sum of a white<br/>
noise and a black noise. However, it may happen that it is not. We<br/>
have for now two such examples: “noise if splitting” and “noise of<br/>
stickiness” (they are probably non-isomorphic); both are found by Jonathan<br/>
Warren. I am trying to understand, whether your matter can give more<br/>
examples.</p>
<p> </p>
<h3>August 1998: Bible code story</h3>
<p>Dear Gil,</p>
<p>Thanks for the text.<br/>
As for me, it is already an `overkill’, since for me the WRR94<br/>
is basically dead. But maybe for others…</p>
<p>Yours, Boris.</p>
<p> </p></div>
    </content>
    <updated>2020-04-03T08:03:55Z</updated>
    <published>2020-04-03T08:03:55Z</published>
    <category term="Combinatorics"/>
    <category term="Obituary"/>
    <category term="Probability"/>
    <category term="Quantum"/>
    <category term="Boris Tsirelson"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-04-04T19:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.01163</id>
    <link href="http://arxiv.org/abs/2004.01163" rel="alternate" type="text/html"/>
    <title>A Spectral Approach to the Shortest Path Problem</title>
    <feedworld_mtime>1585872000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Steinerberger:Stefan.html">Stefan Steinerberger</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.01163">PDF</a><br/><b>Abstract: </b>Let $G=(V,E)$ be a simple, connected graph. One is often interested in a
short path between two vertices $u,v$. We propose a spectral algorithm:
construct the function $\phi:V \rightarrow \mathbb{R}_{\geq 0}$ $$ \phi =
\arg\min_{f:V \rightarrow \mathbb{R} \atop f(u) = 0, f \not\equiv 0}
\frac{\sum_{(w_1, w_2) \in E}{(f(w_1)-f(w_2))^2}}{\sum_{w \in V}{f(w)^2}}.$$
$\phi$ can also be understood as the smallest eigenvector of the Laplacian
Matrix $L=D-A$ after the $u-$th row and column have been removed. We start in
the point $v$ and construct a path from $v$ to $u$: at each step, we move to
the neighbor for which $\phi$ is the smallest. This algorithm provably
terminates and results in a short path from $v$ to $u$, often the shortest. The
efficiency of this method is due to a discrete analogue of a phenomenon in
Partial Differential Equations that is not well understood. We prove optimality
for trees and discuss a number of open questions.
</p></div>
    </summary>
    <updated>2020-04-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.01156</id>
    <link href="http://arxiv.org/abs/2004.01156" rel="alternate" type="text/html"/>
    <title>No Repetition: Fast Streaming with Highly Concentrated Hashing</title>
    <feedworld_mtime>1585872000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aamand:Anders.html">Anders Aamand</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Das:Debarati.html">Debarati Das</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kipouridis:Evangelos.html">Evangelos Kipouridis</a>, Jakob B. T. Knudsen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rasmussen:Peter_M=_R=.html">Peter M. R. Rasmussen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thorup:Mikkel.html">Mikkel Thorup</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.01156">PDF</a><br/><b>Abstract: </b>To get estimators that work within a certain error bound with high
probability, a common strategy is to design one that works with constant
probability, and then boost the probability using independent repetitions.
Important examples of this approach are small space algorithms for estimating
the number of distinct elements in a stream, or estimating the set similarity
between large sets. Using standard strongly universal hashing to process each
element, we get a sketch based estimator where the probability of a too large
error is, say, 1/4. By performing $r$ independent repetitions and taking the
median of the estimators, the error probability falls exponentially in $r$.
However, running $r$ independent experiments increases the processing time by a
factor $r$.
</p>
<p>Here we make the point that if we have a hash function with strong
concentration bounds, then we get the same high probability bounds without any
need for repetitions. Instead of $r$ independent sketches, we have a single
sketch that is $r$ times bigger, so the total space is the same. However, we
only apply a single hash function, so we save a factor $r$ in time, and the
overall algorithms just get simpler.
</p>
<p>Fast practical hash functions with strong concentration bounds were recently
proposed by Aamand em et al. (to appear in STOC 2020). Using their hashing
schemes, the algorithms thus become very fast and practical, suitable for
online processing of high volume data streams.
</p></div>
    </summary>
    <updated>2020-04-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.01120</id>
    <link href="http://arxiv.org/abs/2004.01120" rel="alternate" type="text/html"/>
    <title>On Locating Paths in Compressed Cardinal Trees</title>
    <feedworld_mtime>1585872000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Prezza:Nicola.html">Nicola Prezza</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.01120">PDF</a><br/><b>Abstract: </b>A compressed index is a data structure representing a text within compressed
space and supporting fast indexing queries: given a pattern, count/return all
positions where the pattern occurs. In recent years, powerful compressed
indexes have emerged. These are based on Entropy, the Lempel-Ziv factorization,
the run-length Burrows-Wheeler Transform (BWT), context-free grammars and, more
recently, string attractors. Trees add a whole new dimension to the problem:
one needs not only to compress the labels, but also the tree's topology. On
this side, less is known. Jacobson showed how to represent the topology of a
tree with $n$ nodes in $2n+o(n)$ bits of space (succinct) while also supporting
constant-time navigation queries. Ferragina et al. presented the first
entropy-compressed labeled tree representation (the XBWT) able to count, but
not locate, paths labeled with a given pattern. Grammars and the Lempel-Ziv
factorization have been extended to trees, but those representations do not
support indexing queries. In this paper, we extend to cardinal trees (i.e.
tries) the most powerful string compression and indexing tools known to date.
We start by proposing suitable generalizations of run-length BWT, high-order
entropy, and string attractors to cardinal trees. We show that the number
$r\leq n$ of XBWT-runs upper-bounds the size of the smallest tree attractor and
lower-bounds the trie's high-order worst-case entropy $\mathcal H^{wc}_k$. The
main result of this paper is the first tree index able to \emph{locate} in
pre-order nodes reached by a path labeled with a given pattern. Our index
locates path occurrences in constant time each and takes $2n + o(n) + O(r\log
n) \leq 2n + o(n) + O(\mathcal H^{wc}_k\log n)$ bits of space: the reporting
time is optimal and the locate machinery fits within compressed space on top of
the tree's topology.
</p></div>
    </summary>
    <updated>2020-04-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.01032</id>
    <link href="http://arxiv.org/abs/2004.01032" rel="alternate" type="text/html"/>
    <title>Grammar-Compressed Indexes with Logarithmic Search Time</title>
    <feedworld_mtime>1585872000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Claude:Francisco.html">Francisco Claude</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Navarro:Gonzalo.html">Gonzalo Navarro</a>, Alejandro Pacheco <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.01032">PDF</a><br/><b>Abstract: </b>Let a text $T[1..n]$ be the only string generated by a context-free grammar
with $g$ (terminal and nonterminal) symbols, and of size $G$ (measured as the
sum of the lengths of the right-hand sides of the rules). Such a grammar,
called a grammar-compressed representation of $T$, can be encoded using
essentially $G\lg g$ bits. We introduce the first grammar-compressed index that
uses $O(G\lg n)$ bits and can find the $occ$ occurrences of patterns $P[1..m]$
in time $O((m^2+occ)\lg G)$. We implement the index and demonstrate its
practicality in comparison with the state of the art, on highly repetitive text
collections.
</p></div>
    </summary>
    <updated>2020-04-03T23:20:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.00750</id>
    <link href="http://arxiv.org/abs/2004.00750" rel="alternate" type="text/html"/>
    <title>Terrain Visibility Graphs: Persistence is Not Enough</title>
    <feedworld_mtime>1585872000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Safwa Ameer, Matt Gibson-Lopez, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krohn:Erik.html">Erik Krohn</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Soderman:Sean.html">Sean Soderman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Qing.html">Qing Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.00750">PDF</a><br/><b>Abstract: </b>In this paper, we consider the Visibility Graph Recognition and
Reconstruction problems in the context of terrains. Here, we are given a graph
$G$ with labeled vertices $v_0, v_1, \ldots, v_{n-1}$ such that the labeling
corresponds with a Hamiltonian path $H$. $G$ also may contain other edges. We
are interested in determining if there is a terrain $T$ with vertices $p_0,
p_1, \ldots, p_{n-1}$ such that $G$ is the visibility graph of $T$ and the
boundary of $T$ corresponds with $H$. $G$ is said to be persistent if and only
if it satisfies the so-called X-property and Bar-property. It is known that
every "pseudo-terrain" has a persistent visibility graph and that every
persistent graph is the visibility graph for some pseudo-terrain. The
connection is not as clear for (geometric) terrains. It is known that the
visibility graph of any terrain $T$ is persistent, but it has been unclear
whether every persistent graph $G$ has a terrain $T$ such that $G$ is the
visibility graph of $T$. There actually have been several papers that claim
this to be the case (although no formal proof has ever been published), and
recent works made steps towards building a terrain reconstruction algorithm for
any persistent graph. In this paper, we show that there exists a persistent
graph $G$ that is not the visibility graph for any terrain $T$. This means
persistence is not enough by itself to characterize the visibility graphs of
terrains, and implies that pseudo-terrains are not stretchable.
</p></div>
    </summary>
    <updated>2020-04-03T23:32:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.00722</id>
    <link href="http://arxiv.org/abs/2004.00722" rel="alternate" type="text/html"/>
    <title>k-Median clustering under discrete Fr\'{e}chet and Hausdorff distances</title>
    <feedworld_mtime>1585872000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nath:Abhinandan.html">Abhinandan Nath</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Taylor:Erin.html">Erin Taylor</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.00722">PDF</a><br/><b>Abstract: </b>We give the first near-linear time $(1+\eps)$-approximation algorithm for
$k$-median clustering of polygonal trajectories under the discrete Fr\'{e}chet
distance, and the first polynomial time $(1+\eps)$-approximation algorithm for
$k$-median clustering of finite point sets under the Hausdorff distance,
provided the cluster centers, ambient dimension, and $k$ are bounded by a
constant. The main technique is a general framework for solving clustering
problems where the cluster centers are restricted to come from a \emph{simpler}
metric space. We precisely characterize conditions on the simpler metric space
of the cluster centers that allow faster $(1+\eps)$-approximations for the
$k$-median problem. We also show that the $k$-median problem under Hausdorff
distance is \textsc{NP-Hard}.
</p></div>
    </summary>
    <updated>2020-04-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.00655</id>
    <link href="http://arxiv.org/abs/2004.00655" rel="alternate" type="text/html"/>
    <title>Parameterized Analysis of Assignment Under Multiple Preferences</title>
    <feedworld_mtime>1585872000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Barak Steindl, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zehavi:Meirav.html">Meirav Zehavi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.00655">PDF</a><br/><b>Abstract: </b>The Assignment problem is a fundamental, well-studied problem in the
intersection of Social Choice, Computational Economics and Discrete Allocation.
In the Assignment problem, we seek a pareto optimal allocation of items to
agents given the preferences of the agents. We introduce a generalized version
of this problem, where each agent is equipped with multiple incomplete
preference lists: each list (called a layer) is a ranking of items in a
possibly different way according to a different criterion. We introduce a new
concept of pareto optimality, and study the generalized version of the problem
from the perspective of Parameterized Complexity. Here, we consider several
natural parameters such as the number of layers, number of agents, number of
items, and maximal length of a preference list; we present a comprehensive
picture of the parameterized complexity of the problem with respect to these
parameters.
</p></div>
    </summary>
    <updated>2020-04-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6956243767390574114</id>
    <link href="https://blog.computationalcomplexity.org/feeds/6956243767390574114/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/lets-hear-it-for-cloud.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6956243767390574114" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6956243767390574114" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/lets-hear-it-for-cloud.html" rel="alternate" type="text/html"/>
    <title>Let's Hear It for the Cloud</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>Since March 19th I have worked out of home. I've had virtual meetings, sometimes seven or eight a day, on Zoom, Bluejeans, Google Hangouts, Google Meet, Blackboard Collaborate Ultra and Microsoft Teams. I take notes on my iPad using Penultimate which syncs with Evernote. I store my files in Dropbox and collaborate in Google Drive. I communicate by Google Chat, Gmail, Facebook messenger and a dozen other platforms. I continue to tweet and occasionally post in this blog. </div><div><br/></div><div>A billion of my closest friends around the world are also working out of home and using the same and similar tools. Yet outside of some pretty minor issues, all of these services continue to work and work well. Little of this would have been possible fifteen years ago. </div><div><br/></div><div>As Amazon scaled up their web operations to handle their growing business in the early 2000's they realized they could sell computing services. AWS, Amazon Web Services, started in 2006. Microsoft Azure, Google and others followed. These sites powered smartphones and their apps that push heavy processing to the cloud, small startups who don't need to run their own servers, and companies like Zoom when they need to scale up quickly and scale down like Expedia when they don't need as much use. Amazon and Microsoft makes most of their profit on cloud services. Amazon can't get me toilet paper but they can make sure Blackboard continues to work when all of our classes move online. </div><div><br/></div><div>Just for fun I like to occasionally look over the large collection of <a href="https://aws.amazon.com/products">Amazon Cloud Products</a>. Transcribe an audio recording and translate to Portuguese, not a problem. </div><div><br/></div><div>The cloud can't allow all of us to work from home. We have many who still go to work including front-line health care workers putting their lives on the line. Many have lost their jobs. Then of course there are those sick with the virus, many of whom will never recover. We can't forget about the reason we stay indoors.</div><div><br/></div><div>But every now and then it's good to look back and see how a technology has changed our world in a very short time. If we had this virus in the 90's we'd still be having to go to work, or simply stop teaching and other activities all together.</div><div><br/></div><div>And how will our universities and other work spaces look like in the future now that we find we can work reasonably well from home and even better technologies develop? Only time will tell.</div><div><br/></div><div><br/></div><div><br/></div></div>
    </content>
    <updated>2020-04-02T19:20:00Z</updated>
    <published>2020-04-02T19:20:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-04-04T15:36:02Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-6301869508435164660</id>
    <link href="http://processalgebra.blogspot.com/feeds/6301869508435164660/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=6301869508435164660" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6301869508435164660" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6301869508435164660" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2020/04/an-interview-with-davide-sangiorgi.html" rel="alternate" type="text/html"/>
    <title>An interview with Davide Sangiorgi, CONCUR Test-of-Time Award recipient</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The <a href="https://concur2020.forsyte.at/">International Conference on Concurrency Theory (CONCUR)</a> and the I<a href="https://concurrency-theory.org/organizations/ifip">FIP 1.8 Working Group on Concurrency Theory</a> are happy to announce the first edition of the CONCUR  Test-of-Time Award. The purpose of the award is to recognize important  achievements in Concurrency Theory that were published at the CONCUR  conference and have stood the test of time. All papers published in  CONCUR between 1990 and 1995 were eligible.<br/><br/>The award winners for the  CONCUR ToT Awards 2020 may be found <a href="https://concur2020.forsyte.at/test-of-time/index.html">here</a>, together with the citations for the awars. They were selected by a jury composed of Jos Baeten, Patricia  Bouyer-Decitre, Holger Hermanns, Alexandra Silva and myself.<br/><br/>This post is the first of a series in which I interview the recipients of the  CONCUR ToT Awards 2020. I asked <a href="http://www.cs.unibo.it/~sangio/">Davide Sangiorgi </a>(University of Bologna, Italy) a small number of questions via email and I report his answers below in a slightly edited form. Let  me thank Davide for his willingness to take part in an interview and for his inspiring answers, which I hope will be of interest to readers of this blog and will inspire young researchers to take up work on Concurrency Theory.<br/><br/>In what follows, LA stands for Luca Aceto and DS for Davide Sangiorgi.<br/><br/>LA: You receive one of the two CONCUR ToT Awards for the period 1992-1995 for your paper "<a href="http://www.lfcs.inf.ed.ac.uk/reports/93/ECS-LFCS-93-270/">A Theory of Bisimulation for the pi-Calculus</a>", presented at CONCUR 1993. Could you tell us briefly what spurred you to develop open bisimilarity and how the ideas underlying that notion came about?<br/><br/>DS: I developed the paper on open bisimulation during 1992 and 1993.  I was in Robin Milner's group, in Edinburgh.  We were studying and questioning basic aspects of the theory of the <a href="https://en.wikipedia.org/wiki/%CE%A0-calculus">pi-calculus</a>. One such aspect was the definition of equality on processes; thus a very fundamental aspect, underlying the whole theory.  The equality had to be a form of bisimulation, in the same way as it was for CCS.  The two forms of bisimilarity that were around for the pi-calculus, late and early bisimilarity, are not congruence relations.  In both cases, the input clause of bisimilarity uses a universal quantification on the possible instantiations of the bound name. As  a consequence, neither bisimilarity is preserved by the input prefix (forbidding substitutions in the input clause would make things worse, as congruence  would fail for parallel composition). Therefore, one has to introduce separately the induced congruence, by universally quantifying the bisimilarities over all name substitutions.  In other words,  the two bisimilarities are  not fully substitutive ('equal' terms cannot be replaced, one for the other,  in an arbitrary context).   On the other hand, the  congruences induced by the bisimilarities  are not themselves  bisimilarities. Hence in this case 'equal' terms, after some actions,  need not be 'equal' anymore.  Thus, for instance, such relations do not support dynamic modifications of the context surrounding related terms.<br/><br/>This situation was not fully satisfactory. The same could be said for the algebraic theory: there were proof systems for the two bisimilarities (of course, on finitary processes) but, because of the above congruence issue, there were no axiomatisations.  (In those years I was also working with Joachim Parrow on axiomatisations of these relations.)<br/><br/>The universal quantification on substitutions in the input clause of the bisimilarites and in the definitions of the induced congruences was also unsatisfactory because it  could make checking equalities cumbersome.<br/><br/>All these were  motivations for looking at possible variations of the definition of bisimulation. The specific hints towards open bisimulation came from thinking at two key facets of the pi-calculus model that were somehow neglected in the definitions of  early and late bisimilarities.  The first facet has to do with the pi-calculus rejection of the separation between channels and variables (`channel' here meaning a 'constant identifier'). In the pi-calculus ,there is only one syntactic category, that of <i>names</i>, with no formal distinction between channels and variables. This contributes to the elegance of the model and its theory. However, both in early and in late bisimilarity, the free names of processes are treated as channels, whereas the bound names of  inputs are treated as variables because of their immediate  instantiation  in the bisimilarity clause.   There was somehow a discrepancy between the syntax and the semantics. <br/><br/>The second facet of the pi-calculus that contributed to the definition of open bisimilarity is the lack of the mismatch operator: the pi-calculus, at least in its original proposal, has a match operator to test equality between names, but not the dual mismatch, to test for inequality.  Mismatching had been excluded for the preservation of a monotonicity property on transitions, intuitively asserting that substitutions may only increase the action capabilities of a  process.  (Both facets above represented major differences between the pi-calculus and its closest ancestor----Engberg and Nielsen's Extended CCS.)  Thus I started playing with the idea of avoiding the name instantiation in the input clause and, instead, allowing, at any moment, for arbitrary instantiations (i.e., substitutions) of the names of the processes---the latter justified by the above monotonicity property of transitions. By adding the requirement of being a congruence, the definition of open bisimilarity came about.<br/><br/>Still, I was not sure that such a bisimulation could be interesting and robust.  Two further developments helped here. One was the axiomatisation (over recursion-free terms).  It was a pure axiomatisation, it was  simple,  and with a completeness proof that leads to the construction of canonical and minimal (in some syntactic sense) representatives for the equivalence classes of the bisimilarity.  For other bisimilarities, or related congruences, obtaining canonical representatives seems hard; at best such representatives are parametrised upon a set of free names and even in these cases minimality is not guaranteed.<br/><br/>The other development has to do with a symbolic or "efficient" characterisation of the bisimilarity. The initial definition of open bisimulation makes heavy use of substitutions.  In the symbolic characterisation, substitutions are performed only when needed (for instance, the unification of two names <i>a</i> and <i>b</i> is required if there is an input at <i>a</i> and an output at <i>b</i> that can interact), somehow echoing the call-by-need style of  functional languages.  Such a characterisation seemed promising for automated or semi-automated verification. <br/><br/>LA: How much of your later work has built on your CONCUR 1993 paper? What results of yours are you most proud of and why?<br/><br/>DS: The most basic idea in open bisimulation is to avoid the instantiation of the bound name of an input, possibly making such a bound name a free name of the derivative term.  The use of substitutions, elsewhere in the definition, is necessary to obtain a congruence relation for the pi-calculus.  I was surprised to discover, in the following years, that such substitutions are not necessary in two relevant subsets of the pi-calculus.  I called the variant of open bisimulation without substitutions <i>ground</i> bisimulation (I think the name came from Robin).  One subset is Honda and <a href="https://hal.inria.fr/inria-00076939/en">Boudol</a>'s Asynchronous pi-calculus, whose main constraint is to make outputs floating particles that do not trigger the activation of a continuation (other limitations concern sum and matching).  The other subset is the Internal (or Private) pi-calculus, in which only private (i.e., restricted) names may be transmitted.  I designed the Internal pi-calculus with ground bisimilarity in mind.  People seem to have found this calculus useful in many ways, partly because of its expressiveness combined with its  simple theory (in many aspects similar to that of CCS), partly because it allows one to limit or control aliasing between names, which can be useful for carrying out proofs about behavioural properties of processes, or for designing and reasoning about type systems, or for representing the calculus in logical systems.<br/><br/>Sometimes, the possibility of using ground bisimulation can considerably simplify proofs of equalities of terms. For instance, in my works on comparisons between pi-calculus and lambda-calculus, when I had to translate the latter into the former I have always used one of the above subcalculi (sometimes even combining them, e.g., the Asynchronous Internal pi-calculus), precisely for being able to use ground bisimilarity.<br/><br/>I  consider both ground bisimilarity and the Internal pi-calculus spin-offs of the work on open bisimilarity.<br/><br/>While working on open bisimilarity for the pi-calculus, in a different paper, I applied the idea of open bisimilarity to the lambda-calculus.  I kept the name 'open'  but the bisimulation is really 'ground', as there are no substitutions involved.  I remember Robin encouraging me to keep the name 'open' because it conveyed well the idea of setting a bisimulation on open terms, rather than on closed terms as usually done. In  open bisimulation for the lambda-calculus, a lambda-abstraction<i> lambda x. M</i> yields an action with label <i>lambda x</i> that should be matched (modulo  alpha-conversion) by the same action by a bisimilar term. (Of course additional bisimulation clauses are needed when a free variable is found in evaluation position.) In contrast, in the ordinary bisimulation for the lambda-calculus,  Abramsky's applicative bisimilarity, the bound variable of an abstraction has to be instantiated with all closed terms, which is heavy. In general, open bisimilarity is finer than applicative bisimilarity and contextual equivalence (the reference equivalence in the lambda-calculus) but they often coincide in examples of concrete interest. Moreover, open bisimilarity does coincide with contextual equivalence in appropriate extensions of the lambda-calculus.  In short, open bisimilarity offers us a technique for reasoning on higher-order languages  using  'first-order' tools, somehow similarly to what game semantics does.<br/><br/>This line of work about open bisimilarity in higher-order languages has been very fruitful, and is still studied a lot, for various forms of higher-order languages, sometimes under the name of 'normal-form' bisimulation. <br/><br/>LA: In your opinion, what is the most interesting or unexpected use in the literature of the notions and techniques you developed in your award-winning paper?<br/><br/>DS: I mentioned the hope, when working on open bisimilarity, that its symbolic "efficient" characterisation could be useful for automated or semi-automated tools for reasoning about behavioural properties.  Shortly after introducing open bisimulation,   Björn Victor and Faron Moller, both in Edinburgh at the time,   exploited it to design the Mobility Workbench. I also worked on an algorithm and a prototype tool for on-the-fly checking, with Marco Pistore.  <br/><br/>However the most surprising applications in this direction have arrived later, when the 'lazy' instantiation of bound names of open bisimilarity has been applied to languages richer than pi-calculus.  For instance, Chaki, Rajamani, Rehof have used open similarity in their methods and tools for model checking distributed message-passing software.  Others have applied open bisimilarity to languages for security and cryptography, like the spi-calculus and applied pi-calculus. These include S. Brias, U. Nestmann and colleagues at EPFL and Berlin.   R. Horne, A. Tiu and colleagues in Singapore and Luxembourg have pushed significantly in this direction, with verification techniques and tools. For instance very recently they have discovered a privacy vulnerability for e-passports.  <br/><br/>Similarly, Yuxin Deng and colleagues have applied the idea of open bisimulation to quantum processes, with analogous motivations --- avoiding the universal quantification in the  instantiation of variables, algorithmically unfeasible in the quantum setting as quantum states constitute a continuum.<br/><br/>Another line of work that I found interesting and surprising concerns abstract frameworks for concurrency, including logical frameworks. Here forms of open bisimulation are often the 'natural' bisimulation that come up. These frameworks may be based, for instance on  coalgebras and category theory  (e.g., works by M. Fiore and S. Staton, N. Ghani,   K. Yemane, and B. Victor), category theory for reactive systems (e.g., works by F. Bonchi, B. König and U. Montanari), nominal SOS rule formats  (e.g., works by M. Cimini,  M. R. Mousavi, and  M. A. Reniers), higher-order logic languages (e.g., works by A.  Tiu, G. Nadathur, and D. Miller). <br/><br/>There have been works that have pushed the idea of open bisimulation of avoiding the instantiation of  bound names in interactions with an external observer one step further: such bound names are not instantiated even in interactions<i> internal </i>to the processes. The substitutions produced by the interactions are added to the calculus, producing particles sometimes called fusions.  This mechanism resembles the explicit substitutions of the lambda-calculus, but it goes beyond that; for instance the addition of fusions leads to modifications of  input and output prefixes that produce pleasant syntactic and semantic symmetry properties.  Various people have worked on this, including B. Victor, J. Parrow, Y. Fu, C. Laneve, P. Gardner and L. Wischik.<br/><br/>I should also mention the recent work by K. Y. Ahn, R. Horne, and A. Tiu  on logical interpretations of open bisimilarity. Remarkably, they explain the difference between the original (late and early)  formulations of bisimilarity in the pi-calculus  and open bisimilarity as the difference between  intuitionistic and classical versions of modal logics. <br/><br/>Apologies for not mentioning everybody!<br/><br/>LA: To your mind, how has the focus of CONCUR changed since its first edition in 1990?<br/><br/>DS: I remember that in the early years of CONCUR there was  a tremendous excitement about the conference.  A forum for grouping the (fast-growing) community had been long-awaited.  In Edinburgh, every year after the conference,   the people with an interest in concurrency   would meet (multiple times!)  and discuss the contents of the proceedings.  Several of us every year would attend the conference. Attending the conference was very useful and interesting: one was sure to meet a lot of people, hear about excellent papers, have lively discussions.  We would  try to go,  even without  a paper in the proceedings.   I vividly remember the 1993 edition, where I presented the paper on open bisimulation.  It had been organised by Eike Best in Hildesheim, Germany. It was an  enjoyable and exciting week,  I met and knew a number of people of our community, and learned a lot. (How sad and unwise that the Computer Science department in Hildesheim, so strong in concurrency  at the time, was shut down a few years later.)  Over the years, the CONCUR community has kept increasing its size. The conference has substantially broadened its scope,  rightly including new emerging topics. Perhaps it is more difficult than in the past to (more or less) understand most of the presented papers, both because of the diversity of the topics and of their technical specialisation.  On the other hand, there are now satellite events, covering  a number of areas. Hence  there are always plenty of interesting presentations and talks to attend (this definitely occurred to me in the last edition, in Amsterdam!).  I should also mention here the activity on the IFIP WG 1.8 on Concurrency Theory, currently chaired by Ilaria Castellani, that in many ways  supports and promotes CONCUR.<br/><br/>The quality of the papers at CONCUR is still very high. This is very important. As a community we should strive to maintain, and possibly even increase, the excellence and prestige of the conference, first of all, by submitting our best papers to the conference. CONCUR must be a reference conference in Computer Science, which is essential for injecting new people and energy into the community.<br/><br/><b>Acknowledgements:</b> Many thanks to <a href="http://www-sop.inria.fr/members/Ilaria.Castellani/">Ilaria Castellani</a>, who pointed out a number of typos in the original version of this text. </div>
    </content>
    <updated>2020-04-02T16:16:00Z</updated>
    <published>2020-04-02T16:16:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2020-04-04T14:46:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-04-02-bilinear-accumulators-for-cryptocurrency/</id>
    <link href="https://decentralizedthoughts.github.io/2020-04-02-bilinear-accumulators-for-cryptocurrency/" rel="alternate" type="text/html"/>
    <title>Bilinear Accumulators for Cryptocurrency Enthusiasts</title>
    <summary>Accumulator schemes are an alternative to Merkle Hash Trees (MHTs) for committing to sets of elements. Their main advantages are: Constant-sized membership and non-membership proofs, an improvement over logarithmic-sized proofs in MHTs, Algebraic structure that enables more efficient proofs about committed elements1 (e.g., ZeroCoin2 uses RSA accumulators for anonymity), Constant-sized...</summary>
    <updated>2020-04-02T08:10:00Z</updated>
    <published>2020-04-02T08:10:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-04-03T23:47:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1644</id>
    <link href="https://theorydish.blog/2020/04/01/approx-random-2020-is-virtual-from-the-get-go/" rel="alternate" type="text/html"/>
    <title>APPROX/RANDOM 2020 is Virtual From the Get Go</title>
    <summary>While APPROX/RANDOM 2020 was scheduled for September, we decided to reduce uncertainty in these stormy days and declare it to be virtual already in the CFP. We hope to have APPROX/RANDOM 2021 hosted in Seattle by UW, instead of this year,  So if you never sent papers to APPROX/RANDOM because you hate travel, this is your year to start!</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>While <a href="https://randomconference.com/random-2020-home/">APPROX/RANDOM 2020</a> was scheduled for September, we decided to reduce uncertainty in these stormy days and declare it to be virtual already in the <a href="https://randomconference.files.wordpress.com/2020/04/randomapprox2020cfp-3.pdf">CFP</a>. We hope to have APPROX/RANDOM 2021 hosted in Seattle by UW, instead of this year,  So if you never sent papers to APPROX/RANDOM because you hate travel, this is your year to start!</p></div>
    </content>
    <updated>2020-04-01T22:37:07Z</updated>
    <published>2020-04-01T22:37:07Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-04-04T19:21:24Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-7256726075360411284</id>
    <link href="http://processalgebra.blogspot.com/feeds/7256726075360411284/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=7256726075360411284" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/7256726075360411284" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/7256726075360411284" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2020/04/magnus-m-halldorsson-eatcs-fellow-2020.html" rel="alternate" type="text/html"/>
    <title>Magnus M. Halldorsson: EATCS Fellow 2020</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">As announced <a href="http://eatcs.org/index.php/component/content/article/1-news/2851--eatcs-fellows-class-of-2020-named">here</a>, the EATCS Fellows vintage 2020 are<br/><ul><li><a href="http://pages.di.unipi.it/degano/">Pierpaolo Degano</a>, Universita di Pisa, Italy: for his contributions in concurrency theory and applications in security and for biological systems. </li><li><a href="http://www.cs.umd.edu/~hajiagha/">Mohammad Taghi Hajiaghayi,</a> University of Maryland, USA: for his contributions to the theory of algorithms, in particular algorithmic graph theory, game theory, and distributed computing. </li><li><a href="https://www.ru.is/~mmh/">Magnus Mar Halldorsson</a>, Reyjavik University, Iceland: for his contributions to the theory of approximation and graph algorithms as well as to the study of wireless algorithmics. </li></ul>Congratulations to all of them! However, I trust that Mohammad and Pierpaolo will forgive me if I devote this post to celebrate Magnus, his work and his contributions to the TCS community.<br/><br/>So, why was Magnus chosen as one of the EATCS Fellows 2020? Here are some reasons why.<br/><br/>Magnús has offered seminal contributions to the theory of approximation and graph algorithms as well as to the study of wireless algorithmics. His research career and contributions so far can be roughly divided into two phases. The first phase spans the time from the beginning of his career until roughly ten years ago. During that time, Magnús made significant contributions to approximation algorithms for maximum independent set and graph colouring, amongst many other problems. In the second phase, which started a bit more than ten years ago, he has worked on the algorithmics of realistic models for wireless computation. I think that it is fair to say that Magnús is currently <i>the</i> expert on wireless algorithmics based on the SINR model.<br/><br/>These two phases are not at all disjoint. Indeed, the typical problems studied in the SINR model, such as determining the capacity of wireless networks or how to schedule messages in such networks, can be seen as independent set and colouring problems, respectively, and his experience with those problems in graph algorithmics certainly helped Magnús in obtaining breakthrough results in wireless algorithmics. Throughout his career, Magnús has also given significant contributions to the computation of independent sets and colourings in restricted computational models, such as the online model of computation and the data streaming model. His sustained research productivity, both in quality and in quantity, is all the more remarkable since it has largely been achieved working in the difficult research environment in Iceland, where he was largely isolated until the establishment of the <a href="http://icetcs.ru.is/">Icelandic Centre of Excellent in Theoretical Computer Science (ICE-TCS)</a> in 2005. (Magnus has been the scientific director of the centre for 15 years.)<br/><br/>In addition to his seminal research achievements, Magnús has served the theoretical computer science community by sitting on prestigious award committees, organizing conferences and workshops in Iceland and elsewhere, serving on steering committees and by acting as an inspiring mentor for young researchers in computer science who have come to Iceland explicitly to work with him. By way of example, Magnús is a member of the steering committees for SIROCCO (chair), ALGOSENSORS and SWAT, Scandinavian Symposium and Workshops on Algorithm Theory (chair). He was a member of the Council of the EATCS and has organized the best attended ICALP conference to date (ICALP 2008). Amongst many other such duties, he was PC chair for Track C of ICALP 2015 and of ESA 2011.<br/><br/>Magnús was also one of the initiators and first editors of “<a href="http://www.nada.kth.se/%20%CC%83viggo/wwwcompendium/">A compendium of NP optimization problems”</a>, which is catalog of approximability results for NP optimization problems and has been a useful resource for researchers in that field for a long time. <br/><br/>Summing up, Magnús is a true stalwart of the algorithmics research community, and a great example for many of us. In my, admittedly biased, opinion, he richly deserves the recognition of being named an EATCS Fellow. I have no doubt that he will continue to lead by example in the coming years.<br/><br/><br/><br/></div>
    </content>
    <updated>2020-04-01T21:54:00Z</updated>
    <published>2020-04-01T21:54:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2020-04-04T14:46:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19719</id>
    <link href="https://gilkalai.wordpress.com/2020/04/01/an-update-from-israel-and-memories-from-singapore-partha-dasgupta-robin-mason-frank-ramsey-and-007/" rel="alternate" type="text/html"/>
    <title>A small update from Israel and memories from Singapore: Partha Dasgupta, Robin Mason, Frank Ramsey, and 007</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A small update about the situation here in Israel Eight weeks ago I wrote that my heart goes out to the people of Wuhan and China, and these days my heart goes out to people in Italy, Spain, the US, … <a href="https://gilkalai.wordpress.com/2020/04/01/an-update-from-israel-and-memories-from-singapore-partha-dasgupta-robin-mason-frank-ramsey-and-007/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h3>A small update about the situation here in Israel</h3>
<p>Eight weeks ago <a href="https://gilkalai.wordpress.com/2020/02/03/thinking-about-the-people-of-wuhan-and-china/">I wrote</a> that my heart goes out to the people of Wuhan and China, and these days my heart goes out to people in Italy, Spain, the US, Iran, France, the United Kingdom, Germany, Netherland and many other countries all over the world. Of course, I am especially worried about the situation here in my beloved country Israel, and let me tell you a little about it.</p>
<p>The pandemic started here late but it hit us pretty hard with 5,358 identified cases yesterday. Severe measures of social distancing were gradually introduced, and right now it is too early to tell if the pandemic is under control.</p>
<p>My part in this struggle is to stay at home. (Many Israeli scientists are making various endeavors and proposing ideas of various kind for fighting the disease and I salute them all for their efforts.) Like all of us I am very thankful to medical and other essential workers who are in the front-lines. As a scientist, I am especially impressed by the people from the Ministry of Health who manage the crisis and communicate with the public. They represent the very best we can offer in terms of science and medicine, decision making, gathering information, communicating with the public, and managing the crisis. In the picture below you can see three of the leaders – Moshe Bar Siman Tov (middle) Prof. Itamar Grotto (right) and Professor Sigal Sadetzki (left).</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/listen.png"><img alt="" class="alignnone size-full wp-image-19695" height="371" src="https://gilkalai.files.wordpress.com/2020/03/listen.png?w=640&amp;h=371" width="640"/></a></p>
<h2>And now for today’s post</h2>
<p>We had a tradition of sharing entertaining taxi-and-more stories and this post belongs to this category. We note that our highest quality story teller Michal Linial, a prominent Israeli biologist, is now involved in various aspects of the struggle against the disease. Our post today is part of<a href="https://gilkalai.files.wordpress.com/2020/03/gil-michal.docx"> a report by Michal Feldman and me on our experience from the ICA3 conferences in Singapore and Birmingham</a>.</p>
<h2>Partha Dasgupta, Robin Mason, Frank Ramsey, and James Bond</h2>
<p>After hearing about him for many years, it was a great pleasure for both Michal Feldman and myself to finally meet Partha Dasgupta in person and to listen to his lecture. Partha who is the Frank Ramsey Professor of Economics at Cambridge was introduced by a person, who entered the room directly from an intercontinental flight, whom we did not know but who made a strong impression on us. He devoted part of his introduction to Frank Ramsey who was a mathematician, philosopher and economist, and who had made fundamental contributions to algebra and had developed the canonical model of saving in economic growth, before he died at the young age of 26. (And yes! also Ramsey’s theorem!)</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/james-bond.png"><img alt="" class="alignnone size-full wp-image-19699" height="423" src="https://gilkalai.files.wordpress.com/2020/03/james-bond.png?w=640&amp;h=423" width="640"/></a></p>
<p>Seeing the introducer, Robin Mason, three words came into our minds (more precisely two words, one repeated twice): “Bond, James Bond.”</p>
<p>Indeed, this has led to the following sequence of profound ideas:</p>
<p>1) Robin Mason is a perfect choice for a new generation James Bond.</p>
<p>2) The name “James Bond” is overused. “Robin Mason” is a perfect name to replace the name “James Bond”.</p>
<p>3) Espionage is a little obsolete and it lost much of its prestige and charm. Science and academia is the new thing! An international interdisciplinary academics is the perfect profession which, at present, deserves the prestige formely associated with espionage.</p>
<p>In summary, we came a full circle. Robin Mason is the perfect new choice for James Bond, “Robin Mason” is the perfect new name to replace the name “James Bond,” and Mason’s academic activities and title of Pro-Vice-Chancellor (International) are the perfect replacement for Bond’s activities and the title ‘007’.</p>
<p>(The option of Mason playing his role on the movies rather than in real life should be considered. ‘Q’ could be handy for science as well. )</p>
<p><a href="https://youtu.be/dMSHmHc0z-E">Clique here</a> for Robin’s introduction and Partha’s lectur</p></div>
    </content>
    <updated>2020-04-01T19:44:35Z</updated>
    <published>2020-04-01T19:44:35Z</published>
    <category term="Algebra"/>
    <category term="Combinatorics"/>
    <category term="Conferences"/>
    <category term="Economics"/>
    <category term="Taxi-and-other-stories"/>
    <category term="Updates"/>
    <category term="Frank Ramsey"/>
    <category term="Itamar Grotto"/>
    <category term="Michal Feldman"/>
    <category term="Michal Linial"/>
    <category term="Moshe Bar Siman Tov"/>
    <category term="Partha Dasgupta"/>
    <category term="Robin Mason"/>
    <category term="Sigal Sadetzki"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-04-04T19:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blog.simons.berkeley.edu/?p=146</id>
    <link href="https://blog.simons.berkeley.edu/2020/04/lattice-blog-reduction-part-i-bkz/" rel="alternate" type="text/html"/>
    <title>Lattice Blog Reduction – Part I: BKZ</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This is the first entry in a (planned) series of at least three, potentially four or five, posts about lattice block reduction. The purpose of this series is to give a high level introduction to the most popular algorithms and … <a href="https://blog.simons.berkeley.edu/2020/04/lattice-blog-reduction-part-i-bkz/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This is the first entry in a (planned) series of at least three, potentially four or five, posts about lattice block reduction. The purpose of this series is to give a high level introduction to the most popular algorithms and their analysis, with pointers to the literature for more details. The idea is to start with the obvious – the classic BKZ algorithm. In the next two posts we will look at two lesser known algorithm, which allow to highlight useful tools in lattice reduction. These three posts will focus on provable results. I have not decided how to proceed from there, but I could see the series being extended to topics involving heuristic analyses, practical considerations, and/or a survey of more exotic algorithms that have been considered in the literature.</p>
<h4 id="target-audience">Target Audience</h4>
<p>I will assume that readers of this series are already familiar with basic concepts of lattices, e.g. bases, determinants, successive minima, Minkowski’s bound, Gram-Schmidt orthogonalization, dual lattices and dual bases, etc. If any of these concepts seem new to you, there are great resources to familiarize yourself with them first (see e.g. lecture notes by <a href="http://cseweb.ucsd.edu/classes/fa19/cse206A-a/">Daniele</a>, <a href="https://cims.nyu.edu/~regev/teaching/lattices_fall_2009/index.html">Oded</a>, <a href="https://homepages.cwi.nl/~dadush/teaching/lattices-2018/">Daniel/Léo</a>). It will probably help if you are familiar with the LLL algorithm (also covered in aforementioned notes), but I’ll try to phrase everything so it is understandable even if if you aren’t.</p>
<p>Ok, so let’s get started. Before we look at BKZ in particular, first some comments about lattice block reduction in general.</p>
<h1 id="sec:basics">The Basics</h1>
<h4 id="the-goal">The Goal</h4>
<p>Why would anyone use block reduction? There are (at least) two reasons.</p>
<h4 id="section"/>
<p>1) Block reduction allows you to find short vectors in a lattice. Recall that finding the shortest vector in a lattice (i.e. solving SVP) is really hard (as far as we know, this takes at least <span class="math inline">\(2^{\Omega(n)}\)</span> time or even <span class="math inline">\(n^{\Omega(n)}\)</span> if you are not willing to also spend exponential amounts of memory). On the other hand, finding somewhat short vectors that are longer than the shortest vector by “only” an exponential factor is really easy (see LLL). So what do you do if you need something that is shorter than what LLL gives you, but you don’t have enough time to actually find the shortest vector? (This situation arises practically every time you use lattice reduction for cryptanalysis.) You can try to find something in between and hope that it doesn’t take as long. This is where lattice reduction comes in: it gives you a smooth trade-off between the two settings. It is worth mentioning that when it comes to approximation algorithms, block reduction is essentially the only game in town, i.e. there are, as far as I know, no non-trivial approximation algorithms that cannot be viewed as block reduction. (In fact, this is related to an open problem that Noah stated during the program: to come up with a non-trivial approximation algorithm that does not rely on a subroutine to find the shortest lattice vector in smaller dimensions.) The only exception to this are quantum algorithms that are able to find subexponential approximations in polynomial time in lattices with certain (cryptographically highly relevant) structure (see <span class="citation">[CDPR16]</span> and follow up work).</p>
<h4 id="section-1"/>
<p>2) Block reduction actually gives you more than just short vectors. It gives you guarantees on the “quality” of the basis. What do we mean by the quality of the basis? Consider the Gram-Schmidt vectors <span class="math inline">\({\mathbf{b}}_i^*\)</span> (GSO vectors) associated to a lattice basis <span class="math inline">\({\mathbf{B}}\)</span>. What we want is that the length of these Gram-Schmidt vectors (the GSO norms) does not drop off too quickly. The reason why this is a useful measure of quality for lattice bases is that it gives a sense of how orthogonal the basis vectors are: conditioned on being bases of the same lattice, the less accentuated the drop off in the GSO vectors, the more orthogonal the basis, and the more useful this basis is to solve several problems in a lattice. In fact, recall that the product of the GSO norms is equal to the determinant of the lattice and thus remains constant. Accordingly, if the GSO norms do not drop off too quickly, the first vector can be shown to be relatively short. So by analyzing the quality of the basis that block reduction achieves, a guarantee on the length of the first vector comes for free (see goal 1)). If you are familiar with the analysis of LLL, this should not come as a surprise to you.</p>
<h4 id="tools">Tools</h4>
<p>In order to ensure that the GSO norms do not drop off to quickly, it seems useful to be able to reduce them locally. To this end, we will work with projected lattice blocks (this is where the term “block” in block reduction comes from). More formally, given a basis <span class="math inline">\({\mathbf{B}}\)</span> we will consider the block <span class="math inline">\({\mathbf{B}}_{[i,j]}\)</span> for <span class="math inline">\(i &lt; j\)</span> as the basis formed by the basis vectors <span class="math inline">\({\mathbf{b}}_i, {\mathbf{b}}_{i+1}, \dots, {\mathbf{b}}_{j}\)</span> <em>projected orthogonally to the first <span class="math inline">\(i-1\)</span> basis vectors</em>. So <span class="math inline">\({\mathbf{B}}_{[i,j]}\)</span> is a basis for the lattice given by the sublattice formed by <span class="math inline">\({\mathbf{b}}_1, {\mathbf{b}}_{2}, \dots, {\mathbf{b}}_{j}\)</span> projected onto the orthogonal subspace of the vectors <span class="math inline">\({\mathbf{b}}_1, {\mathbf{b}}_{2}, \dots, {\mathbf{b}}_{i-1}\)</span>. Notice that the first vector of <span class="math inline">\({\mathbf{B}}_{[i,j]}\)</span> is exactly <span class="math inline">\({\mathbf{b}}^*_i\)</span> – the <span class="math inline">\(i\)</span>-th GSO vector. Another way to view this is to consider the QR-factorization of <span class="math inline">\({\mathbf{B}} = {\mathbf{Q}} {\mathbf{R}}\)</span>, where <span class="math inline">\({\mathbf{B}}\)</span> is the matrix whose columns are the basis vectors <span class="math inline">\({\mathbf{b}}_i\)</span>. Since <span class="math inline">\({\mathbf{Q}}\)</span> is orthonormal, it represents a rotation of the lattice and we can consider the lattice generated by the columns of <span class="math inline">\({\mathbf{R}}\)</span> instead, which is an upper triangular matrix. For an upper triangular basis, the projection of a basis vector orthogonal to the previous basis vectors simply results in dropping the first entries from the vector. So considering a projected block <span class="math inline">\({\mathbf{R}}_{i,j}\)</span> is simply to consider the square submatrix of <span class="math inline">\({\mathbf{R}}\)</span> consisting of the rows and columns with index <span class="math inline">\(k\)</span> between <span class="math inline">\(i \leq k \leq j\)</span>.</p>
<p>Now we need a tool that allows us to control these GSO vectors, which we view as the first basis vectors in projected sublattices. For this, we will fall back to algorithms that solve SVP. Recall that this is very expensive, so we will not call this on the basis <span class="math inline">\({\mathbf{B}}\)</span> but rather on the projected blocks <span class="math inline">\({\mathbf{B}}_{[i,j]}\)</span>, where we ensure that the dimension <span class="math inline">\(k = j-i+1\)</span> of the lattice generated by this projected block is not too large. In fact, the maximum dimension <span class="math inline">\(k\)</span> that we call the SVP algorithm on will control the time/quality trade-off achieved by our block reduction algorithms and is usually denoted by the block size. So we will assume that we have access to such an SVP algorithm. Actually, we will assume something slightly stronger: we will assume access to a subroutine that takes as input the basis <span class="math inline">\({\mathbf{B}}\)</span> and indices <span class="math inline">\(i,j\)</span> and outputs a basis <span class="math inline">\({\mathbf{C}}\)</span> such that</p>
<ul>
<li><p>the lattice generated by the basis remains the same</p></li>
<li><p>the first <span class="math inline">\(i-1\)</span> and the last vectors starting from <span class="math inline">\(j+1\)</span> remain unchanged</p></li>
<li><p>the projected block <span class="math inline">\({\mathbf{C}}_{[i,j]}\)</span> is <em>SVP reduced</em>, meaning that <span class="math inline">\({\mathbf{c}}^*_i\)</span> is the shortest vector in the lattice generated by <span class="math inline">\({\mathbf{C}}_{[i,j]}\)</span>. Additionally, if <span class="math inline">\({\mathbf{B}}_{[i,j]}\)</span> is already SVP reduced, we assume that the basis <span class="math inline">\({\mathbf{B}}\)</span> is left unchanged.</p></li>
</ul>
<p>We will call an algorithm that achieves this an <em>SVP oracle</em>. Such an oracle can be implemented given any algorithm that solves SVP (for arbitrary lattices). The technical detail of filling in the gap is left as homework to the reader.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-156" height="315" src="https://blog.simons.berkeley.edu/wp-content/uploads/2020/04/svp.png" width="267"/>Effect of a call to the SVP oracle. GSO log norms of the input in black, of the output in red. Note that the sum of the GSO log norms is a constant, so reducing the first vector, increases the (average of the) remaining vectors.</figure></div>



<p>For the analysis we need to know what such an SVP oracle buys us. This is where Minkowski’s theorem comes in: we know that for any <span class="math inline">\(n\)</span>-dimensional lattice <span class="math inline">\(\Lambda\)</span> we have <span class="math inline">\(\lambda_1(\Lambda) \leq \sqrt{\gamma_n} \det(\Lambda)^{1/n}\)</span> (where <span class="math inline">\(\lambda_1(\Lambda)\)</span> is the length of the shortest vector in <span class="math inline">\(\Lambda\)</span> and <span class="math inline">\(\gamma_n = \Theta(n)\)</span> is Hermite’s constant). This tells us that after we’ve applied the SVP oracle to a projected block <span class="math inline">\({\mathbf{B}}_{[i,i+k-1]}\)</span>, we have <span class="math display">\[\|{\mathbf{b}}^*_i \| \leq \sqrt{\gamma_{k}} \left(\prod_{j = i}^{i+k-1} \|{\mathbf{b}}_j^* \| \right)^{1/k}.\]</span> Almost all of the analyses of block reduction algorithms, at least in terms of their output quality, rely on this single inequality.</p>
<h4 id="disclaimer">Disclaimer</h4>
<p>Before we finally get to talk about BKZ, I want to remark that throughout this series I will punt on a technical (but very important) topic: the number of arithmetic operations (outside of the oracle calls) and the size of the numbers. The number of arithmetic operations is usually not a problem, since it will be dominated by the calls to the SVP oracle. We will only compute projections of sublattices corresponding to projected blocks as described above to pass them to the oracle, which can be done efficiently using the Gram-Schmidt orthogonalization. The size of the numbers is a more delicate issue. We need to ensure that the required precision for these projections does not explode somehow. This is usually addressed by interleaving the calls to the SVP oracle with calls to LLL. If you are familiar with the LLL algorithm, it should be intuitive that this allows to control the size of the number. For a clean example of how this can be handled, we refer to e.g. <span class="citation">[GN08a]</span>. So, in summary, we will measure the running time of our algorithms thoughout simply in the number of calls to the SVP oracle.</p>
<h1 id="sec:bkz">BKZ</h1>
<p>Schnorr <span class="citation">[S87]</span> introduced the concept of BKZ reduction in the 80’s as a generalization of LLL. The first version of the BKZ algorithm as we consider it today was proposed by Schnorr and Euchner <span class="citation">[SE94]</span> a few years later. With our setup above, the algorithm can be described in a very simple way. Let <span class="math inline">\({\mathbf{B}}\)</span> be a lattice basis of an <span class="math inline">\(n\)</span>-dimensional lattice and <span class="math inline">\(k\)</span> be the block size. Recall that this is a parameter that will determine the time/quality trade-off as we shall see in the analysis. We start by calling the SVP oracle on the first block <span class="math inline">\({\mathbf{B}}_{[1,k]}\)</span> of size <span class="math inline">\(k\)</span>. Once this block is SVP reduced, we shift our attention to the next block <span class="math inline">\({\mathbf{B}}_{[2,k+1]}\)</span> and call the oracle on that. Notice that SVP reduction of <span class="math inline">\({\mathbf{B}}_{[2,k+1]}\)</span> may change the lattice generated by <span class="math inline">\({\mathbf{B}}_{[1,k]}\)</span> and <span class="math inline">\({\mathbf{b}}_1\)</span> may not be the shortest vector in the first block anymore, i.e. it can potentially be reduced even further. However, instead of going back and fixing that, we will simply leave this as a problem to “future us”. For now, we continue in this fashion until we reach the end of the basis, i.e. until we called the oracle on <span class="math inline">\({\mathbf{B}}_{n-k,n}\)</span>. Note that so far this can be viewed as considering a constant sized window moving from the start of the basis to the end and reducing the first vector of the projected block in this window as much as possible using the oracle. Once we have reached the end of the basis, we start reducing the window size, i.e. we call the oracle on <span class="math inline">\({\mathbf{B}}_{n-k+1,n}\)</span>, then on <span class="math inline">\({\mathbf{B}}_{n-k+2,n}\)</span>, etc. This whole process is called a <em>BKZ tour</em>.</p>
<p>Now that we have finished a tour, it is time to go back and fix the blocks that are not SVP reduced anymore. We do this simply by running another tour. Again, if the second tour modified the basis, there is no guarantee that all the blocks are SVP redcued. So we simply repeat, and repeat, and … you get the idea. We run as many tours as required until the basis does not change anymore. That’s it. If this looks familiar to you, that’s not a coincidence: if we plug in <span class="math inline">\(k=2\)</span> as our block size, we obtain (a version of) LLL! So BKZ is a proper generalization of LLL.</p>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-157" src="https://blog.simons.berkeley.edu/wp-content/uploads/2020/04/bkz.png"/>BKZ in one picture: apply the SVP oracle to the projected blocks from start to finish and when you reach the end, repeat.</figure>



<p>The obvious questions now are: what can we expect from the output? And how long does it take?</p>
<h4 id="the-good">The Good</h4>
<p>We will now take a closer look at the approximation factor achieved by BKZ. If you want to follow this analysis along, you might want to get out pen and paper. Otherwise, feel free to trust me on the calculations (I wouldn’t!) and/or jump ahead to the end of this section for the result (no spoilers!). Let’s assume for now that the BKZ algorithm terminates. If it does, we know that the projected block <span class="math inline">\({\mathbf{B}}_{[i, i+k-1]}\)</span> is SVP reduced for every <span class="math inline">\(i \in [1,\dots,n-k+1]\)</span>. This means that we have <span class="math display">\[\|{\mathbf{b}}^*_i \|^k \leq \gamma_{k}^{k/2} \prod_{j = i}^{i+k-1} \|{\mathbf{b}}_j^* \|\]</span> for all these <span class="math inline">\(n-k+1\)</span> values of <span class="math inline">\(i\)</span>. Multiplying all of these inequalities and canceling terms gives the inequality <span class="math display">\[\|{\mathbf{b}}^*_1 \|^{k-1}\|{\mathbf{b}}^*_2 \|^{k-2} \dots \|{\mathbf{b}}^*_{k-1} \| \leq \gamma_{k}^{\frac{(n-k+1)k}{2}} \|{\mathbf{b}}_{n-k+2}^* \|^{k-1} \|{\mathbf{b}}_{n-k+3}^* \|^{k-2} \dots \|{\mathbf{b}}_{n}^* \|.\]</span> Now we make two more observations: 1) not only is <span class="math inline">\({\mathbf{B}}_{[1, k]}\)</span> SVP reduced, but so is <span class="math inline">\({\mathbf{B}}_{[1, i]}\)</span> for every <span class="math inline">\(i &lt; k\)</span>. (Why? Think about it for 2 seconds!) This means we can multiply the inequalities <span class="math display">\[\|{\mathbf{b}}^*_1 \|^i \leq \gamma_{i}^{i/2} \prod_{j = 1}^{i} \|{\mathbf{b}}_j^* \|\]</span> for all <span class="math inline">\(i \in [2,k-1]\)</span> together with the trivial inequality <span class="math inline">\(\|{\mathbf{b}}^*_1 \| \leq \|{\mathbf{b}}^*_1 \|\)</span>, which gives <span class="math display">\[\|{\mathbf{b}}^*_1 \|^{\frac{k(k-1)}{2}} \leq \left(\prod_{i = 2}^{k-1} \gamma_{i}^{i/2} \right) \prod_{i = 1}^{k-1} \|{\mathbf{b}}_i^* \|^{k-1}\]</span> Now we use the fact that <span class="math inline">\(\gamma_k^k \geq \gamma_i^i\)</span> for all <span class="math inline">\(i \leq k\)</span> (Why? Homework!) and combine with our long inequality above to get <span class="math display">\[\|{\mathbf{b}}^*_1 \|^{\frac{k(k-1)}{2}} \leq \gamma_k^{\frac{k(n-1)}{2}} \|{\mathbf{b}}_{n-k+2}^* \|^{k-1} \|{\mathbf{b}}_{n-k+3}^* \|^{k-2} \dots \|{\mathbf{b}}_{n}^* \|.\]</span> (I’m aware that this is a lengthy calculation for a blog post, but we’re almost there, so bear with me. It’s worth it!)</p>
<p>We now use one final observation, which is a pretty common trick in lattice algorithms: w.l.o.g. assume that for some shortest vector <span class="math inline">\({\mathbf{v}}\)</span> in our lattice its projection orthogonal to the first <span class="math inline">\(n-1\)</span> basis vectors is non-zero (if it is zero for all of the shortest vectors, simply drop the last vector from the basis, the result is still BKZ reduced, so use induction). Then we must have that <span class="math inline">\(\lambda_1 = \| {\mathbf{v}} \| \geq \|{\mathbf{b}}_i^* \|\)</span> for all <span class="math inline">\(i \in [n-k+2, \dots, n]\)</span>, since otherwise the projected block <span class="math inline">\({\mathbf{B}}_{i,n}\)</span> would not be SVP reduced. This means, we have <span class="math inline">\(\lambda_1 \geq \max_{i \in [n-k+2, \dots, n]} \|{\mathbf{b}}_i^* \|\)</span>. This is the final puzzle piece to get our approximation bound: <span class="math display">\[\|{\mathbf{b}}^*_1 \| \leq \gamma_{k}^{\frac{n-1}{k-1}} \lambda_1.\]</span> Note that this analysis (dating back to Schnorr <span class="citation">[S94]</span>) is reminiscent of the analysis of LLL and if we plug in <span class="math inline">\(k=2\)</span>, we get exactly what we’d expect from LLL. Though we do note a gap in the other extreme: if we plug in <span class="math inline">\(k=n\)</span>, we know that the approximation factor is <span class="math inline">\(1\)</span> (we are solving SVP in the entire lattice), but the bound above yields a factor <span class="math inline">\(\gamma_n = \Theta(n)\)</span>.</p>
<h4 id="the-bad">The Bad</h4>
<p>Now that we’ve looked at the output quality of the basis, let’s see what we can say about the running time (recall that our focus is on the number of calls to the SVP oracle). The short answer is: not much and that’s very unfortunate. Ideally, we’d want a bound on the number of SVP calls that is polynomial in <span class="math inline">\(n\)</span> and <span class="math inline">\(k\)</span>. This would mean that the overall running time for large <span class="math inline">\(k\)</span> is dominated by the running time of the SVP oracle in dimension <span class="math inline">\(k\)</span> and the block size would give us exactly the expected trade-off. However, an LLL style analysis has so far only yielded a bound on the number of tours which is <span class="math inline">\(O(k^n)\)</span> <span class="citation">[HPS11, Appendix]</span>. This is quite bad – for large <span class="math inline">\(k\)</span> the number of calls will be the dominating factor in the running time.</p>
<h4 id="the-ugly">The Ugly</h4>
<p>Recall that the analysis of LLL does not only provide a bound on the approximation factor, but also on the Hermite factor, i.e. on the ratio of <span class="math inline">\(\| {\mathbf{b}}_1\|/\det(\Lambda)^{1/n}\)</span>. Since an LLL-style analysis worked out nicely for the approximation factor of BKZ, it stands to reason that a similar analysis should yield a similar bound for BKZ. By extrapolating from LLL, one could expect a bound along the lines of <span class="math inline">\(\| {\mathbf{b}}_1\|/\det(\Lambda)^{1/n} \leq \gamma_{k}^{n/2k}\)</span> (note the square root improvement w.r.t. the trivial bound obtained from the approximation factor). And, in fact, a bound of <span class="math inline">\(\gamma_{k}^{\frac{n-1}{2(k-1)} + 1}\)</span> has been claimed in <span class="citation">[GN08b]</span> but without proof (as pointed out in <span class="citation">[HPS11]</span>) and it is not clear, how one would prove this. (<span class="citation">[GN08b]</span> claims that one can use a similar argument as we did for the approximation factor, but I don’t see it.)</p>
<h4 id="the-rescue">The Rescue</h4>
<p>So it seems different techniques are necessary to complete the analysis of BKZ. The work of <span class="citation">[HPS11]</span> introduced such a new technique based on the analysis of dynamical systems. This work applied the technique successfully to BKZ, but the analysis is quite involved. What it shows is that one can terminate BKZ after a polynomial number of tours and still get a guarantee on the output quality, which is very close to the conjectured bound on the Hermite factor above. (Caveat: Technically, <span class="citation">[HPS11]</span> only showed this result for a slight variant of BKZ, but the difference to the standard BKZ algorithm only lies in the scope of the interleaving LLL applications, which is something that we glossed over above.) This is in line with experimental studies <span class="citation">[SE94,GN08b,MW16]</span>, which show that BKZ produces high quality bases after a few tours already.</p>
<p>We will revisit this approach when considering a different block reduction variant, SDBKZ, where the analysis is much cleaner. As a teaser for the next post though, recall that BKZ can be viewed as a generalization of LLL (which corresponds to BKZ with block size <span class="math inline">\(k=2\)</span>). Since the analysis of LLL did not carry entirely to BKZ, one could wonder if there is a different generalization of LLL such that an LLL-style analysis also generalizes naturally. The answer to this is yes, and we will consider such an algorithm in the next post.</p>



<ul><li>[CDPR16] Cramer, Ducas, Peikert, Regev. <em>Recovering short generators of principal ideals in cyclotomic rings.</em> EUROCRYPT 2016</li><li>[GN08a] Gama, Nguyen. <em>Finding short lattice vectors within Mordell’s inequality</em>. STOC 2008</li><li>[GN08b] Gama, Nguyen. <em>Predicting lattice reduction</em>. EUROCRYPT 2008</li><li>[HPS11] Hanrot, Pujol, Stehlé.<em> Analyzing blockwise lattice algorithms using dynamical systems.</em> CRYPTO 2011</li><li>[MW16] Micciancio, Walter. <em>Practical, predictable lattice basis reduction.</em> EUROCRYPT 2016</li><li>[SE94] Schnorr, Euchner. <em>Lattice basis reduction: Improved practical algorithms and solving subset sum problems.</em> Mathematical Programming 1994</li><li>[S87] Schnorr. <em>A hierarchy of polynomial time lattice basis reduction algorithms.</em> Theoretical Computer Science 1987</li><li>[S94] Schnorr. <em>Block reduced lattice bases and successive minima.</em> Combinatorics, Probability and Computing 1994</li></ul></div>
    </content>
    <updated>2020-04-01T15:17:39Z</updated>
    <published>2020-04-01T15:17:39Z</published>
    <category term="General"/>
    <category term="BKZ"/>
    <category term="Lattice Block Reduction"/>
    <author>
      <name>Michael Walter</name>
    </author>
    <source>
      <id>https://blog.simons.berkeley.edu</id>
      <link href="https://blog.simons.berkeley.edu/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blog.simons.berkeley.edu" rel="alternate" type="text/html"/>
      <subtitle>What's New at the Simons Institute for the Theory of Computing.</subtitle>
      <title>Calvin Café: The Simons Institute Blog</title>
      <updated>2020-04-03T23:46:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16904</id>
    <link href="https://rjlipton.wordpress.com/2020/04/01/research-at-home/" rel="alternate" type="text/html"/>
    <title>Research at Home</title>
    <summary>An idea for human-interest interviews Pixabay free src Dr. Lofa Polir is, like many of us, working from home. When we last wrote about her two years ago, she had started work for the Livingston, Louisiana branch of LIGO. They sent her and the rest of the staff home on March 19 and suspended observations […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>An idea for human-interest interviews</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/04/01/research-at-home/femalefool/" rel="attachment wp-att-16906"><img alt="" class="alignright wp-image-16906" height="213" src="https://rjlipton.files.wordpress.com/2020/03/femalefool.png?w=137&amp;h=213" width="137"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Pixabay free <a href="https://pixabay.com/illustrations/toon-figure-female-fool-funny-4292442/">src</a></font></td>
</tr>
</tbody>
</table>
<p>
Dr. Lofa Polir is, like many of us, working from home. When we last <a href="https://rjlipton.wordpress.com/2018/04/01/the-entropy-of-baseball/">wrote</a> about her two years ago, she had started work for the Livingston, Louisiana branch of <a href="https://www.ligo.caltech.edu/page/about">LIGO</a>. They sent her and the rest of the staff home on March 19 and <a href="https://www.ligo.caltech.edu/news/ligo20200326">suspended</a> observations on the 26th. Since Polir’s duties already included public outreach, she is looking to continue that online.</p>
<p>
Today we helped Dr. Polir interview another pandemic-affected researcher.</p>
<p>
We liked her idea of interviewing young people just starting their careers, who are facing unexpected uncertainties. Her first choice was a new graduate of Cambridge University doing fundamental work related to LIGO. Unfortunately, he had been unable to install a current version of Zoom on his handheld device, or maybe afraid owing to security <a href="https://twitter.com/random_walker/status/1244987617676050434?s=11">issues</a>. So she requested the special equipment we have used to <a href="https://rjlipton.wordpress.com/2011/10/31/an-interview-with-kurt-gdel/">interview</a> people <a href="https://rjlipton.wordpress.com/2012/11/03/more-interview-with-kurt-godel/">in</a> the <a href="https://rjlipton.wordpress.com/2013/11/15/the-graph-of-math/">past</a>. </p>
<p>
He replied at the speed of light that he was willing to do the interview so long as we respected some privacy measures. As for what name to use, he said we could just call him Izzy—Izzy Jr., in fact. So Dick, I, and Dr. Polir all used our own Zoom to port into our machine’s console room. The connection worked right away as Izzy’s head glimmered into view.</p>
<p>
</p><p/><h2> Starting The Interview </h2><p/>
<p/><p>
At first glimpse, all we could see was his long, light-brown hippie hair. This really surprised us—not the image we had of Cambridge—and we gasped about it before even saying hello. He replied that it was fashion from the Sixties. We asked how his family was doing and he said his fathers had passed on but mother and young siblings were at home and fine. We think he said “fathers” plural—the machine rendered him in a drawl like Mick Jagger and he was hard to follow.</p>
<p>
Izzy picked up on our discomfort and immediately assured us he hadn’t been doing any drugs: “You can’t get them anyway because they’re all being diverted to treat the sick.” But he did open up to us that he was in some kind of withdrawal. He confessed that he had resorted to looking at the sun with one eye. “It was ecstasy but bad—I still can see only reds and blues with that eye, and I need to use an extra-large rectangular cursor to read text.” We were curious what brand of handheld device he was using because of his problems with Zoom, and he told us it was a Napier 1660 by <a href="http://www.oughtred.org/history.shtml">Oughtred, Ltd.</a> We hadn’t heard of that model but he said he’d connected three of them into a good home lab setup.</p>
<p>
We asked how he was coping with distance teaching, but he said he hadn’t yet started his faculty position at Trinity College. We were surprised to learn that lecture attendance at Cambridge University is optional. “I shall be required to give the lectures but nobody will come to them so that’s all the same now—at least here I’ll have a cat for audience. No dogs and not my mother or siblings—I’d sooner burn the house down.” He quickly added, “Oh, my mother and I get along fine now and I love playing teatime with my little sisters.”</p>
<p>
We really didn’t want to go into Izzy’s personal life, and I tried to shift the small-talk by noting a little chess set on a shelf behind him. He snapped that he shouldn’t have spent money on it and he was a poor player anyway. We thought, wow, either this guy’s really down on himself or the cabin fever of the pandemic is getting to him. So Dick, always quick to pick up on things and find ways of encouragement, said:</p>
<p>
“Dr. Polir here works on gravity and we’re told you have some great new ideas about it. We’d love to hear them.”</p>
<p>
“Yes, I do—or did. But something happened yesterday that is making me realize that it’s all wrong, rubbish really…”</p>
<p>
</p><p/><h2> In the Garden </h2><p/>
<p/><p>
Izzy started by explaining that it’s a basic principle of alchemy that all objects have humors that can manifest as kinds of magnetism. (“Alchemy”? did we hear him right?) If you realize that the Earth and Sun are objects just like any other then you can model gravity that way. You just need to assign each object a number called its “mass” and then you get the equation </p>
<p align="center"><img alt="\displaystyle  F = G \frac{m_1 m_2}{r^2} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F+%3D+G+%5Cfrac%7Bm_1+m_2%7D%7Br%5E2%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  F = G \frac{m_1 m_2}{r^2} "/></p>
<p>for the force of attraction, where <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> is the distance between the objects with masses <img alt="{m_1,m_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_1%2Cm_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_1,m_2}"/> and <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is a constant that depends on your units.</p>
<p>
“We understand all that,” said Dr. Polir.</p>
<p>
Izzy said the point is that <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> depends <b>only</b> on your units and is the same regardless of where you are on Earth or on the Moon or wherever. It is very small, though. Then he went into his story of yesterday.</p>
<blockquote><p><b> </b> <em> “I was in our garden by the path to the neighbor’s farm. I was supposed to be watching my little brother Benjamin who wanted to help harvest squash but I hate farming so I let him go without me. I was lying under an apple tree for shade when an apple fell and I realized all my mistakes.” </em>
</p></blockquote>
<p/><p>
“What?,” we thought silently. We didn’t need to speak up—Izzy launched right into his litany of error:</p>
<blockquote><p><b> </b> <em> “First, I’d thought the force was in what made the apple fall, but that’s nonsense. The apple would fall naturally because down is the shortest path it would be on if the tree branch were not holding it back. The only force is the tensile strength of the branch which was restraining it. I think that the tensile force really is magnetism, by the way.”</em></p><em>
<p>
“Second, it’s ridiculous to think the force is coming <b>from</b> the Earth. On first principles, it could come from the ground, but that’s not what the equations say. They could have it all coming from one point in the <b>center</b> of the Earth. Just one point—four thousand miles deep!”</p>
</em><p><em>
“Third and worst, though, is when you apply it to the Sun and the Earth. My equation means they are exerting force on each other instantaneously. But they are millions of miles apart. Whereas, the tree was <b>touching</b> the apple. Force can work only by touch, not by some kind of spooky action at a distance.” </em>
</p></blockquote>
<p/><p>
We realized what he was driving at. Dick again always likes to encourage, so he said:</p>
<p>
“But the math you developed for this force theory—surely it is good for calculations…?”</p>
<blockquote><p><b> </b> <em> “No it’s not—it’s the Devil’s own box. I can calculate two bodies—the Earth and the Sun, or the Moon and the Earth if you suppose there is no Sun, but as soon as you have all three bodies it’s a bog. Worst of all, I can arrange five bodies so that one of them gets accelerated to infinite velocity—<a href="https://rjlipton.wordpress.com/2019/10/31/hobgoblins-in-our-equations/">in finite time</a>. This is a clear impossibility, a contradiction, so by <em>modus tollens</em>… it can all go in the bin.” </em>
</p></blockquote>
<p/><p>
We didn’t think it would help to tell him that his math was good enough to <a href="https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19720022040.pdf">calculate</a> a Moon landing but not to locate a friend’s house while driving. He supplied his own <em>coup-de-grâce</em> anyway:</p>
<blockquote><p><b> </b> <em> “And even the two-body calculations are tainted. I can calculate the orbits of the planets but the equations I get aren’t stable. I would wind up having to postulate something like God keeps the planets on their tracks. Yes, you need an intelligent Agent to start the planets going—all in one plane, basically—but to need such intervention all the time defeats the point of having equations.” </em>
</p></blockquote>
<p>
</p><p/><h2> Inklings </h2><p/>
<p/><p>
We asked Izzy what he was going to do. He said that the one blessing of enforced solitude is that one gets time to reflect on things and deepen the foundations. And he said he’d had an idea later that afternoon.</p>
<blockquote><p><b> </b> <em> “Toward supper I realized I needed to get Benjamin home. The path to the farm is straight except it goes over a mound. I was sauntering along and when I got to the hill I realized that if I didn’t watch it I’d have fallen right into it. So that got me thinking. First, what I thought was straight on the path was really a curve—the Earth is after all a ball. We think space is straight, but maybe it too is curved. So when I’m standing here, perhaps I would really be moving in a diagonally down direction, but the Earth is stopping me. The Irish blessing says, ‘may the road rise up to meet you.’ Perhaps it does.” </em>
</p></blockquote>
<p/><p>
“So are you doing math to work that out?,” I ventured.</p>
<blockquote><p><b> </b> <em> “I started after supper. One good thing is that it allows light to be affected by gravity—which I was already convinced of—even if light has no mass. But a problem is that it appears Time would have to be included as curved. That does not make sense either.” </em>
</p></blockquote>
<p/><p>
We asked when he might write up all this. He said he didn’t want to be quick to publish something so flawed on the one hand, or incomplete on the other, “unless someone else be about to publish the same.” We noted that there weren’t going to be any in-person conferences to present papers at for awhile anyway.</p>
<blockquote><p><b> </b> <em> “Besides, that’s not what I’m most eager to do. What the respite is really giving me time for is to start writing up my work on Theology. That’s most important—it could have stopped thirty years of war. For one thing, <a href="https://en.wikipedia.org/wiki/Homoiousios">homoiousios</a>, not <a href="https://en.wikipedia.org/wiki/Homoousios">homoousios</a>, is the right rendering. There will be a time and times and the dividing of times in under 400 years <a href="https://www.questia.com/library/journal/1G1-116141910/a-time-and-times-and-the-dividing-of-time-isaac">anyway</a>.” </em>
</p></blockquote>
<p/><p>
That last statement somehow did not reassure us. We thanked Izzy Jr. for the interview and he gave consent to publish it posthumously.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We hope that your April Fool’s Day is such as to allow a time to laugh. But also seriously, would you be interested in the idea of our interviewing people during these times? Is there anyone you would like to suggest?</p>
<p/></font></font></div>
    </content>
    <updated>2020-04-01T05:10:02Z</updated>
    <published>2020-04-01T05:10:02Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="People"/>
    <category term="Teaching"/>
    <category term="April Fool"/>
    <category term="gravity"/>
    <category term="interview"/>
    <category term="Lofa Polir"/>
    <category term="outreach"/>
    <category term="pandemic"/>
    <category term="Physics"/>
    <category term="working from home"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-04-04T19:20:41Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/03/31/linkage</id>
    <link href="https://11011110.github.io/blog/2020/03/31/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Still at home, hoping the coffee arrives tomorrow as scheduled.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Still at home, hoping the coffee arrives tomorrow as scheduled.</p>

<ul>
  <li>
    <p><a href="https://twitter.com/scienceshitpost">Science diagrams that look like shitposts</a> (<a href="https://mathstodon.xyz/@11011110/103834852903279134"/>, <a href="https://www.metafilter.com/186088/Science-diagrams-that-look-like-shitposts">via</a>).</p>
  </li>
  <li>
    <p><a href="https://www.cambridge.org/core/what-we-publish/textbooks">All Cambridge University Press textbooks are free-to-read until May</a> (<a href="https://mathstodon.xyz/@JordiGH/103841002082854377"/>).</p>
  </li>
  <li>
    <p><a href="https://www.rweber.net/projects/non-gray-grayscales/">Non-gray grayscales</a> (<a href="https://mathstodon.xyz/@11011110/103848490584549963"/>). Rebecca Weber finds a method to produce off-gray colors in a range of lightness with visually-matching hues and saturations. It’s not just a matter of plotting a straight line in HSL colorspace. (Found while looking for more information on her book <em>Computability Theory</em>, but nowadays there isn’t much actual math on her website.)</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2003.08456">Convex hulls of random order types</a> (<a href="https://mathstodon.xyz/@11011110/103853512504928724"/>). This is one of my favorite papers in the list accepted to SoCG 2020, which now will be online-only. Point sets whose order type is uniformly random are different from randomly drawn points, and harder to study. Xavier Goaoc and Emo Welzl observe that the projective transformations of a random order type are equally likely, and use this idea to prove that these point sets typically have very small convex hulls.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Greedy_coloring">Greedy coloring</a> (<a href="https://mathstodon.xyz/@11011110/103856462402785120"/>). Now a Good Article on Wikipedia.</p>
  </li>
  <li>
    <p><a href="https://www.theguardian.com/science/2019/oct/21/can-you-solve-it-the-four-points-two-distances-problem">The four points, two distances problem</a> (<a href="https://mathstodon.xyz/@11011110/103864906436854951"/>). Can you find all of the ways of arranging four distinct points in the plane so that they form only two distances? The link is not a spoiler but it has a separate link to the solution. “Nearly everyone misses at least one” says Peter Winkler; can you guess the one I missed?</p>
  </li>
  <li>
    <p><a href="https://mastodon.social/@sarielhp/103853624792571796">Sariel Har-Peled makes some suggestions for online conferences</a>: all papers above threshold should be accepted, rather than imposing artificial acceptance rates, and authors should provide versions of their talks in multiple lengths.</p>
  </li>
  <li>
    <p><a href="https://community.wolfram.com/groups/-/m/t/1904335">Minimal-stick examples of the knots , , , , and </a> (<a href="https://mathstodon.xyz/@shonk/103868182994018206"/>).</p>
  </li>
  <li>
    <p>Two linocut interpretations of a rhombic dodecahedron by the same artist, Josh Millard: <a href="https://mastodon.social/@joshmillard/103876129272051551">abstract</a> and <a href="https://mastodon.social/@joshmillard/103881150094999086">physical</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/103887968806441789"/>).</span></p>
  </li>
  <li>
    <p>Three recent “Did you know?” (<a href="https://mathstodon.xyz/@11011110/103893665729668173"/>):</p>

    <ul>
      <li>
        <p>… that <a href="https://en.wikipedia.org/wiki/Chiara_Daraio">Chiara Daraio</a> used Newton’s cradle to create sound bullets, and ball bearing filled walls to create one-way sound barriers?</p>
      </li>
      <li>
        <p>… that <a href="https://en.wikipedia.org/wiki/Heronian_tetrahedron">a tetrahedron with integer edge lengths, face areas, and volume</a> can be given integer coordinates?</p>
      </li>
      <li>
        <p>… that former college basketball star <a href="https://en.wikipedia.org/wiki/Amy_Langville">Amy Langville</a> is an expert in ranking systems, and has applied her ranking expertise to basketball bracketology?</p>
      </li>
    </ul>
  </li>
  <li>
    <p><a href="http://www.mi.sanu.ac.rs/vismath/mart.htm">VisMath MathArt</a> (<a href="https://mathstodon.xyz/@11011110/103898916402221482"/>). Many linked galleries of images of mathematical art, from the 1990s-style web (occasional broken links and all).</p>
  </li>
  <li>
    <p><a href="https://blog.computationalcomplexity.org/2020/03/robin-thomas.html">Sadly, graph theorist Robin Thomas has died</a> (<a href="https://mathstodon.xyz/@11011110/103901957462987629"/>).</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=IK7nBOLYzdE">What happens when half a cellular automaton runs Conway’s Game of Life and the other half runs a rolling version of Rule 30 pushing chaos across the border</a> (<a href="https://mathstodon.xyz/@11011110/103915202241542224"/>)? I wish I could see a larger scale of time and space to get an idea of how far the effects penetrate. If the boundary emitted gliders at a constant rate they’d collide far away in a form of ballistic annihilation but the boundary junk and glider-collision junk makes it more complicated.</p>
  </li>
  <li>
    <p><a href="https://mathoverflow.net/q/356220/440">Monotone subsets of uncountable plane sets</a> (<a href="https://mathstodon.xyz/@11011110/103919594138003386"/>). I ask on MathOverflow about infinite generalizations of the Erdős–Szekeres theorem on the existence of square-root-sized monotone subsets of finite sets of points in the plane.</p>
  </li>
</ul></div>
    </content>
    <updated>2020-03-31T21:25:00Z</updated>
    <published>2020-03-31T21:25:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-04-01T04:49:01Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4912143677920692930</id>
    <link href="https://blog.computationalcomplexity.org/feeds/4912143677920692930/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/03/length-of-descriptions-for-dfa-nfa-cfg.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4912143677920692930" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4912143677920692930" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/03/length-of-descriptions-for-dfa-nfa-cfg.html" rel="alternate" type="text/html"/>
    <title>Length of Descriptions for DFA, NFA, CFG</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
We will be looking at the size of descriptions<br/>
<br/>
 For DFAs and NFAs this is the number of states.<br/>
<br/>
For CFG's we will assume they are in Chomsky Normal Form. So for this post CFG means CFG in Chomsky normal form. The length of a Chomsky Normal Form CFL is the number of rules.<br/>
<br/>
1) It is known there is a family of languages L_n such that<br/>
<br/>
DFA for L_n requires roughly 2^n states.<br/>
<br/>
NFA for L_n can be done with roughly n states.<br/>
<br/>
L_n =  (a,b)^* a (a,b)^n<br/>
<br/>
Also note that there is a CFG for L_n with roughly n rules. (one can show this directly or by some theorem that goes from an NFA of size s to a CFG of size roughly s).<br/>
<br/>
So L_n shows there is an exp blowup between DFAs and NFA's<br/>
<br/>
2) It is known that there is a family of languages L_n such that<br/>
<br/>
DFA for L_n requires roughly 2^n states<br/>
<br/>
NFA for L_n requires roughly 2^n states<br/>
<br/>
CFG for L_n can be done with roughly n rules<br/>
<br/>
L_n = { a^{2^n}  }<br/>
<br/>
So L_n shows there is an exp blowup between NFAs and CFGs.<br/>
<br/>
<br/>
3) Is there a family of languages L_n such that<br/>
<br/>
NFA for L_n requires 2^{2^n} states<br/>
<br/>
CFG for L_n can be done with roughly n rules.<br/>
<br/>
The answer is not quite- and perhaps open.  There is a set of family of languages L_n such that for infinitely many n he above holds. These languages have to do with Turing Machines. In fact, you can replace<br/>
<br/>
2^{2^n}} with any function f  \le_T  INF (so second level of undecidability).<br/>
<br/>
For this blog this is NOT what we are looking for. (For more on this angle see <a href="https://arxiv.org/pdf/1503.08847.pdf">here</a><br/>
<br/>
<br/>
4) OPEN (I think) Is there a family of langs L_n such that for ALL n<br/>
<br/>
NFA for L_n requires 2^{2^n} (or some other fast growing function<br/>
<br/>
CFG for L_n can be done with roughly n states (we'll take n^{O(1)})<br/>
<br/>
5) OPEN (I think) Is there a family of langs L_n such that for ALL n<br/>
(or even for just inf many n)<br/>
<br/>
DFA for L_n requires 2^{2^n}} states<br/>
<br/>
NFA for L_n requires 2^n states and can be done in 2^n<br/>
<br/>
CFG for L_n can be done with n rules.<br/>
<br/>
(we'll settle for not quite as drastic, but still want to see DFA, NFA, CFG all<br/>
far apart).<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2020-03-31T17:53:00Z</updated>
    <published>2020-03-31T17:53:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-04-04T15:36:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/042</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/042" rel="alternate" type="text/html"/>
    <title>TR20-042 |  Poly-time blackbox identity testing for sum of log-variate constant-width ROABPs | 

	Pranav Bisht, 

	Nitin Saxena</title>
    <summary>Blackbox polynomial identity testing (PIT) affords 'extreme variable-bootstrapping' (Agrawal et al, STOC'18; PNAS'19; Guo et al, FOCS'19). This motivates us to study log-variate read-once oblivious algebraic branching programs (ROABP). We restrict width of ROABP to a constant and study the more general sum-of-ROABPs model. We give the first poly($s$)-time blackbox PIT for sum of constant-many, size-$s$, $O(\log s)$-variate constant-width ROABPs. The previous best for this model was quasi-polynomial time (Gurjar et al, CCC'15; CC'16) which is comparable to brute-force in the log-variate setting. Also, we handle unbounded-many such ROABPs if each ROABP computes a homogeneous polynomial. 

Our new techniques comprise-- (1) an ROABP computing a homogeneous polynomial can be made syntactically homogeneous in the same width; and (2) overcome the hurdle of unknown variable order in sum-of-ROABPs in the log-variate setting (over any field).</summary>
    <updated>2020-03-31T13:31:36Z</updated>
    <published>2020-03-31T13:31:36Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-04T19:20:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4695</id>
    <link href="https://www.scottaaronson.com/blog/?p=4695" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4695#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4695" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">On “armchair epidemiology”</title>
    <summary xml:lang="en-US">Update (March 31): Since commenter after commenter seems to have missed my point—or rather, rounded the point to something different that I didn’t say—let me try one more time. My faith in official pronouncements from health authorities, and in institutions like the CDC and the FDA, was clearly catastrophically misplaced—and if that doesn’t force significant […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong><font color="red">Update (March 31):</font></strong> Since commenter after commenter seems to have missed my point—or rather, rounded the point to something different that I didn’t say—let me try one more time.  My faith in official pronouncements from health authorities, and in institutions like the CDC and the FDA, was clearly <em>catastrophically </em>misplaced—and if that doesn’t force significant revisions to my worldview, then I’m beyond hope.  Maybe the failures are because these organizations are at the mercy of political incompetents—meaning ultimately Trump and the people who put him in office.  Or maybe the rot started long before Trump.  Maybe it’s specific to the US, or maybe it’s everywhere.  I still don’t know the answers to those questions.</p>



<p>On the other hand, my faith in my ability to listen to individual people, whether they’re expert epidemiologists or virologists or just technologists or rationalists or anyone else (who in turn listened to the experts), and to say “yes, this person clearly has good judgment and has thought about it carefully, and if they’re worried then I should be too”—my faith in <em>that</em> has only gone up.  The problem is simply that I didn’t do enough of that back in January and February, and when I did, I didn’t sufficiently act on it.</p>



<p><strong><font color="red">End of Update</font></strong></p>



<p>On Feb. 4, a friend sent me an email that read, in part:</p>



<blockquote class="wp-block-quote"><p>Dr. A,<br/>What do you make of this coronavirus risk? …  I don’t know what level of precaution is necessary!  Please share your view.  </p></blockquote>



<p>This was the first time that I’d been prompted to give this subject any thought whatsoever.  I sent a quick reply two minutes later:</p>



<blockquote class="wp-block-quote"><p>For now, I think the risk from the ordinary flu is much much greater!  But worth watching to see if it becomes a real pandemic. </p></blockquote>



<p>Strictly speaking, this reply was “correct”—even “reasonable” and “balanced,” admitting the possibility of changing circumstances.  Yet if I could go back in time, I’d probably send a slightly different message—one that would fare better in the judgment of history.  Something like this, maybe:</p>



<blockquote class="wp-block-quote"><p><strong>HOLY SHIT!!!!!—GET YOUR PARENTS SOMEWHERE SAFE—CANCEL ALL TRAVEL PLANS—STOCK UP ON FOOD AND MASKS AND HAND SANITIZERS.  SELL ALL STOCK YOU OWN!!!  SHORT THE MARKET IF YOU KNOW HOW, OTHERWISE GET CASH AND BONDS.  HAVE AN ISOLATED PLACE TO ESCAPE TO.  IF YOU’RE FEELING ALTRUISTIC, JOIN GROUPS MAKING THEIR OWN MASKS AND VENTILATORS.</strong></p><p><strong>DO NOT RELY ON OFFICIAL PRONOUNCEMENTS, OR REASSURING ARTICLES FROM MAINSTREAM SOURCES LIKE <em>VOX</em> OR <em>THE WASHINGTON POST</em>.  THEY’RE FULL OF IT.  THE CDC AND OTHER FEDERAL AGENCIES ARE ASLEEP AT THE WHEEL, HOLLOWED-OUT SHELLS OF WHAT YOU IMAGINE THEM TO BE.  FOR ALL IT WILL DO IN ITS MOMENT OF ULTIMATE NEED, IT WOULD BE BETTER IF THE CDC NEVER EXISTED.</strong></p><p><strong>WHO THEN SHOULD YOU LISTEN TO?  CONTRARIAN, RATIONALIST NERDS AND TECH TYCOONS ON SOCIAL MEDIA.  BILL GATES, BALAJI SRINIVASAN, PAUL GRAHAM, GREG COCHRAN, ROBIN HANSON, SARAH CONSTANTIN, ELIEZER YUDKOWSKY, NICHOLAS CHRISTAKIS, ERIC WEINSTEIN.  NO, NOT ALL SUCH PEOPLE—NOT ELON MUSK, FOR EXAMPLE—BUT YOU’LL DO RIDICULOUSLY BETTER THAN AVERAGE THIS WAY. </strong></p><p><strong>BASICALLY, THE MORE SNEERCLUB WOULD SNEER AT A GIVEN PERSON, THE MORE THEY’D CALL THEM AN AUTODIDACT STEMLORD DUNNING-KRUGER ASSHOLE WHO’S THE EMBODIMENT OF EVERYTHING WRONG WITH NEOLIBERAL CAPITALISM, THE MORE YOU SHOULD LISTEN TO THAT PERSON RIGHT NOW FOR THE SAKE OF YOUR AND YOUR LOVED ONES’ FUCKING LIVES.  </strong></p><p><strong>DON’T WORRY: WITHIN 6-8 WEEKS, WHAT THE CONTRARIANS ARE SAYING TODAY WILL <em>BE</em> CONVENTIONAL WISDOM.  THE PUBLICATIONS THAT NOW SNEER AT PANDEMIC PREPPERS WILL TURN AROUND AND SNEER AT THE IRRESPONSIBLE NON-PREPPERS, WITHOUT EVER ADMITTING ERROR.  WE’LL ALWAYS HAVE BEEN AT WAR WITH OCEANIA—OR RATHER CORONIA.  TRUTH, OFFICIAL RECOMMENDATIONS, AND PROGRESSIVE POLITICS WILL GET BACK INTO ALIGNMENT JUST LIKE THEY NORMALLY ARE, AND WE’LL ALL BE SHARING MEMES JUSTLY DENOUNCING TRUMP AND THE CRAVEN REPUBLICAN SENATORS AND EVANGELICAL PASTORS AND NUTTY CONSPIRACY THEORISTS WHO DON’T CARE HOW MANY LIVES THEY SACRIFICE WITH THEIR DENIALS.</strong></p><p><strong>BUT EVEN THOUGH THE ENLIGHTENED MAINSTREAM WILL FIGURE OUT THE TRUTH IN A MONTH OR SO—AND EVEN THOUGH THAT’S FAR BETTER THAN OUR IDIOT PRESIDENT AND MILLIONS OF HIS FOLLOWERS, WHO WILL UNDERSTAND ONLY AFTER THE TRENCHES OVERFLOW WITH BODIES, IF THEN—EVEN SO, WE DON’T HAVE A MONTH.  IF YOU WANT TO BE AHEAD OF THE SENSIBLE MAINSTREAM, THEN ALMOST BY DEFINITION, THAT MEANS YOU NEED TO LISTEN TO THE POLITICALLY INCORRECT, CRAZY-SOUNDING ICONOCLASTS: TO THOSE WHO, UNLIKE YOU AND ALSO UNLIKE ME, HAVE DEMONSTRATED THAT THEY DON’T CARE IF PEOPLE SNEER AT THEM. </strong> </p></blockquote>



<p>Of course, I would never have sent such an email, and not only because of the bold and all-caps.  My whole personality stands against every sentence.  I’ve always taken my cues from “mainstream, reasonable, balanced” authorities, in any subject where I’m not personally expert.  That heuristic has generally been an excellent way to maximize expected rightness.  But when it fails … holy crap!</p>



<p>Now, and for the rest of my life, I’ll face the question: what was wrong with me, such that I would never have sent a “nutty” email like the one above?  Can I fix it?</p>



<p>More specifically, was my problem intellectual or emotional?  I lean toward the latter.  By mid-to-late February, as more and more of my smartest friends started panicking and telling me why I should too, I got intellectually fully on board with the idea that millions of people might die as the new virus spread around the world, and I affirmed as much on Facebook and elsewhere.  And yet it still took me a few more weeks to get from “millions could die” to “<strong>HOLY SHIT MILLIONS COULD DIE—PANIC—DROP EVERYTHING ELSE—BUILD MORE VENTILATORS!!!!</strong>“</p>



<p>A <a href="https://medium.com/@noahhaber/flatten-the-curve-of-armchair-epidemiology-9aa8cf92d652">viral article</a> implores us to “flatten the curve of armchair epidemiology”—that is, to listen only to authoritive sources like the CDC, not random people spouting on social media.  This was notable to me for being the diametric opposite of the <em>actual</em> lesson of the past two months.  It would be like taking the lesson from the 2008 financial crisis that from now on, you would only trust serious rating agencies, like Moody’s or Standard &amp; Poor.</p>



<p>Oh, but I forgot to tell you the punchline.  A couple days ago, the same friend who emailed me on February 4, emailed again to tell me that both of her parents (who live outside the US) now have covid-19.  Her father had to go to the emergency room and tested positive.  Her mother stayed home with somewhat milder symptoms.  Given the overloaded medical system in their country, neither can expect a high standard of care.  My friend has spent the past few days desperately trying to get anyone from the hospital on the phone.</p>



<p>This post represents my apology to her.  Like, it’s one thing to be so afraid of the jeers of the enlightened that you feign asexuality and live as an ascetic for a decade.  It’s worse to be so afraid that you fail adequately to warn your friends when you see an exponential function coming to kill their loved ones.</p></div>
    </content>
    <updated>2020-03-31T00:05:43Z</updated>
    <published>2020-03-31T00:05:43Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-03-31T15:58:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1640</id>
    <link href="https://theorydish.blog/2020/03/30/forc-2020-going-strong-going-virtual/" rel="alternate" type="text/html"/>
    <title>FORC 2020: Going Strong, Going Virtual</title>
    <summary>FORC 2020 accepted papers are out. Despite the last minute announcement and minimal advertising of this new conference, we have an exciting and strong program. This confirms our conviction that the new conference fills an important need for a home to the TOC sub-community that works on the societal aspects of computation. Unfortunately, but non-surprisingly, the conference will be virtual this year. But I’m sure that, thanks to Aaron Roth and to the inaugural PC, we will make the best what’s possible and have a great event.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>FORC 2020 <a href="https://responsiblecomputing.org/accepted-papers/?fbclid=IwAR0NTKaoKheiOmzYYyBqbDVtnkrPL8ooELD2RvfRFe7BHMF5tbgFg_bV840">accepted papers are out</a>. Despite the <a href="https://theorydish.blog/2019/10/30/toc-for-society/">last minute announcement</a> and minimal advertising of this new conference, we have an exciting and strong program. This confirms our conviction that the new conference fills an important need for a home to the TOC sub-community that works on the societal aspects of computation.</p>
<p>Unfortunately, but non-surprisingly, the conference will be virtual this year. But I’m sure that, thanks to <a href="https://www.cis.upenn.edu/~aaroth/">Aaron Roth</a> and to the inaugural PC, we will make the best what’s possible and have a great event.</p></div>
    </content>
    <updated>2020-03-30T20:35:21Z</updated>
    <published>2020-03-30T20:35:21Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-04-04T19:21:24Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-25562705.post-4686387049269740360</id>
    <link href="http://aaronsadventures.blogspot.com/feeds/4686387049269740360/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=25562705&amp;postID=4686387049269740360" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/4686387049269740360" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/4686387049269740360" rel="self" type="application/atom+xml"/>
    <link href="http://aaronsadventures.blogspot.com/2020/03/forc-2020-accepted-papers.html" rel="alternate" type="text/html"/>
    <title>FORC 2020 Accepted Papers</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">When we <a href="https://aaronsadventures.blogspot.com/2019/10/forc-new-conference-you-should-know.html">announced </a>the new conference <a href="https://responsiblecomputing.org/accepted-papers/">FORC (Foundations of Responsible Computing)</a> we really had no idea what kind of papers folks would send us.<br/><br/>Fortunately, we got a really high quality set of submissions, from which we have accepted the papers that will make up the program of the inaugural FORC. Check out the accepted papers here: <a href="https://responsiblecomputing.org/accepted-papers/">https://responsiblecomputing.org/accepted-papers/</a></div>
    </content>
    <updated>2020-03-30T00:38:00Z</updated>
    <published>2020-03-30T00:38:00Z</published>
    <author>
      <name>Aaron</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/09952936358739421126</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-25562705</id>
      <category term="game theory"/>
      <category term="news"/>
      <author>
        <name>Aaron</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/09952936358739421126</uri>
      </author>
      <link href="http://aaronsadventures.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://aaronsadventures.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <title>Adventures in Computation</title>
      <updated>2020-03-30T00:38:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16861</id>
    <link href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/" rel="alternate" type="text/html"/>
    <title>Logic and Star-Free, Part Deux</title>
    <summary>A visual proof with no abstract-algebra overhead Composite crop of src1, src2 Dominique Perrin and Jean-Éric Pin are French mathematicians who have done significant work in automata theory. Their 1986 paper “First-Order Logic and Star-Free Sets” gave a new proof that first-order logic plus the relation characterizes star-free regular sets. Today we present their proof […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>A visual proof with no abstract-algebra overhead</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/perrinpin/" rel="attachment wp-att-16863"><img alt="" class="alignright wp-image-16863" height="154" src="https://rjlipton.files.wordpress.com/2020/03/perrinpin.png?w=200&amp;h=154" width="200"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop of <a href="http://www-igm.univ-mlv.fr/~perrin/">src1</a>, <a href="https://www.ae-info.org/ae/Member/Pin_Jean-Eric">src2</a></font></td>
</tr>
</tbody>
</table>
<p>
Dominique Perrin and Jean-Éric Pin are French mathematicians who have done significant work in automata theory. Their 1986 <a href="https://core.ac.uk/download/pdf/82354218.pdf">paper</a> “First-Order Logic and Star-Free Sets” gave a new proof that first-order logic plus the <img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/> relation characterizes star-free regular sets.</p>
<p>
Today we present their proof in a new visual way, using “stacked words” rather than their “marked words.” We also sidestep algebra by appealing to the familiar theorem that every regular language has a unique minimal deterministic finite automaton (DFA).<br/>
<span id="more-16861"/></p>
<p>
The first <a href="https://rjlipton.wordpress.com/2020/03/21/star-free-regular-languages-and-logic/">post</a> in this series defined the classes <img alt="{\mathsf{SF}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{SF}}"/> for star-free regular and <img alt="{\mathsf{FO}[&lt;]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{FO}[&lt;]}"/> for first-order logic where variables <img alt="{u,v,w,\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%2Cw%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u,v,w,\dots}"/> range over the indices <img alt="{0,\dots,n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%2C%5Cdots%2Cn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0,\dots,n-1}"/> of a string <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. For any character <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/> in the alphabet <img alt="{\Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Sigma}"/> there is the predicate <img alt="{X_c(u)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_c%28u%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_c(u)}"/> saying that the character in position <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> equals <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/>. The first part proved that for any language <img alt="{A \in \mathsf{SF}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Cin+%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \in \mathsf{SF}}"/> there is a sentence <img alt="{\psi_A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi_A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\psi_A}"/> using only predicates <img alt="{X_c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_c}"/> and the relation <img alt="{u &lt; v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu+%3C+v%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u &lt; v}"/> besides the usual quantifiers and Boolean operations of first-order logic. such that <img alt="{\psi_A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi_A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\psi_A}"/> defined <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>. That is, it proved <img alt="{\mathsf{SF}\subseteq\mathsf{FO}[&lt;]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%5Csubseteq%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{SF}\subseteq\mathsf{FO}[&lt;]}"/>.</p>
<p>
A key trick was to focus not on <img alt="{\psi_A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi_A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\psi_A}"/> but on a formula <img alt="{\phi_A(i,j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_A%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi_A(i,j)}"/> expressing that the part of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> from position <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> (inclusive) to <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> (exclusive) belongs to <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>. To prove the converse direction, <img alt="{\mathsf{FO}[&lt;]\subseteq\mathsf{SF}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%5Csubseteq%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{FO}[&lt;]\subseteq\mathsf{SF}}"/>, we focus not on middles of strings but on prefixes and suffixes. The previous <a href="https://rjlipton.wordpress.com/2020/03/21/star-free-regular-languages-and-logic/">post</a> proved two lemmas showing that if <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L}"/> is star-free then for any string <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/>, so are its prefix and suffix languages: </p>
<p align="center"><img alt="\displaystyle  \begin{array}{rcl}  L\backslash y &amp;=&amp; \{z: yz \in L\}\\ L/y &amp;=&amp; \{x: xy \in L\}. \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++L%5Cbackslash+y+%26%3D%26+%5C%7Bz%3A+yz+%5Cin+L%5C%7D%5C%5C+L%2Fy+%26%3D%26+%5C%7Bx%3A+xy+%5Cin+L%5C%7D.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{rcl}  L\backslash y &amp;=&amp; \{z: yz \in L\}\\ L/y &amp;=&amp; \{x: xy \in L\}. \end{array} "/></p>
<p>We will piece together star-free expressions for a multitude of <img alt="{L/y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%2Fy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L/y}"/> and <img alt="{L \backslash y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL+%5Cbackslash+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L \backslash y}"/> sets that come from analyzing minimum DFAs <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> at each induction step, until we have built a big star-free expression <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> for <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>. This sounds complex—and is complex—but all the steps are elementary. At the end we’ll try to see how big <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> gets. <b>Again the rest of this post up to end notes is written by Daniel Winton</b>.</p>
<p>
</p><p>
</p><p/><h2> Stacked Words and FO Formulas </h2><p/>
<p/><p>
We implement the “marked words” idea of Perrin and Pin by using extra dimensions rather than marks. Consider any formula <img alt="{\phi(u_1, \dots, u_j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%28u_1%2C+%5Cdots%2C+u_j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi(u_1, \dots, u_j)}"/> in FO[<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>] where <img alt="{u_1,\dots,u_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu_1%2C%5Cdots%2Cu_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u_1,\dots,u_j}"/> are the free variables. Our "stacked words" have <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> extra rows underneath the top level holding the string <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>. Each row <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> has the same length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> as <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and contains a single <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> and <img alt="{(n-1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28n-1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(n-1)}"/> <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>s. The column <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> in which the <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> lies gives the value of the variable <img alt="{u_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u_i}"/>. Thus the alphabet of our stacked words is <img alt="{\Sigma^{(j)} = \Sigma\times\{0,1\}^j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%5E%7B%28j%29%7D+%3D+%5CSigma%5Ctimes%5C%7B0%2C1%5C%7D%5Ej%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Sigma^{(j)} = \Sigma\times\{0,1\}^j}"/>. Here is an example:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/stackedword/" rel="attachment wp-att-16865"><img alt="" class="aligncenter wp-image-16865" height="248" src="https://rjlipton.files.wordpress.com/2020/03/stackedword.jpg?w=242&amp;h=248" width="242"/></a></p>
<p/><p><br/>
Each column is really a single character <img alt="{C \in \Sigma^{(j)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%5Cin+%5CSigma%5E%7B%28j%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C \in \Sigma^{(j)}}"/>, but we picture its entries as characters in <img alt="{\Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Sigma}"/> or <img alt="{\{0,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{0,1\}}"/>. For any row <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, define <img alt="{Y_{i,0}(\cdot)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY_%7Bi%2C0%7D%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y_{i,0}(\cdot)}"/> to be the disjunction of <img alt="{X_C(\cdot)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_C%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_C(\cdot)}"/> over all <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> that have a <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> in entry <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, and define <img alt="{Y_{i,1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY_%7Bi%2C1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y_{i,1}}"/> similarly. Then the following sentence expresses the “format condition” that row <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> has exactly one <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>: </p>
<p align="center"><img alt="\displaystyle  (\exists k)[Y_{i,1}(k) \land (\forall \ell) [\ell \neq k \rightarrow Y_{i,0}(k)]]. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28%5Cexists+k%29%5BY_%7Bi%2C1%7D%28k%29+%5Cland+%28%5Cforall+%5Cell%29+%5B%5Cell+%5Cneq+k+%5Crightarrow+Y_%7Bi%2C0%7D%28k%29%5D%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (\exists k)[Y_{i,1}(k) \land (\forall \ell) [\ell \neq k \rightarrow Y_{i,0}(k)]]. "/></p>
<p>This readily transforms into a star-free expression for the language of stacked words with exactly one <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> in row <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>: </p>
<p align="center"><img alt="\displaystyle  \alpha_i = C_{i,0}^* C_{i,1} C_{i,0}^*, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Calpha_i+%3D+C_%7Bi%2C0%7D%5E%2A+C_%7Bi%2C1%7D+C_%7Bi%2C0%7D%5E%2A%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \alpha_i = C_{i,0}^* C_{i,1} C_{i,0}^*, "/></p>
<p>Here <img alt="{C_{i,0}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bi%2C0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{i,0}}"/> is the union of all stacked characters that have a <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> in entry <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, and <img alt="{C_{i,1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bi%2C1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{i,1}}"/> is similarly defined. This is where the examples in the previous <a href="https://rjlipton.wordpress.com/2020/03/21/star-free-regular-languages-and-logic/">post</a> about finite unions inside stars come in handy. The upshot is that </p>
<p align="center"><img alt="\displaystyle  \alpha_0 = \bigcap_{i=1}^j \alpha_i " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Calpha_0+%3D+%5Cbigcap_%7Bi%3D1%7D%5Ej+%5Calpha_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \alpha_0 = \bigcap_{i=1}^j \alpha_i "/></p>
<p>is a <img alt="{\mathsf{SF}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{SF}}"/> expression that enforces the “format condition” over all rows. We will use this at the crux of the proof; whether <img alt="{\alpha_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha_0}"/> is really needed is a question at the end. If we take the format for granted, then the main advantage of our stacked words will be visualizing how to decompose automata according to when the <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> in a critical row is read.</p>
<p>
</p><p/><h2> From FO To SF </h2><p/>
<p/><p>
The proof manipulates formulas <img alt="{\phi(u_1,\dots,u_j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%28u_1%2C%5Cdots%2Cu_j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi(u_1,\dots,u_j)}"/> having the <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> free variables shown. The corresponding language <img alt="{L_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\phi}"/> is the set of stacked words that make <img alt="{\phi(k_1,\dots,k_j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%28k_1%2C%5Cdots%2Ck_j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi(k_1,\dots,k_j)}"/> true, where for each <img alt="{i \leq j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%5Cleq+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i \leq j}"/>, <img alt="{k_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k_i}"/> is the position of the lone <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> in row <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, which gives the value of <img alt="{u_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u_i}"/>. </p>
<blockquote><p><b>Theorem 1</b> <em> For all formulas <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\phi}"/> over <img alt="{\mathsf{FO}[&lt;]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{FO}[&lt;]}"/>, <img alt="{L_\phi\in\mathsf{SF}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%5Cin%5Cmathsf%7BSF%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{L_\phi\in\mathsf{SF}}"/>. </em>
</p></blockquote>
<p/><p>
Without loss of generality we may suppose <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> is in <em>prenex form</em>, meaning that it has all quantifiers out front. If there are <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> variables of which <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> are free, this means </p>
<p align="center"><img alt="\displaystyle  \phi = (Q_{j+1} u_{j+1})\cdots (Q_r u_r)\mu, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cphi+%3D+%28Q_%7Bj%2B1%7D+u_%7Bj%2B1%7D%29%5Ccdots+%28Q_r+u_r%29%5Cmu%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \phi = (Q_{j+1} u_{j+1})\cdots (Q_r u_r)\mu, "/></p>
<p>where each <img alt="{Q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_i}"/> is <img alt="{\forall}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cforall%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\forall}"/> or <img alt="{\exists}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cexists%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\exists}"/> and <img alt="{\mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu}"/> has no quantifiers. If we picture the variables <img alt="{u_1,\dots,u_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu_1%2C%5Cdots%2Cu_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u_1,\dots,u_j}"/> as once having had quantifiers <img alt="{Q_1,\dots,Q_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_1%2C%5Cdots%2CQ_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_1,\dots,Q_j}"/>, then the proof—after dealing with <img alt="{\mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu}"/>—restores them one at a time, beginning with <img alt="{Q_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_j}"/>. That is the induction. We prove the base case <img alt="{\mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu}"/> here and the induction case in the coming sections.</p>
<p>
<em>Proof:</em>  Quantifier free formulas in <img alt="{\mathsf{FO}[&lt;]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{FO}[&lt;]}"/> are Boolean combinations of the <em>atomic predicates</em> <img alt="{X_c(u_i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_c%28u_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_c(u_i)}"/> and <img alt="{u_h &lt; u_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu_h+%3C+u_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u_h &lt; u_i}"/>. Here <img alt="{X_c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_c}"/> is only for the characters <img alt="{c \in \Sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc+%5Cin+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c \in \Sigma}"/>, not the stacked characters <img alt="{C \in \Sigma^{(j)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%5Cin+%5CSigma%5E%7B%28j%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C \in \Sigma^{(j)}}"/>. But inside <img alt="{\mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu}"/> (when we have <img alt="{j = r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj+%3D+r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j = r}"/>) we have to deal with the whole stack to represent <img alt="{X_c(u_i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_c%28u_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_c(u_i)}"/>. Putting <img alt="{\Sigma = \{c_1,\dots,c_{\ell}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CSigma+%3D+%5C%7Bc_1%2C%5Cdots%2Cc_%7B%5Cell%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Sigma = \{c_1,\dots,c_{\ell}\}}"/>, the expression can be viewed schematically as:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/xcstackedexp/" rel="attachment wp-att-16867"><img alt="" class="aligncenter size-large wp-image-16867" height="126" src="https://rjlipton.files.wordpress.com/2020/03/xcstackedexp.jpg?w=600&amp;h=126" width="600"/></a></p>
<p/><p><br/>
As illustrated above, using the initial lemma in the part-1 <a href="https://rjlipton.wordpress.com/2020/03/21/star-free-regular-languages-and-logic/">post</a>, this is equivalent to a star-free regular expression. The other atomic predicate, <img alt="{u_h &lt; u_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu_h+%3C+u_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u_h &lt; u_i}"/>, is true when we have a stacked word <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> of the form: </p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/ltstackedword2/" rel="attachment wp-att-16891"><img alt="" class="aligncenter wp-image-16891" height="250" src="https://rjlipton.files.wordpress.com/2020/03/ltstackedword2.jpg?w=300&amp;h=250" width="300"/></a></p>
<p/><p><br/>
It is not important to have <img alt="{h &lt; i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh+%3C+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h &lt; i}"/>; these are just the labels of the variables. Their values <img alt="{k_1,k_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk_1%2Ck_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k_1,k_2}"/> must obey <img alt="{k_1 &lt; k_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk_1+%3C+k_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k_1 &lt; k_2}"/>, meaning that the <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> in row <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h}"/> comes in an earlier column than the <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> in row <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>. The characters of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> in the top row are immaterial. We can capture this condition over all strings <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> over <img alt="{\Sigma^{(j)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%5E%7B%28j%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Sigma^{(j)}}"/> by the expression:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/ltstackedexp/" rel="attachment wp-att-16872"><img alt="" class="aligncenter size-large wp-image-16872" height="212" src="https://rjlipton.files.wordpress.com/2020/03/ltstackedexp.jpg?w=600&amp;h=212" width="600"/></a></p>
<p/><p><br/>
Again by the lemma in Part 1, this yields a star-free expression. To complete the basis, we note that if <img alt="{L_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_1}"/> and <img alt="{L_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_2}"/> have star-free expressions <img alt="{\alpha_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha_1}"/> and <img alt="{\alpha_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha_2}"/> corresponding to <img alt="{\phi_1, \phi_2\in \mathsf{FO}[&lt;]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_1%2C+%5Cphi_2%5Cin+%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi_1, \phi_2\in \mathsf{FO}[&lt;]}"/>, then <img alt="{\lnot\phi_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clnot%5Cphi_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lnot\phi_1}"/> is represented by <img alt="{\sim{\alpha_1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csim%7B%5Calpha_1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sim{\alpha_1}}"/> and <img alt="{\phi_1\lor\phi_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_1%5Clor%5Cphi_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi_1\lor\phi_2}"/> by <img alt="{\alpha_1\cup\alpha_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_1%5Ccup%5Calpha_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha_1\cup\alpha_2}"/>, both of which are clearly star-free. </p>
<p>
</p><p/><h2> Strategy For the Induction Case </h2><p/>
<p/><p>
Assume that all formulas in <img alt="{\mathsf{FO}[&lt;]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{FO}[&lt;]}"/> with <img alt="{\ell = r - j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%3D+r+-+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell = r - j}"/> quantifiers have star-free translations. We will show that any formula in <img alt="{\mathsf{FO}[&lt;]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{FO}[&lt;]}"/> with <img alt="{\ell+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell+1}"/> quantifiers also has a star-free translation. Let <img alt="{\psi(u_1,... ,u_{j-1})=\exists u_j \phi(u_1,..., u_j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%28u_1%2C...+%2Cu_%7Bj-1%7D%29%3D%5Cexists+u_j+%5Cphi%28u_1%2C...%2C+u_j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\psi(u_1,... ,u_{j-1})=\exists u_j \phi(u_1,..., u_j)}"/> where <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> is a formula in <img alt="{\mathsf{FO}[&lt;]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{FO}[&lt;]}"/> that has <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> total variables, <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> free variables and <img alt="{m-j=\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm-j%3D%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m-j=\ell}"/> quantifiers. We are allowed to assume the first quantifier in <img alt="{\psi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\psi}"/> is existential as <img alt="{\exists \equiv \lnot (\forall \lnot)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cexists+%5Cequiv+%5Clnot+%28%5Cforall+%5Clnot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\exists \equiv \lnot (\forall \lnot)}"/> and we observed above that the star-free expressible formulas in <img alt="{\mathsf{FO}[&lt;]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{FO}[&lt;]}"/> are closed under negation. </p>
<p>
The language of <img alt="{\psi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\psi}"/> is given by: </p>
<p>
<img alt="{L_\psi=\{z\in(\Sigma\times \{0,1\}^{j-1})^*:}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cpsi%3D%5C%7Bz%5Cin%28%5CSigma%5Ctimes+%5C%7B0%2C1%5C%7D%5E%7Bj-1%7D%29%5E%2A%3A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\psi=\{z\in(\Sigma\times \{0,1\}^{j-1})^*:}"/> we can add a <img alt="{{(j+1)}^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%28j%2B1%29%7D%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{(j+1)}^{th}}"/> row to each of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> characters of <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/> using <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> minus one <img alt="{0'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0'}"/>s and one <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> such that the resulting string <img alt="{z'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z'}"/> belongs to <img alt="{L_\phi\}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%5C%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\phi\}.}"/> </p>
<p>We must show that <img alt="{L_\psi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\psi}"/> is star-free. As <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> has <img alt="{\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell}"/> quantifiers, then by assumption <img alt="{L_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\phi}"/> is star-free regular. </p>
<p>
Note that <img alt="{L_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\phi}"/> has one more row than <img alt="{L_\psi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\psi}"/> because it has one more free variable. Without loss of generality we may suppose it is the bottom row. </p>
<p>
</p><p/><h3> The Tricky Point </h3><p/>
<p/><p>
Since we have an existential quantifier we might think we can simply delete the last row of <img alt="{L_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\phi}"/>. But here is a counterexample to show why we must be careful not to “lose information”:</p>
<p>
Let <img alt="{\alpha=}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha=}"/> </p>
<p>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/alphastackedexp/" rel="attachment wp-att-16875"><img alt="" class="aligncenter size-large wp-image-16875" height="56" src="https://rjlipton.files.wordpress.com/2020/03/alphastackedexp.jpg?w=600&amp;h=56" width="600"/></a></p>
<p>
and <img alt="{\alpha'=}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%27%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha'=}"/> </p>
<p>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/alphaprime/" rel="attachment wp-att-16876"><img alt="" class="aligncenter size-large wp-image-16876" height="43" src="https://rjlipton.files.wordpress.com/2020/03/alphaprime.jpg?w=600&amp;h=43" width="600"/></a></p>
<p>
Notice that <img alt="{\alpha'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha'}"/> equals <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> with its final row removed. We have <img alt="{L_\alpha=}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Calpha%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\alpha=}"/></p>
<p>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/lalpha/" rel="attachment wp-att-16878"><img alt="" class="aligncenter wp-image-16878" height="44" src="https://rjlipton.files.wordpress.com/2020/03/lalpha.jpg?w=357&amp;h=44" width="357"/></a></p>
<p>
and <img alt="{L_{\alpha'}=}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7B%5Calpha%27%7D%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{\alpha'}=}"/></p>
<p>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/lalphaprime/" rel="attachment wp-att-16880"><img alt="" class="aligncenter wp-image-16880" height="44" src="https://rjlipton.files.wordpress.com/2020/03/lalphaprime.jpg?w=300&amp;h=44" width="300"/></a></p>
<p/><p><br/>
Then <img alt="{L_\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\alpha}"/> is the language of strings with at least three zeroes in a row and <img alt="{L_{\alpha'}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7B%5Calpha%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{\alpha'}}"/> is the language of strings with at least two zeroes in a row.</p>
<p>
We cannot add a second row consisting of zeroes and one 1 to each word <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> in <img alt="{L_\alpha'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Calpha%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\alpha'}"/> to force <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> to be in <img alt="{L_\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\alpha}"/>. For a trivial example, consider the word <img alt="{w=}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w=}"/></p>
<p>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/w00/" rel="attachment wp-att-16881"><img alt="" class="aligncenter wp-image-16881" height="36" src="https://rjlipton.files.wordpress.com/2020/03/w00.jpg?w=75&amp;h=36" width="75"/></a></p>
<p/><p/>
<p>
The fault can be interpreted as <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> not being recoverable uniquely from <img alt="{\alpha'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha'}"/> owing to a loss of information. We could also pin the fault in this case on the central <img alt="{\cap}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ccap%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\cap}"/>, noting that <img alt="{(\exists u)(f(u) \wedge g(u))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cexists+u%29%28f%28u%29+%5Cwedge+g%28u%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\exists u)(f(u) \wedge g(u))}"/> is generally not equivalent to <img alt="{(\exists u)f(u) \wedge (\exists u)g(u)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cexists+u%29f%28u%29+%5Cwedge+%28%5Cexists+u%29g%28u%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\exists u)f(u) \wedge (\exists u)g(u)}"/>. </p>
<p>
Either way, this means we must be careful with how we express (the final row of) <img alt="{L_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\phi}"/>. The idea is to give <img alt="{L_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\phi}"/> in segments such that the final row of each segment is all-zero or a single <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>, so that the act of removing the final row could be inverted. This is the crux of the proof. To handle it we employ the unique DFA for the regular expression already obtained by induction for <img alt="{L_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\phi}"/>. </p>
<p>
</p><p/><h2> Main Part of the Proof </h2><p/>
<p/><p>
By the Myhill-Nerode Theorem, there must exist a unique minimal automaton <img alt="{M_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M_\phi}"/> over the alphabet of our stacked words defining the language <img alt="{L_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\phi}"/> of <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/>. </p>
<p>
The state set <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> of <img alt="{M_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M_\phi}"/> can be partitioned into the set <img alt="{Q_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_1}"/> of states before any <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> is read in the final row, the set <img alt="{Q_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_2}"/> of states reached after reading a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> in the final row, plus a dead state <img alt="{q_D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_D}"/> belonging to neither <img alt="{Q_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_1}"/> nor <img alt="{Q_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_2}"/>. The start state belongs to <img alt="{Q_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_1}"/> and all accepting states belong to <img alt="{Q_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_2}"/>. Since any stacked word and therefore accepting computation has exactly one <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> in any row, all arcs within <img alt="{Q_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_1}"/> and <img alt="{Q_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_2}"/> must have a only <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>s in their final row, while the letters connecting states in <img alt="{Q_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_1}"/> and <img alt="{Q_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_2}"/> must have a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> in their final row. The minimality of <img alt="{M_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M_\phi}"/> enforces these properties. Here is a sketch, omitting <img alt="{q_D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_D}"/>: </p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/lphidfa/" rel="attachment wp-att-16883"><img alt="" class="aligncenter size-large wp-image-16883" height="324" src="https://rjlipton.files.wordpress.com/2020/03/lphidfa.jpg?w=600&amp;h=324" width="600"/></a></p>
<p/><p><br/>
Let <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/> be the set of edges that cross from <img alt="{Q_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_1}"/> to <img alt="{Q_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_2}"/>. With <img alt="{m = |E|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+%7CE%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = |E|}"/> we can label their origins by states <img alt="{p_1,\dots,p_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_1%2C%5Cdots%2Cp_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_1,\dots,p_m}"/> (not necessarily all distinct), and similarly label their characters by <img alt="{c_1,\dots,c_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_1%2C%5Cdots%2Cc_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_1,\dots,c_m}"/> and the destination states by <img alt="{r_1,\dots,r_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br_1%2C%5Cdots%2Cr_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r_1,\dots,r_m}"/>. Then <img alt="{C = \{c_1,\dots,c_m\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%3D+%5C%7Bc_1%2C%5Cdots%2Cc_m%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C = \{c_1,\dots,c_m\}}"/> collects all the characters used by <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> that have a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> in row <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> (except those into or at the dead state <img alt="{q_D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_D}"/>). We can identify <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/> with the set of instructions <img alt="{\{(p_e, c_e, r_e): 1 \leq e \leq m\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%28p_e%2C+c_e%2C+r_e%29%3A+1+%5Cleq+e+%5Cleq+m%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{(p_e, c_e, r_e): 1 \leq e \leq m\}}"/>. </p>
<p>
Finally let <img alt="{L_{p,q}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bp%2Cq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{p,q}}"/> denote the set of strings that take <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> from state <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> to state <img alt="{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q}"/>, and let <img alt="{L_{r,F} = \cup_{f \in F} L_{r,f}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Br%2CF%7D+%3D+%5Ccup_%7Bf+%5Cin+F%7D+L_%7Br%2Cf%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{r,F} = \cup_{f \in F} L_{r,f}}"/>. Then we can define <img alt="{L_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\phi}"/> by the expression <a name="expansion"/></p><a name="expansion">
<p align="center"><img alt="\displaystyle  L_\phi =\bigcup_{(p_e, c_e, r_e)\in E} L_{s,p_e}\cdot c_e \cdot L_{r_e,F}. \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++L_%5Cphi+%3D%5Cbigcup_%7B%28p_e%2C+c_e%2C+r_e%29%5Cin+E%7D+L_%7Bs%2Cp_e%7D%5Ccdot+c_e+%5Ccdot+L_%7Br_e%2CF%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  L_\phi =\bigcup_{(p_e, c_e, r_e)\in E} L_{s,p_e}\cdot c_e \cdot L_{r_e,F}. \ \ \ \ \ (1)"/></p>
</a><p><a name="expansion"/> What remains is to find <img alt="{\mathsf{SF}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{SF}}"/> expressions for <img alt="{L_{s,p_e}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_e%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{s,p_e}}"/> and <img alt="{L_{r_e,F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Br_e%2CF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{r_e,F}}"/> for each <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e}"/>. The latter is easy: Pick any string <img alt="{y_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y_e}"/> in <img alt="{L_{s,p_e}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_e%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{s,p_e}}"/>. Then </p>
<p align="center"><img alt="\displaystyle  L_{r_e,F} = \{z: y_e\cdot c_e \cdot z \in L(M)\} = L_{\phi} \backslash y_e c_e. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++L_%7Br_e%2CF%7D+%3D+%5C%7Bz%3A+y_e%5Ccdot+c_e+%5Ccdot+z+%5Cin+L%28M%29%5C%7D+%3D+L_%7B%5Cphi%7D+%5Cbackslash+y_e+c_e.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  L_{r_e,F} = \{z: y_e\cdot c_e \cdot z \in L(M)\} = L_{\phi} \backslash y_e c_e. "/></p>
<p>The closure of <img alt="{\mathsf{SF}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{SF}}"/> under left quotients supplies expressions <img alt="{\beta_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta_e}"/> for <img alt="{L_{r_e,F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Br_e%2CF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{r_e,F}}"/>. </p>
<p>
The case of <img alt="{L_{s,p_e}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_e%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{s,p_e}}"/>, however, is harder. What we would like to do is choose some (any) string <img alt="{w_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w_e}"/> that goes from <img alt="{r_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r_e}"/> to an accepting state and claim that <img alt="{L_{s,p_e} = L(M)/c_e w_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_e%7D+%3D+L%28M%29%2Fc_e+w_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{s,p_e} = L(M)/c_e w_e}"/>. The problem is that <img alt="{w_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w_e}"/> might be accepted from some state <img alt="{r_d \neq r_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br_d+%5Cneq+r_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r_d \neq r_e}"/> that has an incoming arc on the same character <img alt="{c_d = c_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_d+%3D+c_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_d = c_e}"/> from some other state <img alt="{p_d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_d}"/>. Then <img alt="{L_{s,p_d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_d%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{s,p_d}}"/>, which is disjoint from <img alt="{L_{s,p_e}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_e%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{s,p_e}}"/>, is included also in <img alt="{L(M)/c_e w_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%28M%29%2Fc_e+w_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L(M)/c_e w_e}"/>. There may, however, be strings <img alt="{y_d \in L_{s,p_d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By_d+%5Cin+L_%7Bs%2Cp_d%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y_d \in L_{s,p_d}}"/> and <img alt="{w'_e \in L_{r_e,F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%27_e+%5Cin+L_%7Br_e%2CF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w'_e \in L_{r_e,F}}"/> such that <img alt="{y = y_d c_e w'_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By+%3D+y_d+c_e+w%27_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y = y_d c_e w'_e}"/> is <b>not</b> accepted by <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/>. Then the string <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> would be wrongly included if we substituted <img alt="{L(M)/c_e z_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%28M%29%2Fc_e+z_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L(M)/c_e z_e}"/> for <img alt="{L_{s,p_e}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_e%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{s,p_e}}"/> (or for <img alt="{L_{s,p_e} \cup L_{s,p_d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_e%7D+%5Ccup+L_%7Bs%2Cp_d%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{s,p_e} \cup L_{s,p_d}}"/>) in (1). </p>
<p>
There is also a second issue when crossing edges on the same character <img alt="{c_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_e}"/> come in from distinct states <img alt="{p_d,p_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_d%2Cp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_d,p_e}"/> to the same state <img alt="{r_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r_e}"/>. To fix all this, we need to use sets of strings that distinguish <img alt="{p_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_e}"/> from all the other states <img alt="{p_d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_d}"/>. This requires the most particular use of the minimality of <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/>: If <img alt="{p_d \neq p_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_d+%5Cneq+p_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_d \neq p_e}"/>, then there is either (or both):</p>
<ul>
<li>
a string <img alt="{z_{e,d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz_%7Be%2Cd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z_{e,d}}"/> in <img alt="{L_{p_e,F} - L_{p_d,F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bp_e%2CF%7D+-+L_%7Bp_d%2CF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{p_e,F} - L_{p_d,F}}"/>, or <p/>
</li><li>
a string <img alt="{z_{d,e}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz_%7Bd%2Ce%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z_{d,e}}"/> in <img alt="{L_{p_d,F} - L_{p_e,F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bp_d%2CF%7D+-+L_%7Bp_e%2CF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{p_d,F} - L_{p_e,F}}"/>.
</li></ul>
<p>
The strings in question need not begin with a character in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>—they need not cross right away. Let <img alt="{Z_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z_e}"/> stand for a choice of strings of the former kind, <img alt="{Z'_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%27_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z'_e}"/> the latter kind, covering all states <img alt="{p_d \neq p_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_d+%5Cneq+p_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_d \neq p_e}"/>. Then <a name="distinct"/></p><a name="distinct">
<p align="center"><img alt="\displaystyle  L_{s,p_e} = \left(\bigcap_{z \in Z_e} L_{\phi}/z\right) \cap \left(\bigcap_{z' \in Z'_e} (\alpha_0 \cap \tilde{L}_{\phi})/z'\right). \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++L_%7Bs%2Cp_e%7D+%3D+%5Cleft%28%5Cbigcap_%7Bz+%5Cin+Z_e%7D+L_%7B%5Cphi%7D%2Fz%5Cright%29+%5Ccap+%5Cleft%28%5Cbigcap_%7Bz%27+%5Cin+Z%27_e%7D+%28%5Calpha_0+%5Ccap+%5Ctilde%7BL%7D_%7B%5Cphi%7D%29%2Fz%27%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  L_{s,p_e} = \left(\bigcap_{z \in Z_e} L_{\phi}/z\right) \cap \left(\bigcap_{z' \in Z'_e} (\alpha_0 \cap \tilde{L}_{\phi})/z'\right). \ \ \ \ \ (2)"/></p>
</a><p><a name="distinct"/> We could not use just the complement <img alt="{\tilde{L}_{\phi}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BL%7D_%7B%5Cphi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde{L}_{\phi}}"/> of <img alt="{L_{\phi}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7B%5Cphi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{\phi}}"/> because that would allow strings that violate the “one <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>” condition in the rows. Note that <img alt="{\alpha_0 \cap \tilde{L}_{\phi} = L_{\neg\phi}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_0+%5Ccap+%5Ctilde%7BL%7D_%7B%5Cphi%7D+%3D+L_%7B%5Cneg%5Cphi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha_0 \cap \tilde{L}_{\phi} = L_{\neg\phi}}"/>. Whether one can do the induction for <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> and <img alt="{\neg\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneg%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neg\phi}"/> in tandem without invoking <img alt="{\alpha_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha_0}"/> is a riddle we pose at the end. </p>
<p>
Either way, the closure of <img alt="{\mathsf{SF}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{SF}}"/> under right quotients yields a star-free expression <img alt="{\alpha_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha_e}"/> for <img alt="{L_{s,p_e}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_e%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{s,p_e}}"/>. Then we just have to plug our expressions <img alt="{\alpha_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha_e}"/> and <img alt="{\beta_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta_e}"/> into (1) to get a star-free expression <img alt="{\beta_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta_\phi}"/> for <img alt="{L_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\phi}"/>. Now we are ready for the crude final step:</p>
<blockquote><p><b> </b> <em> Form <img alt="{\beta'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%27%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\beta'}"/> by knocking out the last entry in every character occurring in <img alt="{\beta_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta_%5Cphi%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\beta_\phi}"/>. Then <img alt="{\beta'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%27%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\beta'}"/> represents <img alt="{L_{\psi}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7B%5Cpsi%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{L_{\psi}}"/>. </em>
</p></blockquote>
<p/><p>
To prove this final statement, first suppose <img alt="{w'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w'}"/> is a stacked word in <img alt="{L_\psi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\psi}"/>. Then <img alt="{w'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w'}"/> satisfies <img alt="{(\exists u)\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cexists+u%29%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\exists u)\phi}"/>, so there is a value <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> so that <img alt="{w'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w'}"/> satisfies <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> with <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> set equal to the value <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>. This means that the stacked word <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> formed from <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> and a last row with <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> in position <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> belongs to <img alt="{L_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_\phi}"/> and hence matches <img alt="{\beta_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta_\phi}"/>. Since <img alt="{w'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w'}"/> is obtained by knocking out the last row of <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/>, <img alt="{w'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w'}"/> matches <img alt="{\beta'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta'}"/>. </p>
<p>
The converse is the part where the tricky point we noted at the outset could trip us up. Suppose <img alt="{w'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w'}"/> matches <img alt="{\beta'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta'}"/>. From the form of (1) as a union of terms <img alt="{\alpha_e c_e \beta_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_e+c_e+%5Cbeta_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha_e c_e \beta_e}"/>, we can trace how <img alt="{w'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w'}"/> is matched to identify a place in <img alt="{w'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w'}"/> that matches a “middle character” <img alt="{c'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c'}"/> obtained from a <img alt="{c_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_e}"/> in a crossing edge. Putting a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> in a new row underneath this place and <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>s elsewhere hence makes a word <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> that matches the unique regular expression <img alt="{\beta''}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta''}"/> obtained by appending a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> component to every “middle character” <img alt="{c'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c'}"/> and a <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> to all other characters in <img alt="{\beta'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta'}"/>. Then <img alt="{\beta''}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta''}"/> is equivalent to <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/>, so <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> satisfies <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/>. Since the last row that was added to <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> amounts to supplying a value <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> for the variable <img alt="{u_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u_j}"/>, it follows that <img alt="{w'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w'}"/> satisfies <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi}"/> with <img alt="{u_j = k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu_j+%3D+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u_j = k}"/>, hence satisfies <img alt="{\psi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\psi}"/>. This yields <img alt="{L(\beta') = L_{\psi}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%28%5Cbeta%27%29+%3D+L_%7B%5Cpsi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L(\beta') = L_{\psi}}"/> and so the entire induction goes through. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
First, as an end note, the end of the proof wound up different from what we envisioned until polishing this post. It originally applied the distinct-states argument to states <img alt="{r_d,r_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br_d%2Cr_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r_d,r_e}"/> on the far side of the crossing, but we had to backtrack on having previously thought that the “second issue” did not matter. Two other questions we pose for our readers:</p>
<ul>
<li>
Do the definitions of <img alt="{Z_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z_e}"/> and <img alt="{Z'_e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%27_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z'_e}"/> need to extend over all states <img alt="{p \in Q_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%5Cin+Q_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p \in Q_1}"/>, not just the other states <img alt="{p_d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_d}"/> on the border? <p/>
</li><li>
Is <img alt="{\alpha_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha_0}"/> needed in (2), or in the proof overall?
</li></ul>
<p>
A larger question concerns how the size of the translated expressions increases as we add more quantifiers. We discuss the blowup in terms of quantifier depth <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> and length <img alt="{n=|x|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D%7Cx%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=|x|}"/>. Let <img alt="{\psi_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\psi_0}"/> be a first-order formula with no quantifiers and let <img alt="{\psi_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\psi_m}"/> denote <img alt="{\psi_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\psi_0}"/> with <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> quantifiers applied to it. Also let <img alt="{\alpha_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha_m}"/> be a star-free translation of <img alt="{\psi_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\psi_m}"/> and the length of <img alt="{\alpha_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha_0}"/>, denoted by len<img alt="{(\alpha_0)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Calpha_0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\alpha_0)}"/>, equal <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. </p>
<p>
To obtain <img alt="{\alpha_{1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_%7B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha_{1}}"/> from <img alt="{\alpha_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha_0}"/> we represent <img alt="{\alpha_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha_0}"/> by a union over crossing edges between <img alt="{Q_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_1}"/> and <img alt="{Q_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_2}"/> and the final states of <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> of the concatenation of prefix and suffix languages and a crossing character between them. We have that <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> gives a decent approximation for—worst-case—length of the prefix languages, suffix languages and the product of crossing edges and final states. Using these approximations we have <img alt="{\mathit{len}(\alpha_1)\approx(2n+1)(n)\approx n^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathit%7Blen%7D%28%5Calpha_1%29%5Capprox%282n%2B1%29%28n%29%5Capprox+n%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathit{len}(\alpha_1)\approx(2n+1)(n)\approx n^2}"/>. Iterating gives <img alt="{\mathit{len}(\alpha_2)\approx(2\mathit{len}(\alpha_1)+1)\mathit{len}(\alpha_1)\approx n^4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathit%7Blen%7D%28%5Calpha_2%29%5Capprox%282%5Cmathit%7Blen%7D%28%5Calpha_1%29%2B1%29%5Cmathit%7Blen%7D%28%5Calpha_1%29%5Capprox+n%5E4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathit{len}(\alpha_2)\approx(2\mathit{len}(\alpha_1)+1)\mathit{len}(\alpha_1)\approx n^4}"/>, <img alt="{\mathit{len}(\alpha_3)\approx n^8}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathit%7Blen%7D%28%5Calpha_3%29%5Capprox+n%5E8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathit{len}(\alpha_3)\approx n^8}"/>, and in general, <img alt="{\mathit{len}(\alpha_m)\approx ({n^{2^m}})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathit%7Blen%7D%28%5Calpha_m%29%5Capprox+%28%7Bn%5E%7B2%5Em%7D%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathit{len}(\alpha_m)\approx ({n^{2^m}})}"/>. This says that our blowup could be doubly exponential. Is there a tighter estimate?</p>
<p>
Our final question is: how well do our “stacked words” help to visualize the proof? Are they helpful for framing proofs of equivalences between language classes and logics that are higher up?</p>
<p/></font></font></div>
    </content>
    <updated>2020-03-29T19:40:03Z</updated>
    <published>2020-03-29T19:40:03Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="Proofs"/>
    <category term="Teaching"/>
    <category term="trick"/>
    <category term="Daniel Winton"/>
    <category term="descriptive complexity"/>
    <category term="Dominique Perrin"/>
    <category term="formal languages"/>
    <category term="Jean-Eric Pin"/>
    <category term="Logic"/>
    <category term="marked words"/>
    <category term="stacked words"/>
    <category term="star-free regular sets"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-04-04T19:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4346</id>
    <link href="https://lucatrevisan.wordpress.com/2020/03/29/4346/" rel="alternate" type="text/html"/>
    <title>Another dispatch from Milan</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">By virtue of being one or two weeks ahead of the rest of the Western world, Italy has been giving advance notices to other countries about what to expect in the covid19 epidemic. For this reason, friends from other countries … <a href="https://lucatrevisan.wordpress.com/2020/03/29/4346/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>By virtue of being one or two weeks ahead of the rest of the Western world, Italy has been giving advance notices to other countries about what to expect in the covid19 epidemic. For this reason, friends from other countries have been frequently asking me some questions, whose answers I would like to share.</p>
<p><span id="more-4346"/></p>
<p><b>Will lockdowns work in countries that are not big on rules-following?</b></p>
<p>Apparently, yes. The number of confirmed cases is not a very reliable signal of what is happening, because it is tied as much to the testing capacity as to the actual diffusion of the infection, while the number of deaths is a more informative one (although read below about some issues with how this number is reported). Schools were closed 34 days ago in Lombardy, which went on lockdown 21 days ago, and all of Italy went on lockdown 19 days ago. For the last several days there has been a slowing down in the number of reported deaths, and daily numbers have been decreasing for the last two days. This is a graph updated today of the cumulative number of deaths:</p>
<p><img alt="italy" class="alignnone size-full wp-image-4349" src="https://lucatrevisan.files.wordpress.com/2020/03/italy.png?w=584"/><br/>
(Data from Protezione Civile, chart by me)</p>
<p><b>How does this compare to other places?</b></p>
<p>This graph shows cumulative number of deaths in NYC and in Lombardy, which have a similar population, shifting the NYC data by 17 days:</p>
<p><img alt="lombardy-nyc" class="alignnone size-full wp-image-4350" src="https://lucatrevisan.files.wordpress.com/2020/03/lombardy-nyc.png?w=584"/><br/>
(Data from Protezione Civile and NYT, chart by me)</p>
<p>In Lombardy, schools were closed on February 24 (along with universities, museums, cinemas and several other places) and the lockdown started on March 8; in the shifted timeline, the New York lockdown started on March 3, so one should hope for an earlier slowdown and that NYC will do a lot better than Lombardy.</p>
<p><b>But how bad would things be without restrictive measures?</b></p>
<p>Some smaller towns in Lombardy, where the virus might have circulated for several weeks before the lockdown, have had substantial increases in all-cause deaths. These go from 4x the usual number over the last three months to 7x the usual number during the first three weeks of March. These excess deaths are more than the number of reported covid19 deaths from such towns, and this should be taken into account when looking at reported mortality in Lombardy. Already, the excess deaths in these small towns account for about 0.7% of the population, suggesting that worst-case scenarios of 2 million deaths in the US and of half a million in the UK without mitigation/containment measures made sense.</p>
<p><b>What’s it like after three weeks of lockdown?</b></p>
<p>The mood in the country seems to be shifting: after all  the singing from the balconies, and the baking of cakes, and the practicing of yoga and the posting on Instagram of all of the above, the mood is souring a bit. Unions and employers are at odds on when to reopen factories and many families are living on their savings and wondering how long they can manage to do so. People whose work relates to tourism and hospitality (which accounts for a  very large fraction of the country’s GDP) are wondering not just when  they will be able to reopen their business or return to their job, but if they will be able to do so.</p>
<p>Because of the way the Euro works, Italy cannot just decide to embark on a massive stimulus program. This is because each state’s budget deficit “creates” Euros, and so there is a common policy in the “Eurozone” that limits each state deficit-spending. While this is being negotiated, the Italian government has committed to 25 billions of extra spending, and there is already a big scramble to lobby for who and how should get various parts of this stimulus program.</p>
<p><b>What will it be like after the lockdown is lifted?</b></p>
<p>I am worried that there is no official plan for that. </p>
<p>I hope that there are lots of competent experts working in secret on a plan that takes the best of the contact-tracing and isolation strategies of Korea, Singapore and Taiwan, injects in it the strong tradition of privacy laws that (little known fact) Italy pioneered in Europe even before the GDPR, and creates a wonderfully functioning system.</p>
<p>Hey, once you are hoping, you may as well hope big!</p>
<p><b>What are good sources for predictions of future scenarios?</b></p>
<p>Memes! It has been mind-bending how yesterday’s satire becomes tomorrow’s news.</p>
<p>For example, this meme started circulating on March 14, in which Johnson says “because of the coronavirus, we should prepare to lose some of our loved ones,” to which the queen replies “I am sorry for you and your family.” Johnson tested positive two weeks later.</p>
<p><img alt="fullsizeoutput_18d8" class="alignnone size-full wp-image-4351" src="https://lucatrevisan.files.wordpress.com/2020/03/fullsizeoutput_18d8.jpeg?w=584"/></p>
<p>On March 15, the Pope visited a church in (a deserted) central Rome, where there is a crucifix that, according to tradition, survived unscathed a fire in 1519 and, in 1522, was taken around the city and stopped an epidemic of bubonic plague. The pope prayed for the end of the covid19 epidemic.</p>
<p>On March 24, Lercio, the Italian equivalent of The Onion, published an article titled <a href="https://www.lercio.it/forse-non-ha-capito-bene-papa-francesco-chiede-di-nuovo-a-dio-di-fermare-lepidemia/">“‘Maybe He didn’t hear me the first time’: Pope Francis asks God again to stop the epidemic”</a>.</p>
<p>Sure enough, on March 27 the Pope prayed again for the end of the epidemic, alone in a deserted Saint Peter square.</p>
<p><img alt="Pope Francis extraordinary Urbi et Orbi blessing during the coronavirus crisis" class="alignnone size-full wp-image-4352" src="https://lucatrevisan.files.wordpress.com/2020/03/8e6a2f2ff6542ea2870a1a4c13f6fd06.jpg?w=584"/><br/>
(Photo credit: Yara Nardi and Vatican Press Office)</p>
<p>The images of the pope walking alone at dusk toward the stage on which he prayed were something no disaster movie had prepared us for. Of course people were able to see the humor in that as well.</p>
<p><img alt="IMG_9423" class="alignnone size-full wp-image-4354" src="https://lucatrevisan.files.wordpress.com/2020/03/img_9423.jpg?w=584"/></p>
<p><b>Edited to add:</b> On March 13, The Onion published an article titled <a href="https://www.theonion.com/health-experts-worry-coronavirus-will-overwhelm-america-1842314132">Health Experts Worry Coronavirus Will Overwhelm America’s GoFundMe System</a>. On March 26, The New York Times published an article titled <a href="https://www.nytimes.com/2020/03/26/style/gofundme-coronavirus.html">GoFundMe Confronts Coronavirus Demand</a>.</p></div>
    </content>
    <updated>2020-03-29T18:27:41Z</updated>
    <published>2020-03-29T18:27:41Z</published>
    <category term="Milan"/>
    <category term="New York"/>
    <category term="covid-19"/>
    <category term="Pope Francis"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2020-04-04T19:20:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/03/29/postdoctoral-researchers-at-millennium-institute-for-foundational-research-on-data-imfd-chile-apply-by-january-7-2020/</id>
    <link href="https://cstheory-jobs.org/2020/03/29/postdoctoral-researchers-at-millennium-institute-for-foundational-research-on-data-imfd-chile-apply-by-january-7-2020/" rel="alternate" type="text/html"/>
    <title>Postdoctoral Researchers at Millennium Institute for Foundational Research on Data, IMFD Chile (apply by January 7, 2020)</title>
    <summary>The Millennium Institute for Foundational Research on Data (IMFD Chile, http://www.imfd.cl) offers a postdoc position to advance the understanding of theoretical aspects of neural network architectures, in particular, its expressive and computational power. The coordinators of this project are Professors Pablo Barceló (http://pbarcelo.ing.uc.cl/) and Jorge Pérez (https://users.dcc.uchile.cl/~jperez/). Website: https://docs.google.com/document/d/1PyHp-MRAPWg_0aeinpDGmzJGZbwMtsqC6BqE_4T3KFc/edit Email: pbarcelo@ing.puc.cl</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Millennium Institute for Foundational Research on Data (IMFD Chile, <a href="http://www.imfd.cl" rel="nofollow">http://www.imfd.cl</a>) offers a postdoc position to advance the understanding of theoretical aspects of neural network architectures, in particular, its expressive and computational power. The coordinators of this project are Professors Pablo Barceló (<a href="http://pbarcelo.ing.uc.cl/">http://pbarcelo.ing.uc.cl/</a>) and Jorge Pérez (<a href="https://users.dcc.uchile.cl/~jperez/">https://users.dcc.uchile.cl/~jperez/</a>).</p>
<p>Website: <a href="https://docs.google.com/document/d/1PyHp-MRAPWg_0aeinpDGmzJGZbwMtsqC6BqE_4T3KFc/edit">https://docs.google.com/document/d/1PyHp-MRAPWg_0aeinpDGmzJGZbwMtsqC6BqE_4T3KFc/edit</a><br/>
Email: pbarcelo@ing.puc.cl</p></div>
    </content>
    <updated>2020-03-29T16:18:42Z</updated>
    <published>2020-03-29T16:18:42Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-04-04T19:20:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/03/29/backyard-sunlight</id>
    <link href="https://11011110.github.io/blog/2020/03/29/backyard-sunlight.html" rel="alternate" type="text/html"/>
    <title>Backyard sunlight</title>
    <summary>A few photos from my garden:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A few photos from my garden:</p>

<div><table style="margin-left: auto; margin-right: auto;">
<tbody><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/backyard/CrissCrossShadow.html"><img alt="Criss cross shadow" src="http://www.ics.uci.edu/~eppstein/pix/backyard/CrissCrossShadow-m.jpg" style="border-style: solid; border-color: black;" width="315"/></a></td>
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/backyard/DiagonalRosemary.html"><img alt="Diagonal rosemary" src="http://www.ics.uci.edu/~eppstein/pix/backyard/DiagonalRosemary-m.jpg" style="border-style: solid; border-color: black;" width="378"/></a></td>
</tr><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/backyard/RockAndTreeShadow.html"><img alt="Rock and tree shadow" src="http://www.ics.uci.edu/~eppstein/pix/backyard/RockAndTreeShadow-m.jpg" style="border-style: solid; border-color: black;" width="350"/></a></td>
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/backyard/TruffulaTree.html"><img alt="Truffula tree" src="http://www.ics.uci.edu/~eppstein/pix/backyard/TruffulaTree-m.jpg" style="border-style: solid; border-color: black;" width="252"/></a></td>
</tr></tbody></table></div>

<p>(<a href="https://mathstodon.xyz/@11011110/103908517022371423">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-03-29T14:34:00Z</updated>
    <published>2020-03-29T14:34:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-04-01T04:49:01Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-03-29-private-set-intersection-a-soft-introduction/</id>
    <link href="https://decentralizedthoughts.github.io/2020-03-29-private-set-intersection-a-soft-introduction/" rel="alternate" type="text/html"/>
    <title>Private Set Intersection</title>
    <summary>Private Set Intersection (PSI) is a problem within the broader field of secure computation. The PSI problem There are two friends Alice and Bob such that Alice has a set of items $A=(a_1,\ldots,a_n)$ and Bob has the set $B=(b_1,\ldots,b_n)$. The goal is to design a protocol by which Alice and...</summary>
    <updated>2020-03-29T08:00:00Z</updated>
    <published>2020-03-29T08:00:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-04-03T23:47:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/041</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/041" rel="alternate" type="text/html"/>
    <title>TR20-041 |  A Polynomial Degree Bound on Defining Equations of Non-rigid Matrices and  Small Linear Circuits | 

	Mrinal Kumar, 

	Ben Lee Volk</title>
    <summary>We show that there is a defining equation of degree at most poly(n) for the (Zariski closure of the) set of the non-rigid matrices: that is, we show that for every large enough field $\mathbb{F}$, there is a non-zero $n^2$-variate polynomial $P \in \mathbb{F}(x_{1, 1}, \ldots, x_{n, n})$ of degree at most poly(n) such that  every matrix $M$ which can be written as a sum of a matrix of rank at most $n/100$ and sparsity at most $n^2/100$ satisfies $P(M) = 0$. This  confirms a conjecture of Gesmundo, Hauenstein, Ikenmeyer and Landsberg [GHIL16] and improves the best upper bound known for this problem down from $\exp(n^2)$ [KLPS14, GHIL16] to $poly(n)$. 

We also show a similar polynomial degree bound for the (Zariski closure of the) set of all matrices $M$ such that the linear transformation represented by $M$ can be computed by an algebraic circuit with at most  $n^2/200$ edges (without any restriction on the depth). As far as we are aware, no such bound was known prior to this work when the depth of the circuits is unbounded. 

Our methods are elementary and short and rely on a polynomial map of Shpilka and Volkovich [SV15] to construct low degree ``universal'' maps for non-rigid matrices and small linear circuits. Combining this construction with a simple dimension counting argument to show that any such polynomial map has a low degree annihilating polynomial completes the proof.</summary>
    <updated>2020-03-29T06:14:01Z</updated>
    <published>2020-03-29T06:14:01Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-04T19:20:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19560</id>
    <link href="https://gilkalai.wordpress.com/2020/03/29/game-theory-on-line-course-at-idc-herzliya/" rel="alternate" type="text/html"/>
    <title>Game Theory – on-line Course at IDC, Herzliya</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Game theory, a graduate course at IDC, Herzliya; Lecturer: Gil Kalai; TA: Einat Wigderson,  ZOOM mentor: Ethan. Starting Tuesday March 31, I am giving an on-line course (in Hebrew) on Game theory at IDC, Herzliya (IDC English site; IDC Chinese … <a href="https://gilkalai.wordpress.com/2020/03/29/game-theory-on-line-course-at-idc-herzliya/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h3>Game theory, a graduate course at IDC, Herzliya; Lecturer: Gil Kalai; TA: Einat Wigderson,  ZOOM mentor: Ethan.</h3>
<p>Starting Tuesday March 31, I am giving an on-line course (in Hebrew) on Game theory at <a href="https://www.idc.ac.il/he/pages/home.aspx">IDC, Herzliya</a> (<a href="https://www.idc.ac.il/en/pages/home.aspx">IDC English site</a>; <a href="https://www.idc.ac.il/chinese/pages/home.aspx">IDC Chinese site</a>).</p>
<p>In addition to the IDC moodle (course site) that allows IDC students to listen to recorded lectures, submit solutions to problem sets , etc., there will be a page here on the blog devoted to the course. Zoom link for the first meeting. <a href="https://idc-il.zoom.us/j/726950787" rel="nofollow">https://idc-il.zoom.us/j/726950787</a></p>
<p>A small memory: In 1970 there was a strike in Israelis’ high schools and I took a few classes at the university. One of these classes was Game theory and it was taught by <a href="https://gilkalai.wordpress.com/?s=Michael+Maschler">Michael Maschler</a>. (I also took that trimester a course on art taught by Ziva <span class="st"><span dir="ltr">Meisels</span></span>.) Our department at HUJI is very strong in game theory, but once all the “professional” game theorists retired, I gave twice a game theory course which I enjoyed a lot and it was well accepted by students. In term of the number of registered students, it seems that this year’s course at IDC is quite popular and I hope it will be successful.</p>
<h2>The first six slides of the first presentation</h2>
<p>(Click to enlarge)</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/gt1.png"><img alt="" class="alignnone size-medium wp-image-19661" height="225" src="https://gilkalai.files.wordpress.com/2020/03/gt1.png?w=300&amp;h=225" width="300"/></a></p>
<p>Game Theory 2020, games, decisions, competition, strategies, mechanisms, cooperation</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/gt2.png"><img alt="" class="alignnone size-medium wp-image-19662" height="131" src="https://gilkalai.files.wordpress.com/2020/03/gt2.png?w=300&amp;h=131" width="300"/></a></p>
<p>The course deals with basic notions, central mathematical results, and important examples in non-cooperative game theory and in cooperative game theory, and with connections of game theory with computer science, economics and other areas.</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/gt3.png"><img alt="" class="alignnone size-medium wp-image-19663" height="226" src="https://gilkalai.files.wordpress.com/2020/03/gt3.png?w=300&amp;h=226" width="300"/></a></p>
<p>What we will learn</p>
<p>1. Full information zero-sum games. The value of a game. Combinatorial games.</p>
<p>2. Zero-sum games with incomplete information. Mixed strategies, the Minmax Theorem and the value of the game.</p>
<p>3. Non cooperative games, the prisoner dilemma, Nash equilibrium, Nash’s theorem on the existence of equilibrium.</p>
<p>4. Cooperative games, the core and the Shapley value. Nash bargaining problem, voting rules and social choice.</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/gt4.png"><img alt="" class="alignnone size-medium wp-image-19664" height="225" src="https://gilkalai.files.wordpress.com/2020/03/gt4.png?w=300&amp;h=225" width="300"/></a></p>
<p>Background material:</p>
<p><a href="https://homes.cs.washington.edu/~karlin/GameTheoryBook.pdf">Game theory alive</a> by Anna Karlin and Yuval Peres (available on-line).</p>
<p>In addition I may use material from several books in Hebrew by Maschler, Solan, Zamir, by Hefetz, and by Megiddo (based on lectures by Peleg). (If only I will manage to unite with my books that are not here.) We will also use a site by Ariel Rubinstein for playing games and some material from the book by Osborne and Rubinstein.</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/gt5.png"><img alt="" class="alignnone size-medium wp-image-19665" height="226" src="https://gilkalai.files.wordpress.com/2020/03/gt5.png?w=300&amp;h=226" width="300"/></a></p>
<p>Requirement and challenges:</p>
<ul>
<li><strong>Play, play, play games</strong>, in Ariel Rubinshtein site and various other games.</li>
<li>Solve 10 short theoretical problem set.</li>
<li>Final assignment, including some programming project that can be carried out during the semester.</li>
<li>Of course, we will experience on-line study which is a huge challenge for us all.</li>
</ul>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/gt6.png"><img alt="" class="alignnone size-medium wp-image-19667" height="226" src="https://gilkalai.files.wordpress.com/2020/03/gt6.png?w=300&amp;h=226" width="300"/></a></p>
<p>Games and computers</p>
<ul>
<li>Computer games</li>
<li>Algorithms for playing games</li>
<li>algorithmic game theory:
<ul>
<li>Mechanism design</li>
<li>Analyzing games in tools of computer science</li>
<li>Electronic commerce</li>
</ul>
</li>
<li>Games, logic and automata: there will be a parallel course by <a href="http://www.faculty.idc.ac.il/udiboker/">Prof. Udi Boker</a></li>
</ul>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/z9.png"><img alt="" class="alignnone size-large wp-image-19668" height="192" src="https://gilkalai.files.wordpress.com/2020/03/z9.png?w=640&amp;h=192" width="640"/></a></p>
<p><span style="color: #ff0000;">I still have some difficulty with the virtual background in ZOOM.</span></p></div>
    </content>
    <updated>2020-03-28T21:19:41Z</updated>
    <published>2020-03-28T21:19:41Z</published>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Economics"/>
    <category term="Games"/>
    <category term="Rationality"/>
    <category term="Teaching"/>
    <category term="Game theory"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-04-04T19:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=410</id>
    <link href="https://tcsplus.wordpress.com/2020/03/28/tcs-talk-wednesday-april-1-venkat-guruswami-cmu/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, April 1 — Venkat Guruswami, CMU</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, April 1th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Venkat Guruswami from CMU will speak about “Arıkan meets Shannon: Polar codes with near-optimal convergence to channel capacity” (abstract below). You can reserve a spot as an individual […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, April 1th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Venkat Guruswami</strong> from CMU will speak about “<em>Arıkan meets Shannon: Polar codes with near-optimal convergence to channel capacity</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. (The link will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our website</a> on the day of the talk, so people who did not sign up will still be able to join, until the maximum capacity of 300 seats is reached.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: We establish a constructive version of Shannon’s noisy coding theorem for binary codes, with information rate converging near-optimally fast to channel capacity as a function of code length. Specifically, let <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=fff&amp;fg=444444&amp;s=0" title="W"/> be an arbitrary binary-input memoryless symmetric channel with Shannon capacity <img alt="I(W)" class="latex" src="https://s0.wp.com/latex.php?latex=I%28W%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="I(W)"/>, and fix any <img alt="\delta &gt;0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E0&amp;bg=fff&amp;fg=444444&amp;s=0" title="\delta &gt;0"/>. We construct, for any sufficiently small <img alt="\varepsilon &gt;0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarepsilon+%3E0&amp;bg=fff&amp;fg=444444&amp;s=0" title="\varepsilon &gt;0"/>, binary linear codes of block length <img alt="O(1/\varepsilon^{2+\delta})" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2F%5Cvarepsilon%5E%7B2%2B%5Cdelta%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="O(1/\varepsilon^{2+\delta})"/> and rate <img alt="I(W)-\varepsilon" class="latex" src="https://s0.wp.com/latex.php?latex=I%28W%29-%5Cvarepsilon&amp;bg=fff&amp;fg=444444&amp;s=0" title="I(W)-\varepsilon"/> that enable reliable communication on <img alt="W" class="latex" src="https://s0.wp.com/latex.php?latex=W&amp;bg=fff&amp;fg=444444&amp;s=0" title="W"/> with quasi-linear time encoding and decoding. Shannon’s theorem implies the existence of such codes (without efficient constructions or decoding) with block length <img alt="O(1/\varepsilon^2)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2F%5Cvarepsilon%5E2%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="O(1/\varepsilon^2)"/>. This quadratic dependence on the gap epsilon to capacity is known to be best possible. Previously such a construction was only known for the case of the erasure channel.</p>
<p>Our codes are a variant of Arıkan’s polar codes based on multiple carefully constructed local kernels, one for each intermediate channel that arises in the decoding. A key technical ingredient in the analysis is a strong converse to the noisy coding theorem that shows extreme unpredictability of even a single message bit when communicating via random linear codes at rates slightly above capacity.</p>
<p>Joint work with Andrii Riazanov and Min Ye.</p></blockquote>
<p> </p></div>
    </content>
    <updated>2020-03-28T16:46:12Z</updated>
    <published>2020-03-28T16:46:12Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-04-04T19:21:08Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-655863126004196531</id>
    <link href="https://blog.computationalcomplexity.org/feeds/655863126004196531/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/03/robin-thomas.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/655863126004196531" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/655863126004196531" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/03/robin-thomas.html" rel="alternate" type="text/html"/>
    <title>Robin Thomas</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="separator" style="clear: both; text-align: center;">
<a href="https://1.bp.blogspot.com/-i5UN1hxg7RI/Xn9uVPL8h1I/AAAAAAABygU/5THjPemeT9UhN3yQenJkO_3cM_c2Awi5QCLcBGAsYHQ/s1600/Thomas.jpg" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img border="0" height="200" src="https://1.bp.blogspot.com/-i5UN1hxg7RI/Xn9uVPL8h1I/AAAAAAABygU/5THjPemeT9UhN3yQenJkO_3cM_c2Awi5QCLcBGAsYHQ/s200/Thomas.jpg" width="133"/></a></div>
Graph Theorist and Georgia Tech Math Professor Robin Thomas passed away Thursday after his long battle with ALS. He was one of the giants of the field and a rare double winner of the Fulkerson Prize, for the six-color case of the <a href="https://en.wikipedia.org/wiki/Hadwiger_conjecture_(graph_theory)">Hadwiger Conjecture</a> and the proof of the <a href="https://en.wikipedia.org/wiki/Strong_perfect_graph_theorem">strong perfect graph theorem</a>.<br/>
<br/>
If you start with a graph G and either delete some vertices or merge vertices connected by an edge, you get a minor of G. The Hadwiger conjecture asks whether every graph that is not (k+1)-colorable graph has a clique of size k as a minor. Neil Robertson, Paul Seymour and Thomas proved the k=6 case in 1993 and still the k&gt;6 cases remain open.<br/>
<br/>
A graph G is perfect if for G and all its induced subgraphs, the maximum clique size is equal to its chromatic number. In 2002 Maria Chudnovsky, Robertson, Seymour and Thomas showed that a graph G is not perfect if and only if either G or the complement of G has an induced odd cycle of length greater than 3.<br/>
<br/>
Robin Thomas was already confined to a wheelchair when I arrived at Georgia Tech in 2012. He was incredibly inspiring as he continued to teach and lead the Algorithms, Combinatorics and Optimization PhD program until quite recently. Our department <a href="https://youtu.be/e4FdY9eiWDs">did the ALS challenge</a> for him. In 2016 he <a href="https://provost.gatech.edu/updates/thomas-earns-top-faculty-honor">received</a> the Class of 1934 Distinguished Professor Award, the highest honor for a professor at Georgia Tech.  He'll be terribly missed.</div>
    </content>
    <updated>2020-03-28T15:40:00Z</updated>
    <published>2020-03-28T15:40:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-04-04T15:36:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3461</id>
    <link href="https://agtb.wordpress.com/2020/03/27/calendar-of-virtual-csecon-seminars/" rel="alternate" type="text/html"/>
    <title>Calendar of Virtual CS+Econ Seminars</title>
    <summary>Our community has some outstanding long-running virtual seminars, and there are many traditional seminars now moving to a virtual format.  Northwestern Ph.D. students Modibo Camara and Yiding Feng have a collection of them in a Google Calendar at Virtual CS+Econ Seminars.  Don’t miss any of the action! The topics include but not limited to theoretical […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Our community has some outstanding long-running virtual seminars, and there are many traditional seminars now moving to a virtual format.  Northwestern Ph.D. students <a href="https://mkcamara.github.io/">Modibo Camara</a> and <a href="https://sites.northwestern.edu/yiding/">Yiding Feng</a> have a collection of them in a Google Calendar at <a href="https://sites.google.com/view/virtualcseconseminars/">Virtual CS+Econ Seminars</a>.  Don’t miss any of the action!</p>
<p>The topics include but not limited to theoretical computer science, economic theory, theoretical machine learning, and econometrics.  The calendar currently tracks talks in <a href="https://mobile.twitter.com/CaltechEconThry">Caltech Econ Theory</a>, <a href="https://www.chamberlainseminar.org">Chamberlain Seminar in Econometrics</a>, <a href="https://www.ideal.northwestern.edu/">IDEAL</a>, <a href="http://md4sg.com">MD4SG</a>, and <a href="https://sites.google.com/site/plustcs">TCS+</a>. Send other relevant talk series or one-off events to Modibo and Yiding at <a class="c-link" href="mailto:VirtualCSEconSeminar@gmail.com" rel="noopener noreferrer" target="_blank">VirtualCSEconSeminar@gmail.com</a>.</p></div>
    </content>
    <updated>2020-03-26T22:24:40Z</updated>
    <published>2020-03-26T22:24:40Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Jason Hartline</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2020-04-04T19:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/040</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/040" rel="alternate" type="text/html"/>
    <title>TR20-040 |  Topology and adjunction in promise constraint satisfaction | 

	Andrei Krokhin, 

	Jakub Opršal, 

	Marcin Wrochna, 

	Stanislav Zivny</title>
    <summary>The approximate graph colouring problem concerns colouring a $k$-colourable
  graph with $c$ colours, where $c\geq k$. This problem naturally generalises
  to promise graph homomorphism and further to promise constraint satisfaction
  problems. Complexity analysis of all these problems is notoriously difficult.
  In this paper, we introduce two new techniques to analyse the complexity of
  promise CSPs: one is based on topology and the other on adjunction. We apply
  these techniques, together with the previously introduced algebraic approach,
  to obtain new NP-hardness results for a significant class of approximate
  graph colouring and promise graph homomorphism problems.</summary>
    <updated>2020-03-26T14:25:32Z</updated>
    <published>2020-03-26T14:25:32Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-04T19:20:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7660</id>
    <link href="https://windowsontheory.org/2020/03/26/technology-for-theory-covid-19-edition/" rel="alternate" type="text/html"/>
    <title>Technology for theory: COVID-19 edition</title>
    <summary>The new coronavirus upended much of society, including our little corner of it. I believe at this point almost all theorists are teaching and doing research at home, and I thought it would be good to share some of the tools we use for doing so. Below I will describe my setup, but I hope […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The new coronavirus upended much of society, including our little corner of it. I believe at this point almost all theorists are teaching and doing research at home, and I thought it would be good to share some of the tools we use for doing so. Below I will describe my setup, but I hope other people share theirs too.</p>



<h2>Teaching and virtual whiteboards</h2>



<p>I am teaching using Zoom and using an iPad pro with a pencil to simulate a whiteboard. I use a laptop to connect to Zoom and for the camera, laptop, and chat window, and then join the iPad.There are several ways to connect an iPad to a Zoom session:</p>



<ol><li>Join the session from the iPad separately using the iPad Zoom app. (To do so you <em>might</em> need to logout of your other account.)</li><li>Within the Zoom program on your computer you can choose “share screen” and then one of the option is to join an iPad connected to the same wireless network as the laptop/desktop and use “screen mirroring” on the iPad. (You can find the screen mirroring option on the iPad by swiping from the top right corner in a diagonal motion.)</li><li>Another variant of this is to use a third party app such as <a href="https://www.airsquirrels.com/reflector">Reflector 3</a>. Reflector 3 sets up an airplay server on your PC so you can mirror the iPad screen to it. You can then share the Reflector 3 window from Zoom (see screen shorts below). If you do use Reflector 3, you can remove its annoying iPad like frame.</li><li>You can use a wired connection, which is either by just connecting through USB (in a Mac) or a complex combination of combining an adapter to take an HDMI signal out of an iPad with an HDMI capture card to stream this signal to the computer.</li></ol>



<p>I use either option 2 or 3. (Might have used 4 if I had a Mac.) The main reason I prefer these to option 1 is because the application I use for a whiteboard –  <a href="https://www.goodnotes.com/">GoodNotes</a> – has a <a href="https://support.goodnotes.com/hc/en-us/articles/360001100576-How-to-use-Presentation-Mode">presentation mode</a> that behaves differently when you are connected to an external display or use AirPlay (which is what options 2 and 3 do). In this presentation mode the students don’t see your interface, and so you can Zoom, go to the page selector and more without it disturbing what they see. GoodNotes also has a great “laser pointer”. I set the pages at a landscape orientation,  and pre-write a good chunk of what I plan to present before the lecture. I also use the ability to “duplicate pages” to achieve the PowerPoint like effect of gradual reveal.</p>



<p>It is not perfect – I’ve discovered that the screen share sometimes stops refreshing and I need to leave GoodNotes and return to it for it to go back (this seems to works better in Reflector 3 so far for me).</p>



<p>Monitoring the chat window and raised hands in Zoom is non-trivial. It helps a lot that I have a teaching assistant that participates in lecture and notices if I missed something. </p>



<p>Some people say that a “matte screen protector” such as <a href="https://paperlike.com/">PaperLike</a> makes the iPad more comfortable to write on – haven’t yet tried it. (Update 4/1/2020: I now tried PaperLike and can vouch for it – it greatly improves my handwriting! shipping from the UK did take some time though.)</p>



<p>I have a good Webcam (<a href="https://www.amazon.com/Logitech-BRIO-Conferencing-Recording-Streaming/dp/B01N5UOYC4">Logitech Brio</a>) but at the moment I’m not using it since it seems too taxing on my laptop and so I went back to the native webcam. I have a very nice wireless headset/mic combo (<a href="https://www.amazon.com/Jabra-Bluetooth-Headphones-Including-Packaging/dp/B072JWYJMC">Jabra Evolve 75</a>) that I am constantly using and have been very happy with. I particularly like the feature of being able to unmute and mute yourself by raising and lowering the mike. </p>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-7668" src="https://windowsontheory.files.wordpress.com/2020/04/screenshot-2020-04-01-10.27.41.png?w=1024"/>Using Screen share from Zoom to either share an iPad or the Reflector 3 window</figure>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-7667" src="https://windowsontheory.files.wordpress.com/2020/04/21360-1.jpg?w=1024"/>Choose which source to mirror the screen to on your iPad screen</figure>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-7669" src="https://windowsontheory.files.wordpress.com/2020/04/85387-1.jpg?w=726"/>You can reach the screen mirroring options by swiping from the top right corner of the iPad.</figure>



<h2>Research</h2>



<p>For research Slack continues to extremely useful. For working jointly on a paper <a href="https://www.overleaf.com/">Overleaf </a> is of course great, but for maintaining a shared document it sometimes useful to use simpler platform that are not full fledged LaTeX. Some options include:</p>



<ul><li><a href="https://hackmd.io/">Hackmd.io</a> for markdown (supports LaTeX math)</li><li>Google docs of course. I heard about the <a href="https://gsuite.google.com/marketplace/app/autolatex_equations/850293439076">Auto-LaTeX plugin</a> but haven’t used it yet.</li><li><a href="https://www.dropbox.com/paper">Dropbox Paper</a> supports LaTeX natively.</li></ul>



<p><a href="https://jamboard.google.com/">Google JamBoard</a> is an interactive whiteboard, also with an <a href="https://apps.apple.com/us/app/jamboard/id1143591418">iPad app</a>. I haven’t tried it yet but it seems promising.</p>



<p/>



<h2>Keeping children busy</h2>



<p>For many people I imagine childcare is one of the most challenging aspects. At the moment at least the Cambridge Public Schools are not keeping my kids too busy. While probably most of their time is spent in non educational pursuits, we try to also encourage (i.e., bribe/extort/threaten/beg) them to do some learning. If your kids are interested in math, I highly recommend the courses offered by the <a href="https://artofproblemsolving.com/">Art of Problem Solving</a> (they also have a theory connection: one of their books was co-authored by theorist Ravi Boppana). For younger kids you can also try their <a href="https://beastacademy.com/">Beast Academy</a>.</p>



<p>The AOPS program is not free but over the years my kids (especially my 13 year old daughter Alma) have also spent a lot of time on the free and amazing <a href="https://www.khanacademy.org/">Khan Academy</a>. In fact, last year she was inspired enough by Khan’s JavaScript course to write the following poem which (for obvious reasons)  moved me very much:</p>



<p>Tending / Alma Barak</p>



<p>My mind is a desert<br/>of boredom<br/>of blankness<br/>of leaning-back-in-your-chairness<br/>and of simply-staring-at-the-ceilingness<br/>I kick at a crumpled<br/>deserted baby-blonde post-it<br/>with my spotted socked feet<br/>waiting for Aba to come.</p>



<p>We dive when he comes<br/>into the seas of Khan<br/>free-styling our way<br/>into the lakes of Java<br/>we pass codes we already<br/>knew<br/>while loops<br/>for loops<br/>arrays<br/>reminding me of what I’d learned</p>



<p>We frog-kick to an<br/>uncharted<br/>unfamiliar<br/>lagoon of code I don’t know<br/>sometimes I get swept away by currents<br/>of confusion<br/>but my aba, my dad<br/>grabs my hand<br/>and shows me the way through<br/>teaching me<br/>tending to me<br/>washing away the sands of boredom with the sea of Khan.</p>



<p/></div>
    </content>
    <updated>2020-03-26T12:52:26Z</updated>
    <published>2020-03-26T12:52:26Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-04-04T19:20:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/039</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/039" rel="alternate" type="text/html"/>
    <title>TR20-039 |  Lower bounds on the sum of 25th-powers of univariates lead to complete derandomization of PIT | 

	Pranjal Dutta, 

	Nitin Saxena, 

	Thomas Thierauf</title>
    <summary>We consider the univariate polynomial $f_d:=(x+1)^d$ when represented as a sum of constant-powers of univariate polynomials. We define a natural measure for the model, the support-union, and conjecture that it is $\Omega(d)$ for $f_d$. 

We show a stunning connection of the conjecture to the two main problems in algebraic complexity: Polynomial Identity Testing (PIT) and VP vs VNP. Our conjecture on $f_d$ implies blackbox-PIT in P. Assuming the  Generalized Riemann Hypothesis (GRH), it also implies VP $\neq$ VNP. No such connection to PIT, from lower bounds on constant-powers representation of polynomials was known before. We establish that studying the expression of $(x+1)^d$, as the sum of $25^{th}$-powers of univariates, suffices to solve the two major open questions.   

In support, we show that our conjecture holds over the integer ring of any number field. We also establish a connection with the well-studied notion of matrix rigidity.</summary>
    <updated>2020-03-25T21:21:25Z</updated>
    <published>2020-03-25T21:21:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-04T19:20:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7657</id>
    <link href="https://windowsontheory.org/2020/03/25/new-cs-theory-talk-aggragator/" rel="alternate" type="text/html"/>
    <title>New CS theory talk aggragator</title>
    <summary>Shcachar Lovett has put together a new website aggregating information about virtual talks in CS theory: https://cstheorytalks.wordpress.com/  It has a Google calendar that people can add to their own, and a form to submit a new talk that automatically gets added to the Google calendar.  This can be a fantastic resource these days that almost […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Shcachar Lovett has put together a new website aggregating information about virtual talks in CS theory: <a href="https://cstheorytalks.wordpress.com/">https://cstheorytalks.wordpress.com/</a></p>



<p> It has a Google calendar that people can add to their own, and a form to submit a new talk that automatically gets added to the Google calendar. </p>



<p>This can be a fantastic resource these days that almost no one can travel – please publicize this and also submit to it talks that you are organizing.</p></div>
    </content>
    <updated>2020-03-25T17:00:17Z</updated>
    <published>2020-03-25T17:00:17Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-04-04T19:20:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/03/24/full-professor-w3-at-tu-dortmund-university-apply-by-april-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/03/24/full-professor-w3-at-tu-dortmund-university-apply-by-april-15-2020/" rel="alternate" type="text/html"/>
    <title>Full Professor (W3)  at TU Dortmund University (apply by April 15, 2020)</title>
    <summary>The Department of Computer Science at TU Dortmund University (https://tu-dortmund.de/en) is seeking to fill the position of a Full Professor Position (W3) in “Efficient Algorithms and Complexity Theory” commencing as soon as possible. Website: https://service.tu-dortmund.de/documents/18/2120803/Professor+W3+in+Efficient+Algorithms+and+Complexity+Theory.pdf/64785b24-b188-fbaa-e337-a2405661868f Email: thomas.schwentick@tu-dortmund.de</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at TU Dortmund University (<a href="https://tu-dortmund.de/en">https://tu-dortmund.de/en</a>) is seeking to fill the position of a Full Professor Position (W3) in “Efficient Algorithms and Complexity Theory” commencing as soon as possible.</p>
<p>Website: <a href="https://service.tu-dortmund.de/documents/18/2120803/Professor+W3+in+Efficient+Algorithms+and+Complexity+Theory.pdf/64785b24-b188-fbaa-e337-a2405661868f">https://service.tu-dortmund.de/documents/18/2120803/Professor+W3+in+Efficient+Algorithms+and+Complexity+Theory.pdf/64785b24-b188-fbaa-e337-a2405661868f</a><br/>
Email: thomas.schwentick@tu-dortmund.de</p></div>
    </content>
    <updated>2020-03-24T10:41:04Z</updated>
    <published>2020-03-24T10:41:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-04-04T19:20:44Z</updated>
    </source>
  </entry>
</feed>
