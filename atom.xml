<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-07-14T04:22:15Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4253</id>
    <link href="https://www.scottaaronson.com/blog/?p=4253" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4253#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4253" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">On two blog posts of Jerry Coyne</title>
    <summary xml:lang="en-US">A few months ago, I got to know Jerry Coyne, the recently-retired biologist at the University of Chicago who writes the blog “Why Evolution Is True.” The interaction started when Jerry put up a bemused post about my thoughts on predictability and free will, and if I pointed out that if he wanted to engage […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>A few months ago, I got to know <a href="https://en.wikipedia.org/wiki/Jerry_Coyne">Jerry Coyne</a>, the recently-retired biologist at the University of Chicago who writes the blog <a href="https://whyevolutionistrue.wordpress.com/">“Why Evolution Is True.”</a>  The interaction started when Jerry put up a <a href="https://whyevolutionistrue.wordpress.com/2019/01/15/a-computer-scientist-finds-the-question-of-free-will-uninteresting-for-bad-reasons/">bemused post about my thoughts on predictability and free will</a>, and if I pointed out that if he wanted to engage me on those topics, there was <a href="https://www.scottaaronson.com/papers/giqtm3.pdf">more to go on</a> than an 8-minute YouTube video.  I told Coyne that it would be a shame to get off on the wrong foot with him, since perusal of his blog made it obvious that whatever he and I disputed, it was dwarfed by our areas of agreement.  He and I exchanged more emails and had lunch in Chicago.</p>



<p>By way of explaining how he hadn’t read <a href="https://www.scottaaronson.com/papers/giqtm3.pdf">“The Ghost in the Quantum Turing Machine,”</a> Coyne emphasized the difference in my and his turnaround times: while these days I update my blog only a couple times per month, Coyne often updates multiple times per <em>day</em>.  Indeed the sheer volume of material he posts, on subjects from biology to culture wars to <a href="https://whyevolutionistrue.wordpress.com/2019/02/27/the-chicago-hot-dog-museum-and-our-wonderful-hot-dogs/">Chicago hot dogs</a>, would take months to absorb.</p>



<p>Today, though, I want to comment on just two posts of Jerry’s.</p>



<p>The <a href="https://whyevolutionistrue.wordpress.com/2019/05/17/computer-scientist-david-gelertner-drinks-the-academic-kool-aid-buys-into-intelligent-design/">first post</a>, from back in May, concerns <a href="https://en.wikipedia.org/wiki/David_Gelernter">David Gelernter</a>, the computer science professor at Yale who was infamously injured in a 1993 attack by the Unabomber, and who’s now mainly known as a right-wing commentator.  I don’t know Gelernter, though I did once attend a small interdisciplinary workshop in the south of France that Gelernter also attended, wherein I gave a talk about quantum computing and computational complexity in which Gelernter showed no interest.  Anyway, Gelernter, in an <a href="https://www.claremont.org/crb/article/giving-up-darwin/">essay in May for the <em>Claremont Review of Books</em></a>, argued that recent work has <em>definitively </em>disproved Darwinism as a mechanism for generating new species, and until something better comes along, Intelligent Design is the best available alternative.</p>



<p>Curiously, I think that Gelernter’s argument falls flat not for detailed reasons of biology, but mostly just because it indulges in <em>bad math and computer science</em>—in fact, in precisely the sorts of arguments that I was trying to answer in <a href="https://www.scottaaronson.com/blog/?p=1487">my segment on Morgan Freeman’s </a><em><a href="https://www.scottaaronson.com/blog/?p=1487">Through the Wormhole</a></em> (see also Section 3.2 of <a href="https://www.scottaaronson.com/papers/philos.pdf">Why Philosophers Should Care About Computational Complexity</a>).  Gelernter says that</p>



<ol><li>a random change to an amino acid sequence will pretty much always make it worse,</li><li>the probability of finding a useful new such sequence by picking one at random is at most ~1 in 10<sup>77</sup>, and</li><li>there have only been maybe ~10<sup>40</sup> organisms in earth’s history.</li></ol>



<p>Since 10<sup>77</sup> &gt;&gt; 10<sup>40</sup>, Darwinism is thereby refuted—not in principle, but as an explanation for life on earth.  QED. </p>



<p>The most glaring hole in the above argument, it seems to me, is that it simply ignores <em>intermediate</em> possible numbers of mutations.  How hard would it be to change, not 1 or 100, but 5 amino acids in a given protein to get a usefully different one—as might happen, for example, with local optimization methods like simulated annealing run at nonzero temperature?  And how many chances were there for <em>that</em> kind of mutation in the earth’s history?</p>



<p>Gelernter can’t personally see how a path could cut through the exponentially large solution space in a polynomial amount of time, so he asserts that it’s impossible.  Many of the would-be P≠NP provers who email me every week do the same.  But this particular kind of “argument from incredulity” has an abysmal track record: it would’ve applied equally well, for example, to problems like maximum matching that turned out to have efficient algorithms.  This is why, in CS, we demand better evidence of hardness—like completeness results or black-box lower bounds—neither of which seem however to apply to the case at hand.  Surely Gelernter understands all this, but had he not, he could’ve learned it from my lecture in the south of France!</p>



<p>Alas, online debate, as it’s wont to do, focused on less on Gelernter’s actual arguments and the problems with them, than on the tiresome questions of “standing” and “status.”  In particular: does Gelernter’s authority, as a noted computer science professor, somehow lend new weight to Intelligent Design?  Or conversely: does the very fact that a computer scientist endorsed ID prove that computer science itself isn’t a real science at all, and that its practitioners should never be taken seriously in any statements about the real world?</p>



<p>It’s hard to say which of these two questions makes me want to bury my face deeper into my hands.  <a href="https://en.wikipedia.org/wiki/Serge_Lang">Serge Lang</a>, the famous mathematician and textbook author, spent much of his later life fervently denying the connection between HIV and AIDS.  <a href="https://en.wikipedia.org/wiki/Lynn_Margulis">Lynn Margulis</a>, the discoverer of the origin of mitochondria (and Carl Sagan’s first wife), died a 9/11 truther.  What broader lesson should we draw from any of this?  And anyway, what percentage of computer scientists actually do doubt evolution, and how does it compare to the percentage in other academic fields and other professions?  Isn’t the question of how divorced we computer scientists are from the real world an … ahem … <strong>empirical</strong> matter, one hard to answer on the basis of armchair certainties and anecdotes?</p>



<p>Speaking of empiricism, if you check Gelernter’s <a href="https://dblp.uni-trier.de/pers/hd/g/Gelernter:David">publication list on DBLP</a> and his <a href="https://scholar.google.ca/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=david+gelernter&amp;btnG=&amp;oq=david+geler">Google Scholar page</a>, you’ll find that he did influential work in programming languages, parallel computing, and other areas from 1981 through 1997, and then in the past 22 years published a grand total of … <strong>two</strong> papers in computer science.  One with four coauthors, the other a review/perspective piece about his earlier work.  So it seems fair to say that, some time after receiving tenure in a CS department, Gelernter pivoted (to put it mildly) away from CS and toward conservative punditry.  His recent offerings, in case you’re curious, include the book <a href="https://www.amazon.com/America-Lite-Imperial-Academia-Dismantled-Obamacrats/dp/1594036063/ref=sr_1_1?keywords=david+gelernter&amp;qid=1563047627&amp;s=gateway&amp;sr=8-1">America-Lite: How Imperial Academia Dismantled Our Culture (and Ushered In the Obamacrats)</a>.</p>



<p>Some will claim that this case underscores what’s wrong with the tenure system itself, while others will reply that it’s precisely what tenure was designed for, even if in this instance you happen to disagree with what Gelernter uses his tenured freedom to say.  The point I wanted to make is different, though.  It’s that the question “what kind of a field is computer science, anyway, that a guy can do high-level CS research on Monday, and then on Tuesday reject Darwinism and unironically use the word ‘Obamacrat’?”—well, even if I accepted the immense weight this question places on one atypical example (which I don’t), and even if I dismissed the power of compartmentalization (which I again don’t), the question <em>still</em> wouldn’t arise in Gelernter’s case, since getting from “Monday” to “Tuesday” seems to have taken him 15+ years.</p>



<p>Anyway, the second post of Coyne’s that I wanted to talk about is <a href="https://whyevolutionistrue.wordpress.com/2019/07/12/tarring-steve-pinker-and-others-with-jeffrey-epstein/">from just yesterday</a>, and is about Jeffrey Epstein—the financier, science philanthropist, and confessed sex offender, whose appalling crimes you’ll have read all about this week if you weren’t on a long sea voyage without Internet or something.</p>



<p>For the benefit of my many fair-minded friends on Twitter, I should clarify that I’ve never met Jeffrey Epstein, let alone accepted any private flights to his sex island or whatever.  I doubt he has any clue who I am either—even if he did once claim to be <a href="https://web.archive.org/web/20101112131000/http://www.jeffreyepsteinscience.com/2010/10/the-value-of-quantum-computing-to-jeffrey-epstein/">“intrigued”</a> by quantum information.</p>



<p>I do know a few of the scientists who Epstein once hung out with, including Seth Lloyd and Steven Pinker.  Pinker, in particular, is now facing vociferous attacks on Twitter, similar in magnitude perhaps to what I faced in the comment-171 affair, for having been photographed next to Epstein at a 2014 luncheon that was hosted by Lawrence Krauss (a physicist who later faced sexual harassment allegations of his own).  By the evidentiary standards of social media, this photo suffices to convict Pinker as basically a child molester himself, and is <em>also</em> a devastating refutation of any data that Pinker might have adduced in his books about the Enlightenment’s contributions to human flourishing.</p>



<p>From my standpoint, what’s surprising is not that Pinker is up against this, but that it <em>took this long</em> to happen, given that Pinker’s pro-Enlightenment, anti-blank-slate views have had the effect of painting a giant red target on his back.  Despite the near-inevitability, though, you can’t blame Pinker for wanting to defend himself, as I did when it was my turn for the struggle session.</p>



<p>Thus, in response to an emailed inquiry by Jerry Coyne, Pinker shared some detailed reflections about Epstein; Pinker then gave Coyne permission to post those reflections on his blog (though they were originally meant for Coyne only).  Like everything Pinker writes, they’re <a href="https://whyevolutionistrue.wordpress.com/2019/07/12/tarring-steve-pinker-and-others-with-jeffrey-epstein/">worth reading in full</a>.  Here’s the opening paragraph:</p>



<blockquote class="wp-block-quote"><p>The annoying irony is that I could never stand the guy [Epstein], never took research funding from him, and always tried to keep my distance. Friends and colleagues described him to me as a quantitative genius and a scientific sophisticate, and they invited me to salons and coffee klatches at which he held court. But I found him to be a kibitzer and a dilettante — he would abruptly change the subject ADD style, dismiss an observation with an adolescent wisecrack, and privilege his own intuitions over systematic data.</p></blockquote>



<p>Pinker goes on to discuss his record of celebrating, and extensively documenting, the forces of modernity that led to dramatic reductions in violence against women and that have the power to continue doing so.  On Twitter, Pinker had <a href="https://twitter.com/sapinker/status/1149154274787627010">already written</a>: “Needless to say I condemn Epstein’s crimes in the strongest terms.”</p>



<p>I probably should’ve predicted that Pinker would then be attacked again—this time, for having prefaced his condemnation with the phrase “needless to say.”  The argument, as best I can follow, runs like this: given all the isms of which woke Twitter has already convicted Pinker—scientism, neoliberalism, biological determinism, etc.—how could Pinker’s being against Epstein’s crimes (which we recently learned probably include the <a href="https://www.cnn.com/videos/us/2019/07/10/jeffrey-epstein-accuser-speaks-out-today-show-nbc-intv-sot-newday-vpx.cnn">rape</a>, and not only statutorily, of a 15-year-old) <em>possibly</em> be assumed as a given?</p>



<p>For the record, just as Epstein’s friends and enablers weren’t confined to one party or ideology, so the public condemnation of Epstein strikes me as a matter that is (or should be) beyond ideology, with all reasonable dispute now confined to the space between “very bad” and “extremely bad,” between “lock away for years” and “lock away for life.”</p>



<p>While I didn’t need Pinker to tell me <em>that</em>, one reason I personally appreciated his comments is that they helped to answer a question that had bugged me, and that none of the mountains of other condemnations of Epstein had given me a clear sense about.  Namely: supposing, hypothetically, that I’d met Epstein around 2002 or so—without, of course, knowing about his crimes—would I have been as taken with him as many other academics seem to have been?  (Would <em>you</em> have been?  How sure are you?)</p>



<p>Over the last decade, I’ve had the opportunity to meet some titans and semi-titans of finance and business, to talk about quantum computing and other nerdy topics.  For a few (by no means all) of these titans, my overriding impression was <em>precisely</em> their unwillingness to concentrate on any one point for more than about 20 seconds—as though they wanted the crust of a deep intellectual exchange without the meat filling.  My experience with them fit Pinker’s description of Epstein to a T (though I hasten to add that, as far as I know, none of these others ran teenage sex rings).</p>



<p>Anyway, given all the anger at Pinker for having intersected with Epstein, it’s ironic that I could easily imagine Pinker’s comments rattling Epstein the most of anyone’s, if Epstein hears of them from his prison cell.  It’s like: Epstein must have developed a skin like a rhinoceros’s by this point about being called a child abuser, creep, and a thousand similarly deserved epithets.  But “a kibitzer and a dilettante” who merely lured famous intellectuals into his living room, with wads of cash not entirely unlike the ones used to lure teenage girls to his massage table?  Ouch!</p>



<p>OK, but what about Alan Dershowitz—the man who apparently used to be Epstein’s close friend, who still is Pinker’s friend, and who played a crucial role in securing Epstein’s 2008 plea bargain, the one now condemned as a travesty of justice?  I’m not sure how I feel.  It’s like: I understand that our system requires attorneys willing to mount a vociferous defense even for clients who they privately know or believe to be guilty—and even to get those clients off on technicalities or bargaining whenever they can.  I’m also incredibly grateful that I chose CS rather than law school, because I don’t think I could last an hour advocating causes that I knew to be unjust.  Just like my fellow CS professor, the intelligent design advocate David Gelernter, I have the privilege and the burden of speaking only for myself.</p></div>
    </content>
    <updated>2019-07-13T23:33:12Z</updated>
    <published>2019-07-13T23:33:12Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Obviously I'm Not Defending Aaronson"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-13T23:39:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05401</id>
    <link href="http://arxiv.org/abs/1907.05401" rel="alternate" type="text/html"/>
    <title>Computational Concentration of Measure: Optimal Bounds, Reductions, and More</title>
    <feedworld_mtime>1562976000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Etesami:Omid.html">Omid Etesami</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahloujifar:Saeed.html">Saeed Mahloujifar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahmoody:Mohammad.html">Mohammad Mahmoody</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05401">PDF</a><br/><b>Abstract: </b>Product measures of dimension $n$ are known to be concentrated in Hamming
distance: for any set $S$ in the product space of probability $\epsilon$, a
random point in the space, with probability $1-\delta$, has a neighbor in $S$
that is different from the original point in only
$O(\sqrt{n\ln(1/(\epsilon\delta))})$ coordinates. We obtain the tight
computational version of this result, showing how given a random point and
access to an $S$-membership oracle, we can find such a close point in
polynomial time. This resolves an open question of [Mahloujifar and Mahmoody,
ALT 2019]. As corollaries, we obtain polynomial-time poisoning and (in certain
settings) evasion attacks against learning algorithms when the original
vulnerabilities have any cryptographically non-negligible probability.
</p>
<p>We call our algorithm MUCIO ("MUltiplicative Conditional Influence
Optimizer") since proceeding through the coordinates, it decides to change each
coordinate of the given point based on a multiplicative version of the
influence of that coordinate, where influence is computed conditioned on
previously updated coordinates.
</p>
<p>We also define a new notion of algorithmic reduction between computational
concentration of measure in different metric probability spaces. As an
application, we get computational concentration of measure for high-dimensional
Gaussian distributions under the $\ell_1$ metric.
</p>
<p>We prove several extensions to the results above: (1) Our computational
concentration result is also true when the Hamming distance is weighted. (2) We
obtain an algorithmic version of concentration around mean, more specifically,
McDiarmid's inequality. (3) Our result generalizes to discrete random
processes, and this leads to new tampering algorithms for collective coin
tossing protocols. (4) We prove exponential lower bounds on the average running
time of non-adaptive query algorithms.
</p></div>
    </summary>
    <updated>2019-07-13T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05391</id>
    <link href="http://arxiv.org/abs/1907.05391" rel="alternate" type="text/html"/>
    <title>Walking Randomly, Massively, and Efficiently</title>
    <feedworld_mtime>1562976000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jakub Łącki, Slobodan Mitrović, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Onak:Krzysztof.html">Krzysztof Onak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sankowski:Piotr.html">Piotr Sankowski</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05391">PDF</a><br/><b>Abstract: </b>We introduce an approach that enables for efficiently generating many
independent random walks in big graph models, such as the Massive Parallel
Computation (MPC) model. We consider the case where the space per machine is
strongly sublinear in the number of vertices. In this case, many natural
approaches for graph problems struggle to overcome the $\Theta(\log n)$ MPC
round complexity barrier. We design a PageRank algorithm that break this
barrier even for directed graphs, and also show how to break this barrier for
bipartiteness and expansion testing.
</p>
<p>In the undirected case we start our random walks from the stationary
distribution, so we approximately know the empirical distribution of their next
steps. This way we can use doubling approach to prepare continuations of
sampled walks in advance. Our approach enables generating multiple random walks
of length $l$ in $\Theta(\log l)$ rounds on MPC. Moreover, we show that under
\textsc{2-Cycle} conjecture this round complexity is asymptotically tight. One
of the most important application of random walks is PageRank computation. We
show how to use our approach to compute approximate PageRank w.h.p. for
constant damping factor in $O(\log \log n)$ rounds on undirected graphs (with
$\tilde{O}(m)$ total space), and $\tilde{O}(\log \log n)$ rounds on directed
graphs (with $\tilde{O}(m+n^{1+o(1)})$ total space).
</p>
<p>Building on our random-walk primitive and traditional property testing
algorithms, we also show how to approximately test bipartiteness and expansion
in $O(\log\log(n))$ MPC rounds.
</p></div>
    </summary>
    <updated>2019-07-13T23:45:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05378</id>
    <link href="http://arxiv.org/abs/1907.05378" rel="alternate" type="text/html"/>
    <title>Quantum and Classical Algorithms for Approximate Submodular Function Minimization</title>
    <feedworld_mtime>1562976000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hamoudi:Yassine.html">Yassine Hamoudi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rebentrost:Patrick.html">Patrick Rebentrost</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rosmanis:Ansis.html">Ansis Rosmanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santha:Miklos.html">Miklos Santha</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05378">PDF</a><br/><b>Abstract: </b>Submodular functions are set functions mapping every subset of some ground
set of size $n$ into the real numbers and satisfying the diminishing returns
property. Submodular minimization is an important field in discrete
optimization theory due to its relevance for various branches of mathematics,
computer science and economics. The currently fastest strongly polynomial
algorithm for exact minimization [LSW15] runs in time $\widetilde{O}(n^3 \cdot
\mathrm{EO} + n^4)$ where $\mathrm{EO}$ denotes the cost to evaluate the
function on any set. For functions with range $[-1,1]$, the best
$\epsilon$-additive approximation algorithm [CLSW17] runs in time
$\widetilde{O}(n^{5/3}/\epsilon^{2} \cdot \mathrm{EO})$. In this paper we
present a classical and a quantum algorithm for approximate submodular
minimization. Our classical result improves on the algorithm of [CLSW17] and
runs in time $\widetilde{O}(n^{3/2}/\epsilon^2 \cdot \mathrm{EO})$. Our quantum
algorithm is, up to our knowledge, the first attempt to use quantum computing
for submodular optimization. The algorithm runs in time
$\widetilde{O}(n^{5/4}/\epsilon^{5/2} \cdot \log(1/\epsilon) \cdot
\mathrm{EO})$. The main ingredient of the quantum result is a new method for
sampling with high probability $T$ independent elements from any discrete
probability distribution of support size $n$ in time $O(\sqrt{Tn})$. Previous
quantum algorithms for this problem were of complexity $O(T\sqrt{n})$.
</p></div>
    </summary>
    <updated>2019-07-13T23:45:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05350</id>
    <link href="http://arxiv.org/abs/1907.05350" rel="alternate" type="text/html"/>
    <title>Competitive Analysis with a Sample and the Secretary Problem</title>
    <feedworld_mtime>1562976000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaplan:Haim.html">Haim Kaplan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Naori:David.html">David Naori</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raz:Danny.html">Danny Raz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05350">PDF</a><br/><b>Abstract: </b>We extend the standard online worst-case model to accommodate past experience
which is available to the online player in many practical scenarios. We do this
by revealing a random sample of the adversarial input to the online player
ahead of time. The online player competes with the expected optimal value on
the part of the input that arrives online. Our model bridges between existing
online stochastic models (e.g., items are drawn i.i.d. from a distribution) and
the online worst-case model. We also extend in a similar manner (by revealing a
sample) the online random-order model.
</p>
<p>We study the classical secretary problem in our new models. In the worst-case
model we present a simple online algorithm with optimal competitive-ratio for
any sample size. In the random-order model, we also give a simple online
algorithm with an almost tight competitive-ratio for small sample sizes.
Interestingly, we prove that for a large enough sample, no algorithm can be
simultaneously optimal both in the worst-cast and random-order models.
</p></div>
    </summary>
    <updated>2019-07-13T23:30:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05309</id>
    <link href="http://arxiv.org/abs/1907.05309" rel="alternate" type="text/html"/>
    <title>State-of-The-Art Sparse Direct Solvers</title>
    <feedworld_mtime>1562976000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bollh=ouml=fer:Matthias.html">Matthias Bollhöfer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schenk:Olaf.html">Olaf Schenk</a>, Radim Janalík, Steve Hamm, Kiran Gullapalli <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05309">PDF</a><br/><b>Abstract: </b>In this chapter we will give an insight into modern sparse elimination
methods. These are driven by a preprocessing phase based on combinatorial
algorithms which improve diagonal dominance, reduce fill-in, and improve
concurrency to allow for parallel treatment. Moreover, these methods detect
dense submatrices which can be handled by dense matrix kernels based on
multithreaded level-3 BLAS. We will demonstrate for problems arising from
circuit simulation, how the improvements in recent years have advanced direct
solution methods significantly.
</p></div>
    </summary>
    <updated>2019-07-13T23:33:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05296</id>
    <link href="http://arxiv.org/abs/1907.05296" rel="alternate" type="text/html"/>
    <title>Simplification of Polyline Bundles</title>
    <feedworld_mtime>1562976000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spoerhase:Joachim.html">Joachim Spoerhase</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Storandt:Sabine.html">Sabine Storandt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zink:Johannes.html">Johannes Zink</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05296">PDF</a><br/><b>Abstract: </b>We propose and study generalizations to the well-known problem of polyline
simplification. Instead of a single polyline, we are given a set of polylines
possibly sharing some line segments and bend points. The simplification of
those shared parts has to be consistent among the polylines. We consider two
optimization goals: either minimizing the number of line segments or minimizing
the number of bend points in the simplification. By reduction from
Minimum-Independent-Dominating-Set, we show that both of these optimization
problems are NP-hard to approximate within a factor $n^{1/3 - \varepsilon}$ for
any $\varepsilon &gt; 0$ where $n$ is the number of bend points in the polyline
bundle. Moreover, we outline that both problems remain NP-hard even if the
input is planar. On the positive side, we give a polynomial-size integer linear
program and show fixed-parameter tractability in the number of shared bend
points.
</p></div>
    </summary>
    <updated>2019-07-13T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05257</id>
    <link href="http://arxiv.org/abs/1907.05257" rel="alternate" type="text/html"/>
    <title>Stick Graphs with Length Constraints</title>
    <feedworld_mtime>1562976000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chaplick:Steven.html">Steven Chaplick</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kindermann:Philipp.html">Philipp Kindermann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/L=ouml=ffler:Andre.html">Andre Löffler</a>, Florian Thiele, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolff:Alexander.html">Alexander Wolff</a>, Alexander Zaft, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zink:Johannes.html">Johannes Zink</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05257">PDF</a><br/><b>Abstract: </b>Stick graphs are intersection graphs of horizontal and vertical line segments
that all touch a line of slope -1 and lie above this line. De Luca et al.
[GD'18] considered the recognition problem of stick graphs for the case that
the ordering of either one of the two sets (STICK_A) is given and for the case
that the ordering of both sets is given (STICK_AB). They showed how to solve
both cases efficiently. In this paper, we improve the running times of their
algorithms and consider new variants of STICK, where no ordering is given,
STICK_A, and STICK_AB where the lengths of the sticks are given as input. We
show that all new problem variants are NP-complete and give an efficient
solution for STICK_AB with fixed stick lengths if there are no isolated
vertices.
</p></div>
    </summary>
    <updated>2019-07-13T23:48:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05135</id>
    <link href="http://arxiv.org/abs/1907.05135" rel="alternate" type="text/html"/>
    <title>Perturbed Greedy on Oblivious Matching Problems</title>
    <feedworld_mtime>1562976000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Zhihao_Gavin.html">Zhihao Gavin Tang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Xiaowei.html">Xiaowei Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Yuhao.html">Yuhao Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05135">PDF</a><br/><b>Abstract: </b>We study the maximum matching problem in the oblivious setting, i.e. the edge
set of the graph is unknown to the algorithm. The existence of an edge is
revealed upon the probe of this pair of vertices. Further, if an edge exists
between two probed vertices, then the edge must be included in the matching
irrevocably. For unweighted graphs, the \textsf{Ranking} algorithm by Karp et
al.~(STOC 1990) achieves approximation ratios $0.696$ for bipartite graphs and
$0.526$ for general graphs. For vertex-weighted graphs, Chan et al. (TALG 2018)
proposed a $0.501$-approximate algorithm. In contrast, the edge-weighted
version only admits the trivial $0.5$-approximation by Greedy.
</p>
<p>In this paper, we propose the \textsf{Perturbed Greedy} algorithm for the
edge-weighted oblivious matching problem and prove that it achieves a $0.501$
approximation ratio. Besides, we show that the approximation ratio of our
algorithm on unweighted graphs is $0.639$ for bipartite graphs, and $0.531$ for
general graphs. The later improves the state-of-the-art result by Chan et al.
(TALG 2018). Furthermore, our algorithm can be regarded as a robust version of
the \textsf{Modified Randomized Greedy} (MRG) algorithm. By implication, our
$0.531$ approximation ratio serves as the first analysis of the MRG algorithm
beyond the $(1/2+\epsilon)$ regime.
</p></div>
    </summary>
    <updated>2019-07-13T23:27:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05121</id>
    <link href="http://arxiv.org/abs/1907.05121" rel="alternate" type="text/html"/>
    <title>Approximate Model Counting, Sparse XOR Constraints and Minimum Distance</title>
    <feedworld_mtime>1562976000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Boreale:Michele.html">Michele Boreale</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gorla:Daniele.html">Daniele Gorla</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05121">PDF</a><br/><b>Abstract: </b>The problem of counting the number of models of a given Boolean formula has
numerous applications, including computing the leakage of deterministic
programs in Quantitative Information Flow. Model counting is a hard,
#P-complete problem. For this reason, many approximate counters have been
developed in the last decade, offering formal guarantees of confidence and
accuracy. A popular approach is based on the idea of using random XOR
constraints to, roughly, successively halving the solution set until no model
is left: this is checked by invocations to a SAT solver. The effectiveness of
this procedure hinges on the ability of the SAT solver to deal with XOR
constraints, which in turn crucially depends on the length of such constraints.
We study to what extent one can employ sparse, hence short, constraints,
keeping guarantees of correctness. We show that the resulting bounds are
closely related to the geometry of the set of models, in particular to the
minimum Hamming distance between models. We evaluate our theoretical results on
a few concrete formulae. Based on our findings, we finally discuss possible
directions for improvements of the current state of the art in approximate
model counting.
</p></div>
    </summary>
    <updated>2019-07-13T23:26:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05094</id>
    <link href="http://arxiv.org/abs/1907.05094" rel="alternate" type="text/html"/>
    <title>Analysis of Ward's Method</title>
    <feedworld_mtime>1562976000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gro=szlig=wendt:Anna.html">Anna Großwendt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/R=ouml=glin:Heiko.html">Heiko Röglin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Melanie.html">Melanie Schmidt</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05094">PDF</a><br/><b>Abstract: </b>We study Ward's method for the hierarchical $k$-means problem. This popular
greedy heuristic is based on the \emph{complete linkage} paradigm: Starting
with all data points as singleton clusters, it successively merges two clusters
to form a clustering with one cluster less. The pair of clusters is chosen to
(locally) minimize the $k$-means cost of the clustering in the next step.
</p>
<p>Complete linkage algorithms are very popular for hierarchical clustering
problems, yet their theoretical properties have been studied relatively little.
For the Euclidean $k$-center problem, Ackermann et al. show that the
$k$-clustering in the hierarchy computed by complete linkage has a worst-case
approximation ratio of $\Theta(\log k)$. If the data lies in $\mathbb{R}^d$ for
constant dimension $d$, the guarantee improves to $\mathcal{O}(1)$, but the
$\mathcal{O}$-notation hides a linear dependence on $d$. Complete linkage for
$k$-median or $k$-means has not been analyzed so far.
</p>
<p>In this paper, we show that Ward's method computes a $2$-approximation with
respect to the $k$-means objective function if the optimal $k$-clustering is
well separated. If additionally the optimal clustering also satisfies a balance
condition, then Ward's method fully recovers the optimum solution. These
results hold in arbitrary dimension. We accompany our positive results with a
lower bound of $\Omega((3/2)^d)$ for data sets in $\mathbb{R}^d$ that holds if
no separation is guaranteed, and with lower bounds when the guaranteed
separation is not sufficiently strong. Finally, we show that Ward produces an
$\mathcal{O}(1)$-approximative clustering for one-dimensional data sets.
</p></div>
    </summary>
    <updated>2019-07-13T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05083</id>
    <link href="http://arxiv.org/abs/1907.05083" rel="alternate" type="text/html"/>
    <title>Cake Cutting on Graphs: A Discrete and Bounded Proportional Protocol</title>
    <feedworld_mtime>1562976000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bei:Xiaohui.html">Xiaohui Bei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Xiaoming.html">Xiaoming Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Hao.html">Hao Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Jialin.html">Jialin Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Zhijie.html">Zhijie Zhang</a>, Wei Zi <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05083">PDF</a><br/><b>Abstract: </b>The classical cake cutting problem studies how to find fair allocations of a
heterogeneous and divisible resource among multiple agents. Two of the most
commonly studied fairness concepts in cake cutting are proportionality and
envy-freeness. It is well known that a proportional allocation among $n$ agents
can be found efficiently via simple protocols [16]. For envy-freeness, in a
recent breakthrough, Aziz and Mackenzie [5] proposed a discrete and bounded
envy-free protocol for any number of players. However, the protocol suffers
from high multiple-exponential query complexity and it remains open to find
simpler and more efficient envy-free protocols.
</p>
<p>In this paper we consider a variation of the cake cutting problem by assuming
an underlying graph over the agents whose edges describe their acquaintance
relationships, and agents evaluate their shares relatively to those of their
neighbors. An allocation is called locally proportional if each agent thinks
she receives at least the average value over her neighbors. Local
proportionality generalizes proportionality and is in an interesting middle
ground between proportionality and envy-freeness: its existence is guaranteed
by that of an envy-free allocation, but no simple protocol is known to produce
such a locally proportional allocation for general graphs. Previous works
showed locally proportional protocols for special classes of graphs, and it is
listed in both [1] and [8] as an open question to design simple locally
proportional protocols for more general classes of graphs. In this paper we
completely resolved this open question by presenting a discrete and bounded
locally proportional protocol for any given graphs. Our protocol has a query
complexity of only single exponential, which is significantly smaller than the
six towers of $n$ query complexity of the envy-free protocol given in [5].
</p></div>
    </summary>
    <updated>2019-07-13T23:21:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05000</id>
    <link href="http://arxiv.org/abs/1907.05000" rel="alternate" type="text/html"/>
    <title>ADDMC: Exact Weighted Model Counting with Algebraic Decision Diagrams</title>
    <feedworld_mtime>1562976000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dudek:Jeffrey_M=.html">Jeffrey M. Dudek</a>, Vu H. N. Phan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vardi:Moshe_Y=.html">Moshe Y. Vardi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05000">PDF</a><br/><b>Abstract: </b>We compute exact literal-weighted model counts of CNF formulas. Our algorithm
employs dynamic programming, with Algebraic Decision Diagrams as the primary
data structure. This technique is implemented in ADDMC, a new model counter. We
empirically evaluate various heuristics that can be used with ADDMC. We also
compare ADDMC to state-of-the-art exact model counters (Cachet, c2d, d4,
miniC2D, and sharpSAT) on the two largest CNF model counting benchmark families
(BayesNet and Planning). ADDMC solves the most benchmarks in total within the
given timeout.
</p></div>
    </summary>
    <updated>2019-07-13T23:34:13Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04904</id>
    <link href="http://arxiv.org/abs/1907.04904" rel="alternate" type="text/html"/>
    <title>A Resource-Aware Approach to Collaborative Loop Closure Detection with Provable Performance Guarantees</title>
    <feedworld_mtime>1562976000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tian:Yulun.html">Yulun Tian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khosoussi:Kasra.html">Kasra Khosoussi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/How:Jonathan_P=.html">Jonathan P. How</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04904">PDF</a><br/><b>Abstract: </b>This paper presents resource-aware algorithms for distributed inter-robot
loop closure detection for applications such as collaborative simultaneous
localization and mapping (CSLAM) and distributed image retrieval. In real-world
scenarios, this process is resource-intensive as it involves exchanging many
observations and geometrically verifying a large number of potential matches.
This poses severe challenges for small-size and low-cost robots with various
operational and resource constraints that limit, e.g., energy consumption,
communication bandwidth, and computation capacity. This paper proposes a
framework in which robots first exchange compact queries to identify a set of
potential loop closures. We then seek to select a subset of potential
inter-robot loop closures for geometric verification that maximizes a monotone
submodular performance metric without exceeding budgets on computation (number
of geometric verifications) and communication (amount of exchanged data for
geometric verification). We demonstrate that this problem is in general
NP-hard, and present efficient approximation algorithms with provable
performance guarantees. The proposed framework is extensively evaluated on real
and synthetic datasets. A natural convex relaxation scheme is also presented to
certify the near-optimal performance of the proposed framework in practice.
</p></div>
    </summary>
    <updated>2019-07-13T23:27:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04889</id>
    <link href="http://arxiv.org/abs/1907.04889" rel="alternate" type="text/html"/>
    <title>Computing Minimal Persistent Cycles: Polynomial and Hard Cases</title>
    <feedworld_mtime>1562976000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dey:Tamal_K=.html">Tamal K. Dey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hou:Tao.html">Tao Hou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mandal:Sayan.html">Sayan Mandal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04889">PDF</a><br/><b>Abstract: </b>Persistent cycles, especially the minimal ones, are useful geometric features
functioning as augmentations for the intervals in the purely topological
persistence diagrams (also termed as barcodes). In our earlier work, we showed
that computing minimal 1-dimensional persistent cycles (persistent 1-cycles)
for finite intervals is NP-hard while the same for infinite intervals is
polynomially tractable. In this paper, we address this problem for general
dimensions with $Z_2$ coefficients. In addition to proving that it is NP-hard
to compute minimal persistent d-cycles (d&gt;1) for both types of intervals given
arbitrary simplicial complexes, we identify two interesting cases which are
polynomially tractable. These two cases assume the complex to be a certain
generalization of manifolds which we term as weak pseudomanifolds. For finite
intervals from the d-th persistence diagram of a weak (d+1)-pseudomanifold, we
utilize the fact that persistent cycles of such intervals are null-homologous
and reduce the problem to a minimal cut problem. Since the same problem for
infinite intervals is NP-hard, we further assume the weak (d+1)-pseudomanifold
to be embedded in $\mathbb{R}^{d+1}$ so that the complex has a natural dual
graph structure and the problem reduces to a minimal cut problem. Experiments
with both algorithms on scientific data indicate that the minimal persistent
cycles capture various significant features of the data.
</p></div>
    </summary>
    <updated>2019-07-13T23:47:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04565</id>
    <link href="http://arxiv.org/abs/1907.04565" rel="alternate" type="text/html"/>
    <title>Progressive Wasserstein Barycenters of Persistence Diagrams</title>
    <feedworld_mtime>1562976000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jules Vidal, Joseph Budin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tierny:Julien.html">Julien Tierny</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04565">PDF</a><br/><b>Abstract: </b>This paper presents an efficient algorithm for the progressive approximation
of Wasserstein barycenters of persistence diagrams, with applications to the
visual analysis of ensemble data. Given a set of scalar fields, our approach
enables the computation of a persistence diagram which is representative of the
set, and which visually conveys the number, data ranges and saliences of the
main features of interest found in the set. Such representative diagrams are
obtained by computing explicitly the discrete Wasserstein barycenter of the set
of persistence diagrams, a notoriously computationally intensive task. In
particular, we revisit efficient algorithms for Wasserstein distance
approximation [12,51] to extend previous work on barycenter estimation [94]. We
present a new fast algorithm, which progressively approximates the barycenter
by iteratively increasing the computation accuracy as well as the number of
persistent features in the output diagram. Such a progressivity drastically
improves convergence in practice and allows to design an interruptible
algorithm, capable of respecting computation time constraints. This enables the
approximation of Wasserstein barycenters within interactive times. We present
an application to ensemble clustering where we revisit the k-means algorithm to
exploit our barycenters and compute, within execution time constraints,
meaningful clusters of ensemble data along with their barycenter diagram.
Extensive experiments on synthetic and real-life data sets report that our
algorithm converges to barycenters that are qualitatively meaningful with
regard to the applications, and quantitatively comparable to previous
techniques, while offering an order of magnitude speedup when run until
convergence (without time constraint). Our algorithm can be trivially
parallelized to provide additional speedups in practice on standard
workstations. [...]
</p></div>
    </summary>
    <updated>2019-07-13T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16085</id>
    <link href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/" rel="alternate" type="text/html"/>
    <title>Tools and Sensitivity</title>
    <summary>Cutting right through a 30-year-old conjecture Cropped from Emory homepage Hao Huang is a mathematician and computer scientist at Emory University. Last week he released a paper of only six pages that solves the Boolean Sensitivity Conjecture, which goes back at least to a 1992 paper by Noam Nisan and Mario Szegedy. Today we discuss […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Cutting right through a 30-year-old conjecture</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/haohuangcropped/" rel="attachment wp-att-16086"><img alt="" class="alignright wp-image-16086" height="212" src="https://rjlipton.files.wordpress.com/2019/07/haohuangcropped.jpg?w=148&amp;h=212" width="148"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Emory <a href="http://www.mathcs.emory.edu/~hhuan30/">homepage</a></font></td>
</tr>
</tbody>
</table>
<p>
Hao Huang is a mathematician and computer scientist at Emory University. Last week he released a <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">paper</a> of only six pages that solves the Boolean Sensitivity Conjecture, which goes back at least to a 1992 <a href="https://www.researchgate.net/publication/2508255_On_the_Degree_of_Boolean_Functions_as_Real_Polynomials">paper</a> by Noam Nisan and Mario Szegedy.</p>
<p>
Today we discuss his brilliant proof and what it means for sensitivity of the <em>tools</em> one employs.</p>
<p>
Several of our blogging friends have <a href="https://www.scottaaronson.com/blog/?p=4229">covered</a> this <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">news</a> in <a href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html">posts</a> <a href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/">already</a>, and Ryan O’Donnell even summarized the proof in one <a href="https://twitter.com/BooleanAnalysis/status/1145837576487612416">tweet</a>. Scott Aaronson’s thread includes a <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813116">comment</a> by Huang on how he came by his proof. </p>
<p>
We will try to draw implications for the related matter of how <em>you</em> might come by proofs of <em>other</em> conjectures. We have previously <a href="https://rjlipton.wordpress.com/2016/04/09/missing-mate-in-ten/">discussed</a> the possibility of overlooking short solutions to major problems. Here we will discuss how to <em>find</em> them.</p>
<p>
</p><p/><h2> A Graph Puzzle </h2><p/>
<p/><p>
To get a flavor of what Huang proved, consider the graph of an ordinary <a href="https://commons.wikimedia.org/wiki/File:Cube_graph.png">cube</a>:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph/" rel="attachment wp-att-16087"><img alt="" class="aligncenter wp-image-16087" height="181" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph.png?w=192&amp;h=181" width="192"/></a></p>
<p/><p><br/>
The question is, <em>can you color 5 vertices red so that no red node has 3 red neighbors?</em> Your first impulse might be to color 4 nodes red according to parity so that none has a red neighbor, per below left:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph_tries/" rel="attachment wp-att-16088"><img alt="" class="aligncenter wp-image-16088" height="175" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph_tries.png?w=450&amp;h=175" width="450"/></a></p>
<p/><p><br/>
But then any 5th node will have 3 red neighbors. Another “greedy” idea is to pack a subgraph of the allowed degree 2 into half the cube, as at right. Any 5th node will again create a degree-3 vertex in the subgraph induced by the red nodes.</p>
<p>
The answer is that actually one can pack 6 nodes that induce a simple cycle:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph_solved/" rel="attachment wp-att-16089"><img alt="" class="aligncenter wp-image-16089" height="181" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph_solved.png?w=192&amp;h=181" width="192"/></a></p>
<p/><p><br/>
Now let’s up the dimension by one—that is, take <img alt="{n = 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 4}"/> and <img alt="{N = 2^n = 16}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+2%5En+%3D+16%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N = 2^n = 16}"/>. How many nodes can we color red and keep the induced degree 2? </p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/hypercube_graph/" rel="attachment wp-att-16091"><img alt="" class="aligncenter wp-image-16091" height="230" src="https://rjlipton.files.wordpress.com/2019/07/hypercube_graph-1.png?w=300&amp;h=230" width="300"/></a></p>
<p/><p><br/>
Again the parity trick gives us degree 0 with 8 nodes, but then we can’t add a 9th. We can greedily try to pack the outer cube with our 6-node solution, but then—perhaps surprisingly—we can add only 2 more red nodes from the inner cube. So we can only do 5 from the outer cube. We can get 9 overall by:</p>
<p><a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/hypercube_graph_try10/" rel="attachment wp-att-16092"><img alt="" class="aligncenter wp-image-16092" height="230" src="https://rjlipton.files.wordpress.com/2019/07/hypercube_graph_try10.png?w=300&amp;h=230" width="300"/></a></p>
<p/><p><br/>
The fact that one red node is isolated seems to give room to improve, but there is no way to make 10. </p>
<p>
</p><p/><h2> The Theorem </h2><p/>
<p/><p>
The calculations have left an interesting jump from degree 0 with eight red nodes and degree 2 with nine. How about degree 1? Can we do that with 9 nodes? We can pack four disjoint edges but then there is nowhere to stick an isolated node. </p>
<p>
So for 9 nodes, which is <img alt="{\frac{N}{2} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2} + 1}"/>, the best we can do is degree 2, which is <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. This is what Huang proved:</p>
<blockquote><p><b>Theorem 1</b> <em><a name="graphs"/> Every subgraph induced by <img alt="{\frac{N}{2} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\frac{N}{2} + 1}"/> nodes of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>-dimensional hypercube graph has a node of degree at least <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. </em>
</p></blockquote>
<p/><p>
This is completely tight. When <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is a perfect square there is a way to achieve <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/> as the maximum degree (shown <a href="https://pdfs.semanticscholar.org/3917/3e0cb4e028c94328f1355bf02febea132127.pdf">here</a>). Otherwise the least integer above <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/> is best. Thus every subgraph of the <img alt="{5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5}"/>-cube induced by 17 nodes has a node with three neighbors, but you can go as high as 257 nodes in the <img alt="{9}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B9%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{9}"/>-cube while keeping the maximum degree to 3.</p>
<p>
We will mention the relation to Boolean sensitivity only briefly. The nodes of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube correspond to truth assignments in <img alt="{\{0,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{0,1\}^n}"/>. Since every red node <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> has <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> neighbors in the cube but at most <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/> red neighbors, the color function is highly sensitive to bitflips. But every flip also changes the parity of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>. Hence the <em>exclusive-or</em> of the color function with the parity function has <em>low</em> sensitivity. </p>
<p>
But not too low: Huang proved it is at least <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. That was enough to prove the conjecture. I’ve cut two sections on Boolean sensitivity from this post’s <a href="https://cse.buffalo.edu/~regan/cse705/wsensitivity.pdf">original draft</a>—let’s just say the connection to the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube and graph degree was known since this 1992 <a href="https://www.sciencedirect.com/science/article/pii/0097316592900608">paper</a>. Here we’ll focus on what it took to prove this theorem.</p>
<p>
</p><p/><h2> The Proof </h2><p/>
<p/><p>
From my undergrad days I’ve kept an interest in spectral graph theory. One of the basic facts is that the degree <img alt="{d(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(G)}"/> of a graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is always at least as great as the largest eigenvalue <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda}"/> of its adjacency matrix <img alt="{A_G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_G}"/>. For a <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/>-regular graph they are equal. Huang’s first trick is to note that the classic proof of this also allows <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> values on edges:</p>
<blockquote><p><b>Lemma 2</b> <em> Let <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> be a symmetric matrix obtained from <img alt="{A_G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_G%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A_G}"/> by multiplying some entries by <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{-1}"/> and <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\lambda}"/> any of its eigenvalues. Then <img alt="{d(G) \geq |\lambda|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29+%5Cgeq+%7C%5Clambda%7C%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{d(G) \geq |\lambda|}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Choose an eigenvector <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> such that <img alt="{Av = \lambda v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAv+%3D+%5Clambda+v%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Av = \lambda v}"/> and take an index <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> that maximizes <img alt="{|v_i|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_i%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_i|}"/>. Then </p>
<p align="center"><img alt="\displaystyle  |\lambda v_i| = |(A v)_i| = |\sum_j A_{i,j} v_j| \leq |\sum_j A_{i,j}| \cdot |v_i| \leq \sum_{(i,j) \in E(G)} |A_{i,j}|\cdot |v_i| \leq d(G)|v_i|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5Clambda+v_i%7C+%3D+%7C%28A+v%29_i%7C+%3D+%7C%5Csum_j+A_%7Bi%2Cj%7D+v_j%7C+%5Cleq+%7C%5Csum_j+A_%7Bi%2Cj%7D%7C+%5Ccdot+%7Cv_i%7C+%5Cleq+%5Csum_%7B%28i%2Cj%29+%5Cin+E%28G%29%7D+%7CA_%7Bi%2Cj%7D%7C%5Ccdot+%7Cv_i%7C+%5Cleq+d%28G%29%7Cv_i%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |\lambda v_i| = |(A v)_i| = |\sum_j A_{i,j} v_j| \leq |\sum_j A_{i,j}| \cdot |v_i| \leq \sum_{(i,j) \in E(G)} |A_{i,j}|\cdot |v_i| \leq d(G)|v_i|. "/></p>
<p>Dividing out <img alt="{|v_i|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_i%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_i|}"/> gives the lemma. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p/><p><br/>
So now what we want to do is find conditions that force <img alt="{\lambda = \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda+%3D+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda = \sqrt{n}}"/> when <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is a <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/>-vertex subgraph of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube with <img alt="{m \geq \frac{N}{2} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%5Cgeq+%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m \geq \frac{N}{2} + 1}"/>, where <img alt="{N = 2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N = 2^n}"/>. The trick that Huang realized is that he could do this by making <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> sit inside a matrix <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/> with at least <img alt="{\frac{N}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2}}"/> eigenvalues of <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/>. </p>
<p>
To see how, form <img alt="{A_{N-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{N-1}}"/> by knocking out the last row and column of <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>. Since <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/> and <img alt="{A_{N-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{N-1}}"/> are both real and symmetric, their eigenvalues are real, so we can order them <img alt="{\lambda_1,\dots,\lambda_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1%2C%5Cdots%2C%5Clambda_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_1,\dots,\lambda_N}"/> and <img alt="{\mu_1,\dots,\mu_{N-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu_1%2C%5Cdots%2C%5Cmu_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu_1,\dots,\mu_{N-1}}"/> in nonincreasing order. The basic fact is that they always <em>interlace</em>: </p>
<p align="center"><img alt="\displaystyle  \lambda_1 \geq \mu_1 \geq \lambda_2 \geq \mu_2 \geq \lambda_3 \geq \cdots \geq \mu_{N-1} \geq \lambda_N. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_1+%5Cgeq+%5Cmu_1+%5Cgeq+%5Clambda_2+%5Cgeq+%5Cmu_2+%5Cgeq+%5Clambda_3+%5Cgeq+%5Ccdots+%5Cgeq+%5Cmu_%7BN-1%7D+%5Cgeq+%5Clambda_N.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \lambda_1 \geq \mu_1 \geq \lambda_2 \geq \mu_2 \geq \lambda_3 \geq \cdots \geq \mu_{N-1} \geq \lambda_N. "/></p>
<p>See <a href="https://arxiv.org/pdf/math/0502408.pdf">this</a> for a one-page proof. The neat point is that you can repeat this: if you get <img alt="{A''}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A''}"/> by knocking out another row and corresponding column, and <img alt="{[\nu_i]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B%5Cnu_i%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[\nu_i]}"/> are its eigenvalues in order, then </p>
<p align="center"><img alt="\displaystyle  \mu_1 \geq \nu_1 \geq \mu_2 \geq \nu_2 \geq \mu_3 \cdots. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmu_1+%5Cgeq+%5Cnu_1+%5Cgeq+%5Cmu_2+%5Cgeq+%5Cnu_2+%5Cgeq+%5Cmu_3+%5Ccdots.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mu_1 \geq \nu_1 \geq \mu_2 \geq \nu_2 \geq \mu_3 \cdots. "/></p>
<p>It follows that <img alt="{\lambda_1 \geq \nu_1 \geq \lambda_3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1+%5Cgeq+%5Cnu_1+%5Cgeq+%5Clambda_3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_1 \geq \nu_1 \geq \lambda_3}"/>. If you do this again, you get a matrix whose leading eigenvalue is still at least as big as <img alt="{\lambda_4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_4}"/>. Do it <img alt="{\frac{N}{2} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2} - 1}"/> times inside <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>, and you’re still above <img alt="{\lambda_{N/2}(A_N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_%7BN%2F2%7D%28A_N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_{N/2}(A_N)}"/>, which we just said we will arrange to be <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/>. Thus if we knock out the <img alt="{\frac{N}{2} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2} - 1}"/> white nodes, we will get the graph on the red nodes with adjacency matrix <img alt="{A_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_m}"/> and conclude: </p>
<p align="center"><img alt="\displaystyle  \lambda_1(A_N) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_1%28A_N%29+%5Cgeq+%5Clambda_1%28A_m%29+%5Cgeq+%5Clambda_%7BN%2F2%7D%28A_N%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \lambda_1(A_N) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) "/></p>
<p>Plugging into the lemma gives: </p>
<p align="center"><img alt="\displaystyle  d(G) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) = \sqrt{n}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d%28G%29+%5Cgeq+%5Clambda_1%28A_m%29+%5Cgeq+%5Clambda_%7BN%2F2%7D%28A_N%29+%3D+%5Csqrt%7Bn%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  d(G) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) = \sqrt{n}. "/></p>
<p>(In fact, as also <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813084">noted</a> on Scott’s blog, this case of interlacing can be inferred from simpler reasoning—but our point is that the interlacing theorem was in Huang’s bag of tricks.) </p>
<p>
</p><p/><h2> Building the Matrix </h2><p/>
<p/><p>
Finally, how do we lay hands on <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>? We want a matrix of trace zero such that <img alt="{A_N^2 = nI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%5E2+%3D+nI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N^2 = nI}"/>. Then all its eigenvalues are <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/> and <img alt="{-\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-\sqrt{n}}"/>.  They come in equal numbers because they sum to the trace which is zero. So we will have <img alt="{N/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N/2}"/> eigenvalues of <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/>, as needed. And we would want <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/> to be the matrix of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube but that doesn’t work: each <img alt="{i,j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i,j}"/> entry of its square counts all paths of length 2 from node <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> to node <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> and that number can be nonzero.</p>
<p>
This is where the trick of putting <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> on edges comes in, and we can explain it in a way familiar from quantum. We arrange that every 4-cycle of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube has exactly one edge with <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/>. Then the pairs of paths from one corner to the opposite corner will always <em>cancel</em>, leaving <img alt="{A^2_{i,j} = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E2_%7Bi%2Cj%7D+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^2_{i,j} = 0}"/> whenever <img alt="{i \neq j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%5Cneq+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i \neq j}"/>. And <img alt="{A^2_{i,j} = n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E2_%7Bi%2Cj%7D+%3D+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^2_{i,j} = n}"/> because there are <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> ways to go out and come back along the same edge, always contributing <img alt="{1\cdot 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%5Ccdot+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1\cdot 1}"/> or <img alt="{(-1)\cdot(-1) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5Ccdot%28-1%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1)\cdot(-1) = 1}"/> either way. Huang defines the needed labeling explicitly by the recursion: </p>
<p align="center"><img alt="\displaystyle  A_2 = \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix},\quad\text{and for } N &gt; 2,\quad A_N = \begin{bmatrix} A_{N/2} &amp; I \\ I &amp; -A_{N/2} \end{bmatrix}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A_2+%3D+%5Cbegin%7Bbmatrix%7D+0+%26+1+%5C%5C+1+%26+0+%5Cend%7Bbmatrix%7D%2C%5Cquad%5Ctext%7Band+for+%7D+N+%3E+2%2C%5Cquad+A_N+%3D+%5Cbegin%7Bbmatrix%7D+A_%7BN%2F2%7D+%26+I+%5C%5C+I+%26+-A_%7BN%2F2%7D+%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  A_2 = \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix},\quad\text{and for } N &gt; 2,\quad A_N = \begin{bmatrix} A_{N/2} &amp; I \\ I &amp; -A_{N/2} \end{bmatrix}. "/></p>
<p>This puts a <img alt="{-}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-}"/> sign on exactly one-fourth of the entries in the needed way. OK, we changed Huang’s subscripts for consistency with “<img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>” above and also to note that the basis could be <img alt="{A_1 = [0]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_1+%3D+%5B0%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_1 = [0]}"/>.  Anyway, he verifies <img alt="{A_N^2 = nI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%5E2+%3D+nI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N^2 = nI}"/> directly by simple algebra and induction.  That’s it—that’s the proof.</p>
<p>
Why was it hard to spot? Dick and I believe it was the <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> trick. In the 1980s, I thought about ways to convert undirected graphs into directed ones by putting arrows on the edges, but not <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> signs. The chance of thinking of it maybe rises with knowing quantum ideas such as interference and amplification. Now we can see, OK, <img alt="{A_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_2}"/> is the quantum NOT gate and the recursion treats signs in similar fashion to the recursion defining Hadamard matrices.  The matrix <img alt="{\frac{1}{\sqrt{n}}A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7DA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{1}{\sqrt{n}}A_N}"/> is unitary, so it defines a quantum operator. This all goes to our main point about having tools at one’s command—the more tools, the better. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Huang’s theorem still leaves a gap between a quadratic lower bound and his 4th-power upper bound (my longer <a href="https://cse.buffalo.edu/~regan/cse705/wsensitivity.pdf">draft</a> lays this out).  Can this gap be closed?  In discussing this, Huang notes that his spectral methods need not be confined to sub-matrices of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube, and our thoughts of involving quantum are similar. Can quantum tools improve the results even further?</p>
<p/></font></font></div>
    </content>
    <updated>2019-07-12T10:51:42Z</updated>
    <published>2019-07-12T10:51:42Z</published>
    <category term="algorithms"/>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="Teaching"/>
    <category term="trick"/>
    <category term="Boolean functions"/>
    <category term="Boolean sensitivity conjecture"/>
    <category term="complexity"/>
    <category term="concrete complexity"/>
    <category term="eigenvalues"/>
    <category term="Hao Huang"/>
    <category term="linear algebra"/>
    <category term="matrices"/>
    <category term="quantum"/>
    <category term="spectral methods"/>
    <category term="tricks"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-07-14T04:20:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1705625191398821823</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1705625191398821823/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/degree-and-sensitivity.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1705625191398821823" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1705625191398821823" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/degree-and-sensitivity.html" rel="alternate" type="text/html"/>
    <title>Degree and Sensitivity</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Hao Huang's <a href="https://arxiv.org/abs/1907.00847">proof of the sensitivity conjecture</a> that I <a href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html">posted on last week</a> relied on a 1992 <a href="https://doi.org/10.1016/0097-3165(92)90060-8">result of Gotsman and Linial</a>. Let's talk about that result.<br/>
<br/>
Consider the set S={-1,1}<sup>n</sup>. The hypercube of dimension n is the graph with vertex set S and an edge between x = (x<sub>1</sub>,…,x<sub>n</sub>) and y = (y<sub>1</sub>,…,y<sub>n</sub>) in S if there is exactly one i such that x<sub>i</sub> ≠ y<sub>i</sub>. Every vertex has degree n.<br/>
<br/>
We say a vertex x is odd if x has an odd number of -1 coordinates, even otherwise. Every edge joins an odd and even vertex.<br/>
<br/>
Let f be a function mapping S to {-1,1}. The sensitivity of f on x is the number of i such that f(x<sub>1</sub>,…,x<sub>i</sub>,…,x<sub>n</sub>) ≠ f(x<sub>1</sub>,…,-x<sub>i</sub>,…,x<sub>n</sub>). The sensitivity of f is the maximum over all x in S of the sensitivity of f on x.<br/>
<br/>
Let g be the same function as f except that we flip the value on all odd vertices. Notice now that the sensitivity of f on x is the number of i such that g(x<sub>1</sub>,…,x<sub>i</sub>,…,x<sub>n</sub>) = g(x<sub>1</sub>,…,-x<sub>i</sub>,…,x<sub>n</sub>).<br/>
<br/>
Let G be the induced subgraph of vertices of x such that g(x)=-1 and H be induced subgraph on the set of x such that g(x)=1. The sensitivity of f is the maximum number of neighbors of any vertex in G or H.<br/>
<br/>
Consider f as a multilinear polynomial over the reals. The sensitivity conjecture states there is some α&gt;0 such that if f has degree n then f has sensitivity at least n<sup>α</sup>.<br/>
<br/>
Note g(x<sub>1</sub>,…,x<sub>n</sub>)=f(x<sub>1</sub>,…,x<sub>n</sub>)x<sub>1</sub>⋯x<sub>n</sub>. If f has a degree n term, the variables in that term cancel out on S (since x<sub>i</sub><sup>2</sup>=1) and the constant of the degree n term of f becomes the constant term of g. The constant term is just the expected value, so f has full degree iff g is unbalanced.<br/>
<br/>
GL Assumption: Suppose you have a partition of the hypercube into sets A and B with |A| ≠ |B|, and let G and H be the induced subgraphs of A and B. Then there is some constant α&gt;0 such that there is a node of A or B with at least n<sup>α</sup> neighbors.<br/>
<br/>
The above argument, due to Gotsman and Linial, shows that the GL assumption is equivalent to the sensitivity conjecture.<br/>
<br/>
Huang proved that given any subset A of the vertices of a hypercube with |A|&gt;2<sup>n</sup>/2 the induced subgraph has a node of degree at least n<sup>1/2</sup>. Since either A or B in the GL assumption has size greater than 2<sup>n</sup>/2, Huang's result gives the sensitivity conjecture.</div>
    </content>
    <updated>2019-07-11T17:54:00Z</updated>
    <published>2019-07-11T17:54:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-13T10:51:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=656</id>
    <link href="https://emanueleviola.wordpress.com/2019/07/10/non-abelian-combinatorics-and-communication-complexity/" rel="alternate" type="text/html"/>
    <title>Non-abelian combinatorics and communication complexity</title>
    <summary>Below and here in pdf is a survey I am writing for SIGACT, due next week.  Comments would be very helpful. Finite groups provide an amazing wealth of problems of interest to complexity theory. And complexity theory also provides a useful viewpoint of group-theoretic notions, such as what it means for a group to be […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Below and <a href="http://www.ccs.neu.edu/home/viola/papers/viola-sigact-snafu.pdf">here in pdf</a> is a survey I am writing for SIGACT, due next week.  Comments would be very helpful.</p>
<hr/>
<p style="text-align: justify;">Finite groups provide an amazing wealth of problems of interest to complexity theory. And complexity theory also provides a useful viewpoint of group-theoretic notions, such as what it means for a group to be “far from abelian.” The general problem that we consider in this survey is that of computing a <em>group product</em> <img alt="g=x_{1}\cdot x_{2}\cdot \cdots \cdot x_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3Dx_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+%5Ccdots+%5Ccdot+x_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=x_{1}\cdot x_{2}\cdot \cdots \cdot x_{n}"/> over a finite group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. Several variants of this problem are considered in this survey and in the literature, including in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XKrohnMR66">KMR66</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBarrington89">Bar89</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBen-OrC92">BC92</a>, <a href="https://emanueleviola.wordpress.com/feed/#XImmermanL95">IL95</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBGKL03">BGKL03</a>, <a href="https://emanueleviola.wordpress.com/feed/#XPRS97">PRS97</a>, <a href="https://emanueleviola.wordpress.com/feed/#XAmbainis96">Amb96</a>, <a href="https://emanueleviola.wordpress.com/feed/#XAmbainisL00">AL00</a>, <a href="https://emanueleviola.wordpress.com/feed/#XRaz00">Raz00</a>, <a href="https://emanueleviola.wordpress.com/feed/#XMilesV-leak">MV13</a>, <a href="https://emanueleviola.wordpress.com/feed/#XMiles14">Mil14</a>, <a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>.</p>
<p style="text-align: justify;">Some specific, natural computational problems related to <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> are, from hardest to easiest:</p>
<p style="text-align: justify;">(1) Computing <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/>,</p>
<p style="text-align: justify;">(2) Deciding if <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/>, where <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/> is the identity element of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>, and</p>
<p style="text-align: justify;">(3) Deciding if <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/> under the promise that either <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/> or <img alt="g=h" class="latex" src="https://s0.wp.com/latex.php?latex=g%3Dh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=h"/> for a fixed <img alt="h\ne 1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cne+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\ne 1_{G}"/>.</p>
<p style="text-align: justify;">Problem (3) is from <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMilesV-leak">MV13</a>]</span>. The focus of this survey is on (2) and (3).</p>
<p style="text-align: justify;">We work in the model of <em>communication complexity </em><span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XYao79">Yao79</a>]</span>, with which we assume familiarity. For background see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XKuN97">KN97</a>, <a href="https://emanueleviola.wordpress.com/feed/#XRaoY2019">RY19</a>]</span>. Briefly, the terms <img alt="x_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i}"/> in a product <img alt="x_{1}\cdot x_{2}\cdot \cdots \cdot x_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+%5Ccdots+%5Ccdot+x_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot x_{2}\cdot \cdots \cdot x_{n}"/> will be partitioned among collaborating parties – in several ways – and we shall bound the number of bits that the parties need to exchange to solve the problem.</p>
<p style="text-align: justify;"><b>Organization</b>.</p>
<p style="text-align: justify;">We begin in Section <a href="https://emanueleviola.wordpress.com/feed/#x1-20002">2<!--tex4ht:ref: sec:Two-parties --></a> with two-party communication complexity. In Section <a href="https://emanueleviola.wordpress.com/feed/#x1-30003">3<!--tex4ht:ref: sec:Proof-of-Gowers-Viola --></a> we give a streamlined proof, except for a step that is only sketched, of a result of Gowers and the author <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int">GV15</a>, <a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-2">GVb</a>]</span> about interleaved group products. In particular we present an alternative proof, communicated to us by Will Sawin, of a lemma from <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. We then consider two models of three-party communication. In Section <a href="https://emanueleviola.wordpress.com/feed/#x1-70004">4<!--tex4ht:ref: sec:Three-parties,-number-in-hand --></a> we consider number-in-hand protocols, and we relate the communication complexity to so-called <em>quasirandom groups</em> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBabaiNP08">BNP08</a>]</span>. In Section <a href="https://emanueleviola.wordpress.com/feed/#x1-140006">6<!--tex4ht:ref: sec:Three-parties,-number-on-forehea --></a> we consider number-in-hand protocols, and specifically the problem of separating deterministic and randomized communication. In Section <a href="https://emanueleviola.wordpress.com/feed/#x1-150007">7<!--tex4ht:ref: sec:The-corners-theorem --></a> we give an exposition of a result by Austin <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAustin2016">Aus16</a>]</span>, and show that it implies a separation that matches the state-of-the-art <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XBeameDPW10">BDPW10</a>]</span> but applies to a different problem.</p>
<p style="text-align: justify;">Some of the sections follow closely a set of lectures by the author <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#Xviola-special-topics17">Vio17</a>]</span>; related material can also be found in the blog posts <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#Xviola-blog-mixing-in-groups">Vioa</a>, <a href="https://emanueleviola.wordpress.com/feed/#Xviola-blog-mixing-in-groups-ii">Viob</a>]</span>. One of the goals of this survey is to present this material in a more organized matter, in addition to including new material.</p>
<h3 class="sectionHead"><span class="titlemark">2 </span> <a id="x1-20002"/>Two parties</h3>
<p style="text-align: justify;">Let <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> be a group and let us start by considering the following basic communication task. Alice gets an element <img alt="x\in G" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in G"/> and Bob gets an element <img alt="y\in G" class="latex" src="https://s0.wp.com/latex.php?latex=y%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y\in G"/> and their goal is to check if <img alt="x\cdot y=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y=1_{G}"/>. How much communication do they need? Well, <img alt="x\cdot y=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y=1_{G}"/> is equivalent to <img alt="x=y^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Dy%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=y^{-1}"/>. Because Bob can compute <img alt="y^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=y%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y^{-1}"/> without communication, this problem is just a rephrasing of the <em>equality</em> problem, which has a randomized protocol with constant communication. This holds for any group.</p>
<p style="text-align: justify;">The same is true if Alice gets two elements <img alt="x_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}"/> and <img alt="x_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{2}"/> and they need to check if <img alt="x_{1}\cdot y\cdot x_{2}=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y%5Ccdot+x_%7B2%7D%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot y\cdot x_{2}=1_{G}"/>. Indeed, it is just checking equality of <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> and <img alt="x_{1}^{-1}\cdot x_{2}^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5E%7B-1%7D%5Ccdot+x_%7B2%7D%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}^{-1}\cdot x_{2}^{-1}"/>, and again Alice can compute the latter without communication.</p>
<p style="text-align: justify;">Things get more interesting if both Alice and Bob get two elements and they need to check if the <em>interleaved product</em> of the elements of Alice and Bob equals <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/>, that is, if</p>
<div style="text-align: center;"><img alt="\begin{aligned} x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}=1_{G}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D%3D1_%7BG%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}=1_{G}. \end{aligned}"/></div>
<p style="text-align: justify;">Now the previous transformations don’t help anymore. In fact, the complexity depends on the group. If it is abelian then the elements can be reordered and the problem is equivalent to checking if <img alt="(x_{1}\cdot x_{2})\cdot (y_{1}\cdot y_{2})=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%28x_%7B1%7D%5Ccdot+x_%7B2%7D%29%5Ccdot+%28y_%7B1%7D%5Ccdot+y_%7B2%7D%29%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x_{1}\cdot x_{2})\cdot (y_{1}\cdot y_{2})=1_{G}"/>. Again, Alice can compute <img alt="x_{1}\cdot x_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+x_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot x_{2}"/> without communication, and Bob can compute <img alt="y_{1}\cdot y_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B1%7D%5Ccdot+y_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{1}\cdot y_{2}"/> without communication. So this is the same problem as before and it has a constant communication protocol.</p>
<p style="text-align: justify;">For non-abelian groups this reordering cannot be done, and the problem seems hard. This can be formalized for a class of groups that are “far from abelian” – or we can take this result as a definition of being far from abelian. One of the groups that works best in this sense is the following, first constructed by Galois in the 1830’s.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-2001r1"/> Definition 1. </span>The<em> special linear group </em><img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/> is the group of <img alt="2\times 2" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ctimes+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2\times 2"/> invertible matrices over the field <img alt="\mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{F} _{q}"/> with determinant <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">The following result was asked in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMilesV-leak">MV13</a>]</span> and was proved in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. <a id="x1-2002r1"/></p>
<p style="text-align: justify;"><b>Theorem 1.</b> Let <img alt="G=SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DSL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=SL(2,q)"/> and let <img alt="h\ne 1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cne+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\ne 1_{G}"/>. Suppose Alice receives <img alt="x_{1},x_{2}\in G" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1},x_{2}\in G"/> and Bob receives <img alt="y_{1},y_{2}\in G" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B1%7D%2Cy_%7B2%7D%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{1},y_{2}\in G"/>. They are promised that <img alt="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}"/> either equals <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/> or <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/>. Deciding which case it is requires randomized communication <img alt="\Omega (\log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log |G|)"/>.</p>
<p style="text-align: justify;">This bound is tight as Alice can send her input, taking <img alt="O(\log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\log |G|)"/> bits. We present the proof of this theorem in the next section.</p>
<p style="text-align: justify;">Similar results are known for other groups as well, see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span> and <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XShalev16">Sha16</a>]</span>. For example, one group that is “between” abelian groups and <img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/> is the following.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-2003r2"/> Definition 2. </span>The<em> alternating group</em> <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/> is the group of even permutations of <img alt="1,2,\ldots ,n" class="latex" src="https://s0.wp.com/latex.php?latex=1%2C2%2C%5Cldots+%2Cn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1,2,\ldots ,n"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">If we work over <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/> instead of <img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/> in Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a> then the communication complexity is <img alt="\Omega (\log \log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log \log |G|)"/> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XShalev16">Sha16</a>]</span>. The latter bound is tight <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMilesV-leak">MV13</a>]</span>: with knowledge of <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/>, the parties can agree on an element <img alt="a\in {1,2,\ldots ,n}" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Cin+%7B1%2C2%2C%5Cldots+%2Cn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\in {1,2,\ldots ,n}"/> such that <img alt="h(a)\ne a" class="latex" src="https://s0.wp.com/latex.php?latex=h%28a%29%5Cne+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h(a)\ne a"/>. Hence they only need to keep track of the image <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/>. This takes communication <img alt="O(\log n)=O(\log \log |A_{n}|)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clog+n%29%3DO%28%5Clog+%5Clog+%7CA_%7Bn%7D%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\log n)=O(\log \log |A_{n}|)"/> because <img alt="|A_{n}|=n!/2." class="latex" src="https://s0.wp.com/latex.php?latex=%7CA_%7Bn%7D%7C%3Dn%21%2F2.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|A_{n}|=n!/2."/> In more detail, the protocol is as follows. First Bob sends <img alt="y_{2}(a)" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B2%7D%28a%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{2}(a)"/>. Then Alice sends <img alt="x_{2}y_{2}(a)" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B2%7Dy_%7B2%7D%28a%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{2}y_{2}(a)"/>. Then Bob sends <img alt="y_{1}x_{2}y_{2}(a)" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B1%7Dx_%7B2%7Dy_%7B2%7D%28a%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{1}x_{2}y_{2}(a)"/> and finally Alice can check if <img alt="x_{1}y_{1}x_{2}y_{2}(a)=a" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7Dy_%7B1%7Dx_%7B2%7Dy_%7B2%7D%28a%29%3Da&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}y_{1}x_{2}y_{2}(a)=a"/>.</p>
<p style="text-align: justify;">Interestingly, to decide if <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/> without the promise a stronger lower bound can be proved for many groups, including <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/>, see Corollary <a href="https://emanueleviola.wordpress.com/feed/#x1-2006r3">3<!--tex4ht:ref: cor:A_n-bound --></a> below.</p>
<p style="text-align: justify;">In general, it seems an interesting open problem to try to understand for which groups Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a> applies. For example, is the communication large for every quasirandom group <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>]</span>?</p>
<p style="text-align: justify;">Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a> and the corresponding results for other groups also scale with the length of the product: for example deciding if <img alt="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}\cdots x_{n}\cdot y_{n}=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D%5Ccdots+x_%7Bn%7D%5Ccdot+y_%7Bn%7D%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}\cdots x_{n}\cdot y_{n}=1_{G}"/> over <img alt="G=SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DSL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=SL(2,q)"/> requires communication <img alt="\Omega (n\log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n\log |G|)"/> which is tight.</p>
<p style="text-align: justify;">A strength of the above results is that they hold for any choice of <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> in the promise. This makes them equivalent to certain <img alt="mixing" class="latex" src="https://s0.wp.com/latex.php?latex=mixing&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="mixing"/> results, discussed below in Section <a href="https://emanueleviola.wordpress.com/feed/#x1-120005.0.1">5.0.1<!--tex4ht:ref: subsec:-mixing --></a>. Next we prove two other lower bounds that do not have this property and can be obtained by reduction from <em>disjointness</em>. First we show that for any non-abelian group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> there exists an element <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> such that deciding if <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/> or <img alt="g=h" class="latex" src="https://s0.wp.com/latex.php?latex=g%3Dh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=h"/> requires communication linear in the length of the product. Interestingly, the proof works for any non-abelian group. The choice of <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> is critical, as for some <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> and <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> the problem is easy. For example: take any group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> and consider <img alt="H:=G\times \mathbb {Z}_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=H%3A%3DG%5Ctimes+%5Cmathbb+%7BZ%7D_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H:=G\times \mathbb {Z}_{2}"/> where <img alt="\mathbb {Z}_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BZ%7D_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {Z}_{2}"/> is the group of integers with addition modulo <img alt="2" class="latex" src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2"/>. Distinguishing between <img alt="1_{H}=(1_{G},0)" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BH%7D%3D%281_%7BG%7D%2C0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{H}=(1_{G},0)"/> and <img alt="h=(1_{G},1)" class="latex" src="https://s0.wp.com/latex.php?latex=h%3D%281_%7BG%7D%2C1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h=(1_{G},1)"/> amounts to computing the parity of (the <img alt="\mathbb {Z}_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BZ%7D_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {Z}_{2}"/> components of) the input, which takes constant communication. <a id="x1-2004r2"/></p>
<p style="text-align: justify;"><b>Theorem 2.</b> Let <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> be a non-abelian group. There exists <img alt="h\in G" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\in G"/> such that the following holds. Suppose Alice receives <img alt="x_{1},x_{2},\ldots ,x_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1},x_{2},\ldots ,x_{n}"/> and receives <img alt="y_{1},y_{2},\ldots ,y_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B1%7D%2Cy_%7B2%7D%2C%5Cldots+%2Cy_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{1},y_{2},\ldots ,y_{n}"/>. They are promised that <img alt="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}\cdot \cdots \cdot x_{n}\cdot y_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D%5Ccdot+%5Ccdots+%5Ccdot+x_%7Bn%7D%5Ccdot+y_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}\cdot \cdots \cdot x_{n}\cdot y_{n}"/> either equals <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/> or <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/>. Deciding which case it is requires randomized communication <img alt="\Omega (n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n)"/>.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We reduce from <em>unique set-disjointness</em>, defined below. For the reduction we encode the And of two bits <img alt="s,t\in \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=s%2Ct%5Cin+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s,t\in \{0,1\}"/> as a group product. This encoding is similar to the famous puzzle that asks to hang a picture on a wall with two nails in such a way that the picture falls if either one of the nails is removed. Since <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> is non-abelian, there exist <img alt="a,b\in G" class="latex" src="https://s0.wp.com/latex.php?latex=a%2Cb%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a,b\in G"/> such that <img alt="a\cdot b\neq b\cdot a" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+b%5Cneq+b%5Ccdot+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot b\neq b\cdot a"/>, and in particular <img alt="a\cdot b\cdot a^{-1}\cdot b^{-1}=h" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+b%5Ccdot+a%5E%7B-1%7D%5Ccdot+b%5E%7B-1%7D%3Dh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot b\cdot a^{-1}\cdot b^{-1}=h"/> with <img alt="h\neq 1" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cneq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\neq 1"/>. We can use this fact to encode the And of <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> and <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> as</p>
<div style="text-align: center;"><img alt="\begin{aligned} a^{s}\cdot b^{t}\cdot a^{-s}\cdot b^{-t}=\begin {cases} 1~~\text {if And\ensuremath {(s,t)=0}}\\ h~~\text {otherwise} \end {cases}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a%5E%7Bs%7D%5Ccdot+b%5E%7Bt%7D%5Ccdot+a%5E%7B-s%7D%5Ccdot+b%5E%7B-t%7D%3D%5Cbegin+%7Bcases%7D+1%7E%7E%5Ctext+%7Bif+And%5Censuremath+%7B%28s%2Ct%29%3D0%7D%7D%5C%5C+h%7E%7E%5Ctext+%7Botherwise%7D+%5Cend+%7Bcases%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} a^{s}\cdot b^{t}\cdot a^{-s}\cdot b^{-t}=\begin {cases} 1~~\text {if And\ensuremath {(s,t)=0}}\\ h~~\text {otherwise} \end {cases}. \end{aligned}"/></div>
<p style="text-align: justify;">In the disjointness problem Alice and Bob get inputs <img alt="x,y\in \{0,1\}^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in \{0,1\}^{n}"/> respectively, and they wish to check if there exists an <img alt="i\in [n]" class="latex" src="https://s0.wp.com/latex.php?latex=i%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i\in [n]"/> such that <img alt="x_{i}\land y_{i}=1" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D%5Cland+y_%7Bi%7D%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i}\land y_{i}=1"/>. If you think of <img alt="x,y" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y"/> as characteristic vectors of sets, this problem is asking if the sets have a common element or not. The communication of this problem is <img alt="\Omega (n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n)"/> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XKalyanasundaramS92">KS92</a>, <a href="https://emanueleviola.wordpress.com/feed/#XRazborov92">Raz92</a>]</span>. Moreover, in the “unique” variant of this problem where the number of such <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>’s is 0 or 1, the same lower bound <img alt="\Omega (n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n)"/> still applies. This follows from <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XKalyanasundaramS92">KS92</a>, <a href="https://emanueleviola.wordpress.com/feed/#XRazborov92">Raz92</a>]</span> – see also Proposition 3.3 in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAMS99">AMS99</a>]</span>. For more on disjointness see the surveys <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XSherstov14-35years">She14</a>, <a href="https://emanueleviola.wordpress.com/feed/journals/sigact/ChattopadhyayP10">CP10</a>]</span>.</p>
<p style="text-align: justify;">We will reduce unique disjointness to group products. For <img alt="x,y\in \{0,1\}^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in \{0,1\}^{n}"/> we produce inputs for the group problem as follows:</p>
<div style="text-align: center;"><img alt="\begin{aligned} x &amp; \rightarrow (a^{x_{1}},a^{-x_{1}},\ldots ,a^{x_{n}},a^{-x_{n}})\\ y &amp; \rightarrow (b^{y_{1}},b^{-y_{1}},\ldots ,b^{y_{n}},b^{-y_{n}}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x+%26+%5Crightarrow+%28a%5E%7Bx_%7B1%7D%7D%2Ca%5E%7B-x_%7B1%7D%7D%2C%5Cldots+%2Ca%5E%7Bx_%7Bn%7D%7D%2Ca%5E%7B-x_%7Bn%7D%7D%29%5C%5C+y+%26+%5Crightarrow+%28b%5E%7By_%7B1%7D%7D%2Cb%5E%7B-y_%7B1%7D%7D%2C%5Cldots+%2Cb%5E%7By_%7Bn%7D%7D%2Cb%5E%7B-y_%7Bn%7D%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x &amp; \rightarrow (a^{x_{1}},a^{-x_{1}},\ldots ,a^{x_{n}},a^{-x_{n}})\\ y &amp; \rightarrow (b^{y_{1}},b^{-y_{1}},\ldots ,b^{y_{n}},b^{-y_{n}}). \end{aligned}"/></div>
<p style="text-align: justify;">The group product becomes</p>
<div style="text-align: center;"><img alt="\begin{aligned} \underbrace {a^{x_{1}}\cdot b^{y_{1}}\cdot a^{-x_{1}}\cdot b^{-y_{1}}}_{\text {1 bit}}\cdots \cdots a^{x_{n}}\cdot b^{y_{n}}\cdot a^{-x_{n}}\cdot b^{-y_{n}}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cunderbrace+%7Ba%5E%7Bx_%7B1%7D%7D%5Ccdot+b%5E%7By_%7B1%7D%7D%5Ccdot+a%5E%7B-x_%7B1%7D%7D%5Ccdot+b%5E%7B-y_%7B1%7D%7D%7D_%7B%5Ctext+%7B1+bit%7D%7D%5Ccdots+%5Ccdots+a%5E%7Bx_%7Bn%7D%7D%5Ccdot+b%5E%7By_%7Bn%7D%7D%5Ccdot+a%5E%7B-x_%7Bn%7D%7D%5Ccdot+b%5E%7B-y_%7Bn%7D%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \underbrace {a^{x_{1}}\cdot b^{y_{1}}\cdot a^{-x_{1}}\cdot b^{-y_{1}}}_{\text {1 bit}}\cdots \cdots a^{x_{n}}\cdot b^{y_{n}}\cdot a^{-x_{n}}\cdot b^{-y_{n}}. \end{aligned}"/></div>
<p style="text-align: justify;">If there isn’t an <img alt="i\in [n]" class="latex" src="https://s0.wp.com/latex.php?latex=i%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i\in [n]"/> such that <img alt="x_{i}\land y_{i}=1" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D%5Cland+y_%7Bi%7D%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i}\land y_{i}=1"/>, then for each <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> the term <img alt="a^{x_{i}}\cdot b^{y_{i}}\cdot a^{-x_{i}}\cdot b^{-y_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%7Bx_%7Bi%7D%7D%5Ccdot+b%5E%7By_%7Bi%7D%7D%5Ccdot+a%5E%7B-x_%7Bi%7D%7D%5Ccdot+b%5E%7B-y_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a^{x_{i}}\cdot b^{y_{i}}\cdot a^{-x_{i}}\cdot b^{-y_{i}}"/> is <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/>, and thus the whole product is 1.</p>
<p style="text-align: justify;">Otherwise, there exists a unique <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> such that <img alt="x_{i}\land y_{i}=1" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D%5Cland+y_%7Bi%7D%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i}\land y_{i}=1"/> and thus the product will be <img alt="1\cdots 1\cdot h\cdot 1\cdots 1=h" class="latex" src="https://s0.wp.com/latex.php?latex=1%5Ccdots+1%5Ccdot+h%5Ccdot+1%5Ccdots+1%3Dh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1\cdots 1\cdot h\cdot 1\cdots 1=h"/>, with <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> being in the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>-th position. If Alice and Bob can check if the above product is equal to 1, they can also solve the unique set disjointness problem, and thus the lower bound applies for the former. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">We required the uniqueness property, because otherwise we might get a product <img alt="h^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=h%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h^{c}"/> that could be equal to 1 in some groups.</p>
<p style="text-align: justify;">Next we prove a result for products of length just <img alt="4" class="latex" src="https://s0.wp.com/latex.php?latex=4&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="4"/>; it applies to non-abelian groups of the form <img alt="G=H^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DH%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=H^{n}"/> and not with the promise. <a id="x1-2005r3"/></p>
<p style="text-align: justify;"><b>Theorem 3.</b> Let <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> be a non-abelian group and consider <img alt="G=H^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DH%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=H^{n}"/>. Suppose Alice receives <img alt="x_{1},x_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1},x_{2}"/> and Bob receives <img alt="y_{1},y_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B1%7D%2Cy_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{1},y_{2}"/>. Deciding if <img alt="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}=1_{G}"/> requires randomized communication <img alt="\Omega (n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n)"/>.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>The proof is similar to the proof of Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2004r2">2<!--tex4ht:ref: thm:for-every-non-abelian --></a>. We use coordinate <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> to encode bit <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> of the disjointness instance. If there is no intersection in the latter, the product will be <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/>. Otherwise, at least some coordinate will be <img alt="\ne 1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cne+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ne 1_{G}"/>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">As a corollary we can prove a lower bound for <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/>.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-2006r3"/> Corollary 3. </span>Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2005r3">3<!--tex4ht:ref: thm:G-to-the-n-hard --></a> holds for <img alt="G=A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DA_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=A_{n}"/>.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Note that <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/> contains <img alt="(A_{4})^{\lfloor n/4\rfloor }" class="latex" src="https://s0.wp.com/latex.php?latex=%28A_%7B4%7D%29%5E%7B%5Clfloor+n%2F4%5Crfloor+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(A_{4})^{\lfloor n/4\rfloor }"/> and that <img alt="A_{4}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{4}"/> is not abelian. Apply Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2005r3">3<!--tex4ht:ref: thm:G-to-the-n-hard --></a>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2005r3">3<!--tex4ht:ref: thm:G-to-the-n-hard --></a> is tight for constant-size <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. We do not know if Corollary <a href="https://emanueleviola.wordpress.com/feed/#x1-2006r3">3<!--tex4ht:ref: cor:A_n-bound --></a> is tight. The trivial upper bound is <img alt="O(\log |A_{n}|)=O(n\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clog+%7CA_%7Bn%7D%7C%29%3DO%28n%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\log |A_{n}|)=O(n\log n)"/>.</p>
<h3 class="sectionHead"><span class="titlemark">3 </span> <a id="x1-30003"/>Proof of Theorem 1</h3>
<p style="text-align: justify;">Several related proofs of this theorem exist, see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int">GV15</a>, <a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>, <a href="https://emanueleviola.wordpress.com/feed/#XShalev16">Sha16</a>]</span>. As in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>, the proof that we present can be broken down in three steps. First we reduce the problem to a statement about conjugacy classes. Second we reduce this to a statement about trace maps. Third we prove the latter. We present the first step in a way that is similar but slightly different from the presentation in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. The second step is only sketched, but relies on classical results about <img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/> and can be found in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. For the third we present a proof that was communicated to us by Will Sawin. We thank him for his permission to include it here.</p>
<h4 class="subsectionHead"><span class="titlemark">3.1 </span> <a id="x1-40003.1"/>Step 1</h4>
<p style="text-align: justify;">We would like to rule out randomized protocols, but it is hard to reason about them directly. Instead, we are going to rule out deterministic protocols on random inputs. First, for any group element <img alt="g\in G" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\in G"/> we define the distribution on quadruples <img alt="D_{g}:=(x_{1},y_{1},x_{2},(x_{1}\cdot y_{1}\cdot x_{2})^{-1}g)" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7Bg%7D%3A%3D%28x_%7B1%7D%2Cy_%7B1%7D%2Cx_%7B2%7D%2C%28x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%29%5E%7B-1%7Dg%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{g}:=(x_{1},y_{1},x_{2},(x_{1}\cdot y_{1}\cdot x_{2})^{-1}g)"/>, where <img alt="x,y\in G" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in G"/> are uniformly random elements. Note the product of the elements in <img alt="D_{g}" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7Bg%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{g}"/> is always <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/>.</p>
<p style="text-align: justify;">Towards a contradiction, suppose we have a randomized protocol <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> such that</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb{P} [P(D_{1})=1]\geq \mathbb{P} [P(D_{h})=1]+\frac {1}{10}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb%7BP%7D+%5BP%28D_%7B1%7D%29%3D1%5D%5Cgeq+%5Cmathbb%7BP%7D+%5BP%28D_%7Bh%7D%29%3D1%5D%2B%5Cfrac+%7B1%7D%7B10%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb{P} [P(D_{1})=1]\geq \mathbb{P} [P(D_{h})=1]+\frac {1}{10}. \end{aligned}"/></div>
<p>This implies a deterministic protocol with the same gap, by fixing the randomness.</p>
<p style="text-align: justify;">We reach a contradiction by showing that for every deterministic protocol <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> using little communication, we have</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\Pr [P(D_{1})=1]-\Pr [P(D_{h})=1]|\leq \frac {1}{100}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5CPr+%5BP%28D_%7B1%7D%29%3D1%5D-%5CPr+%5BP%28D_%7Bh%7D%29%3D1%5D%7C%5Cleq+%5Cfrac+%7B1%7D%7B100%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\Pr [P(D_{1})=1]-\Pr [P(D_{h})=1]|\leq \frac {1}{100}. \end{aligned}"/></div>
<p style="text-align: justify;">We start with the following standard lemma, which describes a protocol using product sets.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-4001r4"/> Lemma 4. </span>(The set of accepted inputs of) A deterministic <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>-bit protocol for a function <img alt="f:X\times Y\to Z" class="latex" src="https://s0.wp.com/latex.php?latex=f%3AX%5Ctimes+Y%5Cto+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:X\times Y\to Z"/> can be written as a disjoint union of <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> rectangles, where a rectangle is a set of the form <img alt="A\times B" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\times B"/> with <img alt="A\subseteq X" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Csubseteq+X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\subseteq X"/> and <img alt="B\subseteq Y" class="latex" src="https://s0.wp.com/latex.php?latex=B%5Csubseteq+Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B\subseteq Y"/> and where <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> is constant.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>(sketch) For every communication transcript <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>, let <img alt="S_{t}\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=S_%7Bt%7D%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S_{t}\subseteq G^{2}"/> be the set of inputs giving transcript <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>. The sets <img alt="S_{t}" class="latex" src="https://s0.wp.com/latex.php?latex=S_%7Bt%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S_{t}"/> are disjoint since an input gives only one transcript, and their number is <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/>: one for each communication transcript of the protocol. The rectangle property can be proven by induction on the protocol tree. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">Next, we show that any rectangle <img alt="A\times B" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\times B"/> cannot distinguish <img alt="D_{1},D_{h}" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7B1%7D%2CD_%7Bh%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{1},D_{h}"/>. The way we achieve this is by showing that for every <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> the probability that <img alt="(A\times B)(D_{g})=1" class="latex" src="https://s0.wp.com/latex.php?latex=%28A%5Ctimes+B%29%28D_%7Bg%7D%29%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(A\times B)(D_{g})=1"/> is roughly the same for every <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/>, and is roughly the density of the rectangle. (Here we write <img alt="A\times B" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\times B"/> for the characteristic function of the set <img alt="A\times B" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\times B"/>.) Without loss of generality we set <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/>. Let <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> have density <img alt="\alpha " class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha "/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> have density <img alt="\beta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta "/>. We aim to bound above</p>
<div style="text-align: center;"><img alt="\begin{aligned} \left |\mathbb{E} _{a_{1},b_{1},a_{2},b_{2}:a_{1}b_{1}a_{2}b_{2}=1}A(a_{1},a_{2})B(b_{1},b_{2})-\alpha \beta \right |, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb%7BE%7D+_%7Ba_%7B1%7D%2Cb_%7B1%7D%2Ca_%7B2%7D%2Cb_%7B2%7D%3Aa_%7B1%7Db_%7B1%7Da_%7B2%7Db_%7B2%7D%3D1%7DA%28a_%7B1%7D%2Ca_%7B2%7D%29B%28b_%7B1%7D%2Cb_%7B2%7D%29-%5Calpha+%5Cbeta+%5Cright+%7C%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left |\mathbb{E} _{a_{1},b_{1},a_{2},b_{2}:a_{1}b_{1}a_{2}b_{2}=1}A(a_{1},a_{2})B(b_{1},b_{2})-\alpha \beta \right |, \end{aligned}"/></div>
<p>where note the distribution of <img alt="a_{1},b_{1},a_{2},b_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=a_%7B1%7D%2Cb_%7B1%7D%2Ca_%7B2%7D%2Cb_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_{1},b_{1},a_{2},b_{2}"/> is the same as <img alt="D_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{1}"/>.</p>
<p style="text-align: justify;">Because the distribution of <img alt="(b_{1},b_{2})" class="latex" src="https://s0.wp.com/latex.php?latex=%28b_%7B1%7D%2Cb_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(b_{1},b_{2})"/> is uniform in <img alt="G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G^{2}"/>, the above can be rewritten as</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; \left |\mathbb{E} _{b_{1},b_{2}}B(b_{1},b_{2})\mathbb{E} _{a_{1},a_{2}:a_{1}b_{1}a_{2}b_{2}=1}(A(a_{1},a_{2})-\alpha )\right |\\ &amp; \le \sqrt {\mathbb{E} _{b_{1},b_{2}}B(b_{1},b_{2})^{2}}\sqrt {\mathbb{E} _{b_{1},b_{2}}\mathbb{E} _{a_{1},a_{2}:a_{1}b_{1}a_{2}b_{2}=1}^{2}(A(a_{1},a_{2})-\alpha )}.\\ &amp; =\sqrt {\beta }\sqrt {\mathbb{E} _{b_{1},b_{2},a_{1},a_{2},a_{1}',a_{2}':a_{1}b_{1}a_{2}b_{2}=a_{1}'b_{1}a_{2}'b_{2}=1}A(a_{1},a_{2})A(a_{1}',a_{2}')-\alpha ^{2}}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Cleft+%7C%5Cmathbb%7BE%7D+_%7Bb_%7B1%7D%2Cb_%7B2%7D%7DB%28b_%7B1%7D%2Cb_%7B2%7D%29%5Cmathbb%7BE%7D+_%7Ba_%7B1%7D%2Ca_%7B2%7D%3Aa_%7B1%7Db_%7B1%7Da_%7B2%7Db_%7B2%7D%3D1%7D%28A%28a_%7B1%7D%2Ca_%7B2%7D%29-%5Calpha+%29%5Cright+%7C%5C%5C+%26+%5Cle+%5Csqrt+%7B%5Cmathbb%7BE%7D+_%7Bb_%7B1%7D%2Cb_%7B2%7D%7DB%28b_%7B1%7D%2Cb_%7B2%7D%29%5E%7B2%7D%7D%5Csqrt+%7B%5Cmathbb%7BE%7D+_%7Bb_%7B1%7D%2Cb_%7B2%7D%7D%5Cmathbb%7BE%7D+_%7Ba_%7B1%7D%2Ca_%7B2%7D%3Aa_%7B1%7Db_%7B1%7Da_%7B2%7Db_%7B2%7D%3D1%7D%5E%7B2%7D%28A%28a_%7B1%7D%2Ca_%7B2%7D%29-%5Calpha+%29%7D.%5C%5C+%26+%3D%5Csqrt+%7B%5Cbeta+%7D%5Csqrt+%7B%5Cmathbb%7BE%7D+_%7Bb_%7B1%7D%2Cb_%7B2%7D%2Ca_%7B1%7D%2Ca_%7B2%7D%2Ca_%7B1%7D%27%2Ca_%7B2%7D%27%3Aa_%7B1%7Db_%7B1%7Da_%7B2%7Db_%7B2%7D%3Da_%7B1%7D%27b_%7B1%7Da_%7B2%7D%27b_%7B2%7D%3D1%7DA%28a_%7B1%7D%2Ca_%7B2%7D%29A%28a_%7B1%7D%27%2Ca_%7B2%7D%27%29-%5Calpha+%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; \left |\mathbb{E} _{b_{1},b_{2}}B(b_{1},b_{2})\mathbb{E} _{a_{1},a_{2}:a_{1}b_{1}a_{2}b_{2}=1}(A(a_{1},a_{2})-\alpha )\right |\\ &amp; \le \sqrt {\mathbb{E} _{b_{1},b_{2}}B(b_{1},b_{2})^{2}}\sqrt {\mathbb{E} _{b_{1},b_{2}}\mathbb{E} _{a_{1},a_{2}:a_{1}b_{1}a_{2}b_{2}=1}^{2}(A(a_{1},a_{2})-\alpha )}.\\ &amp; =\sqrt {\beta }\sqrt {\mathbb{E} _{b_{1},b_{2},a_{1},a_{2},a_{1}',a_{2}':a_{1}b_{1}a_{2}b_{2}=a_{1}'b_{1}a_{2}'b_{2}=1}A(a_{1},a_{2})A(a_{1}',a_{2}')-\alpha ^{2}}. \end{aligned}"/></div>
<p style="text-align: justify;">The inequality is Cauchy-Schwarz, and the step after that is obtained by expanding the square and noting that <img alt="(a_{1},a_{2})" class="latex" src="https://s0.wp.com/latex.php?latex=%28a_%7B1%7D%2Ca_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a_{1},a_{2})"/> is uniform in <img alt="G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G^{2}"/>, so that the expectation of the term <img alt="A(a_{1},a_{2})\alpha " class="latex" src="https://s0.wp.com/latex.php?latex=A%28a_%7B1%7D%2Ca_%7B2%7D%29%5Calpha+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(a_{1},a_{2})\alpha "/> is <img alt="\alpha ^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha ^{2}"/>.</p>
<p style="text-align: justify;">Now we do several transformations to rewrite the distribution in the last expectation in a convenient form. First, right-multiplying by <img alt="b_{2}^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=b_%7B2%7D%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b_{2}^{-1}"/> we can rewrite the distribution as the uniform distribution on tuples such that</p>
<div style="text-align: center;"><img alt="\begin{aligned} a_{1}b_{1}a_{2}=a_{1}'b_{1}a_{2}'. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7B1%7Db_%7B1%7Da_%7B2%7D%3Da_%7B1%7D%27b_%7B1%7Da_%7B2%7D%27.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} a_{1}b_{1}a_{2}=a_{1}'b_{1}a_{2}'. \end{aligned}"/></div>
<p style="text-align: justify;">The last equation is equivalent to <img alt="b_{1}^{-1}(a_{1}')^{-1}a_{1}b_{1}a_{2}=a_{2}'" class="latex" src="https://s0.wp.com/latex.php?latex=b_%7B1%7D%5E%7B-1%7D%28a_%7B1%7D%27%29%5E%7B-1%7Da_%7B1%7Db_%7B1%7Da_%7B2%7D%3Da_%7B2%7D%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b_{1}^{-1}(a_{1}')^{-1}a_{1}b_{1}a_{2}=a_{2}'"/>.</p>
<p style="text-align: justify;">We can now do a transformation setting <img alt="a_{1}'" class="latex" src="https://s0.wp.com/latex.php?latex=a_%7B1%7D%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_{1}'"/> to be <img alt="a_{1}x^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=a_%7B1%7Dx%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_{1}x^{-1}"/> to rewrite the distribution of the four-tuple as</p>
<div style="text-align: center;"><img alt="\begin{aligned} (a_{1},a_{2},a_{1}x^{-1},C(x)a_{2}) \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28a_%7B1%7D%2Ca_%7B2%7D%2Ca_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (a_{1},a_{2},a_{1}x^{-1},C(x)a_{2}) \end{aligned}"/></div>
<p>where we use <img alt="C(x)" class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x)"/> to denote a uniform element from the conjugacy class of <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, that is <img alt="b^{-1}xb" class="latex" src="https://s0.wp.com/latex.php?latex=b%5E%7B-1%7Dxb&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b^{-1}xb"/> for a uniform <img alt="b\in G" class="latex" src="https://s0.wp.com/latex.php?latex=b%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b\in G"/>.</p>
<p style="text-align: justify;">Hence it is sufficient to bound</p>
<div style="text-align: center;"><img alt="\begin{aligned} \left |\mathbb{E} A(a_{1},a_{2})A(a_{1}x^{-1},C(x)a_{2})-\alpha ^{2}\right |, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb%7BE%7D+A%28a_%7B1%7D%2Ca_%7B2%7D%29A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29-%5Calpha+%5E%7B2%7D%5Cright+%7C%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left |\mathbb{E} A(a_{1},a_{2})A(a_{1}x^{-1},C(x)a_{2})-\alpha ^{2}\right |, \end{aligned}"/></div>
<p>where all the variables are uniform and independent.</p>
<p style="text-align: justify;">With a similar derivation as above, this can be rewritten as</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; \left |\mathbb{E} A(a_{1},a_{2})\mathbb{E} (A(a_{1}x^{-1},C(x)a_{2})-\alpha )\right |\\ &amp; \le \sqrt {\mathbb{E} A(a_{1},a{}_{2})^{2}}\sqrt {\mathbb{E} _{a_{1},a_{2}}\mathbb{E} _{x}^{2}(A(a_{1}x^{-1},C(x)a_{2})-\alpha )}.\\ &amp; =\sqrt {\alpha }\sqrt {\mathbb{E} A(a_{1}x^{-1},C(x)a_{2})A(a_{1}x'^{-1},C(x')a_{2})-\alpha ^{2}}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Cleft+%7C%5Cmathbb%7BE%7D+A%28a_%7B1%7D%2Ca_%7B2%7D%29%5Cmathbb%7BE%7D+%28A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29-%5Calpha+%29%5Cright+%7C%5C%5C+%26+%5Cle+%5Csqrt+%7B%5Cmathbb%7BE%7D+A%28a_%7B1%7D%2Ca%7B%7D_%7B2%7D%29%5E%7B2%7D%7D%5Csqrt+%7B%5Cmathbb%7BE%7D+_%7Ba_%7B1%7D%2Ca_%7B2%7D%7D%5Cmathbb%7BE%7D+_%7Bx%7D%5E%7B2%7D%28A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29-%5Calpha+%29%7D.%5C%5C+%26+%3D%5Csqrt+%7B%5Calpha+%7D%5Csqrt+%7B%5Cmathbb%7BE%7D+A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29A%28a_%7B1%7Dx%27%5E%7B-1%7D%2CC%28x%27%29a_%7B2%7D%29-%5Calpha+%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; \left |\mathbb{E} A(a_{1},a_{2})\mathbb{E} (A(a_{1}x^{-1},C(x)a_{2})-\alpha )\right |\\ &amp; \le \sqrt {\mathbb{E} A(a_{1},a{}_{2})^{2}}\sqrt {\mathbb{E} _{a_{1},a_{2}}\mathbb{E} _{x}^{2}(A(a_{1}x^{-1},C(x)a_{2})-\alpha )}.\\ &amp; =\sqrt {\alpha }\sqrt {\mathbb{E} A(a_{1}x^{-1},C(x)a_{2})A(a_{1}x'^{-1},C(x')a_{2})-\alpha ^{2}}. \end{aligned}"/></div>
<p style="text-align: justify;">Here each occurrence of <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> denotes a uniform and independent conjugate. Hence it is sufficient to bound</p>
<div style="text-align: center;"><img alt="\begin{aligned} \left |\mathbb{E} A(a_{1}x^{-1},C(x)a_{2})A(a_{1}x'^{-1},C(x')a_{2})-\alpha ^{2}\right |. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb%7BE%7D+A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29A%28a_%7B1%7Dx%27%5E%7B-1%7D%2CC%28x%27%29a_%7B2%7D%29-%5Calpha+%5E%7B2%7D%5Cright+%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left |\mathbb{E} A(a_{1}x^{-1},C(x)a_{2})A(a_{1}x'^{-1},C(x')a_{2})-\alpha ^{2}\right |. \end{aligned}"/></div>
<p style="text-align: justify;">We can now replace <img alt="a_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=a_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_{2}"/> with <img alt="C(x)^{-1}a_{2}." class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%29%5E%7B-1%7Da_%7B2%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x)^{-1}a_{2}."/> Because <img alt="C(x)^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%29%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x)^{-1}"/> has the same distribution of <img alt="C(x^{-1})" class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%5E%7B-1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x^{-1})"/>, it is sufficient to bound</p>
<div style="text-align: center;"><img alt="\begin{aligned} \left |\mathbb{E} A(a_{1}x^{-1},a_{2})A(a_{1}x'^{-1},C(x')C(x^{-1})a_{2})-\alpha ^{2}\right |. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb%7BE%7D+A%28a_%7B1%7Dx%5E%7B-1%7D%2Ca_%7B2%7D%29A%28a_%7B1%7Dx%27%5E%7B-1%7D%2CC%28x%27%29C%28x%5E%7B-1%7D%29a_%7B2%7D%29-%5Calpha+%5E%7B2%7D%5Cright+%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left |\mathbb{E} A(a_{1}x^{-1},a_{2})A(a_{1}x'^{-1},C(x')C(x^{-1})a_{2})-\alpha ^{2}\right |. \end{aligned}"/></div>
<p style="text-align: justify;">For this, it is enough to show that with high probability <img alt="1-1/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=1-1%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1-1/|G|^{\Omega (1)}"/> over <img alt="x'" class="latex" src="https://s0.wp.com/latex.php?latex=x%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x'"/> and <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, the distribution of <img alt="C(x')C(x^{-1})" class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%27%29C%28x%5E%7B-1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x')C(x^{-1})"/>, over the choice of the two independent conjugates, has statistical distance <img alt="\le 1/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cle+1%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\le 1/|G|^{\Omega (1)}"/> from uniform.</p>
<h4 class="subsectionHead"><span class="titlemark">3.2 </span> <a id="x1-50003.2"/>Step 2</h4>
<p style="text-align: justify;">In this step we use information on the conjugacy classes of the group to reduce the latter task to one about the equidistribution of the trace map. Let <img alt="Tr" class="latex" src="https://s0.wp.com/latex.php?latex=Tr&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Tr"/> be the Trace map:</p>
<div style="text-align: center;"><img alt="\begin{aligned} Tr\begin {pmatrix}a_{1} &amp; a_{2}\\ a_{3} &amp; a_{4} \end {pmatrix}=a_{1}+a_{4}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+Tr%5Cbegin+%7Bpmatrix%7Da_%7B1%7D+%26+a_%7B2%7D%5C%5C+a_%7B3%7D+%26+a_%7B4%7D+%5Cend+%7Bpmatrix%7D%3Da_%7B1%7D%2Ba_%7B4%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} Tr\begin {pmatrix}a_{1} &amp; a_{2}\\ a_{3} &amp; a_{4} \end {pmatrix}=a_{1}+a_{4}. \end{aligned}"/></div>
<p style="text-align: justify;">We state the lemma that we want to show.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-5001r5"/> Lemma 5. </span>Let <img alt="a:=\begin {pmatrix}0 &amp; 1\\ 1 &amp; w \end {pmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=a%3A%3D%5Cbegin+%7Bpmatrix%7D0+%26+1%5C%5C+1+%26+w+%5Cend+%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a:=\begin {pmatrix}0 &amp; 1\\ 1 &amp; w \end {pmatrix}"/> and <img alt="b:=\begin {pmatrix}v &amp; 1\\ 1 &amp; 0 \end {pmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=b%3A%3D%5Cbegin+%7Bpmatrix%7Dv+%26+1%5C%5C+1+%26+0+%5Cend+%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b:=\begin {pmatrix}v &amp; 1\\ 1 &amp; 0 \end {pmatrix}"/>. For all but <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> values of <img alt="w\in \mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=w%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w\in \mathbb{F} _{q}"/> and <img alt="v\in \mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=v%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v\in \mathbb{F} _{q}"/>, the distribution of</p>
<div style="text-align: center;"><img alt="\begin{aligned} Tr\left (au^{-1}bu\right ) \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+Tr%5Cleft+%28au%5E%7B-1%7Dbu%5Cright+%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} Tr\left (au^{-1}bu\right ) \end{aligned}"/></div>
<p>is <img alt="O(1/q)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2Fq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1/q)"/> close to uniform over <img alt="\mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{F} _{q}"/> in statistical distance.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">To give some context, in <img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/> the conjugacy class of an element is essentially determined by the trace. Moreover, we can think of <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> and <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b"/> as generic elements in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. So the lemma can be interpreted as saying that for typical <img alt="a,b\in G" class="latex" src="https://s0.wp.com/latex.php?latex=a%2Cb%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a,b\in G"/>, taking a uniform element from the conjugacy class of <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b"/> and multiplying it by <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> yields an element whose conjugacy class is uniform among the classes of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. Using that essentially all conjugacy classes are equal, and some of the properties of the trace map, one can show that the above lemma implies that for typical <img alt="x,x'" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cx%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,x'"/> the distribution of <img alt="C(x')C(x^{-1})" class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%27%29C%28x%5E%7B-1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x')C(x^{-1})"/> is close to uniform. For more on how this fits we refer the reader to <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>.</p>
<h4 class="subsectionHead"><span class="titlemark">3.3 </span> <a id="x1-60003.3"/>Step 3</h4>
<p style="text-align: justify;">We now present a proof of Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-5001r5">5<!--tex4ht:ref: lem:trace --></a>. The high-level argument of the proof is the same as in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span> (Lemma 5.5), but the details may be more accessible and in particular the use of the Lang-Weil theorem <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XLangWeil54">LW54</a>]</span> from algebraic geometry is replaced by a more elementary argument. For simplicity we shall only cover the case where <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> is prime. We will show that for all but <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> values of <img alt="v,w,c\in \mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=v%2Cw%2Cc%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v,w,c\in \mathbb{F} _{q}"/>, the probability over <img alt="u" class="latex" src="https://s0.wp.com/latex.php?latex=u&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="u"/> that <img alt="Tr(au^{-1}bu)=c" class="latex" src="https://s0.wp.com/latex.php?latex=Tr%28au%5E%7B-1%7Dbu%29%3Dc&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Tr(au^{-1}bu)=c"/> is within <img alt="O(1/q^{2})" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2Fq%5E%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1/q^{2})"/> of <img alt="1/q" class="latex" src="https://s0.wp.com/latex.php?latex=1%2Fq&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/q"/>, and for the others it is at most <img alt="O(1/q)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2Fq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1/q)"/>. Summing over <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/> gives the result.</p>
<p style="text-align: justify;">We shall consider elements <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b"/> whose trace is unique to the conjugacy class of <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b"/>. (This holds for all but <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> conjugacy classes – see for example <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span> for details.) This means that the distribution of <img alt="u^{-1}bu" class="latex" src="https://s0.wp.com/latex.php?latex=u%5E%7B-1%7Dbu&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="u^{-1}bu"/> is that of a uniform element in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> conditioned on having trace <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b"/>. Hence, we can write the probability that <img alt="Tr(au^{-1}bu)=c" class="latex" src="https://s0.wp.com/latex.php?latex=Tr%28au%5E%7B-1%7Dbu%29%3Dc&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Tr(au^{-1}bu)=c"/> as the number of solutions in <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> to the following three equations (divided by the size of the group, which is <img alt="q^{3}-q" class="latex" src="https://s0.wp.com/latex.php?latex=q%5E%7B3%7D-q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q^{3}-q"/>):</p>
<div style="text-align: center;"><img alt="\begin{aligned} x_{3}+x_{2}+wx_{4} &amp; =c &amp; \hspace {1cm}(Tr(ax)=c),\\ x_{1}+x_{4} &amp; =v &amp; \hspace {1cm}(Tr(x)=Tr(b)),\\ x_{1}x_{4}-x_{3}x_{3} &amp; =1 &amp; \hspace {1cm}(Det(x)=1). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x_%7B3%7D%2Bx_%7B2%7D%2Bwx_%7B4%7D+%26+%3Dc+%26+%5Chspace+%7B1cm%7D%28Tr%28ax%29%3Dc%29%2C%5C%5C+x_%7B1%7D%2Bx_%7B4%7D+%26+%3Dv+%26+%5Chspace+%7B1cm%7D%28Tr%28x%29%3DTr%28b%29%29%2C%5C%5C+x_%7B1%7Dx_%7B4%7D-x_%7B3%7Dx_%7B3%7D+%26+%3D1+%26+%5Chspace+%7B1cm%7D%28Det%28x%29%3D1%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x_{3}+x_{2}+wx_{4} &amp; =c &amp; \hspace {1cm}(Tr(ax)=c),\\ x_{1}+x_{4} &amp; =v &amp; \hspace {1cm}(Tr(x)=Tr(b)),\\ x_{1}x_{4}-x_{3}x_{3} &amp; =1 &amp; \hspace {1cm}(Det(x)=1). \end{aligned}"/></div>
<p style="text-align: justify;">We use the second one to remove <img alt="x_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}"/> and the first one to remove <img alt="x_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{2}"/> from the last equation. This gives</p>
<div style="text-align: center;"><img alt="\begin{aligned} (v-x_{4})x_{4}-(c-x_{3}-wx_{4})x_{3}=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28v-x_%7B4%7D%29x_%7B4%7D-%28c-x_%7B3%7D-wx_%7B4%7D%29x_%7B3%7D%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (v-x_{4})x_{4}-(c-x_{3}-wx_{4})x_{3}=1. \end{aligned}"/></div>
<p style="text-align: justify;">This is an equation in two variables. Write <img alt="x=x_{3}" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Dx_%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=x_{3}"/> and <img alt="y=x_{4}" class="latex" src="https://s0.wp.com/latex.php?latex=y%3Dx_%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y=x_{4}"/> and use distributivity to rewrite the equation as</p>
<div style="text-align: center;"><img alt="\begin{aligned} -y^{2}+vy-cx+x^{2}+wxy=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+-y%5E%7B2%7D%2Bvy-cx%2Bx%5E%7B2%7D%2Bwxy%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} -y^{2}+vy-cx+x^{2}+wxy=1. \end{aligned}"/></div>
<p style="text-align: justify;">At least since Lagrange it has been known how to reduce this to a Pell equation <img alt="x^{2}+dy^{2}=e" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D%2Bdy%5E%7B2%7D%3De&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{2}+dy^{2}=e"/>. This is done by applying an invertible affine transformation, which does not change the number of solutions. First set <img alt="x=x-wy/2" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Dx-wy%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=x-wy/2"/>. Then the equation becomes</p>
<div style="text-align: center;"><img alt="\begin{aligned} -y^{2}+vy-c(x-wy/2)+(x-wy/2)^{2}+w(x-wy/2)y=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+-y%5E%7B2%7D%2Bvy-c%28x-wy%2F2%29%2B%28x-wy%2F2%29%5E%7B2%7D%2Bw%28x-wy%2F2%29y%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} -y^{2}+vy-c(x-wy/2)+(x-wy/2)^{2}+w(x-wy/2)y=1. \end{aligned}"/></div>
<p style="text-align: justify;">Equivalently, the cross-term has disappeared and we have</p>
<div style="text-align: center;"><img alt="\begin{aligned} y^{2}(-1-w^{2}/4)+y(v+cw/2)+x^{2}-cx=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+y%5E%7B2%7D%28-1-w%5E%7B2%7D%2F4%29%2By%28v%2Bcw%2F2%29%2Bx%5E%7B2%7D-cx%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} y^{2}(-1-w^{2}/4)+y(v+cw/2)+x^{2}-cx=1. \end{aligned}"/></div>
<p style="text-align: justify;">Now one can add constants to <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> to remove the linear terms, changing the constant term. Specifically, let <img alt="h:=(v+cw/2)/2" class="latex" src="https://s0.wp.com/latex.php?latex=h%3A%3D%28v%2Bcw%2F2%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h:=(v+cw/2)/2"/> and set <img alt="y=y-h" class="latex" src="https://s0.wp.com/latex.php?latex=y%3Dy-h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y=y-h"/> and <img alt="x=x+c/2" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Dx%2Bc%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=x+c/2"/>. The equation becomes</p>
<div style="text-align: center;"><img alt="\begin{aligned} (y-h)^{2}(-1-w^{2}/4)+(y-h)2h+(x+c/2)^{2}-c(x+c/2)=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28y-h%29%5E%7B2%7D%28-1-w%5E%7B2%7D%2F4%29%2B%28y-h%292h%2B%28x%2Bc%2F2%29%5E%7B2%7D-c%28x%2Bc%2F2%29%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (y-h)^{2}(-1-w^{2}/4)+(y-h)2h+(x+c/2)^{2}-c(x+c/2)=1. \end{aligned}"/></div>
<p style="text-align: justify;">The linear terms disappear, the coefficients of <img alt="x^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{2}"/> and <img alt="y^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=y%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y^{2}"/> do not change and the equation can be rewritten as</p>
<div style="text-align: center;"><img alt="\begin{aligned} y^{2}(-1-w^{2}/4)+h^{2}(-1-w^{2}/4)-2h^{2}+x^{2}+(c/2)^{2}-c^{2}/2=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+y%5E%7B2%7D%28-1-w%5E%7B2%7D%2F4%29%2Bh%5E%7B2%7D%28-1-w%5E%7B2%7D%2F4%29-2h%5E%7B2%7D%2Bx%5E%7B2%7D%2B%28c%2F2%29%5E%7B2%7D-c%5E%7B2%7D%2F2%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} y^{2}(-1-w^{2}/4)+h^{2}(-1-w^{2}/4)-2h^{2}+x^{2}+(c/2)^{2}-c^{2}/2=1. \end{aligned}"/></div>
<p style="text-align: justify;">So this is now a Pell equation</p>
<div style="text-align: center;"><img alt="\begin{aligned} x^{2}+dy^{2}=e \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5E%7B2%7D%2Bdy%5E%7B2%7D%3De+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x^{2}+dy^{2}=e \end{aligned}"/></div>
<p style="text-align: justify;">where <img alt="d:=(-1-w^{2}/4)" class="latex" src="https://s0.wp.com/latex.php?latex=d%3A%3D%28-1-w%5E%7B2%7D%2F4%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d:=(-1-w^{2}/4)"/> and</p>
<div style="text-align: center;"><img alt="\begin{aligned} e:=1+h^{2}(3+w^{2}/4)+(c/2)^{2}=1+(v^{2}+(cw/2)^{2}+cvw)(1/4)(3+w^{2}/4)+(c/2)^{2}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+e%3A%3D1%2Bh%5E%7B2%7D%283%2Bw%5E%7B2%7D%2F4%29%2B%28c%2F2%29%5E%7B2%7D%3D1%2B%28v%5E%7B2%7D%2B%28cw%2F2%29%5E%7B2%7D%2Bcvw%29%281%2F4%29%283%2Bw%5E%7B2%7D%2F4%29%2B%28c%2F2%29%5E%7B2%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} e:=1+h^{2}(3+w^{2}/4)+(c/2)^{2}=1+(v^{2}+(cw/2)^{2}+cvw)(1/4)(3+w^{2}/4)+(c/2)^{2}. \end{aligned}"/></div>
<p style="text-align: justify;">For all but <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> values of <img alt="w" class="latex" src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w"/> we have that <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> is non-zero. Moreover, for all but <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> values of <img alt="v,w" class="latex" src="https://s0.wp.com/latex.php?latex=v%2Cw&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v,w"/> the term <img alt="e" class="latex" src="https://s0.wp.com/latex.php?latex=e&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e"/> is a non-zero polynomial in <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>. (Specifically, for any <img alt="v\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=v%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v\ne 0"/> and any <img alt="w" class="latex" src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w"/> such that <img alt="3+w^{2}/4\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=3%2Bw%5E%7B2%7D%2F4%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="3+w^{2}/4\ne 0"/>.) So we only consider the values of <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/> that make it non-zero. Those where <img alt="e=0" class="latex" src="https://s0.wp.com/latex.php?latex=e%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e=0"/> give <img alt="O(q)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(q)"/> solutions, which is fine. We conclude with the following lemma.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-6001r6"/> Lemma 6. </span>For <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> and <img alt="e" class="latex" src="https://s0.wp.com/latex.php?latex=e&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e"/> non-zero, and prime <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/>, the number of solutions over <img alt="\mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{F} _{q}"/> to the Pell equation</p>
<div style="text-align: center;"><img alt="\begin{aligned} x^{2}+dy^{2}=e \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5E%7B2%7D%2Bdy%5E%7B2%7D%3De+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x^{2}+dy^{2}=e \end{aligned}"/></div>
<p style="text-align: justify;">is within <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> of <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">This is a basic result from algebraic geometry that can be proved from first principles.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>If <img alt="d=-f^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=d%3D-f%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d=-f^{2}"/> for some <img alt="f\in \mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=f%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f\in \mathbb{F} _{q}"/>, then we can replace <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> with <img alt="fy" class="latex" src="https://s0.wp.com/latex.php?latex=fy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="fy"/> and we can count instead the solutions to the equation</p>
<div style="text-align: center;"><img alt="\begin{aligned} x^{2}-y^{2}=e. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5E%7B2%7D-y%5E%7B2%7D%3De.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x^{2}-y^{2}=e. \end{aligned}"/></div>
<p style="text-align: justify;">Because <img alt="x^{2}-y^{2}=(x-y)(x+y)" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D-y%5E%7B2%7D%3D%28x-y%29%28x%2By%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{2}-y^{2}=(x-y)(x+y)"/> we can set <img alt="x':=x-y" class="latex" src="https://s0.wp.com/latex.php?latex=x%27%3A%3Dx-y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x':=x-y"/> and <img alt="y':=x+y" class="latex" src="https://s0.wp.com/latex.php?latex=y%27%3A%3Dx%2By&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y':=x+y"/>, which preserves the number of solutions, and rewrite the equation as</p>
<div style="text-align: center;"><img alt="\begin{aligned} x'y'=e. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%27y%27%3De.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x'y'=e. \end{aligned}"/></div>
<p style="text-align: justify;">Because <img alt="e\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=e%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e\ne 0"/>, this has <img alt="q-1" class="latex" src="https://s0.wp.com/latex.php?latex=q-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q-1"/> solutions: for every non-zero <img alt="y'" class="latex" src="https://s0.wp.com/latex.php?latex=y%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y'"/> we have <img alt="x'=e/y'" class="latex" src="https://s0.wp.com/latex.php?latex=x%27%3De%2Fy%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x'=e/y'"/>.</p>
<p style="text-align: justify;">So now we can assume that <img alt="d\ne -f^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cne+-f%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\ne -f^{2}"/> for any <img alt="f\in \mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=f%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f\in \mathbb{F} _{q}"/>. Because the number of squares is <img alt="(q+1)/2" class="latex" src="https://s0.wp.com/latex.php?latex=%28q%2B1%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(q+1)/2"/>, the range of <img alt="x^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{2}"/> has size <img alt="(q+1)/2" class="latex" src="https://s0.wp.com/latex.php?latex=%28q%2B1%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(q+1)/2"/>. Similarly, the range of <img alt="e-dy^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=e-dy%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e-dy^{2}"/> also has size <img alt="(q+1)/2" class="latex" src="https://s0.wp.com/latex.php?latex=%28q%2B1%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(q+1)/2"/>. Hence these two ranges intersect, and there is a solution <img alt="(a,b)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)"/>.</p>
<p style="text-align: justify;">We take a line passing through <img alt="(a,b)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)"/>: for parameters <img alt="s,t\in \mathbb{F} " class="latex" src="https://s0.wp.com/latex.php?latex=s%2Ct%5Cin+%5Cmathbb%7BF%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s,t\in \mathbb{F} "/> we consider pairs <img alt="(a+t,b+st)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Bt%2Cb%2Bst%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a+t,b+st)"/>. There is a bijection between such pairs with <img alt="t\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=t%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t\ne 0"/> and the points <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/> with <img alt="x\ne a" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cne+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\ne a"/>. Because the number of solutions with <img alt="x=a" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Da&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=a"/> is <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/>, using that <img alt="d\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\ne 0"/>, it suffices to count the solutions with <img alt="t\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=t%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t\ne 0"/>.</p>
<p style="text-align: justify;">The intuition is that this line has two intersections with the curve <img alt="x^{2}+dy^{2}=e" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D%2Bdy%5E%7B2%7D%3De&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{2}+dy^{2}=e"/>. Because one of them, <img alt="(a,b)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)"/>, lies in <img alt="\mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{F} _{q}"/>, the other has to lie as well there. Algebraically, we can plug the pair in the expression to obtain the equivalent equation</p>
<div style="text-align: center;"><img alt="\begin{aligned} a^{2}+t^{2}+2at+d(b^{2}+s^{2}t^{2}+2bst)=e. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a%5E%7B2%7D%2Bt%5E%7B2%7D%2B2at%2Bd%28b%5E%7B2%7D%2Bs%5E%7B2%7Dt%5E%7B2%7D%2B2bst%29%3De.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} a^{2}+t^{2}+2at+d(b^{2}+s^{2}t^{2}+2bst)=e. \end{aligned}"/></div>
<p style="text-align: justify;">Using that <img alt="(a,b)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)"/> is a solution this becomes</p>
<div style="text-align: center;"><img alt="\begin{aligned} t^{2}+2at+ds^{2}t^{2}+2dbst=0 \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%5E%7B2%7D%2B2at%2Bds%5E%7B2%7Dt%5E%7B2%7D%2B2dbst%3D0+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} t^{2}+2at+ds^{2}t^{2}+2dbst=0 \end{aligned}"/></div>
<p style="text-align: justify;">We can divide by <img alt="t\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=t%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t\ne 0"/>. Obtaining</p>
<div style="text-align: center;"><img alt="\begin{aligned} t(1+ds^{2})+2a+2dbs=0. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%281%2Bds%5E%7B2%7D%29%2B2a%2B2dbs%3D0.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} t(1+ds^{2})+2a+2dbs=0. \end{aligned}"/></div>
<p style="text-align: justify;">We can now divide by <img alt="1+ds^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2Bds%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1+ds^{2}"/> which is non-zero by the assumption <img alt="d\ne -f^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cne+-f%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\ne -f^{2}"/>. This yields</p>
<div style="text-align: center;"><img alt="\begin{aligned} t=(-2a-2dbs)/(1+ds^{2}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%3D%28-2a-2dbs%29%2F%281%2Bds%5E%7B2%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} t=(-2a-2dbs)/(1+ds^{2}). \end{aligned}"/></div>
<p style="text-align: justify;">Hence for every value of <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> there is a unique <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> giving a solution. This gives <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> solutions. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<h3 class="sectionHead"><span class="titlemark">4 </span> <a id="x1-70004"/>Three parties, number-in-hand</h3>
<p style="text-align: justify;">In this section we consider the following three-party number-in-hand problem: Alice gets <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, Bob gets <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/>, Charlie gets <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z"/>, and they want to know if <img alt="x\cdot y\cdot z=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%5Ccdot+z%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y\cdot z=1_{G}"/>. The communication depends on the group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. We present next two efficient protocols for abelian groups, and then a communication lower bound for other groups.</p>
<h4 class="subsectionHead"><span class="titlemark">4.1 </span> <a id="x1-80004.1"/>A randomized protocol for the hypercube</h4>
<p style="text-align: justify;">We begin with the simplest setting. Let <img alt="G=(\mathbb {Z}_{2})^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=G%3D%28%5Cmathbb+%7BZ%7D_%7B2%7D%29%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=(\mathbb {Z}_{2})^{n}"/>, that is <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-bit strings with bit-wise addition modulo 2. The parties want to check if <img alt="x+y+z=0^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x+y+z=0^{n}"/>. They can do so as follows. First, they pick a hash function <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> that is linear: <img alt="h(x+y)=h(x)+h(y)" class="latex" src="https://s0.wp.com/latex.php?latex=h%28x%2By%29%3Dh%28x%29%2Bh%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h(x+y)=h(x)+h(y)"/>. Specifically, for a uniformly random <img alt="a\in \{0,1\}^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\in \{0,1\}^{n}"/> define <img alt="h_{a}(x):=\sum a_{i}x_{i}\mod 2" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%3A%3D%5Csum+a_%7Bi%7Dx_%7Bi%7D%5Cmod+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x):=\sum a_{i}x_{i}\mod 2"/>. Then, the protocol is as follows.</p>
<ul class="itemize1">
<li class="itemize">Alice sends <img alt="h_{a}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)"/>,</li>
<li class="itemize">Bob send <img alt="h_{a}(y)" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(y)"/>,</li>
<li class="itemize">Charlie accepts if and only if <img alt="h_{a}(x)+h_{a}(y)+h_{a}(z)=0s" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%2Bh_%7Ba%7D%28y%29%2Bh_%7Ba%7D%28z%29%3D0s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)+h_{a}(y)+h_{a}(z)=0s"/>.</li>
</ul>
<p style="text-align: justify;">The hash function outputs 1 bit, so the communication is constant. By linearity, the protocol accepts iff <img alt="h_{a}(x+y+z)=0" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%2Bz%29%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y+z)=0"/>. If <img alt="x+y+z=0" class="latex" src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x+y+z=0"/> this is always the case, otherwise it happens with probability <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/>.</p>
<h4 class="subsectionHead"><span class="titlemark">4.2 </span> <a id="x1-90004.2"/>A randomized protocol for <img alt="\mathbb {Z}_{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BZ%7D_%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {Z}_{N}"/></h4>
<p style="text-align: justify;">This protocol is from <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XViola-ccsum">Vio14</a>]</span>. For simplicity we only consider the case <img alt="N=2^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=N%3D2%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N=2^{n}"/> here – the protocol for general <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/> is in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XViola-ccsum">Vio14</a>]</span>. Again, the parties want to check if <img alt="x+y+z=0\mod N" class="latex" src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0%5Cmod+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x+y+z=0\mod N"/>. For this group, there is no 100% linear hash function but there are almost linear hash functions <img alt="h:\mathbb {Z}_{N}\rightarrow \mathbb {Z}_{2^{\ell }}" class="latex" src="https://s0.wp.com/latex.php?latex=h%3A%5Cmathbb+%7BZ%7D_%7BN%7D%5Crightarrow+%5Cmathbb+%7BZ%7D_%7B2%5E%7B%5Cell+%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h:\mathbb {Z}_{N}\rightarrow \mathbb {Z}_{2^{\ell }}"/> that satisfy the following properties. Note that the inputs to <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> are interpreted modulo <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/> and the outputs modulo <img alt="2^{\ell }" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B%5Cell+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{\ell }"/>.</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-9002x1">for all <img alt="a,x,y" class="latex" src="https://s0.wp.com/latex.php?latex=a%2Cx%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a,x,y"/> there is <img alt="c\in \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cin+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\in \{0,1\}"/> such that <img alt="h_{a}(x+y)=h_{a}(x)+h_{a}(y)+c" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%29%3Dh_%7Ba%7D%28x%29%2Bh_%7Ba%7D%28y%29%2Bc&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y)=h_{a}(x)+h_{a}(y)+c"/>,</li>
<li class="enumerate" id="x1-9004x2">for all <img alt="x\neq 0" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cneq+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\neq 0"/> we have <img alt="\mathbb{P} _{a}[h_{a}(x)\in \{-2,-1,0,1,2\}]\leq O(1/2^{\ell })" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+_%7Ba%7D%5Bh_%7Ba%7D%28x%29%5Cin+%5C%7B-2%2C-1%2C0%2C1%2C2%5C%7D%5D%5Cleq+O%281%2F2%5E%7B%5Cell+%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} _{a}[h_{a}(x)\in \{-2,-1,0,1,2\}]\leq O(1/2^{\ell })"/>,</li>
<li class="enumerate" id="x1-9006x3"><img alt="h_{a}(0)=0" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%280%29%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(0)=0"/>.</li>
</ol>
<p style="text-align: justify;">Assuming some random hash function <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> that satisfies the above properties the protocol works similarly to the previous one:</p>
<ul class="itemize1">
<li class="itemize">Alice sends <img alt="h_{a}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)"/>,</li>
<li class="itemize">Bob sends <img alt="h_{a}(y)" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(y)"/>,</li>
<li class="itemize">Charlie accepts if and only if <img alt="h_{a}(x)+h_{a}(y)+h_{a}(z)\in \{-2,-1,0\}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%2Bh_%7Ba%7D%28y%29%2Bh_%7Ba%7D%28z%29%5Cin+%5C%7B-2%2C-1%2C0%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)+h_{a}(y)+h_{a}(z)\in \{-2,-1,0\}"/>.</li>
</ul>
<p style="text-align: justify;">We can set <img alt="\ell =O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell+%3DO%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell =O(1)"/> to achieve constant communication and constant error.</p>
<p style="text-align: justify;">To prove correctness of the protocol, first note that <img alt="h_{a}(x)+h_{a}(y)+h_{a}(z)=h_{a}(x+y+z)-c" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%2Bh_%7Ba%7D%28y%29%2Bh_%7Ba%7D%28z%29%3Dh_%7Ba%7D%28x%2By%2Bz%29-c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)+h_{a}(y)+h_{a}(z)=h_{a}(x+y+z)-c"/> for some <img alt="c\in \{0,1,2\}" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cin+%5C%7B0%2C1%2C2%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\in \{0,1,2\}"/>. Then consider the following two cases:</p>
<ul class="itemize1">
<li class="itemize">if <img alt="x+y+z=0" class="latex" src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x+y+z=0"/> then <img alt="h_{a}(x+y+z)-c=h_{a}(0)-c=-c," class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%2Bz%29-c%3Dh_%7Ba%7D%280%29-c%3D-c%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y+z)-c=h_{a}(0)-c=-c,"/> and the protocol is always correct.</li>
<li class="itemize">if <img alt="x+y+z\neq 0" class="latex" src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%5Cneq+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x+y+z\neq 0"/> then the probability that <img alt="h_{a}(x+y+z)-c\in \{-2,-1,0\}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%2Bz%29-c%5Cin+%5C%7B-2%2C-1%2C0%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y+z)-c\in \{-2,-1,0\}"/> for some <img alt="c\in \{0,1,2\}" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cin+%5C%7B0%2C1%2C2%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\in \{0,1,2\}"/> is at most the probability that <img alt="h_{a}(x+y+z)\in \{-2,-1,0,1,2\}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%2Bz%29%5Cin+%5C%7B-2%2C-1%2C0%2C1%2C2%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y+z)\in \{-2,-1,0,1,2\}"/> which is <img alt="\leq 2^{-\Omega (\ell )}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleq+2%5E%7B-%5COmega+%28%5Cell+%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\leq 2^{-\Omega (\ell )}"/>; so the protocol is correct with high probability.</li>
</ul>
<p style="text-align: justify;"><b>The hash function.</b>.</p>
<p style="text-align: justify;">For the hash function we can use a function analyzed in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XDietzfelbingerHKP97">DHKP97</a>]</span>. Let <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> be a random odd number modulo <img alt="2^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{n}"/>. Define</p>
<div style="text-align: center;"><img alt="\begin{aligned} h_{a}(x):=(a\cdot x\gg n-\ell )\mod 2^{\ell } \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+h_%7Ba%7D%28x%29%3A%3D%28a%5Ccdot+x%5Cgg+n-%5Cell+%29%5Cmod+2%5E%7B%5Cell+%7D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} h_{a}(x):=(a\cdot x\gg n-\ell )\mod 2^{\ell } \end{aligned}"/></div>
<p>where the product <img alt="a\cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot x"/> is integer multiplication, and <img alt="\gg " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgg+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\gg "/> is bit-shift. In other words we output the bits <img alt="n-\ell +1,n-\ell +2,\ldots ,n" class="latex" src="https://s0.wp.com/latex.php?latex=n-%5Cell+%2B1%2Cn-%5Cell+%2B2%2C%5Cldots+%2Cn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n-\ell +1,n-\ell +2,\ldots ,n"/> of the integer product <img alt="a\cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot x"/>.</p>
<p style="text-align: justify;">We now verify that the above hash function family satisfies the three properties we required above.</p>
<p style="text-align: justify;">Property (3) is trivially satisfied.</p>
<p style="text-align: justify;">For property (1) we have the following. Let <img alt="s=a\cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=s%3Da%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s=a\cdot x"/> and <img alt="t=a\cdot y" class="latex" src="https://s0.wp.com/latex.php?latex=t%3Da%5Ccdot+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=a\cdot y"/> and <img alt="u=n-\ell " class="latex" src="https://s0.wp.com/latex.php?latex=u%3Dn-%5Cell+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="u=n-\ell "/>. To recap, by definition we have:</p>
<ul class="itemize1">
<li class="itemize"><img alt="h_{a}(x+y)=((s+t)\gg u)\mod 2^{\ell }," class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%29%3D%28%28s%2Bt%29%5Cgg+u%29%5Cmod+2%5E%7B%5Cell+%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y)=((s+t)\gg u)\mod 2^{\ell },"/></li>
<li class="itemize"><img alt="h_{a}(x)=(s\gg u)\mod 2^{\ell }" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%3D%28s%5Cgg+u%29%5Cmod+2%5E%7B%5Cell+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)=(s\gg u)\mod 2^{\ell }"/>,</li>
<li class="itemize"><img alt="h_{a}(x)=(t\gg u)\mod 2^{\ell }" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%3D%28t%5Cgg+u%29%5Cmod+2%5E%7B%5Cell+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)=(t\gg u)\mod 2^{\ell }"/>.</li>
</ul>
<p style="text-align: justify;">Notice that if in the addition <img alt="s+t" class="latex" src="https://s0.wp.com/latex.php?latex=s%2Bt&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s+t"/> the carry into the <img alt="u+1" class="latex" src="https://s0.wp.com/latex.php?latex=u%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="u+1"/> bit is <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/>, then</p>
<div style="text-align: center;"><img alt="\begin{aligned} (s\gg u)+(t\gg u)=(s+t)\gg u \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28s%5Cgg+u%29%2B%28t%5Cgg+u%29%3D%28s%2Bt%29%5Cgg+u+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (s\gg u)+(t\gg u)=(s+t)\gg u \end{aligned}"/></div>
<p>otherwise</p>
<div style="text-align: center;"><img alt="\begin{aligned} (s\gg u)+(t\gg u)+1=(s+t)\gg u \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28s%5Cgg+u%29%2B%28t%5Cgg+u%29%2B1%3D%28s%2Bt%29%5Cgg+u+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (s\gg u)+(t\gg u)+1=(s+t)\gg u \end{aligned}"/></div>
<p>which concludes the proof for property (1).</p>
<p style="text-align: justify;">Finally, we prove property (2). We start by writing <img alt="x=s\cdot 2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Ds%5Ccdot+2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=s\cdot 2^{c}"/> where <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> is odd. So the binary representation of <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> looks like</p>
<div style="text-align: center;"><img alt="\begin{aligned} (\cdots \cdots 1\underbrace {0\cdots 0}_{c~\textrm {bits}}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28%5Ccdots+%5Ccdots+1%5Cunderbrace+%7B0%5Ccdots+0%7D_%7Bc%7E%5Ctextrm+%7Bbits%7D%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (\cdots \cdots 1\underbrace {0\cdots 0}_{c~\textrm {bits}}). \end{aligned}"/></div>
<p>The binary representation of the product <img alt="a\cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot x"/> for a uniformly random <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> looks like</p>
<div style="text-align: center;"><img alt="\begin{aligned} (\textit {uniform}~1\underbrace {0\cdots 0}_{c~\textrm {bits}}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28%5Ctextit+%7Buniform%7D%7E1%5Cunderbrace+%7B0%5Ccdots+0%7D_%7Bc%7E%5Ctextrm+%7Bbits%7D%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (\textit {uniform}~1\underbrace {0\cdots 0}_{c~\textrm {bits}}). \end{aligned}"/></div>
<p>We consider the two following cases for the product <img alt="a\cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot x"/>:</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-9008x1">If <img alt="a\cdot x=(\underbrace {\textit {uniform}~1\overbrace {00}^{2~bits}}_{\ell ~bits}\cdots 0)" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x%3D%28%5Cunderbrace+%7B%5Ctextit+%7Buniform%7D%7E1%5Coverbrace+%7B00%7D%5E%7B2%7Ebits%7D%7D_%7B%5Cell+%7Ebits%7D%5Ccdots+0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot x=(\underbrace {\textit {uniform}~1\overbrace {00}^{2~bits}}_{\ell ~bits}\cdots 0)"/>, or equivalently <img alt="c\geq n-\ell +2" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cgeq+n-%5Cell+%2B2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\geq n-\ell +2"/>, the output never lands in the bad set <img alt="\{-2,-1,0,1,2\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B-2%2C-1%2C0%2C1%2C2%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{-2,-1,0,1,2\}"/>;</li>
<li class="enumerate" id="x1-9010x2">Otherwise, the hash function output has <img alt="\ell -O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell+-O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell -O(1)"/> uniform bits. For any set <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>, the probability that the output lands in <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> is at most <img alt="|B|\cdot 2^{-\ell +O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CB%7C%5Ccdot+2%5E%7B-%5Cell+%2BO%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|B|\cdot 2^{-\ell +O(1)}"/>.</li>
</ol>
<h4 class="subsectionHead"><span class="titlemark">4.3 </span> <a id="x1-100004.3"/>Quasirandom groups</h4>
<p style="text-align: justify;">What happens in other groups? The hash function used in the previous result was fairly non-trivial. Do we have an almost linear hash function for <img alt="2\times 2" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ctimes+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2\times 2"/> matrices? The answer is negative. For <img alt="SL_{2}(q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL_%7B2%7D%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL_{2}(q)"/> and <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/> the problem is hard, even under the promise. For a group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> the complexity can be expressed in terms of a parameter <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> which comes from representation theory. We will not formally define this parameter here, but several qualitatively equivalent formulations can be found in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>]</span>. Instead the following table shows the <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>’s for the groups we’ve introduced.</p>
<div style="text-align: center;">
<div class="tabular">
<table cellpadding="0" cellspacing="0" class="tabular" id="TBL-1">
<colgroup id="TBL-1-1g">
<col id="TBL-1-1"/></colgroup>
<colgroup id="TBL-1-2g">
<col id="TBL-1-2"/></colgroup>
<colgroup id="TBL-1-3g">
<col id="TBL-1-3"/></colgroup>
<colgroup id="TBL-1-4g">
<col id="TBL-1-4"/></colgroup>
<colgroup id="TBL-1-5g">
<col id="TBL-1-5"/></colgroup>
<tbody>
<tr class="hline">
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
</tr>
<tr id="TBL-1-1-" style="vertical-align: baseline;">
<td class="td11" id="TBL-1-1-1" style="white-space: nowrap; text-align: center;"><img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/></td>
<td class="td11" id="TBL-1-1-2" style="white-space: nowrap; text-align: center;">:</td>
<td class="td11" id="TBL-1-1-3" style="white-space: nowrap; text-align: center;">abelian</td>
<td class="td11" id="TBL-1-1-4" style="white-space: nowrap; text-align: center;"><img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/></td>
<td class="td11" id="TBL-1-1-5" style="white-space: nowrap; text-align: center;"><img alt="SL_{2}(q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL_%7B2%7D%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL_{2}(q)"/></td>
</tr>
<tr class="hline">
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
</tr>
<tr id="TBL-1-2-" style="vertical-align: baseline;">
<td class="td11" id="TBL-1-2-1" style="white-space: nowrap; text-align: center;"><img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/></td>
<td class="td11" id="TBL-1-2-2" style="white-space: nowrap; text-align: center;">:</td>
<td class="td11" id="TBL-1-2-3" style="white-space: nowrap; text-align: center;"><img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/></td>
<td class="td11" id="TBL-1-2-4" style="white-space: nowrap; text-align: center;"><img alt="\Omega (\frac {\log |G|}{\log \log |G|})" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Cfrac+%7B%5Clog+%7CG%7C%7D%7B%5Clog+%5Clog+%7CG%7C%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\frac {\log |G|}{\log \log |G|})"/></td>
<td class="td11" id="TBL-1-2-5" style="white-space: nowrap; text-align: center;"><img alt="|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|G|^{\Omega (1)}"/></td>
</tr>
<tr class="hline">
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
</tr>
<tr id="TBL-1-3-" style="vertical-align: baseline;">
<td class="td11" id="TBL-1-3-1" style="white-space: nowrap; text-align: center;"/>
</tr>
</tbody>
</table>
</div>
<p>.</p>
</div>
<p> </p>
<p style="text-align: justify;"><b>Theorem 1.</b> Let <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> be a group, and let <img alt="h\in G" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\in G"/>. Let <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> be the minimum dimension of any irreducible representation of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. Suppose Alice, Bob, and Charlie receive <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, y, and <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z"/> respectively. They are promised that <img alt="x\cdot y\cdot z" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%5Ccdot+z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y\cdot z"/> either equals <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/> or <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/>. Deciding which case it is requires randomized communication complexity <img alt="\Omega (\log d)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+d%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log d)"/>.</p>
<p style="text-align: justify;">This result is tight for the groups we have discussed so far. The arguments are the same as before. Specifically, for <img alt="SL_{2}(q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL_%7B2%7D%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL_{2}(q)"/> the communication is <img alt="\Omega (\log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log |G|)"/>. This is tight up to constants, because Alice and Bob can send their elements. For <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/> the communication is <img alt="\Omega (\log \log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log \log |G|)"/>. This is tight as well, as the parties can again just communicate the images of an element <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> such that <img alt="h(a)\ne a" class="latex" src="https://s0.wp.com/latex.php?latex=h%28a%29%5Cne+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h(a)\ne a"/>, as discussed in Section <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a>. This also gives a computational proof that <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> cannot be too large for <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/>, i.e., it is at most <img alt="(\log |G|)^{O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Clog+%7CG%7C%29%5E%7BO%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\log |G|)^{O(1)}"/>. For abelian groups we get nothing, matching the efficient protocols given above.</p>
<h3 class="sectionHead"><span class="titlemark">5 </span> <a id="x1-110005"/>Proof of Theorem 1</h3>
<p style="text-align: justify;">First we discuss several “mixing” lemmas for groups, then we come back to protocols and see how to apply one of them there.</p>
<h5 class="subsubsectionHead"><span class="titlemark">5.0.1 </span> <a id="x1-120005.0.1"/><img alt="XY" class="latex" src="https://s0.wp.com/latex.php?latex=XY&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="XY"/> mixing</h5>
<p style="text-align: justify;">We want to consider “high entropy” distributions over <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>, and state a fact showing that the multiplication of two such distributions “mixes” or in other words increases the entropy. To define entropy we use the norms <img alt="\lVert A\rVert _{c}=\left (\sum _{x}A(x)^{c}\right )^{\frac {1}{c}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+A%5CrVert+_%7Bc%7D%3D%5Cleft+%28%5Csum+_%7Bx%7DA%28x%29%5E%7Bc%7D%5Cright+%29%5E%7B%5Cfrac+%7B1%7D%7Bc%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert A\rVert _{c}=\left (\sum _{x}A(x)^{c}\right )^{\frac {1}{c}}"/>. Our notion of (non-)entropy will be <img alt="\lVert A\rVert _{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+A%5CrVert+_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert A\rVert _{2}"/>. Note that <img alt="\lVert A\rVert _{2}^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert A\rVert _{2}^{2}"/> is exactly the <em>collision probability</em> <img alt="\mathbb{P} [A=A']" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5BA%3DA%27%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [A=A']"/> where <img alt="A'" class="latex" src="https://s0.wp.com/latex.php?latex=A%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A'"/> is independent and identically distributed to <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>. The smaller this quantity, the higher the entropy of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>. For the uniform distribution <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> we have <img alt="\lVert U\rVert _{2}^{2}=\frac {1}{|G|}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+U%5CrVert+_%7B2%7D%5E%7B2%7D%3D%5Cfrac+%7B1%7D%7B%7CG%7C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert U\rVert _{2}^{2}=\frac {1}{|G|}"/> and so we can think of <img alt="1/|G|" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|"/> as maximum entropy. If <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> is uniform over <img alt="\Omega (|G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (|G|)"/> elements, we have <img alt="\lVert A\rVert _{2}^{2}=O(1/|G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D%3DO%281%2F%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert A\rVert _{2}^{2}=O(1/|G|)"/> and we think of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> as having “high” entropy.</p>
<p style="text-align: justify;">Because the entropy of <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> is small, we can think of the distance between <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> in the 2-norm as being essentially the entropy of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>:</p>
<div style="text-align: center;"><img alt="\begin{aligned} \lVert A-U\rVert _{2}^{2} &amp; =\sum _{x\in G}\left (A(x)-\frac {1}{|G|}\right )^{2}\\ &amp; =\sum _{x\in G}A(x)^{2}-2A(x)\frac {1}{|G|}+\frac {1}{|G|^{2}}\\ &amp; =\lVert A\rVert _{2}^{2}-\frac {1}{|G|}\\ &amp; =\lVert A\rVert _{2}^{2}-\lVert U\rVert _{2}^{2}\\ &amp; \approx \lVert A\rVert _{2}^{2}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5ClVert+A-U%5CrVert+_%7B2%7D%5E%7B2%7D+%26+%3D%5Csum+_%7Bx%5Cin+G%7D%5Cleft+%28A%28x%29-%5Cfrac+%7B1%7D%7B%7CG%7C%7D%5Cright+%29%5E%7B2%7D%5C%5C+%26+%3D%5Csum+_%7Bx%5Cin+G%7DA%28x%29%5E%7B2%7D-2A%28x%29%5Cfrac+%7B1%7D%7B%7CG%7C%7D%2B%5Cfrac+%7B1%7D%7B%7CG%7C%5E%7B2%7D%7D%5C%5C+%26+%3D%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D-%5Cfrac+%7B1%7D%7B%7CG%7C%7D%5C%5C+%26+%3D%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D-%5ClVert+U%5CrVert+_%7B2%7D%5E%7B2%7D%5C%5C+%26+%5Capprox+%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \lVert A-U\rVert _{2}^{2} &amp; =\sum _{x\in G}\left (A(x)-\frac {1}{|G|}\right )^{2}\\ &amp; =\sum _{x\in G}A(x)^{2}-2A(x)\frac {1}{|G|}+\frac {1}{|G|^{2}}\\ &amp; =\lVert A\rVert _{2}^{2}-\frac {1}{|G|}\\ &amp; =\lVert A\rVert _{2}^{2}-\lVert U\rVert _{2}^{2}\\ &amp; \approx \lVert A\rVert _{2}^{2}. \end{aligned}"/></div>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-12001r7"/> Lemma 7. </span><span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBabaiNP08">BNP08</a>]</span> If <img alt="X,Y" class="latex" src="https://s0.wp.com/latex.php?latex=X%2CY&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X,Y"/> are independent over <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>, then</p>
<div style="text-align: center;"><img alt="\begin{aligned} \lVert X\cdot Y-U\rVert _{2}\leq \lVert X\rVert _{2}\lVert Y\rVert _{2}\sqrt {\frac {|G|}{d}}, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5ClVert+X%5Ccdot+Y-U%5CrVert+_%7B2%7D%5Cleq+%5ClVert+X%5CrVert+_%7B2%7D%5ClVert+Y%5CrVert+_%7B2%7D%5Csqrt+%7B%5Cfrac+%7B%7CG%7C%7D%7Bd%7D%7D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \lVert X\cdot Y-U\rVert _{2}\leq \lVert X\rVert _{2}\lVert Y\rVert _{2}\sqrt {\frac {|G|}{d}}, \end{aligned}"/></div>
<p>where <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> is the minimum dimension of an irreducible representation of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">By this lemma, for high entropy distributions <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/>, we get <img alt="\lVert X\cdot Y-U\rVert _{2}\leq \frac {O(1)}{\sqrt {|G|d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+X%5Ccdot+Y-U%5CrVert+_%7B2%7D%5Cleq+%5Cfrac+%7BO%281%29%7D%7B%5Csqrt+%7B%7CG%7Cd%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert X\cdot Y-U\rVert _{2}\leq \frac {O(1)}{\sqrt {|G|d}}"/>. The factor <img alt="1/\sqrt {|G|}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Csqrt+%7B%7CG%7C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/\sqrt {|G|}"/> allows us to pass to <em>statistical distance </em><img alt="\lVert .\rVert _{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+.%5CrVert+_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert .\rVert _{1}"/> using Cauchy-Schwarz:</p>
<div style="text-align: center;"><img alt="\begin{aligned} \lVert X\cdot Y-U\rVert _{1}\leq \sqrt {|G|}\lVert X\cdot Y-U\rVert _{2}\leq \frac {O(1)}{\sqrt {d}}.~~~~(1) \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5ClVert+X%5Ccdot+Y-U%5CrVert+_%7B1%7D%5Cleq+%5Csqrt+%7B%7CG%7C%7D%5ClVert+X%5Ccdot+Y-U%5CrVert+_%7B2%7D%5Cleq+%5Cfrac+%7BO%281%29%7D%7B%5Csqrt+%7Bd%7D%7D.%7E%7E%7E%7E%281%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \lVert X\cdot Y-U\rVert _{1}\leq \sqrt {|G|}\lVert X\cdot Y-U\rVert _{2}\leq \frac {O(1)}{\sqrt {d}}.~~~~(1) \end{aligned}"/></div>
<p style="text-align: justify;">This is the way in which we will use the lemma.</p>
<p style="text-align: justify;">Another useful consequence of this lemma, which however we will not use directly, is this. Suppose now you have <img alt="three" class="latex" src="https://s0.wp.com/latex.php?latex=three&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="three"/> independent, high-entropy variables <img alt="X,Y,Z" class="latex" src="https://s0.wp.com/latex.php?latex=X%2CY%2CZ&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X,Y,Z"/>. Then for every <img alt="g\in G" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\in G"/> we have</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb{P} [X\cdot Y\cdot Z=g]-1/|G||\le \lVert X\rVert _{2}\lVert Y\rVert _{2}\lVert Z\rVert _{2}\sqrt {\frac {|G|}{d}}.~~~~(2) \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb%7BP%7D+%5BX%5Ccdot+Y%5Ccdot+Z%3Dg%5D-1%2F%7CG%7C%7C%5Cle+%5ClVert+X%5CrVert+_%7B2%7D%5ClVert+Y%5CrVert+_%7B2%7D%5ClVert+Z%5CrVert+_%7B2%7D%5Csqrt+%7B%5Cfrac+%7B%7CG%7C%7D%7Bd%7D%7D.%7E%7E%7E%7E%282%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb{P} [X\cdot Y\cdot Z=g]-1/|G||\le \lVert X\rVert _{2}\lVert Y\rVert _{2}\lVert Z\rVert _{2}\sqrt {\frac {|G|}{d}}.~~~~(2) \end{aligned}"/></div>
<p style="text-align: justify;">To show this, set <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/> without loss of generality and rewrite the left-hand-side as</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\sum _{h\in G}\mathbb{P} [X=h](\mathbb{P} [YZ=h^{-1}]-1/|G|)|. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Csum+_%7Bh%5Cin+G%7D%5Cmathbb%7BP%7D+%5BX%3Dh%5D%28%5Cmathbb%7BP%7D+%5BYZ%3Dh%5E%7B-1%7D%5D-1%2F%7CG%7C%29%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\sum _{h\in G}\mathbb{P} [X=h](\mathbb{P} [YZ=h^{-1}]-1/|G|)|. \end{aligned}"/></div>
<p>By Cauchy-Schwarz this is at most</p>
<div style="text-align: center;"><img alt="\begin{aligned} \sqrt {\sum _{h}\mathbb{P} ^{2}[X=h]}\sqrt {\sum _{h}(\mathbb{P} [YZ=h^{-1}]-1/|G|)^{2}}=\lVert X\lVert _{2}\lVert YZ-U\lVert _{2} \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Csqrt+%7B%5Csum+_%7Bh%7D%5Cmathbb%7BP%7D+%5E%7B2%7D%5BX%3Dh%5D%7D%5Csqrt+%7B%5Csum+_%7Bh%7D%28%5Cmathbb%7BP%7D+%5BYZ%3Dh%5E%7B-1%7D%5D-1%2F%7CG%7C%29%5E%7B2%7D%7D%3D%5ClVert+X%5ClVert+_%7B2%7D%5ClVert+YZ-U%5ClVert+_%7B2%7D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \sqrt {\sum _{h}\mathbb{P} ^{2}[X=h]}\sqrt {\sum _{h}(\mathbb{P} [YZ=h^{-1}]-1/|G|)^{2}}=\lVert X\lVert _{2}\lVert YZ-U\lVert _{2} \end{aligned}"/></div>
<p>and we can conclude by Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7<!--tex4ht:ref: lem:XY-mixing --></a>. Hence the product of three high-entropy distributions is close to uniform in a point-wise sense: each group element is obtained with roughly probability <img alt="1/|G|" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|"/>.</p>
<p style="text-align: justify;">At least over <img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/>, there exists an alternative proof of this fact that does not mention representation theory (see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span> and <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#Xviola-blog-mixing-in-groups">Vioa</a>, <a href="https://emanueleviola.wordpress.com/feed/#Xviola-blog-mixing-in-groups-ii">Viob</a>]</span>).</p>
<p style="text-align: justify;">With this notation in hand, we conclude by stating a “mixing” version of Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-20002">2<!--tex4ht:ref: sec:Two-parties --></a>. For more on this perspective we refer the reader to <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. <a id="x1-12002r1"/></p>
<p style="text-align: justify;"><b>Theorem 1.</b> Let <img alt="G=SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DSL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=SL(2,q)"/>. Let <img alt="X=(X_{1},X_{2})" class="latex" src="https://s0.wp.com/latex.php?latex=X%3D%28X_%7B1%7D%2CX_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X=(X_{1},X_{2})"/> and <img alt="Y=(Y_{1},Y_{2})" class="latex" src="https://s0.wp.com/latex.php?latex=Y%3D%28Y_%7B1%7D%2CY_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y=(Y_{1},Y_{2})"/> be two distributions over <img alt="G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G^{2}"/>. Suppose <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> is independent from <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/>. Let <img alt="g\in G" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\in G"/>. We have</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb{P} [X_{1}Y_{1}X_{2}Y_{2}=g]-1/|G||\le |G|^{1-\Omega (1)}\lVert X\rVert _{2}\lVert Y\rVert _{2}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb%7BP%7D+%5BX_%7B1%7DY_%7B1%7DX_%7B2%7DY_%7B2%7D%3Dg%5D-1%2F%7CG%7C%7C%5Cle+%7CG%7C%5E%7B1-%5COmega+%281%29%7D%5ClVert+X%5CrVert+_%7B2%7D%5ClVert+Y%5CrVert+_%7B2%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb{P} [X_{1}Y_{1}X_{2}Y_{2}=g]-1/|G||\le |G|^{1-\Omega (1)}\lVert X\rVert _{2}\lVert Y\rVert _{2}. \end{aligned}"/></div>
<p style="text-align: justify;">For example, when <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> have high entropy over <img alt="G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G^{2}"/> (that is, are uniform over <img alt="\Omega (|G|^{2})" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%7CG%7C%5E%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (|G|^{2})"/> pairs), we have <img alt="\lVert X\rVert _{2}\le \sqrt {O(1)/|G|^{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+X%5CrVert+_%7B2%7D%5Cle+%5Csqrt+%7BO%281%29%2F%7CG%7C%5E%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert X\rVert _{2}\le \sqrt {O(1)/|G|^{2}}"/>, and so <img alt="|G|^{1-\Omega (1)}\lVert X\rVert _{2}\lVert Y\rVert _{2}\le 1/|G|^{1+\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CG%7C%5E%7B1-%5COmega+%281%29%7D%5ClVert+X%5CrVert+_%7B2%7D%5ClVert+Y%5CrVert+_%7B2%7D%5Cle+1%2F%7CG%7C%5E%7B1%2B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|G|^{1-\Omega (1)}\lVert X\rVert _{2}\lVert Y\rVert _{2}\le 1/|G|^{1+\Omega (1)}"/>. In particular, <img alt="X_{1}Y_{1}X_{2}Y_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=X_%7B1%7DY_%7B1%7DX_%7B2%7DY_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_{1}Y_{1}X_{2}Y_{2}"/> is <img alt="1/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|^{\Omega (1)}"/> close to uniform over <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> in statistical distance.</p>
<h5 class="subsubsectionHead"><span class="titlemark">5.0.2 </span> <a id="x1-130005.0.2"/>Back to protocols</h5>
<p style="text-align: justify;">As in the beginning of Section <a href="https://emanueleviola.wordpress.com/feed/#x1-30003">3<!--tex4ht:ref: sec:Proof-of-Gowers-Viola --></a>, for any group element <img alt="g\in G" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\in G"/> we define the distribution on triples <img alt="D_{g}:=(x,y,(x\cdot y)^{-1}g)" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7Bg%7D%3A%3D%28x%2Cy%2C%28x%5Ccdot+y%29%5E%7B-1%7Dg%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{g}:=(x,y,(x\cdot y)^{-1}g)"/>, where <img alt="x,y\in G" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in G"/> are uniform and independent. Note the product of the elements in <img alt="D_{g}" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7Bg%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{g}"/> is always <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/>. Again as in Section <a href="https://emanueleviola.wordpress.com/feed/#x1-30003">3<!--tex4ht:ref: sec:Proof-of-Gowers-Viola --></a>, it suffices to show that for every <em>deterministic</em> protocols <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> using little communication we have</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\Pr [P(D_{1})=1]-\Pr [P(D_{h})=1]|\leq \frac {1}{100}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5CPr+%5BP%28D_%7B1%7D%29%3D1%5D-%5CPr+%5BP%28D_%7Bh%7D%29%3D1%5D%7C%5Cleq+%5Cfrac+%7B1%7D%7B100%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\Pr [P(D_{1})=1]-\Pr [P(D_{h})=1]|\leq \frac {1}{100}. \end{aligned}"/></div>
<p style="text-align: justify;">Analogously to Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-4001r4">4<!--tex4ht:ref: lem:prot-rect --></a>, the following lemma describes a protocol using rectangles. The proof is nearly identical and is omitted.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-13001r8"/> Lemma 8. </span>(The set of accepted inputs of) A deterministic <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>-bit number-in-hand protocol with three parties can be written as a disjoint union of <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> “rectangles,” that is sets of the form <img alt="A\times B\times C" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B%5Ctimes+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\times B\times C"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">Next we show that these product sets cannot distinguish these two distributions <img alt="D_{1},D_{h}" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7B1%7D%2CD_%7Bh%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{1},D_{h}"/>, via a straightforward application of lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7<!--tex4ht:ref: lem:XY-mixing --></a>.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-13002r9"/> Lemma 9. </span>For all <img alt="A,B,C\subseteq G" class="latex" src="https://s0.wp.com/latex.php?latex=A%2CB%2CC%5Csubseteq+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A,B,C\subseteq G"/> we have <img alt="|\mathbb{P} (A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\leq 1/d^{\Omega (1)}." class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb%7BP%7D+%28A%5Ctimes+B%5Ctimes+C%29%28D_%7B1%7D%29%3D1%5D-%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7Bh%7D%29%3D1%5D%7C%5Cleq+1%2Fd%5E%7B%5COmega+%281%29%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathbb{P} (A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\leq 1/d^{\Omega (1)}."/></p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Pick any <img alt="h\in G" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\in G"/> and let <img alt="x,y,z" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%2Cz&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y,z"/> be the inputs of Alice, Bob, and Charlie respectively. Then</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb{P} [(A\times B\times C)(D_{h})=1]=\mathbb{P} [(x,y)\in A\times B]\cdot \mathbb{P} [(x\cdot y)^{-1}\cdot h\in C|(x,y)\in A\times B],~~~~(3) \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7Bh%7D%29%3D1%5D%3D%5Cmathbb%7BP%7D+%5B%28x%2Cy%29%5Cin+A%5Ctimes+B%5D%5Ccdot+%5Cmathbb%7BP%7D+%5B%28x%5Ccdot+y%29%5E%7B-1%7D%5Ccdot+h%5Cin+C%7C%28x%2Cy%29%5Cin+A%5Ctimes+B%5D%2C%7E%7E%7E%7E%283%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb{P} [(A\times B\times C)(D_{h})=1]=\mathbb{P} [(x,y)\in A\times B]\cdot \mathbb{P} [(x\cdot y)^{-1}\cdot h\in C|(x,y)\in A\times B],~~~~(3) \end{aligned}"/></div>
<p>where <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/> is uniform in <img alt="G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G^{2}"/>. If either <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> or <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> is small, that is <img alt="\mathbb{P} [x\in A]\leq \epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5Bx%5Cin+A%5D%5Cleq+%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [x\in A]\leq \epsilon "/> or <img alt="\mathbb{P} [y\in B]\leq \epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5By%5Cin+B%5D%5Cleq+%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [y\in B]\leq \epsilon "/>, then also <img alt="\mathbb{P} [(x,y)\in A\times B]\le \epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5B%28x%2Cy%29%5Cin+A%5Ctimes+B%5D%5Cle+%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [(x,y)\in A\times B]\le \epsilon "/> and hence (??) is at most <img alt="\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon "/> as well. This holds for every <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/>, so we also have <img alt="|\mathbb{P} (A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\leq \epsilon ." class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb%7BP%7D+%28A%5Ctimes+B%5Ctimes+C%29%28D_%7B1%7D%29%3D1%5D-%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7Bh%7D%29%3D1%5D%7C%5Cleq+%5Cepsilon+.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathbb{P} (A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\leq \epsilon ."/> We will choose <img alt="\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon "/> later.</p>
<p style="text-align: justify;">Otherwise, <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> are large: <img alt="\mathbb{P} [x\in A]&gt;\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5Bx%5Cin+A%5D%3E%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [x\in A]&gt;\epsilon "/> and <img alt="\mathbb{P} [y\in B]&gt;\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5By%5Cin+B%5D%3E%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [y\in B]&gt;\epsilon "/>. Let <img alt="(x',y')" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%27%2Cy%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x',y')"/> be the distribution of <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/> conditioned on <img alt="(x,y)\in A\times B" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29%5Cin+A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)\in A\times B"/>. We have that <img alt="x'" class="latex" src="https://s0.wp.com/latex.php?latex=x%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x'"/> and <img alt="y'" class="latex" src="https://s0.wp.com/latex.php?latex=y%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y'"/> are independent and each is uniform over at least <img alt="\epsilon |G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon |G|"/> elements. By Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7<!--tex4ht:ref: lem:XY-mixing --></a> this implies <img alt="\lVert x'\cdot y'-U\rVert _{2}\leq \lVert x'\rVert _{2}\cdot \lVert y'\rVert _{2}\cdot \sqrt {\frac {|G|}{d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+x%27%5Ccdot+y%27-U%5CrVert+_%7B2%7D%5Cleq+%5ClVert+x%27%5CrVert+_%7B2%7D%5Ccdot+%5ClVert+y%27%5CrVert+_%7B2%7D%5Ccdot+%5Csqrt+%7B%5Cfrac+%7B%7CG%7C%7D%7Bd%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert x'\cdot y'-U\rVert _{2}\leq \lVert x'\rVert _{2}\cdot \lVert y'\rVert _{2}\cdot \sqrt {\frac {|G|}{d}}"/>, where <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> is the uniform distribution. As mentioned after the lemma, by Cauchy–Schwarz we obtain</p>
<div style="text-align: center;"><img alt="\begin{aligned} \lVert x'\cdot y'-U\rVert _{1}\leq |G|\cdot \lVert x'\rVert _{2}\cdot \lVert y'\rVert _{2}\cdot \sqrt {\frac {1}{d}}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5ClVert+x%27%5Ccdot+y%27-U%5CrVert+_%7B1%7D%5Cleq+%7CG%7C%5Ccdot+%5ClVert+x%27%5CrVert+_%7B2%7D%5Ccdot+%5ClVert+y%27%5CrVert+_%7B2%7D%5Ccdot+%5Csqrt+%7B%5Cfrac+%7B1%7D%7Bd%7D%7D%5Cleq+%5Cfrac+%7B1%7D%7B%5Cepsilon+%7D%5Ccdot+%5Cfrac+%7B1%7D%7B%5Csqrt+%7Bd%7D%7D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \lVert x'\cdot y'-U\rVert _{1}\leq |G|\cdot \lVert x'\rVert _{2}\cdot \lVert y'\rVert _{2}\cdot \sqrt {\frac {1}{d}}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}, \end{aligned}"/></div>
<p>where the last inequality follows from the fact that <img alt="\lVert x\rVert _{2},\lVert y\rVert _{2}\leq \sqrt {\frac {1}{\epsilon |G|}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+x%5CrVert+_%7B2%7D%2C%5ClVert+y%5CrVert+_%7B2%7D%5Cleq+%5Csqrt+%7B%5Cfrac+%7B1%7D%7B%5Cepsilon+%7CG%7C%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert x\rVert _{2},\lVert y\rVert _{2}\leq \sqrt {\frac {1}{\epsilon |G|}}"/>.</p>
<p style="text-align: justify;">This implies that <img alt="\lVert (x'\cdot y')^{-1}-U\rVert _{1}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+%28x%27%5Ccdot+y%27%29%5E%7B-1%7D-U%5CrVert+_%7B1%7D%5Cleq+%5Cfrac+%7B1%7D%7B%5Cepsilon+%7D%5Ccdot+%5Cfrac+%7B1%7D%7B%5Csqrt+%7Bd%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert (x'\cdot y')^{-1}-U\rVert _{1}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}"/> and <img alt="\lVert (x'\cdot y')^{-1}\cdot h-U\rVert _{1}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+%28x%27%5Ccdot+y%27%29%5E%7B-1%7D%5Ccdot+h-U%5CrVert+_%7B1%7D%5Cleq+%5Cfrac+%7B1%7D%7B%5Cepsilon+%7D%5Ccdot+%5Cfrac+%7B1%7D%7B%5Csqrt+%7Bd%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert (x'\cdot y')^{-1}\cdot h-U\rVert _{1}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}"/>, because taking inverses and multiplying by <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> does not change the distance to uniform. These two last inequalities imply that</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb{P} [(x'\cdot y')^{-1}\in C]-\mathbb{P} [(x'\cdot y')^{-1}\cdot h\in C]|\le O(\frac {1}{\epsilon \sqrt {d}}); \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb%7BP%7D+%5B%28x%27%5Ccdot+y%27%29%5E%7B-1%7D%5Cin+C%5D-%5Cmathbb%7BP%7D+%5B%28x%27%5Ccdot+y%27%29%5E%7B-1%7D%5Ccdot+h%5Cin+C%5D%7C%5Cle+O%28%5Cfrac+%7B1%7D%7B%5Cepsilon+%5Csqrt+%7Bd%7D%7D%29%3B+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb{P} [(x'\cdot y')^{-1}\in C]-\mathbb{P} [(x'\cdot y')^{-1}\cdot h\in C]|\le O(\frac {1}{\epsilon \sqrt {d}}); \end{aligned}"/></div>
<p>and thus we get that</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb{P} [(A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\le O(\frac {1}{\epsilon \sqrt {d}}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7B1%7D%29%3D1%5D-%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7Bh%7D%29%3D1%5D%7C%5Cle+O%28%5Cfrac+%7B1%7D%7B%5Cepsilon+%5Csqrt+%7Bd%7D%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb{P} [(A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\le O(\frac {1}{\epsilon \sqrt {d}}). \end{aligned}"/></div>
<p>Picking <img alt="\epsilon =1/d^{1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1%2Fd%5E%7B1%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon =1/d^{1/4}"/> completes the proof. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">Returning to arbitrary deterministic protocols <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> (as opposed to rectangles), write <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> as a union of <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> disjoint rectangles by Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-13001r8">8<!--tex4ht:ref: lem:prot-nih-rect --></a>. Applying Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-13002r9">9<!--tex4ht:ref: lem:NIH-rect --></a> and summing over all rectangles we get that the distinguishing advantage of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> is at most <img alt="2^{c}/d^{1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D%2Fd%5E%7B1%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}/d^{1/4}"/>. For <img alt="c\leq (1/100)\log d" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cleq+%281%2F100%29%5Clog+d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\leq (1/100)\log d"/> the advantage is at most <img alt="1/100" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F100&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/100"/>, concluding the proof.</p>
<h3 class="sectionHead"><span class="titlemark">6 </span> <a id="x1-140006"/>Three parties, number-on-forehead</h3>
<p style="text-align: justify;">In number-on-forehead (NOH) communication complexity <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XCFL83">CFL83</a>]</span> with <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> parties, the input is a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-tuple <img alt="(x_{1},\dotsc ,x_{k})" class="latex" src="https://s0.wp.com/latex.php?latex=%28x_%7B1%7D%2C%5Cdotsc+%2Cx_%7Bk%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x_{1},\dotsc ,x_{k})"/> and each party <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> sees all of it except <img alt="x_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i}"/>. For background, it is not known how to prove negative results for <img alt="k\ge \log n" class="latex" src="https://s0.wp.com/latex.php?latex=k%5Cge+%5Clog+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k\ge \log n"/> parties.</p>
<p style="text-align: justify;">We mention that Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a> can be extended to the multiparty setting, see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. Several questions arise here, such as whether this problem remains hard for <img alt="k\ge \log n" class="latex" src="https://s0.wp.com/latex.php?latex=k%5Cge+%5Clog+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k\ge \log n"/>, and what is the minimum length of an interleaved product that is hard for <img alt="k=3" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k=3"/> parties (the proof in <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a> gives a large constant).</p>
<p style="text-align: justify;">However in this survey we shall instead focus on the problem of separating deterministic and randomized communication. For <img alt="k=2" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k=2"/>, we know the optimal separation: The equality function requires <img alt="\Omega (n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n)"/> communication for deterministic protocols, but can be solved using <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> communication if we allow the protocols to use public coins. For <img alt="k=3" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k=3"/>, the best known separation between deterministic and randomized protocol is <img alt="\Omega (\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log n)"/> vs <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XBeameDPW10">BDPW10</a>]</span>. In the following we give a new proof of this result, for a different function: <img alt="f(x,y,z)=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%2Cz%29%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x,y,z)=1_{G}"/> if and only if <img alt="x\cdot y\cdot z=1" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%5Ccdot+z%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y\cdot z=1"/> for <img alt="x,y,z\in SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%2Cz%5Cin+SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y,z\in SL(2,q)"/>. As is true for some functions in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XBeameDPW10">BDPW10</a>]</span>, a stronger separation could hold for <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>. For context, let us state and prove the upper bound for randomized communication.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-14001r10"/> Claim 10. </span><img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> has randomized communication complexity <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/>.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>In the number-on-forehead model, computing <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> reduces to two-party equality with no additional communication: Alice computes <img alt="y\cdot z=:w" class="latex" src="https://s0.wp.com/latex.php?latex=y%5Ccdot+z%3D%3Aw&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y\cdot z=:w"/> privately, then Alice and Bob check if <img alt="x=w^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Dw%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=w^{-1}"/>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">To prove the lower bound for deterministic protocols we reduce the communication problem to a combinatorial problem.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-14002r11"/> Definition 11. </span>A <em>corner</em> in a group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> is a set <img alt="\{(x,y),(xz,y),(x,zy)\}\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%29%2C%28xz%2Cy%29%2C%28x%2Czy%29%5C%7D%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(x,y),(xz,y),(x,zy)\}\subseteq G^{2}"/>, where <img alt="x,y" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y"/> are arbitrary group elements and <img alt="z\neq 1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=z%5Cneq+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z\neq 1_{G}"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">For intuition, if <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> is the abelian group of real numbers with addition, a corner becomes <img alt="\{(x,y),(x+z,y),(x,y+z)\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%29%2C%28x%2Bz%2Cy%29%2C%28x%2Cy%2Bz%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(x,y),(x+z,y),(x,y+z)\}"/> for <img alt="z\neq 0" class="latex" src="https://s0.wp.com/latex.php?latex=z%5Cneq+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z\neq 0"/>, which are the coordinates of an isosceles triangle. We now state the theorem that connects corners and lower bounds.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-14003r12"/> Lemma 12. </span>Let <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> be a group and <img alt="\delta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta "/> a real number. Suppose that every subset <img alt="A\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\subseteq G^{2}"/> with <img alt="|A|/|G^{2}|\ge \delta " class="latex" src="https://s0.wp.com/latex.php?latex=%7CA%7C%2F%7CG%5E%7B2%7D%7C%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|A|/|G^{2}|\ge \delta "/> contains a corner. Then the deterministic communication complexity of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> (defined as <img alt="f(x,y,z)=1\iff x\cdot y\cdot z=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%2Cz%29%3D1%5Ciff+x%5Ccdot+y%5Ccdot+z%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x,y,z)=1\iff x\cdot y\cdot z=1_{G}"/>) is <img alt="\Omega (\log (1/\delta ))" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%281%2F%5Cdelta+%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log (1/\delta ))"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">It is known that <img alt="\delta \ge 1/\mathrm {polyloglog}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cge+1%2F%5Cmathrm+%7Bpolyloglog%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta \ge 1/\mathrm {polyloglog}|G|"/> implies a corner for certain abelian groups <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>, see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMR2289954">LM07</a>]</span> for the best bound and pointers to the history of the problem. For <img alt="G=SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DSL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=SL(2,q)"/> a stronger result is known: <img alt="\delta \ge 1/\mathrm {polylog}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cge+1%2F%5Cmathrm+%7Bpolylog%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta \ge 1/\mathrm {polylog}|G|"/> implies a corner <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAustin2016">Aus16</a>]</span>. This in turn implies communication <img alt="\Omega (\log \log |G|)=\Omega (\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%5Clog+%7CG%7C%29%3D%5COmega+%28%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log \log |G|)=\Omega (\log n)"/>.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We saw already twice that a number-in-hand <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>-bit protocol can be written as a disjoint union of <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> rectangles (Lemmas <a href="https://emanueleviola.wordpress.com/feed/#x1-4001r4">4<!--tex4ht:ref: lem:prot-rect --></a>, <a href="https://emanueleviola.wordpress.com/feed/#x1-13001r8">8<!--tex4ht:ref: lem:prot-nih-rect --></a>). Likewise, a number-on-forehead <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>-bit protocol <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> can be written as a disjoint union of <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> cylinder intersections <img alt="C_{i}:=\{(x,y,z):f_{i}(y,z)g_{i}(x,z)h_{i}(x,y)=1\}" class="latex" src="https://s0.wp.com/latex.php?latex=C_%7Bi%7D%3A%3D%5C%7B%28x%2Cy%2Cz%29%3Af_%7Bi%7D%28y%2Cz%29g_%7Bi%7D%28x%2Cz%29h_%7Bi%7D%28x%2Cy%29%3D1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_{i}:=\{(x,y,z):f_{i}(y,z)g_{i}(x,z)h_{i}(x,y)=1\}"/> for some <img alt="f_{i},g_{i},h_{i}\colon G^{2}\to \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f_%7Bi%7D%2Cg_%7Bi%7D%2Ch_%7Bi%7D%5Ccolon+G%5E%7B2%7D%5Cto+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f_{i},g_{i},h_{i}\colon G^{2}\to \{0,1\}"/>:</p>
<div style="text-align: center;"><img alt="\begin{aligned} P(x,y,z)=\sum _{i=1}^{2^{c}}f_{i}(y,z)g_{i}(x,z)h_{i}(x,y). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+P%28x%2Cy%2Cz%29%3D%5Csum+_%7Bi%3D1%7D%5E%7B2%5E%7Bc%7D%7Df_%7Bi%7D%28y%2Cz%29g_%7Bi%7D%28x%2Cz%29h_%7Bi%7D%28x%2Cy%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} P(x,y,z)=\sum _{i=1}^{2^{c}}f_{i}(y,z)g_{i}(x,z)h_{i}(x,y). \end{aligned}"/></div>
<p>The proof idea of the above fact is to consider the <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> transcripts of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>, then one can see that the inputs giving a fixed transcript are a cylinder intersection.</p>
<p style="text-align: justify;">Let <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> be a <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>-bit protocol. Consider the inputs <img alt="\{(x,y,(xy)^{-1})\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%2C%28xy%29%5E%7B-1%7D%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(x,y,(xy)^{-1})\}"/> on which <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> accepts. Note that at least <img alt="2^{-c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B-c%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{-c}"/> fraction of them are accepted by some cylinder intersection <img alt="C=f\cdot g\cdot h" class="latex" src="https://s0.wp.com/latex.php?latex=C%3Df%5Ccdot+g%5Ccdot+h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C=f\cdot g\cdot h"/>. Let <img alt="A:=\{(x,y):(x,y,(xy)^{-1})\in C\}\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=A%3A%3D%5C%7B%28x%2Cy%29%3A%28x%2Cy%2C%28xy%29%5E%7B-1%7D%29%5Cin+C%5C%7D%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A:=\{(x,y):(x,y,(xy)^{-1})\in C\}\subseteq G^{2}"/>. Since the first two elements in the tuple determine the last, we have <img alt="|A|/|G^{2}|\ge 2^{-c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CA%7C%2F%7CG%5E%7B2%7D%7C%5Cge+2%5E%7B-c%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|A|/|G^{2}|\ge 2^{-c}"/>.</p>
<p style="text-align: justify;">Now suppose <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> contains a corner <img alt="\{(x,y),(xz,y),(x,zy)\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%29%2C%28xz%2Cy%29%2C%28x%2Czy%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(x,y),(xz,y),(x,zy)\}"/>. Then</p>
<div style="text-align: center;"><img alt="\begin{aligned} (x,y)\in A &amp; \implies (x,y,(xy)^{-1})\in C &amp; &amp; \implies h(x,y)=1,\\ (xz,y)\in A &amp; \implies (xz,y,(xzy)^{-1})\in C &amp; &amp; \implies f(y,(xyz)^{-1})=1,\\ (x,zy)\in A &amp; \implies (x,zy,(xzy)^{-1})\in C &amp; &amp; \implies g(x,(xyz)^{-1})=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2Cy%29%5Cin+A+%26+%5Cimplies+%28x%2Cy%2C%28xy%29%5E%7B-1%7D%29%5Cin+C+%26+%26+%5Cimplies+h%28x%2Cy%29%3D1%2C%5C%5C+%28xz%2Cy%29%5Cin+A+%26+%5Cimplies+%28xz%2Cy%2C%28xzy%29%5E%7B-1%7D%29%5Cin+C+%26+%26+%5Cimplies+f%28y%2C%28xyz%29%5E%7B-1%7D%29%3D1%2C%5C%5C+%28x%2Czy%29%5Cin+A+%26+%5Cimplies+%28x%2Czy%2C%28xzy%29%5E%7B-1%7D%29%5Cin+C+%26+%26+%5Cimplies+g%28x%2C%28xyz%29%5E%7B-1%7D%29%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (x,y)\in A &amp; \implies (x,y,(xy)^{-1})\in C &amp; &amp; \implies h(x,y)=1,\\ (xz,y)\in A &amp; \implies (xz,y,(xzy)^{-1})\in C &amp; &amp; \implies f(y,(xyz)^{-1})=1,\\ (x,zy)\in A &amp; \implies (x,zy,(xzy)^{-1})\in C &amp; &amp; \implies g(x,(xyz)^{-1})=1. \end{aligned}"/></div>
<p>This implies <img alt="(x,y,(xzy)^{-1})\in C" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%2C%28xzy%29%5E%7B-1%7D%29%5Cin+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y,(xzy)^{-1})\in C"/>, which is a contradiction because <img alt="z\neq 1" class="latex" src="https://s0.wp.com/latex.php?latex=z%5Cneq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z\neq 1"/> and so <img alt="x\cdot y\cdot (xzy)^{-1}\neq 1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%5Ccdot+%28xzy%29%5E%7B-1%7D%5Cneq+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y\cdot (xzy)^{-1}\neq 1_{G}"/>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<h3 class="sectionHead"><span class="titlemark">7 </span> <a id="x1-150007"/>The corners theorem for quasirandom groups</h3>
<p style="text-align: justify;">In this section we prove the corners theorem for quasirandom groups, following Austin <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAustin2016">Aus16</a>]</span>. Our exposition has several minor differences with that in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAustin2016">Aus16</a>]</span>, which may make it more computer-science friendly. Possibly a proof can also be obtained via certain local modifications and simplifications of Green’s exposition <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGre04-finite">Gre05b</a>, <a href="https://emanueleviola.wordpress.com/feed/#XGreen-supplement">Gre05a</a>]</span> of an earlier proof for the abelian case. We focus on the case <img alt="G=\textit {SL}(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3D%5Ctextit+%7BSL%7D%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=\textit {SL}(2,q)"/> for simplicity, but the proof immediately extends to other quasirandom groups (with corresponding parameters). <a id="x1-15001r1"/></p>
<p style="text-align: justify;"><b>Theorem 1.</b> Let <img alt="G=\textit {SL}(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3D%5Ctextit+%7BSL%7D%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=\textit {SL}(2,q)"/>. Every subset <img alt="A\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\subseteq G^{2}"/> of density <img alt="|A|/|G|^{2}\geq 1/\log ^{a}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%7CA%7C%2F%7CG%7C%5E%7B2%7D%5Cgeq+1%2F%5Clog+%5E%7Ba%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|A|/|G|^{2}\geq 1/\log ^{a}|G|"/> contains a corner <img alt="\{(x,y),(xz,y),(x,zy)~|~z\neq 1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%29%2C%28xz%2Cy%29%2C%28x%2Czy%29%7E%7C%7Ez%5Cneq+1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(x,y),(xz,y),(x,zy)~|~z\neq 1\}"/>.</p>
<h4 class="subsectionHead"><span class="titlemark">7.1 </span> <a id="x1-160007.1"/>Proof idea</h4>
<p style="text-align: justify;">For intuition, suppose <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> is a product set, i.e., <img alt="A=B\times C" class="latex" src="https://s0.wp.com/latex.php?latex=A%3DB%5Ctimes+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A=B\times C"/> for <img alt="B,C\subseteq G" class="latex" src="https://s0.wp.com/latex.php?latex=B%2CC%5Csubseteq+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B,C\subseteq G"/>. Let’s look at the quantity</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}_{x,y,z\leftarrow G}[A(x,y)A(xz,y)A(x,zy)] \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cz%5Cleftarrow+G%7D%5BA%28x%2Cy%29A%28xz%2Cy%29A%28x%2Czy%29%5D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}_{x,y,z\leftarrow G}[A(x,y)A(xz,y)A(x,zy)] \end{aligned}"/></div>
<p>where <img alt="A(x,y)=1" class="latex" src="https://s0.wp.com/latex.php?latex=A%28x%2Cy%29%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(x,y)=1"/> iff <img alt="(x,y)\in A" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29%5Cin+A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)\in A"/>. Note that the random variable in the expectation is equal to <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> exactly when <img alt="x,y,z" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%2Cz&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y,z"/> form a corner in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>. We’ll show that this quantity is greater than <img alt="1/|G|" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|"/>, which implies that <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> contains a corner (where <img alt="z\neq 1" class="latex" src="https://s0.wp.com/latex.php?latex=z%5Cneq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z\neq 1"/>). Since we are taking <img alt="A=B\times C" class="latex" src="https://s0.wp.com/latex.php?latex=A%3DB%5Ctimes+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A=B\times C"/>, we can rewrite the above quantity as</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(xz)C(y)B(x)C(zy)] &amp; =\mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(xz)C(zy)]\\ &amp; =\mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(z)C(x^{-1}zy)] \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cz%5Cleftarrow+G%7D%5BB%28x%29C%28y%29B%28xz%29C%28y%29B%28x%29C%28zy%29%5D+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cz%5Cleftarrow+G%7D%5BB%28x%29C%28y%29B%28xz%29C%28zy%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cz%5Cleftarrow+G%7D%5BB%28x%29C%28y%29B%28z%29C%28x%5E%7B-1%7Dzy%29%5D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(xz)C(y)B(x)C(zy)] &amp; =\mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(xz)C(zy)]\\ &amp; =\mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(z)C(x^{-1}zy)] \end{aligned}"/></div>
<p>where the last line follows by replacing <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z"/> with <img alt="x^{-1}z" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B-1%7Dz&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{-1}z"/> in the uniform distribution. If <img alt="|A|/|G|^{2}\ge \delta " class="latex" src="https://s0.wp.com/latex.php?latex=%7CA%7C%2F%7CG%7C%5E%7B2%7D%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|A|/|G|^{2}\ge \delta "/>, then both |B|/|G|<img alt="\ge \delta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ge \delta "/> and <img alt="|B|/|G|\ge \delta " class="latex" src="https://s0.wp.com/latex.php?latex=%7CB%7C%2F%7CG%7C%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|B|/|G|\ge \delta "/>. Condition on <img alt="x\in B" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in B"/>, <img alt="y\in C" class="latex" src="https://s0.wp.com/latex.php?latex=y%5Cin+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y\in C"/>, <img alt="z\in B" class="latex" src="https://s0.wp.com/latex.php?latex=z%5Cin+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z\in B"/>. Then the distribution <img alt="x^{-1}zy" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B-1%7Dzy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{-1}zy"/> is a product of three independent distributions, each uniform on a set of density <img alt="\ge \delta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ge \delta "/>. (In fact, two distributions would suffice for this.) By Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7<!--tex4ht:ref: lem:XY-mixing --></a>, <img alt="x^{-1}zy" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B-1%7Dzy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{-1}zy"/> is <img alt="\delta ^{-1}/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5E%7B-1%7D%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta ^{-1}/|G|^{\Omega (1)}"/> close to uniform in statistical distance. This implies that the above expectation equals</p>
<div style="text-align: center;"><img alt="\begin{aligned} \frac {|A|}{|G|^{2}}\cdot \frac {|B|}{|G|}\cdot \left (\frac {|C|}{|G|}\pm \frac {\delta ^{-1}}{|G|^{\Omega (1)}}\right ) &amp; \geq \delta ^{2}\left (\delta -\frac {1}{|G|^{\Omega (1)}}\right )\geq \delta ^{3}/2&gt;1/|G|, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac+%7B%7CA%7C%7D%7B%7CG%7C%5E%7B2%7D%7D%5Ccdot+%5Cfrac+%7B%7CB%7C%7D%7B%7CG%7C%7D%5Ccdot+%5Cleft+%28%5Cfrac+%7B%7CC%7C%7D%7B%7CG%7C%7D%5Cpm+%5Cfrac+%7B%5Cdelta+%5E%7B-1%7D%7D%7B%7CG%7C%5E%7B%5COmega+%281%29%7D%7D%5Cright+%29+%26+%5Cgeq+%5Cdelta+%5E%7B2%7D%5Cleft+%28%5Cdelta+-%5Cfrac+%7B1%7D%7B%7CG%7C%5E%7B%5COmega+%281%29%7D%7D%5Cright+%29%5Cgeq+%5Cdelta+%5E%7B3%7D%2F2%3E1%2F%7CG%7C%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \frac {|A|}{|G|^{2}}\cdot \frac {|B|}{|G|}\cdot \left (\frac {|C|}{|G|}\pm \frac {\delta ^{-1}}{|G|^{\Omega (1)}}\right ) &amp; \geq \delta ^{2}\left (\delta -\frac {1}{|G|^{\Omega (1)}}\right )\geq \delta ^{3}/2&gt;1/|G|, \end{aligned}"/></div>
<p style="text-align: justify;">for <img alt="\delta &gt;1/|G|^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E1%2F%7CG%7C%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta &gt;1/|G|^{c}"/> for a small enough constant <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>. Hence, product sets of density polynomial in <img alt="1/|G|" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|"/> contain corners.</p>
<p style="text-align: justify;">Given the above, it is natural to try to decompose an arbitrary set <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> into product sets. We will make use of a more general result.</p>
<h4 class="subsectionHead"><span class="titlemark">7.2 </span> <a id="x1-170007.2"/>Weak Regularity Lemma</h4>
<p style="text-align: justify;">Let <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> be some universe (we will take <img alt="U=G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=U%3DG%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U=G^{2}"/>) and let <img alt="f:U\rightarrow [-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=f%3AU%5Crightarrow+%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:U\rightarrow [-1,1]"/> be a function (for us, <img alt="f=1_{A}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3D1_%7BA%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f=1_{A}"/>). Let <img alt="D\subseteq \{d:U\rightarrow [-1,1]\}" class="latex" src="https://s0.wp.com/latex.php?latex=D%5Csubseteq+%5C%7Bd%3AU%5Crightarrow+%5B-1%2C1%5D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D\subseteq \{d:U\rightarrow [-1,1]\}"/> be some set of functions, which can be thought of as “easy functions” or “distinguishers” (these will be rectangles or closely related to them). The next theorem shows how to decompose <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> into a linear combination <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> of the <img alt="d_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=d_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d_{i}"/> up to an error which is polynomial in the length of the combination. More specifically, <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> will be indistinguishable from <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> by the <img alt="d_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=d_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d_{i}"/>.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-17001r13"/> Lemma 13. </span>Let <img alt="f:U\rightarrow [-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=f%3AU%5Crightarrow+%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:U\rightarrow [-1,1]"/> be a function and <img alt="D\subseteq \{d:U\rightarrow [-1,1]\}" class="latex" src="https://s0.wp.com/latex.php?latex=D%5Csubseteq+%5C%7Bd%3AU%5Crightarrow+%5B-1%2C1%5D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D\subseteq \{d:U\rightarrow [-1,1]\}"/> a set of functions. For all <img alt="\epsilon &gt;0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon &gt;0"/>, there exists a function <img alt="g:=\sum _{i\le s}c_{i}\cdot d_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3A%3D%5Csum+_%7Bi%5Cle+s%7Dc_%7Bi%7D%5Ccdot+d_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g:=\sum _{i\le s}c_{i}\cdot d_{i}"/> where <img alt="d_{i}\in D" class="latex" src="https://s0.wp.com/latex.php?latex=d_%7Bi%7D%5Cin+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d_{i}\in D"/>, <img alt="c_{i}\in \mathbb {R}" class="latex" src="https://s0.wp.com/latex.php?latex=c_%7Bi%7D%5Cin+%5Cmathbb+%7BR%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c_{i}\in \mathbb {R}"/> and <img alt="s=1/\epsilon ^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=s%3D1%2F%5Cepsilon+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s=1/\epsilon ^{2}"/> such that for all <img alt="d\in D" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cin+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\in D"/></p>
<div style="text-align: center;"><img alt="\begin{aligned} \left |\mathbb {E}_{x\leftarrow U}[f(x)\cdot d(x)]-\mathbb {E}_{x\leftarrow U}[g(x)\cdot d(x)]\right |\le \epsilon . \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb+%7BE%7D_%7Bx%5Cleftarrow+U%7D%5Bf%28x%29%5Ccdot+d%28x%29%5D-%5Cmathbb+%7BE%7D_%7Bx%5Cleftarrow+U%7D%5Bg%28x%29%5Ccdot+d%28x%29%5D%5Cright+%7C%5Cle+%5Cepsilon+.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left |\mathbb {E}_{x\leftarrow U}[f(x)\cdot d(x)]-\mathbb {E}_{x\leftarrow U}[g(x)\cdot d(x)]\right |\le \epsilon . \end{aligned}"/></div>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">A different way to state the conclusion, which we will use, is to say that we can write <img alt="f=g+h" class="latex" src="https://s0.wp.com/latex.php?latex=f%3Dg%2Bh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f=g+h"/> so that <img alt="\mathbb{E} [h(x)\cdot d(x)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D+%5Bh%28x%29%5Ccdot+d%28x%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{E} [h(x)\cdot d(x)]"/> is small.</p>
<p style="text-align: justify;">The lemma is due to Frieze and Kannan <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/conf/focs/FriezeK96">FK96</a>]</span>. It is called “weak” because it came after Szemerédi’s regularity lemma, which has a stronger distinguishing conclusion. However, the lemma is also “strong” in the sense that Szemerédi’s regularity lemma has <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> as a tower of <img alt="1/\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/\epsilon "/> whereas here we have <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> polynomial in <img alt="1/\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/\epsilon "/>. The weak regularity lemma is also simpler. There also exists a proof <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XTao2017-szemerediproof">Tao17</a>]</span> of Szemerédi’s theorem (on arithmetic progressions), which uses weak regularity as opposed to the full regularity lemma used initially.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We will construct the approximation <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> through an iterative process producing functions <img alt="g_{0},g_{1},\dots ,g" class="latex" src="https://s0.wp.com/latex.php?latex=g_%7B0%7D%2Cg_%7B1%7D%2C%5Cdots+%2Cg&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g_{0},g_{1},\dots ,g"/>. We will show that <img alt="||f-g_{i}||_{2}^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7Cf-g_%7Bi%7D%7C%7C_%7B2%7D%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="||f-g_{i}||_{2}^{2}"/> decreases by <img alt="\ge \epsilon ^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cge+%5Cepsilon+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ge \epsilon ^{2}"/> each iteration.</p>
<p style="text-align: justify;"><b>Start</b>: Define <img alt="g_{0}=0" class="latex" src="https://s0.wp.com/latex.php?latex=g_%7B0%7D%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g_{0}=0"/> (which can be realized setting <img alt="c_{0}=0" class="latex" src="https://s0.wp.com/latex.php?latex=c_%7B0%7D%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c_{0}=0"/>).</p>
<p style="text-align: justify;"><b>Iterate</b>: If not done, there exists <img alt="d\in D" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cin+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\in D"/> such that <img alt="|\mathbb {E}[(f-g)\cdot d]|&gt;\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb+%7BE%7D%5B%28f-g%29%5Ccdot+d%5D%7C%3E%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathbb {E}[(f-g)\cdot d]|&gt;\epsilon "/>. Assume without loss of generality <img alt="\mathbb {E}[(f-g)\cdot d]&gt;\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5B%28f-g%29%5Ccdot+d%5D%3E%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}[(f-g)\cdot d]&gt;\epsilon "/>.</p>
<p style="text-align: justify;"><b>Update</b>: <img alt="g':=g+\lambda d" class="latex" src="https://s0.wp.com/latex.php?latex=g%27%3A%3Dg%2B%5Clambda+d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g':=g+\lambda d"/> where <img alt="\lambda \in \mathbb {R}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda+%5Cin+%5Cmathbb+%7BR%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda \in \mathbb {R}"/> shall be picked later.</p>
<p style="text-align: justify;">Let us analyze the progress made by the algorithm.</p>
<div style="text-align: center;"><img alt="\begin{aligned} ||f-g'||_{2}^{2} &amp; =\mathbb {E}_{x}[(f-g')^{2}(x)]\\ &amp; =\mathbb {E}_{x}[(f-g-\lambda d)^{2}(x)]\\ &amp; =\mathbb {E}_{x}[(f-g)^{2}]+\mathbb {E}_{x}[\lambda ^{2}d^{2}(x)]-2\mathbb {E}_{x}[(f-g)\cdot \lambda d(x)]\\ &amp; \leq ||f-g||_{2}^{2}+\lambda ^{2}-2\lambda \mathbb {E}_{x}[(f-g)d(x)]\\ &amp; \leq ||f-g||_{2}^{2}+\lambda ^{2}-2\lambda \epsilon \\ &amp; \leq ||f-g||_{2}^{2}-\epsilon ^{2} \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%7Cf-g%27%7C%7C_%7B2%7D%5E%7B2%7D+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g%27%29%5E%7B2%7D%28x%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g-%5Clambda+d%29%5E%7B2%7D%28x%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g%29%5E%7B2%7D%5D%2B%5Cmathbb+%7BE%7D_%7Bx%7D%5B%5Clambda+%5E%7B2%7Dd%5E%7B2%7D%28x%29%5D-2%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g%29%5Ccdot+%5Clambda+d%28x%29%5D%5C%5C+%26+%5Cleq+%7C%7Cf-g%7C%7C_%7B2%7D%5E%7B2%7D%2B%5Clambda+%5E%7B2%7D-2%5Clambda+%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g%29d%28x%29%5D%5C%5C+%26+%5Cleq+%7C%7Cf-g%7C%7C_%7B2%7D%5E%7B2%7D%2B%5Clambda+%5E%7B2%7D-2%5Clambda+%5Cepsilon+%5C%5C+%26+%5Cleq+%7C%7Cf-g%7C%7C_%7B2%7D%5E%7B2%7D-%5Cepsilon+%5E%7B2%7D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} ||f-g'||_{2}^{2} &amp; =\mathbb {E}_{x}[(f-g')^{2}(x)]\\ &amp; =\mathbb {E}_{x}[(f-g-\lambda d)^{2}(x)]\\ &amp; =\mathbb {E}_{x}[(f-g)^{2}]+\mathbb {E}_{x}[\lambda ^{2}d^{2}(x)]-2\mathbb {E}_{x}[(f-g)\cdot \lambda d(x)]\\ &amp; \leq ||f-g||_{2}^{2}+\lambda ^{2}-2\lambda \mathbb {E}_{x}[(f-g)d(x)]\\ &amp; \leq ||f-g||_{2}^{2}+\lambda ^{2}-2\lambda \epsilon \\ &amp; \leq ||f-g||_{2}^{2}-\epsilon ^{2} \end{aligned}"/></div>
<p>where the last line follows by taking <img alt="\lambda =\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda+%3D%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda =\epsilon "/>. Therefore, there can only be <img alt="1/\epsilon ^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/\epsilon ^{2}"/> iterations because <img alt="||f-g_{0}||_{2}^{2}=||f||_{2}^{2}\leq 1" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7Cf-g_%7B0%7D%7C%7C_%7B2%7D%5E%7B2%7D%3D%7C%7Cf%7C%7C_%7B2%7D%5E%7B2%7D%5Cleq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="||f-g_{0}||_{2}^{2}=||f||_{2}^{2}\leq 1"/>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<h4 class="subsectionHead"><span class="titlemark">7.3 </span> <a id="x1-180007.3"/>Getting more for rectangles</h4>
<p style="text-align: justify;">Returning to the main proof, we will use the weak regularity lemma to approximate the indicator function for arbitrary <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> by rectangles. That is, we take <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D"/> to be the collection of indicator functions for all sets of the form <img alt="S\times T" class="latex" src="https://s0.wp.com/latex.php?latex=S%5Ctimes+T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S\times T"/> for <img alt="S,T\subseteq G" class="latex" src="https://s0.wp.com/latex.php?latex=S%2CT%5Csubseteq+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S,T\subseteq G"/>. The weak regularity lemma shows how to decompose <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> into a linear combination of rectangles. These rectangles may overlap. However, we ideally want <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> to be a linear combination of <em>non-overlapping</em> rectangles. In other words, we want a <em>partition </em>of rectangles. It is possible to achieve this at the price of exponentiating the number of rectangles. Note that an exponential loss is necessary even if <img alt="S=G" class="latex" src="https://s0.wp.com/latex.php?latex=S%3DG&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S=G"/> in every <img alt="S\times T" class="latex" src="https://s0.wp.com/latex.php?latex=S%5Ctimes+T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S\times T"/> rectangle; or in other words in the uni-dimensional setting. This is one step where the terminology “rectangle” may be misleading – the set <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> is not necessarily an interval. If it was, a polynomial rather than exponential blow-up would have sufficed to remove overlaps.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-18001r14"/> Claim 14. </span>Given a decomposition of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> into rectangles from the weak regularity lemma with <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> functions, there exists a decomposition with <img alt="2^{O(s)}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BO%28s%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{O(s)}"/> rectangles which don’t overlap.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Exercise. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">In the above decomposition, note that it is natural to take the coefficients of rectangles to be the density of points in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> that are in the rectangle. This gives rise to the following claim.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-18002r15"/> Claim 15. </span>The weights of the rectangles in the above claim can be the average of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> in the rectangle, at the cost of doubling the error.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">Consequently, we have that <img alt="f=g+h" class="latex" src="https://s0.wp.com/latex.php?latex=f%3Dg%2Bh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f=g+h"/>, where <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> is the sum of <img alt="2^{O(s)}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BO%28s%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{O(s)}"/> non-overlapping rectangles <img alt="S\times T" class="latex" src="https://s0.wp.com/latex.php?latex=S%5Ctimes+T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S\times T"/> with coefficients <img alt="\mathbb{P} _{(x,y)\in S\times T}[f(x,y)=1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+_%7B%28x%2Cy%29%5Cin+S%5Ctimes+T%7D%5Bf%28x%2Cy%29%3D1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} _{(x,y)\in S\times T}[f(x,y)=1]"/>.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Let <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> be a partition decomposition with arbitrary weights. Let <img alt="g'" class="latex" src="https://s0.wp.com/latex.php?latex=g%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g'"/> be a partition decomposition with weights being the average of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>. It is enough to show that for all rectangle distinguishers <img alt="d\in D" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cin+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\in D"/></p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq |\mathbb {E}[(f-g)d]|. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb+%7BE%7D%5B%28f-g%27%29d%5D%7C%5Cleq+%7C%5Cmathbb+%7BE%7D%5B%28f-g%29d%5D%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq |\mathbb {E}[(f-g)d]|. \end{aligned}"/></div>
<p>By the triangle inequality, we have that</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq |\mathbb {E}[(f-g)d]|+|\mathbb {E}[(g-g')d]|. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb+%7BE%7D%5B%28f-g%27%29d%5D%7C%5Cleq+%7C%5Cmathbb+%7BE%7D%5B%28f-g%29d%5D%7C%2B%7C%5Cmathbb+%7BE%7D%5B%28g-g%27%29d%5D%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq |\mathbb {E}[(f-g)d]|+|\mathbb {E}[(g-g')d]|. \end{aligned}"/></div>
<p>To bound <img alt="\mathbb {E}[(g-g')d]|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5B%28g-g%27%29d%5D%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}[(g-g')d]|"/>, note that the error is maximized for a <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> that respects the decomposition in non-overlapping rectangles, i.e., <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> is the union of some non-overlapping rectangles from the decomposition. This can be argued using that, unlike <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>, the value of <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> and <img alt="g'" class="latex" src="https://s0.wp.com/latex.php?latex=g%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g'"/> on a rectangle <img alt="S\times T" class="latex" src="https://s0.wp.com/latex.php?latex=S%5Ctimes+T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S\times T"/> from the decomposition is fixed. But, from the point of “view” of such <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>, <img alt="g'=f" class="latex" src="https://s0.wp.com/latex.php?latex=g%27%3Df&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g'=f"/>! More formally, <img alt="\mathbb {E}[(g-g')d]=\mathbb {E}[(g-f)d]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5B%28g-g%27%29d%5D%3D%5Cmathbb+%7BE%7D%5B%28g-f%29d%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}[(g-g')d]=\mathbb {E}[(g-f)d]"/>. This gives</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq 2|\mathbb {E}[(f-g)d]| \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb+%7BE%7D%5B%28f-g%27%29d%5D%7C%5Cleq+2%7C%5Cmathbb+%7BE%7D%5B%28f-g%29d%5D%7C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq 2|\mathbb {E}[(f-g)d]| \end{aligned}"/></div>
<p>and concludes the proof. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">We need to get still a little more from this decomposition. In our application of the weak regularity lemma above, we took the set of distinguishers to be characteristic functions of rectangles. That is, distinguishers that can be written as <img alt="U(x)\cdot V(y)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28x%29%5Ccdot+V%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(x)\cdot V(y)"/> where <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> and <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> map <img alt="G\to \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5Cto+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G\to \{0,1\}"/>. We will use that the same guarantee holds for <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> and <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> with range <img alt="[-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-1,1]"/>, up to a constant factor loss in the error. Indeed, let <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> and <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> have range <img alt="[-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-1,1]"/>. Write <img alt="U=U_{+}-U_{-}" class="latex" src="https://s0.wp.com/latex.php?latex=U%3DU_%7B%2B%7D-U_%7B-%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U=U_{+}-U_{-}"/> where <img alt="U_{+}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B%2B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{+}"/> and <img alt="U_{-}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B-%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{-}"/> have range <img alt="[0,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[0,1]"/>, and the same for <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/>. The error for distinguisher <img alt="U\cdot V" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Ccdot+V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U\cdot V"/> is at most the sum of the errors for distinguishers <img alt="U_{+}\cdot V_{+}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B%2B%7D%5Ccdot+V_%7B%2B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{+}\cdot V_{+}"/>, <img alt="U_{+}\cdot V_{-}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B%2B%7D%5Ccdot+V_%7B-%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{+}\cdot V_{-}"/>, <img alt="U_{-}\cdot V_{+}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B-%7D%5Ccdot+V_%7B%2B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{-}\cdot V_{+}"/>, and <img alt="U_{-}\cdot V_{-}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B-%7D%5Ccdot+V_%7B-%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{-}\cdot V_{-}"/>. So we can restrict our attention to distinguishers <img alt="U(x)\cdot V(y)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28x%29%5Ccdot+V%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(x)\cdot V(y)"/> where <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> and <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> have range <img alt="[0,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[0,1]"/>. In turn, a function <img alt="U(x)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(x)"/> with range <img alt="[0,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[0,1]"/> can be written as an expectation <img alt="\mathbb{E} _{a}U_{a}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D+_%7Ba%7DU_%7Ba%7D%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{E} _{a}U_{a}(x)"/> for functions <img alt="U_{a}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7Ba%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{a}"/> with range <img alt="\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\}"/>, and the same for <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/>. We conclude by observing that</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb{E} _{x,y}[(f-g)(x,y)\mathbb{E} _{a}U_{a}(x)\cdot \mathbb{E} _{b}V_{b}(y)]\le \max _{a,b}\mathbb{E} _{x,y}[(f-g)(x,y)U_{a}(x)\cdot V_{b}(y)]. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb%7BE%7D+_%7Bx%2Cy%7D%5B%28f-g%29%28x%2Cy%29%5Cmathbb%7BE%7D+_%7Ba%7DU_%7Ba%7D%28x%29%5Ccdot+%5Cmathbb%7BE%7D+_%7Bb%7DV_%7Bb%7D%28y%29%5D%5Cle+%5Cmax+_%7Ba%2Cb%7D%5Cmathbb%7BE%7D+_%7Bx%2Cy%7D%5B%28f-g%29%28x%2Cy%29U_%7Ba%7D%28x%29%5Ccdot+V_%7Bb%7D%28y%29%5D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb{E} _{x,y}[(f-g)(x,y)\mathbb{E} _{a}U_{a}(x)\cdot \mathbb{E} _{b}V_{b}(y)]\le \max _{a,b}\mathbb{E} _{x,y}[(f-g)(x,y)U_{a}(x)\cdot V_{b}(y)]. \end{aligned}"/></div>
<h4 class="subsectionHead"><span class="titlemark">7.4 </span> <a id="x1-190007.4"/>Proof</h4>
<p style="text-align: justify;">Let us now finish the proof by showing a corner exists for sufficiently dense sets <img alt="A\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\subseteq G^{2}"/>. We’ll use three types of decompositions for <img alt="f:G^{2}\rightarrow \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3AG%5E%7B2%7D%5Crightarrow+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:G^{2}\rightarrow \{0,1\}"/>, with respect to the following three types of distinguishers, where <img alt="U_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{i}"/> and <img alt="V_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=V_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V_{i}"/> have range <img alt="\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\}"/>:</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-19002x1"><img alt="U_{1}(x)\cdot V_{1}(y)" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B1%7D%28x%29%5Ccdot+V_%7B1%7D%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{1}(x)\cdot V_{1}(y)"/>,</li>
<li class="enumerate" id="x1-19004x2"><img alt="U_{2}(xy)\cdot V_{2}(y)" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B2%7D%28xy%29%5Ccdot+V_%7B2%7D%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{2}(xy)\cdot V_{2}(y)"/>,</li>
<li class="enumerate" id="x1-19006x3"><img alt="U_{3}(x)\cdot V_{3}(xy)" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B3%7D%28x%29%5Ccdot+V_%7B3%7D%28xy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{3}(x)\cdot V_{3}(xy)"/>.</li>
</ol>
<p style="text-align: justify;">The first type is just rectangles, what we have been discussing until now. The distinguishers in the last two classes can be visualized over <img alt="\mathbb {R}^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BR%7D%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {R}^{2}"/> as parallelograms with a 45-degree angle. The same extra properties we discussed for rectangles can be verified hold for them too.</p>
<p style="text-align: justify;">Recall that we want to show</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}_{x,y,g}[f(x,y)f(xg,y)f(x,gy)]&gt;\frac {1}{|G|}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%7D%5Bf%28x%2Cy%29f%28xg%2Cy%29f%28x%2Cgy%29%5D%3E%5Cfrac+%7B1%7D%7B%7CG%7C%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}_{x,y,g}[f(x,y)f(xg,y)f(x,gy)]&gt;\frac {1}{|G|}. \end{aligned}"/></div>
<p>We’ll decompose the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>-th occurrence of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> via the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>-th decomposition listed above. We’ll write this decomposition as <img alt="f=g_{i}+h_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3Dg_%7Bi%7D%2Bh_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f=g_{i}+h_{i}"/>. We apply this in a certain order to produce sums of products of three functions. The inputs to the functions don’t change, so to avoid clutter we do not write them, and it is understood that in each product of three functions the inputs are, in order <img alt="(x,y),(xg,y),(x,gy)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29%2C%28xg%2Cy%29%2C%28x%2Cgy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y),(xg,y),(x,gy)"/>. The decomposition is:</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; fff\\ = &amp; ffg_{3}+ffh_{3}\\ = &amp; fg_{2}g_{3}+fh_{2}g_{3}+ffh_{3}\\ = &amp; g_{1}g_{2}g_{3}+h_{1}g_{2}g_{3}+fh_{2}g_{3}+ffh_{3}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+fff%5C%5C+%3D+%26+ffg_%7B3%7D%2Bffh_%7B3%7D%5C%5C+%3D+%26+fg_%7B2%7Dg_%7B3%7D%2Bfh_%7B2%7Dg_%7B3%7D%2Bffh_%7B3%7D%5C%5C+%3D+%26+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%2Bh_%7B1%7Dg_%7B2%7Dg_%7B3%7D%2Bfh_%7B2%7Dg_%7B3%7D%2Bffh_%7B3%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; fff\\ = &amp; ffg_{3}+ffh_{3}\\ = &amp; fg_{2}g_{3}+fh_{2}g_{3}+ffh_{3}\\ = &amp; g_{1}g_{2}g_{3}+h_{1}g_{2}g_{3}+fh_{2}g_{3}+ffh_{3}. \end{aligned}"/></div>
<p style="text-align: justify;">We first show that the expectation of the first term is big. This takes the next two claims. Then we show that the expectations of the other terms are small.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-19007r16"/> Claim 16. </span>For all <img alt="g\in G" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\in G"/>, the expectations <img alt="\mathbb {E}_{x,y}[g_{1}(x,y)g_{2}(xg,y)g_{3}(x,gy)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Bg_%7B1%7D%28x%2Cy%29g_%7B2%7D%28xg%2Cy%29g_%7B3%7D%28x%2Cgy%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}_{x,y}[g_{1}(x,y)g_{2}(xg,y)g_{3}(x,gy)]"/> are the same up to an error of <img alt="2^{O(s)}/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BO%28s%29%7D%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{O(s)}/|G|^{\Omega (1)}"/>.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We just need to get error <img alt="1/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|^{\Omega (1)}"/> for any product of three functions for the three decomposition types. We have:</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; \mathbb {E}_{x,y}[c_{1}U_{1}(x)V_{1}(y)\cdot c_{2}U_{2}(xgy)V_{2}(y)\cdot c_{3}U_{3}(x)V_{3}(xgy)]\\ = &amp; c_{1}c_{2}c_{3}\mathbb {E}_{x,y}[(U_{1}\cdot U_{3})(x)(V_{1}\cdot V_{2})(y)(U_{2}\cdot V_{3})(xgy)]\\ = &amp; c_{1}c_{2}c_{3}\cdot \mathbb {E}_{x}[(U_{1}\cdot U_{3})(x)]\cdot \mathbb {E}_{y}[(V_{1}\cdot V_{2})(y)]\cdot \mathbb {E}_{z}[(U_{2}\cdot V_{3})(z)]\pm \frac {1}{|G|^{\Omega (1)}}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Bc_%7B1%7DU_%7B1%7D%28x%29V_%7B1%7D%28y%29%5Ccdot+c_%7B2%7DU_%7B2%7D%28xgy%29V_%7B2%7D%28y%29%5Ccdot+c_%7B3%7DU_%7B3%7D%28x%29V_%7B3%7D%28xgy%29%5D%5C%5C+%3D+%26+c_%7B1%7Dc_%7B2%7Dc_%7B3%7D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5B%28U_%7B1%7D%5Ccdot+U_%7B3%7D%29%28x%29%28V_%7B1%7D%5Ccdot+V_%7B2%7D%29%28y%29%28U_%7B2%7D%5Ccdot+V_%7B3%7D%29%28xgy%29%5D%5C%5C+%3D+%26+c_%7B1%7Dc_%7B2%7Dc_%7B3%7D%5Ccdot+%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28U_%7B1%7D%5Ccdot+U_%7B3%7D%29%28x%29%5D%5Ccdot+%5Cmathbb+%7BE%7D_%7By%7D%5B%28V_%7B1%7D%5Ccdot+V_%7B2%7D%29%28y%29%5D%5Ccdot+%5Cmathbb+%7BE%7D_%7Bz%7D%5B%28U_%7B2%7D%5Ccdot+V_%7B3%7D%29%28z%29%5D%5Cpm+%5Cfrac+%7B1%7D%7B%7CG%7C%5E%7B%5COmega+%281%29%7D%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; \mathbb {E}_{x,y}[c_{1}U_{1}(x)V_{1}(y)\cdot c_{2}U_{2}(xgy)V_{2}(y)\cdot c_{3}U_{3}(x)V_{3}(xgy)]\\ = &amp; c_{1}c_{2}c_{3}\mathbb {E}_{x,y}[(U_{1}\cdot U_{3})(x)(V_{1}\cdot V_{2})(y)(U_{2}\cdot V_{3})(xgy)]\\ = &amp; c_{1}c_{2}c_{3}\cdot \mathbb {E}_{x}[(U_{1}\cdot U_{3})(x)]\cdot \mathbb {E}_{y}[(V_{1}\cdot V_{2})(y)]\cdot \mathbb {E}_{z}[(U_{2}\cdot V_{3})(z)]\pm \frac {1}{|G|^{\Omega (1)}}. \end{aligned}"/></div>
<p style="text-align: justify;">This is similar to what we discussed in the overview, and is where we use mixing. Specifically, if <img alt="\mathbb {E}_{x}[(U_{1}\cdot U_{3})(x)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28U_%7B1%7D%5Ccdot+U_%7B3%7D%29%28x%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}_{x}[(U_{1}\cdot U_{3})(x)]"/> or <img alt="\mathbb {E}_{y}[(V_{1}\cdot V_{2})(y)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7By%7D%5B%28V_%7B1%7D%5Ccdot+V_%7B2%7D%29%28y%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}_{y}[(V_{1}\cdot V_{2})(y)]"/> are at most <img alt="1/|G|^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|^{c}"/> for a small enough constant <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/> than we are done. Otherwise, conditioned on <img alt="(U_{1}\cdot U_{3})(x)=1" class="latex" src="https://s0.wp.com/latex.php?latex=%28U_%7B1%7D%5Ccdot+U_%7B3%7D%29%28x%29%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(U_{1}\cdot U_{3})(x)=1"/>, the distribution on <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> is uniform over a set of density <img alt="1/|G|^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|^{c}"/>, and the same holds for <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/>, and the result follows by Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7<!--tex4ht:ref: lem:XY-mixing --></a>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">Recall that we start with a set of density <img alt="\ge 1/\log ^{a}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cge+1%2F%5Clog+%5E%7Ba%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ge 1/\log ^{a}|G|"/>.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-19008r17"/> Claim 17. </span><img alt="\mathbb {E}_{x,y}[g_{1}(x,y)g_{2}(x,y)g_{3}(x,y)]&gt;1/\log ^{4a}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Bg_%7B1%7D%28x%2Cy%29g_%7B2%7D%28x%2Cy%29g_%7B3%7D%28x%2Cy%29%5D%3E1%2F%5Clog+%5E%7B4a%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}_{x,y}[g_{1}(x,y)g_{2}(x,y)g_{3}(x,y)]&gt;1/\log ^{4a}|G|"/>.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We will relate the expectation over <img alt="x,y" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y"/> to <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> using the Hölder inequality: For random variables <img alt="X_{1},X_{2},\ldots ,X_{k}" class="latex" src="https://s0.wp.com/latex.php?latex=X_%7B1%7D%2CX_%7B2%7D%2C%5Cldots+%2CX_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_{1},X_{2},\ldots ,X_{k}"/>,</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}[X_{1}\dots X_{k}]\leq \prod _{i=1}^{k}\mathbb {E}[X_{i}^{c_{i}}]^{1/c_{i}}\text { such that }\sum 1/c_{i}=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D%5BX_%7B1%7D%5Cdots+X_%7Bk%7D%5D%5Cleq+%5Cprod+_%7Bi%3D1%7D%5E%7Bk%7D%5Cmathbb+%7BE%7D%5BX_%7Bi%7D%5E%7Bc_%7Bi%7D%7D%5D%5E%7B1%2Fc_%7Bi%7D%7D%5Ctext+%7B+such+that+%7D%5Csum+1%2Fc_%7Bi%7D%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}[X_{1}\dots X_{k}]\leq \prod _{i=1}^{k}\mathbb {E}[X_{i}^{c_{i}}]^{1/c_{i}}\text { such that }\sum 1/c_{i}=1. \end{aligned}"/></div>
<p style="text-align: justify;">To apply this inequality in our setting, write</p>
<div style="text-align: center;"><img alt="\begin{aligned} f=(f\cdot g_{1}g_{2}g_{3})^{1/4}\cdot \left (\frac {f}{g_{1}}\right )^{1/4}\cdot \left (\frac {f}{g_{2}}\right )^{1/4}\cdot \left (\frac {f}{g_{3}}\right )^{1/4}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%3D%28f%5Ccdot+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%29%5E%7B1%2F4%7D%5Ccdot+%5Cleft+%28%5Cfrac+%7Bf%7D%7Bg_%7B1%7D%7D%5Cright+%29%5E%7B1%2F4%7D%5Ccdot+%5Cleft+%28%5Cfrac+%7Bf%7D%7Bg_%7B2%7D%7D%5Cright+%29%5E%7B1%2F4%7D%5Ccdot+%5Cleft+%28%5Cfrac+%7Bf%7D%7Bg_%7B3%7D%7D%5Cright+%29%5E%7B1%2F4%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} f=(f\cdot g_{1}g_{2}g_{3})^{1/4}\cdot \left (\frac {f}{g_{1}}\right )^{1/4}\cdot \left (\frac {f}{g_{2}}\right )^{1/4}\cdot \left (\frac {f}{g_{3}}\right )^{1/4}. \end{aligned}"/></div>
<p>By the Hölder inequality the expectation of the right-hand side is</p>
<div style="text-align: center;"><img alt="\begin{aligned} \leq \mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}\mathbb {E}\left [\frac {f}{g_{1}}\right ]^{1/4}\mathbb {E}\left [\frac {f}{g_{2}}\right ]^{1/4}\mathbb {E}\left [\frac {f}{g_{3}}\right ]^{1/4}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleq+%5Cmathbb+%7BE%7D%5Bf%5Ccdot+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%5D%5E%7B1%2F4%7D%5Cmathbb+%7BE%7D%5Cleft+%5B%5Cfrac+%7Bf%7D%7Bg_%7B1%7D%7D%5Cright+%5D%5E%7B1%2F4%7D%5Cmathbb+%7BE%7D%5Cleft+%5B%5Cfrac+%7Bf%7D%7Bg_%7B2%7D%7D%5Cright+%5D%5E%7B1%2F4%7D%5Cmathbb+%7BE%7D%5Cleft+%5B%5Cfrac+%7Bf%7D%7Bg_%7B3%7D%7D%5Cright+%5D%5E%7B1%2F4%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \leq \mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}\mathbb {E}\left [\frac {f}{g_{1}}\right ]^{1/4}\mathbb {E}\left [\frac {f}{g_{2}}\right ]^{1/4}\mathbb {E}\left [\frac {f}{g_{3}}\right ]^{1/4}. \end{aligned}"/></div>
<p>The last three terms equal to <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> because</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}_{x,y}\frac {f(x,y)}{g_{i}(x,y)} &amp; =\mathbb {E}_{x,y}\frac {f(x,y)}{\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}=\mathbb {E}_{x,y}\frac {\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}{\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Cfrac+%7Bf%28x%2Cy%29%7D%7Bg_%7Bi%7D%28x%2Cy%29%7D+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Cfrac+%7Bf%28x%2Cy%29%7D%7B%5Cmathbb+%7BE%7D_%7Bx%27%2Cy%27%5Cin+%5Ctextit+%7BCell%7D%28x%2Cy%29%7D%5Bf%28x%27%2Cy%27%29%5D%7D%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Cfrac+%7B%5Cmathbb+%7BE%7D_%7Bx%27%2Cy%27%5Cin+%5Ctextit+%7BCell%7D%28x%2Cy%29%7D%5Bf%28x%27%2Cy%27%29%5D%7D%7B%5Cmathbb+%7BE%7D_%7Bx%27%2Cy%27%5Cin+%5Ctextit+%7BCell%7D%28x%2Cy%29%7D%5Bf%28x%27%2Cy%27%29%5D%7D%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}_{x,y}\frac {f(x,y)}{g_{i}(x,y)} &amp; =\mathbb {E}_{x,y}\frac {f(x,y)}{\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}=\mathbb {E}_{x,y}\frac {\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}{\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}=1. \end{aligned}"/></div>
<p>where <img alt="\textit {Cell}(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextit+%7BCell%7D%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\textit {Cell}(x,y)"/> is the set in the partition that contains <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/>. Putting the above together we obtain</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}[f]\leq \mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D%5Bf%5D%5Cleq+%5Cmathbb+%7BE%7D%5Bf%5Ccdot+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%5D%5E%7B1%2F4%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}[f]\leq \mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}. \end{aligned}"/></div>
<p>Finally, because the functions are positive, we have that <img alt="\mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}\leq \mathbb {E}[g_{1}g_{2}g_{3}]^{1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5Bf%5Ccdot+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%5D%5E%7B1%2F4%7D%5Cleq+%5Cmathbb+%7BE%7D%5Bg_%7B1%7Dg_%7B2%7Dg_%7B3%7D%5D%5E%7B1%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}\leq \mathbb {E}[g_{1}g_{2}g_{3}]^{1/4}"/>. This concludes the proof. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">It remains to show the other terms are small. Let <img alt="\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon "/> be the error in the weak regularity lemma with respect to distinguishers with range <img alt="\{0,1\} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\} "/>. Recall that this implies error <img alt="O(\epsilon )" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Cepsilon+%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\epsilon )"/> with respect to distinguishers with range <img alt="[-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-1,1]"/>. We give the proof for one of the terms and then we say little about the other two.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-19009r18"/> Claim 18. </span><img alt="|\mathbb {E}[f(x,y)f(xg,y)h_{3}(x,gy)]|\leq O(\epsilon )^{1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb+%7BE%7D%5Bf%28x%2Cy%29f%28xg%2Cy%29h_%7B3%7D%28x%2Cgy%29%5D%7C%5Cleq+O%28%5Cepsilon+%29%5E%7B1%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathbb {E}[f(x,y)f(xg,y)h_{3}(x,gy)]|\leq O(\epsilon )^{1/4}"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">The proof involves changing names of variables and doing Cauchy-Schwarz to remove the terms with <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> and bound the expectation above by <img alt="\mathbb {E}[h_{3}(x,g)U(x)V(xg)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5Bh_%7B3%7D%28x%2Cg%29U%28x%29V%28xg%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}[h_{3}(x,g)U(x)V(xg)]"/>, which is small by the regularity lemma.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Replace <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> with <img alt="gy^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=gy%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="gy^{-1}"/> in the uniform distribution to get</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; \mathbb {E}_{x,y,g}^{4}[f(x,y)f(xg,y)h_{3}(x,gy)]\\ &amp; =\mathbb {E}_{x,y,g}^{4}[f(x,y)f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; =\mathbb {E}_{x,y}^{4}[f(x,y)\mathbb {E}_{g}[f(xgy^{-1},y)h_{3}(x,g)]]\\ &amp; \leq \mathbb {E}_{x,y}^{2}[f^{2}(x,y)]\mathbb {E}_{x,y}^{2}\mathbb {E}_{g}^{2}[f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; \leq \mathbb {E}_{x,y}^{2}\mathbb {E}_{g}^{2}[f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; =\mathbb {E}_{x,y,g,g'}^{2}[f(xgy^{-1},y)h_{3}(x,g)f(xg'y^{-1},y)h_{3}(x,g')], \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%7D%5E%7B4%7D%5Bf%28x%2Cy%29f%28xg%2Cy%29h_%7B3%7D%28x%2Cgy%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%7D%5E%7B4%7D%5Bf%28x%2Cy%29f%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5E%7B4%7D%5Bf%28x%2Cy%29%5Cmathbb+%7BE%7D_%7Bg%7D%5Bf%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29%5D%5D%5C%5C+%26+%5Cleq+%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5E%7B2%7D%5Bf%5E%7B2%7D%28x%2Cy%29%5D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5E%7B2%7D%5Cmathbb+%7BE%7D_%7Bg%7D%5E%7B2%7D%5Bf%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29%5D%5C%5C+%26+%5Cleq+%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5E%7B2%7D%5Cmathbb+%7BE%7D_%7Bg%7D%5E%7B2%7D%5Bf%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%2Cg%27%7D%5E%7B2%7D%5Bf%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29f%28xg%27y%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%27%29%5D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; \mathbb {E}_{x,y,g}^{4}[f(x,y)f(xg,y)h_{3}(x,gy)]\\ &amp; =\mathbb {E}_{x,y,g}^{4}[f(x,y)f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; =\mathbb {E}_{x,y}^{4}[f(x,y)\mathbb {E}_{g}[f(xgy^{-1},y)h_{3}(x,g)]]\\ &amp; \leq \mathbb {E}_{x,y}^{2}[f^{2}(x,y)]\mathbb {E}_{x,y}^{2}\mathbb {E}_{g}^{2}[f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; \leq \mathbb {E}_{x,y}^{2}\mathbb {E}_{g}^{2}[f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; =\mathbb {E}_{x,y,g,g'}^{2}[f(xgy^{-1},y)h_{3}(x,g)f(xg'y^{-1},y)h_{3}(x,g')], \end{aligned}"/></div>
<p>where the first inequality is by Cauchy-Schwarz.</p>
<p style="text-align: justify;">Now replace <img alt="g\rightarrow x^{-1}g,g'\rightarrow x^{-1}g" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Crightarrow+x%5E%7B-1%7Dg%2Cg%27%5Crightarrow+x%5E%7B-1%7Dg&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\rightarrow x^{-1}g,g'\rightarrow x^{-1}g"/> and reason in the same way:</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; =\mathbb {E}_{x,y,g,g'}^{2}[f(gy^{-1},y)h_{3}(x,x^{-1}g)f(g'y^{-1},y)h_{3}(x,x^{-1}g')]\\ &amp; =\mathbb {E}_{g,g',y}^{2}[f(gy^{-1},y)\cdot f(g'y^{-1},y)\mathbb {E}_{x}[h_{3}(x,x^{-1}g)\cdot h_{3}(x,x^{-1}g')]]\\ &amp; \leq \mathbb {E}_{x,x',g,g'}[h_{3}(x,x^{-1}g)h_{3}(x,x^{-1}g')h_{3}(x',x'^{-1}g)h_{3}(x',x'^{-1}g')]. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%2Cg%27%7D%5E%7B2%7D%5Bf%28gy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%29f%28g%27y%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%27%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bg%2Cg%27%2Cy%7D%5E%7B2%7D%5Bf%28gy%5E%7B-1%7D%2Cy%29%5Ccdot+f%28g%27y%5E%7B-1%7D%2Cy%29%5Cmathbb+%7BE%7D_%7Bx%7D%5Bh_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%29%5Ccdot+h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%27%29%5D%5D%5C%5C+%26+%5Cleq+%5Cmathbb+%7BE%7D_%7Bx%2Cx%27%2Cg%2Cg%27%7D%5Bh_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%29h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%27%29h_%7B3%7D%28x%27%2Cx%27%5E%7B-1%7Dg%29h_%7B3%7D%28x%27%2Cx%27%5E%7B-1%7Dg%27%29%5D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; =\mathbb {E}_{x,y,g,g'}^{2}[f(gy^{-1},y)h_{3}(x,x^{-1}g)f(g'y^{-1},y)h_{3}(x,x^{-1}g')]\\ &amp; =\mathbb {E}_{g,g',y}^{2}[f(gy^{-1},y)\cdot f(g'y^{-1},y)\mathbb {E}_{x}[h_{3}(x,x^{-1}g)\cdot h_{3}(x,x^{-1}g')]]\\ &amp; \leq \mathbb {E}_{x,x',g,g'}[h_{3}(x,x^{-1}g)h_{3}(x,x^{-1}g')h_{3}(x',x'^{-1}g)h_{3}(x',x'^{-1}g')]. \end{aligned}"/></div>
<p style="text-align: justify;">Replace <img alt="g\rightarrow xg" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Crightarrow+xg&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\rightarrow xg"/> to rewrite the expectation as</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}[h_{3}(x,g)h_{3}(x,x^{-1}g')h_{3}(x',x'^{-1}xg)h_{3}(x',x'^{-1}g')]. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D%5Bh_%7B3%7D%28x%2Cg%29h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%27%29h_%7B3%7D%28x%27%2Cx%27%5E%7B-1%7Dxg%29h_%7B3%7D%28x%27%2Cx%27%5E%7B-1%7Dg%27%29%5D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}[h_{3}(x,g)h_{3}(x,x^{-1}g')h_{3}(x',x'^{-1}xg)h_{3}(x',x'^{-1}g')]. \end{aligned}"/></div>
<p style="text-align: justify;">We want to view the last three terms as a distinguisher <img alt="U(x)\cdot V(xg)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28x%29%5Ccdot+V%28xg%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(x)\cdot V(xg)"/>. First, note that <img alt="h_{3}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{3}"/> has range <img alt="[-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-1,1]"/>. This is because <img alt="h_{3}(x,y)=f(x,y)-\mathbb{E} _{x',y'\in \textit {Cell}(x,y)}f(x',y')" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7B3%7D%28x%2Cy%29%3Df%28x%2Cy%29-%5Cmathbb%7BE%7D+_%7Bx%27%2Cy%27%5Cin+%5Ctextit+%7BCell%7D%28x%2Cy%29%7Df%28x%27%2Cy%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{3}(x,y)=f(x,y)-\mathbb{E} _{x',y'\in \textit {Cell}(x,y)}f(x',y')"/> and <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> has range <img alt="\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\}"/>, where recall that <img alt="Cell(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=Cell%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Cell(x,y)"/> is the set in the partition that contains <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/>. Fix <img alt="x',g'" class="latex" src="https://s0.wp.com/latex.php?latex=x%27%2Cg%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x',g'"/>. The last term in the expectation becomes a constant <img alt="c\in [-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cin+%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\in [-1,1]"/>. The second term only depends on <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, and the third only on <img alt="xg" class="latex" src="https://s0.wp.com/latex.php?latex=xg&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="xg"/>. Hence for appropriate functions <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> and <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> with range <img alt="[-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-1,1]"/> this expectation can be rewritten as</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}[h_{3}(x,g)U(x)V(xg)], \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D%5Bh_%7B3%7D%28x%2Cg%29U%28x%29V%28xg%29%5D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}[h_{3}(x,g)U(x)V(xg)], \end{aligned}"/></div>
<p>which concludes the proof. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">There are similar proofs to show the remaining terms are small. For <img alt="fh_{2}g_{3}" class="latex" src="https://s0.wp.com/latex.php?latex=fh_%7B2%7Dg_%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="fh_{2}g_{3}"/>, we can perform simple manipulations and then reduce to the above case. For <img alt="h_{1}g_{2}g_{3}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7B1%7Dg_%7B2%7Dg_%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{1}g_{2}g_{3}"/>, we have a slightly easier proof than above.</p>
<h5 class="subsubsectionHead"><span class="titlemark">7.4.1 </span> <a id="x1-200007.4.1"/>Parameters</h5>
<p style="text-align: justify;">Suppose our set has density <img alt="\delta \ge 1/\log ^{a}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cge+1%2F%5Clog+%5E%7Ba%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta \ge 1/\log ^{a}|G|"/>, and the error in the regularity lemma is <img alt="\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon "/>. By the above results we can bound</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}_{x,y,g}[f(x,y)f(xg,y)f(x,gy)]\ge 1/\log ^{4a}|G|-2^{O(1/\epsilon ^{2})}/|G|^{\Omega (1)}-\epsilon ^{\Omega (1)}, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%7D%5Bf%28x%2Cy%29f%28xg%2Cy%29f%28x%2Cgy%29%5D%5Cge+1%2F%5Clog+%5E%7B4a%7D%7CG%7C-2%5E%7BO%281%2F%5Cepsilon+%5E%7B2%7D%29%7D%2F%7CG%7C%5E%7B%5COmega+%281%29%7D-%5Cepsilon+%5E%7B%5COmega+%281%29%7D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}_{x,y,g}[f(x,y)f(xg,y)f(x,gy)]\ge 1/\log ^{4a}|G|-2^{O(1/\epsilon ^{2})}/|G|^{\Omega (1)}-\epsilon ^{\Omega (1)}, \end{aligned}"/></div>
<p>where the terms in the right-hand size come, left-to-right from Claim <a href="https://emanueleviola.wordpress.com/feed/#x1-19008r17">17<!--tex4ht:ref: claim:austin-g1 --></a>, <a href="https://emanueleviola.wordpress.com/feed/#x1-19007r16">16<!--tex4ht:ref: claim:austin-same-for-every-g --></a>, and <a href="https://emanueleviola.wordpress.com/feed/#x1-19009r18">18<!--tex4ht:ref: claim:austin-h-error --></a>. Picking <img alt="\epsilon =1/\log ^{1/3}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1%2F%5Clog+%5E%7B1%2F3%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon =1/\log ^{1/3}|G|"/> the proof is completed for sufficiently small <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/>.</p>
<h3 class="likesectionHead"><a id="x1-210007.4.1"/>References</h3>
<div class="thebibliography">
<p class="bibitem"><span class="biblabel"> [AL00] <span class="bibsp">   </span></span><a id="XAmbainisL00"/>Andris Ambainis and Satyanarayana V. Lokam. Imroved upper bounds on the simultaneous messages complexity of the generalized addressing function. In Latin American Symposium on Theoretical Informatics (LATIN), pages 207–216, 2000.</p>
<p class="bibitem"><span class="biblabel"> [Amb96] <span class="bibsp">   </span></span><a id="XAmbainis96"/>Andris Ambainis. Upper bounds on multiparty communication complexity of shifts. In Symp. on Theoretical Aspects of Computer Science (STACS), pages 631–642, 1996.</p>
<p class="bibitem"><span class="biblabel"> [AMS99] <span class="bibsp">   </span></span><a id="XAMS99"/>Noga Alon, Yossi Matias, and Mario Szegedy. The space complexity of approximating the frequency moments. J. of Computer and System Sciences, 58(1, part 2):137–147, 1999.</p>
<p class="bibitem"><span class="biblabel"> [Aus16] <span class="bibsp">   </span></span><a id="XAustin2016"/>Tim Austin. Ajtai-Szemerédi theorems over quasirandom groups. In Recent trends in combinatorics, volume 159 of IMA Vol. Math. Appl., pages 453–484. Springer, [Cham], 2016.</p>
<p class="bibitem"><span class="biblabel"> [Bar89] <span class="bibsp">   </span></span><a id="XBarrington89"/>David A. Mix Barrington. Bounded-width polynomial-size branching programs recognize exactly those languages in NC<img alt="^1" class="latex" src="https://s0.wp.com/latex.php?latex=%5E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="^1"/>. J. of Computer and System Sciences, 38(1):150–164, 1989.</p>
<p class="bibitem"><span class="biblabel"> [BC92] <span class="bibsp">   </span></span><a id="XBen-OrC92"/>Michael Ben-Or and Richard Cleve. Computing algebraic formulas using a constant number of registers. SIAM J. on Computing, 21(1):54–58, 1992.</p>
<p class="bibitem"><span class="biblabel"> [BDPW10]<span class="bibsp">   </span></span><a id="XBeameDPW10"/>Paul Beame, Matei David, Toniann Pitassi, and Philipp Woelfel. Separating deterministic from randomized multiparty communication complexity. Theory of Computing, 6(1):201–225, 2010.</p>
<p class="bibitem"><span class="biblabel"> [BGKL03] <span class="bibsp">   </span></span><a id="XBGKL03"/>László Babai, Anna Gál, Peter G. Kimmel, and Satyanarayana V. Lokam. Communication complexity of simultaneous messages. SIAM J. on Computing, 33(1):137–166, 2003.</p>
<p class="bibitem"><span class="biblabel"> [BNP08] <span class="bibsp">   </span></span><a id="XBabaiNP08"/>László Babai, Nikolay Nikolov, and László Pyber. Product growth and mixing in finite groups. In ACM-SIAM Symp. on Discrete Algorithms (SODA), pages 248–257, 2008.</p>
<p class="bibitem"><span class="biblabel"> [CFL83] <span class="bibsp">   </span></span><a id="XCFL83"/>Ashok K. Chandra, Merrick L. Furst, and Richard J. Lipton. Multi-party protocols. In 15th ACM Symp. on the Theory of Computing (STOC), pages 94–99, 1983.</p>
<p class="bibitem"><span class="biblabel"> [CP10] <span class="bibsp">   </span></span><a id="XDBLP:journals/sigact/ChattopadhyayP10"/>Arkadev Chattopadhyay and Toniann Pitassi. The story of set disjointness. SIGACT News, 41(3):59–85, 2010.</p>
<p class="bibitem"><span class="biblabel"> [DHKP97] <span class="bibsp">   </span></span><a id="XDietzfelbingerHKP97"/>Martin Dietzfelbinger, Torben Hagerup, Jyrki Katajainen, and Martti Penttonen. A reliable randomized algorithm for the closest-pair problem. J. Algorithms, 25(1):19–51, 1997.</p>
<p class="bibitem"><span class="biblabel"> [FK96] <span class="bibsp">   </span></span><a id="XDBLP:conf/focs/FriezeK96"/>Alan M. Frieze and Ravi Kannan. The regularity lemma and approximation schemes for dense problems. In IEEE Symp. on Foundations of Computer Science (FOCS), pages 12–20, 1996.</p>
<p class="bibitem"><span class="biblabel"> [Gow08] <span class="bibsp">   </span></span><a id="XGowers08"/>W. T. Gowers. Quasirandom groups. Combinatorics, Probability &amp; Computing, 17(3):363–387, 2008.</p>
<p class="bibitem"><span class="biblabel"> [Gre05a] <span class="bibsp">   </span></span><a id="XGreen-supplement"/>Ben Green. An argument of Shkredov in the finite field setting, 2005. Available at people.maths.ox.ac.uk/greenbj/papers/corners.pdf.</p>
<p class="bibitem"><span class="biblabel"> [Gre05b] <span class="bibsp">   </span></span><a id="XGre04-finite"/>Ben Green. Finite field models in additive combinatorics. Surveys in Combinatorics, London Math. Soc. Lecture Notes 327, 1-27, 2005.</p>
<p class="bibitem"><span class="biblabel"> [GVa] <span class="bibsp">   </span></span><a id="XGowersV-cc-int-journal"/>W. T. Gowers and Emanuele Viola. Interleaved group products. SIAM J. on Computing.</p>
<p class="bibitem"><span class="biblabel"> [GVb] <span class="bibsp">   </span></span><a id="XGowersV-cc-int-2"/>W. T. Gowers and Emanuele Viola. The multiparty communication complexity of interleaved group products. SIAM J. on Computing.</p>
<p class="bibitem"><span class="biblabel"> [GV15] <span class="bibsp">   </span></span><a id="XGowersV-cc-int"/>W. T. Gowers and Emanuele Viola. The communication complexity of interleaved group products. In ACM Symp. on the Theory of Computing (STOC), 2015.</p>
<p class="bibitem"><span class="biblabel"> [IL95] <span class="bibsp">   </span></span><a id="XImmermanL95"/>Neil Immerman and Susan Landau. The complexity of iterated multiplication. Inf. Comput., 116(1):103–116, 1995.</p>
<p class="bibitem"><span class="biblabel"> [KMR66] <span class="bibsp">   </span></span><a id="XKrohnMR66"/>Kenneth Krohn, W. D. Maurer, and John Rhodes. Realizing complex Boolean functions with simple groups. Information and Control, 9:190–195, 1966.</p>
<p class="bibitem"><span class="biblabel"> [KN97] <span class="bibsp">   </span></span><a id="XKuN97"/>Eyal Kushilevitz and Noam Nisan. Communication complexity. Cambridge University Press, 1997.</p>
<p class="bibitem"><span class="biblabel"> [KS92] <span class="bibsp">   </span></span><a id="XKalyanasundaramS92"/>Bala Kalyanasundaram and Georg Schnitger. The probabilistic communication complexity of set intersection. SIAM J. Discrete Math., 5(4):545–557, 1992.</p>
<p class="bibitem"><span class="biblabel"> [LM07] <span class="bibsp">   </span></span><a id="XMR2289954"/>Michael T. Lacey and William McClain. On an argument of Shkredov on two-dimensional corners. Online J. Anal. Comb., (2):Art. 2, 21, 2007.</p>
<p class="bibitem"><span class="biblabel"> [LW54] <span class="bibsp">   </span></span><a id="XLangWeil54"/>Serge Lang and André Weil. Number of points of varieties in finite fields. American Journal of Mathematics, 76:819–827, 1954.</p>
<p class="bibitem"><span class="biblabel"> [Mil14] <span class="bibsp">   </span></span><a id="XMiles14"/>Eric Miles. Iterated group products and leakage resilience against <img alt="NC^1" class="latex" src="https://s0.wp.com/latex.php?latex=NC%5E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="NC^1"/>. In ACM Innovations in Theoretical Computer Science conf. (ITCS), 2014.</p>
<p class="bibitem"><span class="biblabel"> [MV13] <span class="bibsp">   </span></span><a id="XMilesV-leak"/>Eric Miles and Emanuele Viola. Shielding circuits with groups. In ACM Symp. on the Theory of Computing (STOC), 2013.</p>
<p class="bibitem"><span class="biblabel"> [PRS97] <span class="bibsp">   </span></span><a id="XPRS97"/>Pavel Pudlák, Vojtěch Rödl, and Jiří Sgall. Boolean circuits, tensor ranks, and communication complexity. SIAM J. on Computing, 26(3):605–633, 1997.</p>
<p class="bibitem"><span class="biblabel"> [Raz92] <span class="bibsp">   </span></span><a id="XRazborov92"/>Alexander A. Razborov. On the distributional complexity of disjointness. Theor. Comput. Sci., 106(2):385–390, 1992.</p>
<p class="bibitem"><span class="biblabel"> [Raz00] <span class="bibsp">   </span></span><a id="XRaz00"/>Ran Raz. The BNS-Chung criterion for multi-party communication complexity. Computational Complexity, 9(2):113–122, 2000.</p>
<p class="bibitem"><span class="biblabel"> [RY19] <span class="bibsp">   </span></span><a id="XRaoY2019"/>Anup Rao and Amir Yehudayoff. Communication complexity. 2019. <a href="https://homes.cs.washington.edu/&#xA0;anuprao/pubs/book.pdf" rel="nofollow">https://homes.cs.washington.edu/ anuprao/pubs/book.pdf</a>.</p>
<p class="bibitem"><span class="biblabel"> [Sha16] <span class="bibsp">   </span></span><a id="XShalev16"/>Aner Shalev. Mixing, communication complexity and conjectures of Gowers and Viola. Combinatorics, Probability and Computing, pages 1–13, 6 2016. arXiv:1601.00795.</p>
<p class="bibitem"><span class="biblabel"> [She14] <span class="bibsp">   </span></span><a id="XSherstov14-35years"/>Alexander A. Sherstov. Communication complexity theory: Thirty-five years of set disjointness. In Symp. on Math. Foundations of Computer Science (MFCS), pages 24–43, 2014.</p>
<p class="bibitem"><span class="biblabel"> [Tao17] <span class="bibsp">   </span></span><a id="XTao2017-szemerediproof"/>Terence Tao. Szemerédiâs proof of Szemerédiâs theorem, 2017. <a href="https://terrytao.files.wordpress.com/2017/09/szemeredi-proof1.pdf" rel="nofollow">https://terrytao.files.wordpress.com/2017/09/szemeredi-proof1.pdf</a>.</p>
<p class="bibitem"><span class="biblabel"> [Vioa] <span class="bibsp">   </span></span><a id="Xviola-blog-mixing-in-groups"/>Emanuele Viola. Thoughts: Mixing in groups. <a href="https://emanueleviola.wordpress.com/2016/10/21/mixing-in-groups/" rel="nofollow">https://emanueleviola.wordpress.com/2016/10/21/mixing-in-groups/</a>.</p>
<p class="bibitem"><span class="biblabel"> [Viob] <span class="bibsp">   </span></span><a id="Xviola-blog-mixing-in-groups-ii"/>Emanuele Viola. Thoughts: Mixing in groups ii. <a href="https://emanueleviola.wordpress.com/2016/11/15/mixing-in-groups-ii/" rel="nofollow">https://emanueleviola.wordpress.com/2016/11/15/mixing-in-groups-ii/</a>.</p>
<p class="bibitem"><span class="biblabel"> [Vio14] <span class="bibsp">   </span></span><a id="XViola-ccsum"/>Emanuele Viola. The communication complexity of addition. Combinatorica, pages 1–45, 2014.</p>
<p class="bibitem"><span class="biblabel"> [Vio17] <span class="bibsp">   </span></span><a id="Xviola-special-topics17"/>Emanuele Viola. Special topics in complexity theory. Lecture notes of the class taught at Northeastern University. Available at <a href="http://www.ccs.neu.edu/home/viola/classes/spepf17.html" rel="nofollow">http://www.ccs.neu.edu/home/viola/classes/spepf17.html</a>, 2017.</p>
<p class="bibitem"><span class="biblabel"> [Yao79] <span class="bibsp">   </span></span><a id="XYao79"/>Andrew Chi-Chih Yao. Some complexity questions related to distributive computing. In 11th ACM Symp. on the Theory of Computing (STOC), pages 209–213, 1979.</p>
</div>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-07-10T17:00:32Z</updated>
    <published>2019-07-10T17:00:32Z</published>
    <category term="Uncategorized"/>
    <category term="lecture"/>
    <category term="lower bounds"/>
    <author>
      <name>Emanuele</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2019-07-14T04:21:19Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2019/07/10/trajectories-linear-nets/</id>
    <link href="http://offconvex.github.io/2019/07/10/trajectories-linear-nets/" rel="alternate" type="text/html"/>
    <title>Understanding implicit regularization in deep learning by analyzing trajectories of gradient descent</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Sanjeev’s <a href="http://www.offconvex.org/2019/06/03/trajectories/">recent blog post</a> suggested that the conventional view of optimization is insufficient for understanding deep learning, as the value of the training objective does not reliably capture generalization.
He argued that instead, we need to consider the <em>trajectories</em> of optimization.
One of the illustrative examples given was our <a href="https://arxiv.org/abs/1905.13655">new paper with Sanjeev Arora and Yuping Luo</a>, which studies the use of deep linear neural networks for solving <a href="https://en.wikipedia.org/wiki/Matrix_completion"><em>matrix completion</em></a> more accurately than the classic convex programming approach. 
The current post provides more details on this result.</p>

<p>Recall that in matrix completion we are given some entries $\{ M_{i, j} : (i, j) \in \Omega \}$ of an unknown <em>ground truth</em> matrix $M$, and our goal is to recover the remaining entries.
This can be thought of as a supervised learning (regression) problem, where the training examples are the observed entries of $M$, the model is a matrix $W$ trained with the loss:
[
L(W) = \sum\nolimits_{(i, j) \in \Omega} (W_{i, j} - M_{i, j})^2 ~,
]
and generalization corresponds to how similar $W$ is to $M$ in the unobserved locations.
Obviously the problem is ill-posed if we assume nothing about $M$ $-$ the loss $L(W)$ is underdetermined, i.e. has multiple optima, and it would be impossible to tell (without access to unobserved entries) if one solution is better than another.
The standard assumption (which has many <a href="https://en.wikipedia.org/wiki/Matrix_completion#Applications">practical applications</a>) is that the ground truth matrix $M$ is low-rank, and thus the goal is to find, from among all global minima of the loss $L(W)$, one with minimal rank. 
The classic algorithm for achieving this is to find the matrix with minimum <a href="https://en.wikipedia.org/wiki/Matrix_norm#Schatten_norms"><em>nuclear norm</em></a>. 
This is a convex program, which <em>given enough observed entries</em> (and under mild technical assumptions $-$ “incoherence”) recovers the ground truth exactly (cf. <a href="https://statweb.stanford.edu/~candes/papers/MatrixCompletion.pdf">Candes and Recht</a>). 
We’re interested in the regime where the number of revealed entries is too small for the classic algorithm to succeed.
There it can be beaten by a simple deep learning approach, as described next.</p>

<h2 id="linear-neural-networks-lnn">Linear Neural Networks (LNN)</h2>

<p>A linear neural network (LNN) is a fully-connected neural network with linear activation (i.e. no non-linearity).
If $W_j$ is the weight matrix in layer $j$ of a depth $N$ network, the <em>end-to-end matrix</em> is given by $W = W_N W_{N-1} \cdots W_1$.
Our method for solving matrix completion involves minimizing the loss $L(W)$ by running gradient descent (GD) on this (over-)parameterization, with depth $N \geq 2$ and hidden dimensions that do not constrain rank.
This can be viewed as a deep learning problem with $\ell_2$ loss, and GD can be implemented through the chain rule as usual.
Note that the training objective does not include any regularization term controlling the individual layer matrices $\{ W_j \}_j$.</p>

<p>At first glance our algorithm seems naive, since parameterization by an LNN (that does not constrain rank) is equivalent to parameterization by a single matrix $W$, and obviously running GD on $L(W)$ directly with no regularization is not a good approach (nothing will be learned in the unobserved locations).
However, since matrix completion is an underdetermined problem (has multiple optima), the optimum reached by GD can vary depending on the chosen parameterization.
Our setup isolates the role of over-parameterization in implicitly biasing GD towards certain optima (that hopefully generalize well).</p>

<p>Note that in the special case of depth $N = 2$ our method reduces to a traditional approach for matrix completion,  named <em>matrix factorization</em>. 
By analogy, we refer to the case $N \geq 3$ as <em>deep matrix factorization</em>. 
The table below shows reconstruction errors (generalization) on a matrix completion task where the number of observed entries is too small for nuclear norm minimization to succeed.
As can be seen, it is outperformed by matrix factorization, which itself is outperformed by deep matrix factorization.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/trajectories-linear-nets-exp-reconst-errs.png" style="width: 700px;"/>
<br/>
<b>Table 1:</b> Results for matrix completion with small number of observations.
</div>
<p><br/>
The main focus of our paper is on developing a theoretical understanding of this phenomenon.</p>

<h2 id="trajectory-analysis-implicit-regularization-towards-low-rank">Trajectory Analysis: Implicit Regularization Towards Low Rank</h2>

<p>We are interested in understanding what end-to-end matrix $W$ emerges when we run GD on an LNN to minimize a general convex loss $L(W)$, and in particular the matrix completion loss given above. 
Note that $L(W)$ is convex, but the objective obtained by over-parameterizing with an LNN is not.
We analyze the trajectories of $W$, and specifically the dynamics of its singular value decomposition.
Denote the singular values by $\{ \sigma_r \}_r$, and the corresponding left and right singular vectors by $\{ \mathbf{u}_r \}_r$ and $\{ \mathbf{v}_r \}_r$ respectively.</p>

<p>We start by considering GD applied to $L(W)$ directly (no over-parameterization).</p>

<blockquote>
  <p><strong>Known result:</strong>
Minimizing $L(W)$ directly by GD (with small learning rate $\eta$) leads the singular values of $W$ to evolve by:
[
\sigma_r(t + 1) \leftarrow \sigma_r(t) - \eta \cdot \langle \nabla L(W(t)) , \mathbf{u}_r(t) \mathbf{v}_r^\top(t) \rangle ~.
\qquad (1)
]</p>
</blockquote>

<p>This statement implies that the movement of a singular value is proportional to the projection of the gradient onto the corresponding singular component.</p>

<p>Now suppose that we parameterize $W$ with an $N$-layer LNN, i.e. as $W = W_N W_{N-1} \cdots W_1$.
In previous work (described in <a href="http://www.offconvex.org/2018/03/02/acceleration-overparameterization/">Nadav’s earlier blog post</a>) we have shown that running GD on the LNN, with small learning rate $\eta$ and initialization close to the origin, leads the end-to-end matrix $W$ to evolve by:</p>



<p>In the new paper we rely on this result to prove the following:</p>

<blockquote>
  <p><strong>Theorem:</strong>
Minimizing $L(W)$ by running GD (with small learning rate $\eta$ and initialization close to the origin) on an $N$-layer LNN leads the singular values of $W$ to evolve by:
[ \sigma_r(t + 1) \leftarrow \sigma_r(t) - \eta \cdot \langle \nabla L(W(t)) , \mathbf{u}_r(t) \mathbf{v}_r^\top(t) \rangle \cdot \color{purple}{N \cdot (\sigma_r(t))^{2 - 2 / N}} ~.
]</p>
</blockquote>

<p>Comparing this to Equation $(1)$, we see that over-parameterizing the loss $L(W)$ with an $N$-layer LNN introduces the multiplicative factors $\color{purple}{N \cdot (\sigma_r(t))^{2 - 2 / N}}$ to the evolution of singular values.
While the constant $N$ does not change relative dynamics (can be absorbed into the learning rate $\eta$), the terms $(\sigma_r(t))^{2 - 2 / N}$ do $-$ they enhance movement of large singular values, and on the hand attenuate that of small ones.
Moreover, the enhancement/attenuation becomes more significant as $N$ (network depth) grows.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/trajectories-linear-nets-thm-dynamics.png" style="width: 900px;"/>
<br/>
<b>Figure 1:</b> Over-parameterizing with LNN modifies dynamics of singular values.
</div>
<p><br/></p>

<p>The enhancement/attenuation effect induced by an LNN (factors $\color{purple}{N \cdot (\sigma_r(t))^{2 - 2 / N}}$) leads each singular value to progress very slowly after initialization, when close to zero, and then, upon reaching a certain threshold, move rapidly, with the transition from slow to rapid movement being sharper in case of a deeper network (larger $N$).
If the loss $L(W)$ is underdetermined (has multiple optima) these dynamics promote solutions that have a few large singular values and many small ones (that have yet to reach the phase transition between slow to rapid movement), with a gap that is more extreme the deeper the network is. 
This is an implicit regularization towards low rank, which intensifies with depth.
In the paper we support the intuition with empirical evaluations and theoretical illustrations, demonstrating how adding depth to an LNN can lead GD to produce solutions closer to low-rank.
For example, the following plots, corresponding to a task of matrix completion, show evolution of singular values throughout training of networks with varying depths $-$ as can be seen, adding layers indeed admits a final solution whose spectrum is closer to low-rank, thereby improving generalization.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/trajectories-linear-nets-exp-dynamics.png" style="width: 900px;"/>
<br/>
<b>Figure 2:</b> Dynamics of singular values in training matrix factorizations (LNN).
</div>

<h2 id="do-the-trajectories-minimize-some-regularized-objective">Do the Trajectories Minimize Some Regularized Objective?</h2>

<p>In recent years, researchers have come to realize the importance of implicit regularization induced by the choice of optimization algorithm.
The strong gravitational pull of the conventional view on optimization (see <a href="http://www.offconvex.org/2019/06/03/trajectories/">Sanjeev’s post</a>) has led most papers on this line to try and capture the effect in the language of regularized objectives. 
For example, it is known that over linear models, i.e. depth $1$ networks, GD finds the solution with minimal Frobenius norm (cf. Section 5 in <a href="https://openreview.net/pdf?id=Sy8gdB9xx">Zhang et al.</a>), and a common hypothesis is that this persists over more elaborate neural networks, with Frobenius norm potentially replaced by some other norm (or quasi-norm) that depends on network architecture.
<a href="https://papers.nips.cc/paper/7195-implicit-regularization-in-matrix-factorization.pdf">Gunasekar et al.</a> explicitly conjectured:</p>

<blockquote>
  <p><strong>Conjecture (by <a href="https://papers.nips.cc/paper/7195-implicit-regularization-in-matrix-factorization.pdf">Gunasekar et al.</a>, informally stated):</strong>
GD (with small learning rate and near-zero initialization) training a matrix factorization finds a solution with minimum <a href="https://en.wikipedia.org/wiki/Matrix_norm#Schatten_norms">nuclear norm</a>.</p>
</blockquote>

<p>This conjecture essentially states that matrix factorization (i.e. $2$-layer LNN) trained by GD is equivalent to the famous method of nuclear norm minimization.
Gunasekar et al. motivated the conjecture with some empirical evidence, as well as mathematical evidence in the form of a proof for a (very) restricted setting.</p>

<p>Given the empirical observation by which adding depth to a matrix factorization can improve results in matrix completion, it would be natural to extend the conjecture of Gunasekar et al., and assert that the implicit regularization with depth $3$ or higher corresponds to minimizing some other norm (or quasi-norm) that approximates rank better than nuclear norm does.
For example, a natural candidate would be a <a href="https://en.wikipedia.org/wiki/Schatten_norm">Schatten-$p$ quasi-norm</a> with some $0 &lt; p &lt; 1$.</p>

<p>Our investigation began with this approach, but ultimately, we became skeptical of the entire “implicit regularization as norm minimization” line of reasoning, and in particular of the conjecture by Gunasekar et al.</p>

<blockquote>
  <p><strong>Theorem (mathematical evidence against the conjecture):</strong>
In the same restricted setting for which Gunasekar et al. proved their conjecture, nuclear norm is minimized by GD over matrix factorization not only with depth $2$, but with any depth $\geq 3$ as well.</p>
</blockquote>

<p>This theorem disqualifies Schatten quasi-norms as the implicit regularization in deep matrix factorizations, and instead suggests that all depths correspond to nuclear norm.
However, empirically we found a notable difference in performance between different depths, so the conceptual leap from a proof in the restricted setting to a general conjecture, as done by Gunasekar et al., seems questionable.</p>

<p>In the paper we conduct a systematic set of experiments to empirically evaluate the conjecture.
We find that in the regime where nuclear norm minimization is suboptimal (few observed entries), matrix factorizations consistently outperform it (see for example Table 1).
This holds in particular with depth $2$, in contrast to the conjecture’s prediction.
Together, our theory and experiments lead us to believe that it may not be possible to capture the implicit regularization in LNN with a single mathematical norm (or quasi-norm).</p>

<p>Full details behind our results on “implicit regularization as norm minimization” can be found in Section 2 of <a href="https://arxiv.org/abs/1905.13655">the paper</a>.
The trajectory analysis we discussed earlier appears in Section 3 there.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The <a href="http://www.offconvex.org/2019/06/03/trajectories/">conventional view of optimization</a> has been integral to the theory of machine learning. 
Our study suggests that the associated vocabulary may not suffice for understanding generalization in deep learning, and one should instead analyze trajectories of optimization, taking into account that speed of convergence does not necessarily correlate with generalization.
We hope this work will motivate development of a new vocabulary for analyzing deep learning.</p></div>
    </summary>
    <updated>2019-07-10T17:00:00Z</updated>
    <published>2019-07-10T17:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2019-07-13T23:52:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blogs.princeton.edu/imabandit/?p=1382</id>
    <link href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/" rel="alternate" type="text/html"/>
    <title>Guest post by Julien Mairal: A Kernel Point of View on Convolutional Neural Networks, part I</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>    I (n.b., Julien Mairal) have been interested in drawing links between neural networks and kernel methods for some time, and I am grateful to Sebastien for giving me the opportunity to say a few words about it on … <a href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/">Continue reading <span class="meta-nav">→</span></a></p></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> </p>
<p><a class="liimagelink" href="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/kernel_fig.jpg?ssl=1"><img alt="" class="alignnone wp-image-1393" height="368" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/kernel_fig.jpg?resize=646%2C368&amp;ssl=1" width="646"/></a></p>
<p> </p>
<p>I (<em>n.b., <a class="liinternal" href="https://lear.inrialpes.fr/people/mairal/">Julien Mairal</a></em>) have been interested in drawing links between neural networks and kernel methods for some time, and I am grateful to Sebastien for giving me the opportunity to say a few words about it on his blog. My initial motivation was not to provide another “why deep learning works” theory, but simply to encode into kernel methods a few successful principles from convolutional neural networks (CNNs), such as the ability to model the local stationarity of natural images at multiple scales—we may call that modeling receptive fields—along with feature compositions and invariant representations. There was also something challenging in trying to reconcile end-to-end deep neural networks and non-parametric methods based on kernels that typically decouple data representation from the learning task.</p>
<p>The main goal of this blog post is then to discuss the construction of a particular multilayer kernel for images that encodes the previous principles, derive some invariance and stability properties for CNNs, and also present a simple mechanism to perform feature learning in reproducing kernel Hilbert spaces. In other words, we should not see any intrinsic contradiction between kernels and representation learning.</p>
<p><strong>Preliminaries on kernel methods</strong></p>
<p>Given data living in a set <img alt="\mathcal{X}" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e44d6dd2d58e906a7f3ec11d7f3cac9c_l3.png?resize=15%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="15"/>, a positive definite kernel <img alt="K: \mathcal{X} \times \mathcal{X} \to \mathbb{R}" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-f0d19a1401658006e20eb7aff7c20689_l3.png?resize=124%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="124"/> implicitly defines a Hilbert space <img alt="\mathcal{H}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d8c7ae0e5e08bd1b3f5ef053720bf142_l3.png?resize=15%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="15"/> of functions from <img alt="\mathcal{X}" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e44d6dd2d58e906a7f3ec11d7f3cac9c_l3.png?resize=15%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="15"/> to <img alt="\mathbb{R}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b2c3c459eddec9847f841b19a2274a3d_l3.png?resize=13%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="13"/>, called reproducing kernel Hilbert space (RKHS), along with a mapping function <img alt="\varphi: \mathcal{X} \to \mathcal{H}" class="ql-img-inline-formula " height="16" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-075eb9a40ac7f19fc1d24932d430cf57_l3.png?resize=84%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="84"/>.</p>
<p>A predictive model <img alt="f" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="10"/> in <img alt="\mathcal{H}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d8c7ae0e5e08bd1b3f5ef053720bf142_l3.png?resize=15%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="15"/> associates to every point <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> a label in <img alt="\mathbb{R}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b2c3c459eddec9847f841b19a2274a3d_l3.png?resize=13%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="13"/>, and admits a simple form <img alt="f(x) =\langle f, \varphi(x) \rangle_{\mathcal{H}}" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-af2242f529038b9f66bdd803a7fcf32d_l3.png?resize=138%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="138"/>. Then, Cauchy-Schwarz inequality gives us a first basic stability property</p>
<p class="ql-center-displayed-equation" style="line-height: 21px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \forall x, x'\in \mathcal{X},~~~~~ |f(x)-f(x')| \leq \|f\|_{\mathcal{H}} \| \varphi(x) - \varphi(x')\|_\mathcal{H}. \]" class="ql-img-displayed-equation " height="21" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ba1f97e9889116f67e3caf7d27f6dca2_l3.png?resize=418%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="418"/></p>
<p>This relation exhibits a discrepancy between neural networks and kernel methods. Whereas neural networks optimize the data representation for a specific task, the term on the right involves the product of two quantities where data representation and learning are decoupled:</p>
<p><img alt="\|\varphi(x)-\varphi(x')\|_\mathcal{H}" class="ql-img-inline-formula " height="19" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9b7eefc0051c0b86a82ee0265f44a085_l3.png?resize=125%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="125"/> is a distance between two data representations <img alt="\varphi(x),\varphi(x')" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-41c6c60616e1acea2bdd02deee51011e_l3.png?resize=83%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="83"/>, which are independent of the learning process, and <img alt="\|f\|_\mathcal{H}" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c755a8a9349d0895075e9494d1b11fc1_l3.png?resize=38%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="38"/> is a norm on the model <img alt="f" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="10"/> (typically optimized over data) that acts as a measure of complexity.</p>
<p>Thinking about neural networks in terms of kernel methods then requires defining the underlying representation <img alt="\varphi(x)" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-eb419c2adecf84ed9a2d9693bc58d101_l3.png?resize=35%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/>, which can only depend on the network architecture, and the model <img alt="f" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="10"/>, which will be parametrized by (learned) network’s weights.</p>
<p><strong>Building a convolutional kernel for convolutional neural networks</strong></p>
<p>Following <a class="lipdf" href="http://jmlr.org/papers/volume20/18-190/18-190.pdf">Alberto Bietti’s paper</a>, we now consider the direct construction of a multilayer convolutional kernel for images. Given a two-dimensional image <img alt="x_0" class="ql-img-inline-formula " height="11" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-55b536a6647748d6c0c6b58015805c68_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/>, the main idea is to build a sequence of “feature maps” <img alt="x_1,x_2,\ldots" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4e504020251e8444e8047821206317fa_l3.png?resize=71%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="71"/> that are two-dimensional spatial maps carrying information about image neighborhoods (a.k.a receptive fields) at every location. As we proceed in this sequence, the goal is to model larger neighborhoods with more “invariance”.</p>
<p>Formally, an input image <img alt="x_0" class="ql-img-inline-formula " height="11" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-55b536a6647748d6c0c6b58015805c68_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> is represented as a square-integrable function in <img alt="L^2(\Omega,\mathcal{H}_0)" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b1cdcac953d52ed35e77925a243c3df7_l3.png?resize=76%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="76"/>, where <img alt="\Omega" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ec0c546b6596f336d8e1d41bb064b951_l3.png?resize=12%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="12"/> is a set of pixel coordinates, and <img alt="\mathcal{H}_0" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c58a47e1230e20fa0f090bbe6e111ba7_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/> is a Hilbert space. <img alt="\Omega" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ec0c546b6596f336d8e1d41bb064b951_l3.png?resize=12%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="12"/> may be a discrete grid or a continuous domain such as <img alt="\mathbb{R}^2" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d5abe0f29e8cc710ae26f4f0af5a0859_l3.png?resize=20%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="20"/>, and <img alt="\mathcal{H}_0" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c58a47e1230e20fa0f090bbe6e111ba7_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/> may simply be <img alt="\mathbb{R}^3" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-97886402213f48c46e631e5331a34035_l3.png?resize=20%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="20"/> for RGB images. Then, a feature map <img alt="x_k" class="ql-img-inline-formula " height="11" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ad23c5c360c3f33031a5d000d37416f_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> in <img alt="L^2(\Omega,\mathcal{H}_k)" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-66fdb69a62e8ec8647eac89f54998a71_l3.png?resize=77%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="77"/> is obtained from a previous layer <img alt="x_{k-1}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/> as follows:</p>
<ul>
<li><em> modeling larger neighborhoods than in the previous layer:</em> we map neighborhoods (patches) from <img alt="x_{k-1}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/> to a new Hilbert space <img alt="\mathcal{H}_k" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc26f0de4084a72b9e625a080bd5d674_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/>. Concretely, we define a homogeneous dot-product kernel between patches <img alt="z, z'" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ce80943b7f55934d998e09542933b73e_l3.png?resize=30%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="30"/> from <img alt="x_{k-1}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/>:
<p class="ql-center-displayed-equation" style="line-height: 43px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ K_k(z,z') = \|z\| \|z'\| \kappa_k \left( \left\langle \frac{z}{\|z\|}, \frac{z'}{\|z'\|} \right\rangle \right), \]" class="ql-img-displayed-equation " height="43" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e98e6c584e7aa34a129d04fa46a6981c_l3.png?resize=304%2C43&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="304"/></p>
<p> where <img alt="\langle . , . \rangle" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b62527a227d32e3e2f43b8b9b2b31ad5_l3.png?resize=29%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="29"/> is an inner-product derived from <img alt="\mathcal{H}_{k-1}" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ec7eee8a3bac08b4c319cfce53408682_l3.png?resize=39%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="39"/>, and <img alt="\kappa_k" class="ql-img-inline-formula " height="11" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-684fcf23472c51919624049fb4e0129a_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> is a non-linear function that ensures positive definiteness, <em>e.g.</em>, <img alt="\kappa_k(\langle u,u'\rangle ) = e^{\alpha (\langle u,u'\rangle -1)} = e^{-\frac{\alpha}{2}\|u-u'\|^2}" class="ql-img-inline-formula " height="23" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-46c64b76ccc9f508d30fec2fb80e244d_l3.png?resize=289%2C23&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="289"/> for vectors <img alt="u, u'" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0b88ce07daf9a52ba8a46659cff355fd_l3.png?resize=32%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="32"/> with unit norm, see <a class="lipdf" href="http://jmlr.org/papers/volume20/18-190/18-190.pdf">this paper</a>. By doing so, we implicitly define a kernel mapping <img alt="\varphi_k" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-243ed60e88d807834cd7cb1e1fbe0658_l3.png?resize=19%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="19"/> that maps patches from <img alt="x_{k-1}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/> to a new Hilbert space <img alt="\mathcal{H}_k" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc26f0de4084a72b9e625a080bd5d674_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/>. This mechanism is illustrated in the picture at the beginning of the post, and produces a spatial map that carries these patch representations.</p></li>
<li><em>increasing invariance:</em> to gain invariance to small deformations, we smooth~<img alt="x_{k-1}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/> with a linear filter, as shown in the picture at the beginning of the post, which may be interpreted as anti-aliasing (in terms of signal processing) or linear pooling (in terms of neural networks).</li>
</ul>
<p>Formally, the previous construction amounts to applying operators <img alt="P_k" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4726bbf70431cf284be54bbc6a04ad60_l3.png?resize=18%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="18"/> (patch extraction), <img alt="M_k" class="ql-img-inline-formula " height="15" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78f07026bc8c5150a11bf9e00756b7a7_l3.png?resize=24%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="24"/> (kernel mapping), and <img alt="A_k" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-866de181a59a21d2ca2306a9adbd9bc1_l3.png?resize=20%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> (smoothing/pooling operator) to <img alt="x_{k-1}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/> such that the <img alt="n" class="ql-img-inline-formula " height="8" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a63eb5ff0272d3119fa684be6e7acce8_l3.png?resize=11%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/>-th layer representation can be written as</p>
<p class="ql-center-displayed-equation" style="line-height: 21px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \Phi_n(x_0)= x_n= A_n M_n P_n \ldots A_1 M_1 P_1 x_0~~~\text{in}~~~~L^2(\Omega,\mathcal{H}_n). \]" class="ql-img-displayed-equation " height="21" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e8c2d99cc679426d1af08e6d15510211_l3.png?resize=437%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="437"/></p>
<p>We may finally define a kernel for images as <img alt="\mathcal{K}_n(x_0,x_0')=\langle \Phi_n(x_0), \Phi_n(x_0') \rangle" class="ql-img-inline-formula " height="19" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-16be084d5dd2ed3d7a18cdcf70c33fe2_l3.png?resize=231%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="231"/>, whose RKHS contains the functions <img alt="f_w(x_0) = \langle w , \Phi_n(x_0) \rangle" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-95aa9a4388dd5f5da6292875abe6596a_l3.png?resize=162%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="162"/> for <img alt="w" class="ql-img-inline-formula " height="8" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78d46af3f19bae0d88ac0cabd450a296_l3.png?resize=13%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="13"/> in <img alt="L^2(\Omega,\mathcal{H}_n)" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-502d385c60e5ecdb1a0f26ee770d30b1_l3.png?resize=77%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="77"/>. Note now that we have introduced a concept of image representation <img alt="\Phi_n" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/>, which only depends on some network architecture (amounts of pooling, patch size), and predictive model <img alt="f_w" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-fb636251e88ba51d909c76c1110eed5e_l3.png?resize=19%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="19"/> parametrized by <img alt="w" class="ql-img-inline-formula " height="8" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78d46af3f19bae0d88ac0cabd450a296_l3.png?resize=13%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="13"/>.</p>
<p>From such a construction, we will now derive stability results for classical convolutional neural networks (CNNs) and then derive non-standard CNNs based on kernel approximations that we call convolutional kernel networks (CKNs).</p>
<p> </p>
<p>Next week, we will see how to perform feature (end-to-end) learning with the previous kernel representation, and also discuss other classical links between neural networks and kernel methods.</p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-07-10T15:20:34Z</updated>
    <published>2019-07-10T15:20:34Z</published>
    <category term="Machine learning"/>
    <author>
      <name>Sebastien Bubeck</name>
    </author>
    <source>
      <id>https://blogs.princeton.edu/imabandit</id>
      <link href="https://blogs.princeton.edu/imabandit/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blogs.princeton.edu/imabandit" rel="alternate" type="text/html"/>
      <subtitle>Random topics in optimization, probability, and statistics. By Sébastien Bubeck</subtitle>
      <title>I’m a bandit</title>
      <updated>2019-07-13T23:52:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/092</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/092" rel="alternate" type="text/html"/>
    <title>TR19-092 |  Revisiting Alphabet Reduction in Dinur&amp;#39;s PCP | 

	Venkatesan Guruswami, 

	Jakub Opršal, 

	Sai Sandeep</title>
    <summary>Dinur's celebrated proof of the PCP theorem alternates two main steps in several iterations: gap amplification to increase the soundness gap by a large constant factor (at the expense of much larger alphabet size), and a composition step that brings back the alphabet size to an absolute constant (at the expense of a fixed constant factor loss in the soundness gap). We note that the gap amplification can produce a Label Cover CSP. This allows us to reduce the alphabet size via a direct long-code based reduction from Label Cover to a Boolean CSP. Our composition step thus bypasses the concept of Assignment Testers from Dinur's proof, and we believe it is more intuitive --- it is just a gadget reduction. The analysis also uses only elementary facts (Parseval's identity) about Fourier Transforms over the hypercube.</summary>
    <updated>2019-07-09T16:04:11Z</updated>
    <published>2019-07-09T16:04:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-14T04:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17523</id>
    <link href="https://gilkalai.wordpress.com/2019/07/09/imre-barany-limit-shape/" rel="alternate" type="text/html"/>
    <title>Imre Bárány: Limit shape</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Limit shapes are fascinating objects in the interface between probability and geometry and between the discrete and the continuous. This post is kindly contributed by Imre Bárány. What is a limit shape? There are finitely many convex lattice polygons contained … <a href="https://gilkalai.wordpress.com/2019/07/09/imre-barany-limit-shape/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>Limit shapes are fascinating objects in the interface between probability and geometry and between the discrete and the continuous. This post is kindly contributed by Imre Bárány.</em></p>
<h3><a href="https://gilkalai.files.wordpress.com/2019/07/imre_barany_2011.jpg"><img alt="" class="alignnone size-full wp-image-17560" src="https://gilkalai.files.wordpress.com/2019/07/imre_barany_2011.jpg?w=640"/></a></h3>
<h2>What is a limit shape?</h2>
<p>There are finitely many convex lattice polygons contained in the <img alt="{[0,n]^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B0%2Cn%5D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[0,n]^2}"/> square. Their number turns out to be</p>
<p><img alt="\displaystyle \exp\{3\sqrt[3]{\zeta(3)/\zeta(2)}n^{2/3}(1+o(1))\}. \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cexp%5C%7B3%5Csqrt%5B3%5D%7B%5Czeta%283%29%2F%5Czeta%282%29%7Dn%5E%7B2%2F3%7D%281%2Bo%281%29%29%5C%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \exp\{3\sqrt[3]{\zeta(3)/\zeta(2)}n^{2/3}(1+o(1))\}. \ \ \ \ \ (1)"/></p>
<p>This is a large number. How does a typical element of this large set look? Is there a<br/>
limit shape of these convex lattice polygons?</p>
<p>To answer this question it is convenient to consider the lattice <img alt="{{\mathbb{Z}}_n=\frac 1n {\mathbb{Z}}^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%3D%5Cfrac+1n+%7B%5Cmathbb%7BZ%7D%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n=\frac 1n {\mathbb{Z}}^2}"/> and define <img alt="{\mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n}"/> as the family of all convex <img alt="{{\mathbb{Z}}_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n}"/>-lattice polygons lying in the unit square <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/>. The polygons in <img alt="{\mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n}"/> have a limit shape (as <img alt="{n\rightarrow \infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n\rightarrow \infty}"/>) if there is a convex set <img alt="{K\subset Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%5Csubset+Q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K\subset Q}"/> such that the overwhelming majority of the polygons in <img alt="{\mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n}"/> are very close to <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/>. In other words, for every <img alt="{\epsilon&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon&gt;0}"/> the number of polygons in <img alt="{\mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n}"/> that are farther than <img alt="{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon}"/> from <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> (in Hausdorff distance, say) is a minute part of <img alt="{\mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n}"/>, that is, <img alt="{o(|\mathcal{F}^n|)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bo%28%7C%5Cmathcal%7BF%7D%5En%7C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{o(|\mathcal{F}^n|)}"/> as <img alt="{n \rightarrow \infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \rightarrow \infty}"/>. To put it differently, the average of the characteristic functions <img alt="{\chi_P(.)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_P%28.%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_P(.)}"/> of <img alt="{P\in \mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%5Cin+%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P\in \mathcal{F}^n}"/> tends to a zero-one function:</p>
<p><img alt="\lim {\rm Ave}_{P\in \mathcal{F}^n}\chi_P(x)=\begin{cases} 1&amp; \mbox{ if } x \in K,\\ 0&amp; \mbox{ if } x \notin K. \end{cases} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Clim+%7B%5Crm+Ave%7D_%7BP%5Cin+%5Cmathcal%7BF%7D%5En%7D%5Cchi_P%28x%29%3D%5Cbegin%7Bcases%7D+1%26+%5Cmbox%7B+if+%7D+x+%5Cin+K%2C%5C%5C+0%26+%5Cmbox%7B+if+%7D+x+%5Cnotin+K.+%5Cend%7Bcases%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lim {\rm Ave}_{P\in \mathcal{F}^n}\chi_P(x)=\begin{cases} 1&amp; \mbox{ if } x \in K,\\ 0&amp; \mbox{ if } x \notin K. \end{cases} "/></p>
<h2>The limit shape theorem</h2>
<h3/>
<p>The limit shape theorem says that such a <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> exists, its boundary consists of four parabola arcs each touching consecutive sides of <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q"/> at their midpoints, see the figure.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/limitshape.png"><img alt="" class="alignnone size-full wp-image-17536" src="https://gilkalai.files.wordpress.com/2019/07/limitshape.png?w=640"/></a></p>
<h3>Generating functions and saddle point methods</h3>
<p>The proof is based on the fact that a convex (lattice or non-lattice) polygon with vertices <img alt="v_1,\ldots,v_n" class="latex" src="https://s0.wp.com/latex.php?latex=v_1%2C%5Cldots%2Cv_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v_1,\ldots,v_n"/> (in this order on its boundary) is uniquely determined by the edge-vectors <img alt="v_2-v_1,\ldots,v_n-v_{n-1}, v_1-v_n" class="latex" src="https://s0.wp.com/latex.php?latex=v_2-v_1%2C%5Cldots%2Cv_n-v_%7Bn-1%7D%2C+v_1-v_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v_2-v_1,\ldots,v_n-v_{n-1}, v_1-v_n"/>. Using this one can write down the generating function of the number of convex lattice paths from <img alt="(0,0)" class="latex" src="https://s0.wp.com/latex.php?latex=%280%2C0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(0,0)"/> to <img alt="(a,b)\in \mathbb{Z}^2" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29%5Cin+%5Cmathbb%7BZ%7D%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)\in \mathbb{Z}^2"/> lying in the triangle whose vertices are <img alt="(0,0),(a,0)" class="latex" src="https://s0.wp.com/latex.php?latex=%280%2C0%29%2C%28a%2C0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(0,0),(a,0)"/> and <img alt="(a,b)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)"/>. And this number can be estimated by saddle point methods (from complex variables). This is also how formula (1) for <img alt="|\mathcal{F}^n|" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathcal%7BF%7D%5En%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathcal{F}^n|"/> can be established.</p>
<h3>A beautiful geometric result</h3>
<p>On the geometry part one needs a beautiful (and almost elementary) result saying that, in a triangle <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> with vertices <img alt="1,2,3" class="latex" src="https://s0.wp.com/latex.php?latex=1%2C2%2C3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1,2,3"/> and with subtriangles <img alt="T_1" class="latex" src="https://s0.wp.com/latex.php?latex=T_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T_1"/> and <img alt="T_2" class="latex" src="https://s0.wp.com/latex.php?latex=T_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T_2"/> (see the figure)</p>
<p><img alt="\displaystyle \sqrt[3]{\textrm{Area} \; T}\ge \sqrt[3]{\textrm{Area} \; T_1}+\sqrt[3]{\textrm{Area} \; T_2}, \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T%7D%5Cge+%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T_1%7D%2B%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T_2%7D%2C+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \sqrt[3]{\textrm{Area} \; T}\ge \sqrt[3]{\textrm{Area} \; T_1}+\sqrt[3]{\textrm{Area} \; T_2}, \ \ \ \ \ (2)"/></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/triangle.png"><img alt="" class="alignnone size-full wp-image-17537" src="https://gilkalai.files.wordpress.com/2019/07/triangle.png?w=640"/></a></p>
<p>with equality iff the line segment 46 is touches the special parabola arc at point 5. The special parabola arc is the one that touches sides 12 and 13 of <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> at points 2 and 3. I was very proud of inequality (2) but it turned out that it had been known for long (cf Blaschke: Vorlesungen Über Differentialgeometrie II, (1923) page 38).</p>
<p>In the proof one needs a slightly stronger version of (2). Assuming point 4 (resp. 6) divides segment 12 (and 13) in ratio <img alt="{1-a:a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1-a%3Aa%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1-a:a}"/>, (and <img alt="{b:1-b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%3A1-b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b:1-b}"/>), the stronger inequality says that</p>
<p><img alt="\displaystyle \sqrt[3]{\textrm{Area} \; T}\left(1-\frac13 (a-b)^2\right)\ge \sqrt[3]{\textrm{Area} \; T_1}+\sqrt[3]{\textrm{Area} \; T_2}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T%7D%5Cleft%281-%5Cfrac13+%28a-b%29%5E2%5Cright%29%5Cge+%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T_1%7D%2B%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T_2%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \sqrt[3]{\textrm{Area} \; T}\left(1-\frac13 (a-b)^2\right)\ge \sqrt[3]{\textrm{Area} \; T_1}+\sqrt[3]{\textrm{Area} \; T_2}, "/></p>
<p>which was probably not known to Blaschke.</p>
<p>It is important to point out that <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> is the unique convex subset of <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> whose affine perimeter is the largest among all convex subsets of <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/>. I’ll return to the affine perimeter later.</p>
<p>Yakov Sinai came up with a different, elegant, and more powerful proof using canonical ensembles from statistical physics. His method was developed further by Vershik and Zeitouni, by Bureaux and Enriquez, by Bogachev and Zarbaliev.</p>
<h2>Limit shapes for polygons in convex bodies</h2>
<p>More generally, one can consider a convex body (compact convex set with non-empty interior) <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> in the plane and the family <img alt="{\mathcal{F}^n(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n(C)}"/> of all convex <img alt="{{\mathbb{Z}}_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n}"/>-lattice polygons contained in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>, and ask whether a similar limit shape exists in this case. The answer is yes. The limit shape, <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>, is the unique convex subset of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> whose affine perimeter is maximal among all convex subsets of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. The affine perimeter is upper semicontinuous, implying the existence of convex subset of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> with maximal affine perimeter. The proof of its uniqueness requires extra effort. In the case when <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> is the unit square <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/>, the limit shape <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> is equal to <img alt="{Q_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_0}"/>. Note that for every convex body <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> with <img alt="{Q_0\subset C \subset Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_0%5Csubset+C+%5Csubset+Q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_0\subset C \subset Q}"/>, <img alt="{C_0=Q_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%3DQ_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0=Q_0}"/>.</p>
<h2>Random points vs. lattice points</h2>
<p>What happens if, instead of the <img alt="{{\mathbb{Z}}_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n}"/>-lattice points in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>, we take a random sample <img alt="{X_n=\{x_1,\ldots,x_n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_n%3D%5C%7Bx_1%2C%5Cldots%2Cx_n%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_n=\{x_1,\ldots,x_n\}}"/> of points from <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>, chosen independently and uniformly? Let <img alt="{\mathcal{G}(X_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BG%7D%28X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{G}(X_n)}"/> be the set of all polygons whose vertices belong to <img alt="{X_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_n}"/>. This is again a finite set and one can show that<br/>
<img alt="\displaystyle \lim_{n\rightarrow \infty} n^{-1/3}\log \mathop{\mathbb E}( |\mathcal{G}(X_n)|)=3\cdot2^{-2/3}\frac{A^*(C)}{\sqrt[3]{\textrm{Area} \; C}}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clim_%7Bn%5Crightarrow+%5Cinfty%7D+n%5E%7B-1%2F3%7D%5Clog+%5Cmathop%7B%5Cmathbb+E%7D%28+%7C%5Cmathcal%7BG%7D%28X_n%29%7C%29%3D3%5Ccdot2%5E%7B-2%2F3%7D%5Cfrac%7BA%5E%2A%28C%29%7D%7B%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+C%7D%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \lim_{n\rightarrow \infty} n^{-1/3}\log \mathop{\mathbb E}( |\mathcal{G}(X_n)|)=3\cdot2^{-2/3}\frac{A^*(C)}{\sqrt[3]{\textrm{Area} \; C}}, "/></p>
<p>where <img alt="{A^*(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E%2A%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^*(C)}"/> is equal to the affine perimeter, <img alt="{AP(C_0)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAP%28C_0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AP(C_0)}"/>, of <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>. This confirms the philosophy (or my intuition) that random points and lattice points in convex bodies behave similarly. Note that <img alt="{\mathop{\mathbb E}|\mathcal{G}(X_n)|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%7C%5Cmathcal%7BG%7D%28X_n%29%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}|\mathcal{G}(X_n)|}"/> is of order <img alt="{\exp\{c_1n^{1/3}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cexp%5C%7Bc_1n%5E%7B1%2F3%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\exp\{c_1n^{1/3}\}}"/> while <img alt="{|\mathcal{F}^n(C)|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cmathcal%7BF%7D%5En%28C%29%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|\mathcal{F}^n(C)|}"/> is of order <img alt="{\exp\{c_2n^{2/3}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cexp%5C%7Bc_2n%5E%7B2%2F3%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\exp\{c_2n^{2/3}\}}"/> which is fine as number of <img alt="{{\mathbb{Z}}_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n}"/>-lattice points in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> is approximately <img alt="{n^2 \textrm{Area} \; C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E2+%5Ctextrm%7BArea%7D+%5C%3B+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^2 \textrm{Area} \; C}"/>.</p>
<p>Even more interestingly, the limit shape of the polygons in <img alt="{\mathcal{G}(X_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BG%7D%28X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{G}(X_n)}"/> is <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>, in the sense that, in expectation, the overwhelming majority of polygons in <img alt="{\mathcal{G}(X_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BG%7D%28X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{G}(X_n)}"/> is very close to <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>. More precisely, for every <img alt="{\epsilon&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon&gt;0}"/><br/>
<img alt="\displaystyle \lim_{n \rightarrow \infty} \frac{\mathop{\mathbb E}|\{P\in \mathcal{G}(X_n):\delta(P,C_0)&gt;\epsilon\}|}{\mathop{\mathbb E}(|\mathcal{G}(X_n)|)}=0, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clim_%7Bn+%5Crightarrow+%5Cinfty%7D+%5Cfrac%7B%5Cmathop%7B%5Cmathbb+E%7D%7C%5C%7BP%5Cin+%5Cmathcal%7BG%7D%28X_n%29%3A%5Cdelta%28P%2CC_0%29%3E%5Cepsilon%5C%7D%7C%7D%7B%5Cmathop%7B%5Cmathbb+E%7D%28%7C%5Cmathcal%7BG%7D%28X_n%29%7C%29%7D%3D0%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \lim_{n \rightarrow \infty} \frac{\mathop{\mathbb E}|\{P\in \mathcal{G}(X_n):\delta(P,C_0)&gt;\epsilon\}|}{\mathop{\mathbb E}(|\mathcal{G}(X_n)|)}=0, "/></p>
<p>where <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> stands for the Hausdorf distance.</p>
<p>The proof of the lattice case does not work here. The edge vectors determine the convex polygon, still, but the edge vectors can’t be used, there is no generating function, etc. Instead the proof is based on the following two theorems. For the first let <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/> be a triangle with two specified vertices <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> and <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/> say, and let <img alt="{X_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_k}"/> be a random independent sample of <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> uniform points from <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/>. Then <img alt="{X_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_k}"/> is called a convex chain (from <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> to <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/>) if the convex hull of <img alt="{\{a,b\}\bigcup X_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7Ba%2Cb%5C%7D%5Cbigcup+X_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{a,b\}\bigcup X_k}"/> is a convex polygon with exactly <img alt="{k+2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k+2}"/> vertices. Then<br/>
<img alt="\displaystyle \Pr[X_k \mbox{ is a convex chain}]=\frac {2^k}{k!(k+1)!}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr%5BX_k+%5Cmbox%7B+is+a+convex+chain%7D%5D%3D%5Cfrac+%7B2%5Ek%7D%7Bk%21%28k%2B1%29%21%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Pr[X_k \mbox{ is a convex chain}]=\frac {2^k}{k!(k+1)!}, "/></p>
<p>a surprisingly precise result (due to Pavel Valtr).</p>
<p>For the second theorem let <img alt="{p(n,C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%28n%2CC%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p(n,C)}"/> denote the probability that the random sample <img alt="{X_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_n}"/> (independent and uniform again) lands in convex position, that is, their convex hull is a convex <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-gon. For <img alt="{n=4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=4}"/> this is Sylvester’s famous four point problem from 1864 (although he did not specify the underlying convex body <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>). Then<br/>
<img alt="\displaystyle \lim_{n\rightarrow \infty} n^2\sqrt[n]{p(n,C)}=\frac {e^2}4\frac{A^*(C)}{\sqrt[3]{\textrm{Area} \; C}}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clim_%7Bn%5Crightarrow+%5Cinfty%7D+n%5E2%5Csqrt%5Bn%5D%7Bp%28n%2CC%29%7D%3D%5Cfrac+%7Be%5E2%7D4%5Cfrac%7BA%5E%2A%28C%29%7D%7B%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+C%7D%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \lim_{n\rightarrow \infty} n^2\sqrt[n]{p(n,C)}=\frac {e^2}4\frac{A^*(C)}{\sqrt[3]{\textrm{Area} \; C}}, "/></p>
<p>with the same <img alt="{A^*(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E%2A%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^*(C)}"/> as before. The proof of this theorem uses the previous result of Valtr about convex chains in triangles and the properties of <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>, the largest affine area convex subset of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. The set <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/> appears again: it is the limit shape of <img alt="{\textrm{conv}X_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctextrm%7Bconv%7DX_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\textrm{conv}X_n}"/> under the condition that <img alt="{X_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_n}"/> landed in convex position.</p>
<p>The map <img alt="{C \rightarrow C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%5Crightarrow+C_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C \rightarrow C_0}"/> is affinely equivariant and has interesting properties. <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/> turns out to be the limit shape in some further cases as well. For instance, the maximal number of vertices of the polygons in <img alt="{\mathcal{F}^n(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n(C)}"/> equals</p>
<p><img alt="\displaystyle \frac {3n^{2/3}}{(2\pi)^{2/3}}A^*(C)(1+o(1)), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cfrac+%7B3n%5E%7B2%2F3%7D%7D%7B%282%5Cpi%29%5E%7B2%2F3%7D%7DA%5E%2A%28C%29%281%2Bo%281%29%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \frac {3n^{2/3}}{(2\pi)^{2/3}}A^*(C)(1+o(1)), "/></p>
<p>as <img alt="{n \rightarrow \infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \rightarrow \infty}"/>. This is of course the same as the maximal number of points in <img alt="{{\mathbb{Z}}_n\cap C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%5Ccap+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n\cap C}"/> that are in convex position. Although the convex <img alt="{{\mathbb{Z}}_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n}"/>-lattice polygon <img alt="{\mathcal{F}^n(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n(C)}"/> with maximal number of vertices is not necessary unique, they have a limit shape which is again <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>. The same happens in <img alt="{\mathcal{G}_n(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BG%7D_n%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{G}_n(C)}"/> as well. In this case, however, the expectation of the maximal number of vertices is equal to constant times <img alt="{A^*(C)n^{1/3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E%2A%28C%29n%5E%7B1%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^*(C)n^{1/3}}"/> but the value of this (positive) constant is not known. The reason is the following. In the triangle <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/> with specified vertices <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> and <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/>, and random sample <img alt="{X_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_k}"/> we define <img alt="{L_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_k}"/> as the maximal number of points from <img alt="{X_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_k}"/> that form a convex chain in <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/> from <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> to <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/>. The random variable <img alt="{L_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_k}"/> is concentrated around its expectation, which is equal to some non-negative constant times <img alt="{k^{1/3}(1+o(1))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%5E%7B1%2F3%7D%281%2Bo%281%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k^{1/3}(1+o(1))}"/> as <img alt="{k \rightarrow \infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k \rightarrow \infty}"/> but this constant is not known. Experiments suggest that it is equal to 3 but there is no proof in sight. Not surprisingly, the limit shape of these maximal convex chains is again the special parabola arc in <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/>. This question about the random variable <img alt="{L_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_k}"/> is similar to the longest increasing subsequence problem but much less is known about it.</p>
<h2>Open Problem: high dimensions</h2>
<p>What remains of the limit shape phenomenon in higher dimensions? Well, hardly anything has been proved. In the simplest case, let <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> denote the unit cube in 3-space, and let <img alt="{\mathcal{F}^n(Q)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%28Q%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n(Q)}"/> denote the set of all convex <img alt="{\frac 1n {\mathbb{Z}}^3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac+1n+%7B%5Cmathbb%7BZ%7D%7D%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac 1n {\mathbb{Z}}^3}"/>-lattice polygons contained in <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/>. It is known that <img alt="{\log |\mathcal{F}^n(Q)|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+%7C%5Cmathcal%7BF%7D%5En%28Q%29%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log |\mathcal{F}^n(Q)|}"/> is between <img alt="{c_1n^{1/2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_1n%5E%7B1%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_1n^{1/2}}"/> and <img alt="{c_2 n^{1/2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_2+n%5E%7B1%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_2 n^{1/2}}"/> with <img alt="{0&lt;c_1&lt;c_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%3Cc_1%3Cc_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0&lt;c_1&lt;c_2}"/>, but nothing more precise. Probably there is a limit shape here as well, and it might be the convex subset of <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> that has the largest affine surface area. The existence of such a set follows the same way as above but its uniqueness is not known.</p>
<h2>The affine perimeter</h2>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/affper.png"><img alt="" class="alignnone size-full wp-image-17542" src="https://gilkalai.files.wordpress.com/2019/07/affper.png?w=640"/></a></p>
<p> </p>
<p>Finally a few words about the affine perimeter. Given a convex curve <img alt="{\Gamma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CGamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Gamma}"/> in the plane, choose points <img alt="{x_0,\ldots, x_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%2C%5Cldots%2C+x_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_0,\ldots, x_n}"/> on it, take the tangent lines at these points and form the triangles <img alt="{T_1,\ldots,T_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_1%2C%5Cldots%2CT_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_1,\ldots,T_n}"/> as in the figure. By definition, the affine perimeter <img alt="{AP(\Gamma)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAP%28%5CGamma%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AP(\Gamma)}"/> is the infimum of the sum <img alt="{2\sum_1^n(\textrm{Area} \; T_i)^{1/3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Csum_1%5En%28%5Ctextrm%7BArea%7D+%5C%3B+T_i%29%5E%7B1%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2\sum_1^n(\textrm{Area} \; T_i)^{1/3}}"/> as the subdivision <img alt="{x_0,\ldots,x_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%2C%5Cldots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_0,\ldots,x_n}"/> gets finer and finer. The affine perimeter of the unit circle is <img alt="{2\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2\pi}"/> which explains the constant <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> in front of <img alt="{\sum_1^n(\textrm{Area} \; T_i)^{1/3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_1%5En%28%5Ctextrm%7BArea%7D+%5C%3B+T_i%29%5E%7B1%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sum_1^n(\textrm{Area} \; T_i)^{1/3}}"/>. The exponent <img alt="{1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/3}"/> is the right choice here: for larger exponent the sum is zero, and for smaller it is infinity (for the circle for instance). Inequality (2) shows that infimum in the definition can be replaced by limit. The affine perimeter of a convex polygon is zero.</p>
<p>For a twice differentiable curve <img alt="{AP(\Gamma) = \int_{\Gamma}\kappa^{1/3}ds=\int_{\Gamma}r^{-1/3}ds}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAP%28%5CGamma%29+%3D+%5Cint_%7B%5CGamma%7D%5Ckappa%5E%7B1%2F3%7Dds%3D%5Cint_%7B%5CGamma%7Dr%5E%7B-1%2F3%7Dds%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AP(\Gamma) = \int_{\Gamma}\kappa^{1/3}ds=\int_{\Gamma}r^{-1/3}ds}"/> where <img alt="{\kappa}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ckappa%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\kappa}"/> is the curvature and <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> the radius of curvature and <img alt="{ds}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bds%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ds}"/> means integration with arc length. The affine perimeter is an affine invariant or rather equivariant meaning that <img alt="{AP(S(\Gamma))=\sqrt[3]{|\det S|} AP(\Gamma)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAP%28S%28%5CGamma%29%29%3D%5Csqrt%5B3%5D%7B%7C%5Cdet+S%7C%7D+AP%28%5CGamma%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AP(S(\Gamma))=\sqrt[3]{|\det S|} AP(\Gamma)}"/> for a non-degenerate affine transformation <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. Quite often the affine perimeter (and the affine surface area) appears in connection with affine equivariant properties of the convex set <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. One example is best approximation by inscribed polygons <img alt="{P_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_n}"/> on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> vertices. When approximation is measured by <img alt="{\textrm{Area}\;(C\backslash P_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctextrm%7BArea%7D%5C%3B%28C%5Cbackslash+P_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\textrm{Area}\;(C\backslash P_n)}"/> then the best approximating polygon <img alt="{P_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_n}"/> satisfies the estimate<br/>
<img alt="\displaystyle \textrm{Area} \; (C\backslash P_n)= \frac 1{4\sqrt 3} \frac {AP(C)^3}{n^2}(1+o(1)). \ \ \ \ \ (3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Ctextrm%7BArea%7D+%5C%3B+%28C%5Cbackslash+P_n%29%3D+%5Cfrac+1%7B4%5Csqrt+3%7D+%5Cfrac+%7BAP%28C%29%5E3%7D%7Bn%5E2%7D%281%2Bo%281%29%29.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \textrm{Area} \; (C\backslash P_n)= \frac 1{4\sqrt 3} \frac {AP(C)^3}{n^2}(1+o(1)). \ \ \ \ \ (3)"/></p>
<p>The set <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>, the convex subset of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> with maximal affine perimeter has interesting properties. For instance its boundary contains no line segment, and if some piece of its boundary lies in the interior of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>, then this piece is a parabola arc. It has positive curvature everywhere. It is of course affinely equivariant meaning that <img alt="{S(C_0)= S(C)_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%28C_0%29%3D+S%28C%29_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S(C_0)= S(C)_0}"/>. According to (3) <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/> has the worst approximation properties among all convex subsets of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{C}"/>.  This might explain why it comes up as the limit shape so often. Actually, the high dimensional analogue of (3) suggests that the limit shape in higher dimensions is again connected to the maximal affine surface area subset of the underlying convex body.</p>
<p> </p>
<p>More reading: Imre Bárány, <a href="https://www.ams.org/journals/bull/2008-45-03/S0273-0979-08-01210-X/">Random points and lattice points in convex bodies</a>, Bull AMS (2008)</p></div>
    </content>
    <updated>2019-07-09T08:35:29Z</updated>
    <published>2019-07-09T08:35:29Z</published>
    <category term="Combinatorics"/>
    <category term="Convexity"/>
    <category term="Geometry"/>
    <category term="Guest blogger"/>
    <category term="Probability"/>
    <category term="Imre Barany"/>
    <category term="limit shape"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-14T04:20:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8041836663315088806</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8041836663315088806/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/fortran-is-underated.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8041836663315088806" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8041836663315088806" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/fortran-is-underated.html" rel="alternate" type="text/html"/>
    <title>Fortran is underated!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">(Joint Post with David Marcus who was a classmate of mine at SUNY Stony Brook [now called Stony Brook University]. I was class of 1980, he was class of 1979. We were both math majors.)<br/>
<br/>
David has been reading <a href="https://www.amazon.com/Problems-Point-Exploring-Computer-Science/dp/9813279974">Problems with a POINT</a> (I'm glad someone is reading it) and emailed me a comment on the following passage which was essentially <a href="https://blog.computationalcomplexity.org/2012/02/dusting-off-my-bookshelf-i-find-book-on.html">this post</a>. I paraphrase what I wrote:<br/>
<br/>
PASSAGE IN BOOK:<br/>
I dusted off my book shelves and found a book on Fortran. On the back it said:<br/>
<br/>
FORTRAN is one of the oldest high-level languages and remains the premier language for writing code for science and engineering applications. (NOTE- The back of the book uses Fortran but the spell checker I am using insists on FORTRAN. As a fan of capital letters, I don't mind going along.)<br/>
<br/>
When was the book written?<br/>
<br/>
The answer was surprising in that it was 2012 (the Chapter title was <i>Trick Question or Stupid Question</i>. This was a Trick Question.) I would have thought that FORTRAN was no longer the premier language by then. I also need to dust my bookshelves more often.<br/>
END OF PASSAGE IN BOOK<br/>
<br/>
David Marcus emailed me the following:<br/>
<br/>
DAVID'S EMAIL<br/>
Page 201. Fortran. One clue is that it said "Fortran" rather than"FORTRAN". Fortran 90 changed the name from all upper case. Whether it is the "premier language" depends on what you mean by "premier". It is probably the best language for scientific computing. I used it pretty much exclusively (by choice) in my previous job that I left in 2006. The handling of arrays is better than any other language I've used. Maybe there are some better languages that I'm not familiar with, but the huge number of high-quality scientific libraries available for Fortran makes it hard to beat. On the other hand, I never wrote a GUI app with it (Delphi is best for that).<br/>
END OF DAVID'S EMAIL<br/>
<br/>
In later emails we agreed that Fortran is not used that much (there are lists of most-used languages and neither Fortran nor FORTRAN is ever in the top 10).  But what intrigued me was the following contrast:<br/>
<br/>
1) David says that its the BEST language for Scientific Computing.  I will assume he is right.<br/>
<br/>
2) I doubt much NEW code is being written in it.  I will assume I am right.<br/>
<br/>
So---what's up with that? Some options<br/>
<br/>
OPTION 1) People SHOULD use Fortran but DON'T. If so, why is that?  Fortran is not taught in schools. People are used to what they already know.  Perhaps people who do pick up new things easily and want to use new things would rather use NEW things rather than NEW-TO-THEM-BUT-NOT-TO-THEIR-GRANDMOTHER things. Could be a coolness factor.  Do the advantages of Fortran outweight the disadvantages?  Is what they are using good enough?<br/>
<br/>
OPTION 2) The amount of Scientific computing software being written is small since we already have these great Fortran packages. So it may be a victim of its own success.<br/>
<br/>
CAVEAT: When I emailed David a first draft of the post he pointed out the following which has to do with the lists of most-used programming languages:<br/>
<br/>
DAVIDS EMAIL:<br/>
The problem with the lists you were looking at is that most people in the world are not scientists, so most software being written is not for scientists. Scientists and technical people are writing lots of new code.  If you look at a list of scientific languages, you will see Fortran, e.g., <a href="https://en.wikipedia.org/wiki/Scientific_programming_language">here</a> and <a href="https://en.wikipedia.org/wiki/Fortran#Science_and_engineering">here</a>.<br/>
<br/>
<br/>
There are several Fortran compilers available. One of the best was bought by Intel some time back and they still sell it. I doubt they would do that if no one was using it. Actually, I think Intel had a compiler, but bought the Compaq compiler (which used to be the Digital Equipment compiler) and merged the Compaq team with their team. Something like that. I was using the Compaq compiler around that time.<br/>
END OF DAVID's EMAIL<br/>
<br/>
One quote from the second pointer I find intriguing.  (Second use of the word <i>intriguing</i>. It was my word-of-the-day on my word-calendar).<br/>
<br/>
<i>... facilities for inter-operation with C were added to Fortran 2003 and enhanced by ISO/ICE technical specification 29113, which will be incorporated into Fortran 2018. </i><br/>
<br/>
I (Bill) don't know what some of that means; however, it does mean that Fortran is still active.<br/>
<br/>
<br/>
One fear: with its not being taught that much, will knowledge of it die out.  We be like Star Trek aliens:<br/>
<br/>
<i>The old ones built these machines, but then died and we can't fix them!<br/>
<br/>
<br/>
<br/>
</i></div>
    </content>
    <updated>2019-07-08T03:55:00Z</updated>
    <published>2019-07-08T03:55:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-13T10:51:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/091</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/091" rel="alternate" type="text/html"/>
    <title>TR19-091 |  A Sublinear-space and Polynomial-time Separator Algorithm for Planar Graphs | 

	Ryo Ashida, 

	Tatsuya Imai, 

	Kotaro Nakagawa, 

	A.  Pavan, 

	Vinodchandran Variyam, 

	Osamu Watanabe</title>
    <summary>In [12] (CCC 2013), the authors presented an algorithm for the reachability problem over directed planar graphs that runs in polynomial-time and uses $O(n^{1/2+\epsilon})$ space. A critical ingredient  of their algorithm is a polynomial-time, $\tldO(\sqrt{n})$-space algorithm to compute a separator of a planar graph. The conference version provided a sketch of the algorithm and many nontrivial details were left unexplained. In this work, we provide a detailed construction of their algorithm.</summary>
    <updated>2019-07-07T23:37:15Z</updated>
    <published>2019-07-07T23:37:15Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-14T04:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4233</id>
    <link href="https://www.scottaaronson.com/blog/?p=4233" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4233#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4233" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">John Wright joins UT Austin</title>
    <summary xml:lang="en-US">I’m delighted to announce that quantum computing theorist John Wright will be joining the computer science faculty at UT Austin in Fall 2020, after he finishes a one-year postdoc at Caltech. John made an appearance on this blog a few months ago, when I wrote about the new breakthrough by him and Anand Natarajan: namely, […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-image"><figure class="aligncenter"><img alt="" class="wp-image-4244" src="https://www.scottaaronson.com/blog/wp-content/uploads/2019/07/image-1.png"/></figure></div>



<p>I’m delighted to announce that quantum computing theorist <a href="http://www.mit.edu/~jswright/">John Wright</a> will be joining the computer science faculty at UT Austin in Fall 2020, after he finishes a one-year postdoc at Caltech. </p>



<p>John made an appearance on this blog a few months ago, when I <a href="https://www.scottaaronson.com/blog/?p=4172">wrote about</a> the <a href="https://arxiv.org/abs/1904.05870">new breakthrough</a> by him and <a href="http://www.its.caltech.edu/~anataraj/">Anand Natarajan</a>: namely, that MIP* (multi-prover interactive proofs with entangled provers) contains NEEXP (nondeterministic double-exponential time).  Previously, MIP* had only been known to contain NEXP (nondeterministic <em>single</em> exponential time).  So, this is an exponential expansion in the power of entangled provers over what was previously known and believed, and the first proof that entanglement actually <em>increases</em> the power of multi-prover protocols, rather than decreasing it (as it could’ve done a priori).  Even more strikingly, there seems to be no natural stopping point: MIP* might soon swallow up arbitrary towers of exponentials or even the halting problem (!).  For more, see for example <a href="https://www.quantamagazine.org/computer-scientists-expand-the-frontier-of-verifiable-knowledge-20190523/">this <em>Quanta</em> article</a>, or <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">this post by Thomas Vidick</a>, or <a href="http://www.henryyuen.net/post/alice-and-bob-visit/">this short story [sic] by Henry Yuen</a>.</p>



<p>John grew up in Texas, so he’s no stranger to BBQ brisket or scorching weather.  He did his undergrad in computer science at UT Austin—my colleagues remember him as a star—and then completed his PhD with Ryan O’Donnell at Carnegie Mellon, followed by a postdoc at MIT.  Besides the work on MIP*, John is also well-known for his <a href="https://arxiv.org/abs/1508.01907">2015 work with O’Donnell</a> pinning down the sample complexity of quantum state tomography.  Their important result, a version of which was independently obtained by <a href="https://arxiv.org/abs/1508.01797">Haah et al.</a>, says that if you want to learn an unknown d-dimensional quantum mixed state ρ to a reasonable precision, then ~d<sup>2</sup> copies of ρ are both necessary and sufficient.  This solved a problem that had personally interested me, and already plays a role in, e.g., my work on <a href="https://arxiv.org/abs/1711.01053">shadow tomography</a> and <a href="https://www.scottaaronson.com/papers/dpgentle.pdf">gentle measurements</a>.</p>



<p>Our little <a href="https://www.cs.utexas.edu/~qic/">quantum information center</a> at UT Austin is growing rapidly.  <a href="http://sites.utexas.edu/shyamshankar/">Shyam Shankar</a>, a superconducting qubits guy who previously worked in Michel Devoret’s group at Yale, will also be joining UT’s Electrical and Computer Engineering department this fall.  I’ll have two new postdocs—<a href="https://twitter.com/a_rocchetto?lang=en">Andrea Rocchetto</a> and <a href="http://www.cs.huji.ac.il/~yosiat/">Yosi Atia</a>—as well as new PhD students.  We’ll continue recruiting this coming year, with potential opportunities for students, postdocs, faculty, and research scientists across the CS, physics, and ECE departments as well as the Texas Advanced Computing Center (TACC).  I hope you’ll consider applying to join us.</p>



<p>With no evaluative judgment attached, I can honestly say that this is an unprecedented time for quantum computing as a field.  Where once faculty applicants struggled to make a case for quantum computing (physics departments: “but isn’t this really CS?” / CS departments: “isn’t it really physics?” / everyone: “couldn’t this whole QC thing, like, all blow over in a year?”), today departments are vying with each other and with industry players and startups to recruit talented people.  In such an environment, we’re fortunate to be doing as well as we are.  We hope to continue to expand.</p>



<p>Meanwhile, this was an <a href="https://www.nytimes.com/2019/01/24/technology/computer-science-courses-college.html">unprecedented year for CS hiring at UT Austin</a> more generally.  John Wright is one of at least four new faculty (probably more) who will be joining us.  It’s a good time to be in CS.</p>



<p>A huge welcome to John, and hook ’em Hadamards!</p>



<p>(And for US readers: have a great 4<sup>th</sup>!  Though how could any fireworks match the proof of the Sensitivity Conjecture?)</p></div>
    </content>
    <updated>2019-07-04T01:08:54Z</updated>
    <published>2019-07-04T01:08:54Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-13T23:39:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/07/03/postdoc-at-national-university-of-singapore-apply-by-november-30-2019/</id>
    <link href="https://cstheory-jobs.org/2019/07/03/postdoc-at-national-university-of-singapore-apply-by-november-30-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at National University of Singapore (apply by November 30, 2019)</title>
    <summary>Multiple post-doctoral research positions available in the project on “Provably Verified and Explainable Probabilistic Reasoning,” led by the Principle Investigator, Kuldeep S. Meel. The project broadly aims to develop of formal methods for AI techniques and employ advances in AI techniques for the development of formal methods. Website: https://meelgroup.github.io/files/postdoc.html Email: meel+postdoc@comp.nus.edu.sg</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Multiple post-doctoral research positions available in the project on “Provably Verified and Explainable Probabilistic Reasoning,” led by the Principle Investigator, Kuldeep S. Meel.</p>
<p>The project broadly aims to develop of formal methods for AI techniques and employ advances in AI techniques for the development of formal methods.</p>
<p>Website: <a href="https://meelgroup.github.io/files/postdoc.html">https://meelgroup.github.io/files/postdoc.html</a><br/>
Email: meel+postdoc@comp.nus.edu.sg</p></div>
    </content>
    <updated>2019-07-03T19:39:18Z</updated>
    <published>2019-07-03T19:39:18Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-07-14T04:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16070</id>
    <link href="https://rjlipton.wordpress.com/2019/07/03/mathematics-of-gerrymandering/" rel="alternate" type="text/html"/>
    <title>Mathematics of Gerrymandering</title>
    <summary>Can theory help? source; art by Bill Hennessy John Roberts is the Chief Justice of the United States. Today I will discuss the recent Supreme Court decision on gerrymandering. The 5-4 decision in Rucho v. Common Cause takes the courts out of deciding if redistricting was done fairly. Roberts, penning the majority argument, felt that […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Can theory help?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/07/03/mathematics-of-gerrymandering/unknown-124/" rel="attachment wp-att-16073"><img alt="" class="alignright size-full wp-image-16073" src="https://rjlipton.files.wordpress.com/2019/07/unknown.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><a href="https://nonperele.com/john-biskupic-how-john-roberts-controls-the-us-supreme-court/">source</a>; art by Bill Hennessy</font></td>
</tr>
</tbody>
</table>
<p>
John Roberts is the Chief Justice of the United States.</p>
<p>
Today I will discuss the recent Supreme Court <a href="https://www.scotusblog.com/case-files/cases/rucho-v-common-cause-2/">decision</a> on gerrymandering.<br/>
<span id="more-16070"/></p>
<p>
The 5-4 decision in Rucho v. Common Cause takes the courts out of deciding if redistricting was done fairly. Roberts, penning the majority argument, felt that it was hard, if not impossible, for courts to determine whether districts were reasonably drawn. That is, whether partisan motives dominated when they were created.</p>
<p>
I will explain what <a href="https://en.wikipedia.org/wiki/Gerrymandering">gerrymandering</a> is, and how computational methods may play a role. I must add a takeaway: </p>
<blockquote><p><b> </b> <em> <i>The current view of computational methods to avoid gerrymandering may be based on incorrect assumptions.</i> </em>
</p></blockquote>
<p>More on this later.</p>
<p>
</p><p/><h2> How It Works </h2><p/>
<p/><p>
You probably know that gerrymandering is used, negatively, to describe creating voting districts that do not reflect the voters will. The term was coined as part of an attack on the then Governor of Massachusetts in 1812. The shape of one particularly contrived district looked like a salamander. Since his name was Elbridge Gerry, it became a <i>gerrymander</i>. He was a Democratic-Republican and was not re-elected. </p>
<p>
<a href="https://rjlipton.wordpress.com/2019/07/03/mathematics-of-gerrymandering/gerry/" rel="attachment wp-att-16071"><img alt="" class="aligncenter size-full wp-image-16071" src="https://rjlipton.files.wordpress.com/2019/07/gerry.png?w=600"/></a></p>
<p>
Here is a figure from our friends at Wikipedia that presents examples of gerrymandering. </p>
<p>
<a href="https://rjlipton.wordpress.com/2019/07/03/mathematics-of-gerrymandering/divide/" rel="attachment wp-att-16072"><img alt="" class="aligncenter  wp-image-16072" src="https://rjlipton.files.wordpress.com/2019/07/divide.png?w=270" width="270"/></a></p>
<p>
By redistricting in the above, one can achieve anything from districts all won by the majority, to most won by the majority. These examples, show how the party who controls the districts can control the outcome.</p>
<p>
Well that is an overstatement. They can control the believed leanings of the voters in the districts. In the above example, they can control how yellow a district is. Real life is complicated by other factors: </p>
<ol>
<li>
A candidate may win because they are just more popular. That is a green candidate could still win in a yellow district. <p/>
</li><li>
A candidate may win because of random fluctuations. If the voter margin is small enough, random fluctuations could change the “expected” outcome.
</li></ol>
<p>
The latter is a danger for gerrymanderers. This <a href="https://www.brennancenter.org/blog/what-is-extreme-gerrymandering">site</a> on gerrymandering says: </p>
<blockquote><p><b> </b> <em> The trick is not to spread your voters out so much that districts become vulnerable to flipping to the other party in the normal give and take of electoral politics. </em>
</p></blockquote>
<p>
</p><p/><h2> How We Model It </h2><p/>
<p/><p>
Since Roberts is not our intended audience we will use mathematical definitions. I am sure Roberts and the rest of the Supreme Court justices are smart, but we have our own methods. We do not use legal jargon such as “prima facie” and suspect they do not use math jargon like “prime” numbers.</p>
<p>
So let the yellow party have <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> fraction of the voters. Suppose the voters have to be divided into <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> districts of the same size. A division is just a vector <img alt="{y=(y_{1},\dots,y_{d})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%3D%28y_%7B1%7D%2C%5Cdots%2Cy_%7Bd%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y=(y_{1},\dots,y_{d})}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  y_{1} + \cdots + y_{d} = 1, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y_%7B1%7D+%2B+%5Ccdots+%2B+y_%7Bd%7D+%3D+1%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  y_{1} + \cdots + y_{d} = 1, "/></p>
<p>and each <img alt="{y_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y_{i}}"/> is non-negative. For such a vector <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> the number that yellow <i>wins</i> is the number of indices <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  y_{k} \ge \frac{1}{2d}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y_%7Bk%7D+%5Cge+%5Cfrac%7B1%7D%7B2d%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  y_{k} \ge \frac{1}{2d}. "/></p>
<p>Note, we assume that <img alt="{1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/2}"/> of the voters makes a district a win. We can change this to strictly larger than <img alt="{1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/2}"/>, but will leave it for now.</p>
<blockquote><p><b>Definition 1</b> <em> Define <img alt="{{\rm MaxWin}(d, \alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+MaxWin%7D%28d%2C+%5Calpha%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\rm MaxWin}(d, \alpha)}"/> to the maximum over all <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{y}"/> of the number of wins; and define <img alt="{{\rm MinWin}(d, \alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\rm MinWin}(d, \alpha)}"/> to be the minimum number of wins. </em>
</p></blockquote>
<p>Note, we do not care who is doing the redistricting. Nor do we care about the geometry. For example 	</p>
<p align="center"><img alt="\displaystyle  {\rm MaxWin}(5, 0.60) = 5 \text{ and } {\rm MinWin}(5, 0.60) = 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MaxWin%7D%285%2C+0.60%29+%3D+5+%5Ctext%7B+and+%7D+%7B%5Crm+MinWin%7D%285%2C+0.60%29+%3D+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MaxWin}(5, 0.60) = 5 \text{ and } {\rm MinWin}(5, 0.60) = 1. "/></p>
<p>What can we say about these functions? Here are some simple observations.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> If <img alt="{\alpha \ge 0.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%5Cge+0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha \ge 0.5}"/>, then <img alt="{{\rm MaxWin}(d, \alpha) = d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+MaxWin%7D%28d%2C+%5Calpha%29+%3D+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\rm MaxWin}(d, \alpha) = d}"/>. Just place <img alt="{\alpha }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha }"/> fraction of the voters in each district.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> If <img alt="{\alpha &gt; 0.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%3E+0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha &gt; 0.5}"/>, then <img alt="{{\rm MinWin}(d, \alpha) \ge 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%5Cge+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\rm MinWin}(d, \alpha) \ge 1}"/>. No matter how the districts are drawn there must be at least one where yellow has a majority. </p>
<p>
An advantage of these functions is that now we can discuss growth rates, not just present examples. A strength of theory is that we have replaced statements like “this algorithm is fast” by formulas for their running time. Another advantage is that these functions are <i>independent of geometry</i>. Previously I thought the dominating issue was how regions looked. Now I believe the issue is how close one gets to the best and worst case: <img alt="{\rm MaxWin}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crm+MaxWin%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rm MaxWin}"/> and <img alt="{\rm MinWin}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crm+MinWin%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rm MinWin}"/>. </p>
<blockquote><p><b>Lemma 2</b> <em> Suppose that <img alt="{\alpha &gt; 1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%3E+1%2F2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha &gt; 1/2}"/>. Then 	</em></p><em>
<p align="center"><img alt="\displaystyle  {\rm MinWin}(d, \alpha) = d-\lfloor 2(1-\alpha) d \rfloor " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%3D+d-%5Clfloor+2%281-%5Calpha%29+d+%5Crfloor+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MinWin}(d, \alpha) = d-\lfloor 2(1-\alpha) d \rfloor "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Let <img alt="{\beta = 1-\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta+%3D+1-%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta = 1-\alpha}"/>. Let’s create the arrangement that makes green win as many districts as possible. If <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/> regions are mostly green then that takes <img alt="{\frac{g}{2d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bg%7D%7B2d%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{g}{2d}}"/> of the <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/> green voters. This implies that 	</p>
<p align="center"><img alt="\displaystyle  \frac{g}{2d} \le \beta. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bg%7D%7B2d%7D+%5Cle+%5Cbeta.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{g}{2d} \le \beta. "/></p>
<p>So it follows 	</p>
<p align="center"><img alt="\displaystyle  g \le 2\beta d. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++g+%5Cle+2%5Cbeta+d.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  g \le 2\beta d. "/></p>
<p>This proves that <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/> is equal to <img alt="{\lfloor 2\beta d \rfloor}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clfloor+2%5Cbeta+d+%5Crfloor%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lfloor 2\beta d \rfloor}"/>. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
It may help to set <img alt="{\alpha = 1/2 + \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%3D+1%2F2+%2B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha = 1/2 + \epsilon}"/> where <img alt="{\epsilon&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon&gt;0}"/>. Let’s agree to ignore the rounding off and delete the floor and ceiling functions. Then 	</p>
<p align="center"><img alt="\displaystyle  {\rm MinWin}(d, \alpha) = d-2(1-\alpha) d " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%3D+d-2%281-%5Calpha%29+d+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MinWin}(d, \alpha) = d-2(1-\alpha) d "/></p>
<p>and so 	</p>
<p align="center"><img alt="\displaystyle  {\rm MinWin}(d, \alpha) = 2\epsilon d. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%3D+2%5Cepsilon+d.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MinWin}(d, \alpha) = 2\epsilon d. "/></p>
<p>Thus for <img alt="{\epsilon = 1/10}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3D+1%2F10%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon = 1/10}"/> we get that 	</p>
<p align="center"><img alt="\displaystyle  {\rm MaxWin}(d, \alpha) = d \text{ and } {\rm MinWin}(d, \alpha) = 0.2d. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MaxWin%7D%28d%2C+%5Calpha%29+%3D+d+%5Ctext%7B+and+%7D+%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%3D+0.2d.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MaxWin}(d, \alpha) = d \text{ and } {\rm MinWin}(d, \alpha) = 0.2d. "/></p>
<p>This says that independent of any geometry if yellow has a ten percent majority, then best case if they set the districts they could win all, and if green sets the districts the worst they can get is twenty percent of the districts.</p>
<p>
</p><p/><h2> How Algorithms Can Help </h2><p/>
<p/><p>
There is long-term and continuing interest in algorithms that automate redistricting. The hope is that automated systems will be able to create districts that are fair. A trouble with this research is that there is no universal notion of what makes districts fair. The mantra is: </p>
<blockquote><p><b> </b> <em> <i>A redistricting is fair if and only if the districts collectively satisfy some geometric criterion</i>. </em>
</p></blockquote>
<p>An explicit statement of such a criterion, from a <a href="https://bdistricting.com/about.html">site</a> on such algorithms, is: </p>
<blockquote><p><b> </b> <em> <i>The best district map is the one where people have the lowest average distance to the center of their district</i>. </em>
</p></blockquote>
<p>Of course the name “gerrymandering” came from how districts looked. Somehow this enshrined the notion that districts must look right. I feel this could be wrong.</p>
<p>
Here is a quote from a recent <a href="http://district.cs.brown.edu">paper</a> on an algorithm for redistricting. </p>
<blockquote><p><b> </b> <em> We propose a method for redistricting, decomposing a geographical area into subareas, called districts, so that the populations of the districts are as close as possible and the districts are compact and contiguous. Each district is the intersection of a polygon with the geographical area. The polygons are convex and the average number of sides per polygon is less than six. </em>
</p></blockquote>
<p>The authors are Philip Klein and Neal Young, who are well known researchers on various aspects of algorithms. They do interesting work, their paper is interesting, but the assumption that geometry is the key I do not get.</p>
<p>
</p><p/><h2> How To Do Better? </h2><p/>
<p/><p>
I think that we need to go beyond geometry to understand and avoid gerrymandering. The connection between geometry and fairness is driven—I believe—by tradition. Voters in the same district probably want to be near each other. In the past being near each other was probably important, since travel was so difficult. Perhaps today location is less of an issue then it was before cars, phones, cell phones, internet access, and email. Perhaps districts can be fair and yet do not look good. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
An analogy to <a href="https://en.wikipedia.org/wiki/Fair_cake-cutting">cake cutting</a> may occur to you. Recall in the cake cutting problem success is <i>not</i> measured in how the pieces of the cake look. It is only measured by whether the parties cutting the cake are happy. Is there some way to push this analogy? I just came across a <a href="https://arxiv.org/pdf/1710.08781.pdf">paper</a> using the cake cutting method: <i>A Partisan Districting Protocol With Provably Nonpartisan Outcomes</i> by Wesley Pegden, Ariel Procaccia, and Dingli Yu. More in the future.</p>
<p>
Can algorithmic methods help? Is geometry the fundamental issue? </p>
<p/><p><br/>
[sourced photo, other word edits]</p></font></font></div>
    </content>
    <updated>2019-07-03T13:51:13Z</updated>
    <published>2019-07-03T13:51:13Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="cake-cutting"/>
    <category term="districts"/>
    <category term="fair"/>
    <category term="geometry"/>
    <category term="gerrymander"/>
    <category term="gerrymandering"/>
    <category term="reasonable"/>
    <category term="voters"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-07-14T04:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1136</id>
    <link href="https://ptreview.sublinear.info/?p=1136" rel="alternate" type="text/html"/>
    <title>News for June 2019</title>
    <summary>We’ve got four papers this month. A mix of distribution testing, matrix problems, and a different paper on the power of sampling. On the Complexity of Estimating the Effective Support Size, by Oded Goldreich (ECCC). In distribution testing, a classic problem is that of approximating the support size. By a (now) classic result of Valiant-Valiant, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We’ve got four papers this month. A mix of distribution testing, matrix problems, and a different paper on the power of sampling.</p>



<p><strong>On the Complexity of Estimating the Effective Support Size</strong>, by Oded Goldreich (<a href="https://eccc.weizmann.ac.il/report/2019/088/">ECCC</a>). In distribution testing, a classic problem is that of approximating the support size. By a (now) classic result of <a href="http://theory.stanford.edu/~valiant/papers/VV_stoc11.pdf">Valiant-Valiant</a>, the complexity of this problem is \(\Theta(n/\log n)\). This paper raises the question of approximating the “effective” support, and that too with more than just samples from the distribution. The \(\epsilon\)-support of discrete distribution \(\mathcal{D}\) is the smallest support among any distribution \(\mathcal{D}’\) such that \(\|\mathcal{D} – \mathcal{D}’\|_1 \leq \epsilon\) (or TV-distance). Denote this as \(supp_\epsilon(\mathcal{D})\). One can also consider a bicriteria version. Given approximation parameter \(f\) and thresholds \(\epsilon_1 &lt; \epsilon_2\), we need to provide a number in the range \([supp_{\epsilon_2}(\mathcal{D}), f\cdot supp_{\epsilon_1}(\mathcal{D})]\). The primary model studied allows for random samples and evaluation queries (where one gets the probability of any known element of the domain). In this model, for arbitrary \(\epsilon_1, \epsilon_2\), there is a continuum of algorithms, trading off query complexity with approximation. At one end, for \(f = O(\log n)\), the query complexity is \(\widetilde{O}(1/\epsilon_1)\). At the other end, for \(f=1\), the query complexity is \(O(\log^* n)\). (Here, \(n = supp_{\epsilon_1}(\mathcal{D})\).) There are lower bounds showing the necessity of evaluation queries for subpolynomial query complexities.</p>



<p><strong>Communication and Memory Efficient Testing of Discrete Distributions</strong>, by Ilias Diakonikolas, Themis Gouleakis, Daniel M. Kane, and Sankeerth Rao (<a href="https://arxiv.org/abs/1906.04709">arXiv</a>). This paper adds additional computational constraints to the distribution testing problem. In the streaming setting, the algorithm is only allowed a single pass over the random samples. It has \(m\) bits of storage, much smaller than \(n\), the distribution size. The aim is to minimize the number of samples required for uniformity (and closeness) testing. For uniformity testing in the streaming setting, the paper gives an algorithm that uses \(\widetilde{O}(m + n/m)\) samples. The standard collision algorithm requires \(\Theta(\sqrt{n})\) storage (to store the samples), while this result gives a non-trivial bound for \(m \ll \sqrt{n}\). There are lower bounds showing that these bounds are basically tight. In the distributed distribution testing problem, there are a number of processors, each holding \(\ell\) samples. A referee asks a question to the processor, whose answers are broadcast to everyone. The aim is to minimize communication cost. For uniformity testing in this setting, there is a protocol using \(O(\sqrt{n\log n/\ell})\) bits of communication. As a sanity check, note that for \(\ell = \sqrt{n}\), one processor could simply run the collision algorithm locally to report the result. </p>



<p><strong>Querying a Matrix through Matrix-Vector Products</strong> by Xiaoming Sun, David P. Woodruff, Guang Yang, and Jialin Zhang (<a href="https://arxiv.org/pdf/1906.05736.pdf">arXiv</a>). Consider \(n \times d\) matrix \(M\) over some field \(\mathbb{F}\). One gets access to this matrix through matrix-vector products, and wishes to test some matrix property. This is a natural model in many settings, and generalizes the classic setting of query access. A subtle point is that one can only right multiply with “query” vectors, and there are problems where left multiplication can change the complexity. (A nice example in the paper is testing if a square matrix is symmetric. With both left and right multiplications, this is easy, since we can directly access rows and columns. By only accessing columns, this is non-trivial.) This paper studies a number of problems, broadly classified as linear algebra problems, statistics problems, and graph problems. Some highlights are: testing symmetry can be done in \(O(1)\) queries, and the maximum eigenvalue can be approximated in \(O(\log n)\) queries adaptively (but there is an \(\Omega(n)\) non-adaptive lower bound). For graph problems, here’s an interesting discovery. If \(M\) is the adjacency matrix, connectivity requires \(\Omega(n/\log n)\) queries. But if \(M\) is the signed edge-vertex matrix, then this can be done in \(poly(\log n)\) queries. This paper provides a number of interesting directions and problems to study.</p>



<p><strong>The Adversarial Robustness of Sampling</strong> by Omri Ben-Eliezer and Eylon Yogev (arXiv). This isn’t a property testing paper, but how can one ignore a paper on understanding the power of sampling? It’s convenient to think of the following setting. An algorithm gets a stream of \(n\) numbers, and has to answer some questions about the stream (say, the median or other quantiles). The simplest strategy is to take a small random sample of the stream. But what if an adversary was generating the stream, depending on the current sample? Under what circumstances is the sample still “representative” of the stream? The specific results of this paper require getting into set systems and VC dimension, which I’ll leave for the sake of simplicity. Let’s go back to the median question. To get an approximate median, a constant number of samples suffice. A consequence of the main result is that if one takes \(O(\log n)\) samples, then this is robust to adversarial streams. On the other hand, lower bounds show that constant sized samples can be fooled by an adversary. The paper is a really interesting read, and is a nice take on “standard facts” that we take for granted.</p>



<p/></div>
    </content>
    <updated>2019-07-03T00:54:36Z</updated>
    <published>2019-07-03T00:54:36Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Seshadhri</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-07-13T23:53:06Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8952301722851173857</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8952301722851173857/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8952301722851173857" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8952301722851173857" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html" rel="alternate" type="text/html"/>
    <title>Local Kid Makes History</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="separator" style="clear: both; text-align: center;">
</div>
<a href="https://1.bp.blogspot.com/-OpUgtDyqMf0/XRuOhVHWTFI/AAAAAAABplw/Tz0jTV3EQCo9w0aZ1bsI9xsJiec3OfytgCLcBGAs/s1600/Huang.jpg" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img border="0" height="200" src="https://1.bp.blogspot.com/-OpUgtDyqMf0/XRuOhVHWTFI/AAAAAAABplw/Tz0jTV3EQCo9w0aZ1bsI9xsJiec3OfytgCLcBGAs/s200/Huang.jpg" width="163"/></a>The <a href="https://www.scottaaronson.com/blog/?p=4229">blogosphere</a> is <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">blowing</a> <a href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/">up</a> over Hao Huang's just <a href="https://arxiv.org/abs/1907.00847">posted proof</a> of the sensitivity conjecture, what was one of the more <a href="https://blog.computationalcomplexity.org/2017/12/razors-edge.html">frustrating open questions</a> in complexity.<br/>
<br/>
Huang, an assistant professor in the math department at Emory, settled an open question about the hypercube. The hypercube is a graph on N=2<sup>n</sup> vertices where each vertex corresponds to an n-bit string and their are edges between vertices corresponding to strings that differ in a single bit. Think of the set of the strings of odd parity, N/2 vertices with no edges between them. Add any other vertex and it would have n neighbors. Huang showed that no matter how you placed those N/2+1 vertices in the hypercube, some vertex will have at least n<sup>1/2</sup> neighbors. By an <a href="https://doi.org/10.1016/0097-3165(92)90060-8">old result</a> of Gotsman and Linial, Huang's theorem implies the sensitivity conjecture.<br/>
<br/>
I won't go through the shockingly simple proof, the <a href="https://arxiv.org/abs/1907.00847">paper</a> is well written, or you can read the blogs I linked to above or even just Ryan O'Donnell's <a href="https://twitter.com/BooleanAnalysis/status/1145837576487612416">tweet</a>.<br/>
<br/>
I have nothing more to say than wow, just wow.</div>
    </content>
    <updated>2019-07-02T17:05:00Z</updated>
    <published>2019-07-02T17:05:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-13T10:51:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7530</id>
    <link href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/" rel="alternate" type="text/html"/>
    <title>Sensitivity conjecture proved!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-jetpack-markdown"><p>In a recent breakthrough, <a href="http://www.mathcs.emory.edu/~hhuan30/">Hao Huang</a> gave a <a href="https://arxiv.org/abs/1907.00847">6 page paper</a> proving the longstanding sensitivity conjecture. (Hat tip, <a href="https://www.scottaaronson.com/blog/?p=4229">Scott Aaronson</a> and <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">Gil Kalai</a>. See this <a href="https://cstheory.stackexchange.com/questions/27714/sensitivity-block-sensitivity-conjecture-implications">stackexchange post</a> and <a href="https://eccc.weizmann.ac.il/report/2016/062/">this paper of Avishai</a> for some links to the literature on this.)</p>
<p>The proof is beautiful and simple. I will write a few words here, but it is probably easier for you to just read the <a href="https://arxiv.org/abs/1907.00847">paper</a>. The sensitivity conjecture <a href="https://www.sciencedirect.com/science/article/pii/0097316592900608">was known</a> to follow from the following statement: let <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> be the <em>Boolean Cube</em> which is the degree <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> graph on <img alt="N=2^n" class="latex" src="https://s0.wp.com/latex.php?latex=N%3D2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N=2^n"/> vertices identified with <img alt="\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\}^n"/> such that for every <img alt="x,y\in \{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in \{0,1\}^n"/>, <img alt="x \sim y" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Csim+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \sim y"/> if their Hamming distance is one. Then, the maximum degree of every subgraph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> of <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> of size <img alt="&gt;N/2" class="latex" src="https://s0.wp.com/latex.php?latex=%3EN%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="&gt;N/2"/> is at least <img alt="\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt{n}"/>.</p>
<p>Hao proves the above statement by showing that there is a <em>signing</em> of the <img alt="N\times N" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ctimes+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\times N"/> adjacency matrix of <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> that turns it into a matrix with <img alt="N/2" class="latex" src="https://s0.wp.com/latex.php?latex=N%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N/2"/> eigenvalues equaling <img alt="+\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%2B%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+\sqrt{n}"/> and <img alt="N/2" class="latex" src="https://s0.wp.com/latex.php?latex=N%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N/2"/> eigenvalues equaling <img alt="-\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=-%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-\sqrt{n}"/>. That is, he shows (using a simple but clever inductive argument, see the 5 line proof of his Lemma 2.2) that there is an <img alt="N\times N" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ctimes+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\times N"/> matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> with entries in <img alt="\{ 0, \pm 1 \}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B+0%2C+%5Cpm+1+%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{ 0, \pm 1 \}"/> whose nonzero entries correspond to the edges of the Boolean cube, and such that all the <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/> eigenvalues of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> are <img alt="\pm \sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm \sqrt{n}"/> and they sum up to zero. (Note that this makes sense since <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> should have the same <em>Frobenius norm</em> as  the adjacency matrix of <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/>. The Frobenius norm squared is both the sum of squares of entries, which is <img alt="N\cdot n" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ccdot+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\cdot n"/> for <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> which is a degree <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> graph, and also equal to the sum of squares of the eigenvalues, which is <img alt="N\cdot n" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ccdot+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\cdot n"/> if all eigenvalues are <img alt="\pm \sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm \sqrt{n}"/>.)</p>
<p>Once you have such a signing, the result follows from <a href="https://en.wikipedia.org/wiki/Min-max_theorem#Cauchy_interlacing_theorem">Cauchy’s Interlace Theorem</a> that says that for every <img alt="N\times N" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ctimes+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\times N"/> matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and any <img alt="M\times M" class="latex" src="https://s0.wp.com/latex.php?latex=M%5Ctimes+M&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M\times M"/> matrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> that is a principle sub-matrix of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>,</p>
<p><img alt="\lambda_{1+N-M}(A) \leq \lambda_1(B) \leq \lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_%7B1%2BN-M%7D%28A%29+%5Cleq+%5Clambda_1%28B%29+%5Cleq+%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_{1+N-M}(A) \leq \lambda_1(B) \leq \lambda_1(A)"/></p>
<p>where <img alt="\lambda_1(A) \geq \lambda_2(A) \cdots \geq \lambda_N(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28A%29+%5Cgeq+%5Clambda_2%28A%29+%5Ccdots+%5Cgeq+%5Clambda_N%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(A) \geq \lambda_2(A) \cdots \geq \lambda_N(A)"/> are the eigenvalues of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="\lambda_1(B)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B)"/> is the maximum eigenvalue of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>. A corollary of this (which is the only fact we need) is that if <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> has its top eigenvalue <img alt="\lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(A)"/> with multiplicity <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> (i.e., <img alt="\lambda_1(A)=\lambda_K(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28A%29%3D%5Clambda_K%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(A)=\lambda_K(A)"/>), then every principle sub-matrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> of order larger than <img alt="N-K" class="latex" src="https://s0.wp.com/latex.php?latex=N-K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N-K"/> will satisfy <img alt="\lambda_1(B) = \lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29+%3D+%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B) = \lambda_1(A)"/>. (In fact, we only need <img alt="\lambda_1(B) \geq \lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29+%5Cgeq+%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B) \geq \lambda_1(A)"/>.)</p>
<p>Indeed, suppose that <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is a subgraph of the Boolean cube of size <img alt="M&gt;N/2" class="latex" src="https://s0.wp.com/latex.php?latex=M%3EN%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M&gt;N/2"/>. Then the principle submatrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> corresponding to the vertices of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> satisfies <img alt="\lambda_1(B) \geq \lambda_{1+N-M}(A) = \sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29+%5Cgeq+%5Clambda_%7B1%2BN-M%7D%28A%29+%3D+%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B) \geq \lambda_{1+N-M}(A) = \sqrt{n}"/> (since <img alt="M&gt;N/2" class="latex" src="https://s0.wp.com/latex.php?latex=M%3EN%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M&gt;N/2"/> and the first <img alt="N/2" class="latex" src="https://s0.wp.com/latex.php?latex=N%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N/2"/> eigenvalues of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> are <img alt="+\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%2B%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+\sqrt{n}"/>).
But it’s easy to show that for every matrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> the maximum eigenvalue of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> is upper bounded by the maximum <img alt="\ell_1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_1"/> norm of its rows, which in our case is the maximum degree of the graph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>.</p>
</div></div>
    </content>
    <updated>2019-07-02T16:18:34Z</updated>
    <published>2019-07-02T16:18:34Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-07-14T04:20:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3401</id>
    <link href="https://agtb.wordpress.com/2019/07/02/papafest-september-6-8-columbia/" rel="alternate" type="text/html"/>
    <title>PapaFest (September 6-8 @ Columbia)</title>
    <summary>Announcing a conference celebrating Christos Papadimitriou, September 6-8, 2019, at Columbia University.  Registration is free.  Confirmed invited speakers include: Sanjeev Arora, Michael Collins, Michael I. Jordan, Anna Karlin,  Jon Kleinberg, Elias Koutsoupias, Adi Livnat, Noam Nisan, Prabhakar Raghavan, Scott Shenker, Eva Tardos, John Tsitsiklis, Leslie Valiant, Umesh Vazirani, and Santosh Vempala. More details here. Advertisements</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Announcing a conference celebrating Christos Papadimitriou, September 6-8, 2019, at Columbia University.  Registration is free.  Confirmed invited speakers include: Sanjeev Arora, Michael Collins, Michael I. Jordan, Anna Karlin,  Jon Kleinberg, Elias Koutsoupias, Adi Livnat, Noam Nisan, Prabhakar Raghavan, Scott Shenker, Eva Tardos, John Tsitsiklis, Leslie Valiant, Umesh Vazirani, and Santosh Vempala.</p>
<p>More details <a href="http://papafest.cs.columbia.edu/">here.</a></p></div>
    </content>
    <updated>2019-07-02T12:47:57Z</updated>
    <published>2019-07-02T12:47:57Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>timroughgarden</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-07-14T04:20:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/07/02/the-autumn-school-on-machine-learning/</id>
    <link href="https://cstheory-events.org/2019/07/02/the-autumn-school-on-machine-learning/" rel="alternate" type="text/html"/>
    <title>The Autumn school on Machine Learning</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">October 3-11, 2019 Tbilisi, Georgia https://cte.ibsu.edu.ge/autumn/ Registration deadline: October 3, 2019 The school will be organized by the International Black Sea University with the support of Shota Rustaveli National Science Foundation of Georgia (SRNSFG). The intended audience of the autumn school includes BSc, MSc and PhD students, researchers as well as industry professionals from the … <a class="more-link" href="https://cstheory-events.org/2019/07/02/the-autumn-school-on-machine-learning/">Continue reading <span class="screen-reader-text">The Autumn school on Machine Learning</span></a></div>
    </summary>
    <updated>2019-07-02T09:09:23Z</updated>
    <published>2019-07-02T09:09:23Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-07-14T04:21:45Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-6337479962158243575</id>
    <link href="http://processalgebra.blogspot.com/feeds/6337479962158243575/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=6337479962158243575" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6337479962158243575" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6337479962158243575" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/07/phd-position-at-tu-wirn-formal-methods.html" rel="alternate" type="text/html"/>
    <title>PhD position at TU Wirn: Formal methods applied to the specification and monitoring of large-scale, spatially-distributed, stochastic systems</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="_5pbx userContent _3576" id="js_3b"><i>Interesting PhD position at TU Wien with <a class="profileLink" href="http://www.eziobartocci.com/" title="Ezio Bartocci">Ezio Bartocci</a> and <a href="https://lauranenzi.github.io/">Laura Nenzi</a>. Spread the news! </i><br/><br/> The <a href="http://ti.tuwien.ac.at/">Institute of Computer Engineering</a> at the Technische Universität Wien (TU Wien) is seeking a candidate for a  research assistant position (PhD student, 4 years). The position is  available from September (a starting date until Fall 2019 is intended)  and the successful candidate will be a PhD student of the <a href="https://logic-cs.at/phd/">LogiCS Doctoral Program</a> and she/he will be supervised by Prof. Ezio Bartocci &lt;<a href="https://l.facebook.com/l.php?u=http%3A%2F%2Fwww.eziobartocci.com%2F%3Ffbclid%3DIwAR0DbRlQ3WbZCS1HzoZXYIRYXBsRDz2tCxE2G_6APz6K76RRDmLVMIkgBOg&amp;h=AT3xOIDKhxhBw2_daqAKot9Y3qtCNlITUpSxTEttEVYsbYoofL5LKQ7MD72mx8Nf3f0zPGNE5AY-FvqTQsTVZMllhO6DR94ug3vsjG3H84L4h8RDLdPWJxht8otBFNix1De-G1NEeihv6M6l-3cp" rel="noopener nofollow" target="_blank">http://www.eziobartocci.com/</a>&gt; and co-supervised by Dr. Laura Nenzi &lt;<a href="https://l.facebook.com/l.php?u=https%3A%2F%2Flauranenzi.github.io%2F%3Ffbclid%3DIwAR0O-FIXoCWcyMBVUqn5K-Ejd0vxQQJFYQ7ni1qBAdy9Ez01d6CDolZcb6U&amp;h=AT1RfdebNNlmUThAy2WWm6AclixjQ6sGfMnjrc5C-e4EbEglPtsVHAvYqJHIPfOZfHtYPGxz__so98GKEhDQZkGKQWB2z2fBom5MdlaCvrImUyjEZ5wotHeR5-w6sF4BkAIL-PGzihR9ZVsmSasc" rel="noopener nofollow" target="_blank">https://lauranenzi.github.io/</a>&gt;<br/> The successful applicant will carry out his/her PhD in the research  area of formal methods applied to the specification and monitoring of  large-scale, spatially-distributed, stochastic systems.<br/> The position in funded by the ÖAW and the FWF &lt;<a href="https://l.facebook.com/l.php?u=https%3A%2F%2Fm.fwf.ac.at%2Fen%2Fresearch-funding%2Fpersonnel-costs%2F%3Ffbclid%3DIwAR10rZDtpakXdwSo_WXE4A9GuFDbfkJoVYoCTgpZuBDmCMPVOmC8ZAo7Cyg&amp;h=AT13vFq0Svw4kLAe0VMNoonNMZyo8o6gdfK_-O0_LFJNhJavAH7Zt2YCyKMEKHuymeDiRrW6PggMAbBH0FyhcksLJJ0py3YWXi5vgwUwD0r_i3SFPvATFXhyZukxJL770ABLvhkdvgFQyiFvm5I8" rel="noopener nofollow" target="_blank">https://m.fwf.ac.at/en/research-funding/personnel-costs/</a>&gt;  for the recently acquired YIRG grant: “High-dimensional statistical  learning: new methods to advance economic and sustainability policies”,  an interdisciplinary project to be led for the TU part by PhD Laura  Nenzi.<br/> TASK DESCRIPTION (leader Laura Nenzi):   <br/> Formal  methods provide precise formal specification languages that can be  easily interpreted by humans and verification algorithms that can check  in an automatic way the value of satisfaction of interesting properties.  One of the main problems of such techniques is the curse of  dimensionality. A possibility to treat the problem is to use approximate  methods such as statistical model checking. However, even these  methodologies can be unfeasible for very-large-scale stochastic systems.  A new research line consists of exploiting machine learning techniques  and Bayesian inference to identify relevant data and decrease the  computational cost, permitting the application of such powerful formal  analysis on very complex systems. An important aspect that will be  covered in the study is the spatial configuration of such systems, a key  feature in several real case studies that are considering in the  project. The methodology will be principally applied to tackle questions  related to sustainable urban mobility and thus responsible consumption.<br/> APPLICATION<br/> Please apply your application following  the instructions in the DK LogiCS admission portal. <a href="https://l.facebook.com/l.php?u=https%3A%2F%2Flogic-cs.at%2Fphd%2Fadmission%2F%3Ffbclid%3DIwAR3oZZ1EmwtB7RHLErRrlbfY-HBeprkDbr8y-WyttxBelPGVrFY46hZuy3o&amp;h=AT2erabItYmdcemt5VHuXftBV82JOmliZPV-SIiYfhedKPgLyH9PR_pf1dJ3EHa-SQgsBTWJqgjsgzUJPauzRI4h_2t1t8Ci_NW6DannlCzLkriOSguTjs3IfU4p0eBWTTEvJmljKFMYpbZ36tKn" rel="noopener nofollow" target="_blank">https://logic-cs.at/phd/admission/</a> &lt;<a href="https://logic-cs.at/phd/admission/?fbclid=IwAR1rL9Zavpr2JH9oOonuC0OZ0wPUsoFxWi0usVFZPXQJzSJeSQr97rk490c" rel="noopener nofollow" target="_blank">https://logic-cs.at/phd/admission/</a>&gt;,  by indicating in the application form: Prof. Ezio Bartocci and Dr.  Laura Nenzi as supervisors. While it is not necessary to have the Master  degree at the moment of the application, it is instead mandatory to  complete it before starting the PhD.<br/> CONTACT DETAILS<br/> For  further information and inquiries about this post please contact Laura  Nenzi, e-mail: laura.nenzi@gmail.com  .</div></div>
    </content>
    <updated>2019-07-02T08:47:00Z</updated>
    <published>2019-07-02T08:47:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-07-13T09:23:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/07/02/papafest-for-christos-70th-birthday/</id>
    <link href="https://cstheory-events.org/2019/07/02/papafest-for-christos-70th-birthday/" rel="alternate" type="text/html"/>
    <title>PapaFest for Christos’ 70th birthday</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">September 6-8, 2019 Columbia University http://papafest.cs.columbia.edu/ We are happy to invite you to Columbia University to celebrate Christos Papadimitriou’s contributions to science on the occasion of his 70th birthday, through a mix of talks, panels, and fun activities. One of world’s leading computer scientists, Christos is best known for his work in computational complexity, helping … <a class="more-link" href="https://cstheory-events.org/2019/07/02/papafest-for-christos-70th-birthday/">Continue reading <span class="screen-reader-text">PapaFest for Christos’ 70th birthday</span></a></div>
    </summary>
    <updated>2019-07-02T08:32:49Z</updated>
    <published>2019-07-02T08:32:49Z</published>
    <category term="other"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-07-14T04:21:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4229</id>
    <link href="https://www.scottaaronson.com/blog/?p=4229" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4229#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4229" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Sensitivity Conjecture resolved</title>
    <summary xml:lang="en-US">The Sensitivity Conjecture, which I blogged about here, says that, for every Boolean function f:{0,1}n→{0,1}, the sensitivity of f—that is, the maximum, over all 2n input strings x∈{0,1}n, of the number of input bits such that flipping them changes the value of f—is at most polynomially smaller than a bunch of other complexity measures of […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Sensitivity Conjecture, which I blogged about <a href="https://www.scottaaronson.com/blog/?p=453">here</a>, says that, for every Boolean function f:{0,1}<sup>n</sup>→{0,1}, the <em>sensitivity</em> of f—that is, the maximum, over all 2<sup>n</sup> input strings x∈{0,1}<sup>n</sup>, of the number of input bits such that flipping them changes the value of f—is at most polynomially smaller than a bunch of other complexity measures of f, including f’s block sensitivity, degree as a real polynomial, and classical and quantum query complexities.  (For more, see for example <a href="http://www.cs.columbia.edu/~rocco/Teaching/S12/Readings/BdW.pdf">this survey</a> by Buhrman and de Wolf.  Or for quick definitions of the relevant concepts, <a href="https://cstheory.stackexchange.com/questions/19902/boolean-functions-where-sensitivity-equals-block-sensitivity">see here</a>.)</p>



<p>Ever since it was posed by Nisan and Szegedy in 1989, this conjecture has stood as one of the most frustrating and embarrassing open problems in all of combinatorics and theoretical computer science.  It seemed so easy, and so similar to other statements that had 5-line proofs.  But a lot of the best people in the field sank months into trying to prove it.  For whatever it’s worth, I also sank … well, at least weeks into it.</p>



<p>Now <a href="http://www.mathcs.emory.edu/~hhuan30/">Hao Huang</a>, a mathematician at Emory University, has posted a <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">6-page preprint</a> on his homepage that finally proves the Sensitivity Conjecture, in the form s(f)≥√deg(f).  (I thank Ryan O’Donnell for tipping me off to this.)  Within the preprint, the proof itself is about a page and a half.</p>



<p>Whenever there’s an announcement like this, ~99% of the time either the proof is wrong, or at any rate it’s way too complicated for outsiders to evaluate it quickly.  This is one of the remaining 1% of cases.  I’m rather confident that the proof is right.  Why?  Because I read and understood it.  It took me about half an hour.  If you’re comfortable with concepts like <em>induced subgraph</em> and <em>eigenvalue</em>, you can do the same.</p>



<p>From pioneering work by Gotsman and Linial in 1992, it was known that to prove the Sensitivity Conjecture, it suffices to prove the following even simpler combinatorial conjecture:</p>



<blockquote class="wp-block-quote"><p>Let S be any subset of the n-dimensional Boolean hypercube, {0,1}<sup>n</sup>, which has size 2<sup>n-1</sup>+1.  Then there must be a point in S with at least ~n<sup>c</sup> neighbors in S.</p></blockquote>



<p>Here c&gt;0 is some constant (say 1/2), and two points in S are “neighbors” if and only they differ in a single coordinate.  Note that if S had size 2<sup>n-1</sup>, then the above statement would be false—as witnessed, for example, by the set of all n-bit strings with an even number of 1’s.</p>



<p>Huang proceeds by proving the Gotsman-Linial Conjecture.  And the way he proves Gotsman-Linial is … well, at this point maybe I should just let you <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">read the damn preprint</a> yourself.  I can’t say it more simply than he does.</p>



<p>If I had to try anyway, I’d say: Huang constructs a 2<sup>n</sup>×2<sup>n</sup> matrix, called A<sub>n</sub>, that has 0’s where there are no edges between the corresponding vertices of the Boolean hypercube, and either 1’s or -1’s where there <em>are</em> edges—with a simple, weird pattern of 1’s and -1’s that magically makes everything work.  He then lets H be an induced subgraph of the Boolean hypercube of size 2<sup>n-1</sup>+1.  He lower-bounds the maximum degree of H by the largest eigenvalue of the corresponding (2<sup>n-1</sup>+1)×(2<sup>n-1</sup>+1) submatrix of A<sub>n</sub>.  Finally, he lower-bounds that largest eigenvalue by … no, I don’t want to spoil it!  Read it yourself!</p>



<p>Paul Erdös famously spoke of a book, maintained by God, in which was written the simplest, most beautiful proof of each theorem.  The highest compliment Erdös could give a proof was that it “came straight from the book.”  In this case, I find it hard to imagine that even God knows how to prove the Sensitivity Conjecture in any simpler way than this.</p>



<p>Indeed, the question is: how could such an elementary 1.5-page argument have been overlooked for 30 years?  I don’t have a compelling answer to that, besides noting that “short” and “elementary” often have little to do with “obvious.”  Once you start looking at the spectral properties of this matrix A<sub>n</sub>, the pieces snap together in precisely the right way—but how would you know to look at that?</p>



<p>By coincidence, earlier today I finished reading my first PG Wodehouse novel (<em><a href="http://www.gutenberg.org/files/10554/10554-h/10554-h.htm">Right Ho, Jeeves!</a></em>), on the gushing recommendation of a friend.  I don’t know how I’d missed Wodehouse for 38 years.  His defining talent is his ability to tie together five or six plot threads in a way that feels perfect and inevitable even though you didn’t see it coming.  This produces a form of pleasure that’s nearly indistinguishable from the pleasure one feels in reading a “proof from the book.”  So my pleasure centers are pretty overloaded today—but in such depressing times for the world, I’ll take pleasure wherever I can get it.</p>



<p>Huge congratulations to Hao!</p>



<p><strong>Added thought:</strong> What this really is, is one of the purest illustrations I’ve seen in my career of the power and glory of the P≠NP phenomenon.  We talk all the time about how proofs are easier to verify than to find.  In practice, though, it can be far from obvious that that’s true.  Consider your typical STOC/FOCS paper: writing it probably took the authors several months, while fully understanding the thing from scratch would probably take … <em>also</em> several months!  If there’s a gap, it’s only by a factor of 4 or 5 or something.  Whereas in this case, I don’t know how long Huang spent searching for the proof, but the combined search efforts of the community add up to years or decades.  The ratio of the difficulty of finding to the difficulty of completely grasping is in the hundreds of thousands or millions.</p>



<p><strong>Another added thought:</strong> Because Hao actually proves a stronger statement than the original Sensitivity Conjecture, it has additional implications, a few of which Hao mentions in his preprint.  Here’s one he didn’t mention: any randomized algorithm to guess the parity of an n-bit string, which succeeds with probability at least 2/3 on the majority of strings, must make at least ~√n queries to the string, while any such quantum algorithm must make at least ~n<sup>1/4</sup> queries.  For more, see the paper <a href="https://arxiv.org/pdf/1312.0036.pdf">Weak Parity</a> by me, Ambainis, Balodis, and Bavarian (Section 6).</p>



<p><strong>Important Update:</strong> Hao Huang himself has graciously <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813116">visited the comment section</a> to satisfy readers’ curiosity by providing a detailed timeline of his work on the Sensitivity Conjecture.  (tl;dr: he was introduced to the problem by Mike Saks in 2012, and had been attacking it on and off since then, until he finally had the key insight this past month while writing a grant proposal.  Who knew that grant proposals could ever be useful for anything?!?)</p>



<p><strong>Another Update:</strong> In the comments section, my former student Shalev Ben-David points out a <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813084">simplification</a> of Huang’s argument, which no longer uses Cauchy’s interlacing theorem.  I thought there was no way this proof could possibly be made any simpler, and I was wrong!</p></div>
    </content>
    <updated>2019-07-02T05:15:43Z</updated>
    <published>2019-07-02T05:15:43Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-13T23:39:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17499</id>
    <link href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/" rel="alternate" type="text/html"/>
    <title>Amazing: Hao Huang Proved the Sensitivity Conjecture!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Today’s arXived amazing paper by Hao Huang’s Induced subgraphs of hypercubes and a proof of the Sensitivity Conjecture Contains an amazingly short and beautiful proof of a famous open problem from the theory of computing – the sensitivity conjecture posed … <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Today’s arXived amazing paper by Hao Huang’s</p>
<p><a href="https://arxiv.org/abs/1907.00847">Induced subgraphs of hypercubes and a proof of the Sensitivity Conjecture</a></p>
<p>Contains an amazingly short and beautiful proof of a famous open problem from the theory of computing – the sensitivity conjecture posed by Noam Nisan and Mario Szegedi</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/hao-huang-chicago.jpg"><img alt="" class="alignnone size-medium wp-image-17505" height="225" src="https://gilkalai.files.wordpress.com/2019/07/hao-huang-chicago.jpg?w=300&amp;h=225" width="300"/></a></p>
<p><span style="color: #ff0000;"><strong>Hao Huang</strong></span></p>
<p><strong>Abstract: </strong>In this paper, we show that every <img alt="2^{n-1}+1" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bn-1%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{n-1}+1"/>-vertex induced subgraph of the <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-dimensional cube graph has maximum degree at least <img alt="\sqrt n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt n"/>. This result is best possible, and improves a logarithmic lower bound shown by Chung, Füredi, Graham and Seymour in 1988. As a direct consequence, we prove that the sensitivity and degree of a boolean function are polynomially related, solving an outstanding foundational problem in theoretical computer science, the Sensitivity Conjecture of Nisan and Szegedy.</p>
<p>The proof relies on important relation between the two problems  by Gotsman and Linial. It uses beautifully Cauchy’s interlace theorem (for eigenvalues).</p>
<p>Thanks to Noga Alon for telling me about the breakthrough. For more on the conjecture and a polymath project devoted to solve it see <a href="https://www.scottaaronson.com/blog/?p=453">this post</a> on Aaronson’s Shtetl Optimized (SO).  See also <a href="https://rjlipton.wordpress.com/2016/10/05/congratulations-noam/">this post on GLL.</a> Updates: See this <a href="https://www.scottaaronson.com/blog/?p=4229">new lovely post on SO</a> (and don’t miss the excellent comment thread); and <a href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/">this post by Boaz Barak </a>on WOT (Window on Theory) explains the main ingredient of Huang’s proof. Here is <a href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html">a post by Lance Fortnow</a> on CC (Computational Complexity) mentioning a <a href="https://twitter.com/BooleanAnalysis/status/1145837576487612416">remarkable tweet</a> by Ryan O’Donnell (see below the fold). Here is <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813116">a comment by Hao</a> on SO on the history of his own work on the problem since he heard it from Mike Saks in 2012.</p>
<p>Also today on the arXive a paper by <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pat%C3%A1kov%C3%A1%2C+Z">Zuzana (Zuzka) Patáková</a> and me: <a href="https://arxiv.org/abs/1907.00885">Intersection Patterns of Planar Sets</a>. Like one of my very first papers “Intersection patterns of convex sets” the new paper deals with face numbers of nerves of geometric sets.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/kp1.png"><img alt="" class="alignnone size-full wp-image-17510" src="https://gilkalai.files.wordpress.com/2019/07/kp1.png?w=640"/></a><span id="more-17499"/></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/kp2.png"><img alt="" class="alignnone size-full wp-image-17511" src="https://gilkalai.files.wordpress.com/2019/07/kp2.png?w=640"/></a></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/ro.png"><img alt="" class="alignnone size-full wp-image-17515" height="675" src="https://gilkalai.files.wordpress.com/2019/07/ro.png?w=640&amp;h=675" width="640"/></a></p></div>
    </content>
    <updated>2019-07-02T04:07:15Z</updated>
    <published>2019-07-02T04:07:15Z</published>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Hao Huang"/>
    <category term="sensitivity conjecture"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-14T04:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4220</id>
    <link href="https://www.scottaaronson.com/blog/?p=4220" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4220#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4220" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Quantum Sabinacy</title>
    <summary xml:lang="en-US">Sabine Hossenfelder—well-known to readers of Shtetl-Optimized for opposing the building of a higher-energy collider, and various other things—has weighed in on “quantum supremacy” in this blog post and this video. Sabine consulted with me by phone before doing the video and post, and despite what some might see as her negative stance, I agree with […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Sabine Hossenfelder—well-known to readers of <em>Shtetl-Optimized</em> for <a href="https://www.scottaaronson.com/blog/?p=4122">opposing the building</a> of a higher-energy collider, and various other things—has weighed in on “quantum supremacy” in <a href="http://backreaction.blogspot.com/2019/06/quantum-supremacy-what-is-it-and-what.html?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed:+Backreaction+(Backreaction)&amp;m=1">this blog post</a> and <a href="https://www.youtube.com/watch?time_continue=1&amp;v=GKnfVA1v5ow">this video</a>.  Sabine consulted with me by phone before doing the video and post, and despite what some might see as her negative stance, I agree with what she has to say substantially more than I disagree.</p>



<p>I do, however, have a few quibbles:</p>



<p> 1. We don’t know that millions of physical qubits will be needed for useful simulations of quantum chemistry.  It all depends on how much error correction is needed and how good the error-correcting codes and simulation algorithms become.  Like, sure, you can generate pessimistic forecasts by plugging numbers in to the best known codes and algorithms.  But “the best known” is a rapidly moving target—one where there have already been orders-of-magnitude improvements in the last decade.</p>



<p>2. To my mind, there’s a big conceptual difference between a single molecule that you can’t efficiently simulate classically, and a programmable computer that you can’t efficiently simulate classically.  The difference, in short, is that only for the computer, and not for the molecule, would it ever make sense to say it had given you a <strong>wrong</strong> answer!  In other words, a physical system becomes a “computer” when, and only when, you have sufficient understanding of, and control over, its state space and time evolution that you can ask the system to simulate something <em>other than itself</em>, and then judge whether it succeeded or failed at that goal.</p>



<p>3. The entire point of my recent work, on certified randomness generation (see for example <a href="https://www.scottaaronson.com/talks/certrand2.ppt">here</a> or <a href="https://www.quantamagazine.org/how-to-turn-a-quantum-computer-into-the-ultimate-randomness-generator-20190619/">here</a>), is that sampling random bits with a NISQ-era device <em>could</em> have a practical application.  That application is … I hope you’re sitting down for this … sampling random bits!  And then, more importantly and nontrivially, <strong>proving</strong> to a faraway skeptic that the bits really were randomly generated.</p>



<p>4. While I was involved in some of the first proposals for NISQ quantum supremacy experiments (such as <a href="https://en.wikipedia.org/wiki/Boson_sampling">BosonSampling</a>), I certainly can’t take sole credit for the idea of quantum supremacy!  The term, incidentally, <a href="https://arxiv.org/abs/1203.5813">was coined by John Preskill</a>.</p>



<p>5. The term “NISQ” (Noisy Intermediate Scale Quantum) was also <a href="https://arxiv.org/abs/1801.00862">coined by John Preskill</a>.  He had no intention of misleading investors—he just needed a term to discuss the quantum computers that will plausibly be available in the near future.  As readers of this blog know, there certainly <em>has</em> been some misleading of investors (and journalists, and the public…) about the applications of near-term QCs.  But I don’t think you can lay it at the feet of the term “NISQ.”</p></div>
    </content>
    <updated>2019-07-01T18:30:10Z</updated>
    <published>2019-07-01T18:30:10Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-13T23:39:30Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7054757178293557182</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7054757178293557182/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/a-proof-that-227-pi-0-and-more.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7054757178293557182" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7054757178293557182" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/a-proof-that-227-pi-0-and-more.html" rel="alternate" type="text/html"/>
    <title>A proof that 22/7 - pi &gt; 0 and more</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
My father was a High School English teacher who did not know much math. As I was going off to college, intending to major in math, he gave me the following sage advice:<br/>
<br/>
1) <i>Take Physics as well as Math since Physics and Math go well together.</i> This was good advice. I took the first year of Physics for Physics Majors, and I later took a senior course in Mechanics since that was my favorite part of the first year course. Kudos to Dad!<br/>
<br/>
2) π <i>is exactly </i>22/7. I knew this was not true, but I also knew that I had no easy way to show him this. In fact, I wonder if I could have proven it myself back then.<br/>
<br/>
I had not thought about this in many years when I came across the following:<br/>
<br/>
Problem A-1 on the 1968 Putnam exam:<br/>
<br/>
Prove 22/7 - π = ∫<sub>0</sub><sup>1</sup> (x<sup>4</sup>(1-x)<sup>4</sup>)/(1+ x<sup>2</sup> )dx<br/>
<br/>
(I can easily do his by partial fractions and remembering that ∫ 1/(1+x^2) dx = tan<sup>-1</sup>x  which is tan inverse, not 1/tan. See <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pi.pdf">here</a>.)<br/>
<br/>
(ADDED LATER---I have added conjectures on getting integrals of the form above except with 4 replaced by any natural number. Be the first on your block to solve my conjectures! It has to be easier than the Sensitivity Conjecture!)<br/>
<br/>
<br/>
<br/>
Let n &amp;in N which we will choose later. By looking at the circle that is inscribed in a regular n-polygon (n even) one finds that <br/>
<br/>
<br/>
n tan(π/n) &gt;  π <br/>
<br/>
<br/>
So we seek an even  value of n such that<br/>
<br/>
<br/>
n tan(π/n) &lt; 22/7<br/>
<br/>
<br/>
Using Wolfram alpha the smallest such n is 92.<br/>
<br/>
Would that convince Dad? Would he understand it? Probably not. Oh well.<br/>
<br/>
Some misc points.<br/>
<br/>
<br/>
1)  While working on this post I originally wanted to find tan(π/2<sup>7</sup>) by using the half-angle formula many times, and get an exact answer in terms of radicals,  rather than using Wolfram Alpha. <br/>
<br/>
a) While I have lots of combinatorics books, theory of comp books, and more Ramsey Theory books than one person should own in my house, I didn't have a SINGLE book with any trig in it.<br/>
<br/>
b) I easily found it on the web: <br/>
<br/>
tan(x/2) = sqrt( (1-cos x)/(1+cos x) ) = sin x/(1+cos x) = (1-cos x)/(sin x).<br/>
<br/>
None of these seems like it would get me a nice expression for tan(π/2<sup>7</sup>). But I don't know. Is there a nice expression for tan(π/2<sup>k</sup>) ? If you know of one then leave a polite comment.<br/>
<br/>
2) I assumed that there was a more clever and faster way to do the integral. I could not find old Putnam exams and their solutions  the web (I'm sure they are there someplace! --- if you know then comment politely with a pointer). So I got a book out of the library <i>The William Lowell Putnam Mathematical Competition Problems and Solutions 1965--1984</i> by Alexanderson, Klosinski, and Larson. Here is the clever solution:<br/>
<br/>
<i>The standard approach from Elementary Calculus applies.<br/>
<br/>
</i><br/>
<br/>
Not as clever as I as hoping for.<br/>
<br/>
3) I also looked at the integral with 4 replaced by 1,2,3,4,...,16. The results are in the writeup I pointed to before. It looks like I can use this sequence to get  upper and lower bound on pi, ln(2), pi+2ln(2), and pi-2ln(2). I have not proven any of this. But take a look! And as noted above I have conjectures!<br/>
<br/>
<br/>
4) When I looked up INSCRIBING a circle in a regular n-polygon, Google kept giving me CIRCUMSCRIBING. Why? I do not know but I can speculate. Archimedes had a very nice way of using circumscribed circles to approximate pi. Its on youtube <a href="https://www.youtube.com/watch?v=_rJdkhlWZVQ">here</a>.  Hence people are used to using circumscribed rather than inscribed circles.<br/>
<br/></div>
    </content>
    <updated>2019-07-01T02:34:00Z</updated>
    <published>2019-07-01T02:34:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-13T10:51:41Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/06/30/linkage</id>
    <link href="https://11011110.github.io/blog/2019/06/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Ok, some of these are not so much links as mini-reports from SPAA/STOC/FCRC. For an actual conference report, see Lance’s post.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Ok, some of these are not so much links as mini-reports from SPAA/STOC/FCRC. For an actual conference report, see <a href="https://blog.computationalcomplexity.org/2019/06/fcrc-2019.html">Lance’s post</a>.</p>

<ul>
  <li>
    <p><a href="https://uhills.org/the-university-hills-section-marker-a-history-of-maps-markers-and-monuments-that-eventually-created-university-hills/">Squaring the spherical earth</a> (<a href="https://mathstodon.xyz/@11011110/102285188426196734"/>). For surveying purposes, Orange County is divided into “sections”, typically one square mile (not axis-aligned!) with small brass markers at their corners. One corner lands in the UCI faculty housing development where I live, and the housing association took the opportunity to make a larger decorative marker for it.</p>
  </li>
  <li>
    <p><a href="https://gilkalai.wordpress.com/2019/03/22/danny-nguyen-and-igor-pak-presburger-arithmetic-problem-solved/">Integer linear programming, change-making, and Presburger arithmetic</a> (<a href="https://mathstodon.xyz/@11011110/102291138538406550"/>). Integer arithmetic problems with a constant number of variables and one level of quantifiers (example: given a constant number of coin types, find the largest amount of money for which you cannot make change) have long been known to be polynomially solvable, but <a href="http://www.math.ucla.edu/~pak/papers/hard_presburger3.pdf">in FOCS 2017 Nguyen and Pak proved that only two levels of quantifiers make the problem hard</a>.</p>
  </li>
  <li>
    <p><a href="https://tomas.rokicki.com/dottri.html">Dots and triangles</a> (<a href="https://mathstodon.xyz/@christianp/102297036146535876"/>). Online variant of dots and boxes by Tomas Rikicki.</p>
  </li>
  <li>
    <p><a href="https://cameroncounts.wordpress.com/2019/06/19/combinatorics-at-strathclyde/">University of Strathclyde proposes to axe combinatorics and their three strong combinatorics faculty members</a> (<a href="https://mathstodon.xyz/@11011110/102301038310925223"/>, <a href="https://gowers.wordpress.com/2019/06/19/the-fate-of-combinatorics-at-strathclyde/">via</a>). This comes despite the group being both strong in research and important in undergraduate education. The apparent cause is Strathclyde’s placement of combinatorics in computer science rather than in mathematics and in their use of standards aimed more at computer science than mathematics (like bringing in large grants). There’s an <a href="https://britishcombinatorial.wordpress.com/2019/06/20/combinatorics-at-strathclyde-2/">online petition against the cuts</a> closing very soon: 5pm British time, July 1.</p>
  </li>
  <li>
    <p>Catherine Greenhill is setting up a new network for women in combinatorics, meaning “anyone who identifies as a woman, is non-binary, two-spirit, or gender diverse” (<a href="https://mathstodon.xyz/@11011110/102311965002907932"/>). <a href="https://womenincombinatorics.com/">Their website</a> currently only has a sign-up form, but expect more to come.</p>
  </li>
  <li>
    <p>Slides from three of my recent conference talks (<a href="https://mathstodon.xyz/@11011110/102319479687501682"/>):
<a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-SoCG-19-many-lines-slides.pdf">Cubic planar graphs that cannot be drawn on few lines</a>; <a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-SoCG-19-counting-slides.pdf">Counting polygon triangulations is hard</a>; <a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-SPAA-19-slides.pdf">NC algorithms for perfect matching and maximum flow in one-crossing-minor-free graphs</a>.</p>
  </li>
  <li>
    <p>Certain conference speakers need to be told that using sans-serif ∑ for one central notation and sans-serif bold ∑ for a different central notation is a bad idea. That decorating both of them by the same subscripts and the same hats doesn’t help. And that when someone asks for clarification of the notation, answering with “We should move on…this is a thing you can compute on your own” rather than actually explaining is rude (<a href="https://mathstodon.xyz/@11011110/102323855724493135"/>).</p>
  </li>
  <li>
    <p>The STOC Wikipedia edit-a-thon was called off because the convention center was locked up and participants couldn’t get into the room it was scheduled for (<a href="https://mathstodon.xyz/@11011110/102330434291269046"/>). But <a href="https://thmatters.wordpress.com/2019/06/26/edit-a-thon-update/">it was successfully rescheduled for the next day</a>, unfortunately too late in the conference for me to participate.</p>

    <p>In other news from STOC, spammy journal publishers have found a new way to spam us: fund student authors with travel awards (laudable and non-spammy!) but then require the student presenters to display a whole slide of advertising for the journal by way of acknowledgements (spammy!).</p>
  </li>
  <li>
    <p><a href="https://xkcd.com/2168/">xkcd on reading Wikipedia in the original Greek</a> (<a href="https://mathstodon.xyz/@11011110/102339055555301837"/>).</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1906.10668">Discrete logarithms in quasi-polynomial time in finite fields of fixed characteristic</a> (<a href="https://mathstodon.xyz/@erou/102337004608271854"/>). New preprint by Kleinjung and Weselowski.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=OerQAsqEOLc">Short video on interleaving multiple copies of the infinite Laves graph</a> (<a href="https://mathstodon.xyz/@11011110/102353592823020968"/>). Sound not necessary.</p>
  </li>
  <li>
    <p><a href="https://arstechnica.com/science/2019/06/two-new-papers-explore-the-complicated-physics-behind-bubbles-and-foams/">Two new papers explore the complicated physics behind bubbles and foams</a> (<a href="https://mathstodon.xyz/@11011110/102356874963380843"/>).
Juanes et al find <a href="http://dx.doi.org/10.1073/pnas.1819744116">universality in pinching off uniformly sized bubbles</a> from a tube much like drops from a dripping faucet. And Yanagisawa and Kurita discover <a href="http://dx.doi.org/10.1038/s41598-019-41486-6">two mechanisms for breaking bubbles to propagate through a foam</a>. As it contracts, the breaking bubble can hit other bubbles, and it can also scatter off droplets which hit other bubbles.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1902.07622">Centrality analysis of Wikipedia links between mathematicians</a> (<a href="https://mathstodon.xyz/@11011110/102361585031049847"/>, <a href="https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2019-06-30/Recent_research">via</a>). None of the names listed are surprising, but the ordering might be a little. Noether makes the top 10; Bourbaki, Grothendieck, and Turing are farther down. Martin Gardner makes the cut (barely), at #35.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-06-30T16:16:00Z</updated>
    <published>2019-06-30T16:16:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-06-30T23:47:50Z</updated>
    </source>
  </entry>
</feed>
