<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-07-09T13:21:42Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17523</id>
    <link href="https://gilkalai.wordpress.com/2019/07/09/imre-barany-limit-shape/" rel="alternate" type="text/html"/>
    <title>Imre Bárány: Limit shape</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Limit shapes are fascinating objects in the interface between probability and geometry and between the discrete and the continuous. This post is kindly contributed by Imre Bárány. What is a limit shape? There are finitely many convex lattice polygons contained … <a href="https://gilkalai.wordpress.com/2019/07/09/imre-barany-limit-shape/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>Limit shapes are fascinating objects in the interface between probability and geometry and between the discrete and the continuous. This post is kindly contributed by Imre Bárány.</em></p>
<h3><a href="https://gilkalai.files.wordpress.com/2019/07/imre_barany_2011.jpg"><img alt="" class="alignnone size-full wp-image-17560" src="https://gilkalai.files.wordpress.com/2019/07/imre_barany_2011.jpg?w=640"/></a></h3>
<h2>What is a limit shape?</h2>
<p>There are finitely many convex lattice polygons contained in the <img alt="{[0,n]^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B0%2Cn%5D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[0,n]^2}"/> square. Their number turns out to be</p>
<p><img alt="\displaystyle \exp\{3\sqrt[3]{\zeta(3)/\zeta(2)}n^{2/3}(1+o(1))\}. \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cexp%5C%7B3%5Csqrt%5B3%5D%7B%5Czeta%283%29%2F%5Czeta%282%29%7Dn%5E%7B2%2F3%7D%281%2Bo%281%29%29%5C%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \exp\{3\sqrt[3]{\zeta(3)/\zeta(2)}n^{2/3}(1+o(1))\}. \ \ \ \ \ (1)"/></p>
<p>This is a large number. How does a typical element of this large set look? Is there a<br/>
limit shape of these convex lattice polygons?</p>
<p>To answer this question it is convenient to consider the lattice <img alt="{{\mathbb{Z}}_n=\frac 1n {\mathbb{Z}}^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%3D%5Cfrac+1n+%7B%5Cmathbb%7BZ%7D%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n=\frac 1n {\mathbb{Z}}^2}"/> and define <img alt="{\mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n}"/> as the family of all convex <img alt="{{\mathbb{Z}}_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n}"/>-lattice polygons lying in the unit square <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/>. The polygons in <img alt="{\mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n}"/> have a limit shape (as <img alt="{n\rightarrow \infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n\rightarrow \infty}"/>) if there is a convex set <img alt="{K\subset Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%5Csubset+Q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K\subset Q}"/> such that the overwhelming majority of the polygons in <img alt="{\mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n}"/> are very close to <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/>. In other words, for every <img alt="{\epsilon&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon&gt;0}"/> the number of polygons in <img alt="{\mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n}"/> that are farther than <img alt="{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon}"/> from <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> (in Hausdorff distance, say) is a minute part of <img alt="{\mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n}"/>, that is, <img alt="{o(|\mathcal{F}^n|)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bo%28%7C%5Cmathcal%7BF%7D%5En%7C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{o(|\mathcal{F}^n|)}"/> as <img alt="{n \rightarrow \infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \rightarrow \infty}"/>. To put it differently, the average of the characteristic functions <img alt="{\chi_P(.)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_P%28.%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi_P(.)}"/> of <img alt="{P\in \mathcal{F}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%5Cin+%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P\in \mathcal{F}^n}"/> tends to a zero-one function:</p>
<p><img alt="\lim {\rm Ave}_{P\in \mathcal{F}^n}\chi_P(x)=\begin{cases} 1&amp; \mbox{ if } x \in K,\\ 0&amp; \mbox{ if } x \notin K. \end{cases} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Clim+%7B%5Crm+Ave%7D_%7BP%5Cin+%5Cmathcal%7BF%7D%5En%7D%5Cchi_P%28x%29%3D%5Cbegin%7Bcases%7D+1%26+%5Cmbox%7B+if+%7D+x+%5Cin+K%2C%5C%5C+0%26+%5Cmbox%7B+if+%7D+x+%5Cnotin+K.+%5Cend%7Bcases%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lim {\rm Ave}_{P\in \mathcal{F}^n}\chi_P(x)=\begin{cases} 1&amp; \mbox{ if } x \in K,\\ 0&amp; \mbox{ if } x \notin K. \end{cases} "/></p>
<h2>The limit shape theorem</h2>
<h3/>
<p>The limit shape theorem says that such a <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> exists, its boundary consists of four parabola arcs each touching consecutive sides of <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Q"/> at their midpoints, see the figure.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/limitshape.png"><img alt="" class="alignnone size-full wp-image-17536" src="https://gilkalai.files.wordpress.com/2019/07/limitshape.png?w=640"/></a></p>
<h3>Generating functions and saddle point methods</h3>
<p>The proof is based on the fact that a convex (lattice or non-lattice) polygon with vertices <img alt="v_1,\ldots,v_n" class="latex" src="https://s0.wp.com/latex.php?latex=v_1%2C%5Cldots%2Cv_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v_1,\ldots,v_n"/> (in this order on its boundary) is uniquely determined by the edge-vectors <img alt="v_2-v_1,\ldots,v_n-v_{n-1}, v_1-v_n" class="latex" src="https://s0.wp.com/latex.php?latex=v_2-v_1%2C%5Cldots%2Cv_n-v_%7Bn-1%7D%2C+v_1-v_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v_2-v_1,\ldots,v_n-v_{n-1}, v_1-v_n"/>. Using this one can write down the generating function of the number of convex lattice paths from <img alt="(0,0)" class="latex" src="https://s0.wp.com/latex.php?latex=%280%2C0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(0,0)"/> to <img alt="(a,b)\in \mathbb{Z}^2" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29%5Cin+%5Cmathbb%7BZ%7D%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)\in \mathbb{Z}^2"/> lying in the triangle whose vertices are <img alt="(0,0),(a,0)" class="latex" src="https://s0.wp.com/latex.php?latex=%280%2C0%29%2C%28a%2C0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(0,0),(a,0)"/> and <img alt="(a,b)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)"/>. And this number can be estimated by saddle point methods (from complex variables). This is also how formula (1) for <img alt="|\mathcal{F}^n|" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathcal%7BF%7D%5En%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathcal{F}^n|"/> can be established.</p>
<h3>A beautiful geometric result</h3>
<p>On the geometry part one needs a beautiful (and almost elementary) result saying that, in a triangle <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> with vertices <img alt="1,2,3" class="latex" src="https://s0.wp.com/latex.php?latex=1%2C2%2C3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1,2,3"/> and with subtriangles <img alt="T_1" class="latex" src="https://s0.wp.com/latex.php?latex=T_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T_1"/> and <img alt="T_2" class="latex" src="https://s0.wp.com/latex.php?latex=T_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T_2"/> (see the figure)</p>
<p><img alt="\displaystyle \sqrt[3]{\textrm{Area} \; T}\ge \sqrt[3]{\textrm{Area} \; T_1}+\sqrt[3]{\textrm{Area} \; T_2}, \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T%7D%5Cge+%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T_1%7D%2B%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T_2%7D%2C+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \sqrt[3]{\textrm{Area} \; T}\ge \sqrt[3]{\textrm{Area} \; T_1}+\sqrt[3]{\textrm{Area} \; T_2}, \ \ \ \ \ (2)"/></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/triangle.png"><img alt="" class="alignnone size-full wp-image-17537" src="https://gilkalai.files.wordpress.com/2019/07/triangle.png?w=640"/></a></p>
<p>with equality iff the line segment 46 is touches the special parabola arc at point 5. The special parabola arc is the one that touches sides 12 and 13 of <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> at points 2 and 3. I was very proud of inequality (2) but it turned out that it had been known for long (cf Blaschke: Vorlesungen Über Differentialgeometrie II, (1923) page 38).</p>
<p>In the proof one needs a slightly stronger version of (2). Assuming point 4 (resp. 6) divides segment 12 (and 13) in ratio <img alt="{1-a:a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1-a%3Aa%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1-a:a}"/>, (and <img alt="{b:1-b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%3A1-b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b:1-b}"/>), the stronger inequality says that</p>
<p><img alt="\displaystyle \sqrt[3]{\textrm{Area} \; T}\left(1-\frac13 (a-b)^2\right)\ge \sqrt[3]{\textrm{Area} \; T_1}+\sqrt[3]{\textrm{Area} \; T_2}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T%7D%5Cleft%281-%5Cfrac13+%28a-b%29%5E2%5Cright%29%5Cge+%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T_1%7D%2B%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T_2%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \sqrt[3]{\textrm{Area} \; T}\left(1-\frac13 (a-b)^2\right)\ge \sqrt[3]{\textrm{Area} \; T_1}+\sqrt[3]{\textrm{Area} \; T_2}, "/></p>
<p>which was probably not known to Blaschke.</p>
<p>It is important to point out that <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> is the unique convex subset of <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> whose affine perimeter is the largest among all convex subsets of <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/>. I’ll return to the affine perimeter later.</p>
<p>Yakov Sinai came up with a different, elegant, and more powerful proof using canonical ensembles from statistical physics. His method was developed further by Vershik and Zeitouni, by Bureaux and Enriquez, by Bogachev and Zarbaliev.</p>
<h2>Limit shapes for polygons in convex bodies</h2>
<p>More generally, one can consider a convex body (compact convex set with non-empty interior) <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> in the plane and the family <img alt="{\mathcal{F}^n(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n(C)}"/> of all convex <img alt="{{\mathbb{Z}}_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n}"/>-lattice polygons contained in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>, and ask whether a similar limit shape exists in this case. The answer is yes. The limit shape, <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>, is the unique convex subset of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> whose affine perimeter is maximal among all convex subsets of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. The affine perimeter is upper semicontinuous, implying the existence of convex subset of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> with maximal affine perimeter. The proof of its uniqueness requires extra effort. In the case when <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> is the unit square <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/>, the limit shape <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> is equal to <img alt="{Q_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_0}"/>. Note that for every convex body <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> with <img alt="{Q_0\subset C \subset Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ_0%5Csubset+C+%5Csubset+Q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q_0\subset C \subset Q}"/>, <img alt="{C_0=Q_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%3DQ_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0=Q_0}"/>.</p>
<h2>Random points vs. lattice points</h2>
<p>What happens if, instead of the <img alt="{{\mathbb{Z}}_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n}"/>-lattice points in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>, we take a random sample <img alt="{X_n=\{x_1,\ldots,x_n\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_n%3D%5C%7Bx_1%2C%5Cldots%2Cx_n%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_n=\{x_1,\ldots,x_n\}}"/> of points from <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>, chosen independently and uniformly? Let <img alt="{\mathcal{G}(X_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BG%7D%28X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{G}(X_n)}"/> be the set of all polygons whose vertices belong to <img alt="{X_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_n}"/>. This is again a finite set and one can show that<br/>
<img alt="\displaystyle \lim_{n\rightarrow \infty} n^{-1/3}\log \mathop{\mathbb E}( |\mathcal{G}(X_n)|)=3\cdot2^{-2/3}\frac{A^*(C)}{\sqrt[3]{\textrm{Area} \; C}}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clim_%7Bn%5Crightarrow+%5Cinfty%7D+n%5E%7B-1%2F3%7D%5Clog+%5Cmathop%7B%5Cmathbb+E%7D%28+%7C%5Cmathcal%7BG%7D%28X_n%29%7C%29%3D3%5Ccdot2%5E%7B-2%2F3%7D%5Cfrac%7BA%5E%2A%28C%29%7D%7B%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+C%7D%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \lim_{n\rightarrow \infty} n^{-1/3}\log \mathop{\mathbb E}( |\mathcal{G}(X_n)|)=3\cdot2^{-2/3}\frac{A^*(C)}{\sqrt[3]{\textrm{Area} \; C}}, "/></p>
<p>where <img alt="{A^*(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E%2A%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^*(C)}"/> is equal to the affine perimeter, <img alt="{AP(C_0)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAP%28C_0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AP(C_0)}"/>, of <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>. This confirms the philosophy (or my intuition) that random points and lattice points in convex bodies behave similarly. Note that <img alt="{\mathop{\mathbb E}|\mathcal{G}(X_n)|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%7C%5Cmathcal%7BG%7D%28X_n%29%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathop{\mathbb E}|\mathcal{G}(X_n)|}"/> is of order <img alt="{\exp\{c_1n^{1/3}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cexp%5C%7Bc_1n%5E%7B1%2F3%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\exp\{c_1n^{1/3}\}}"/> while <img alt="{|\mathcal{F}^n(C)|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cmathcal%7BF%7D%5En%28C%29%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|\mathcal{F}^n(C)|}"/> is of order <img alt="{\exp\{c_2n^{2/3}\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cexp%5C%7Bc_2n%5E%7B2%2F3%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\exp\{c_2n^{2/3}\}}"/> which is fine as number of <img alt="{{\mathbb{Z}}_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n}"/>-lattice points in <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> is approximately <img alt="{n^2 \textrm{Area} \; C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E2+%5Ctextrm%7BArea%7D+%5C%3B+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^2 \textrm{Area} \; C}"/>.</p>
<p>Even more interestingly, the limit shape of the polygons in <img alt="{\mathcal{G}(X_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BG%7D%28X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{G}(X_n)}"/> is <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>, in the sense that, in expectation, the overwhelming majority of polygons in <img alt="{\mathcal{G}(X_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BG%7D%28X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{G}(X_n)}"/> is very close to <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>. More precisely, for every <img alt="{\epsilon&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon&gt;0}"/><br/>
<img alt="\displaystyle \lim_{n \rightarrow \infty} \frac{\mathop{\mathbb E}|\{P\in \mathcal{G}(X_n):\delta(P,C_0)&gt;\epsilon\}|}{\mathop{\mathbb E}(|\mathcal{G}(X_n)|)}=0, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clim_%7Bn+%5Crightarrow+%5Cinfty%7D+%5Cfrac%7B%5Cmathop%7B%5Cmathbb+E%7D%7C%5C%7BP%5Cin+%5Cmathcal%7BG%7D%28X_n%29%3A%5Cdelta%28P%2CC_0%29%3E%5Cepsilon%5C%7D%7C%7D%7B%5Cmathop%7B%5Cmathbb+E%7D%28%7C%5Cmathcal%7BG%7D%28X_n%29%7C%29%7D%3D0%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \lim_{n \rightarrow \infty} \frac{\mathop{\mathbb E}|\{P\in \mathcal{G}(X_n):\delta(P,C_0)&gt;\epsilon\}|}{\mathop{\mathbb E}(|\mathcal{G}(X_n)|)}=0, "/></p>
<p>where <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> stands for the Hausdorf distance.</p>
<p>The proof of the lattice case does not work here. The edge vectors determine the convex polygon, still, but the edge vectors can’t be used, there is no generating function, etc. Instead the proof is based on the following two theorems. For the first let <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/> be a triangle with two specified vertices <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> and <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/> say, and let <img alt="{X_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_k}"/> be a random independent sample of <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> uniform points from <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/>. Then <img alt="{X_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_k}"/> is called a convex chain (from <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> to <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/>) if the convex hull of <img alt="{\{a,b\}\bigcup X_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7Ba%2Cb%5C%7D%5Cbigcup+X_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{a,b\}\bigcup X_k}"/> is a convex polygon with exactly <img alt="{k+2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k+2}"/> vertices. Then<br/>
<img alt="\displaystyle \Pr[X_k \mbox{ is a convex chain}]=\frac {2^k}{k!(k+1)!}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr%5BX_k+%5Cmbox%7B+is+a+convex+chain%7D%5D%3D%5Cfrac+%7B2%5Ek%7D%7Bk%21%28k%2B1%29%21%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Pr[X_k \mbox{ is a convex chain}]=\frac {2^k}{k!(k+1)!}, "/></p>
<p>a surprisingly precise result (due to Pavel Valtr).</p>
<p>For the second theorem let <img alt="{p(n,C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%28n%2CC%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p(n,C)}"/> denote the probability that the random sample <img alt="{X_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_n}"/> (independent and uniform again) lands in convex position, that is, their convex hull is a convex <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-gon. For <img alt="{n=4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=4}"/> this is Sylvester’s famous four point problem from 1864 (although he did not specify the underlying convex body <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>). Then<br/>
<img alt="\displaystyle \lim_{n\rightarrow \infty} n^2\sqrt[n]{p(n,C)}=\frac {e^2}4\frac{A^*(C)}{\sqrt[3]{\textrm{Area} \; C}}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clim_%7Bn%5Crightarrow+%5Cinfty%7D+n%5E2%5Csqrt%5Bn%5D%7Bp%28n%2CC%29%7D%3D%5Cfrac+%7Be%5E2%7D4%5Cfrac%7BA%5E%2A%28C%29%7D%7B%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+C%7D%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \lim_{n\rightarrow \infty} n^2\sqrt[n]{p(n,C)}=\frac {e^2}4\frac{A^*(C)}{\sqrt[3]{\textrm{Area} \; C}}, "/></p>
<p>with the same <img alt="{A^*(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E%2A%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^*(C)}"/> as before. The proof of this theorem uses the previous result of Valtr about convex chains in triangles and the properties of <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>, the largest affine area convex subset of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. The set <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/> appears again: it is the limit shape of <img alt="{\textrm{conv}X_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctextrm%7Bconv%7DX_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\textrm{conv}X_n}"/> under the condition that <img alt="{X_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_n}"/> landed in convex position.</p>
<p>The map <img alt="{C \rightarrow C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%5Crightarrow+C_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C \rightarrow C_0}"/> is affinely equivariant and has interesting properties. <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/> turns out to be the limit shape in some further cases as well. For instance, the maximal number of vertices of the polygons in <img alt="{\mathcal{F}^n(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n(C)}"/> equals</p>
<p><img alt="\displaystyle \frac {3n^{2/3}}{(2\pi)^{2/3}}A^*(C)(1+o(1)), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cfrac+%7B3n%5E%7B2%2F3%7D%7D%7B%282%5Cpi%29%5E%7B2%2F3%7D%7DA%5E%2A%28C%29%281%2Bo%281%29%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \frac {3n^{2/3}}{(2\pi)^{2/3}}A^*(C)(1+o(1)), "/></p>
<p>as <img alt="{n \rightarrow \infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \rightarrow \infty}"/>. This is of course the same as the maximal number of points in <img alt="{{\mathbb{Z}}_n\cap C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%5Ccap+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n\cap C}"/> that are in convex position. Although the convex <img alt="{{\mathbb{Z}}_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb{Z}}_n}"/>-lattice polygon <img alt="{\mathcal{F}^n(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n(C)}"/> with maximal number of vertices is not necessary unique, they have a limit shape which is again <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>. The same happens in <img alt="{\mathcal{G}_n(C)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BG%7D_n%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{G}_n(C)}"/> as well. In this case, however, the expectation of the maximal number of vertices is equal to constant times <img alt="{A^*(C)n^{1/3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E%2A%28C%29n%5E%7B1%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^*(C)n^{1/3}}"/> but the value of this (positive) constant is not known. The reason is the following. In the triangle <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/> with specified vertices <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> and <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/>, and random sample <img alt="{X_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_k}"/> we define <img alt="{L_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_k}"/> as the maximal number of points from <img alt="{X_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_k}"/> that form a convex chain in <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/> from <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a}"/> to <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/>. The random variable <img alt="{L_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_k}"/> is concentrated around its expectation, which is equal to some non-negative constant times <img alt="{k^{1/3}(1+o(1))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%5E%7B1%2F3%7D%281%2Bo%281%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k^{1/3}(1+o(1))}"/> as <img alt="{k \rightarrow \infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k \rightarrow \infty}"/> but this constant is not known. Experiments suggest that it is equal to 3 but there is no proof in sight. Not surprisingly, the limit shape of these maximal convex chains is again the special parabola arc in <img alt="{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Delta}"/>. This question about the random variable <img alt="{L_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_k}"/> is similar to the longest increasing subsequence problem but much less is known about it.</p>
<h2>Open Problem: high dimensions</h2>
<p>What remains of the limit shape phenomenon in higher dimensions? Well, hardly anything has been proved. In the simplest case, let <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> denote the unit cube in 3-space, and let <img alt="{\mathcal{F}^n(Q)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%28Q%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{F}^n(Q)}"/> denote the set of all convex <img alt="{\frac 1n {\mathbb{Z}}^3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac+1n+%7B%5Cmathbb%7BZ%7D%7D%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac 1n {\mathbb{Z}}^3}"/>-lattice polygons contained in <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/>. It is known that <img alt="{\log |\mathcal{F}^n(Q)|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+%7C%5Cmathcal%7BF%7D%5En%28Q%29%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log |\mathcal{F}^n(Q)|}"/> is between <img alt="{c_1n^{1/2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_1n%5E%7B1%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_1n^{1/2}}"/> and <img alt="{c_2 n^{1/2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_2+n%5E%7B1%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_2 n^{1/2}}"/> with <img alt="{0&lt;c_1&lt;c_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%3Cc_1%3Cc_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0&lt;c_1&lt;c_2}"/>, but nothing more precise. Probably there is a limit shape here as well, and it might be the convex subset of <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> that has the largest affine surface area. The existence of such a set follows the same way as above but its uniqueness is not known.</p>
<h2>The affine perimeter</h2>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/affper.png"><img alt="" class="alignnone size-full wp-image-17542" src="https://gilkalai.files.wordpress.com/2019/07/affper.png?w=640"/></a></p>
<p> </p>
<p>Finally a few words about the affine perimeter. Given a convex curve <img alt="{\Gamma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CGamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Gamma}"/> in the plane, choose points <img alt="{x_0,\ldots, x_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%2C%5Cldots%2C+x_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_0,\ldots, x_n}"/> on it, take the tangent lines at these points and form the triangles <img alt="{T_1,\ldots,T_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_1%2C%5Cldots%2CT_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_1,\ldots,T_n}"/> as in the figure. By definition, the affine perimeter <img alt="{AP(\Gamma)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAP%28%5CGamma%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AP(\Gamma)}"/> is the infimum of the sum <img alt="{2\sum_1^n(\textrm{Area} \; T_i)^{1/3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Csum_1%5En%28%5Ctextrm%7BArea%7D+%5C%3B+T_i%29%5E%7B1%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2\sum_1^n(\textrm{Area} \; T_i)^{1/3}}"/> as the subdivision <img alt="{x_0,\ldots,x_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_0%2C%5Cldots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_0,\ldots,x_n}"/> gets finer and finer. The affine perimeter of the unit circle is <img alt="{2\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2\pi}"/> which explains the constant <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> in front of <img alt="{\sum_1^n(\textrm{Area} \; T_i)^{1/3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_1%5En%28%5Ctextrm%7BArea%7D+%5C%3B+T_i%29%5E%7B1%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sum_1^n(\textrm{Area} \; T_i)^{1/3}}"/>. The exponent <img alt="{1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/3}"/> is the right choice here: for larger exponent the sum is zero, and for smaller it is infinity (for the circle for instance). Inequality (2) shows that infimum in the definition can be replaced by limit. The affine perimeter of a convex polygon is zero.</p>
<p>For a twice differentiable curve <img alt="{AP(\Gamma) = \int_{\Gamma}\kappa^{1/3}ds=\int_{\Gamma}r^{-1/3}ds}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAP%28%5CGamma%29+%3D+%5Cint_%7B%5CGamma%7D%5Ckappa%5E%7B1%2F3%7Dds%3D%5Cint_%7B%5CGamma%7Dr%5E%7B-1%2F3%7Dds%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AP(\Gamma) = \int_{\Gamma}\kappa^{1/3}ds=\int_{\Gamma}r^{-1/3}ds}"/> where <img alt="{\kappa}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ckappa%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\kappa}"/> is the curvature and <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> the radius of curvature and <img alt="{ds}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bds%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ds}"/> means integration with arc length. The affine perimeter is an affine invariant or rather equivariant meaning that <img alt="{AP(S(\Gamma))=\sqrt[3]{|\det S|} AP(\Gamma)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAP%28S%28%5CGamma%29%29%3D%5Csqrt%5B3%5D%7B%7C%5Cdet+S%7C%7D+AP%28%5CGamma%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AP(S(\Gamma))=\sqrt[3]{|\det S|} AP(\Gamma)}"/> for a non-degenerate affine transformation <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. Quite often the affine perimeter (and the affine surface area) appears in connection with affine equivariant properties of the convex set <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. One example is best approximation by inscribed polygons <img alt="{P_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_n}"/> on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> vertices. When approximation is measured by <img alt="{\textrm{Area}\;(C\backslash P_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctextrm%7BArea%7D%5C%3B%28C%5Cbackslash+P_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\textrm{Area}\;(C\backslash P_n)}"/> then the best approximating polygon <img alt="{P_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_n}"/> satisfies the estimate<br/>
<img alt="\displaystyle \textrm{Area} \; (C\backslash P_n)= \frac 1{4\sqrt 3} \frac {AP(C)^3}{n^2}(1+o(1)). \ \ \ \ \ (3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Ctextrm%7BArea%7D+%5C%3B+%28C%5Cbackslash+P_n%29%3D+%5Cfrac+1%7B4%5Csqrt+3%7D+%5Cfrac+%7BAP%28C%29%5E3%7D%7Bn%5E2%7D%281%2Bo%281%29%29.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \textrm{Area} \; (C\backslash P_n)= \frac 1{4\sqrt 3} \frac {AP(C)^3}{n^2}(1+o(1)). \ \ \ \ \ (3)"/></p>
<p>The set <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/>, the convex subset of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> with maximal affine perimeter has interesting properties. For instance its boundary contains no line segment, and if some piece of its boundary lies in the interior of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>, then this piece is a parabola arc. It has positive curvature everywhere. It is of course affinely equivariant meaning that <img alt="{S(C_0)= S(C)_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%28C_0%29%3D+S%28C%29_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S(C_0)= S(C)_0}"/>. According to (3) <img alt="{C_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_0}"/> has the worst approximation properties among all convex subsets of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{C}"/>.  This might explain why it comes up as the limit shape so often. Actually, the high dimensional analogue of (3) suggests that the limit shape in higher dimensions is again connected to the maximal affine surface area subset of the underlying convex body.</p></div>
    </content>
    <updated>2019-07-09T08:35:29Z</updated>
    <published>2019-07-09T08:35:29Z</published>
    <category term="Combinatorics"/>
    <category term="Convexity"/>
    <category term="Geometry"/>
    <category term="Guest blogger"/>
    <category term="Probability"/>
    <category term="Imre Barany"/>
    <category term="limit shape"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-09T13:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.03620</id>
    <link href="http://arxiv.org/abs/1907.03620" rel="alternate" type="text/html"/>
    <title>Contraction Clustering (RASTER): A Very Fast Big Data Algorithm for Sequential and Parallel Density-Based Clustering in Linear Time, Constant Memory, and a Single Pass</title>
    <feedworld_mtime>1562630400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Ulm:Gregor.html">Gregor Ulm</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Smith:Simon.html">Simon Smith</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nilsson:Adrian.html">Adrian Nilsson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gustavsson:Emil.html">Emil Gustavsson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jirstrand:Mats.html">Mats Jirstrand</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.03620">PDF</a><br/><b>Abstract: </b>Clustering is an essential data mining tool for analyzing and grouping
similar objects. In big data applications, however, many clustering algorithms
are infeasible due to their high memory requirements and/or unfavorable runtime
complexity. In contrast, Contraction Clustering (RASTER) is a single-pass
algorithm for identifying density-based clusters with linear time complexity.
Due to its favorable runtime and the fact that its memory requirements are
constant, this algorithm is highly suitable for big data applications where the
amount of data to be processed is huge. It consists of two steps: (1) a
contraction step which projects objects onto tiles and (2) an agglomeration
step which groups tiles into clusters. This algorithm is extremely fast in both
sequential and parallel execution. In single-threaded execution on a
contemporary workstation, an implementation in Rust processes a batch of 500
million points with 1 million clusters in less than 50 seconds. The speedup due
to parallelization is significant, amounting to a factor of around 4 on an
8-core machine.
</p></div>
    </summary>
    <updated>2019-07-09T01:29:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.03535</id>
    <link href="http://arxiv.org/abs/1907.03535" rel="alternate" type="text/html"/>
    <title>More Hierarchy in Route Planning Using Edge Hierarchies</title>
    <feedworld_mtime>1562630400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hespe:Demian.html">Demian Hespe</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sanders:Peter.html">Peter Sanders</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.03535">PDF</a><br/><b>Abstract: </b>A highly successful approach to route planning in networks (particularly road
networks) is to identify a hierarchy in the network that allows faster queries
after some preprocessing that basically inserts additional "shortcut"-edges
into a graph. In the past there has been a succession of techniques that infer
a more and more fine grained hierarchy enabling increasingly more efficient
queries. This appeared to culminate in contraction hierarchies that assign one
hierarchy level to each vertex. In this paper we show how to identify an even
more fine grained hierarchy that assigns one level to each edge of the network.
Our findings indicate that this can lead to considerably smaller search spaces
in terms of visited edges. Currently, this does not result in improved query
times so that it remains an open question whether these edge hierarchies can
lead to overall improved performance. However, we believe that the technique as
such is a noteworthy enrichment of the portfolio of available techniques that
might prove useful in the future.
</p></div>
    </summary>
    <updated>2019-07-09T01:32:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.03533</id>
    <link href="http://arxiv.org/abs/1907.03533" rel="alternate" type="text/html"/>
    <title>A Formal Axiomatization of Computation</title>
    <feedworld_mtime>1562630400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramezanian:Rasoul.html">Rasoul Ramezanian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.03533">PDF</a><br/><b>Abstract: </b>We introduce a set of axioms for the notion of computation, and show that P=
NP is not derivable from this set of axioms.
</p></div>
    </summary>
    <updated>2019-07-09T01:20:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.03526</id>
    <link href="http://arxiv.org/abs/1907.03526" rel="alternate" type="text/html"/>
    <title>Inapproximability Results for Scheduling with Interval and Resource Restrictions</title>
    <feedworld_mtime>1562630400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maack:Marten.html">Marten Maack</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jansen:Klaus.html">Klaus Jansen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.03526">PDF</a><br/><b>Abstract: </b>In the restricted assignment problem, the input consists of a set of machines
and a set of jobs each with a processing time and a subset of eligible
machines. The goal is to find an assignment of the jobs to the machines
minimizing the makespan, that is, the maximum summed up processing time any
machine receives. Herein, jobs should only be assigned to those machines on
which they are eligible. It is well-known that there is no polynomial time
approximation algorithm with an approximation guarantee of less than 1.5 for
the restricted assignment problem unless P=NP. In this work, we show hardness
results for variants of the restricted assignment problem with particular types
of restrictions.
</p>
<p>In the case of interval restrictions the machines can be totally ordered such
that jobs are eligible on consecutive machines. We resolve the open question of
whether the problem admits a polynomial time approximation scheme (PTAS) in the
negative (unless P=NP). There are several special cases of this problem known
to admit a PTAS.
</p>
<p>Furthermore, we consider a variant with resource restriction where each
machine has capacities and each job demands for a fixed number of resources. A
job is eligible on a machine if its demand is at most the capacity of the
machine for each resource. For one resource, this problem is known to admit a
PTAS, for two, the case of interval restrictions is contained, and in general,
the problem is closely related to unrelated scheduling with a low rank
processing time matrix. We show that there is no polynomial time approximation
algorithm with a rate smaller than 48/47 or 1.5 for scheduling with resource
restrictions with 2 or 4 resources, respectively, unless P=NP. All our results
can be extended to the so called Santa Claus variants of the problems where the
goal is to maximize the minimal processing time any machine receives.
</p></div>
    </summary>
    <updated>2019-07-09T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.03437</id>
    <link href="http://arxiv.org/abs/1907.03437" rel="alternate" type="text/html"/>
    <title>Fair Byzantine Agreements for Blockchains</title>
    <feedworld_mtime>1562630400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chao:Tzu=Wei.html">Tzu-Wei Chao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chung:Hao.html">Hao Chung</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuo:Po=Chun.html">Po-Chun Kuo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.03437">PDF</a><br/><b>Abstract: </b>Byzantine general problem is the core problem of the consensus algorithm, and
many protocols are proposed recently to improve the decentralization level, the
performance and the security of the blockchain. There are two challenging
issues when the blockchain is operating in practice. First, the outcomes of the
consensus algorithm are usually related to the incentive model, so whether each
participant's value has an equal probability of being chosen becomes essential.
However, the issues of fairness are not captured in the traditional security
definition of Byzantine agreement. Second, the blockchain should be resistant
to network failures, such as cloud services shut down or malicious attack,
while remains the high performance most of the time.
</p>
<p>This paper has two main contributions. First, we propose a novel notion
called fair validity for Byzantine agreement. Intuitively, fair validity
lower-bounds the expected numbers that honest nodes' values being decided if
the protocol is executed many times. However, we also show that any Byzantine
agreement could not achieve fair validity in an asynchronous network, so we
focus on synchronous protocols. This leads to our second contribution: we
propose a fair, responsive and partition-resilient Byzantine agreement protocol
tolerating up to 1/3 corruptions. Fairness means that our protocol achieves
fair validity. Responsiveness means that the termination time only depends on
the actual network delay instead of depending on any pre-determined time bound.
Partition-resilience means that the safety still holds even if the network is
partitioned, and the termination will hold if the partition is resolved.
</p></div>
    </summary>
    <updated>2019-07-09T01:32:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.03266</id>
    <link href="http://arxiv.org/abs/1907.03266" rel="alternate" type="text/html"/>
    <title>Complexity of planar signed graph homomorphisms to cycles</title>
    <feedworld_mtime>1562630400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dross:Fran=ccedil=ois.html">François Dross</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Foucaud:Florent.html">Florent Foucaud</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitsou:Valia.html">Valia Mitsou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pierron:Th=eacute=o.html">Théo Pierron</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ochem:Pascal.html">Pascal Ochem</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.03266">PDF</a><br/><b>Abstract: </b>We study homomorphism problems of signed graphs. A signed graph is an
undirected graph where each edge is given a sign, positive or negative. An
important concept for signed graphs is the operation of switching at a vertex,
which is to change the sign of each incident edge. A homomorphism of a graph is
a vertex-mapping that preserves the adjacencies; in the case of signed graphs,
we also preserve the edge-signs. Special homomorphisms of signed graphs, called
s-homomorphisms, have been studied. In an s-homomorphism, we allow, before the
mapping, to perform any number of switchings on the source signed graph. This
concept has been extensively studied, and a full complexity classification
(polynomial or NP-complete) for s-homomorphism to a fixed target signed graph
has recently been obtained. Such a dichotomy is not known when we restrict the
input graph to be planar (not even for non-signed graph homomorphisms).
</p>
<p>We show that deciding whether a (non-signed) planar graph admits a
homomorphism to the square $C_t^2$ of a cycle with $t\ge 6$, or to the circular
clique $K_{4t/(2t-1)}$ with $t\ge2$, are NP-complete problems. We use these
results to show that deciding whether a planar signed graph admits an
s-homomorphism to an unbalanced even cycle is NP-complete. (A cycle is
unbalanced if it has an odd number of negative edges). We deduce a complete
complexity dichotomy for the planar s-homomorphism problem with any signed
cycle as a target.
</p>
<p>We also study further restrictions involving the maximum degree and the girth
of the input signed graph. We prove that planar s-homomorphism problems to
signed cycles remain NP-complete even for inputs of maximum degree~$3$ (except
for the case of unbalanced $4$-cycles, for which we show this for maximum
degree~$4$). We also show that for a given integer $g$, the problem for signed
bipartite planar inputs of girth $g$ is either trivial or NP-complete.
</p></div>
    </summary>
    <updated>2019-07-09T01:31:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.03235</id>
    <link href="http://arxiv.org/abs/1907.03235" rel="alternate" type="text/html"/>
    <title>Bidirectional Text Compression in External Memory</title>
    <feedworld_mtime>1562630400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dinklage:Patrick.html">Patrick Dinklage</a>, Jonas Ellert, Jonas Ellert, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fischer:Johannes.html">Johannes Fischer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/K=ouml=ppl:Dominik.html">Dominik Köppl</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Penschuck:Manuel.html">Manuel Penschuck</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.03235">PDF</a><br/><b>Abstract: </b>Bidirectional compression algorithms work by substituting repeated substrings
by references that, unlike in the famous LZ77-scheme, can point to either
direction. We present such an algorithm that is particularly suited for an
external memory implementation. We evaluate it experimentally on large data
sets of size up to 128 GiB (using only 16 GiB of RAM) and show that it is
significantly faster than all known LZ77 compressors, while producing a roughly
similar number of factors. We also introduce an external memory decompressor
for texts compressed with any uni- or bidirectional compression scheme.
</p></div>
    </summary>
    <updated>2019-07-09T01:29:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.03205</id>
    <link href="http://arxiv.org/abs/1907.03205" rel="alternate" type="text/html"/>
    <title>Oracle Separations Between Quantum and Non-interactive Zero-Knowledge Classes</title>
    <feedworld_mtime>1562630400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Benjamin Morrison, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Groce:Adam.html">Adam Groce</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.03205">PDF</a><br/><b>Abstract: </b>We study the relationship between problems solvable by quantum algorithms in
polynomial time and those for which zero-knowledge proofs exist. In prior work,
Aaronson [arxiv:<a href="http://export.arxiv.org/abs/quant-ph/0111102">quant-ph/0111102</a>] showed an oracle separation between BQP and
SZK, i.e. an oracle $A$ such that $\mathrm{SZK}^A \not\subseteq
\mathrm{BQP}^A$. In this paper we give a simple extension of Aaronson's result
to non-interactive zero-knowledge proofs with perfect security. This class,
NIPZK, is the most restrictive zero-knowledge class. We show that even for this
class we can construct an $A$ with $\mathrm{NIPZK}^A \not\subseteq
\mathrm{BQP}^A$.
</p></div>
    </summary>
    <updated>2019-07-09T01:23:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.03201</id>
    <link href="http://arxiv.org/abs/1907.03201" rel="alternate" type="text/html"/>
    <title>A Randomized Algorithm for Edge-Colouring Graphs in $O(m\sqrt{n})$ Time</title>
    <feedworld_mtime>1562630400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sinnamon:Corwin.html">Corwin Sinnamon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.03201">PDF</a><br/><b>Abstract: </b>We present a simple randomized algorithm to edge-colour arbitrary simple
graphs based on the classic decomposition strategy of Gabow et al. The
algorithm uses $d+1$ colours and runs in $O(m \sqrt n)$ time with high
probability.
</p></div>
    </summary>
    <updated>2019-07-09T01:32:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.03197</id>
    <link href="http://arxiv.org/abs/1907.03197" rel="alternate" type="text/html"/>
    <title>Composable Core-sets for Determinant Maximization: A Simple Near-Optimal Algorithm</title>
    <feedworld_mtime>1562630400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Indyk:Piotr.html">Piotr Indyk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahabadi:Sepideh.html">Sepideh Mahabadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gharan:Shayan_Oveis.html">Shayan Oveis Gharan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rezaei:Alireza.html">Alireza Rezaei</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.03197">PDF</a><br/><b>Abstract: </b>``Composable core-sets'' are an efficient framework for solving optimization
problems in massive data models. In this work, we consider efficient
construction of composable core-sets for the determinant maximization problem.
This can also be cast as the MAP inference task for determinantal point
processes, that have recently gained a lot of interest for modeling diversity
and fairness. The problem was recently studied in [IMOR'18], where they
designed composable core-sets with the optimal approximation bound of $\tilde
O(k)^k$. On the other hand, the more practical Greedy algorithm has been
previously used in similar contexts. In this work, first we provide a
theoretical approximation guarantee of $O(C^{k^2})$ for the Greedy algorithm in
the context of composable core-sets; Further, we propose to use a Local Search
based algorithm that while being still practical, achieves a nearly optimal
approximation bound of $O(k)^{2k}$; Finally, we implement all three algorithms
and show the effectiveness of our proposed algorithm on standard data sets.
</p></div>
    </summary>
    <updated>2019-07-09T01:23:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.03190</id>
    <link href="http://arxiv.org/abs/1907.03190" rel="alternate" type="text/html"/>
    <title>Testing Mixtures of Discrete Distributions</title>
    <feedworld_mtime>1562630400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aliakbarpour:Maryam.html">Maryam Aliakbarpour</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Ravi.html">Ravi Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rubinfeld:Ronitt.html">Ronitt Rubinfeld</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.03190">PDF</a><br/><b>Abstract: </b>There has been significant study on the sample complexity of testing
properties of distributions over large domains. For many properties, it is
known that the sample complexity can be substantially smaller than the domain
size. For example, over a domain of size $n$, distinguishing the uniform
distribution from distributions that are far from uniform in $\ell_1$-distance
uses only $O(\sqrt{n})$ samples.
</p>
<p>However, the picture is very different in the presence of arbitrary noise,
even when the amount of noise is quite small. In this case, one must
distinguish if samples are coming from a distribution that is $\epsilon$-close
to uniform from the case where the distribution is $(1-\epsilon)$-far from
uniform. The latter task requires nearly linear in $n$ samples [Valiant 2008,
Valian and Valiant 2011].
</p>
<p>In this work, we present a noise model that on one hand is more tractable for
the testing problem, and on the other hand represents a rich class of noise
families. In our model, the noisy distribution is a mixture of the original
distribution and noise, where the latter is known to the tester either
explicitly or via sample access; the form of the noise is also known a priori.
Focusing on the identity and closeness testing problems leads to the following
mixture testing question: Given samples of distributions $p, q_1,q_2$, can we
test if $p$ is a mixture of $q_1$ and $q_2$? We consider this general question
in various scenarios that differ in terms of how the tester can access the
distributions, and show that indeed this problem is more tractable. Our results
show that the sample complexity of our testers are exactly the same as for the
classical non-mixture case.
</p></div>
    </summary>
    <updated>2019-07-09T01:25:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.03182</id>
    <link href="http://arxiv.org/abs/1907.03182" rel="alternate" type="text/html"/>
    <title>Towards Testing Monotonicity of Distributions Over General Posets</title>
    <feedworld_mtime>1562630400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aliakbarpour:Maryam.html">Maryam Aliakbarpour</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gouleakis:Themis.html">Themis Gouleakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peebles:John.html">John Peebles</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rubinfeld:Ronitt.html">Ronitt Rubinfeld</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yodpinyanee:Anak.html">Anak Yodpinyanee</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.03182">PDF</a><br/><b>Abstract: </b>In this work, we consider the sample complexity required for testing the
monotonicity of distributions over partial orders. A distribution $p$ over a
poset is monotone if, for any pair of domain elements $x$ and $y$ such that $x
\preceq y$, $p(x) \leq p(y)$. To understand the sample complexity of this
problem, we introduce a new property called bigness over a finite domain, where
the distribution is $T$-big if the minimum probability for any domain element
is at least $T$. We establish a lower bound of $\Omega(n/\log n)$ for testing
bigness of distributions on domains of size $n$. We then build on these lower
bounds to give $\Omega(n/\log{n})$ lower bounds for testing monotonicity over a
matching poset of size $n$ and significantly improved lower bounds over the
hypercube poset. We give sublinear sample complexity bounds for testing bigness
and for testing monotonicity over the matching poset.
</p>
<p>We then give a number of tools for analyzing upper bounds on the sample
complexity of
</p>
<p>the monotonicity testing problem.
</p></div>
    </summary>
    <updated>2019-07-09T01:30:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.03129</id>
    <link href="http://arxiv.org/abs/1907.03129" rel="alternate" type="text/html"/>
    <title>Constant-Factor Approximation Algorithms for Parity-Constrained Facility Location Problems</title>
    <feedworld_mtime>1562630400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kim:Kangsan.html">Kangsan Kim</a>, Yongho Shin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/An:Hyung=Chan.html">Hyung-Chan An</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.03129">PDF</a><br/><b>Abstract: </b>Facility location is a prominent optimization problem that has inspired a
large quantity of both theoretical and practical studies in combinatorial
optimization. Although the problem has been investigated under various settings
reflecting typical structures within the optimization problems of practical
interest, little is known on how the problem behaves in conjunction with parity
constraints. This shortfall of understanding was rather disturbing when we
consider the central role of parity in the field of combinatorics. In this
paper, we present the first constant-factor approximation algorithm for the
facility location problem with parity constraints. We are given as the input a
metric on a set of facilities and clients, the opening cost of each facility,
and the parity requirement--odd, even, or unconstrained--of every facility in
this problem. The objective is to open a subset of facilities and assign every
client to an open facility so as to minimize the sum of the total opening costs
and the assignment distances, but subject to the condition that the number of
clients assigned to each open facility must have the same parity as its
requirement.
</p>
<p>Although the unconstrained facility location problem as a relaxation for this
parity-constrained generalization has unbounded gap, we demonstrate that it
yields a structured solution whose parity violation can be corrected at small
cost. This correction is prescribed by a T-join on an auxiliary graph
constructed by the algorithm. This graph does not satisfy the triangle
inequality, but we show that a carefully chosen set of shortcutting operations
leads to a cheap and sparse T-join. Finally, we bound the correction cost by
exhibiting a combinatorial multi-step construction of an upper bound. We also
present the first constant-factor approximation algorithm for the
parity-constrained k-center problem, the bottleneck optimization variant.
</p></div>
    </summary>
    <updated>2019-07-09T01:32:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.03037</id>
    <link href="http://arxiv.org/abs/1907.03037" rel="alternate" type="text/html"/>
    <title>Near-Optimal Fully Dynamic Densest Subgraph</title>
    <feedworld_mtime>1562630400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sawlani:Saurabh.html">Saurabh Sawlani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Junxing.html">Junxing Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.03037">PDF</a><br/><b>Abstract: </b>We give the first fully dynamic algorithm which maintains a
$(1+\epsilon)$-approximate densest subgraph in worst-case time
$\text{poly}(\log n, \epsilon^{-1})$ per update with high probability. Dense
subgraph discovery is an important primitive for many real-world applications
such as community detection, link spam detection, distance query indexing, and
computational biology. Our result improves upon the previous best approximation
factor of $(4+\epsilon)$ for fully dynamic densest subgraph obtained by
[Bhattacharya-Henzinger-Nanongkai-Tsourakakis, STOC`15]. Our algorithm combines
the uniform sparsification technique used in
[Mitzenmacher-Pachocki-Peng-Tsourakakis-Xu, KDD`15] and
[McGregor-Tench-Vorotnikova-Vu, MFCS`15] along with an augmenting path-like
dual adjustment technique to maintain an approximate solution efficiently.
</p></div>
    </summary>
    <updated>2019-07-09T01:30:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8041836663315088806</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8041836663315088806/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/fortran-is-underated.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8041836663315088806" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8041836663315088806" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/fortran-is-underated.html" rel="alternate" type="text/html"/>
    <title>Fortran is underated!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">(Joint Post with David Marcus who was a classmate of mine at SUNY Stony Brook [now called Stony Brook University]. I was class of 1980, he was class of 1979. We were both math majors.)<br/>
<br/>
David has been reading <a href="https://www.amazon.com/Problems-Point-Exploring-Computer-Science/dp/9813279974">Problems with a POINT</a> (I'm glad someone is reading it) and emailed me a comment on the following passage which was essentially <a href="https://blog.computationalcomplexity.org/2012/02/dusting-off-my-bookshelf-i-find-book-on.html">this post</a>. I paraphrase what I wrote:<br/>
<br/>
PASSAGE IN BOOK:<br/>
I dusted off my book shelves and found a book on Fortran. On the back it said:<br/>
<br/>
FORTRAN is one of the oldest high-level languages and remains the premier language for writing code for science and engineering applications. (NOTE- The back of the book uses Fortran but the spell checker I am using insists on FORTRAN. As a fan of capital letters, I don't mind going along.)<br/>
<br/>
When was the book written?<br/>
<br/>
The answer was surprising in that it was 2012 (the Chapter title was <i>Trick Question or Stupid Question</i>. This was a Trick Question.) I would have thought that FORTRAN was no longer the premier language by then. I also need to dust my bookshelves more often.<br/>
END OF PASSAGE IN BOOK<br/>
<br/>
David Marcus emailed me the following:<br/>
<br/>
DAVID'S EMAIL<br/>
Page 201. Fortran. One clue is that it said "Fortran" rather than"FORTRAN". Fortran 90 changed the name from all upper case. Whether it is the "premier language" depends on what you mean by "premier". It is probably the best language for scientific computing. I used it pretty much exclusively (by choice) in my previous job that I left in 2006. The handling of arrays is better than any other language I've used. Maybe there are some better languages that I'm not familiar with, but the huge number of high-quality scientific libraries available for Fortran makes it hard to beat. On the other hand, I never wrote a GUI app with it (Delphi is best for that).<br/>
END OF DAVID'S EMAIL<br/>
<br/>
In later emails we agreed that Fortran is not used that much (there are lists of most-used languages and neither Fortran nor FORTRAN is ever in the top 10).  But what intrigued me was the following contrast:<br/>
<br/>
1) David says that its the BEST language for Scientific Computing.  I will assume he is right.<br/>
<br/>
2) I doubt much NEW code is being written in it.  I will assume I am right.<br/>
<br/>
So---what's up with that? Some options<br/>
<br/>
OPTION 1) People SHOULD use Fortran but DON'T. If so, why is that?  Fortran is not taught in schools. People are used to what they already know.  Perhaps people who do pick up new things easily and want to use new things would rather use NEW things rather than NEW-TO-THEM-BUT-NOT-TO-THEIR-GRANDMOTHER things. Could be a coolness factor.  Do the advantages of Fortran outweight the disadvantages?  Is what they are using good enough?<br/>
<br/>
OPTION 2) The amount of Scientific computing software being written is small since we already have these great Fortran packages. So it may be a victim of its own success.<br/>
<br/>
CAVEAT: When I emailed David a first draft of the post he pointed out the following which has to do with the lists of most-used programming languages:<br/>
<br/>
DAVIDS EMAIL:<br/>
The problem with the lists you were looking at is that most people in the world are not scientists, so most software being written is not for scientists. Scientists and technical people are writing lots of new code.  If you look at a list of scientific languages, you will see Fortran, e.g., <a href="https://en.wikipedia.org/wiki/Scientific_programming_language">here</a> and <a href="https://en.wikipedia.org/wiki/Fortran#Science_and_engineering">here</a>.<br/>
<br/>
<br/>
There are several Fortran compilers available. One of the best was bought by Intel some time back and they still sell it. I doubt they would do that if no one was using it. Actually, I think Intel had a compiler, but bought the Compaq compiler (which used to be the Digital Equipment compiler) and merged the Compaq team with their team. Something like that. I was using the Compaq compiler around that time.<br/>
END OF DAVID's EMAIL<br/>
<br/>
One quote from the second pointer I find intriguing.  (Second use of the word <i>intriguing</i>. It was my word-of-the-day on my word-calendar).<br/>
<br/>
<i>... facilities for inter-operation with C were added to Fortran 2003 and enhanced by ISO/ICE technical specification 29113, which will be incorporated into Fortran 2018. </i><br/>
<br/>
I (Bill) don't know what some of that means; however, it does mean that Fortran is still active.<br/>
<br/>
<br/>
One fear: with its not being taught that much, will knowledge of it die out.  We be like Star Trek aliens:<br/>
<br/>
<i>The old ones built these machines, but then died and we can't fix them!<br/>
<br/>
<br/>
<br/>
</i></div>
    </content>
    <updated>2019-07-08T03:55:00Z</updated>
    <published>2019-07-08T03:55:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-09T11:06:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02929</id>
    <link href="http://arxiv.org/abs/1907.02929" rel="alternate" type="text/html"/>
    <title>Improved local search for graph edit distance</title>
    <feedworld_mtime>1562544000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Boria:Nicolas.html">Nicolas Boria</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blumenthal:David_B=.html">David B. Blumenthal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bougleux:S=eacute=bastien.html">Sébastien Bougleux</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brun:Luc.html">Luc Brun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02929">PDF</a><br/><b>Abstract: </b>Graph Edit Distance (GED) measures the dissimilarity between two graphs as
the minimal cost of a sequence of elementary operations transforming one graph
into another. This measure is fundamental in many areas such as structural
pattern recognition or classification. However, exactly computing GED is
NP-hard. Among different classes of heuristic algorithms that were proposed to
compute approximate solutions, local search based algorithms provide the
tightest upper bounds for GED. In this paper, we present K-REFINE and RANDPOST.
K-REFINE generalizes and improves an existing local search algorithm and
performs particularly well on small graphs. RANDPOST is a general warm start
framework that stochastically generates promising initial solutions to be used
by any local search based GED algorithm. It is particularly efficient on large
graphs. An extensive empirical evaluation demonstrates that both K-REFINE and
RANDPOST perform excellently in practice.
</p></div>
    </summary>
    <updated>2019-07-08T23:23:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02919</id>
    <link href="http://arxiv.org/abs/1907.02919" rel="alternate" type="text/html"/>
    <title>Hitting Topological Minor Models in Planar Graphs is Fixed Parameter Tractable</title>
    <feedworld_mtime>1562544000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Golovach:Petr_A=.html">Petr A. Golovach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stamoulis:Giannos.html">Giannos Stamoulis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thilikos:Dimitrios_M=.html">Dimitrios M. Thilikos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02919">PDF</a><br/><b>Abstract: </b>For a finite collection of graphs ${\cal F}$, the ${\cal F}$-TM-Deletion
problem has as input an $n$-vertex graph $G$ and an integer $k$ and asks
whether there exists a set $S \subseteq V(G)$ with $|S| \leq k$ such that $G
\setminus S$ does not contain any of the graphs in ${\cal F}$ as a topological
minor. We prove that for every such ${\cal F}$, ${\cal F}$-TM-Deletion is fixed
parameter tractable on planar graphs. In particular, we provide an $f(h,k)\cdot
n^{2}$ algorithm where $h$ is an upper bound to the vertices of the graphs in
${\cal F}$.
</p></div>
    </summary>
    <updated>2019-07-08T23:24:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02916</id>
    <link href="http://arxiv.org/abs/1907.02916" rel="alternate" type="text/html"/>
    <title>Nonuniform Families of Polynomial-Size Quantum Finite Automata and Quantum Logarithmic-Space Computation with Polynomial-Size Advice</title>
    <feedworld_mtime>1562544000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yamakami:Tomoyuki.html">Tomoyuki Yamakami</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02916">PDF</a><br/><b>Abstract: </b>The state complexity of a finite(-state) automaton intuitively measures the
size of the description of the automaton. Sakoda and Sipser [STOC 1972, pp.
275-286] were concerned with nonuniform families of finite automata and they
discussed the behaviors of nonuniform complexity classes defined by families of
such finite automata having polynomial-size state complexity. In a similar
fashion, we introduce nonuniform state complexity classes using families of
quantum finite automata. Our primarily concern is one-way quantum finite
automata empowered by garbage tapes. We show inclusion and separation
relationships among nonuniform state complexity classes of various one-way
finite automata, including deterministic, nondeterministic, probabilistic, and
quantum finite automata of polynomial size. For two-way quantum finite automata
equipped with garbage tapes, we discover a close relationship between the
nonuniform state complexity of such a polynomial-size quantum finite automata
family and the parameterized complexity class induced by quantum
logarithmic-space computation assisted by polynomial-size advice.
</p></div>
    </summary>
    <updated>2019-07-08T23:20:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02900</id>
    <link href="http://arxiv.org/abs/1907.02900" rel="alternate" type="text/html"/>
    <title>HashGraph -- Scalable Hash Tables Using A Sparse Graph Data Structure</title>
    <feedworld_mtime>1562544000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Green:Oded.html">Oded Green</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02900">PDF</a><br/><b>Abstract: </b>Hash tables are ubiquitous and used in a wide range of applications for
efficient probing of large and unsorted data. If designed properly, hash-tables
can enable efficients look ups in a constant number of operations or commonly
referred to as O(1) operations. As data sizes continue to grow and data becomes
less structured (as is common for big-data applications), the need for
efficient and scalable hash table also grows. In this paper we introduce
HashGraph, a new scalable approach for building hash tables that uses concepts
taken from sparse graph representations--hence the name HashGraph. We show two
different variants of HashGraph, a simple algorithm that outlines the method to
create the hash-table and an advanced method that creates the hash table in a
more efficient manner (with an improved memory access pattern). HashGraph shows
a new way to deal with hash-collisions that does not use "open-addressing" or
"chaining", yet has all the benefits of both these approaches. HashGraph
currently works for static inputs, though recent progress with dynamic graph
data structures suggest that HashGraph might be extended to dynamic inputs as
well. We show that HashGraph can deal with a large number of hash-values per
entry without loss of performance as most open-addressing and chaining
approaches have. Further, we show that HashGraph is indifferent to the
load-factor. Lastly, we show a new probing algorithm for the second phase of
value lookups. Given the above, HashGraph is extremely fast and outperforms
several state of the art hash-table implementations. The implementation of
HashGraph in this paper is for NVIDIA GPUs, though HashGraph is not
architecture dependent. Using a NVIDIA GV100 GPU, HashGraph is anywhere from
2X-8X faster than cuDPP, WarpDrive, and cuDF. HashGraph is able to build a
hash-table at a rate of 2.5 billion keys per second and can probe at nearly the
same rate.
</p></div>
    </summary>
    <updated>2019-07-08T23:24:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02892</id>
    <link href="http://arxiv.org/abs/1907.02892" rel="alternate" type="text/html"/>
    <title>Identifiability of Graphs with Small Color Classes by the Weisfeiler-Leman Algorithm</title>
    <feedworld_mtime>1562544000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fuhlbr=uuml=ck:Frank.html">Frank Fuhlbrück</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/K=ouml=bler:Johannes.html">Johannes Köbler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Verbitsky:Oleg.html">Oleg Verbitsky</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02892">PDF</a><br/><b>Abstract: </b>As it is well known, the isomorphism problem for vertex-colored graphs with
color multiplicity at most 3 is solvable by the classical 2-dimensional
Weisfeiler-Leman algorithm (2-WL). On the other hand, the prominent
Cai-F\"urer-Immerman construction shows that even the multidimensional version
of the algorithm does not suffice for graphs with color multiplicity 4. We give
an efficient decision procedure that, given a graph $G$ of color multiplicity
4, recognizes whether or not $G$ is identifiable by 2-WL, that is, whether or
not 2-WL distinguishes $G$ from any non-isomorphic graph. In fact, we solve the
much more general problem of recognizing whether or not a given coherent
configuration of maximum fiber size 4 is separable. This extends our
recognition algorithm to graphs of color multiplicity 4 with directed and
colored edges.
</p>
<p>Our decision procedure is based on an explicit description of the class of
graphs with color multiplicity 4 that are not identifiable by 2-WL. The
Cai-F\"urer-Immerman graphs of color multiplicity 4 appear here as a natural
subclass, which demonstrates that the Cai-F\"urer-Immerman construction is not
ad hoc. Our classification reveals also other types of graphs that are hard for
2-WL. One of them arises from patterns known as $(n_3)$-configurations in
incidence geometry.
</p></div>
    </summary>
    <updated>2019-07-08T23:22:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02686</id>
    <link href="http://arxiv.org/abs/1907.02686" rel="alternate" type="text/html"/>
    <title>Optimization of Quantum Circuit Mapping using Gate Transformation and Commutation</title>
    <feedworld_mtime>1562544000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Itoko:Toshinari.html">Toshinari Itoko</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raymond:Rudy.html">Rudy Raymond</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Imamichi:Takashi.html">Takashi Imamichi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Matsuo:Atsushi.html">Atsushi Matsuo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02686">PDF</a><br/><b>Abstract: </b>This paper addresses quantum circuit mapping for Noisy Intermediate-Scale
Quantum (NISQ) computers. Since NISQ computers constraint two-qubit operations
on limited couplings, an input circuit must be transformed into an equivalent
output circuit obeying the constraints. The transformation often requires
additional gates that can affect the accuracy of running the circuit. Based
upon a previous work of quantum circuit mapping that leverages gate commutation
rules, this paper shows algorithms that utilize both transformation and
commutation rules. Experiments on a standard benchmark dataset confirm the
algorithms with more rules can find even better circuit mappings compared with
the previously-known best algorithms.
</p></div>
    </summary>
    <updated>2019-07-08T23:23:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.02539</id>
    <link href="http://arxiv.org/abs/1907.02539" rel="alternate" type="text/html"/>
    <title>Vector Colorings of Random, Ramanujan, and Large-Girth Irregular Graphs</title>
    <feedworld_mtime>1562544000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Banks:Jess.html">Jess Banks</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Trevisan:Luca.html">Luca Trevisan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.02539">PDF</a><br/><b>Abstract: </b>We prove that in sparse Erd\H{o}s-R\'{e}nyi graphs of average degree $d$, the
vector chromatic number (the relaxation of chromatic number coming from the
Lov\`{a}sz theta function) is typically $\tfrac{1}{2}\sqrt{d} + o_d(1)$. This
fits with a long-standing conjecture that various refutation and
hypothesis-testing problems concerning $k$-colorings of sparse
Erd\H{o}s-R\'{e}nyi graphs become computationally intractable below the
`Kesten-Stigum threshold' $d_{KS,k} = (k-1)^2$. Along the way, we use the
celebrated Ihara-Bass identity and a carefully constructed non-backtracking
random walk to prove two deterministic results of independent interest: a lower
bound on the vector chromatic number (and thus the chromatic number) using the
spectrum of the non-backtracking walk matrix, and an upper bound dependent only
on the girth and universal cover. Our upper bound may be equivalently viewed as
a generalization of the Alon-Boppana theorem to irregular graphs
</p></div>
    </summary>
    <updated>2019-07-08T23:21:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-08T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/091</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/091" rel="alternate" type="text/html"/>
    <title>TR19-091 |  A Sublinear-space and Polynomial-time Separator Algorithm for Planar Graphs | 

	Ryo Ashida, 

	Tatsuya Imai, 

	Kotaro Nakagawa, 

	A.  Pavan, 

	Vinodchandran Variyam, 

	Osamu Watanabe</title>
    <summary>In [12] (CCC 2013), the authors presented an algorithm for the reachability problem over directed planar graphs that runs in polynomial-time and uses $O(n^{1/2+\epsilon})$ space. A critical ingredient  of their algorithm is a polynomial-time, $\tldO(\sqrt{n})$-space algorithm to compute a separator of a planar graph. The conference version provided a sketch of the algorithm and many nontrivial details were left unexplained. In this work, we provide a detailed construction of their algorithm.</summary>
    <updated>2019-07-07T23:37:15Z</updated>
    <published>2019-07-07T23:37:15Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-09T13:20:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4233</id>
    <link href="https://www.scottaaronson.com/blog/?p=4233" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4233#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4233" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">John Wright joins UT Austin</title>
    <summary xml:lang="en-US">I’m delighted to announce that quantum computing theorist John Wright will be joining the computer science faculty at UT Austin in Fall 2020, after he finishes a one-year postdoc at Caltech. John made an appearance on this blog a few months ago, when I wrote about the new breakthrough by him and Anand Natarajan: namely, […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-image"><figure class="aligncenter"><img alt="" class="wp-image-4244" src="https://www.scottaaronson.com/blog/wp-content/uploads/2019/07/image-1.png"/></figure></div>



<p>I’m delighted to announce that quantum computing theorist <a href="http://www.mit.edu/~jswright/">John Wright</a> will be joining the computer science faculty at UT Austin in Fall 2020, after he finishes a one-year postdoc at Caltech. </p>



<p>John made an appearance on this blog a few months ago, when I <a href="https://www.scottaaronson.com/blog/?p=4172">wrote about</a> the <a href="https://arxiv.org/abs/1904.05870">new breakthrough</a> by him and <a href="http://www.its.caltech.edu/~anataraj/">Anand Natarajan</a>: namely, that MIP* (multi-prover interactive proofs with entangled provers) contains NEEXP (nondeterministic double-exponential time).  Previously, MIP* had only been known to contain NEXP (nondeterministic <em>single</em> exponential time).  So, this is an exponential expansion in the power of entangled provers over what was previously known and believed, and the first proof that entanglement actually <em>increases</em> the power of multi-prover protocols, rather than decreasing it (as it could’ve done a priori).  Even more strikingly, there seems to be no natural stopping point: MIP* might soon swallow up arbitrary towers of exponentials or even the halting problem (!).  For more, see for example <a href="https://www.quantamagazine.org/computer-scientists-expand-the-frontier-of-verifiable-knowledge-20190523/">this <em>Quanta</em> article</a>, or <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">this post by Thomas Vidick</a>, or <a href="http://www.henryyuen.net/post/alice-and-bob-visit/">this short story [sic] by Henry Yuen</a>.</p>



<p>John grew up in Texas, so he’s no stranger to BBQ brisket or scorching weather.  He did his undergrad in computer science at UT Austin—my colleagues remember him as a star—and then completed his PhD with Ryan O’Donnell at Carnegie Mellon, followed by a postdoc at MIT.  Besides the work on MIP*, John is also well-known for his <a href="https://arxiv.org/abs/1508.01907">2015 work with O’Donnell</a> pinning down the sample complexity of quantum state tomography.  Their important result, a version of which was independently obtained by <a href="https://arxiv.org/abs/1508.01797">Haah et al.</a>, says that if you want to learn an unknown d-dimensional quantum mixed state ρ to a reasonable precision, then ~d<sup>2</sup> copies of ρ are both necessary and sufficient.  This solved a problem that had personally interested me, and already plays a role in, e.g., my work on <a href="https://arxiv.org/abs/1711.01053">shadow tomography</a> and <a href="https://www.scottaaronson.com/papers/dpgentle.pdf">gentle measurements</a>.</p>



<p>Our little <a href="https://www.cs.utexas.edu/~qic/">quantum information center</a> at UT Austin is growing rapidly.  <a href="http://sites.utexas.edu/shyamshankar/">Shyam Shankar</a>, a superconducting qubits guy who previously worked in Rob Schoelkopf’s lab at Yale, will also be joining UT’s Electrical and Computer Engineering department this fall.  I’ll have two new postdocs—<a href="https://twitter.com/a_rocchetto?lang=en">Andrea Rocchetto</a> and <a href="http://www.cs.huji.ac.il/~yosiat/">Yosi Atia</a>—as well as new PhD students.  We’ll continue recruiting this coming year, with potential opportunities for students, postdocs, faculty, and research scientists across the CS, physics, and ECE departments as well as the Texas Advanced Computing Center (TACC).  I hope you’ll consider applying to join us.</p>



<p>With no evaluative judgment attached, I can honestly say that this is an unprecedented time for quantum computing as a field.  Where once faculty applicants struggled to make a case for quantum computing (physics departments: “but isn’t this really CS?” / CS departments: “isn’t it really physics?” / everyone: “couldn’t this whole QC thing, like, all blow over in a year?”), today departments are vying with each other and with industry players and startups to recruit talented people.  In such an environment, we’re fortunate to be doing as well as we are.  We hope to continue to expand.</p>



<p>Meanwhile, this was an <a href="https://www.nytimes.com/2019/01/24/technology/computer-science-courses-college.html">unprecedented year for CS hiring at UT Austin</a> more generally.  John Wright is one of at least four new faculty (probably more) who will be joining us.  It’s a good time to be in CS.</p>



<p>A huge welcome to John, and hook ’em Hadamards!</p>



<p>(And for US readers: have a great 4<sup>th</sup>!  Though how could any fireworks match the proof of the Sensitivity Conjecture?)</p></div>
    </content>
    <updated>2019-07-04T01:08:54Z</updated>
    <published>2019-07-04T01:08:54Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-05T04:22:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/07/03/postdoc-at-national-university-of-singapore-apply-by-november-30-2019/</id>
    <link href="https://cstheory-jobs.org/2019/07/03/postdoc-at-national-university-of-singapore-apply-by-november-30-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at National University of Singapore (apply by November 30, 2019)</title>
    <summary>Multiple post-doctoral research positions available in the project on “Provably Verified and Explainable Probabilistic Reasoning,” led by the Principle Investigator, Kuldeep S. Meel. The project broadly aims to develop of formal methods for AI techniques and employ advances in AI techniques for the development of formal methods. Website: https://meelgroup.github.io/files/postdoc.html Email: meel+postdoc@comp.nus.edu.sg</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Multiple post-doctoral research positions available in the project on “Provably Verified and Explainable Probabilistic Reasoning,” led by the Principle Investigator, Kuldeep S. Meel.</p>
<p>The project broadly aims to develop of formal methods for AI techniques and employ advances in AI techniques for the development of formal methods.</p>
<p>Website: <a href="https://meelgroup.github.io/files/postdoc.html">https://meelgroup.github.io/files/postdoc.html</a><br/>
Email: meel+postdoc@comp.nus.edu.sg</p></div>
    </content>
    <updated>2019-07-03T19:39:18Z</updated>
    <published>2019-07-03T19:39:18Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-07-09T13:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16070</id>
    <link href="https://rjlipton.wordpress.com/2019/07/03/mathematics-of-gerrymandering/" rel="alternate" type="text/html"/>
    <title>Mathematics of Gerrymandering</title>
    <summary>Can theory help? source; art by Bill Hennessy John Roberts is the Chief Justice of the United States. Today I will discuss the recent Supreme Court decision on gerrymandering. The 5-4 decision in Rucho v. Common Cause takes the courts out of deciding if redistricting was done fairly. Roberts, penning the majority argument, felt that […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Can theory help?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/07/03/mathematics-of-gerrymandering/unknown-124/" rel="attachment wp-att-16073"><img alt="" class="alignright size-full wp-image-16073" src="https://rjlipton.files.wordpress.com/2019/07/unknown.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><a href="https://nonperele.com/john-biskupic-how-john-roberts-controls-the-us-supreme-court/">source</a>; art by Bill Hennessy</font></td>
</tr>
</tbody>
</table>
<p>
John Roberts is the Chief Justice of the United States.</p>
<p>
Today I will discuss the recent Supreme Court <a href="https://www.scotusblog.com/case-files/cases/rucho-v-common-cause-2/">decision</a> on gerrymandering.</p>
<p>
The 5-4 decision in Rucho v. Common Cause takes the courts out of deciding if redistricting was done fairly. Roberts, penning the majority argument, felt that it was hard, if not impossible, for courts to determine whether districts were reasonably drawn. That is, whether partisan motives dominated when they were created.</p>
<p>
I will explain what <a href="https://en.wikipedia.org/wiki/Gerrymandering">gerrymandering</a> is, and how computational methods may play a role. I must add a takeaway: </p>
<blockquote><p><b> </b> <em> <i>The current view of computational methods to avoid gerrymandering may be based on incorrect assumptions.</i> </em>
</p></blockquote>
<p>More on this later.</p>
<p>
</p><p/><h2> How It Works </h2><p/>
<p/><p>
You probably know that gerrymandering is used, negatively, to describe creating voting districts that do not reflect the voters will. The term was coined as part of an attack on the then Governor of Massachusetts in 1812. The shape of one particularly contrived district looked like a salamander. Since his name was Elbridge Gerry, it became a <i>gerrymander</i>. He was a Democratic-Republican and was not re-elected. </p>
<p>
<a href="https://rjlipton.wordpress.com/2019/07/03/mathematics-of-gerrymandering/gerry/" rel="attachment wp-att-16071"><img alt="" class="aligncenter size-full wp-image-16071" src="https://rjlipton.files.wordpress.com/2019/07/gerry.png?w=600"/></a></p>
<p>
Here is a figure from our friends at Wikipedia that presents examples of gerrymandering. </p>
<p>
<a href="https://rjlipton.wordpress.com/2019/07/03/mathematics-of-gerrymandering/divide/" rel="attachment wp-att-16072"><img alt="" class="aligncenter  wp-image-16072" src="https://rjlipton.files.wordpress.com/2019/07/divide.png?w=270" width="270"/></a></p>
<p>
By redistricting in the above, one can achieve anything from districts all won by the majority, to most won by the majority. These examples, show how the party who controls the districts can control the outcome.</p>
<p>
Well that is an overstatement. They can control the believed leanings of the voters in the districts. In the above example, they can control how yellow a district is. Real life is complicated by other factors: </p>
<ol>
<li>
A candidate may win because they are just more popular. That is a green candidate could still win in a yellow district. <p/>
</li><li>
A candidate may win because of random fluctuations. If the voter margin is small enough, random fluctuations could change the “expected” outcome.
</li></ol>
<p>
The latter is a danger for gerrymanderers. This <a href="https://www.brennancenter.org/blog/what-is-extreme-gerrymandering">site</a> on gerrymandering says: </p>
<blockquote><p><b> </b> <em> The trick is not to spread your voters out so much that districts become vulnerable to flipping to the other party in the normal give and take of electoral politics. </em>
</p></blockquote>
<p>
</p><p/><h2> How We Model It </h2><p/>
<p/><p>
Since Roberts is not our intended audience we will use mathematical definitions. I am sure Roberts and the rest of the Supreme Court justices are smart, but we have our own methods. We do not use legal jargon such as “prima facie” and suspect they do not use math jargon like “prime” numbers.</p>
<p>
So let the yellow party have <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> fraction of the voters. Suppose the voters have to be divided into <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> districts of the same size. A division is just a vector <img alt="{y=(y_{1},\dots,y_{d})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%3D%28y_%7B1%7D%2C%5Cdots%2Cy_%7Bd%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y=(y_{1},\dots,y_{d})}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  y_{1} + \cdots + y_{d} = 1, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y_%7B1%7D+%2B+%5Ccdots+%2B+y_%7Bd%7D+%3D+1%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  y_{1} + \cdots + y_{d} = 1, "/></p>
<p>and each <img alt="{y_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y_{i}}"/> is non-negative. For such a vector <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> the number that yellow <i>wins</i> is the number of indices <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  y_{k} \ge \frac{1}{2d}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y_%7Bk%7D+%5Cge+%5Cfrac%7B1%7D%7B2d%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  y_{k} \ge \frac{1}{2d}. "/></p>
<p>Note, we assume that <img alt="{1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/2}"/> of the voters makes a district a win. We can change this to strictly larger than <img alt="{1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/2}"/>, but will leave it for now.</p>
<blockquote><p><b>Definition 1</b> <em> Define <img alt="{{\rm MaxWin}(d, \alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+MaxWin%7D%28d%2C+%5Calpha%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\rm MaxWin}(d, \alpha)}"/> to the maximum over all <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{y}"/> of the number of wins; and define <img alt="{{\rm MinWin}(d, \alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\rm MinWin}(d, \alpha)}"/> to be the minimum number of wins. </em>
</p></blockquote>
<p>Note, we do not care who is doing the redistricting. Nor do we care about the geometry. For example 	</p>
<p align="center"><img alt="\displaystyle  {\rm MaxWin}(5, 0.60) = 5 \text{ and } {\rm MinWin}(5, 0.60) = 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MaxWin%7D%285%2C+0.60%29+%3D+5+%5Ctext%7B+and+%7D+%7B%5Crm+MinWin%7D%285%2C+0.60%29+%3D+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MaxWin}(5, 0.60) = 5 \text{ and } {\rm MinWin}(5, 0.60) = 1. "/></p>
<p>What can we say about these functions? Here are some simple observations.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> If <img alt="{\alpha \ge 0.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%5Cge+0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha \ge 0.5}"/>, then <img alt="{{\rm MaxWin}(d, \alpha) = d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+MaxWin%7D%28d%2C+%5Calpha%29+%3D+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\rm MaxWin}(d, \alpha) = d}"/>. Just place <img alt="{\alpha }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha }"/> fraction of the voters in each district.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> If <img alt="{\alpha &gt; 0.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%3E+0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha &gt; 0.5}"/>, then <img alt="{{\rm MinWin}(d, \alpha) \ge 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%5Cge+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\rm MinWin}(d, \alpha) \ge 1}"/>. No matter how the districts are drawn there must be at least one where yellow has a majority. </p>
<p>
An advantage of these functions is that now we can discuss growth rates, not just present examples. A strength of theory is that we have replaced statements like “this algorithm is fast” by formulas for their running time. Another advantage is that these functions are <i>independent of geometry</i>. Previously I thought the dominating issue was how regions looked. Now I believe the issue is how close one gets to the best and worst case: <img alt="{\rm MaxWin}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crm+MaxWin%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rm MaxWin}"/> and <img alt="{\rm MinWin}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crm+MinWin%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rm MinWin}"/>. </p>
<blockquote><p><b>Lemma 2</b> <em> Suppose that <img alt="{\alpha &gt; 1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%3E+1%2F2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha &gt; 1/2}"/>. Then 	</em></p><em>
<p align="center"><img alt="\displaystyle  {\rm MinWin}(d, \alpha) = d-\lfloor 2(1-\alpha) d \rfloor " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%3D+d-%5Clfloor+2%281-%5Calpha%29+d+%5Crfloor+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MinWin}(d, \alpha) = d-\lfloor 2(1-\alpha) d \rfloor "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Let <img alt="{\beta = 1-\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta+%3D+1-%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta = 1-\alpha}"/>. Let’s create the arrangement that makes green win as many districts as possible. If <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/> regions are mostly green then that takes <img alt="{\frac{g}{2d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bg%7D%7B2d%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{g}{2d}}"/> of the <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/> green voters. This implies that 	</p>
<p align="center"><img alt="\displaystyle  \frac{g}{2d} \le \beta. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bg%7D%7B2d%7D+%5Cle+%5Cbeta.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{g}{2d} \le \beta. "/></p>
<p>So it follows 	</p>
<p align="center"><img alt="\displaystyle  g \le 2\beta d. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++g+%5Cle+2%5Cbeta+d.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  g \le 2\beta d. "/></p>
<p>This proves that <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/> is equal to <img alt="{\lfloor 2\beta d \rfloor}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clfloor+2%5Cbeta+d+%5Crfloor%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lfloor 2\beta d \rfloor}"/>. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
It may help to set <img alt="{\alpha = 1/2 + \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%3D+1%2F2+%2B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha = 1/2 + \epsilon}"/> where <img alt="{\epsilon&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon&gt;0}"/>. Let’s agree to ignore the rounding off and delete the floor and ceiling functions. Then 	</p>
<p align="center"><img alt="\displaystyle  {\rm MinWin}(d, \alpha) = d-2(1-\alpha) d " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%3D+d-2%281-%5Calpha%29+d+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MinWin}(d, \alpha) = d-2(1-\alpha) d "/></p>
<p>and so 	</p>
<p align="center"><img alt="\displaystyle  {\rm MinWin}(d, \alpha) = 2\epsilon d. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%3D+2%5Cepsilon+d.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MinWin}(d, \alpha) = 2\epsilon d. "/></p>
<p>Thus for <img alt="{\epsilon = 1/10}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3D+1%2F10%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon = 1/10}"/> we get that 	</p>
<p align="center"><img alt="\displaystyle  {\rm MaxWin}(d, \alpha) = d \text{ and } {\rm MinWin}(d, \alpha) = 0.2d. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MaxWin%7D%28d%2C+%5Calpha%29+%3D+d+%5Ctext%7B+and+%7D+%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%3D+0.2d.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MaxWin}(d, \alpha) = d \text{ and } {\rm MinWin}(d, \alpha) = 0.2d. "/></p>
<p>This says that independent of any geometry if yellow has a ten percent majority, then best case if they set the districts they could win all, and if green sets the districts the worst they can get is twenty percent of the districts.</p>
<p>
</p><p/><h2> How Algorithms Can Help </h2><p/>
<p/><p>
There is long-term and continuing interest in algorithms that automate redistricting. The hope is that automated systems will be able to create districts that are fair. A trouble with this research is that there is no universal notion of what makes districts fair. The mantra is: </p>
<blockquote><p><b> </b> <em> <i>A redistricting is fair if and only if the districts collectively satisfy some geometric criterion</i>. </em>
</p></blockquote>
<p>An explicit statement of such a criterion, from a <a href="https://bdistricting.com/about.html">site</a> on such algorithms, is: </p>
<blockquote><p><b> </b> <em> <i>The best district map is the one where people have the lowest average distance to the center of their district</i>. </em>
</p></blockquote>
<p>Of course the name “gerrymandering” came from how districts looked. Somehow this enshrined the notion that districts must look right. I feel this could be wrong.</p>
<p>
Here is a quote from a recent <a href="http://district.cs.brown.edu">paper</a> on an algorithm for redistricting. </p>
<blockquote><p><b> </b> <em> We propose a method for redistricting, decomposing a geographical area into subareas, called districts, so that the populations of the districts are as close as possible and the districts are compact and contiguous. Each district is the intersection of a polygon with the geographical area. The polygons are convex and the average number of sides per polygon is less than six. </em>
</p></blockquote>
<p>The authors are Philip Klein and Neal Young, who are well known researchers on various aspects of algorithms. They do interesting work, their paper is interesting, but the assumption that geometry is the key I do not get.</p>
<p>
</p><p/><h2> How To Do Better? </h2><p/>
<p/><p>
I think that we need to go beyond geometry to understand and avoid gerrymandering. The connection between geometry and fairness is driven—I believe—by tradition. Voters in the same district probably want to be near each other. In the past being near each other was probably important, since travel was so difficult. Perhaps today location is less of an issue then it was before cars, phones, cell phones, internet access, and email. Perhaps districts can be fair and yet do not look good. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
An analogy to <a href="https://en.wikipedia.org/wiki/Fair_cake-cutting">cake cutting</a> may occur to you. Recall in the cake cutting problem success is <i>not</i> measured in how the pieces of the cake look. It is only measured by whether the parties cutting the cake are happy. Is there some way to push this analogy? I just came across a <a href="https://arxiv.org/pdf/1710.08781.pdf">paper</a> using the cake cutting method: <i>A Partisan Districting Protocol With Provably Nonpartisan Outcomes</i> by Wesley Pegden, Ariel Procaccia, and Dingli Yu. More in the future.</p>
<p>
Can algorithmic methods help? Is geometry the fundamental issue? </p>
<p/><p><br/>
[sourced photo, other word edits]</p></font></font></div>
    </content>
    <updated>2019-07-03T13:51:13Z</updated>
    <published>2019-07-03T13:51:13Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="cake-cutting"/>
    <category term="districts"/>
    <category term="fair"/>
    <category term="geometry"/>
    <category term="gerrymander"/>
    <category term="gerrymandering"/>
    <category term="reasonable"/>
    <category term="voters"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-07-09T13:20:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1136</id>
    <link href="https://ptreview.sublinear.info/?p=1136" rel="alternate" type="text/html"/>
    <title>News for June 2019</title>
    <summary>We’ve got four papers this month. A mix of distribution testing, matrix problems, and a different paper on the power of sampling. On the Complexity of Estimating the Effective Support Size, by Oded Goldreich (ECCC). In distribution testing, a classic problem is that of approximating the support size. By a (now) classic result of Valiant-Valiant, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We’ve got four papers this month. A mix of distribution testing, matrix problems, and a different paper on the power of sampling.</p>



<p><strong>On the Complexity of Estimating the Effective Support Size</strong>, by Oded Goldreich (<a href="https://eccc.weizmann.ac.il/report/2019/088/">ECCC</a>). In distribution testing, a classic problem is that of approximating the support size. By a (now) classic result of <a href="http://theory.stanford.edu/~valiant/papers/VV_stoc11.pdf">Valiant-Valiant</a>, the complexity of this problem is \(\Theta(n/\log n)\). This paper raises the question of approximating the “effective” support, and that too with more than just samples from the distribution. The \(\epsilon\)-support of discrete distribution \(\mathcal{D}\) is the smallest support among any distribution \(\mathcal{D}’\) such that \(\|\mathcal{D} – \mathcal{D}’\|_1 \leq \epsilon\) (or TV-distance). Denote this as \(supp_\epsilon(\mathcal{D})\). One can also consider a bicriteria version. Given approximation parameter \(f\) and thresholds \(\epsilon_1 &lt; \epsilon_2\), we need to provide a number in the range \([supp_{\epsilon_2}(\mathcal{D}), f\cdot supp_{\epsilon_1}(\mathcal{D})]\). The primary model studied allows for random samples and evaluation queries (where one gets the probability of any known element of the domain). In this model, for arbitrary \(\epsilon_1, \epsilon_2\), there is a continuum of algorithms, trading off query complexity with approximation. At one end, for \(f = O(\log n)\), the query complexity is \(\widetilde{O}(1/\epsilon_1)\). At the other end, for \(f=1\), the query complexity is \(O(\log^* n)\). (Here, \(n = supp_{\epsilon_1}(\mathcal{D})\).) There are lower bounds showing the necessity of evaluation queries for subpolynomial query complexities.</p>



<p><strong>Communication and Memory Efficient Testing of Discrete Distributions</strong>, by Ilias Diakonikolas, Themis Gouleakis, Daniel M. Kane, and Sankeerth Rao (<a href="https://arxiv.org/abs/1906.04709">arXiv</a>). This paper adds additional computational constraints to the distribution testing problem. In the streaming setting, the algorithm is only allowed a single pass over the random samples. It has \(m\) bits of storage, much smaller than \(n\), the distribution size. The aim is to minimize the number of samples required for uniformity (and closeness) testing. For uniformity testing in the streaming setting, the paper gives an algorithm that uses \(\widetilde{O}(m + n/m)\) samples. The standard collision algorithm requires \(\Theta(\sqrt{n})\) storage (to store the samples), while this result gives a non-trivial bound for \(m \ll \sqrt{n}\). There are lower bounds showing that these bounds are basically tight. In the distributed distribution testing problem, there are a number of processors, each holding \(\ell\) samples. A referee asks a question to the processor, whose answers are broadcast to everyone. The aim is to minimize communication cost. For uniformity testing in this setting, there is a protocol using \(O(\sqrt{n\log n/\ell})\) bits of communication. As a sanity check, note that for \(\ell = \sqrt{n}\), one processor could simply run the collision algorithm locally to report the result. </p>



<p><strong>Querying a Matrix through Matrix-Vector Products</strong> by Xiaoming Sun, David P. Woodruff, Guang Yang, and Jialin Zhang (<a href="https://arxiv.org/pdf/1906.05736.pdf">arXiv</a>). Consider \(n \times d\) matrix \(M\) over some field \(\mathbb{F}\). One gets access to this matrix through matrix-vector products, and wishes to test some matrix property. This is a natural model in many settings, and generalizes the classic setting of query access. A subtle point is that one can only right multiply with “query” vectors, and there are problems where left multiplication can change the complexity. (A nice example in the paper is testing if a square matrix is symmetric. With both left and right multiplications, this is easy, since we can directly access rows and columns. By only accessing columns, this is non-trivial.) This paper studies a number of problems, broadly classified as linear algebra problems, statistics problems, and graph problems. Some highlights are: testing symmetry can be done in \(O(1)\) queries, and the maximum eigenvalue can be approximated in \(O(\log n)\) queries adaptively (but there is an \(\Omega(n)\) non-adaptive lower bound). For graph problems, here’s an interesting discovery. If \(M\) is the adjacency matrix, connectivity requires \(\Omega(n/\log n)\) queries. But if \(M\) is the signed edge-vertex matrix, then this can be done in \(poly(\log n)\) queries. This paper provides a number of interesting directions and problems to study.</p>



<p><strong>The Adversarial Robustness of Sampling</strong> by Omri Ben-Eliezer and Eylon Yogev (arXiv). This isn’t a property testing paper, but how can one ignore a paper on understanding the power of sampling? It’s convenient to think of the following setting. An algorithm gets a stream of \(n\) numbers, and has to answer some questions about the stream (say, the median or other quantiles). The simplest strategy is to take a small random sample of the stream. But what if an adversary was generating the stream, depending on the current sample? Under what circumstances is the sample still “representative” of the stream? The specific results of this paper require getting into set systems and VC dimension, which I’ll leave for the sake of simplicity. Let’s go back to the median question. To get an approximate median, a constant number of samples suffice. A consequence of the main result is that if one takes \(O(\log n)\) samples, then this is robust to adversarial streams. On the other hand, lower bounds show that constant sized samples can be fooled by an adversary. The paper is a really interesting read, and is a nice take on “standard facts” that we take for granted.</p>



<p/></div>
    </content>
    <updated>2019-07-03T00:54:36Z</updated>
    <published>2019-07-03T00:54:36Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Seshadhri</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-07-08T23:30:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8952301722851173857</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8952301722851173857/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8952301722851173857" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8952301722851173857" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html" rel="alternate" type="text/html"/>
    <title>Local Kid Makes History</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="separator" style="clear: both; text-align: center;">
</div>
<a href="https://1.bp.blogspot.com/-OpUgtDyqMf0/XRuOhVHWTFI/AAAAAAABplw/Tz0jTV3EQCo9w0aZ1bsI9xsJiec3OfytgCLcBGAs/s1600/Huang.jpg" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img border="0" height="200" src="https://1.bp.blogspot.com/-OpUgtDyqMf0/XRuOhVHWTFI/AAAAAAABplw/Tz0jTV3EQCo9w0aZ1bsI9xsJiec3OfytgCLcBGAs/s200/Huang.jpg" width="163"/></a>The <a href="https://www.scottaaronson.com/blog/?p=4229">blogosphere</a> is <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">blowing</a> <a href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/">up</a> over Hao Huang's just <a href="https://arxiv.org/abs/1907.00847">posted proof</a> of the sensitivity conjecture, what was one of the more <a href="https://blog.computationalcomplexity.org/2017/12/razors-edge.html">frustrating open questions</a> in complexity.<br/>
<br/>
Huang, an assistant professor in the math department at Emory, settled an open question about the hypercube. The hypercube is a graph on N=2<sup>n</sup> vertices where each vertex corresponds to an n-bit string and their are edges between vertices corresponding to strings that differ in a single bit. Think of the set of the strings of odd parity, N/2 vertices with no edges between them. Add any other vertex and it would have n neighbors. Huang showed that no matter how you placed those N/2+1 vertices in the hypercube, some vertex will have at least n<sup>1/2</sup> neighbors. By an <a href="https://doi.org/10.1016/0097-3165(92)90060-8">old result</a> of Gotsman and Linial, Huang's theorem implies the sensitivity conjecture.<br/>
<br/>
I won't go through the shockingly simple proof, the <a href="https://arxiv.org/abs/1907.00847">paper</a> is well written, or you can read the blogs I linked to above or even just Ryan O'Donnell's <a href="https://twitter.com/BooleanAnalysis/status/1145837576487612416">tweet</a>.<br/>
<br/>
I have nothing more to say than wow, just wow.</div>
    </content>
    <updated>2019-07-02T17:05:00Z</updated>
    <published>2019-07-02T17:05:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-09T11:06:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7530</id>
    <link href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/" rel="alternate" type="text/html"/>
    <title>Sensitivity conjecture proved!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-jetpack-markdown"><p>In a recent breakthrough, <a href="http://www.mathcs.emory.edu/~hhuan30/">Hao Huang</a> gave a <a href="https://arxiv.org/abs/1907.00847">6 page paper</a> proving the longstanding sensitivity conjecture. (Hat tip, <a href="https://www.scottaaronson.com/blog/?p=4229">Scott Aaronson</a> and <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">Gil Kalai</a>. See this <a href="https://cstheory.stackexchange.com/questions/27714/sensitivity-block-sensitivity-conjecture-implications">stackexchange post</a> and <a href="https://eccc.weizmann.ac.il/report/2016/062/">this paper of Avishai</a> for some links to the literature on this.)</p>
<p>The proof is beautiful and simple. I will write a few words here, but it is probably easier for you to just read the <a href="https://arxiv.org/abs/1907.00847">paper</a>. The sensitivity conjecture <a href="https://www.sciencedirect.com/science/article/pii/0097316592900608">was known</a> to follow from the following statement: let <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> be the <em>Boolean Cube</em> which is the degree <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> graph on <img alt="N=2^n" class="latex" src="https://s0.wp.com/latex.php?latex=N%3D2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N=2^n"/> vertices identified with <img alt="\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\}^n"/> such that for every <img alt="x,y\in \{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in \{0,1\}^n"/>, <img alt="x \sim y" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Csim+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \sim y"/> if their Hamming distance is one. Then, the maximum degree of every subgraph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> of <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> of size <img alt="&gt;N/2" class="latex" src="https://s0.wp.com/latex.php?latex=%3EN%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="&gt;N/2"/> is at least <img alt="\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt{n}"/>.</p>
<p>Hao proves the above statement by showing that there is a <em>signing</em> of the <img alt="N\times N" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ctimes+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\times N"/> adjacency matrix of <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> that turns it into a matrix with <img alt="N/2" class="latex" src="https://s0.wp.com/latex.php?latex=N%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N/2"/> eigenvalues equaling <img alt="+\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%2B%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+\sqrt{n}"/> and <img alt="N/2" class="latex" src="https://s0.wp.com/latex.php?latex=N%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N/2"/> eigenvalues equaling <img alt="-\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=-%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-\sqrt{n}"/>. That is, he shows (using a simple but clever inductive argument, see the 5 line proof of his Lemma 2.2) that there is an <img alt="N\times N" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ctimes+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\times N"/> matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> with entries in <img alt="\{ 0, \pm 1 \}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B+0%2C+%5Cpm+1+%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{ 0, \pm 1 \}"/> whose nonzero entries correspond to the edges of the Boolean cube, and such that all the <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/> eigenvalues of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> are <img alt="\pm \sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm \sqrt{n}"/> and they sum up to zero. (Note that this makes sense since <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> should have the same <em>Frobenius norm</em> as  the adjacency matrix of <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/>. The Frobenius norm squared is both the sum of squares of entries, which is <img alt="N\cdot n" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ccdot+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\cdot n"/> for <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> which is a degree <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> graph, and also equal to the sum of squares of the eigenvalues, which is <img alt="N\cdot n" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ccdot+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\cdot n"/> if all eigenvalues are <img alt="\pm \sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm \sqrt{n}"/>.)</p>
<p>Once you have such a signing, the result follows from <a href="https://en.wikipedia.org/wiki/Min-max_theorem#Cauchy_interlacing_theorem">Cauchy’s Interlace Theorem</a> that says that for every <img alt="N\times N" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ctimes+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\times N"/> matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and any <img alt="M\times M" class="latex" src="https://s0.wp.com/latex.php?latex=M%5Ctimes+M&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M\times M"/> matrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> that is a principle sub-matrix of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>,</p>
<p><img alt="\lambda_{1+N-M}(A) \leq \lambda_1(B) \leq \lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_%7B1%2BN-M%7D%28A%29+%5Cleq+%5Clambda_1%28B%29+%5Cleq+%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_{1+N-M}(A) \leq \lambda_1(B) \leq \lambda_1(A)"/></p>
<p>where <img alt="\lambda_1(A) \geq \lambda_2(A) \cdots \geq \lambda_N(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28A%29+%5Cgeq+%5Clambda_2%28A%29+%5Ccdots+%5Cgeq+%5Clambda_N%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(A) \geq \lambda_2(A) \cdots \geq \lambda_N(A)"/> are the eigenvalues of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="\lambda_1(B)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B)"/> is the maximum eigenvalue of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>. A corollary of this (which is the only fact we need) is that if <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> has its top eigenvalue <img alt="\lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(A)"/> with multiplicity <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> (i.e., <img alt="\lambda_1(A)=\lambda_K(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28A%29%3D%5Clambda_K%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(A)=\lambda_K(A)"/>), then every principle sub-matrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> of order larger than <img alt="N-K" class="latex" src="https://s0.wp.com/latex.php?latex=N-K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N-K"/> will satisfy <img alt="\lambda_1(B) = \lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29+%3D+%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B) = \lambda_1(A)"/>. (In fact, we only need <img alt="\lambda_1(B) \geq \lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29+%5Cgeq+%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B) \geq \lambda_1(A)"/>.)</p>
<p>Indeed, suppose that <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is a subgraph of the Boolean cube of size <img alt="M&gt;N/2" class="latex" src="https://s0.wp.com/latex.php?latex=M%3EN%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M&gt;N/2"/>. Then the principle submatrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> corresponding to the vertices of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> satisfies <img alt="\lambda_1(B) \geq \lambda_{1+N-M}(A) = \sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29+%5Cgeq+%5Clambda_%7B1%2BN-M%7D%28A%29+%3D+%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B) \geq \lambda_{1+N-M}(A) = \sqrt{n}"/> (since <img alt="M&gt;N/2" class="latex" src="https://s0.wp.com/latex.php?latex=M%3EN%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M&gt;N/2"/> and the first <img alt="N/2" class="latex" src="https://s0.wp.com/latex.php?latex=N%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N/2"/> eigenvalues of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> are <img alt="+\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%2B%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+\sqrt{n}"/>).
But it’s easy to show that for every matrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> the maximum eigenvalue of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> is upper bounded by the maximum <img alt="\ell_1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_1"/> norm of its rows, which in our case is the maximum degree of the graph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>.</p>
</div></div>
    </content>
    <updated>2019-07-02T16:18:34Z</updated>
    <published>2019-07-02T16:18:34Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-07-09T13:20:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3401</id>
    <link href="https://agtb.wordpress.com/2019/07/02/papafest-september-6-8-columbia/" rel="alternate" type="text/html"/>
    <title>PapaFest (September 6-8 @ Columbia)</title>
    <summary>Announcing a conference celebrating Christos Papadimitriou, September 6-8, 2019, at Columbia University.  Registration is free.  Confirmed invited speakers include: Sanjeev Arora, Michael Collins, Michael I. Jordan, Anna Karlin,  Jon Kleinberg, Elias Koutsoupias, Adi Livnat, Noam Nisan, Prabhakar Raghavan, Scott Shenker, Eva Tardos, John Tsitsiklis, Leslie Valiant, Umesh Vazirani, and Santosh Vempala. More details here. Advertisements</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Announcing a conference celebrating Christos Papadimitriou, September 6-8, 2019, at Columbia University.  Registration is free.  Confirmed invited speakers include: Sanjeev Arora, Michael Collins, Michael I. Jordan, Anna Karlin,  Jon Kleinberg, Elias Koutsoupias, Adi Livnat, Noam Nisan, Prabhakar Raghavan, Scott Shenker, Eva Tardos, John Tsitsiklis, Leslie Valiant, Umesh Vazirani, and Santosh Vempala.</p>
<p>More details <a href="http://papafest.cs.columbia.edu/">here.</a></p></div>
    </content>
    <updated>2019-07-02T12:47:57Z</updated>
    <published>2019-07-02T12:47:57Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>timroughgarden</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-07-09T13:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/07/02/the-autumn-school-on-machine-learning/</id>
    <link href="https://cstheory-events.org/2019/07/02/the-autumn-school-on-machine-learning/" rel="alternate" type="text/html"/>
    <title>The Autumn school on Machine Learning</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">October 3-11, 2019 Tbilisi, Georgia https://cte.ibsu.edu.ge/autumn/ Registration deadline: October 3, 2019 The school will be organized by the International Black Sea University with the support of Shota Rustaveli National Science Foundation of Georgia (SRNSFG). The intended audience of the autumn school includes BSc, MSc and PhD students, researchers as well as industry professionals from the … <a class="more-link" href="https://cstheory-events.org/2019/07/02/the-autumn-school-on-machine-learning/">Continue reading <span class="screen-reader-text">The Autumn school on Machine Learning</span></a></div>
    </summary>
    <updated>2019-07-02T09:09:23Z</updated>
    <published>2019-07-02T09:09:23Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-07-09T13:21:20Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-6337479962158243575</id>
    <link href="http://processalgebra.blogspot.com/feeds/6337479962158243575/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=6337479962158243575" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6337479962158243575" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6337479962158243575" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/07/phd-position-at-tu-wirn-formal-methods.html" rel="alternate" type="text/html"/>
    <title>PhD position at TU Wirn: Formal methods applied to the specification and monitoring of large-scale, spatially-distributed, stochastic systems</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="_5pbx userContent _3576" id="js_3b"><i>Interesting PhD position at TU Wien with <a class="profileLink" href="http://www.eziobartocci.com/" title="Ezio Bartocci">Ezio Bartocci</a> and <a href="https://lauranenzi.github.io/">Laura Nenzi</a>. Spread the news! </i><br/><br/> The <a href="http://ti.tuwien.ac.at/">Institute of Computer Engineering</a> at the Technische Universität Wien (TU Wien) is seeking a candidate for a  research assistant position (PhD student, 4 years). The position is  available from September (a starting date until Fall 2019 is intended)  and the successful candidate will be a PhD student of the <a href="https://logic-cs.at/phd/">LogiCS Doctoral Program</a> and she/he will be supervised by Prof. Ezio Bartocci &lt;<a href="https://l.facebook.com/l.php?u=http%3A%2F%2Fwww.eziobartocci.com%2F%3Ffbclid%3DIwAR0DbRlQ3WbZCS1HzoZXYIRYXBsRDz2tCxE2G_6APz6K76RRDmLVMIkgBOg&amp;h=AT3xOIDKhxhBw2_daqAKot9Y3qtCNlITUpSxTEttEVYsbYoofL5LKQ7MD72mx8Nf3f0zPGNE5AY-FvqTQsTVZMllhO6DR94ug3vsjG3H84L4h8RDLdPWJxht8otBFNix1De-G1NEeihv6M6l-3cp" rel="noopener nofollow" target="_blank">http://www.eziobartocci.com/</a>&gt; and co-supervised by Dr. Laura Nenzi &lt;<a href="https://l.facebook.com/l.php?u=https%3A%2F%2Flauranenzi.github.io%2F%3Ffbclid%3DIwAR0O-FIXoCWcyMBVUqn5K-Ejd0vxQQJFYQ7ni1qBAdy9Ez01d6CDolZcb6U&amp;h=AT1RfdebNNlmUThAy2WWm6AclixjQ6sGfMnjrc5C-e4EbEglPtsVHAvYqJHIPfOZfHtYPGxz__so98GKEhDQZkGKQWB2z2fBom5MdlaCvrImUyjEZ5wotHeR5-w6sF4BkAIL-PGzihR9ZVsmSasc" rel="noopener nofollow" target="_blank">https://lauranenzi.github.io/</a>&gt;<br/> The successful applicant will carry out his/her PhD in the research  area of formal methods applied to the specification and monitoring of  large-scale, spatially-distributed, stochastic systems.<br/> The position in funded by the ÖAW and the FWF &lt;<a href="https://l.facebook.com/l.php?u=https%3A%2F%2Fm.fwf.ac.at%2Fen%2Fresearch-funding%2Fpersonnel-costs%2F%3Ffbclid%3DIwAR10rZDtpakXdwSo_WXE4A9GuFDbfkJoVYoCTgpZuBDmCMPVOmC8ZAo7Cyg&amp;h=AT13vFq0Svw4kLAe0VMNoonNMZyo8o6gdfK_-O0_LFJNhJavAH7Zt2YCyKMEKHuymeDiRrW6PggMAbBH0FyhcksLJJ0py3YWXi5vgwUwD0r_i3SFPvATFXhyZukxJL770ABLvhkdvgFQyiFvm5I8" rel="noopener nofollow" target="_blank">https://m.fwf.ac.at/en/research-funding/personnel-costs/</a>&gt;  for the recently acquired YIRG grant: “High-dimensional statistical  learning: new methods to advance economic and sustainability policies”,  an interdisciplinary project to be led for the TU part by PhD Laura  Nenzi.<br/> TASK DESCRIPTION (leader Laura Nenzi):   <br/> Formal  methods provide precise formal specification languages that can be  easily interpreted by humans and verification algorithms that can check  in an automatic way the value of satisfaction of interesting properties.  One of the main problems of such techniques is the curse of  dimensionality. A possibility to treat the problem is to use approximate  methods such as statistical model checking. However, even these  methodologies can be unfeasible for very-large-scale stochastic systems.  A new research line consists of exploiting machine learning techniques  and Bayesian inference to identify relevant data and decrease the  computational cost, permitting the application of such powerful formal  analysis on very complex systems. An important aspect that will be  covered in the study is the spatial configuration of such systems, a key  feature in several real case studies that are considering in the  project. The methodology will be principally applied to tackle questions  related to sustainable urban mobility and thus responsible consumption.<br/> APPLICATION<br/> Please apply your application following  the instructions in the DK LogiCS admission portal. <a href="https://l.facebook.com/l.php?u=https%3A%2F%2Flogic-cs.at%2Fphd%2Fadmission%2F%3Ffbclid%3DIwAR3oZZ1EmwtB7RHLErRrlbfY-HBeprkDbr8y-WyttxBelPGVrFY46hZuy3o&amp;h=AT2erabItYmdcemt5VHuXftBV82JOmliZPV-SIiYfhedKPgLyH9PR_pf1dJ3EHa-SQgsBTWJqgjsgzUJPauzRI4h_2t1t8Ci_NW6DannlCzLkriOSguTjs3IfU4p0eBWTTEvJmljKFMYpbZ36tKn" rel="noopener nofollow" target="_blank">https://logic-cs.at/phd/admission/</a> &lt;<a href="https://logic-cs.at/phd/admission/?fbclid=IwAR1rL9Zavpr2JH9oOonuC0OZ0wPUsoFxWi0usVFZPXQJzSJeSQr97rk490c" rel="noopener nofollow" target="_blank">https://logic-cs.at/phd/admission/</a>&gt;,  by indicating in the application form: Prof. Ezio Bartocci and Dr.  Laura Nenzi as supervisors. While it is not necessary to have the Master  degree at the moment of the application, it is instead mandatory to  complete it before starting the PhD.<br/> CONTACT DETAILS<br/> For  further information and inquiries about this post please contact Laura  Nenzi, e-mail: laura.nenzi@gmail.com  .</div></div>
    </content>
    <updated>2019-07-02T08:47:00Z</updated>
    <published>2019-07-02T08:47:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-07-02T12:00:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/07/02/papafest-for-christos-70th-birthday/</id>
    <link href="https://cstheory-events.org/2019/07/02/papafest-for-christos-70th-birthday/" rel="alternate" type="text/html"/>
    <title>PapaFest for Christos’ 70th birthday</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">September 6-8, 2019 Columbia University http://papafest.cs.columbia.edu/ We are happy to invite you to Columbia University to celebrate Christos Papadimitriou’s contributions to science on the occasion of his 70th birthday, through a mix of talks, panels, and fun activities. One of world’s leading computer scientists, Christos is best known for his work in computational complexity, helping … <a class="more-link" href="https://cstheory-events.org/2019/07/02/papafest-for-christos-70th-birthday/">Continue reading <span class="screen-reader-text">PapaFest for Christos’ 70th birthday</span></a></div>
    </summary>
    <updated>2019-07-02T08:32:49Z</updated>
    <published>2019-07-02T08:32:49Z</published>
    <category term="other"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-07-09T13:21:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4229</id>
    <link href="https://www.scottaaronson.com/blog/?p=4229" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4229#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4229" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Sensitivity Conjecture resolved</title>
    <summary xml:lang="en-US">The Sensitivity Conjecture, which I blogged about here, says that, for every Boolean function f:{0,1}n→{0,1}, the sensitivity of f—that is, the maximum, over all 2n input strings x∈{0,1}n, of the number of input bits such that flipping them changes the value of f—is at most polynomially smaller than a bunch of other complexity measures of […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Sensitivity Conjecture, which I blogged about <a href="https://www.scottaaronson.com/blog/?p=453">here</a>, says that, for every Boolean function f:{0,1}<sup>n</sup>→{0,1}, the <em>sensitivity</em> of f—that is, the maximum, over all 2<sup>n</sup> input strings x∈{0,1}<sup>n</sup>, of the number of input bits such that flipping them changes the value of f—is at most polynomially smaller than a bunch of other complexity measures of f, including f’s block sensitivity, degree as a real polynomial, and classical and quantum query complexities.  (For more, see for example <a href="http://www.cs.columbia.edu/~rocco/Teaching/S12/Readings/BdW.pdf">this survey</a> by Buhrman and de Wolf.  Or for quick definitions of the relevant concepts, <a href="https://cstheory.stackexchange.com/questions/19902/boolean-functions-where-sensitivity-equals-block-sensitivity">see here</a>.)</p>



<p>Ever since it was posed by Nisan and Szegedy in 1989, this conjecture has stood as one of the most frustrating and embarrassing open problems in all of combinatorics and theoretical computer science.  It seemed so easy, and so similar to other statements that had 5-line proofs.  But a lot of the best people in the field sank months into trying to prove it.  For whatever it’s worth, I also sank … well, at least weeks into it.</p>



<p>Now <a href="http://www.mathcs.emory.edu/~hhuan30/">Hao Huang</a>, a mathematician at Emory University, has posted a <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">6-page preprint</a> on his homepage that finally proves the Sensitivity Conjecture, in the form s(f)≥√deg(f).  (I thank Ryan O’Donnell for tipping me off to this.)  Within the preprint, the proof itself is about a page and a half.</p>



<p>Whenever there’s an announcement like this, ~99% of the time either the proof is wrong, or at any rate it’s way too complicated for outsiders to evaluate it quickly.  This is one of the remaining 1% of cases.  I’m rather confident that the proof is right.  Why?  Because I read and understood it.  It took me about half an hour.  If you’re comfortable with concepts like <em>induced subgraph</em> and <em>eigenvalue</em>, you can do the same.</p>



<p>From pioneering work by Gotsman and Linial in 1992, it was known that to prove the Sensitivity Conjecture, it suffices to prove the following even simpler combinatorial conjecture:</p>



<blockquote class="wp-block-quote"><p>Let S be any subset of the n-dimensional Boolean hypercube, {0,1}<sup>n</sup>, which has size 2<sup>n-1</sup>+1.  Then there must be a point in S with at least ~n<sup>c</sup> neighbors in S.</p></blockquote>



<p>Here c&gt;0 is some constant (say 1/2), and two points in S are “neighbors” if and only they differ in a single coordinate.  Note that if S had size 2<sup>n-1</sup>, then the above statement would be false—as witnessed, for example, by the set of all n-bit strings with an even number of 1’s.</p>



<p>Huang proceeds by proving the Gotsman-Linial Conjecture.  And the way he proves Gotsman-Linial is … well, at this point maybe I should just let you <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">read the damn preprint</a> yourself.  I can’t say it more simply than he does.</p>



<p>If I had to try anyway, I’d say: Huang constructs a 2<sup>n</sup>×2<sup>n</sup> matrix, called A<sub>n</sub>, that has 0’s where there are no edges between the corresponding vertices of the Boolean hypercube, and either 1’s or -1’s where there <em>are</em> edges—with a simple, weird pattern of 1’s and -1’s that magically makes everything work.  He then lets H be an induced subgraph of the Boolean hypercube of size 2<sup>n-1</sup>+1.  He lower-bounds the maximum degree of H by the largest eigenvalue of the corresponding (2<sup>n-1</sup>+1)×(2<sup>n-1</sup>+1) submatrix of A<sub>n</sub>.  Finally, he lower-bounds that largest eigenvalue by … no, I don’t want to spoil it!  Read it yourself!</p>



<p>Paul Erdös famously spoke of a book, maintained by God, in which was written the simplest, most beautiful proof of each theorem.  The highest compliment Erdös could give a proof was that it “came straight from the book.”  In this case, I find it hard to imagine that even God knows how to prove the Sensitivity Conjecture in any simpler way than this.</p>



<p>Indeed, the question is: how could such an elementary 1.5-page argument have been overlooked for 30 years?  I don’t have a compelling answer to that, besides noting that “short” and “elementary” often have little to do with “obvious.”  Once you start looking at the spectral properties of this matrix A<sub>n</sub>, the pieces snap together in precisely the right way—but how would you know to look at that?</p>



<p>By coincidence, earlier today I finished reading my first PG Wodehouse novel (<em><a href="http://www.gutenberg.org/files/10554/10554-h/10554-h.htm">Right Ho, Jeeves!</a></em>), on the gushing recommendation of a friend.  I don’t know how I’d missed Wodehouse for 38 years.  His defining talent is his ability to tie together five or six plot threads in a way that feels perfect and inevitable even though you didn’t see it coming.  This produces a form of pleasure that’s nearly indistinguishable from the pleasure one feels in reading a “proof from the book.”  So my pleasure centers are pretty overloaded today—but in such depressing times for the world, I’ll take pleasure wherever I can get it.</p>



<p>Huge congratulations to Hao!</p>



<p><strong>Added thought:</strong> What this really is, is one of the purest illustrations I’ve seen in my career of the power and glory of the P≠NP phenomenon.  We talk all the time about how proofs are easier to verify than to find.  In practice, though, it can be far from obvious that that’s true.  Consider your typical STOC/FOCS paper: writing it probably took the authors several months, while fully understanding the thing from scratch would probably take … <em>also</em> several months!  If there’s a gap, it’s only by a factor of 4 or 5 or something.  Whereas in this case, I don’t know how long Huang spent searching for the proof, but the combined search efforts of the community add up to years or decades.  The ratio of the difficulty of finding to the difficulty of completely grasping is in the hundreds of thousands or millions.</p>



<p><strong>Another added thought:</strong> Because Hao actually proves a stronger statement than the original Sensitivity Conjecture, it has additional implications, a few of which Hao mentions in his preprint.  Here’s one he didn’t mention: any randomized algorithm to guess the parity of an n-bit string, which succeeds with probability at least 2/3 on the majority of strings, must make at least ~√n queries to the string, while any such quantum algorithm must make at least ~n<sup>1/4</sup> queries.  For more, see the paper <a href="https://arxiv.org/pdf/1312.0036.pdf">Weak Parity</a> by me, Ambainis, Balodis, and Bavarian (Section 6).</p>



<p><strong>Important Update:</strong> Hao Huang himself has graciously <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813116">visited the comment section</a> to satisfy readers’ curiosity by providing a detailed timeline of his work on the Sensitivity Conjecture.  (tl;dr: he was introduced to the problem by Mike Saks in 2012, and had been attacking it on and off since then, until he finally had the key insight this past month while writing a grant proposal.  Who knew that grant proposals could ever be useful for anything?!?)</p>



<p><strong>Another Update:</strong> In the comments section, my former student Shalev Ben-David points out a <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813084">simplification</a> of Huang’s argument, which no longer uses Cauchy’s interlacing theorem.  I thought there was no way this proof could possibly be made any simpler, and I was wrong!</p></div>
    </content>
    <updated>2019-07-02T05:15:43Z</updated>
    <published>2019-07-02T05:15:43Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-05T04:22:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17499</id>
    <link href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/" rel="alternate" type="text/html"/>
    <title>Amazing: Hao Huang Proved the Sensitivity Conjecture!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Today’s arXived amazing paper by Hao Huang’s Induced subgraphs of hypercubes and a proof of the Sensitivity Conjecture Contains an amazingly short and beautiful proof of a famous open problem from the theory of computing – the sensitivity conjecture posed … <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Today’s arXived amazing paper by Hao Huang’s</p>
<p><a href="https://arxiv.org/abs/1907.00847">Induced subgraphs of hypercubes and a proof of the Sensitivity Conjecture</a></p>
<p>Contains an amazingly short and beautiful proof of a famous open problem from the theory of computing – the sensitivity conjecture posed by Noam Nisan and Mario Szegedi</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/hao-huang-chicago.jpg"><img alt="" class="alignnone size-medium wp-image-17505" height="225" src="https://gilkalai.files.wordpress.com/2019/07/hao-huang-chicago.jpg?w=300&amp;h=225" width="300"/></a></p>
<p><span style="color: #ff0000;"><strong>Hao Huang</strong></span></p>
<p><strong>Abstract: </strong>In this paper, we show that every <img alt="2^{n-1}+1" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bn-1%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{n-1}+1"/>-vertex induced subgraph of the <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-dimensional cube graph has maximum degree at least <img alt="\sqrt n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt n"/>. This result is best possible, and improves a logarithmic lower bound shown by Chung, Füredi, Graham and Seymour in 1988. As a direct consequence, we prove that the sensitivity and degree of a boolean function are polynomially related, solving an outstanding foundational problem in theoretical computer science, the Sensitivity Conjecture of Nisan and Szegedy.</p>
<p>The proof relies on important relation between the two problems  by Gotsman and Linial. It uses beautifully Cauchy’s interlace theorem (for eigenvalues).</p>
<p>Thanks to Noga Alon for telling me about the breakthrough. For more on the conjecture and a polymath project devoted to solve it see <a href="https://www.scottaaronson.com/blog/?p=453">this post</a> on Aaronson’s Shtetl Optimized (SO).  See also <a href="https://rjlipton.wordpress.com/2016/10/05/congratulations-noam/">this post on GLL.</a> Updates: See this <a href="https://www.scottaaronson.com/blog/?p=4229">new lovely post on SO</a> (and don’t miss the excellent comment thread); and <a href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/">this post by Boaz Barak </a>on WOT (Window on Theory) explains the main ingredient of Huang’s proof. Here is <a href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html">a post by Lance Fortnow</a> on CC (Computational Complexity) mentioning a <a href="https://twitter.com/BooleanAnalysis/status/1145837576487612416">remarkable tweet</a> by Ryan O’Donnell (see below the fold). Here is <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813116">a comment by Hao</a> on SO on the history of his own work on the problem since he heard it from Mike Saks in 2012.</p>
<p>Also today on the arXive a paper by <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pat%C3%A1kov%C3%A1%2C+Z">Zuzana (Zuzka) Patáková</a> and me: <a href="https://arxiv.org/abs/1907.00885">Intersection Patterns of Planar Sets</a>. Like one of my very first papers “Intersection patterns of convex sets” the new paper deals with face numbers of nerves of geometric sets.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/kp1.png"><img alt="" class="alignnone size-full wp-image-17510" src="https://gilkalai.files.wordpress.com/2019/07/kp1.png?w=640"/></a><span id="more-17499"/></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/kp2.png"><img alt="" class="alignnone size-full wp-image-17511" src="https://gilkalai.files.wordpress.com/2019/07/kp2.png?w=640"/></a></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/ro.png"><img alt="" class="alignnone size-full wp-image-17515" height="675" src="https://gilkalai.files.wordpress.com/2019/07/ro.png?w=640&amp;h=675" width="640"/></a></p></div>
    </content>
    <updated>2019-07-02T04:07:15Z</updated>
    <published>2019-07-02T04:07:15Z</published>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Hao Huang"/>
    <category term="sensitivity conjecture"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-09T13:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4220</id>
    <link href="https://www.scottaaronson.com/blog/?p=4220" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4220#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4220" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Quantum Sabinacy</title>
    <summary xml:lang="en-US">Sabine Hossenfelder—well-known to readers of Shtetl-Optimized for opposing the building of a higher-energy collider, and various other things—has weighed in on “quantum supremacy” in this blog post and this video. Sabine consulted with me by phone before doing the video and post, and despite what some might see as her negative stance, I agree with […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Sabine Hossenfelder—well-known to readers of <em>Shtetl-Optimized</em> for <a href="https://www.scottaaronson.com/blog/?p=4122">opposing the building</a> of a higher-energy collider, and various other things—has weighed in on “quantum supremacy” in <a href="http://backreaction.blogspot.com/2019/06/quantum-supremacy-what-is-it-and-what.html?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed:+Backreaction+(Backreaction)&amp;m=1">this blog post</a> and <a href="https://www.youtube.com/watch?time_continue=1&amp;v=GKnfVA1v5ow">this video</a>.  Sabine consulted with me by phone before doing the video and post, and despite what some might see as her negative stance, I agree with what she has to say substantially more than I disagree.</p>



<p>I do, however, have a few quibbles:</p>



<p> 1. We don’t know that millions of physical qubits will be needed for useful simulations of quantum chemistry.  It all depends on how much error correction is needed and how good the error-correcting codes and simulation algorithms become.  Like, sure, you can generate pessimistic forecasts by plugging numbers in to the best known codes and algorithms.  But “the best known” is a rapidly moving target—one where there have already been orders-of-magnitude improvements in the last decade.</p>



<p>2. To my mind, there’s a big conceptual difference between a single molecule that you can’t efficiently simulate classically, and a programmable computer that you can’t efficiently simulate classically.  The difference, in short, is that only for the computer, and not for the molecule, would it ever make sense to say it had given you a <strong>wrong</strong> answer!  In other words, a physical system becomes a “computer” when, and only when, you have sufficient understanding of, and control over, its state space and time evolution that you can ask the system to simulate something <em>other than itself</em>, and then judge whether it succeeded or failed at that goal.</p>



<p>3. The entire point of my recent work, on certified randomness generation (see for example <a href="https://www.scottaaronson.com/talks/certrand2.ppt">here</a> or <a href="https://www.quantamagazine.org/how-to-turn-a-quantum-computer-into-the-ultimate-randomness-generator-20190619/">here</a>), is that sampling random bits with a NISQ-era device <em>could</em> have a practical application.  That application is … I hope you’re sitting down for this … sampling random bits!  And then, more importantly and nontrivially, <strong>proving</strong> to a faraway skeptic that the bits really were randomly generated.</p>



<p>4. While I was involved in some of the first proposals for NISQ quantum supremacy experiments (such as <a href="https://en.wikipedia.org/wiki/Boson_sampling">BosonSampling</a>), I certainly can’t take sole credit for the idea of quantum supremacy!  The term, incidentally, <a href="https://arxiv.org/abs/1203.5813">was coined by John Preskill</a>.</p>



<p>5. The term “NISQ” (Noisy Intermediate Scale Quantum) was also <a href="https://arxiv.org/abs/1801.00862">coined by John Preskill</a>.  He had no intention of misleading investors—he just needed a term to discuss the quantum computers that will plausibly be available in the near future.  As readers of this blog know, there certainly <em>has</em> been some misleading of investors (and journalists, and the public…) about the applications of near-term QCs.  But I don’t think you can lay it at the feet of the term “NISQ.”</p></div>
    </content>
    <updated>2019-07-01T18:30:10Z</updated>
    <published>2019-07-01T18:30:10Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-05T04:22:46Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7054757178293557182</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7054757178293557182/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/a-proof-that-227-pi-0-and-more.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7054757178293557182" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7054757178293557182" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/06/a-proof-that-227-pi-0-and-more.html" rel="alternate" type="text/html"/>
    <title>A proof that 22/7 - pi &gt; 0 and more</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
My father was a High School English teacher who did not know much math. As I was going off to college, intending to major in math, he gave me the following sage advice:<br/>
<br/>
1) <i>Take Physics as well as Math since Physics and Math go well together.</i> This was good advice. I took the first year of Physics for Physics Majors, and I later took a senior course in Mechanics since that was my favorite part of the first year course. Kudos to Dad!<br/>
<br/>
2) π <i>is exactly </i>22/7. I knew this was not true, but I also knew that I had no easy way to show him this. In fact, I wonder if I could have proven it myself back then.<br/>
<br/>
I had not thought about this in many years when I came across the following:<br/>
<br/>
Problem A-1 on the 1968 Putnam exam:<br/>
<br/>
Prove 22/7 - π = ∫<sub>0</sub><sup>1</sup> (x<sup>4</sup>(1-x)<sup>4</sup>)/(1+ x<sup>2</sup> )dx<br/>
<br/>
(I can easily do his by partial fractions and remembering that ∫ 1/(1+x^2) dx = tan<sup>-1</sup>x  which is tan inverse, not 1/tan. See <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pi.pdf">here</a>.)<br/>
<br/>
(ADDED LATER---I have added conjectures on getting integrals of the form above except with 4 replaced by any natural number. Be the first on your block to solve my conjectures! It has to be easier than the Sensitivity Conjecture!)<br/>
<br/>
<br/>
<br/>
Let n &amp;in N which we will choose later. By looking at the circle that is inscribed in a regular n-polygon (n even) one finds that <br/>
<br/>
<br/>
n tan(π/n) &gt;  π <br/>
<br/>
<br/>
So we seek an even  value of n such that<br/>
<br/>
<br/>
n tan(π/n) &lt; 22/7<br/>
<br/>
<br/>
Using Wolfram alpha the smallest such n is 92.<br/>
<br/>
Would that convince Dad? Would he understand it? Probably not. Oh well.<br/>
<br/>
Some misc points.<br/>
<br/>
<br/>
1)  While working on this post I originally wanted to find tan(π/2<sup>7</sup>) by using the half-angle formula many times, and get an exact answer in terms of radicals,  rather than using Wolfram Alpha. <br/>
<br/>
a) While I have lots of combinatorics books, theory of comp books, and more Ramsey Theory books than one person should own in my house, I didn't have a SINGLE book with any trig in it.<br/>
<br/>
b) I easily found it on the web: <br/>
<br/>
tan(x/2) = sqrt( (1-cos x)/(1+cos x) ) = sin x/(1+cos x) = (1-cos x)/(sin x).<br/>
<br/>
None of these seems like it would get me a nice expression for tan(π/2<sup>7</sup>). But I don't know. Is there a nice expression for tan(π/2<sup>k</sup>) ? If you know of one then leave a polite comment.<br/>
<br/>
2) I assumed that there was a more clever and faster way to do the integral. I could not find old Putnam exams and their solutions  the web (I'm sure they are there someplace! --- if you know then comment politely with a pointer). So I got a book out of the library <i>The William Lowell Putnam Mathematical Competition Problems and Solutions 1965--1984</i> by Alexanderson, Klosinski, and Larson. Here is the clever solution:<br/>
<br/>
<i>The standard approach from Elementary Calculus applies.<br/>
<br/>
</i><br/>
<br/>
Not as clever as I as hoping for.<br/>
<br/>
3) I also looked at the integral with 4 replaced by 1,2,3,4,...,16. The results are in the writeup I pointed to before. It looks like I can use this sequence to get  upper and lower bound on pi, ln(2), pi+2ln(2), and pi-2ln(2). I have not proven any of this. But take a look! And as noted above I have conjectures!<br/>
<br/>
<br/>
4) When I looked up INSCRIBING a circle in a regular n-polygon, Google kept giving me CIRCUMSCRIBING. Why? I do not know but I can speculate. Archimedes had a very nice way of using circumscribed circles to approximate pi. Its on youtube <a href="https://www.youtube.com/watch?v=_rJdkhlWZVQ">here</a>.  Hence people are used to using circumscribed rather than inscribed circles.<br/>
<br/></div>
    </content>
    <updated>2019-07-01T02:34:00Z</updated>
    <published>2019-07-01T02:34:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-09T11:06:13Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/06/30/linkage</id>
    <link href="https://11011110.github.io/blog/2019/06/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Ok, some of these are not so much links as mini-reports from SPAA/STOC/FCRC. For an actual conference report, see Lance’s post.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Ok, some of these are not so much links as mini-reports from SPAA/STOC/FCRC. For an actual conference report, see <a href="https://blog.computationalcomplexity.org/2019/06/fcrc-2019.html">Lance’s post</a>.</p>

<ul>
  <li>
    <p><a href="https://uhills.org/the-university-hills-section-marker-a-history-of-maps-markers-and-monuments-that-eventually-created-university-hills/">Squaring the spherical earth</a> (<a href="https://mathstodon.xyz/@11011110/102285188426196734"/>). For surveying purposes, Orange County is divided into “sections”, typically one square mile (not axis-aligned!) with small brass markers at their corners. One corner lands in the UCI faculty housing development where I live, and the housing association took the opportunity to make a larger decorative marker for it.</p>
  </li>
  <li>
    <p><a href="https://gilkalai.wordpress.com/2019/03/22/danny-nguyen-and-igor-pak-presburger-arithmetic-problem-solved/">Integer linear programming, change-making, and Presburger arithmetic</a> (<a href="https://mathstodon.xyz/@11011110/102291138538406550"/>). Integer arithmetic problems with a constant number of variables and one level of quantifiers (example: given a constant number of coin types, find the largest amount of money for which you cannot make change) have long been known to be polynomially solvable, but <a href="http://www.math.ucla.edu/~pak/papers/hard_presburger3.pdf">in FOCS 2017 Nguyen and Pak proved that only two levels of quantifiers make the problem hard</a>.</p>
  </li>
  <li>
    <p><a href="https://tomas.rokicki.com/dottri.html">Dots and triangles</a> (<a href="https://mathstodon.xyz/@christianp/102297036146535876"/>). Online variant of dots and boxes by Tomas Rikicki.</p>
  </li>
  <li>
    <p><a href="https://cameroncounts.wordpress.com/2019/06/19/combinatorics-at-strathclyde/">University of Strathclyde proposes to axe combinatorics and their three strong combinatorics faculty members</a> (<a href="https://mathstodon.xyz/@11011110/102301038310925223"/>, <a href="https://gowers.wordpress.com/2019/06/19/the-fate-of-combinatorics-at-strathclyde/">via</a>). This comes despite the group being both strong in research and important in undergraduate education. The apparent cause is Strathclyde’s placement of combinatorics in computer science rather than in mathematics and in their use of standards aimed more at computer science than mathematics (like bringing in large grants). There’s an <a href="https://britishcombinatorial.wordpress.com/2019/06/20/combinatorics-at-strathclyde-2/">online petition against the cuts</a> closing very soon: 5pm British time, July 1.</p>
  </li>
  <li>
    <p>Catherine Greenhill is setting up a new network for women in combinatorics, meaning “anyone who identifies as a woman, is non-binary, two-spirit, or gender diverse” (<a href="https://mathstodon.xyz/@11011110/102311965002907932"/>). <a href="https://womenincombinatorics.com/">Their website</a> currently only has a sign-up form, but expect more to come.</p>
  </li>
  <li>
    <p>Slides from three of my recent conference talks (<a href="https://mathstodon.xyz/@11011110/102319479687501682"/>):
<a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-SoCG-19-many-lines-slides.pdf">Cubic planar graphs that cannot be drawn on few lines</a>; <a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-SoCG-19-counting-slides.pdf">Counting polygon triangulations is hard</a>; <a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-SPAA-19-slides.pdf">NC algorithms for perfect matching and maximum flow in one-crossing-minor-free graphs</a>.</p>
  </li>
  <li>
    <p>Certain conference speakers need to be told that using sans-serif ∑ for one central notation and sans-serif bold ∑ for a different central notation is a bad idea. That decorating both of them by the same subscripts and the same hats doesn’t help. And that when someone asks for clarification of the notation, answering with “We should move on…this is a thing you can compute on your own” rather than actually explaining is rude (<a href="https://mathstodon.xyz/@11011110/102323855724493135"/>).</p>
  </li>
  <li>
    <p>The STOC Wikipedia edit-a-thon was called off because the convention center was locked up and participants couldn’t get into the room it was scheduled for (<a href="https://mathstodon.xyz/@11011110/102330434291269046"/>). But <a href="https://thmatters.wordpress.com/2019/06/26/edit-a-thon-update/">it was successfully rescheduled for the next day</a>, unfortunately too late in the conference for me to participate.</p>

    <p>In other news from STOC, spammy journal publishers have found a new way to spam us: fund student authors with travel awards (laudable and non-spammy!) but then require the student presenters to display a whole slide of advertising for the journal by way of acknowledgements (spammy!).</p>
  </li>
  <li>
    <p><a href="https://xkcd.com/2168/">xkcd on reading Wikipedia in the original Greek</a> (<a href="https://mathstodon.xyz/@11011110/102339055555301837"/>).</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1906.10668">Discrete logarithms in quasi-polynomial time in finite fields of fixed characteristic</a> (<a href="https://mathstodon.xyz/@erou/102337004608271854"/>). New preprint by Kleinjung and Weselowski.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=OerQAsqEOLc">Short video on interleaving multiple copies of the infinite Laves graph</a> (<a href="https://mathstodon.xyz/@11011110/102353592823020968"/>). Sound not necessary.</p>
  </li>
  <li>
    <p><a href="https://arstechnica.com/science/2019/06/two-new-papers-explore-the-complicated-physics-behind-bubbles-and-foams/">Two new papers explore the complicated physics behind bubbles and foams</a> (<a href="https://mathstodon.xyz/@11011110/102356874963380843"/>).
Juanes et al find <a href="http://dx.doi.org/10.1073/pnas.1819744116">universality in pinching off uniformly sized bubbles</a> from a tube much like drops from a dripping faucet. And Yanagisawa and Kurita discover <a href="http://dx.doi.org/10.1038/s41598-019-41486-6">two mechanisms for breaking bubbles to propagate through a foam</a>. As it contracts, the breaking bubble can hit other bubbles, and it can also scatter off droplets which hit other bubbles.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1902.07622">Centrality analysis of Wikipedia links between mathematicians</a> (<a href="https://mathstodon.xyz/@11011110/102361585031049847"/>, <a href="https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2019-06-30/Recent_research">via</a>). None of the names listed are surprising, but the ordering might be a little. Noether makes the top 10; Bourbaki, Grothendieck, and Turing are farther down. Martin Gardner makes the cut (barely), at #35.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-06-30T16:16:00Z</updated>
    <published>2019-06-30T16:16:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-06-30T23:47:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16046</id>
    <link href="https://rjlipton.wordpress.com/2019/06/29/a-prime-breakthrough/" rel="alternate" type="text/html"/>
    <title>A Prime Breakthrough</title>
    <summary>A breakthrough on the Riemann Hypothesis [ Composite of various sources ] Michael Griffin, Ken Ono, Larry Rolen, and Don Zagier (GORZ) have recently published a paper on an old approach to the famous Riemann Hypothesis (RH). Today we will discuss their work and its connection to P=NP. Their paper is titled, “Jensen polynomials for […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>A breakthrough on the Riemann Hypothesis</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/06/29/a-prime-breakthrough/gorz/" rel="attachment wp-att-16067"><img alt="" class="alignright size-medium wp-image-16067" height="300" src="https://rjlipton.files.wordpress.com/2019/06/gorz.png?w=261&amp;h=300" width="261"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Composite of various sources ]</font></td>
</tr>
</tbody>
</table>
<p>
Michael Griffin, Ken Ono, Larry Rolen, and Don Zagier (GORZ) have recently published a paper on an old approach to the famous Riemann Hypothesis (RH).</p>
<p>
Today we will discuss their work and its connection to P=NP.</p>
<p>
Their <a href="https://arxiv.org/pdf/1902.07321.pdf">paper</a> is titled, “Jensen polynomials for the Riemann zeta function and other sequences.” The final <a href="https://doi.org/10.1073/pnas.1902572116">version</a> is in the Proceedings of the National Academy of Sciences (PNAS).</p>
<p>
The RH is still open. We are not aware of any update on the status of Michael Atiyah’s claim to have solved it since this <a href="https://blogs.ams.org/blogonmathblogs/2018/10/01/on-michael-atiyah-and-the-riemann-hypothesis/">note</a> on an AMS blog and our own <a href="https://rjlipton.wordpress.com/2018/09/26/reading-into-atiyahs-proof/">discussion</a> of his papers’ contents.</p>
<p>
Recall the RH is a central conjecture in number theory, and it has the following properties: </p>
<ul>
<li>
If true, it would greatly enhance our understanding of the structure of the primes: <img alt="{2,3,5,7,\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%2C3%2C5%2C7%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2,3,5,7,\dots}"/> <p/>
</li><li>
It has resisted attacks for 160 years and counting. <p/>
</li><li>
There are an immense number of statements equivalent to the RH.
</li></ul>
<p>See, for example, the survey <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.66.3584&amp;rep=rep1&amp;type=pdf">paper</a>, “The Riemann Hypothesis,” by Brian Conrey. </p>
<p>
Complexity theory has the P=NP question; number theory has the RH. Both seem to be beyond reach, and both are fundamental questions. The recent work of GORZ has created buzz among number theorists—perhaps they are on the verge of a breakthrough? Is there hope that we might see progress on P=NP? Or must we wait 160 years? </p>
<p>
The buzz is reflected in a May 28 <a href="https://www.livescience.com/65577-riemann-hypothesis-big-step-math.html">story</a> in the online journal <i>LiveScience</i>. It quotes Enrico Bombieri, who wrote the official Clay Prize <a href="https://www.claymath.org/sites/default/files/official_problem_description.pdf">description</a> of RH, as saying:</p>
<blockquote><p><b> </b> <em> “Although this remains far away from proving the Riemann hypothesis, it is a big step forward. There is no doubt that this paper will inspire further fundamental work in other areas of number theory as well as in mathematical physics.” </em>
</p></blockquote>
<p/><p>
Bombieri wrote an accompanying <a href="https://www.pnas.org/content/early/2019/05/22/1906804116">paper</a> in PNAS, in which the above quoted sentences also appear. We will try to explain what the excitement is about.</p>
<p>
</p><p/><h2> The Approach and Results </h2><p/>
<p/><p>
RH is equivalent to the hyperbolicity of Jensen polynomials for the Riemann zeta function. Note: A real, polynomial <img alt="{p(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p(x)}"/> is <i>hyperbolic</i> if all its roots are real—a fancy name for a simple concept.</p>
<p>
There is an analytic function <img alt="{E(z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E(z)}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  RH \iff E(z) \text{ has all real roots}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++RH+%5Ciff+E%28z%29+%5Ctext%7B+has+all+real+roots%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  RH \iff E(z) \text{ has all real roots}. "/></p>
<p>Almost a hundred years ago, Johan Jensen and George Pólya created an approach to the RH based on <img alt="{E(z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E(z)}"/>. Rather than prove <img alt="{E(z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E(z)}"/> has only real roots, they showed it is enough to show that a family of polynomials <img alt="{J(n, d)(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BJ%28n%2C+d%29%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{J(n, d)(x)}"/> all are hyperbolic. The point is that polynomials are “simpler” than analytic functions—at least that is the hope.</p>
<p>
What GORZ prove is this: </p>
<blockquote><p><b>Theorem 1</b> <em> For each <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{d}"/> and almost all <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>, the polynomial <img alt="{J(n, d)(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BJ%28n%2C+d%29%28x%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{J(n, d)(x)}"/> is hyperbolic. </em>
</p></blockquote>
<p>Of course, “almost all” means that there at most a finite number of polynomials that are not hyperbolic. They also show that for degree <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> fixed, 	</p>
<p align="center"><img alt="\displaystyle  \lim_{n \rightarrow \infty} J(n, d)(x) = H_{d}(x). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clim_%7Bn+%5Crightarrow+%5Cinfty%7D+J%28n%2C+d%29%28x%29+%3D+H_%7Bd%7D%28x%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \lim_{n \rightarrow \infty} J(n, d)(x) = H_{d}(x). "/></p>
<p>Where the polynomials <img alt="{H_{d}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH_%7Bd%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H_{d}(x)}"/> have only real roots.</p>
<p>
This is explained further in a <a href="http://people.oregonstate.edu/~petschec/ONTD/Talk1.pdf">talk</a> by Ono, which has this table showing how the polynomials converge:</p>
<p><a href="https://rjlipton.wordpress.com/2019/06/29/a-prime-breakthrough/hyper/" rel="attachment wp-att-16049"><img alt="" class="aligncenter size-medium wp-image-16049" height="187" src="https://rjlipton.files.wordpress.com/2019/06/hyper.png?w=300&amp;h=187" width="300"/></a></p>
<p>Note: they use different notation for the polynomials.</p>
<p>
</p><p/><h2> The Approximation Property </h2><p/>
<p>There are many equivalent formulations of the RH.  While all are equivalent, some are more equivalent than others.  Some seem to be a more plausible path toward a resolution of the RH. Of course to date none have worked. </p>
<p>There is a way to distinguish equivalent formulations of the RH. Suppose that <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> depends on some parameter <img alt="\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta"/>. Suppose that as <img alt="\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta"/> increases the statement <img alt="S(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=S%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S(\beta)"/> becomes a weaker version of the RH.<br/>
Then let us informally say that the formulation <img alt="S(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=S%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S(\beta)"/> has the “Approximation Property” (AP). The point is that progress in proving caes of <img alt="S(\beta)" class="latex" src="https://s0.wp.com/latex.php?latex=S%28%5Cbeta%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S(\beta)"/>—even as partial progress—is exciting. But if the equivalence only holds for <img alt="\beta=0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta=0"/>, with no connections for higher <img alt="\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta"/>, then the partial progress could be seen as morally useful—but it is not really mathematically useful.</p>
<p>There are equivalences of the RH that have AP and some that seem not to have it. The approximation for the RH is natural. The RH states that there is no zero <img alt="\sigma + it" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+%2B+it&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma + it"/> of the Riemann zeta function with <img alt="\sigma" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma"/> above <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/>. The weaker statement: If <img alt="\sigma + it" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+%2B+it&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma + it"/> is a zero, then <img alt="\sigma &gt;  \alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma+%3E++%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sigma &gt;  \alpha"/> is unknown for any <img alt="\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha"/> in the open interval <img alt="(1/2,1)" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2F2%2C1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(1/2,1)"/>. This can be used to get a property with the AP.</p>
<p>For example, this 2003 <a href="http://\href{https://arxiv.org/abs/math/0307215}">paper</a> by Luis Baez-Duarte, titled “A new necessary and sufficient condition for the Riemann hypothesis,” has the AP. He notes, in our terminology, that his property is an AP.</p>
<p/><h2> Open Problems </h2><p/>
<p/><p>
Does the approach of GORZ have the AP? The issue is that while we get a universal statement in terms of <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>, the “all but finitely many” condition on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> works against its being an approximation—what if the finite sets of exceptions grow in terms of <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> in ways that offset the purpose behind the equivalence?</p>
<p/></font></font></div>
    </content>
    <updated>2019-06-29T14:50:42Z</updated>
    <published>2019-06-29T14:50:42Z</published>
    <category term="History"/>
    <category term="Open Problems"/>
    <category term="P=NP"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="hyperbolic"/>
    <category term="PNAS"/>
    <category term="polynomial"/>
    <category term="Proof"/>
    <category term="real roots"/>
    <category term="RH"/>
    <category term="Riemann Hypothesis"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-07-09T13:20:39Z</updated>
    </source>
  </entry>
</feed>
