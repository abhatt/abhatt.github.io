<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-04-22T23:38:33Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4230</id>
    <link href="https://lucatrevisan.wordpress.com/2019/04/22/online-optimization-post-0-definitions/" rel="alternate" type="text/html"/>
    <title>Online Optimization Post 0: Definitions</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Online convex optimization deals with the following setup: we want to design an algorithm that, at each discrete time step , comes up with a solution , where is a certain convex set of feasible solution. After the algorithm has … <a href="https://lucatrevisan.wordpress.com/2019/04/22/online-optimization-post-0-definitions/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
 Online convex optimization deals with the following setup: we want to design an algorithm that, at each discrete time step <img alt="{t=1,2,\ldots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%3D1%2C2%2C%5Cldots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t=1,2,\ldots}"/>, comes up with a solution <img alt="{x_t \in K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_t+%5Cin+K%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_t \in K}"/>, where <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> is a certain convex set of feasible solution. After the algorithm has selected its solution <img alt="{x_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_t}"/>, a convex cost function <img alt="{f_t : K \rightarrow {\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_t+%3A+K+%5Crightarrow+%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_t : K \rightarrow {\mathbb R}}"/>, coming from a known restricted set of admissible cost functions <img alt="{{\cal F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\cal F}}"/>, is revealed, and the algorithm pays the loss <img alt="{f_t (x_t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_t+%28x_t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_t (x_t)}"/>. </p>
<p>
Again, the algorithm has to come up with a solution <em>without knowing what cost functions it is supposed to be optimizing</em>. Furthermore, we will think of the sequence of cost functions <img alt="{f_1,f_2, \ldots,f_t,\ldots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_1%2Cf_2%2C+%5Cldots%2Cf_t%2C%5Cldots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_1,f_2, \ldots,f_t,\ldots}"/> not as being fixed in advanced and unknown to the algorithm, but as being dynamically generated by an adversary, after seeing the solutions provided by the algorithm. (This resilience to adaptive adversaries will be important in most of the applications.)</p>
<p>
The <em>offline optimum</em> after <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> steps is the total cost that the best possible fixed solution would have incurred when evaluated against the cost functions seen by the algorithm, that is, it is a solution to </p>
<p align="center"><img alt="\displaystyle  \min_{x\in K} \ \ \sum_{t=1}^T f_t (x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmin_%7Bx%5Cin+K%7D+%5C+%5C+%5Csum_%7Bt%3D1%7D%5ET+f_t+%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \min_{x\in K} \ \ \sum_{t=1}^T f_t (x) "/></p>
<p>
The <em>regret</em> after <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> steps is the difference between the loss suffered by the algorithm and the offline optimum, that is, </p>
<p/><p align="center"><img alt="\displaystyle  {\rm Regret}_T = \sum_{t=1}^T f_t (x_t) - \min_{x\in K} \ \ \sum_{t=1}^T f_t (x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+Regret%7D_T+%3D+%5Csum_%7Bt%3D1%7D%5ET+f_t+%28x_t%29+-+%5Cmin_%7Bx%5Cin+K%7D+%5C+%5C+%5Csum_%7Bt%3D1%7D%5ET+f_t+%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm Regret}_T = \sum_{t=1}^T f_t (x_t) - \min_{x\in K} \ \ \sum_{t=1}^T f_t (x) "/></p>
<p>
The remarkable results that we will review give algorithms that achieve regret</p>
<p/><p align="center"><img alt="\displaystyle  {\rm Regret}_T \leq O_{K, {\cal F}} (\sqrt T) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+Regret%7D_T+%5Cleq+O_%7BK%2C+%7B%5Ccal+F%7D%7D+%28%5Csqrt+T%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm Regret}_T \leq O_{K, {\cal F}} (\sqrt T) "/></p>
<p> that is, for fixed <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> and <img alt="{{\cal F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\cal F}}"/>, the regret-per-time-step goes to zero with the number of steps, as <img alt="{O\left( \frac 1 {\sqrt T} \right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%5Cleft%28+%5Cfrac+1+%7B%5Csqrt+T%7D+%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O\left( \frac 1 {\sqrt T} \right)}"/>. It is intuitive that our bounds will have to depend on how big is the “diameter” of <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{K}"/> and how large is the “magnitude” and “smoothness” of the functions <img alt="{f\in {\cal F}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Cin+%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\in {\cal F}}"/>, but depending on how we choose to formalize these quantities we will be led to define different algorithms. </p>
<p/></div>
    </content>
    <updated>2019-04-22T21:35:44Z</updated>
    <published>2019-04-22T21:35:44Z</published>
    <category term="theory"/>
    <category term="online optimization"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-04-22T23:20:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15778</id>
    <link href="https://rjlipton.wordpress.com/2019/04/21/pnp-proofs/" rel="alternate" type="text/html"/>
    <title>P=NP Proofs</title>
    <summary>Advice to claimers The Claimers The Claimers are a gang on the hit AMC television series The Walking Dead. They are the main antagonists in the second half of the zombie-apocalypse show’s Season 4. According to Wikipedia’s description, they “live by the philosophy of ‘claiming’.” Today Ken and I discuss issues about ‘claiming’ and give […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Advice to claimers</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/04/21/pnp-proofs/claimers3/" rel="attachment wp-att-15790"><img alt="" class="alignright size-medium wp-image-15790" height="191" src="https://rjlipton.files.wordpress.com/2019/04/claimers3.png?w=300&amp;h=191" width="300"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><a href="https://the-walking-dead-tvseries.fandom.com/wiki/The_Claimers">The Claimers</a></font></td>
</tr>
</tbody>
</table>
<p>
The Claimers are a gang on the hit AMC television <a href="https://en.wikipedia.org/wiki/The_Walking_Dead_(TV_series)">series</a> <em>The Walking Dead</em>. They are the main antagonists in the second half of the zombie-apocalypse show’s Season 4. According to Wikipedia’s <a href="https://en.wikipedia.org/wiki/The_Walking_Dead_(season_4)#The_Claimers">description</a>, they “live by the philosophy of ‘claiming’.”</p>
<p>
Today Ken and I discuss issues about ‘claiming’ and give advice on how to present your claims—or not.</p>
<p>
Yes, this post is about our own “claimers” in complexity theory. It is especially about those who claim to have a solution to P=NP. We will not give any names today. You know who you are.</p>
<p>
The TV Claimers meet a grisly end. We will not say any more about it. We want to be nice. But we would like to not keep seeing the same level of zombie claims raised again and again.</p>
<p>
<b>Please: Do not stop reading.</b> Yes we know that it is likely that no claimer really has such a proof. However, our suggestions apply to all of us when we have a non-trivial result. Especially a result that has been open, even if the result is not a major open problem. So please keep reading today.</p>
<p>
</p><p/><h2> So You Can Prove P=NP </h2><p/>
<p/><p>
This is a list of ideas for anyone who claims to have solved P=NP or some similar hard open problem in mathematics. There are already lots of suggestions online about what you should do, so this is just a list of additional thoughts. We hope they are helpful.</p>
<p>
</p><p/><h3> You are being pretty arrogant </h3><p/>
<p/><p>
In order to succeed in mathematics research one has to be a bit arrogant. It is quite difficult to prove new things without some swagger. However, proving or resolving P=NP requires a very non-humble attitude. I think many claimers have not thought how arrogant they are being. The P=NP problem is a huge open problem. Thousands and thousands of researchers have spent years thinking about it. Why do you, the claimer, think you see the light and we remain in the dark?</p>
<p>
It might be useful for the claimers to ponder: <i>Why did I succeed where all others have failed?</i> It might be useful to be a bit humble and at least think what did they see that we all missed? If they can say something like:</p>
<blockquote><p><b> </b> <em> The reason I succeeded in finding an algorithm for P=NP is that I noticed that <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\dots}"/> No one else seems to see that this insight is very powerful. It is very useful since it implies <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\dots}"/> </em>
</p></blockquote>
<p>
</p><p/><h3> Working alone </h3><p/>
<p/><p>
I think the vast majority of claimers of P=NP or other big results have almost always worked alone. This is okay, but the average number of authors these days of a theory paper is pretty large. So any paper that is sole authored, perhaps, leads the community think it is unusual—and is wrong. Another point is that being part of a team may help control the arrogance. It can also be invaluable in detecting errors. </p>
<p>
</p><p/><h3> Show them the money </h3><p/>
<p/><p>
There is an advantage in “proving” P=NP over other major problems. There is the Clay prize of a million dollars. I wonder if claimers could use the prize money in some interesting way. How about saying: If you read the my proof and repair it or make it more readable and it is correct, then you get something. A certain dollar amount. Or a percentage of the prize. Or—you get the idea.</p>
<p>
</p><p/><h3> The role of code </h3><p/>
<p/><p>
Many claimers have also supplied working code for their algorithm. That is they also supply a program that claims to solve some NP-complete problem. I have several thoughts about this. In some cases it seems that it could be possible to have code that works for small size problems, but not in the general case. This seems to be possible for the claims by some that they can solve the Traveling Salesman Problem, for example. Their algorithm could be correct for small instances.</p>
<p>
Mathematics is filled with surprises like: This effect works for all values of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> less than some bound. If the claimers give a program, our expectation based on experience is that it may work for small cases but will probably fail in general. </p>
<p>
The last point is that working code could actually be valuable. If the code can be used to solve SAT problems how about using your program to enter a SAT contest and win it. A win, or even a good showing, would help tremendously in convincing people to read the paper. Or use the code to break some known cryptosystem. That would also convince people that they need to read your paper.</p>
<p>
</p><p/><h2> Writing Your Paper </h2><p/>
<p/><p>
Okay we all dream about solving a major open problem. Or even a minor one. Here we give an outline of how to write up such a paper. </p>
<p/><h3> How to write up the proof </h3><p/>
<p>
I would suggest that you not have any statements about why P=NP is an important problem. None. No history of the problem. No literature survey is needed. None. You goal is to get an expert to read and believe the proof. They will just skip over the above. Also please no statements of how your algorithm that solves P=NP is going to change the world. Just give us the proof.</p>
<p>
</p><p/><h3> How to get them to read the proof </h3><p/>
<p/><p>
This is really hard. Hard. I have read a number of claimers’ papers. I try to be helpful. However, many of us do not have the time to look at such papers. Years ago, before Fermat’s Last Theorem was solved, a famous mathematician once made up a post-card that looked like this:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/04/21/pnp-proofs/postcard/" rel="attachment wp-att-15784"><img alt="" class="aligncenter size-medium wp-image-15784" height="221" src="https://rjlipton.files.wordpress.com/2019/04/postcard.png?w=300&amp;h=221" width="300"/></a></p>
<p>
I think that we all have a mental version of this card. There are definitely ways to help induce someone to read a paper and its proof. Look at some recent top theory papers. Even the authors of these papers, often well known authors, work hard to motivate potential readers. The authors often do several things:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>They often sketch the proof.</em> By leaving out details they may help get a reader interested. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>They often explain the new trick—or tricks.</em> The goal here is to explain some new insight that is used in the proof. We are very self-oriented: If I see that your new trick could be useful in my research that is a huge motivator for me to understand the proof. People are very excited about a strong result, but they are even more excited about a new trick. Explain what is new in your proof. If there is nothing new, no new trick or method, then hmmmm<img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/></p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <em>They often first prove a weaker result.</em> That is, they show that their method can already make progress. If you could prove that the zeta function has all its nontrivial zeros on the critical line, that would be apocalyptic—the famous Riemann Hypothesis, of course. But if you could merely prove that there is no zero in some new region, then that would still be <em>wonderful</em>. And also probably more believable. If you could prove that there is no zero <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/> with its real part <img alt="{0.99999}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0.99999%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0.99999}"/> that would be huge. If the proof of this is simpler, then use it to get readers excited about your full result. </p>
<p>
An observation related to the last point is: </p>
<blockquote><p><b> </b> <em> <i>Why do all claims of progress on P=NP give a polynomial time bound?</i> </em>
</p></blockquote>
<p>How about just getting a better bound of say <img alt="{2^{n/10}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn%2F10%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{n/10}}"/> for the Traveling Salesman Problem? Or a better bound for factoring? Or a better bound for your favorite problem?</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p>I hope these points help. One last pointer is to double-check dependencies. If your proof relies on a result by someone else, make sure the result really gives what you need. Terms may be defined differently from what you expect, or you may really need a feature of the proof rather than the mere statement. A mis-attributed result can become “undead.”</p></font></font></div>
    </content>
    <updated>2019-04-22T03:25:39Z</updated>
    <published>2019-04-22T03:25:39Z</published>
    <category term="Open Problems"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="claimed proofs"/>
    <category term="claims"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-04-22T23:36:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09284</id>
    <link href="http://arxiv.org/abs/1904.09284" rel="alternate" type="text/html"/>
    <title>Stochastic Online Metric Matching</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Anupam.html">Anupam Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guruganesh:Guru.html">Guru Guruganesh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Binghui.html">Binghui Peng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wajc:David.html">David Wajc</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09284">PDF</a><br/><b>Abstract: </b>We study the minimum-cost metric perfect matching problem under online i.i.d
arrivals. We are given a fixed metric with a server at each of the points, and
then requests arrive online, each drawn independently from a known probability
distribution over the points. Each request has to be matched to a free server,
with cost equal to the distance. The goal is to minimize the expected total
cost of the matching.
</p>
<p>Such stochastic arrival models have been widely studied for the maximization
variants of the online matching problem; however, the only known result for the
minimization problem is a tight $O(\log n)$-competitiveness for the
random-order arrival model. This is in contrast with the adversarial model,
where an optimal competitive ratio of $O(\log n)$ has long been conjectured and
remains a tantalizing open question.
</p>
<p>In this paper, we show improved results in the i.i.d arrival model. We show
how the i.i.d model can be used to give substantially better algorithms: our
main result is an $O((\log \log \log n)^2)$-competitive algorithm in this
model. Along the way we give a $9$-competitive algorithm for the line and tree
metrics. Both results imply a strict separation between the i.i.d model and the
adversarial and random order models, both for general metrics and these
much-studied metrics.
</p></div>
    </summary>
    <updated>2019-04-22T23:22:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09266</id>
    <link href="http://arxiv.org/abs/1904.09266" rel="alternate" type="text/html"/>
    <title>Secure and secret cooperation of robotic swarms by using Merkle trees</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Ferrer:Eduardo_Castell=oacute=.html">Eduardo Castelló Ferrer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hardjono:Thomas.html">Thomas Hardjono</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pentland:Alex.html">Alex Pentland</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09266">PDF</a><br/><b>Abstract: </b>Swarm robotics systems are envisioned to become an important component of
both academic research and real-world applications. However, in order to reach
widespread adoption, new models that ensure the secure cooperation of these
systems need to be developed. This work proposes a novel model to encapsulate
cooperative robotic missions in Merkle trees, one of the fundamental components
of blockchain technology. With the proposed model, swarm operators can provide
the "blueprint" of the swarm's mission without disclosing raw data about the
mission itself. In other words, data verification can be separated from data
itself. We propose a system where swarm robots have to "prove" their integrity
to their peers by exchanging cryptographic proofs. This work analyzes and tests
the proposed approach for two different robotic missions: foraging (where
robots modify the environment) and maze formation (where robots become part of
the environment). In both missions, robots were able to cooperate and carry out
sequential operations in the correct order without having explicit knowledge
about the mission's high-level goals or objectives. The performance,
communication costs, and information diversity requirements for the proposed
approach are analyzed. Finally, conclusions are drawn and future work
directions are suggested.
</p></div>
    </summary>
    <updated>2019-04-22T23:24:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09265</id>
    <link href="http://arxiv.org/abs/1904.09265" rel="alternate" type="text/html"/>
    <title>SSRGD: Simple Stochastic Recursive Gradient Descent for Escaping Saddle Points</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Zhize.html">Zhize Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09265">PDF</a><br/><b>Abstract: </b>We analyze stochastic gradient algorithms for optimizing nonconvex problems.
In particular, our goal is to find local minima (second-order stationary
points) instead of just finding first-order stationary points which may be some
bad unstable saddle points. We show that a simple perturbed version of
stochastic recursive gradient descent algorithm (called SSRGD) can find an
$(\epsilon,\delta)$-second-order stationary point with
$\widetilde{O}(\sqrt{n}/\epsilon^2 + \sqrt{n}/\delta^4 + n/\delta^3)$
stochastic gradient complexity for nonconvex finite-sum problems. As a
by-product, SSRGD finds an $\epsilon$-first-order stationary point with
$O(n+\sqrt{n}/\epsilon^2)$ stochastic gradients. These results are almost
optimal since Fang et al. [2018] provided a lower bound
$\Omega(\sqrt{n}/\epsilon^2)$ for finding even just an $\epsilon$-first-order
stationary point. We emphasize that SSRGD algorithm for finding second-order
stationary points is as simple as for finding first-order stationary points
just by adding a uniform perturbation sometimes, while all other algorithms for
finding second-order stationary points with similar gradient complexity need to
combine with a negative-curvature search subroutine (e.g., Neon2 [Allen-Zhu and
Li, 2018]). Moreover, the simple SSRGD algorithm gets a simpler analysis.
Besides, we also extend our results from nonconvex finite-sum problems to
nonconvex online (expectation) problems, and prove the corresponding
convergence results.
</p></div>
    </summary>
    <updated>2019-04-22T23:30:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09246</id>
    <link href="http://arxiv.org/abs/1904.09246" rel="alternate" type="text/html"/>
    <title>On the fixed-parameter tractability of the maximum 2-edge-colorable subgraph problem</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aloisio:Alessandro.html">Alessandro Aloisio</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mkrtchyan:Vahan.html">Vahan Mkrtchyan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09246">PDF</a><br/><b>Abstract: </b>A $k$-edge-coloring of a graph is an assignment of colors $\{1,...,k\}$ to
edges of the graph such that adjacent edges receive different colors. In the
maximum $k$-edge-colorable subgraph problem we are given a graph and an integer
$k$, the goal is to find a $k$-edge-colorable subgraph with maximum number of
edges together with its $k$-edge-coloring. In this paper, we consider the
maximum 2-edge-colorable subgraph problem and present some results that deal
with the fixed-parameter tractability of this problem.
</p></div>
    </summary>
    <updated>2019-04-22T23:20:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09228</id>
    <link href="http://arxiv.org/abs/1904.09228" rel="alternate" type="text/html"/>
    <title>Uncertainty about Uncertainty: Near-Optimal Adaptive Algorithms for Estimating Binary Mixtures of Unknown Coins</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Jasper_C=_H=.html">Jasper C. H. Lee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Valiant:Paul.html">Paul Valiant</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09228">PDF</a><br/><b>Abstract: </b>Given a mixture between two populations of coins, "positive" coins that have
(unknown and potentially different) probabilities of heads
$\geq\frac{1}{2}+\Delta$ and negative coins with probabilities
$\leq\frac{1}{2}-\Delta$, we consider the task of estimating the fraction
$\rho$ of coins of each type to within additive error $\epsilon$. We introduce
new techniques to show a fully-adaptive lower bound of
$\Omega(\frac{\rho}{\epsilon^2\Delta^2})$ samples (for constant probability of
success). We achieve almost-matching algorithmic performance of
$O(\frac{\rho}{\epsilon^2\Delta^2}(1+\rho\log\frac{1}{\epsilon}))$ samples,
which matches the lower bound except in the regime where
$\rho=\omega(\frac{1}{\log 1/\epsilon})$. The fine-grained adaptive flavor of
both our algorithm and lower bound contrasts with much previous work in
distributional testing and learning.
</p></div>
    </summary>
    <updated>2019-04-22T23:30:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09222</id>
    <link href="http://arxiv.org/abs/1904.09222" rel="alternate" type="text/html"/>
    <title>Tight Bounds for Online Edge Coloring</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen:Ilan_Reuven.html">Ilan Reuven Cohen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Binghui.html">Binghui Peng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wajc:David.html">David Wajc</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09222">PDF</a><br/><b>Abstract: </b>Vizing's celebrated theorem asserts that any graph of maximum degree $\Delta$
admits an edge coloring using at most $\Delta+1$ colors. In contrast, Bar-Noy,
Naor and Motwani showed over a quarter century that the trivial greedy
algorithm, which uses $2\Delta-1$ colors, is optimal among online algorithms.
Their lower bound has a caveat, however: it only applies to low-degree graphs,
with $\Delta=O(\log n)$, and they conjectured the existence of online
algorithms using $\Delta(1+o(1))$ colors for $\Delta=\omega(\log n)$. Progress
towards resolving this conjecture was only made under stochastic arrivals
(Aggarwal et al., FOCS'03 and Bahmani et al., SODA'10).
</p>
<p>We resolve the above conjecture for \emph{adversarial} vertex arrivals in
bipartite graphs, for which we present a $(1+o(1))\Delta$-edge-coloring
algorithm for $\Delta=\omega(\log n)$ known a priori. Surprisingly, if $\Delta$
is not known ahead of time, we show that no $\big(\frac{e}{e-1} - \Omega(1)
\big) \Delta$-edge-coloring algorithm exists. We then provide an optimal,
$\big(\frac{e}{e-1}+o(1)\big)\Delta$-edge-coloring algorithm for unknown
$\Delta=\omega(\log n)$. Key to our results, and of possible independent
interest, is a novel fractional relaxation for edge coloring, for which we
present optimal fractional online algorithms and a near-lossless online
rounding scheme, yielding our optimal randomized algorithms.
</p></div>
    </summary>
    <updated>2019-04-22T23:21:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09216</id>
    <link href="http://arxiv.org/abs/1904.09216" rel="alternate" type="text/html"/>
    <title>Beyond Submodular Maximization</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghadiri:Mehrdad.html">Mehrdad Ghadiri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santiago:Richard.html">Richard Santiago</a>, Bruce Shepherd <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09216">PDF</a><br/><b>Abstract: </b>While there are well-developed tools for maximizing a submodular function
subject to a matroid constraint, there is much less work on the corresponding
supermodular maximization problems. We develop new techniques for attacking
these problems inspired by the continuous greedy method applied to the
multi-linear extension of a submodular function. We first adapt the continuous
greedy algorithm to work for general twice-continuously differentiable
functions. The performance of the adapted algorithm depends on a new smoothness
parameter. If $F:[0,1]^n\rightarrow\mathbb{R}_{\geq 0}$ is one-sided
$\sigma$-smooth, then the approximation factor only depends on $\sigma$. We
apply the new algorithm to a broad class of quadratic supermodular functions
arising in diversity maximization. The case $\sigma=2$ captures metric
diversity maximization. We also develop new methods (inspired by swap rounding
and approximate integer decomposition) for rounding quadratics over a matroid
polytope. Together with the adapted continuous greedy this leads to a
$O(\sigma^{3/2})$-approximation. This is the best asymptotic approximation
known for this class of diversity maximization and the evidence suggests that
it may be tight.
</p>
<p>We then consider general (non-quadratic) functions. We give a broad
parameterized family of monotone functions which include submodular functions
and the just-discussed supermodular family of discrete quadratics. Such set
functions are called \emph{$\gamma$-meta-submodular}. We develop local search
algorithms with approximation factors that depend only on $\gamma$. We show
that the $\gamma$-meta-submodular families include well-known function classes
including meta-submodular functions ($\gamma=0$), proportionally submodular
($\gamma=1$), and diversity functions based on negative-type distances or
Jensen-Shannon divergence (both $\gamma=2$) and (semi-)metric diversity
functions.
</p></div>
    </summary>
    <updated>2019-04-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.09142</id>
    <link href="http://arxiv.org/abs/1904.09142" rel="alternate" type="text/html"/>
    <title>An Efficient Algorithm for the Fast Delivery Problem</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carvalho:Iago_A=.html">Iago A. Carvalho</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Erlebach:Thomas.html">Thomas Erlebach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Papadopoulos:Kleitos.html">Kleitos Papadopoulos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.09142">PDF</a><br/><b>Abstract: </b>We study a problem where k autonomous mobile agents are initially located on
distinct nodes of a weighted graph (with n nodes and m edges). Each autonomous
mobile agent has a predefined velocity and is only allowed to move along the
edges of the graph. We are interested in delivering a package, initially
positioned in a source node s, to a destination node y. The delivery is
achieved by the collective effort of the autonomous mobile agents, which can
carry and exchange the package among them. The objective is to compute a
delivery schedule that minimizes the delivery time of the package. In this
paper, we propose an O(kn log(kn) + k m) time algorithm for this problem. This
improves the previous state-of-the-art O(k^2 m + k n^2 + APSP) time algorithm
for this problem, where APSP stands for the running-time of an algorithm for
the All-Pairs Shortest Paths problem.
</p></div>
    </summary>
    <updated>2019-04-22T23:30:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08954</id>
    <link href="http://arxiv.org/abs/1904.08954" rel="alternate" type="text/html"/>
    <title>A Conditional Lower Bound on Graph Connectivity in MapReduce</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Im:Sungjin.html">Sungjin Im</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moseley:Benjamin.html">Benjamin Moseley</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08954">PDF</a><br/><b>Abstract: </b>MapReduce (and its open source implementation Hadoop) has become the de facto
platform for processing large data sets. MapReduce offers a streamlined
computational framework by interleaving sequential and parallel computation
while hiding underlying system issues from the programmer. Due to the
popularity of MapReduce, there have been attempts in the theoretical computer
science community to understand the power and limitations of the MapReduce
framework. In the most widely studied MapReduce models each machine has memory
sub-linear in the input size to the problem, hence cannot see the entire input.
This restriction places many limitations on algorithms that can be developed
for the model; however, the current understanding of these restrictions is
still limited.
</p>
<p>In this paper, our goal is to work towards understanding problems which do
not admit efficient algorithms in the MapReduce model. We study the basic
question of determining if a graph is connected or not. We concentrate on
instances of this problem where an algorithm is to determine if a graph
consists of a single cycle or two disconnected cycles. In this problem, locally
every part of the graph is similar and the goal is to determine the global
structure of the graph. We consider a natural class of algorithms that can
store/process/transfer the information only in the form of paths and show that
no randomized algorithm cannot answer the decision question in a
sub-logarithmic number of rounds. Currently, there are no absolute super
constant lower bounds on the number of rounds known for any problem in
MapReduce. We introduce some of the first lower bounds for a natural graph
problem, albeit for a restricted class of algorithms. We believe our result
makes progress towards understanding the limitations of MapReduce.
</p></div>
    </summary>
    <updated>2019-04-22T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08934</id>
    <link href="http://arxiv.org/abs/1904.08934" rel="alternate" type="text/html"/>
    <title>Convex Graph Invariant Relaxations For Graph Edit Distance</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Candogan:Utkan_Onur.html">Utkan Onur Candogan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chandrasekaran:Venkat.html">Venkat Chandrasekaran</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08934">PDF</a><br/><b>Abstract: </b>The edit distance between two graphs is a widely used measure of similarity
that evaluates the smallest number of vertex and edge deletions/insertions
required to transform one graph to another. It is NP-hard to compute in
general, and a large number of heuristics have been proposed for approximating
this quantity. With few exceptions, these methods generally provide upper
bounds on the edit distance between two graphs. In this paper, we propose a new
family of computationally tractable convex relaxations for obtaining lower
bounds on graph edit distance. These relaxations can be tailored to the
structural properties of the particular graphs via convex graph invariants.
Specific examples that we highlight in this paper include constraints on the
graph spectrum as well as (tractable approximations of) the stability number
and the maximum-cut values of graphs. We prove under suitable conditions that
our relaxations are tight (i.e., exactly compute the graph edit distance) when
one of the graphs consists of few eigenvalues. We also validate the utility of
our framework on synthetic problems as well as real applications involving
molecular structure comparison problems in chemistry.
</p></div>
    </summary>
    <updated>2019-04-22T23:31:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08845</id>
    <link href="http://arxiv.org/abs/1904.08845" rel="alternate" type="text/html"/>
    <title>Planar Point Sets Determine Many Pairwise Crossing Segments</title>
    <feedworld_mtime>1555891200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pach:J=aacute=nos.html">János Pach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rubin:Natan.html">Natan Rubin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tardos:G=aacute=bor.html">Gábor Tardos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08845">PDF</a><br/><b>Abstract: </b>We show that any set of $n$ points in general position in the plane
determines $n^{1-o(1)}$ pairwise crossing segments. The best previously known
lower bound, $\Omega\left(\sqrt n\right)$, was proved more than 25 years ago by
Aronov, Erd\H os, Goddard, Kleitman, Klugerman, Pach, and Schulman. Our proof
is fully constructive, and extends to dense geometric graphs.
</p></div>
    </summary>
    <updated>2019-04-22T23:32:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-04-22T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/062</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/062" rel="alternate" type="text/html"/>
    <title>TR19-062 |  Quantum Lower Bounds for Approximate Counting via Laurent Polynomials | 

	Scott Aaronson, 

	Robin Kothari, 

	William Kretschmer, 

	Justin Thaler</title>
    <summary>This paper proves new limitations on the power of quantum computers to solve approximate counting---that is, multiplicatively estimating the size of a nonempty set $S\subseteq [N]$.

Given only a membership oracle for $S$, it is well known that approximate counting takes $\Theta(\sqrt{N/|S|})$ quantum queries. But what if a quantum algorithm is also given "QSamples"---i.e., copies of the state $|S\rangle = \sum_{i\in S}|i\rangle$---or even the ability to apply reflections about $|S\rangle$? Our first main result is that, even then, the algorithm needs either $\Theta(\sqrt{N/|S|})$ queries or else $\Theta(\min\{|S|^{1/3},\sqrt{N/|S|}\})$ reflections or samples. We also give matching upper bounds.

We prove the lower bound using a novel generalization of the polynomial method of Beals et al. to Laurent polynomials, which can have negative exponents. We lower-bound Laurent polynomial degree using two methods: a new "explosion argument" and a new formulation of the dual polynomials method.

Our second main result rules out the possibility of a black-box Quantum Merlin-Arthur (or QMA) protocol for proving that a set is large. We show that, even if Arthur can make $T$ quantum queries to the set $S$, and also receives an $m$-qubit quantum witness from Merlin in support of $S$ being large, we have $Tm=\Omega(\min\{|S|,\sqrt{N/|S|}\})$. This resolves the open problem of giving an oracle separation between SBP and QMA.

Note that QMA is "stronger" than the queries+QSamples model in that Merlin's witness can be anything, rather than just the specific state $|S\rangle$, but also "weaker" in that Merlin's witness cannot be trusted. Intriguingly, Laurent polynomials also play a crucial role in our QMA lower bound, but in a completely different manner than in the queries+QSamples lower bound. This suggests that the "Laurent polynomial method" might be broadly useful in complexity theory.</summary>
    <updated>2019-04-21T13:57:29Z</updated>
    <published>2019-04-21T13:57:29Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-22T23:36:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/061</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/061" rel="alternate" type="text/html"/>
    <title>TR19-061 |  A Quantum Query Complexity Trichotomy for Regular Languages | 

	Daniel Grier, 

	Luke Schaeffer, 

	Scott Aaronson</title>
    <summary>We present a trichotomy theorem for the quantum query complexity of regular languages. Every regular language has quantum query complexity $\Theta(1)$, $\tilde{\Theta}(\sqrt n)$, or $\Theta(n)$. The extreme uniformity of regular languages prevents them from taking any other asymptotic complexity. This is in contrast to even the context-free languages, which we show can have query complexity $\Theta(n^c)$ for all computable $c \in [1/2,1]$. Our result implies an equivalent trichotomy for the approximate degree of regular languages, and a dichotomy---either $\Theta(1)$ or $\Theta(n)$---for sensitivity, block sensitivity, certificate complexity, deterministic query complexity, and randomized query complexity.

The heart of the classification theorem is an explicit quantum algorithm which decides membership in any star-free language in $\tilde{O}(\sqrt n)$ time. This well-studied family of the regular languages admits many interesting characterizations, for instance, as those languages expressible as sentences in first-order logic over the natural numbers with the less-than relation. Therefore, not only do the star-free languages capture functions such as OR, they can also express functions such as ``there exist a pair of 2's such that everything between them is a 0."  

Thus, we view the algorithm for star-free languages as a nontrivial generalization of Grover's algorithm which extends the quantum quadratic speedup to a much wider range of string-processing algorithms than was previously known.  We show a variety of applications---new quantum algorithms for dynamic constant-depth Boolean formulas, balanced parentheses nested constantly many levels deep, binary addition, a restricted word break problem, and path-discovery in narrow grids---all obtained as immediate consequences of our classification theorem.</summary>
    <updated>2019-04-21T13:56:47Z</updated>
    <published>2019-04-21T13:56:47Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-22T23:36:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17317</id>
    <link href="https://gilkalai.wordpress.com/2019/04/21/the-random-matrix-and-more/" rel="alternate" type="text/html"/>
    <title>The (Random) Matrix and more</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Three pictures, and a few related links. Van Vu Spoiler: In one of the most intense scenes, the protagonist, with his bare hands and against all odds, took care of the mighty Wigner semi-circle law in two different ways. (From … <a href="https://gilkalai.wordpress.com/2019/04/21/the-random-matrix-and-more/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Three pictures, and a few related links.</p>
<h3>Van Vu</h3>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/thematrixvv.jpg"><img alt="" class="alignnone size-full wp-image-17318" height="989" src="https://gilkalai.files.wordpress.com/2019/04/thematrixvv.jpg?w=640&amp;h=989" width="640"/></a></p>
<p><span style="color: #ff0000;">Spoiler: In one of the most intense scenes, the protagonist, with his bare hands and against all odds, took care of the mighty Wigner semi-circle law in two different ways. (From VV’s FB)</span></p>
<p><a href="https://math.virginia.edu/ims/lectures/van-vu/">More information on Van Vu’s series of lectures</a>. <a href="http://campuspress.yale.edu/vanvu/">Van Vu’s home page</a>; Related posts: <a href="https://www.scottaaronson.com/blog/?p=3482">did physicists really just prove that the universe is not a computer simulation—that we can’t be living in the Matrix?</a> (Shtetl-Optimized); A <a href="https://terrytao.wordpress.com/2012/02/02/random-matrices-the-universality-phenomenon-for-wigner-ensembles/">related 2012 post</a> on What’s New;</p>
<p>Two more pictures the first also from FB<span id="more-17317"/></p>
<h3>Saharon Shelah</h3>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/saharon75.jpg"><img alt="" class="alignnone size-full wp-image-17320" height="498" src="https://gilkalai.files.wordpress.com/2019/04/saharon75.jpg?w=640&amp;h=498" width="640"/></a></p>
<p>Shaharon Shelah ICM 1974 (Vancouver) (Mohammad Golshani over FB)</p>
<p>See my post <a href="https://gilkalai.wordpress.com/2012/01/18/a-theorem-about-infinite-cardinals-everybody-should-know/" rel="bookmark">A theorem about infinite cardinals everybody should know</a>; Gowers’s post <a href="https://gowers.wordpress.com/2017/09/19/two-infinities-that-are-surprisingly-equal/">Two infinities that are surprisingly equal </a>about a recent breakthrough result by <a href="https://en.wikipedia.org/wiki/Maryanthe_Malliaris">Maryanthe Malliaris</a> and <a href="https://en.wikipedia.org/wiki/Saharon_Shelah">Saharon Shelah</a>; and <a href="https://arxiv.org/abs/1806.04917">a recent 4-page solution to a conjecture of Spencer</a> on finitary Hindman numbers by <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Mohsenipour%2C+S">Shahram Mohsenipour</a> and Shelah.  More information on the last paper: (1) It is an Iranian-Israeli collaboration (2) Spencer asked Shelah the question during the workshop: Combinatorics: Challenges and Applications, celebrating Noga Alon’s <a href="https://gilkalai.wordpress.com/2015/08/10/nogafest-nogaformulas-and-amazing-cash-prizes/">60th birthday</a>, Tel Aviv University, January 17-21, 2016. (3) This is paper 1146 in Shelah’s (main) <a href="http://shelah.logic.at/">list of publications</a>. Shelah’s 1974 lecture was called “Why There Are Many Nonisomorphic Models for Unsuperstable Theories.”</p>
<h3>Sándor Szalai,  Catherine Rényi, Alfréd Rényi András Hajnal and Paul Erdős</h3>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/matrahazaszalairenyihajnalerdos1958.jpg"><img alt="" class="alignnone size-full wp-image-17314" height="434" src="https://gilkalai.files.wordpress.com/2019/04/matrahazaszalairenyihajnalerdos1958.jpg?w=640&amp;h=434" width="640"/></a></p>
<p>From left: Sándor Szalai,  Catherine Rényi, Alfréd Rényi, András Hajnal and Paul Erdős (Matrahaza ) The picture is from Janos Pach’s Lancaster lecture, who also discussed how Szalai came up with Ramsey’s theorem. (See also Noga Alon and Michel Krivelevich’s chapter <a href="http://www.cs.tau.ac.il/~nogaa/PDFS/epc7.pdf" rel="noopener" target="_blank" title="opens in a new window">Extremal and Probabilistic Combinatorics, In: Princeton Companion to Mathematics, W. T. Gowers, Ed., Princeton University Press 2008, pp. 562-575.</a>)</p>
<p>In the course of an examination of friendship between children some fifty years ago, the Hungarian sociologist Sandor Szalai observed that among any group of about twenty children he checked he could always find four children any two of whom were friends, or else four children no two of whom were friends. Despite the temptation to try to draw sociological conclusions, Szalai realized that this might well be a mathematical phenomenon rather than sociological one.  He got interested in the problem, discussed it with  Erdős, Rényi , and Turán and in a short time he came up with a number of interesting constructions. In fact, he obtained record lower bound estimates for several Ramsey numbers.</p>
<p>(Janos’ further remarks: “Sandor (Alexander) Szalai was a well known Hungarian sociologist and a famously bright and witty man. I am not sure whether he was the first to notice and study the the laws of clique- and anti-clique formation among groups of schoolchildren, but I suspect that he was not. The sociology of small groups used to be a popular alternative to more “dangerous” Marxist theories of classes in the 50-ies and 60-ies. My guess would be that Szalai discussed these issues and was fascinated by this subject some time around 1960. It is fair to say that he independently<em> conjectured</em> Ramsey’s theorem.”)</p></div>
    </content>
    <updated>2019-04-21T06:33:41Z</updated>
    <published>2019-04-21T06:33:41Z</published>
    <category term="Combinatorics"/>
    <category term="People"/>
    <category term="What is Mathematics"/>
    <category term="Alfr&#xE9;d R&#xE9;nyi"/>
    <category term="Andr&#xE1;s Hajnal"/>
    <category term="Catherine R&#xE9;nyi"/>
    <category term="Paul Erdos"/>
    <category term="Saharon Shelah"/>
    <category term="S&#xE1;ndor Szalai"/>
    <category term="Van Vu"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-04-22T23:36:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4172</id>
    <link href="https://www.scottaaronson.com/blog/?p=4172" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4172#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4172" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Not yet retired from research</title>
    <summary xml:lang="en-US">Last night, two papers appeared on the quantum physics arXiv that my coauthors and I have been working on for more than a year, and that I’m pretty happy about. The first paper, with Guy Rothblum, is Gentle Measurement of Quantum States and Differential Privacy (85 pages, to appear in STOC’2019). This is Guy’s first […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Last night, two papers appeared on the quantum physics arXiv that my coauthors and I have been working on for more than a year, and that I’m pretty happy about.</p>



<p>The first paper, with Guy Rothblum, is <a href="https://arxiv.org/abs/1904.08747">Gentle Measurement of Quantum States and Differential Privacy</a> (85 pages, to appear in STOC’2019).  This is Guy’s first paper that has anything to do with quantum, and also my first paper that has anything to do with privacy.  (What do I care about privacy?  I just share everything on this blog…)  The paper has its origin when I gave a talk at the Weizmann Institute about “shadow tomography” (a task where you have to measure quantum states very carefully to avoid destroying them), and Guy was in the audience, and he got all excited that the techniques sounded just like what they use to ensure privacy in data-mining, and I figured it was just some wacky coincidence and brushed him off, but he persisted, and it turned out that he was 100% right, and our two fields were often studying the same problems from different angles and we could prove it.  Anyway, here’s the abstract:</p>



<blockquote>In <i>differential privacy (DP)</i>, we want to query a database about n users, in a way that “leaks at most ε about any individual user,” even conditioned on any outcome of the query.  Meanwhile, in <i>gentle measurement</i>, we want to measure n quantum states, in a way that “damages the states by at most α,” even conditioned on any outcome of the measurement.  In both cases, we can achieve the goal by techniques like deliberately adding noise to the outcome before returning it.  This paper proves a new and general connection between the two subjects.  Specifically, we show that on products of n quantum states, any measurement that is α-gentle for small α is also O(α)-DP, and any product measurement that is ε-DP is also O(ε√n)-gentle.
<p>Illustrating the power of this connection, we apply it to the recently studied problem of <i>shadow tomography</i>.  Given an unknown d-dimensional quantum state ρ, as well as known two-outcome measurements E<sub>1</sub>,…,E<sub>m</sub>, shadow tomography asks us to estimate Pr[E<sub>i</sub> accepts ρ], for <i>every</i> i∈[m], by measuring few copies of ρ.  Using our connection theorem, together with a quantum analog of the so-called <i>private multiplicative weights</i> algorithm of Hardt and Rothblum, we give a protocol to solve this problem using O((log m)<sup>2</sup>(log d)<sup>2</sup>) copies of ρ, compared to Aaronson’s previous bound of ~O((log m)<sup>4</sup>(log d)).  Our protocol has the advantages of being <i>online</i> (that is, the E<sub>i</sub>‘s are processed one at a time), gentle, and conceptually simple.
</p><p>Other applications of our connection include new <i>lower</i> bounds for shadow tomography from lower bounds on DP, and a result on the safe use of estimation algorithms as subroutines inside larger quantum algorithms.</p></blockquote>



<p>The second paper, with Robin Kothari, UT Austin PhD student William Kretschmer, and Justin Thaler, is <a href="https://arxiv.org/abs/1904.08914">Quantum Lower Bounds for Approximate Counting via Laurent Polynomials</a>.  Here’s the abstract:</p>



<blockquote>Given only a membership oracle for S, it is well-known that approximate counting takes Θ(√(N/|S|)) quantum queries.  But what if a quantum algorithm is also given “QSamples”—i.e., copies of the state |S〉=Σ<sub>i∈S</sub>|i〉—or even the ability to apply reflections about |S〉?  Our first main result is that, even then, the algorithm needs either Θ(√(N/|S|)) queries or else Θ(min{|S|<sup>1/3</sup>,√(N/|S|)}) reflections or samples.  We also give matching upper bounds.

<p>We prove the lower bound using a novel generalization of the polynomial method of Beals et al. to <i>Laurent polynomials</i>, which can have negative exponents.  We lower-bound Laurent polynomial degree using two methods: a new “explosion argument” that pits the positive- and negative-degree parts of the polynomial against each other, and a new formulation of the dual polynomials method.

</p><p>Our second main result rules out the possibility of a black-box Quantum Merlin-Arthur (or QMA) protocol for proving that a set is large. More precisely, we show that, even if Arthur can make T quantum queries to the set S⊆[N], and also receives an m-qubit quantum
witness from Merlin in support of S being large, we have Tm=Ω(min{|S|,√(N/|S|)}).  This resolves the open problem of giving an oracle separation between SBP, the complexity class that captures
approximate counting, and QMA.

</p><p>Note that QMA is “stronger” than the queries+QSamples model in that Merlin’s witness can be anything, rather than just the specific state |S〉, but also “weaker” in that Merlin’s witness cannot be trusted.  Intriguingly, Laurent polynomials <i>also</i> play a crucial role in our QMA lower bound, but in a completely different
manner than in the queries+QSamples lower bound.  This suggests that the “Laurent polynomial method” might be broadly useful in complexity theory.</p></blockquote>



<p>I need to get ready for our family’s Seder now, but after that, I’m happy to answer any questions about either of these papers in the comments.</p>



<p>Meantime, the biggest breakthrough in quantum complexity theory of the past month isn’t either of the above: it’s the <a href="https://arxiv.org/abs/1904.05870">paper by Anand Natarajan and John Wright</a> showing that MIP*, or multi-prover interactive proof systems with entangled provers, contains NEEXP, or nondeterministic <strong>doubly</strong>-exponential time (!!).  I’ll try to blog about this later, but if you can’t wait, check out <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">this excellent post by Thomas Vidick</a>.</p></div>
    </content>
    <updated>2019-04-19T21:16:21Z</updated>
    <published>2019-04-19T21:16:21Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-04-19T21:17:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15768</id>
    <link href="https://rjlipton.wordpress.com/2019/04/18/a-reason-why-circuit-lower-bounds-are-hard/" rel="alternate" type="text/html"/>
    <title>A Reason Why Circuit Lower Bounds Are Hard</title>
    <summary>And a possible approach to avoid this obstacle Valentine Kabanets is a famous complexity theorist from Simon Fraser University. He has been at the forefront of lower bounds for over two decades. Today we draw attention to this work and raise an idea about trying to unravel what makes circuit lower bounds hard. He is […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>And a possible approach to avoid this obstacle</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2019/04/kabanetssfu.jpg"><img alt="" class="alignright wp-image-15769" height="200" src="https://rjlipton.files.wordpress.com/2019/04/kabanetssfu.jpg?w=129&amp;h=200" width="129"/></a></p>
<p>
Valentine Kabanets is a famous complexity theorist from Simon Fraser University. He has been at the forefront of lower bounds for over two decades. </p>
<p>
Today we draw attention to this work and raise an idea about trying to unravel what makes circuit lower bounds hard.<span id="more-15768"/></p>
<p>
He is the common author on <a href="https://eccc.weizmann.ac.il/report/2019/022/">two</a> new <a href="https://eccc.weizmann.ac.il/report/2019/018/">papers</a> on the Minimum Circuit Size Problem (MCSP), which belongs to <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> but is not known to be complete or in <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/>. We <a href="https://rjlipton.wordpress.com/2015/03/05/news-on-intermediate-problems/">posted</a> on MCSP four years ago and mentioned his 1999 <a href="http://eccc.hpi-web.de/report/1999/045">paper</a> with Jin-Yi Cai, which gives evidence for MCSP truly being neither complete nor in <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/>. This “intermediate” status and the problem’s simplicity have raised hopes that direct attacks might succeed. The new papers prove direct lower bounds against some restricted circuit/formula models, including constant-depth circuits with mod-<img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> gates for <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> prime. But they stop short of mod-<img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> for <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> composite and other barrier cases.</p>
<p>
He has a nifty research <a href="https://www.cs.sfu.ca/~kabanets/research.html">statement</a> on his home page. It shows how derandomization, pseudorandomness, circuit complexity, and crypto combine into his two current projects. In a clickable tab for the third heading, he puts the meta-issue in pithy terms:</p>
<blockquote><p><b> </b> <em> <i>Why is proving circuit lower bounds so difficult?</i> </em>
</p></blockquote>
<p/><p>
His first answer tab speaks a connection we have also often emphasized here:</p>
<blockquote><p><b> </b> <em> Traditionally, designing efficient algorithms is the subject of the theory of algorithms, while lower bounds are sought in complexity theory. It turns out, however, that there is a deep connection between the two directions: better algorithms (for a certain class of problems) also yield strong lower bounds (for related problems), and vice versa: strong lower bounds translate into more efficient algorithms. </em>
</p></blockquote>
<p/><p>
Of course we agree, and we love connections shown in the new papers to problems such as distinguishing a very slightly biased coin from a true one. But we will try to supplement the algorithmic view of circuit lower bounds with a direct look at the underlying logic.</p>
<p>
</p><p/><h2> Logical Structure of Lower Bounds </h2><p/>
<p/><p>
Okay we all know that circuit lower bounds are hard. For all Kabanets’ success and beautiful work—he like the rest of the complexity field—are unable to prove what we believe is true. They cannot in the full circuit model prove anything close to what is believed to be true for at least a half a century: There are explicit Boolean functions that cannot be computed by any linear size circuit.</p>
<p>
We feel that the logical structure of lower bounds statements gives insight into their difficulty. Perhaps this is almost a tautology. Of course the logical structure of any mathematical statement helps us understand its inherent difficulty. But we believe more: That this structure can reveal quite a bit about lower bounds. Let’s take a look at lower bounds and see if this belief holds up.</p>
<p>
In particular let’s compare the two main approaches to proving lower bounds: non-uniform and uniform. Our claim is that they have different logical structure, and that this difference explains why there is such a gap between the two. While lower bounds—non-uniform or uniform—are hard, uniform ones are at least possible now. Non-uniform lower bounds are really very difficult.</p>
<p>
Here is one example. To prove an explicit size lower bound for Boolean circuits—we’ll be content with just a linear one—we must give a particular family of Boolean functions <img alt="{f_{n}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7Bn%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{n}(x)}"/> (each of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> inputs) so that:</p>
<ol>
<li>
Given <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> we can evaluate <img alt="{f_{n}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7Bn%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{n}(x)}"/> in polynomial time; <p/>
</li><li>
There is no Boolean circuit of size <img alt="{\alpha n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha n}"/> that correctly computes <img alt="{f_{n}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7Bn%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{n}(x)}"/> on all <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>.
</li></ol>
<p>
Here <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is a constant and <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is assumed to be large enough. The terrific <a href="http://www.wisdom.weizmann.ac.il/~ranraz/publications/P5nlb.pdf">paper</a> of Kazuo Iwama, Oded Lachish, Hiroki Morizumi, and Ran Raz gives explicit Boolean functions whose size for circuits with the usual <em>not</em> and binary <em>and</em> and <em>or</em> operators exceeds <img alt="{5n-o(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5n-o%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5n-o(n)}"/>. </p>
<p>
</p><p/><h2> An Approach </h2><p/>
<p/><p>
Let’s look at the above example more carefully. Suppose that in place of a single Boolean function on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> inputs we have a list of them: </p>
<p align="center"><img alt="\displaystyle  f_{n,1}(x),\dots,f_{n,m}(x). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f_%7Bn%2C1%7D%28x%29%2C%5Cdots%2Cf_%7Bn%2Cm%7D%28x%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f_{n,1}(x),\dots,f_{n,m}(x). "/></p>
<p>Can we prove the following? </p>
<p align="center"><img alt="\displaystyle  \exists n_{0}\ \forall n &gt; n_{0} \ \exists f_{n,k} \ \forall C \in \mathsf{SIZE}(\alpha n) \ \neg\mathsf{compute}(C,f_{n,k}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cexists+n_%7B0%7D%5C+%5Cforall+n+%3E+n_%7B0%7D+%5C+%5Cexists+f_%7Bn%2Ck%7D+%5C+%5Cforall+C+%5Cin+%5Cmathsf%7BSIZE%7D%28%5Calpha+n%29+%5C+%5Cneg%5Cmathsf%7Bcompute%7D%28C%2Cf_%7Bn%2Ck%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \exists n_{0}\ \forall n &gt; n_{0} \ \exists f_{n,k} \ \forall C \in \mathsf{SIZE}(\alpha n) \ \neg\mathsf{compute}(C,f_{n,k}). "/></p>
<p>The first thing to note is the effect of letting the number <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> of functions vary:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> If <img alt="{\bf m = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m = 1}"/>, this just becomes our original explicit circuit lower bound problem. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> If <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> is a huge value, however, this becomes the exponential lower bound shown by Claude Shannon—a known quantity. </p>
<p>
In our terms, the latter takes <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> equal to <img alt="{2^{2^{n}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B2%5E%7Bn%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{2^{n}}}"/>, so that given <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> our function list is just the list of all Boolean functions. If all we care about is an <img alt="{\alpha n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha n}"/> lower bound, then the high end of the range can be something like <img alt="{m = 2^{2\alpha n\log(n)} = n^{2\alpha n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+2%5E%7B2%5Calpha+n%5Clog%28n%29%7D+%3D+n%5E%7B2%5Calpha+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = 2^{2\alpha n\log(n)} = n^{2\alpha n}}"/>. So at the high end we have a simple counting argument for the proof but have traded away explicitness. The question will be about the tradeoffs for <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> in-between the extremes.</p>
<p>
</p><p/><h2> An Analogy </h2><p/>
<p/><p>
The above idea that we can model the lower bound methods by controlling the length of the list of the functions is the key to our approach. Perhaps it may help to note an analogy to other famous hard problems of constructing explicit objects. In particular, let’s look at constructing transcendental numbers. Recall these are real numbers that are not algebraic: they are not roots of polynomials with integer coefficients. They include <img alt="{\pi = 3.14159\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+%3D+3.14159%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi = 3.14159\dots}"/> and <img alt="{e = 2.71828\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be+%3D+2.71828%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e = 2.71828\dots}"/></p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The <a href="https://en.wikipedia.org/wiki/Liouville_number">Liouville</a> numbers of Joseph Liouville. 	</p>
<p align="center"><img alt="\displaystyle  x = \sum_{k=1}^\infty \frac{a_k}{b^{k!}}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+%5Csum_%7Bk%3D1%7D%5E%5Cinfty+%5Cfrac%7Ba_k%7D%7Bb%5E%7Bk%21%7D%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x = \sum_{k=1}^\infty \frac{a_k}{b^{k!}}. "/></p>
<p>These are explicit numbers that were proved by him in 1844 to be transcendental. In terms of our model <img alt="{\bf m=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m=1}"/>.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The great <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi}"/> and <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e}"/> puzzle. This is the observation that of <img alt="{\pi + e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+%2B+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi + e}"/> or <img alt="{\pi - e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+-+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi - e}"/>, at least one is a transcendental number. In our terms this gives <img alt="{\bf m=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m=2}"/>.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The famous theorem of Georg Cantor—read as proving the existence of transcendental numbers since algebraic ones are countable.</p>
<p>
Here the high end of the range is as extreme as can be. Cantor’s `list’ of numbers is uncountable—in our model, <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> is the cardinality of the real numbers. Note, the fact that his <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> is huge, really huge, may explain why some at the time were unimpressed by this result. They wanted the ‘list’ to be small, actually they wanted <img alt="{\bf m=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m=1}"/>. See <a href="https://www.jstor.org/stable/2975129?seq=1#page_scan_tab_contents">this</a> for a discussion of the history of these ideas.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> The theorem by Waim Zudilin, in a 2001 <a href="https://iopscience.iop.org/article/10.1070/RM2001v056n04ABEH000427/meta">paper</a>, that at least one of the numbers <img alt="{\zeta(5), \zeta(7), \zeta(9), \zeta(11)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Czeta%285%29%2C+%5Czeta%287%29%2C+%5Czeta%289%29%2C+%5Czeta%2811%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\zeta(5), \zeta(7), \zeta(9), \zeta(11)}"/> must be irrational. It is for “irrational” not “transcendental,” but exemplified <img alt="{\bf m = 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m+%3D+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m = 4}"/> in a highly nontrivial manner. The technical point that makes this work is interactions among these numbers that cannot be captured just by considering any one of them separately. This has <img alt="{\bf m = 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m+%3D+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m = 4}"/>.</p>
<p>
</p><p/><h2> Joining Functions </h2><p/>
<p/><p>
The issue is this: Suppose that we have a list of several boolean functions <img alt="{f_{1}(x),\dots,f_{m}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B1%7D%28x%29%2C%5Cdots%2Cf_%7Bm%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{1}(x),\dots,f_{m}(x)}"/>. Then we can join them together to form one function <img alt="{g(x,y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x,y)}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  g(x,1) = f_{1}(x), \cdots, g(x,m) = f_{m}(x). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++g%28x%2C1%29+%3D+f_%7B1%7D%28x%29%2C+%5Ccdots%2C+g%28x%2Cm%29+%3D+f_%7Bm%7D%28x%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  g(x,1) = f_{1}(x), \cdots, g(x,m) = f_{m}(x). "/></p>
<p>Clearly the function <img alt="{g(x,y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x,y)}"/> is easy implies that all of the <img alt="{f_{y}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7By%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{y}(x)}"/> are easy. This join trick shows that we can encode several boolean functions into one function. Note, we can even make <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> have only order <img alt="{\log(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log(n)}"/> where <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> has <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> bits.</p>
<p>
Thus we can join any collection of functions to make a “universal” one that is at least as hard as the worst of the single functions. More precisely, 	</p>
<p align="center"><img alt="\displaystyle  \mathsf{complexity}(g) \ge \mathsf{complexity}(f_{y}) \text{ for } y=1,\dots,m. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7Bcomplexity%7D%28g%29+%5Cge+%5Cmathsf%7Bcomplexity%7D%28f_%7By%7D%29+%5Ctext%7B+for+%7D+y%3D1%2C%5Cdots%2Cm.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{complexity}(g) \ge \mathsf{complexity}(f_{y}) \text{ for } y=1,\dots,m. "/></p>
<p>Here <img alt="{\mathsf{complexity}(h)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bcomplexity%7D%28h%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{complexity}(h)}"/> is the circuit complexity of the boolean function <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h}"/>.</p>
<p>
If <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> is bigger than <img alt="{2^{O(n)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7BO%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{O(n)}}"/>, that is if <img alt="{m = 2^{\omega(n)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+2%5E%7B%5Comega%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = 2^{\omega(n)}}"/>, then the joined function has more than linearly many variables. Can we possibly establish nontrivial interactions among so many functions, say <img alt="{{\bf m} = n^{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+m%7D+%3D+n%5E%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\bf m} = n^{2n}}"/>?</p>
<p>
One can also try to get this effect with fewer or no additional variables by taking the XOR of some subset of functions in the list. If this is done randomly for each input length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> then one can expect hard functions to show up for many <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. If this process can then be <em>de-randomized</em>, then this may yield an explicit hard function. We wonder how this idea might meld with Andy Yao’s famous XOR Lemma and conditions to <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.441.2818&amp;rep=rep1&amp;type=pdf">de-randomize</a> it.</p>
<p>
</p><p/><h2> Joining Numbers </h2><p/>
<p/><p>
Ken and I thought about the above simple fact about joins, which seems special to functions. Joining by interleaving the decimal expansions is not an arithmetic operation. However, it appears that there may be a similar result possible for transcendental numbers. </p>
<blockquote><p><b>Lemma 1</b> <em> Suppose that <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> and <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\beta}"/> are real numbers. Then 	</em></p><em>
<p align="center"><img alt="\displaystyle  \alpha + i\beta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Calpha+%2B+i%5Cbeta+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  \alpha + i\beta "/></p>
</em><p><em>is a transcendental complex number if at least one of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> or <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\beta}"/> are transcendental. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Let <img alt="{\gamma = \alpha + i\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgamma+%3D+%5Calpha+%2B+i%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\gamma = \alpha + i\beta}"/> be an algebraic number. Thus there must be a polynomial <img alt="{q(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q(x)}"/> with integer coefficients so that 	</p>
<p align="center"><img alt="\displaystyle  q(\gamma) = q(\alpha + i\beta) = 0. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++q%28%5Cgamma%29+%3D+q%28%5Calpha+%2B+i%5Cbeta%29+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  q(\gamma) = q(\alpha + i\beta) = 0. "/></p>
<p>Then it follows by complex conjugation that 	</p>
<p align="center"><img alt="\displaystyle  q(\alpha - i\beta) = 0. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++q%28%5Calpha+-+i%5Cbeta%29+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  q(\alpha - i\beta) = 0. "/></p>
<p>	 Therefore <img alt="{\alpha + i\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%2B+i%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha + i\beta}"/> and <img alt="{\alpha -i\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+-i%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha -i\beta}"/> are both algebraic; thus, so is their sum which is <img alt="{2\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2\alpha}"/>. Thus <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is algebraic. It follows that <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/> is also algebraic. This shows that <img alt="{\gamma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\gamma}"/> is transcendental. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
A question: Can we show that we can do a “join” operation for three or more numbers? That is given numbers <img alt="{x_{1},\dots,x_{m}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7B1%7D%2C%5Cdots%2Cx_%7Bm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{1},\dots,x_{m}}"/> can we construct a number <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> that is transcendental if and only if at least one of <img alt="{x_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i}}"/> is transcendental?</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Is the <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> model useful? Is it possible for it to succeed where a direct explicit argument (<img alt="{{\bf m} = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+m%7D+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\bf m} = 1}"/>) does not? Does it need <img alt="{{\bf m} \gg 2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+m%7D+%5Cgg+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\bf m} \gg 2^n}"/> to rise above technical dependence on the <img alt="{\bf m = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m = 1}"/> case via the join construction?</p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/04/valentine-sandan-test-action-small.jpeg"><img alt="" class="aligncenter wp-image-15770" height="158" src="https://rjlipton.files.wordpress.com/2019/04/valentine-sandan-test-action-small.jpeg?w=235&amp;h=158" width="235"/></a>
</td>
</tr>
<tr>
<td class="caption alignright">
<font size="-2">Maybe the barriers just need 3-Dan martial-arts treatment.  <a href="https://www.vancouverwestaikikai.com/programs/intro-beginner.shtml">Source</a>—our congrats.<br/>
</font>
</td>
</tr>
</tbody></table></font></font></div>
    </content>
    <updated>2019-04-18T22:16:11Z</updated>
    <published>2019-04-18T22:16:11Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="circuit complexity"/>
    <category term="circuits"/>
    <category term="lower bounds"/>
    <category term="transcendental numbers"/>
    <category term="Valentine Kabanets"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-04-22T23:36:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/060</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/060" rel="alternate" type="text/html"/>
    <title>TR19-060 |  Gentle Measurement of Quantum States and Differential Privacy | 

	Scott Aaronson, 

	Guy Rothblum</title>
    <summary>In differential privacy (DP), we want to query a database about $n$ users, in a way that "leaks at most $\varepsilon$ about any individual user," even conditioned on any outcome of the query.  Meanwhile, in gentle measurement, we want to measure $n$ quantum states, in a way that "damages the states by at most $\alpha$," even conditioned on any outcome of the measurement.  In both cases, we can achieve the goal by techniques like deliberately adding noise to the outcome before returning it.  This paper proves a new and general connection between the two subjects. Specifically, we show that on products of $n$ quantum states, any measurement that is $\alpha$-gentle for small $\alpha$ is also $O( \alpha)$-DP, and any product measurement that is $\varepsilon$-DP is also $O(\varepsilon\sqrt{n})$-gentle.

Illustrating the power of this connection, we apply it to the recently studied problem of shadow tomography.  Given an unknown $d$-dimensional quantum state $\rho$, as well as known two-outcome measurements $E_{1},\ldots,E_{m}$, shadow tomography asks us to estimate $\Pr\left[  E_{i}\text{ accepts }\rho\right]  $, for every $i\in\left[ m\right]  $, by measuring few copies of $\rho$. Using our connection theorem, together with a quantum analog of the so-called private multiplicative weights algorithm of Hardt and Rothblum, we give a protocol to solve this problem using $O\left( \left(  \log m\right)  ^{2}\left(  \log d\right)  ^{2}\right)$ copies of $\rho$, compared to Aaronson's previous bound of $\widetilde{O} \left(\left(  \log m\right) ^{4}\left( \log d\right)\right) $.  Our protocol has the advantages of being online (that is, the $E_{i}$'s are processed one at a time), gentle, and conceptually simple.

Other applications of our connection include new lower bounds for shadow tomography from lower bounds on DP, and a result on the safe use of estimation algorithms as subroutines inside larger quantum algorithms.</summary>
    <updated>2019-04-18T12:48:21Z</updated>
    <published>2019-04-18T12:48:21Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-22T23:36:26Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2053726780224405945</id>
    <link href="https://blog.computationalcomplexity.org/feeds/2053726780224405945/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/physics-of-everday-life.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2053726780224405945" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2053726780224405945" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/physics-of-everday-life.html" rel="alternate" type="text/html"/>
    <title>Physics of Everday Life</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Based on <a href="https://www.scottaaronson.com/blog/?p=3654">Scott's review</a>, I read through Stephen Pinker's <a href="https://www.amazon.com/Enlightenment-Now-Science-Humanism-Progress-ebook/dp/B073TJBYTB/ref=as_li_ss_tl?crid=2O1U6VZR84R2Q&amp;keywords=enlightenment+now&amp;qid=1554897483&amp;s=gateway&amp;sprefix=engligh,aps,597&amp;sr=8-1&amp;linkCode=ll1&amp;tag=computation09-20&amp;linkId=8f668f77297b7cd8b57a85dca27802b0&amp;language=en_US">Enlightenment Now</a>. I can't top Scott's exposition of the book, but it is pretty incredible how far humanity has gone when you step back to look at the big picture.<br/>
<br/>
One line intrigued me, one that Pinker credits to a book called <a href="https://www.amazon.com/Big-Picture-Origins-Meaning-Universe/dp/1101984252/ref=as_li_ss_tl?ie=UTF8&amp;linkCode=ll1&amp;tag=computation09-20&amp;linkId=6c644c72e1d0c1f818a5907f9b221ce1&amp;language=en_US">The Big Picture</a> by Sean Carroll<br/>
<blockquote class="tr_bq">
The laws of physics underlying everyday life (that is excluding extreme values of energy and gravitation like black holes, dark matter and the Big Bang) are <i>completely known.</i></blockquote>
Hasn't this statement almost always been true, in the sense that the leading minds would make this claim at many times in history. The ancient Greeks probably believed they understood physics that underlies everyday life. So did physicists after Newton. Life back then not today. My everyday life involves using a GPS device that requires understanding relativistic effects and computer chips that needed other scientific advances.<br/>
<br/>
Is it possible we could do more in everyday life if we knew more physics? I'd certainly use a teleporter in everyday life.<br/>
<br/>
And is the statement even true today? We all use public key cryptography, even to read this blog. It's not completely clear if we understand the physics enough to know how or if large-scale quantum computers capable of breaking those systems can be built.<br/>
<br/>
Everday life is relative.</div>
    </content>
    <updated>2019-04-18T11:40:00Z</updated>
    <published>2019-04-18T11:40:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-04-22T08:46:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/059</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/059" rel="alternate" type="text/html"/>
    <title>TR19-059 |  Samplers and extractors for unbounded functions | 

	Rohit Agrawal</title>
    <summary>Blasiok (SODA'18) recently introduced the notion of a subgaussian sampler, defined as an averaging sampler for approximating the mean of functions $f:\{0,1\}^m \to \mathbb{R}$ such that $f(U_m)$ has subgaussian tails, and asked for explicit constructions. In this work, we give the first explicit constructions of subgaussian samplers (and in fact averaging samplers for the broader class of subexponential functions) that match the best-known constructions of averaging samplers for $[0,1]$-bounded functions in the regime of parameters where the approximation error $\varepsilon$ and failure probability $\delta$ are subconstant. Our constructions are established via an extension of the standard notion of randomness extractor (Nisan and Zuckerman, JCSS'96) where the error is measured by an arbitrary divergence rather than total variation distance, and a generalization of Zuckerman's equivalence (Random Struct. Alg.'97) between extractors and samplers. We believe that the framework we develop, and specifically the notion of an extractor for the Kullback-Leibler (KL) divergence, are of independent interest. In particular, KL-extractors are stronger than both standard extractors and subgaussian samplers, but we show that they exist with essentially the same parameters (constructively and non-constructively) as standard extractors.</summary>
    <updated>2019-04-18T00:27:56Z</updated>
    <published>2019-04-18T00:27:56Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-22T23:36:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4166</id>
    <link href="https://www.scottaaronson.com/blog/?p=4166" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4166#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4166" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Just says in P</title>
    <summary xml:lang="en-US">Recently a Twitter account started called justsaysinmice. The only thing this account does, is to repost breathless news articles about medical research breakthroughs that fail to mention that the effect in question was only observed in mice, and then add the words “IN MICE” to them. Simple concept, but it already seems to be changing […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Recently a Twitter account started called <a href="https://twitter.com/justsaysinmice">justsaysinmice</a>.  The only thing this account does, is to repost breathless news articles about medical research breakthroughs that fail to mention that the effect in question was only observed in mice, and then add the words “IN MICE” to them.  Simple concept, but it already seems to be changing the conversation about science reporting.</p>



<p>It occurred to me that we could do something analogous for quantum computing.  While my own deep-seated aversion to Twitter prevents me from doing it myself, which of my readers is up for starting an account that just reposts one overhyped QC article after another, while appending the words “A CLASSICAL COMPUTER COULD ALSO DO THIS” to each one?</p></div>
    </content>
    <updated>2019-04-17T19:14:17Z</updated>
    <published>2019-04-17T19:14:17Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Speaking Truth to Parallelism"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-04-19T21:17:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17286</id>
    <link href="https://gilkalai.wordpress.com/2019/04/17/gothenburg-stockholm-lancaster-mitzpe-ramon-and-israeli-election-day-2019/" rel="alternate" type="text/html"/>
    <title>Gothenburg, Stockholm, Lancaster, Mitzpe Ramon, and Israeli Election Day 2019</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Lancaster – Watching the outcomes of the Israeli elections (photo: Andrey Kupavskii) Sweden I just came back from a trip to Sweden and the U.K. I was invited to Gothenburg to be the opponent for a Ph. D. Candidate  Malin … <a href="https://gilkalai.wordpress.com/2019/04/17/gothenburg-stockholm-lancaster-mitzpe-ramon-and-israeli-election-day-2019/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/04/dsc5390.jpg"><img alt="" class="alignnone size-medium wp-image-17287" height="200" src="https://gilkalai.files.wordpress.com/2019/04/dsc5390.jpg?w=300&amp;h=200" width="300"/></a> <a href="https://gilkalai.files.wordpress.com/2019/04/hand.png"><img alt="" class="alignnone size-medium wp-image-17288" height="251" src="https://gilkalai.files.wordpress.com/2019/04/hand.png?w=300&amp;h=251" width="300"/></a></p>
<p><span style="color: #ff0000;">Lancaster – Watching the outcomes of the Israeli elections (photo: Andrey Kupavskii)</span></p>
<h3>Sweden</h3>
<p>I just came back from a trip to Sweden and the U.K. I was invited to Gothenburg to be the opponent for a Ph. D. Candidate  Malin Palö Forsström (by now Dr. Malin Palö Forsström),  who wrote her excellent Ph. D. thesis under the supervision of Jeff Steif in Chalmers University. We also used the opportunity for a lovely mini-mini-workshop</p>
<p>From Gothenburg I took the train to Stockholm to spend the weekend with Anders Björner and we talked about some old projects regarding algebraic shifting.  We had dinner with several colleagues including Svante Linusson who is a candidate for the European parliament!</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/acg80s.jpeg"><img alt="" class="alignnone size-full wp-image-17296" src="https://gilkalai.files.wordpress.com/2019/04/acg80s.jpeg?w=640"/></a> <a href="https://gilkalai.files.wordpress.com/2019/04/20190407_194045.jpg"><img alt="" class="alignnone size-medium wp-image-17297" height="168" src="https://gilkalai.files.wordpress.com/2019/04/20190407_194045.jpg?w=300&amp;h=168" width="300"/></a></p>
<p><span style="color: #ff0000;">Stockholm: With Anders and Cristins in the late 80s (left, I think this was also when I was an opponent), Svante Linusson ten days ago (right)</span></p>
<h3>The United Kingdom</h3>
<p>The <a href="https://www.lancaster.ac.uk/maths/bmc2019/">British Mathematical Colloquium at Lancaster</a> was a lovely 4-day general meeting, an opportunity to meet some old and new friends (and Internet MO friend <a href="https://mathoverflow.net/users/763/yemon-choi">Yemon Choi</a> in real life), and to learn about various new developments. I am aware of the fact that my list of unfulfilled promises is longer than those of most politicians, but I do hope to come back to some mathematics from this trip to Sweden and to Lancaster.</p>
<h3>Election Day</h3>
<p>Last week’s Tuesday was election day in Israel,  and as much as I like to participate (and to devote a post to election day here on the blog – in <a href="https://gilkalai.wordpress.com/2009/02/10/majority-rules-the-story-of-achnais-oven/">2009</a>, <a href="https://gilkalai.wordpress.com/2013/01/22/election-day/">2012</a>, and <a href="https://gilkalai.wordpress.com/2015/03/17/election-day-2/">2015</a>) I had to miss the election, for the first time since 1985. (I still tried to follow the outcomes in real time.)</p>
<h3>The Negev, Israel</h3>
<p>And we are now spending a three-day vacation and doing some mild hiking in Mitzpe Ramon, in the Negev, the Israeli desert.  The view around here is spectacular. I first fell in love with the sights of the Negev when I spent six months here when I was 19 (in the army). Since then we have been caming here many times over the years, and in 2002 the annual meeting of the Israeli Mathematical Union took place here, in the same hotel.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/img-20190416-wa0036.jpg"><img alt="" class="alignnone size-medium wp-image-17298" height="300" src="https://gilkalai.files.wordpress.com/2019/04/img-20190416-wa0036.jpg?w=169&amp;h=300" width="169"/></a> <a href="https://gilkalai.files.wordpress.com/2019/04/fb_img_1555444073776-e1555444196265.jpg"> <img alt="" class="alignnone size-medium wp-image-17299" height="165" src="https://gilkalai.files.wordpress.com/2019/04/fb_img_1555444073776-e1555444196265.jpg?w=300&amp;h=165" width="300"/></a></p>
<p><span style="color: #ff0000;">Ein Ovdat (left). The 2002 Annual meeting of the IMU (right). A large number of Israeli mathematicians come to a substantial fraction of these annual events.</span></p>
<h3>The stance of the main Israeli parties on quantum computing</h3>
<p>One anecdote about the Israeli election is that both major political parties of Israel, the Likud, led by Benjamin (Bibi) Netanyahu that won 35 seats in the parliament and will probably lead the coalition, and the newly formed “Blue-and-White” party, led by Benny (Benjamin) Gantz that also won 35 seats and will probably lead the opposition, stand behind quantum computing! <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/03/bw-quantum.png"><img alt="" class="alignnone size-medium wp-image-17121" height="233" src="https://gilkalai.files.wordpress.com/2019/03/bw-quantum.png?w=300&amp;h=233" width="300"/></a><a href="https://gilkalai.files.wordpress.com/2019/04/qcbibi.png"> <img alt="" class="alignnone size-medium wp-image-17302" height="258" src="https://gilkalai.files.wordpress.com/2019/04/qcbibi.png?w=300&amp;h=258" width="300"/></a></p>
<p><span style="color: #ff0000;">Left – A paragraph from “Blue and White’s” charter with a pledge to quantum computing (I thank Noam Lifshitz for telling me about it). Right –  a news item (<a href="https://en.globes.co.il/en/article-government-allocates-nis-300m-for-quantum-computing-1001244244">click for the article</a>) about the quantum computing vision of Netanyahu and the Likud party.</span></p>
<p> </p></div>
    </content>
    <updated>2019-04-17T19:10:12Z</updated>
    <published>2019-04-17T19:10:12Z</published>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Updates"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-04-22T23:36:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4227</id>
    <link href="https://lucatrevisan.wordpress.com/2019/04/17/online-optimization-for-complexity-theorists/" rel="alternate" type="text/html"/>
    <title>Online Optimization for Complexity Theorists</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Last year I took some time off to study online convex optimization in some detail. The reason for doing that was similar to the reason why at some point I took time off to study spectral graph theory: it was … <a href="https://lucatrevisan.wordpress.com/2019/04/17/online-optimization-for-complexity-theorists/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
 Last year I took some time off to study online convex optimization in some detail. The reason for doing that was similar to the reason why at some point I took time off to study spectral graph theory: it was coming up in several papers that I wanted to understand, and I felt that I was missing out by not mastering an important tool. In particular, I wanted to understand: </p>
<ol>
<li> The <a href="https://dl.acm.org/citation.cfm?id=1496770.1496899">Barak-Hardt-Kale</a> proof of the <a href="https://ieeexplore.ieee.org/document/492584">Impagliazzo hard-core lemma</a>.
</li><li> The online convex optimization viewpoint on the <a href="https://ieeexplore.ieee.org/document/548459">Frieze-Kannan weak regularity lemma</a>, on the dense model theorem of <a href="https://ieeexplore.ieee.org/document/4690942">(RTTV)</a>, and on the abstract weak regularity lemma of <a href="https://ieeexplore.ieee.org/document/5231258">(TTV)</a> that were described to me by Madhur Tulsiani a few years ago. Furthermore, I wanted to see if Russel Impagliazzo’s subsequent improvements to the dense model theorem and to the abstract weak regularity lemma could be recovered from this point of view.
</li><li> The <a href="https://dl.acm.org/citation.cfm?doid=2906142.2837020">Arora-Kale</a> algorithms for semidefinite programming, including their nearly linear-time algorithm for approximating the Goemans-Williamson relaxation of Max Cut.
</li><li> The meaning of the sentence “multiplicative weights and gradient descent are both special cases of follow-the-regularized-leader, using negative entropy and <img alt="{\ell_2^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2^2}"/> as regularizer, respectively.”
</li><li> The <a href="https://arxiv.org/abs/1506.04838">AllenZhu-Liao-Orecchia</a> online optimization proof of the Batson-Spielman-Srivastava sparsification result.
</li></ol>
<p>
I am happy to say that, except for the “furthermore” part of (2), I achieved my goals. To digest this material a bit better, I came up with the rather ambitious plan of writing a series of posts, in which I would alternate between (i) explaining a notion or theorem from online convex optimization (at a level that someone learning about optimization or machine learning might find useful) and (ii) explaining a complexity-theoretic application. Now that a very intense Spring semester is almost over, I plan to get started on this plan, although it is not clear that I will see it through the end. So stay tuned for the forthcoming first episode, which will be about the good old multiplicative weights algorithm.</p>
<p/></div>
    </content>
    <updated>2019-04-17T15:27:23Z</updated>
    <published>2019-04-17T15:27:23Z</published>
    <category term="theory"/>
    <category term="online optimization"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-04-22T23:20:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4224</id>
    <link href="https://lucatrevisan.wordpress.com/2019/04/16/the-early-years-of-computing-in-italy/" rel="alternate" type="text/html"/>
    <title>The Early Years of Computing in Italy</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Here are in theory‘s first ever book reviews! The books are Giorgio Garuzzo Quando in Italia si facevano i computer Available for free at Amazon.com and Amazon.it. Giorgio Ausiello The Making of a New Science Available from Springer, as a … <a href="https://lucatrevisan.wordpress.com/2019/04/16/the-early-years-of-computing-in-italy/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Here are <i>in theory</i>‘s first ever book reviews! The books are</p>
<p>Giorgio Garuzzo<br/>
<i>Quando in Italia si facevano i computer</i><br/>
Available for free at <a href="https://www.amazon.com/gp/product/B017PTTUKY">Amazon.com</a> and <a href="https://www.amazon.it/Quando-facevano-computer-Giorgio-Garuzzo-ebook/dp/B017PTTUKY">Amazon.it</a>.</p>
<p>Giorgio Ausiello<br/>
<i>The Making of a New Science</i><br/>
Available from <a href="https://www.springer.com/us/book/9783319626796">Springer</a>, as a DRM-free PDF through your academic library.</p>
<p>Both books talk about the early years of computing in Italy, on the industrial and academic side, respectively. They briefly intersect with the story of Olivetti’s Elea computer.</p>
<p><span id="more-4224"/></p>
<p>Olivetti was a company that was founded in 1908 to make typewriters, and then branched out to other office/business machines and avionics. In the 1930s, Adriano Olivetti, a son of the founder Camillo Olivetti, took over the company. Adriano Olivetti was an unusual figure of entrepreneur deeply interested in arts, humanities and social sciences, with a utopian vision of a company reinvesting its profits in its community. In the 1950s, he led the company to develop the Elea, the first Italian computer. The Elea was made with transistors, and it came out before IBM had built its own first transistor-based computer.</p>
<p>The development of Elea was led by Mario Tchou. Mario Tchou was a Chinese-Italian born and raised in Rome, who studied electrical engineering at the Sapienza University of Rome and then at Brooklyn Polytechnic, eventually becoming an assistant professor at Columbia University. Olivetti persuaded Tchou to move back to Italy and lead the development of Elea, whose first prototype came out in 1957. </p>
<p>As production was ramping up, tragedy struck: Adriano Olivetti died in 1960, and Mario Tchou died in 1961. To shore up the finances of the company, the new CEO Roberto Olivetti brought in a series of new investors, who pushed to spin off the computer business.</p>
<p>At that point, Olivetti was working on another revolutionary machine, the P101, a programmable desktop calculator billed as the “first desktop computer,” which came out in 1964, attracting huge interest. Nonetheless the company spun off its “computer” division into a joint venture with GE, eventually divesting of it completely. Fortunately, they kept control of the P101 project, because those working on it were careful in branding it internally as a “calculator” (not part of the of deal with GE) rather than a “computer.”</p>
<p>These events are narrated, with a fascinating insider view, in Garuzzo’s book.</p>
<p>Giorgio Ausiello is one of the founding fathers of academic computer science in Italy. His book is a professional memoir that starts in the 1960s, at the time in which he started working on his undergraduate thesis at the Istituto Nazionale per le Applicazioni del Calcolo (INAC, later renamed IAC) at the National Research Council in Rome. At that point INAC had one of Italy’s few computers, a machine bought in 1954 from the Ferranti company in Manchester (when it was installed, it was Italy’s <i>second</i> computer).</p>
<p>As narrated in a <a href="https://lucatrevisan.wordpress.com/2017/10/23/corrado-bohm/">previous post</a>, Mauro Picone, the mathematician who was leading INAC, brought Corrado Bohm to Rome to work on this computer, and Ausiello started to work with Bohm at the time in which he was just starting to think about models of computation and lambda-calculus.</p>
<p>Later, Ausiello visited Berkeley in the 1968-69 academic year, when Manuel Blum and Dick Karp had just joined the faculty. Ausiello took part in the first STOC, which was held in Marina del Rey in May 1969, and, later that month, he witnessed the occupation of <a href="https://en.wikipedia.org/wiki/People%27s_Park_(Berkeley)">People’s Park</a> in Berkeley.</p>
<p>The Fall of 1969 marks the start of the first Italian undergraduate programs in Computer Science, in just four universities:  Bari, <del datetime="2019-04-17T11:04:18-07:00">Milan,</del> Pisa and Torino. Back in Italy from Berkeley, Ausiello continued to work at the National Research Council in Rome.</p>
<p>The book continues with a behind-the-scene narration of the events that led to the founding of the EATCS professional society, the ICALP conference and the TCS journal. There is also another trip to Berkeley in the 1980s, featuring Silvio Micali and Vijay Vazirani working on their matching algorithm, and Shafi Goldwasser just arriving in Berkeley.</p>
<p>Methodically documented and very detail-oriented, the book is a fascinating read, although it leaves you sometimes wanting to hear more about the personalities and the stories of the people involved and less about the attendance lists of certain meetings.</p>
<p>Even when it comes to the dryer details, however, I am happy that the books documents them and makes them available to future generations that will not have any living memory of the 1960s and 1970s.</p>
<p>I should also mention that Alon Rosen has recently interviewed <a href="https://www.youtube.com/watch?v=vKCE7QnsFcw&amp;t=67s">Christos Papadimitriou</a> and <a href="https://www.youtube.com/watch?v=-GQnK6ys6C0&amp;t=20s">Avi Wigderson</a> and those (<i>long</i>) interviews are full of good stories. Finally, the Simons Foundation site has an <a href="https://www.simonsfoundation.org/2013/02/14/laszlo-lovasz/">interview of Laszlo Lovasz</a> in conversation with Avi Wigderson which I very highly recommend everybody to watch.</p></div>
    </content>
    <updated>2019-04-17T00:52:21Z</updated>
    <published>2019-04-17T00:52:21Z</published>
    <category term="Berkeley"/>
    <category term="history"/>
    <category term="Italy"/>
    <category term="theory"/>
    <category term="Elea"/>
    <category term="Giorgio Ausiello"/>
    <category term="Giorgio Garuzzo"/>
    <category term="Mario Tchou"/>
    <category term="Olivetti"/>
    <category term="P101"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-04-22T23:20:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/058</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/058" rel="alternate" type="text/html"/>
    <title>TR19-058 |  Extractors for small zero-fixing sources | 

	Pavel Pudlak, 

	Vojtech Rodl</title>
    <summary>A random variable $X$ is an $(n,k)$-zero-fixing source if for some subset $V\subseteq[n]$, $X$ is the uniform distribution on the strings $\{0,1\}^n$ that are zero on every coordinate outside of $V$. An $\epsilon$-extractor for $(n,k)$-zero-fixing sources is a mapping $F:\{0,1\}^n\to\{0,1\}^m$, for some $m$, such that $F(X)$ is $\epsilon$-close in statistical distance to the uniform distribution on $\{0,1\}^m$ for every $(n,k)$-zero-fixing source $X$. Zero-fixing sources were introduced by Cohen and Shinkar in~2015 in connection with the previously studied extractors for bit-fixing sources. They constructed, for every $\mu&gt;0$, an efficiently computable extractor that extracts a positive fraction of entropy, i.e., $\Omega(k)$ bits, from $(n,k)$-zero-fixing sources where $k\geq(\log\log n)^{2+\mu}$. 

In this paper we present two different constructions of extractors for zero-fixing sources that are able to extract a positive fraction of entropy for $k$ essentially smaller than $\log\log n$. The first extractor works for $k\geq C\log\log\log n$, for some constant $C$. The second extractor extracts a positive fraction of entropy for $k\geq \log^{(i)}n$ for any fixed $i\in \N$, where $\log^{(i)}$ denotes $i$-times iterated logarithm. The fraction of extracted entropy decreases with $i$. The first extractor is a function computable in polynomial time in~$n$ (for $\epsilon=o(1)$, but not too small); the second one is computable in polynomial time when $k\leq\alpha\log\log n/\log\log\log n$, where $\alpha$ is a positive constant.</summary>
    <updated>2019-04-16T15:10:03Z</updated>
    <published>2019-04-16T15:10:03Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-22T23:36:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/04/16/tensors-algebra-computation-applications/</id>
    <link href="https://cstheory-events.org/2019/04/16/tensors-algebra-computation-applications/" rel="alternate" type="text/html"/>
    <title>Tensors: Algebra-Computation-Applications</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">June 3-14, 2019 U. Colorado Boulder and Colorado State U https://thetensor.space/workshops/2019/02/13/TACA-2019.html The Department of Mathematics at Colorado State University and the Department of Computer Science at the University of Colorado, Boulder invite interested participants to attend a workshop and conference on Tensors: Algebra, Computation, and Applications (TACA). The central theme of tensors is meant to … <a class="more-link" href="https://cstheory-events.org/2019/04/16/tensors-algebra-computation-applications/">Continue reading <span class="screen-reader-text">Tensors: Algebra-Computation-Applications</span></a></div>
    </summary>
    <updated>2019-04-16T15:01:44Z</updated>
    <published>2019-04-16T15:01:44Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-04-22T23:38:02Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/04/15/linkage</id>
    <link href="https://11011110.github.io/blog/2019/04/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>“You know how the \hat command in LaTeΧ puts a caret above a letter? … Well I was thinking it would be funny if someone made a package that made the \hat command put a picture of an actual hat on the symbol instead?” And then Matthew Scroggs and Adam Townsend went ahead and did it ().</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://aperiodical.com/2019/03/realhats-writing-a-latex-package/">“You know how the \hat command in LaTeΧ puts a caret above a letter? … Well I was thinking it would be funny if someone made a package that made the \hat command put a picture of an actual hat on the symbol instead?”</a>
And then Matthew Scroggs and Adam Townsend went ahead and <a href="https://ctan.org/pkg/realhats">did it</a> (<a href="https://mathstodon.xyz/@11011110/101849504150959463"/>).</p>
  </li>
  <li>
    <p><a href="https://syntopia.github.io/Polytopia/polytopes.html">Generating 4d polyhedra from their symmetries</a> (<a href="https://mathstodon.xyz/@11011110/101860652773207990"/>, <a href="https://web.archive.org/web/20190306075446/https://plus.google.com/+RoiceNelson/posts/13EEovjAjh3">via</a>), by Mikael Hvidtfeldt Christensen.</p>
  </li>
  <li>
    <p><a href="https://windowsontheory.org/2019/04/03/focs-2019-real-website-and-submission-server/">Windows on Theory</a> and <a href="https://www.scottaaronson.com/blog/?p=4154">Scott Aaronson</a> both warn about a fake web site for <a href="http://focs2019.cs.jhu.edu/">FOCS 2019</a>, whose submission deadline just passed (<a href="https://mathstodon.xyz/@11011110/101864693573223236"/>).</p>
  </li>
  <li>
    <p><a href="http://service.ifam.uni-hannover.de/~geometriewerkstatt/gallery/index.html">GeometrieWerkstatt Gallery</a> (<a href="https://mathstodon.xyz/@11011110/101872198999374479"/>). A collection of weirdly-shaped mathematical surfaces, mostly of constant mean curvature.</p>
  </li>
  <li>
    <p><a href="http://focs2019.cs.jhu.edu/awards/">Sandi Irani wins IEEE TCMF Distinguished Service Award</a> (<a href="https://mathstodon.xyz/@11011110/101877216457233962"/>). The award recognizes her work chairing the <a href="https://www.ics.uci.edu/~irani/safetoc.html">ad hoc committee to combat harassment and discrimination in the theory of computing community</a>, and then getting many theory conferences to follow its recommendations.</p>
  </li>
  <li>
    <p><a href="http://web.colby.edu/thegeometricviewpoint/2014/04/25/periodic-billiard-paths/">Periodic billiard paths</a> (<a href="https://mathstodon.xyz/@11011110/101883476235740072"/>). If the boundary of a given polygon is made of mirrors, these are paths that a laser beam could take that would eventually reflect back to the starting point and angle and then repeat infinitely. It remains a heavily-studied open question whether such paths exist in every triangle. This blog post from 2014 provides a proof that they do exist in polygons whose vertex angles are all rational multiples of .</p>
  </li>
  <li>
    <p><a href="https://retractionwatch.com/2019/04/08/with-a-badly-handled-tweet-plos-angers-scientists-after-a-blog-disappears/">PLOS disappears one (or maybe more) of its hosted blogs</a> (<a href="https://mathstodon.xyz/@11011110/101894568161561631"/>) without any warning to the blog author, without any attempt at keeping old blog links still working, and with only a belated apology.</p>
  </li>
  <li>
    <p><a href="https://slate.com/news-and-politics/2019/03/scotus-gerrymandering-case-mathematicians-brief-elena-kagan.html">The Supreme Court’s math problem</a> (<a href="https://mathstodon.xyz/@11011110/101900050555580515"/>, <a href="https://www.metafilter.com/180163/The-Supreme-Courts-Math-Problem">via</a>). Jordan Ellenberg explains why, in testing for gerrymandering, asking about deviation from proportional representation is the wrong question. Democratic systems naturally concentrate power to the majority rather than being proportional. The right question is whether that concentration is at the natural level, or is artificially accelerated in one direction or another.</p>
  </li>
  <li>
    <p><a href="https://blog.archive.org/2019/04/10/official-eu-agencies-falsely-report-more-than-550-archive-org-urls-as-terrorist-content/">EU falsely calls Internet Archive’s major collection pages, scholarly articles, and copies of US government publications “terrorism” and demands they be taken down from the internet</a> (<a href="https://mathstodon.xyz/@11011110/101908397856087187"/>, <a href="https://boingboing.net/2019/04/11/one-hour-service.html">see also</a>). The EU is about to vote to require terrorism takedowns to happen within an hour, and these requests are coming on European times when all Internet Archive employees (in California) are asleep, making manual review of these bad takedowns difficult.</p>
  </li>
  <li>
    <p><a href="https://www.siam.org/Conferences/CM/Main/apocs20">SIAM-ACM Conference on Algorithmic Principles of Computer Systems, APOCS</a> (<a href="https://mathstodon.xyz/@11011110/101909431804808574"/>). This is a new conference to be held with SODA, next January in Salt Lake City, covering “all areas of algorithms and architectures that offer insight into the performance and design of computer systems”. Submission titles and abstracts are due August 9 (with full papers due a week later) so if this is an area you’re interested in there’s still plenty of time to come up with something to submit.</p>
  </li>
  <li>
    <p><a href="https://blog.computationalcomplexity.org/2019/04/elwyn-berlekamp-died-april-9-2019.html">Sad news from Berkeley</a>: <a href="https://en.wikipedia.org/wiki/Elwyn_Berlekamp">Elwyn Berlekamp</a> has died (<a href="https://mathstodon.xyz/@11011110/101921251002340100"/>, <a href="https://aperiodical.com/2019/04/elwyn-berlekamp-has-left-us/">see also</a>). Berlekamp made significant contributions to combinatorial game theory (motivated, as I understand it, by the mathematical study of Go endgames), coding theory, and algorithms for polynomials.</p>
  </li>
  <li>
    <p><a href="https://www.berlintransitmap.de/">An unofficially-proposed new Berlin transit map replaces stylized axis-parallel and diagonal line segments with smooth curves</a> (<a href="https://mathstodon.xyz/@11011110"/>, <a href="https://www.metafilter.com/180431/Berlin-Transit-Map-now-with-pleasing-Curves">via</a>). The old design was seen as “out of style”, “too robotized”, and too difficult to follow routes. There’s still a strong preference for axis-parallel and diagonal lines in the new map, but the connections between them have been smoothed out.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-04-15T17:43:00Z</updated>
    <published>2019-04-15T17:43:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-04-16T01:45:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kintali.wordpress.com/?p=1225</id>
    <link href="https://kintali.wordpress.com/2019/04/15/a-personal-story-of-a-founder/" rel="alternate" type="text/html"/>
    <title>A Personal Story of a Founder</title>
    <summary>Disclaimer: This blog post is not intended to offend University of Pennsylvania or IIT Kharagpur or Yahoo or any individuals or parties involved. The goal of this blog post is to point out some of the inefficiencies and acknowledge them as one of the motivations behind developing TrueCerts platform. The year was 2005. I was applying for a PhD program in Computer Science in […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="graf graf--p graf-after--p" id="7e4b"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Disclaimer:</em></strong><em class="markup--em markup--p-em"> This blog post is not intended to offend </em><a class="markup--anchor markup--p-anchor" href="https://en.wikipedia.org/wiki/University_of_Pennsylvania" rel="nofollow noopener" target="_blank"><em class="markup--em markup--p-em">University of Pennsylvania</em></a><em class="markup--em markup--p-em"> or </em><a class="markup--anchor markup--p-anchor" href="https://en.wikipedia.org/wiki/Indian_Institute_of_Technology_Kharagpur" rel="nofollow noopener" target="_blank"><em class="markup--em markup--p-em">IIT Kharagpur</em></a><em class="markup--em markup--p-em"> or </em><a class="markup--anchor markup--p-anchor" href="https://en.wikipedia.org/wiki/Yahoo!" rel="nofollow noopener" target="_blank"><em class="markup--em markup--p-em">Yahoo</em></a><em class="markup--em markup--p-em"> or any individuals or parties involved. The goal of this blog post is to point out some of the inefficiencies and acknowledge them as one of the motivations behind developing </em><a class="markup--anchor markup--p-anchor" href="https://truecerts.co/" rel="nofollow noopener" target="_blank"><em class="markup--em markup--p-em">TrueCerts</em></a><em class="markup--em markup--p-em"> platform.</em></p>
<p class="graf graf--p graf-after--p" id="822b">The year was 2005. I was applying for a PhD program in Computer Science in the top US universities. I have applied to 14 US universities. On Dec 2nd 2015, I received the following email (see the screenshot below) from the University of Pennsylvania (UPenn), Penn Engineering, Office of Academic Programs, Graduate Admissions. I have redacted the name, email address and the phone numbers in the emails, to preserve their privacy.</p>
<p><img alt="upenn1" class="alignnone size-full wp-image-1226" src="https://kintali.files.wordpress.com/2019/04/upenn1.png?w=660"/></p>
<p>Here are the photos of the original transcript (I received from IIT Kharagpur when I graduated) and the additional transcripts (I received from IIT Kharagpur when I requested them for my PhD application). They are all <strong class="markup--strong markup--p-strong">laminated by IIT Kharagpur</strong> and sent to me. Feel free to laugh at my appearance on the transcript. I do too <img alt="&#x1F609;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f609.png" style="height: 1em;"/></p>
<p><img alt="kgp" class="alignnone size-full wp-image-1227" src="https://kintali.files.wordpress.com/2019/04/kgp.jpeg?w=660"/></p>
<p class="graf graf--p graf-after--figure" id="e20e">IIT Kharagpur stated the following in their transcripts policy.</p>
<p class="graf graf--p graf--startsWithDoubleQuote graf-after--p" id="60be"><em class="markup--em markup--p-em">“Institute does not take responsibility of sending the duplicate copy of grade cards (transcripts) directly to other institutions/organizations, in connection with the applicants’ admission/employment etc.”</em></p>
<p class="graf graf--p graf-after--p" id="a381">My reply to the above email and the response from UPenn are shown in the following screenshot.</p>
<p><img alt="upenn2" class="alignnone size-full wp-image-1228" src="https://kintali.files.wordpress.com/2019/04/upenn2.png?w=660"/></p>
<p class="graf graf--p graf-after--figure" id="1fc0">In Summary, UPenn was concerned that my transcript was laminated and opened. Surprised by their response (“Your application will not go any further with the opened transcript”), I have spent couple of hours searching online and discovered that there is a lot of scam involving fake degrees and fake transcripts. There are “professionals” in India and China creating the “highest quality fakes”. These fake transcripts are often laminated. So, UPenn decided not to process any applications with opened and laminated credentials. All my credentials are valid and correct, but my application was not processed because IIT Kharagpur has no way to <strong>securely send valid transcripts</strong> and UPenn has no way to <strong>efficiently validate applicants’ transcripts</strong>.</p>
<p class="graf graf--p graf-after--p" id="0588">I have applied to 14 universities and some of them rejected me because ‘they found a better candidate’ or ‘the research group was not looking for new PhD students’ etc etc. But my UPenn application not going further because of an <strong>inefficient and broken system</strong> is frustrating, to say the least.</p>
<p class="graf graf--p graf-after--p">After a week, I have recovered from this frustration and went back to my daily routine of reading research papers on Theoretical Computer Science. I said to myself “I will get into one of the remaining 13 universities and I have to focus on my research and resolve the <a class="markup--anchor markup--p-anchor" href="https://en.wikipedia.org/wiki/P_versus_NP_problem" rel="nofollow noopener" target="_blank">P vs NP problem</a>” <img alt="&#x1F609;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f609.png" style="height: 1em;"/> I eventually got admission into GeogiaTech and a handful of other universities. I joined GeorgiaTech and did my research at the intersection of complexity theory, game theory, combinatorics, and structural graph theory.</p>
<p class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">On a lighter note: </strong>There is a simple way to verify that my transcript is valid — ‘Simply open it and look at my grades’. There are some really bad grades. My CGPA was just average. I have received a C grade in complexity theory (which later became my primary <a class="markup--anchor markup--p-anchor" href="https://smartech.gatech.edu/handle/1853/42770" rel="noopener" target="_blank">PhD thesis</a> topic at GeorgiaTech). Nobody in their right senses would create a fake transcript with those grades <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/> During the last decade, whenever I met any IITian I first set them up by telling <a class="markup--anchor markup--p-anchor" href="http://shivakintali.org/" rel="noopener" target="_blank">my credentials</a> (B-Tech from IIT Kharagpur, Masters from USC, PhD from GeorgiaTech, Taught at Princeton) and then I bet with them that their CGPA at IIT is greater than mine. I never lost till date. I take pride in this fact <img alt="&#x1F609;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f609.png" style="height: 1em;"/> In my defense, I was an all-rounder at IIT Kharagpur, balancing studies, serving as a ‘secretary of fine arts, modeling and dramatics’ of my hostel, painting, learning guitar and many more things.</p>
<p class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">A second incident: </strong>During summer 2010 (at the end of my fourth year as a PhD student at GeorgiaTech), I was offered an internship at Yahoo labs and the Yahoo HR team wanted to verify all my credentials (my IIT B-Tech degree, USC Master’s degree, work experience). Yahoo uses a third-party service to rigorously verify all credentials of potential employees / interns. <a class="markup--anchor markup--p-anchor" href="https://www.thedailybeast.com/farewell-yahoo-ceo-scott-thompson-ousted-for-a-resume-lie" rel="noopener" target="_blank">Yahoo fired their own CEO</a>when they found out that he lied on his resume. This process is very rigorous, but very time-consuming. The <strong class="markup--strong markup--p-strong">verification of all my credentials took more than couple of months</strong>. Meanwhile, I was waiting with my fingers-crossed (figuratively speaking) and hoping these verifications happen soon, so that I can start my internship and earn some serious summer money for two months and see a bank balance of more than $1,000 dollars for the first time during my grad school <img alt="&#x1F609;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f609.png" style="height: 1em;"/></p>
<p class="graf graf--p">Later that year, when I discovered <a class="markup--anchor markup--p-anchor" href="https://bitcoin.org/bitcoin.pdf" rel="noopener" target="_blank">Bitcoin white paper</a>and the underlying Blockchain, my first thought was to use the technology to build a ‘<em class="markup--em markup--p-em">document integrity platform</em>’ to issue <strong class="markup--strong markup--p-strong">tamper-proof credentials</strong>(degrees, transcripts, employment certificates, Visas, Identity documents, driver’s license etc), <strong class="markup--strong markup--p-strong">which can be verified instantaneously and securely on the blockchain without compromising the privacy</strong>.</p>
<p class="graf graf--p">Early 2011, I got busy writing my PhD thesis and joined the CS department Princeton University in September 2011. I have spent the first couple of years teaching at Princeton, mining Bitcoin, keeping track of Blockchain news and hoping that somebody will develop a ‘document integrity platform’. To my relief, some entrepreneurs tried to develop a ‘credential verification solutions’. To my frustration, none of those solutions are perfect. So I started preparing myself to become a full-time entrepreneur (with several exciting startup ideas) and left Princeton in summer 2015.</p>
<p class="graf graf--p">I hired a truck driver (driving towards west coast) and told him that I will meet him around Sunnyvale/Santa Clara/ San Jose area in couple of weeks. I drove my car for a week to reach the Silicon Valley. Every 300 miles (when I was filling up my gas tank and my stomach), I was wondering “what the heck am I doing?”. I stayed at hotels along the way and I was recollecting all the incidents from my life in a chronological order as if I am watching a movie. This long-drive is a much-needed intermission.</p>
<p class="graf graf--p graf-after--p" id="5810">Today, I am very glad that we have a complete data integrity solution (for universities, employers and enterprises) and I am very excited that we are preventing fraud and corruption in several areas using our <a class="markup--anchor markup--p-anchor" href="https://truecerts.co/" rel="nofollow noopener" target="_blank">TrueCerts</a> platform.</p>
<p class="graf graf--p graf-after--p" id="e378">Every week I read several stories about fraud and corruption online (Eg: the recent <a class="markup--anchor markup--p-anchor" href="https://en.wikipedia.org/wiki/2019_college_admissions_bribery_scandal" rel="nofollow noopener" target="_blank">college admissions scandal</a>). I approach the involved parties and explain how such instances can be rigorously prevented using technology.</p>
<p class="graf graf--p">I feel very fortunate to have discovered an exciting vision towards a fraud-free and efficient future. This discovery happened through the above mentioned unfortunate events and many more real-life experiences. Sometimes the lowest points in your life have the greatest potential to show you the right path to your highest points. The most frustrating problems in your life are the biggest opportunities to develop a rigorous solution.</p></div>
    </content>
    <updated>2019-04-15T04:35:57Z</updated>
    <published>2019-04-15T04:35:57Z</published>
    <category term="blockchain"/>
    <category term="Education"/>
    <category term="IIT Kharagpur"/>
    <category term="upenn"/>
    <category term="Yahoo"/>
    <author>
      <name>kintali</name>
    </author>
    <source>
      <id>https://kintali.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/e1376dd220aa259d0efd0638d7619231?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://kintali.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kintali.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kintali.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kintali.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computational Complexity, Polyhedral Combinatorics, Algorithms and Graph Theory</subtitle>
      <title>My Brain is Open</title>
      <updated>2019-04-22T23:36:43Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3262168094346690140</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3262168094346690140/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/good-article-terrible-headline.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3262168094346690140" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3262168094346690140" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/good-article-terrible-headline.html" rel="alternate" type="text/html"/>
    <title>Good article, terrible headline</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">About a month ago (after my P NP poll appeared) I got email from Jacob Aron asking me some questions about it. One thing he was excited about was that the number of people who thought P vs NP would be solved in the next decade had increased from 11% to 22%. I told him that this also surprised me and <i>there had been no major advances to warrant that increase.</i><br/>
<i><br/></i>
Then the article came out. Here is the pointer to the headline and the first few lines, the rest is behind a paywall<br/>
<br/>
<a href="https://www.newscientist.com/article/2198151-we-could-solve-the-biggest-problem-in-maths-in-the-next-decade/">here</a><br/>
<br/>
You may notice that the headline is<br/>
<br/>
<i>We could solve the biggest problem in math in the next decade</i><br/>
<i><br/></i>
I emailed Jacob to send me the article, which he did. The article was fine, even quoting me as saying that the increase of people who thought it would be solved soon was unwarranted.<br/>
<br/>
1) So, article fine, headline terrible.<br/>
<br/>
2)  A more honest headline would be<br/>
<br/>
<i>The Complexity Theory Community slightly more optimistic about when P vs NP will be resolved for no apparent reason.</i><br/>
<i><br/></i>
3) More bad science:<a href="https://www.newscientist.com/article/mg22329780-400-turings-oracle-the-computer-that-goes-beyond-logic/">here</a><br/>
<br/>
Headline is<br/>
<br/>
<i>Turing's Oracle: The computer that goes beyond logic</i><br/>
<br/>
I think the article was about how a Turing Machine with an oracle for HALT can solve HALT. (If I am wrong about this let me know in the comments and I'll correct it.)<br/>
<br/>
4) More bad science:<a href="https://www.quantamagazine.org/finally-a-problem-that-only-quantum-computers-will-ever-be-able-to-solve-20180621/">here</a><br/>
<br/>
Headline<br/>
<br/>
<i>Finally, a problem that only Quantum Computers will ever be able to solve.</i><br/>
<i><br/></i>
This was about the oracle such that BQP is not in PH. Really!<br/>
<br/>
5) I invite you to add your own.<br/>
<br/>
6) OKAY, so why is the press SO BAD at reporting on our field? And is it just our field? I have one explanation, though I am sure there are many.<br/>
<br/>
Our field is about showing the LIMITS of computation. Its hard to make that sexy so they ... lie? exaggerate. They themselves don't really understand our field? Note:<br/>
<br/>
To explain to someone who does not really know CS why its important to have an oracle where BQP is not in PH is hard<br/>
<br/>
To explain this to someone IN CS but not in Theory is still hard!<br/>
<br/>
To explain this to someone IN CS and even in CS Theory, but not complexity (e.g., algorithms) might be hard, though it may depend on the person.<br/>
<br/>
7) The old saying is `I don't care if you get the story wrong so long as you spell my name right' And indeed, they did spell my name right. So there is that! But more seriously and less about me or even the article that refers to my poll--- is it bad that science reporting is often wrong?<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-04-15T04:08:00Z</updated>
    <published>2019-04-15T04:08:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-04-22T08:46:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://minimizingregret.wordpress.com/?p=116</id>
    <link href="https://minimizingregret.wordpress.com/2019/04/15/reinforcement-learning-without-rewards/" rel="alternate" type="text/html"/>
    <link href="https://videos.files.wordpress.com/ro0BDWO4/cheetah-pretty_hd.mp4" length="19415040" rel="enclosure" type="video/mp4"/>
    <title>Reinforcement learning without rewards</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">by Abby van Soest and Elad Hazan, based on this paper  When humans interact with the environment, we receive a series of signals that indicate the value of our actions. We know that chocolate tastes good, sunburns feel bad, and certain actions generate praise or disapproval from others. Generally speaking, we learn from these signals … <a class="more-link" href="https://minimizingregret.wordpress.com/2019/04/15/reinforcement-learning-without-rewards/">Continue reading <span class="screen-reader-text">Reinforcement learning without rewards</span> <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>by <a href="http://www.abbyvansoest.com/">Abby van Soest</a> and Elad Hazan, based on <a href="https://arxiv.org/abs/1812.02690">this paper</a> </em></p>
<p>When humans interact with the environment, we receive a series of signals that indicate the value of our actions. We know that chocolate tastes good, sunburns feel bad, and certain actions generate praise or disapproval from others. Generally speaking, we learn from these signals and adapt our behavior in order to get more positive “rewards” and fewer negative ones.</p>
<p><i>Reinforcement learning</i> (RL) is a sub-field of machine learning that formally models this setting of learning through interaction in a reactive environment. In RL, we have an <b>agent</b> and an <b>environment</b>. The agent observes its position (or “state”) in the environment and takes actions that transition it to a new state. The environment looks at an agent’s state and hands out rewards based on a hidden set of criteria.</p>
<p style="text-align: center;"><img alt="" height="145" src="https://minimizingregret.files.wordpress.com/2019/04/null.png?w=360&amp;h=145" title="" width="360"/></p>
<p><i>Source: <a href="http://incompleteideas.net/book/bookdraft2017nov5.pdf">Reinforcement Learning: An Introduction</a>. Sutton &amp; Barto, 2017.</i></p>
<p>Typically, the goal of RL is for the agent to learn behavior that maximizes<i> </i>the total reward it receives from the environment. This methodology has led to some notable successes: machines have learned how to<a href="https://deepmind.com/research/publications/playing-atari-deep-reinforcement-learning/"> play Atari games</a>, how to <a href="https://sigmoidal.io/alphago-how-it-uses-reinforcement-learning-to-beat-go-masters/">beat human masters</a> of Go, and how to write <a href="https://www.theverge.com/2019/2/14/18224704/ai-machine-learning-language-models-read-write-openai-gpt2">long-form responses</a> to an essay prompt.</p>
<h2>But what can we learn without an external reward signal?</h2>
<p>It seems like a paradoxical question to ask, given that RL is all about rewards. But even though the reward paradigm is fundamentally flexible in many ways, it is also brittle and limits the agent’s ability to learn about its environment. This is due to several reasons. First, a reward signal directs the agents towards a single specific goal that may not generalize. Second, the reward signal may be sparse and uninformative, as we illustrate below.</p>
<p>Imagine that you want a robot to learn to navigate through the following maze.</p>
<p><b>Case 1: Sparse Rewards.</b> The agent gets a reward of +1 when it exits the maze, and a reward of 0 everywhere else. The agent doesn’t learn anything until it stumbles upon the exit.</p>
<p style="text-align: center;">⇒ Clear reward signals are not always available.</p>
<p><b>Case 2: Misleading Rewards.</b> The agent gets a reward of +1 at the entrance and a reward of +10 at the exit. The agent incorrectly learns to sit at the entrance because it hasn’t explored its environment sufficiently.</p>
<p style="text-align: center;">⇒ Rewards can <i>prevent</i> discovery of the full environment.</p>
<p>These issues are easy to overcome in the small maze on the left. But what about the maze on the right? As the size of the environment grows, it’ll get harder and harder to find the correct solution — the intractability of the problem scales exponentially.</p>
<p style="text-align: center;"><img alt="" height="238" src="https://minimizingregret.files.wordpress.com/2019/04/image.png?w=244&amp;h=238" title="" width="244"/><img alt="pasted image 0.png" class="alignnone size-full wp-image-130" src="https://minimizingregret.files.wordpress.com/2019/04/pasted-image-0.png?w=1100"/></p>
<p>So what we find is that there is power<i> </i>in being able to learn effectively in the <b>absence</b> of rewards. This intuition is supported by a body of research that shows learning fails when rewards aren’t dense or are <a href="https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/NgHaradaRussell-shaping-ICML1999.pdf">poorly shaped</a>; and fixing these problems can require substantial engineering effort.</p>
<p>By enabling agents to discover the environment without the requirement of a reward signal, we create a more<b> flexible and generalizable</b> form of reinforcement learning. This framework can be considered a form of “unsupervised” RL. Rather than relying on explicit and inherently limited signals (or “labels”), we can deal with a broad, unlabelled pool of data. Learning from this pool facilitates a more general extraction of knowledge from the environment.</p>
<h2>Our new approach: Maximum Entropy</h2>
<p>In <a href="https://arxiv.org/abs/1812.02690">recent work</a>, we propose finding a policy that maximizes entropy (which we refer to as a MaxEnt policy), or another related and concave function of the distribution. This objective is reward-independent and favors exploration.</p>
<p>In the video below, a two-dimensional cheetah robot learns to run backwards and forwards, move its legs fast and in all different directions, and even do flips. The cheetah doesn’t have access to any external rewards; it only uses signals from the MaxEnt policy.</p>
<p> </p>
<div class="video-player" id="v-ro0BDWO4-1" style="width: 1100px; height: 620px;">
</div>
<p>Entropy is a function of the distribution over states. A high entropy distribution visits all states with near-equal frequency — it’s a <i>uniform</i> distribution. On the other hand, a low entropy distribution is biased toward visiting some states more frequently than others. (In the maze example, a low entropy distribution would result from the agent sitting at the entrance of the maze forever.)</p>
<p><img alt="slAdX3I4FcseBWeJbioHb_g.png" class=" size-full wp-image-129 aligncenter" src="https://minimizingregret.files.wordpress.com/2019/04/sladx3i4fcsebwejbiohb_g.png?w=1100"/></p>
<p>So given that policy <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\pi"/> creates a distribution <img alt="d_\pi" class="latex" src="https://s0.wp.com/latex.php?latex=d_%5Cpi&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="d_\pi"/> over states, the problem we are hoping to solve is:</p>
<p style="text-align: center;"><img alt="\pi^* = \arg \max_{\pi} \text{entropy}(d_\pi) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi%5E%2A+%3D+%5Carg+%5Cmax_%7B%5Cpi%7D+%5Ctext%7Bentropy%7D%28d_%5Cpi%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\pi^* = \arg \max_{\pi} \text{entropy}(d_\pi) "/></p>
<p>When we know all the states, actions, and dynamics of a given environment, finding the policy with maximum entropy is a concave optimization problem. This type of problem can be easily and exactly solved by convex programming.</p>
<p>But we very rarely have all that knowledge available to use. In practice, one of several complications usually arise:</p>
<ol>
<li>The states are <b>non-linearly approximated </b>by a neural network or some other function approximator.</li>
<li>The transition dynamics are unknown.</li>
<li>The state space is intractably large. (As an interesting example, the game of Go has more than<b> one googol or <img alt="10^{100}" class="latex" src="https://s0.wp.com/latex.php?latex=10%5E%7B100%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="10^{100}"/></b> possible states. That’s more than the number of atoms in the universe, according to <a href="https://ai.googleblog.com/2016/01/alphago-mastering-ancient-game-of-go.html">this blog</a> from 2016, and definitely more than can fit on a computer.)</li>
</ol>
<p>In such cases, the problem of finding a max-entropy policy becomes non-convex and computationally hard.</p>
<p>So what to do? If we look at many practical RL problems (Atari, OpenAI Gym), we see that there are many known, efficient solvers that can construct an optimal (or nearly-optimal) policy when they are <i>given a reward signal</i>.</p>
<p>We thus consider an <i>oracle model</i>: let’s assume that we have access to one of these solvers, so that we can pass it an explicit reward vector and receive an optimal policy in return. Can we now maximize entropy in a provably efficient way? In other words, is it possible to reduce this high complexity optimization problem to that of “standard” RL?</p>
<p>Our approach does exactly that! It is based on the Frank-Wolfe method. This is a gradient-based optimization algorithm that is particularly suited for oracle-based optimization. Instead of moving in the direction of the steepest decline of the objective function, the Frank-Wolfe method iteratively moves in the direction of the optimal point in the direction of the gradient. This is depicted below (and deserves a separate post…). The Frank-Wolfe method is a projection-free algorithm, see <a href="https://drive.google.com/file/d/1GIDnw7T-NT4Do3eC0B5kYJlzwOs6nzIO/view">this exposition</a> about its theoretical properties.</p>
<p><img alt="" height="345" src="https://minimizingregret.files.wordpress.com/2019/04/unnamed-file.png?w=616&amp;h=345" title="" width="616"/></p>
<p>For the exact specification of the algorithm and its performance guarantee, see<a href="https://arxiv.org/abs/1812.02690"> our paper</a>.</p>
<h2>Experiments</h2>
<p>To complement the theory, we also created some experiments to test the MaxEnt algorithm on simulated robotic locomotion tasks (<a href="https://github.com/abbyvansoest/maxent/tree/refactor">open source code available here</a>). We used test environments from <a href="https://gym.openai.com/">OpenAI Gym</a> and <a href="https://github.com/openai/mujoco-py">Mujoco</a> and trained MaxEnt experts for various environments.</p>
<p>These are some results from the Humanoid experiment, where the agent is a human-like bipedal robot. The behavior of the MaxEnt agent (blue) is baselined against a random agent (orange), who explores by sampling randomly from the environment. This random approach is often used in practice for epsilon-greedy RL exploration.</p>
<p style="text-align: center;"><img alt="" height="332" src="https://minimizingregret.files.wordpress.com/2019/04/null-1.png?w=442&amp;h=332" title="" width="442"/></p>
<p>In this figure, we see that over the course of 25 epochs, the MaxEnt agent progressively increases the total entropy over the state space.</p>
<p style="text-align: center;"><img alt="" height="345" src="https://minimizingregret.files.wordpress.com/2019/04/null-2.png?w=460&amp;h=345" title="" width="460"/></p>
<p>Here, we see a visualization of the Humanoid’s coverage of the $xy$-plane, where the shown plane is of size 40-by-40. After one epoch, there is <b>minimal</b> coverage of the area. But by the 5th, 10th, and 15th epoch, we see that the agent has learned to visit all the different states in the plane, obtaining full and nearly uniform coverage of the grid!</p>
<div><a href="https://minimizingregret.wordpress.com/2019/04/15/reinforcement-learning-without-rewards/"><img alt="cheetah-pretty" height="120" src="https://videos.files.wordpress.com/ro0BDWO4/cheetah-pretty_std.original.jpg" width="160"/></a></div></div>
    </content>
    <updated>2019-04-15T01:03:27Z</updated>
    <published>2019-04-15T01:03:27Z</published>
    <category term="Uncategorized"/>
    <category term="machine learning"/>
    <category term="reinforcement learning"/>
    <author>
      <name>Elad Hazan</name>
    </author>
    <source>
      <id>https://minimizingregret.wordpress.com</id>
      <logo>https://minimizingregret.files.wordpress.com/2017/08/cropped-pu1.png?w=32</logo>
      <link href="https://minimizingregret.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://minimizingregret.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://minimizingregret.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://minimizingregret.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Google Princeton AI and Hazan Lab @ Princeton University</subtitle>
      <title>Minimizing Regret</title>
      <updated>2019-04-22T23:38:09Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/04/14/monochromatic-grids-colored</id>
    <link href="https://11011110.github.io/blog/2019/04/14/monochromatic-grids-colored.html" rel="alternate" type="text/html"/>
    <title>Monochromatic grids in colored grids</title>
    <summary>Color the points of an grid with two colors. How big a monochromatic grid-like subset can you find? By “grid-like” I mean that it should be possible to place equally many horizontal and vertical lines, partitioning the plane into cells each of which contains a single point.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Color the points of an  grid with two colors. How big a monochromatic grid-like subset can you find? By “grid-like” I mean that it should be possible to place equally many horizontal and vertical lines, partitioning the plane into  cells each of which contains a single point.</p>

<p>So for the coloring of the  grid below, there are several  monochromatic grid-like subsets. The image below shows one, and the completely red and blue southwest and northeast quadrants provide two others.
The blue quadrant prevents any red grid-like subset from being larger than , and vice versa, so these are the largest grid-like subsets in this grid.</p>

<p style="text-align: center;"><img alt="Monochromatic grid-like subset in a colored grid" src="https://11011110.github.io/blog/assets/2019/subgrid.svg"/></p>

<p>It’s not hard to prove that there always exists a monochromatic grid-like subset of size at least .
Just use vertical and horizontal lines to partition the big grid into blocks of that size. If one of those blocks is monochromatic, then it’s the grid-like subset you’re looking for. And if not, you can choose a red point from each block to get a grid-like subset of the same size.</p>

<p>In the other direction, there exist colorings of an  grid for which the largest monochromatic grid-like subset has size only a little bigger, . To find such a coloring, partition the big grid into square blocks of size , and make each block monochromatic with a randomly chosen color.</p>

<p style="text-align: center;"><img alt="Coloring a grid by dividing into square blocks and coloring each block randomly" src="https://11011110.github.io/blog/assets/2019/blocked-coloring.svg"/></p>

<p>Now, consider any partition by axis-parallel lines into (irregular) rectangles, each containing one of the points of a grid-like subset.  Only one row or column of the rectangles can cross each line of the partition into square blocks, so the number of rectangles that include parts of two or more square blocks is . Any remaining rectangles of the partition must come from a grid-like subset of square blocks that are all colored the same as each other. But with a random coloring, the expected size of this largest monochromatic subset of square blocks is . Therefore, the number of rectangles that stay within a single square block is limited to the total number of points in this grid-like subset of square blocks, which is again .</p>

<p>I’m not sure how to eliminate the remaining  gap between these two bounds, or which way it should go.</p>

<p>One application of these ideas involves the theory of <a href="https://en.wikipedia.org/wiki/Superpattern">superpatterns</a>, permutations that contain as a <a href="https://en.wikipedia.org/wiki/Permutation_pattern">pattern</a> every smaller permutation up to some size .
If  is a superpattern for the permutations of size , then we can obtain a point set by interpreting the position and value of each element of  as Cartesian coordinates. This point set includes a grid-like subset of size , coming from a permutation of size  that translates to a grid-like set of points.
If the elements of the superpattern are colored with two colors, there still exists a monochromatic grid-like subset of size .
And this monochromatic grid-like subset corresponds to a superpattern, for permutations of size . So, whenever the elements of a superpattern are colored with two (or finitely many) colors, there remains a monochromatic subset of elements that is still a superpattern for permutations of some smaller but non-constant size.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/101927319466372642">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-04-14T17:02:00Z</updated>
    <published>2019-04-14T17:02:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-04-16T01:45:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/057</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/057" rel="alternate" type="text/html"/>
    <title>TR19-057 |  Proof Complexity of Symmetry Learning in QBF | 

	Joshua Blinkhorn, 

	Olaf Beyersdorff</title>
    <summary>For quantified Boolean formulas (QBF), a resolution system with a symmetry rule was recently introduced by Kauers and Seidl (Inf. Process. Lett. 2018). In this system, many formulas hard for QBF resolution admit short proofs.

Kauers and Seidl apply the symmetry rule on symmetries of the original formula. Here we propose a new formalism where symmetries are dynamically recomputed during the proof on restrictions of the original QBF. This presents a theoretical model for the potential use of symmetry learning as an inprocessing rule in QCDCL solving.

We demonstrate the power of symmetry learning by proving an exponential separation between Q-resolution with the symmetry rule and Q-resolution with our new symmetry learning rule. In fact, we show that bounding the number of symmetry recomputations gives rise to a hierarchy of QBF resolution systems of strictly increasing strength.</summary>
    <updated>2019-04-14T10:26:19Z</updated>
    <published>2019-04-14T10:26:19Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-22T23:36:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/056</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/056" rel="alternate" type="text/html"/>
    <title>TR19-056 |  A Lower Bound for Relaxed Locally Decodable Codes | 

	Tom Gur, 

	Oded Lachish</title>
    <summary>A locally decodable code (LDC) C:{0,1}^k -&gt; {0,1}^n is an error correcting code wherein individual bits of the message can be recovered by only querying a few bits of a noisy codeword. LDCs found a myriad of applications both in theory and in practice, ranging from probabilistically checkable proofs to distributed storage. However, despite nearly two decades of extensive study, the best known constructions of O(1)-query LDCs have super-polynomial blocklength.

The notion of relaxed LDCs is a natural relaxation of LDCs, which aims to bypass the foregoing barrier by requiring local decoding of nearly all individual message bits, yet allowing decoding failure (but not error) on the rest. State of the art constructions of O(1)-query relaxed LDCs achieve blocklength n = O(k^{1+ \gamma}) for an arbitrarily small constant \gamma.

We prove a lower bound which shows that O(1)-query relaxed LDCs cannot achieve blocklength n = k^{1+ o(1)}. This resolves an open problem raised by Ben-Sasson, Goldreich, Harsha, Sudan, and Vadhan (STOC 2004).</summary>
    <updated>2019-04-14T08:31:30Z</updated>
    <published>2019-04-14T08:31:30Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-22T23:36:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://mycqstate.wordpress.com/?p=1229</id>
    <link href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/" rel="alternate" type="text/html"/>
    <title>Randomness and interaction? Entanglement ups the game!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The study of entanglement through the length of interactive proof systems has been one of the most productive applications of complexity theory to the physical sciences that I know of. Last week Anand Natarajan and John Wright, postdoctoral scholars at … <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The study of entanglement through the length of interactive proof systems has been one of the most productive applications of complexity theory to the physical sciences that I know of. Last week Anand Natarajan and John Wright, postdoctoral scholars at Caltech and MIT respectively, added a <a href="https://arxiv.org/abs/1904.05870">major stone</a> to this line of work. Anand &amp; John (hereafter “NW”) establish the following wild claim: it is possible for a classical polynomial-time verifier to decide membership in any language in <em>non-deterministic doubly exponential time</em> by asking questions to two infinitely powerful, but untrusted, provers sharing entanglement. In symbols, NEEXP <img alt="{\subseteq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csubseteq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\subseteq}"/> MIP<img alt="{^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{^\star}"/>! (The last symbol is for emphasis — no, we don’t have an MIP<img alt="{^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{^\star}"/>! class — yet.)</p>
<p>What is amazing about this result is the formidable gap between the complexity of the verifier and the complexity of the language being verified. We know since the 90s that the use of interaction and randomness can greatly expand the power of polynomial-time verifiers, from NP to <a href="https://dl.acm.org/citation.cfm?id=146609">PSPACE</a> (with a single prover) and <a href="https://dl.acm.org/citation.cfm?id=2794945">NEXP</a> (with two provers). As a result of the work of Natarajan and Wright, we now know that yet an additional ingredient, the use of <em>entanglement</em> between the provers, can be leveraged by the verifier — the same verifier as in the previous results, a classical randomized polynomial-time machine — to obtain an exponential increase in its verification power. Randomness and interaction brought us one exponential; entanglement gives us another.</p>
<p>To gain intuition for the result consider first the structure of a classical two-prover one-round interactive proof system for non-deterministic doubly exponential time, with exponential-time verifier. Cutting some corners, such a protocol can be obtained by “scaling up” a standard two-prover protocol for non-deterministic singly exponential time. In the protocol, the verifier would sample a pair of exponential-length questions <img alt="{(X,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(X,Y)}"/>, send <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> and <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> to each prover, receive answers <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/>, and perform an exponential-time computation that verifies some predicate about <img alt="{(X,Y,A,B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%2CA%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(X,Y,A,B)}"/>.</p>
<p>How can entanglement help design an <em>exponentially more efficient</em> protocol? At first it may seem like a polynomial-time verifier has no way to even get started: if it can only communicate polynomial-length messages with the provers, how can it leverage their power? And indeed, if the provers are classical, it can’t: it is known that even with a polynomial number of provers, and polynomially many rounds of interaction, a polynomial-time verifier cannot decide any language beyond NEXP.</p>
<p>But the provers in the NW protocol are not classical. They can share entanglement. How can the verifier exploit this to its advantage? The key property that is needed is know as the <em>rigidity</em> of entanglement. In words, rigidity is the idea that by verifying the presence of certain statistical correlations between the provers’ questions and answers the verifier can determine precisely (up to a local change of basis) the quantum state and measurements that the provers must have been using to generate their answers. The most famous example of rigidity is the <em>CHSH game</em>: as already shown by <a href="http://www.numdam.org/item/AIHPA_1988__49_2_215_0/">Werner and Summers</a> in 1982, the CHSH game can only be optimally, or even near-optimally, won by measuring a maximally entangled state using two mutually unbiased bases for each player. No other state or measurements will do, unless they trivially imply an EPR pair and mutually unbiased bases (such as a state that is the tensor product of an EPR pair with an additional entangled state).</p>
<p>Rigidity gives the verifier control over the provers’ use of their entanglement. The simplest use of this is for the verifier to force the provers to share a certain number <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> of EPR pairs and measure them to obtain identical uniformly distributed <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/>-bit strings. Such a test for <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> EPR pairs can be constructed from <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> CHSH games. In a <a href="https://arxiv.org/abs/1801.03821">paper</a> with Natarajan we give a more efficient test that only requires questions and answers of length that is poly-logarithmic in <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/>. Interestingly, the test is built on classical machinery — the low-degree test — that plays a central role in the analysis of some classical multi-prover proof systems for NEXP.</p>
<p>At this point we have made an inch of progress: it is possible for a polynomial-time (in <img alt="{n=\log N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D%5Clog+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n=\log N}"/>) verifier to “command” two quantum provers sharing entanglement to share <img alt="{N=2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%3D2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N=2^n}"/> EPR pairs, and measure them in identical bases to obtain identical uniformly random <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/>-bit strings. What is this useful for? Not much — yet. But here comes the main insight in NW: suppose we could similarly force the provers to generate, not identical uniformly random strings, but a pair of <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/>-bit strings <img alt="{(X,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(X,Y)}"/> that is distributed as a pair of questions from the verifier in the aforementioned interactive proof system for NEEXP with exponential-time (in <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>) verifier. Then we could use a polynomial-time (in <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>) verifier to “command” the provers to generate their exponentially-long questions <img alt="{(X,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(X,Y)}"/> by themselves. The provers would then compute answers <img alt="{(A,B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28A%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(A,B)}"/> as in the NEEXP protocol. Finally, they would prove to the verifier, using a polynomial interaction, that <img alt="{(A,B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28A%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(A,B)}"/> is a valid pair of answers to the pair of questions <img alt="{(X,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(X,Y)}"/> — indeed, the latter verification is an NEXP problem, hence can be verified using a protocol with polynomial-time verifier.</p>
<p>Sounds crazy? Yes. But they did it! Of course there are many issues with the brief summary above — for example, how does the verifier even know the questions <img alt="{X,Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%2CY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X,Y}"/> sampled by the provers? The answer is that it doesn’t need to know the entire question; only that it was sampled correctly, and that the quadruple <img alt="{(X,Y,A,B)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%2CA%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(X,Y,A,B)}"/> satisfies the verification predicate of the exponential-time verifier. This can be verified using a polynomial-time interactive proof.</p>
<p>Diving in, the most interesting insight in the NW construction is what they call “introspection”. What makes multi-prover proof systems powerful is the ability for the verifier to send correlated questions to the provers, in a way such that each prover has only partial information about the other’s question — informally, the verifier plays a variant of prisonner’s dilemma with the provers. In particular, any interesting distribution <img alt="{(X,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(X,Y)}"/> will have the property that <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> and <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> are not fully correlated. For a concrete example think of the “planes-vs-lines” distribution, where <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> is a uniformly random plane and <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> a uniformly random line in <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>. The aforementioned test for <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> EPR pairs can be used to force both provers to sample the same uniformly random plane <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>. But how does the verifier ensure that one of the provers “forgets” parts of the plane, to only remember a uniformly random line <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> that is contained in it? NW’s insight is that the information present in a quantum state — such as the prover’s half-EPR pairs — can be “erased” by commanding the prover to perform a measurement in the <em>wrong</em> basis — a basis that is mutually unbiased with the basis used by the other prover to obtain its share of the query. Building on this idea, NW develop a battery of delicate tests that provide the verifier the ability to control precisely what information gets distributed to each prover. This allows a polynomial-time verifier to perfectly simulate the local environment that the exponential-time verifier would have created for the provers in a protocol for NEEXP, thus simulating the latter protocol with exponentially less resources.</p>
<p>One of the aspects of the NW result I like best is that they showed how the “history state barrier” could be overcome. Previous works attempting to establish strong lower bounds on the class MIP<img alt="{^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{^\star}"/>, such as the <a href="https://arxiv.org/abs/1805.12166">paper</a> by Yuen et al., relies on a compression technique that requires the provers to share a history state of the computation performed by a larger protocol. Unfortunately, history states are very non-robust, and as a result such works only succeeded in developing protocols with vanishing completeness-soundness gap. NW entirely bypass the use of history states, and this allows them to maintain a constant gap.</p>
<p>Seven years ago Tsuyoshi Ito and I showed that <a href="https://arxiv.org/abs/1207.0550">MIP<img alt="{}^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7D%5E%5Cstar&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{}^\star"/> contains NEXP</a>. At the time, we thought this may be the end of the story — although it seemed challenging, surely someone would eventually prove a matching upper bound. Natarajan and Wright have defeated this expectation by showing that MIP<img alt="{^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{^\star}"/> contains NEEXP. What next? NEEEXP? The halting problem? I hope to make this the topic of a future post.</p></div>
    </content>
    <updated>2019-04-14T04:35:25Z</updated>
    <published>2019-04-14T04:35:25Z</published>
    <category term="CHSH"/>
    <category term="QPCP"/>
    <category term="Quantum"/>
    <category term="Uncategorized"/>
    <category term="interactive proofs"/>
    <author>
      <name>Thomas</name>
    </author>
    <source>
      <id>https://mycqstate.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://mycqstate.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://mycqstate.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://mycqstate.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://mycqstate.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>In superposition</subtitle>
      <title>MyCQstate</title>
      <updated>2019-04-22T23:38:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/04/13/phd-student-algorithmic-aspects-of-automated-theorem-proving-at-university-of-bergen-norway-apply-by-may-5-2019/</id>
    <link href="https://cstheory-jobs.org/2019/04/13/phd-student-algorithmic-aspects-of-automated-theorem-proving-at-university-of-bergen-norway-apply-by-may-5-2019/" rel="alternate" type="text/html"/>
    <title>PhD Student: Algorithmic aspects of automated theorem proving at University of Bergen (Norway) (apply by May 5, 2019)</title>
    <summary>The Department of Informatics at the University of Bergen (Norway) has announced a 3 years PhD position in Algorithms. The focus of the position will be on the algorithmic aspects of automated reasoning, and in particular, in the algorithms aspects of automated theorem proving. Website: https://www.jobbnorge.no/en/available-jobs/job/168659/phd-position-in-algorithms Email: mateus.oliveira@uib.no</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Informatics at the University of Bergen (Norway) has announced a 3 years PhD position in Algorithms. The focus of the position will be on the algorithmic aspects of automated reasoning, and in particular, in the algorithms aspects of automated theorem proving.</p>
<p>Website: <a href="https://www.jobbnorge.no/en/available-jobs/job/168659/phd-position-in-algorithms">https://www.jobbnorge.no/en/available-jobs/job/168659/phd-position-in-algorithms</a><br/>
Email: mateus.oliveira@uib.no</p></div>
    </content>
    <updated>2019-04-13T09:59:23Z</updated>
    <published>2019-04-13T09:59:23Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-04-22T23:36:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-32902056.post-7573420523219990282</id>
    <link href="http://paulwgoldberg.blogspot.com/feeds/7573420523219990282/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=32902056&amp;postID=7573420523219990282" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/32902056/posts/default/7573420523219990282" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/32902056/posts/default/7573420523219990282" rel="self" type="application/atom+xml"/>
    <link href="http://paulwgoldberg.blogspot.com/2019/04/new-conference-acm-siam-algorithmic.html" rel="alternate" type="text/html"/>
    <title>New conference: ACM-SIAM Algorithmic Principles of Computer Systems (APoCS20)</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div dir="ltr" style="text-align: left;"><div class="">ACM-SIAM Algorithmic Principles of Computer Systems (APoCS20)</div><div class=""><a class="" href="https://www.siam.org/Conferences/CM/Main/apocs20">https://www.siam.org/Conferences/CM/Main/apocs20</a></div><div class=""><br class=""/></div><div class="">January 8, 2020</div><div class="">Hilton Salt Lake City Center, Salt Lake City, Utah, USA</div><div class="">Colocated with SODA, SOSA, and Alenex</div><div class=""><br class=""/></div><div class="">The First ACM-SIAM APoCS is sponsored by SIAM SIAG/ACDA and ACM SIGACT.</div><div class=""><br class=""/></div><div class=""><b class="">Important Dates:</b></div><div class=""><br class=""/></div><div class=""><span class="Apple-tab-span" style="white-space: pre;"/>August 9: Abstract Submission and Paper Registration Deadline</div><div class=""><span class="Apple-tab-span" style="white-space: pre;"/>August 16: Full Paper Deadline</div><div class=""><span class="Apple-tab-span" style="white-space: pre;"/>October 4: Decision Announcement</div><div class=""><br class=""/></div><div class=""><b class="">Program Chair:</b></div><div class=""><br class=""/></div><div class="">Bruce Maggs, Duke University and Akamai Technologies</div><div class=""><br class=""/></div><div class=""><b class="">Submissions:</b></div><div class=""><br class=""/></div><div class="">Contributed papers are sought in all areas of algorithms and  architectures that offer insight into the performance and design of  computer systems.  Topics of interest include, but are not limited to  algorithms and data structures for:</div><div class=""><br class=""/></div><div class="">Databases</div><div class="">Compilers</div><div class="">Emerging Architectures</div><div class="">Energy Efficient Computing</div><div class="">High-performance Computing</div><div class="">Management of Massive Data</div><div class="">Networks, including Mobile, Ad-Hoc and Sensor Networks</div><div class="">Operating Systems</div><div class="">Parallel and Distributed Systems</div><div class="">Storage Systems</div><div class=""><br class=""/></div><div class=""><br class=""/></div><div class="">A submission must report original research that has not previously or is  not concurrently being published. Manuscripts must not exceed twelve  (12) single-spaced double-column pages, in addition the bibliography and  any pages containing only figures.  Submission  must be self-contained, and any extra details may be submitted in a  clearly marked appendix. </div><div class=""><br class=""/></div><div class=""><b class="">Steering Committee:</b></div><div class=""><br class=""/></div><div class="">Michael Bender</div><div class="">Guy Blelloch</div><div class="">Jennifer Chayes</div><div class="">Martin Farach-Colton (Chair)</div><div class="">Charles Leiserson</div><div class="">Don Porter</div><div class="">Jennifer Rexford</div><div class="">Margo Seltzer</div></div></div>
    </content>
    <updated>2019-04-12T08:27:00Z</updated>
    <published>2019-04-12T08:27:00Z</published>
    <category scheme="http://www.blogger.com/atom/ns#" term="aggregator"/>
    <category scheme="http://www.blogger.com/atom/ns#" term="conferences"/>
    <author>
      <name>Paul Goldberg</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/10952445127830395305</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-32902056</id>
      <category term="aggregator"/>
      <category term="UK academia"/>
      <category term="politics"/>
      <category term="meetings"/>
      <category term="research"/>
      <category term="research directions"/>
      <category term="conferences"/>
      <category term="funding"/>
      <category term="people"/>
      <category term="rant"/>
      <category term="economics"/>
      <category term="academia"/>
      <category term="forecasts"/>
      <category term="internet"/>
      <category term="advertisement"/>
      <category term="trips"/>
      <category term="game theory"/>
      <category term="University of Liverpool"/>
      <category term="editorial"/>
      <category term="times higher"/>
      <category term="announcements"/>
      <category term="publications"/>
      <category term="teaching"/>
      <category term="technical"/>
      <category term="work"/>
      <category term="postgraduate research"/>
      <category term="technology"/>
      <category term="books"/>
      <category term="social choice"/>
      <category term="talks"/>
      <category term="CACM"/>
      <category term="liverpool"/>
      <category term="open problems"/>
      <category term="problems"/>
      <category term="research assessment"/>
      <category term="tongue in cheek"/>
      <category term="administration"/>
      <category term="architecture"/>
      <category term="email"/>
      <category term="environment"/>
      <category term="games"/>
      <category term="mechanism design"/>
      <category term="puzzles"/>
      <category term="web sites"/>
      <category term="URLs"/>
      <category term="USS"/>
      <category term="education"/>
      <category term="higher education"/>
      <category term="oxford"/>
      <category term="schools"/>
      <category term="UCU"/>
      <category term="go"/>
      <category term="intellectual property"/>
      <category term="jobs"/>
      <category term="league table"/>
      <category term="math education"/>
      <category term="money"/>
      <category term="products"/>
      <category term="science"/>
      <category term="students"/>
      <category term="Liberal democrats"/>
      <category term="UK"/>
      <category term="XJTLU"/>
      <category term="behavioural economics"/>
      <category term="china"/>
      <category term="current affairs"/>
      <category term="diversity"/>
      <category term="epsrc"/>
      <category term="family"/>
      <category term="geography"/>
      <category term="holidays"/>
      <category term="joke"/>
      <category term="misc"/>
      <category term="nerd humour"/>
      <category term="pensions"/>
      <category term="proposals"/>
      <category term="psephology"/>
      <category term="region"/>
      <category term="visits"/>
      <category term="warwick"/>
      <category term="web"/>
      <category term="weekends"/>
      <category term="wikipedia"/>
      <category term="writing"/>
      <author>
        <name>Paul Goldberg</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/10952445127830395305</uri>
      </author>
      <link href="http://paulwgoldberg.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/32902056/posts/default/-/aggregator" rel="self" type="application/atom+xml"/>
      <link href="http://paulwgoldberg.blogspot.com/search/label/aggregator" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/32902056/posts/default/-/aggregator/-/aggregator?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>theoretical computer science, economics, and academic life in general. Writing in personal capacity, not representing my employer or other colleagues</subtitle>
      <title>Paul Goldberg</title>
      <updated>2019-04-22T08:46:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4152</id>
    <link href="https://www.scottaaronson.com/blog/?p=4152" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4152#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4152" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Wonderful world</title>
    <summary xml:lang="en-US">I was saddened about the results of the Israeli election. The Beresheet lander, which lost its engine and crashed onto the moon as I was writing this, seems like a fitting symbol for where the country is now headed. Whatever he was at the start of his career, Netanyahu has become the Israeli Trump—a breathtakingly […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>I was saddened about the results of the Israeli election.  The Beresheet lander, which lost its engine and crashed onto the moon as I was writing this, seems like a fitting symbol for where the country is now headed.  Whatever he was at the start of his career, Netanyahu has become the Israeli Trump—a breathtakingly corrupt strongman who appeals to voters’ basest impulses, sacrifices his country’s future and standing in the world for short-term electoral gain, considers himself unbound by laws, recklessly incites hatred of minorities, and (despite zero personal piety) cynically panders to religious fundamentalists who help keep him in power.  Just like with Trump, it’s probably futile to hope that lawyers will swoop in and free the nation from the demagogue’s grip: legal systems simply aren’t designed for assaults of this magnitude.</p>



<p>(If, for example, you were designing the US Constitution, how would you guard against a presidential candidate who <em>openly</em> supported and was supported by a hostile foreign power, and won anyway?  Would it even occur to you to include such possibilities in your definitions of concepts like “treason” or “collusion”?)</p>



<p>The original Zionist project—the secular, democratic vision of Herzl and Ben-Gurion and Weizmann and Einstein, which the Nazis turned from a dream to a necessity—matters more to me than most things in this world, and that was true even before I’d spent time in Israel and before I had a wife and kids who are Israeli citizens.  It would be depressing if, after a century of wildly improbable victories against external threats, Herzl’s project were finally to eat itself from the inside.  Of course I have analogous worries (scaled up by two orders of magnitude) for the US—not to mention the UK, India, Brazil, Poland, Hungary, the Philippines … the world is now engaged in a massive test of whether Enlightenment liberalism can long endure, or whether it’s just a metastable state between one Dark Age and the next.  (And to think that people have accused me of uncritical agreement with Steven Pinker, the world’s foremost optimist!)</p>



<p>In times like this, one takes one’s happiness where one can find it.</p>



<p>So, yeah: I’m happy that there’s now an “image of a black hole” (or rather, of radio waves being bent around a black hole’s silhouette).  If you really want to understand what the now-ubiquitous image is showing, I strongly recommend <a href="https://profmattstrassler.com/2019/04/09/a-non-experts-guide-to-a-black-holes-silhouette/">this guide</a> by Matt Strassler.</p>



<p>I’m happy that integer multiplication can apparently <a href="https://web.maths.unsw.edu.au/~davidharvey/papers/nlogn/">now be done</a> in O(n log n), capping a decades-long quest (see also <a href="https://rjlipton.wordpress.com/2019/03/29/integer-multiplication-in-nlogn-time/">here</a>).</p>



<p>I’m happy that there’s now apparently a spectacular fossil record of the first minutes after the asteroid impact that ended the Cretaceous period.  Even better will be if this finally proves that, yes, some non-avian dinosaurs were still alive on impact day, and had not gone extinct due to unrelated climate changes slightly earlier.  (Last week, my 6-year-old daughter sang a song in a school play about how “no one knows what killed the dinosaurs”—the verses ran through the asteroid and several other possibilities.  I wonder if they’ll retire that song next year.)  If you haven’t yet read it, the <em><a href="https://www.newyorker.com/magazine/2019/04/08/the-day-the-dinosaurs-died">New Yorker</a></em><a href="https://www.newyorker.com/magazine/2019/04/08/the-day-the-dinosaurs-died"> piece on this</a> is a must.</p>



<p>I’m happy that my good friend Zach Weinersmith (legendary author of <a href="http://smbc-comics.com/">SMBC Comics</a>), as well as the GMU economist Bryan Caplan (rabblerousing author of <em>The Case Against Education</em>, which I <a href="https://www.scottaaronson.com/blog/?p=3678">reviewed here</a>), have a new book out: a graphic novel that makes a moral and practical case for open borders (!).  Their book is <a href="https://www.amazon.com/Open-Borders-Science-Ethics-Immigration/dp/1250316979/ref=pd_lpo_sbs_14_t_2?_encoding=UTF8&amp;psc=1&amp;refRID=A2TM1SK1AE3QXC3DEC99">now available for pre-order</a>, and at least at some point cracked Amazon’s top 10.  Just last week I met Bryan for the first time, when he visited UT Austin to give a talk based on the book.  He said that meeting me (having known me only from the blog) was like meeting a fictional character; I said the feeling was mutual.  And as for Bryan’s talk?  It felt great to spend an hour visiting a fantasyland where the world’s economies are run by humane rationalist technocrats, and where walls are going down rather than up.</p>



<p>I’m happy that, according to <a href="https://www.vanityfair.com/news/2019/02/men-are-scum-inside-facebook-war-on-hate-speech?verso=true">this </a><em><a href="https://www.vanityfair.com/news/2019/02/men-are-scum-inside-facebook-war-on-hate-speech?verso=true">Vanity Fair</a></em><a href="https://www.vanityfair.com/news/2019/02/men-are-scum-inside-facebook-war-on-hate-speech?verso=true"> article</a>, Facebook will still ban you for writing that “men are scum” <em>or</em> that “women are scum”—having ultimately rejected the demands of social-justice activists that it ban only the latter sentence, not the former.  According to the article, everyone on Facebook’s Community Standards committee agreed with the activists that this was the right result: dehumanizing comments about women have no place on the platform, while (superficially) dehumanizing comments about men are an important part of feminist consciousness-raising that require protection.  The problem was simply that the committee couldn’t come up with any <em>general principle</em> that would yield that desired result, without also yielding bad results in other cases.</p>



<p>I’m happy that the 737 Max jets are grounded and will hopefully be fixed, with no thanks to the FAA.  Strangely, while this was still the top news story, I gave a short talk about quantum computing to a group of Boeing executives who were visiting UT Austin on a previously scheduled trip.  The title of the session they put me in?  “Disruptive Computation.”</p>



<p>I’m happy that <a href="https://en.wikipedia.org/wiki/Greta_Thunberg">Greta Thunberg</a>, the 15-year-old Swedish climate activist, has attracted a worldwide following and might win the Nobel Peace Prize.  I hope she does—and more importantly, I hope her personal story will help galvanize the world into accepting things that it already knows are true, as with the example of Anne Frank (or for that matter, Gandhi or MLK).  Confession: back when I was an adolescent, I often daydreamed about doing exactly what Thunberg is doing right now, leading a worldwide children’s climate movement.  I didn’t, of course.  In my defense, I wouldn’t have had the charisma for it anyway—and also, I got sidetracked by even more pressing problems, like working out the quantum query complexity of recursive Fourier sampling.  But fate seems to have made an excellent choice in Thunberg.  She’s not the prop of any adult—just a nerdy girl with Asperger’s who formed the idea to sit in front of Parliament every day to protest the destruction of the world, because she couldn’t understand why everyone else wasn’t.</p>



<p>I’m happy that the college admissions scandal has finally forced Americans to confront the farcical injustice of our current system—a system where elite colleges pretend to peer into applicants’ souls (or the souls of the essay consultants hired by the applicants’ parents?), and where they preen about the moral virtue of their “holistic, multidimensional” admissions criteria, which amount in practice to shutting out brilliant working-class Asian kids in favor of legacies and rich badminton players.  Not to horn-toot, but Steven Pinker and I tried to raise the alarm about this travesty five years ago (see for example <a href="https://www.scottaaronson.com/blog/?p=2003">this post</a>), and were both severely criticized for it.  I do worry, though, that people will draw <em>precisely</em> the wrong lessons from the scandal.  If, for example, a few rich parents resorted to outright cheating on the SAT—all their other forms of gaming and fraud apparently being insufficient—then the SAT itself must be to blame so we should get rid of it.  In reality, the SAT (whatever its flaws) is almost the only bulwark we have against the <em>complete</em> collapse of college admissions offices into nightclub bouncers.  <a href="https://quillette.com/2019/03/13/standardized-testing-and-meritocracy/?fbclid=IwAR0mvO48sFgBps3mrSJ0bdK-qGzmiFd06vG6Au6enANaBC5Qh_YAa9tloJY">This </a><em><a href="https://quillette.com/2019/03/13/standardized-testing-and-meritocracy/?fbclid=IwAR0mvO48sFgBps3mrSJ0bdK-qGzmiFd06vG6Au6enANaBC5Qh_YAa9tloJY">Quillette</a></em><a href="https://quillette.com/2019/03/13/standardized-testing-and-meritocracy/?fbclid=IwAR0mvO48sFgBps3mrSJ0bdK-qGzmiFd06vG6Au6enANaBC5Qh_YAa9tloJY"> article</a> says it much better than I can.</p>



<p>I’m happy that there will a <a href="http://www.fields.utoronto.ca/activities/18-19/NP50">symposium from May 6-9</a> at the University of Toronto, to honor Stephen Cook and the (approximate) 50<sup>th</sup> anniversary of the discovery of NP-completeness.  I’m happy that I’ll be attending and speaking there.  If you’re interested, there’s still time to register!</p>



<p>Finally, I’m happy about the following “Sierpinskitaschen” baked by CS grad student and friend-of-the-blog <a href="https://twitter.com/optimistsinc?lang=en">Jess Sorrell</a>, and included with her permission (Jess says she got the idea from <a href="https://seattlelocalfood.com/2011/03/20/sierpinski-hamantaschen-sierpinskitaschen/?fbclid=IwAR1Qvoe8OYFXGbcke8u8XBS40tJMG2SkdJ8RI34u3CTSdjB2Fk1uob4OKzo">Debs Gardner</a>).</p>



<figure class="wp-block-image"><img alt="Image may contain: food" src="https://scontent-dfw5-2.xx.fbcdn.net/v/t1.0-9/55443394_10103182448260215_4376534862459305984_n.jpg?_nc_cat=111&amp;_nc_ht=scontent-dfw5-2.xx&amp;oh=ee33736b1c1ea5088ed66541d02dca23&amp;oe=5D02FAF8"/></figure></div>
    </content>
    <updated>2019-04-11T22:38:18Z</updated>
    <published>2019-04-11T22:38:18Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-04-19T21:17:59Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-721449905698588127</id>
    <link href="https://blog.computationalcomplexity.org/feeds/721449905698588127/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/elwyn-berlekamp-died-april-9-2019.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/721449905698588127" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/721449905698588127" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/elwyn-berlekamp-died-april-9-2019.html" rel="alternate" type="text/html"/>
    <title>Elwyn Berlekamp Died April 9, 2019</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Elwyn R. Berlekamp entered this world on Sept 6, 1940, and left it on April 9, 2019.  <a href="https://en.wikipedia.org/wiki/Elwyn_Berlekamp">Wikipedia</a> calls him <i>An American Mathematician</i> which seems to narrow to me. He worked on a variety of topics which were Math, Comp Sci, finance, and likely others --- if you know any that I missed leave comments.<br/>
<br/>
Here are some of the things he worked on:<br/>
<br/>
1) Factoring Polynomials over large finite fields (See <a href="https://www.jstor.org/stable/2004849?seq=1#metadata_info_tab_contents">here</a> from 1970)<br/>
<br/>
I quote the abstract<br/>
<blockquote class="tr_bq">
This paper reviews some of the known algorithms for factoring polynomials over finite fields and presents a new deterministic procedure for reducing the problem of factoring an arbitrary polynomial over the Galois field GP(p<sup>m</sup>) to the problem of finding roots in GF(p) of certain other polynomials over GP(p). The amount of computation and the storage space required by these algorithms are algebraic in both the degree of the polynomial to be factored and the log of the order of the field.</blockquote>
<blockquote class="tr_bq">
Certain observations on the application of these methods to factorization of polynomials over the rational integers are also included. </blockquote>
I think he meant what we would call polynomial time when he says algebraic.<br/>
<br/>
2) Combinatorial Games. He co-wrote the classic Winning Ways For your Mathematical Plays with John Conway and Richard Guy.  These books are like NIM on steroids. They are FUN and have some serious math in them. (My blog system thinks Combinatorial is not a word. It is wrong)<br/>
<br/>
3) Combinatorial Games. He was very interested in Go via Combinatorial Games. I have an article (alas, not online) by him entitled Introductory Overview of Mathematical Go Endgames.  There has been further work on this that is on the web, see <a href="http://web.stanford.edu/~wqy/research/Honor%20Thesis.pdf">here</a>. I wonder what ERB would think of the ALPHAGO program.<br/>
<br/>
4) Berlekamp-Massey Algorithm finds the shortest linear feedback shift register for a given binary output sequence.<br/>
<br/>
5) Berlekamp-Welch Algorithm efficiently corrects errors in Reed-Solomon codes.  (Berlekamp also wrote a book on Algebraic Coding Theory.)<br/>
<br/>
6) I didn't know about his work in finance until I began writing this, but the following quote from Wikipedia is impressive<br/>
<blockquote class="tr_bq">
In 1989, Berlekamp purchased the largest interest in a trading company named Axcom Trading Advisors. After the firm's futures trading algorithms were rewritten, Axcom's Medallion Fund had a return (in 1990) of 55%, net of all management fees and transaction costs. The fund has subsequently continued to realize annualized returns exceeding 30% under management by James Harris Simons and his Renaissance Technologies Corporation.</blockquote></div>
    </content>
    <updated>2019-04-11T22:13:00Z</updated>
    <published>2019-04-11T22:13:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-04-22T08:46:17Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/04/11/coloring-kinggraphs</id>
    <link href="https://11011110.github.io/blog/2019/04/11/coloring-kinggraphs.html" rel="alternate" type="text/html"/>
    <title>Coloring kinggraphs</title>
    <summary>Draw a collection of quadrilaterals in the plane, meeting edge to edge, so that they don’t surround any open space (the region they cover is a topological disk) and every vertex interior to the disk touches at least four quadrilaterals. Is it always possible to color the corners of the quadrilaterals with four colors so that all four colors appear in each quadrilateral?</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Draw a collection of quadrilaterals in the plane, meeting edge to edge, so that they don’t surround any open space (the region they cover is a topological disk) and every vertex interior to the disk touches at least four quadrilaterals. Is it always possible to color the corners of the quadrilaterals with four colors so that all four colors appear in each quadrilateral?</p>

<p style="text-align: center;"><img alt="4-colored kinggraph" src="https://11011110.github.io/blog/assets/2019/colored-kinggraph.svg"/></p>

<p>The graph of corners and quadrilateral edges is a <a href="https://en.wikipedia.org/wiki/Squaregraph">squaregraph</a> but this question is really about coloring a different and related graph, called a kinggraph, that also includes as edges the diagonals of each quad. It’s called that because one example of this kind of graph is the <a href="https://en.wikipedia.org/wiki/King's_graph">king’s graph</a> describing the possible moves of a chess king on a chessboard.</p>

<p style="text-align: center;"><img alt="The king's graph" src="https://11011110.github.io/blog/assets/2019/kings-graph.svg"/></p>

<p>The king’s graph, and kinggraphs more generally, are examples of 1-planar graphs, graphs drawn in the plane in such a way that each edge is crossed at most once. The edges of the underlying squaregraph are not crossed at all, and the diagonals of each quad only cross each other. Squaregraphs are bipartite (like every planar graph in which all faces have an even number of edges), so they can be colored with only two colors. 1-planar graphs, in general, can require six colors (for instance you can draw the complete graph  as a 1-planar graph by adding diagonals to the squares of a triangular prism) and this is tight.
And you can easily 4-color the king’s graph by using two colors in alternation across the even rows of the chessboard, and a different two colors across the odd rows. So the number of colors for kinggraphs should be somewhere between these two extremes, but where?</p>

<p>One useful and general graph coloring method is based on the <a href="https://en.wikipedia.org/wiki/Degeneracy_(graph_theory)">degeneracy</a> of graphs. This is the largest number  such that every subgraph has a vertex with at most  neighbors; one can use a <a href="https://en.wikipedia.org/wiki/Greedy_coloring">greedy coloring algorithm</a> to color any graph with  colors. Kinggraphs themselves always have a vertex with at most  neighbors, but unfortunately they do not have degeneracy . If you form a king’s graph on a  chessboard, and then remove its four corners, you get a subgraph in which all vertices have at least four neighbors.
This turns out to be as large as possible: every kinggraph has degeneracy at most four. This is because, if you consider the zones of the system of quads (strips of quads connected on opposite pairs of edges), there always exists an “outer zone”, a zone with nothing on one side of it (see the illustration, below). You can remove the vertices of the outer zone one at a time, in order from one end to the other, always removing a vertex of degree at most four, and then repeat on another outer zone until the whole graph is gone. So the degeneracy and greedy coloring method shows that you can 5-color every kinggraph, better than the 6-coloring that we get for arbitrary 1-planar graphs.</p>

<p style="text-align: center;"><img alt="An outer zone" src="https://11011110.github.io/blog/assets/2019/outer-zone.svg"/></p>

<p>This turns out to be optimal! For a while I thought that every kinggraph must be 4-colorable, because it was true of all the small examples that I tried. But it’s not true in general, and here’s why. If you look at the zones of the 4-colored kinggraph above, you might notice a pattern. The edges that connect pairs of quads from the same zone have colorings that alternate between two different pairs of colors. For instance, we might have a zone that has red–yellow edges alternating with blue–green edges, or another zone that has red–blue edges alternating with green–yellow edges. This is true whenever a kinggraph can be 4-colored. But there are only three ways of coloring a zone (that is, of partitioning the four colors into two disjoint pairs, which alternate along the zone). And when two zones cross each other, they must be colored differently. So every 4-coloring of a kinggraph turns into a 3-coloring of its zones. But the graph that describes the zones and its crossings is a triangle-free <a href="https://en.wikipedia.org/wiki/Circle_graph">circle graph</a>, and vice versa: every triangle-free circle graph describes a kinggraph. And triangle-free circle graphs may sometimes need as many as five colors, in which case so does the corresponding kinggraph.</p>

<p>I posted <a href="https://11011110.github.io/blog/2008/03/23/ageevs-squaregraph.html">an example of a squaregraph whose circle graph needs five colors</a> on this blog in 2008. Here’s a slightly different drawing of the same graph from <a href="https://11011110.github.io/blog/2009/05/29/congratulations-dr-wortman.html">a later post</a>.
Because its circle graph is not 3-colorable, the corresponding kinggraph is not 4-colorable.</p>

<p style="text-align: center;"><img alt="A squaregraph whose kinggraph is not 4-colorable" src="https://11011110.github.io/blog/assets/2009/cd220c.svg"/></p>

<p>There are simpler examples of squaregraphs whose circle graph needs four colors. As long as the number of colors of the circle graph is more than three, the number of colors of the kinggraph will be more than four.</p>

<p>On the other hand, if you can color the circle graph with three colors, then it’s also possible to translate this 3-coloring of zones back into a 4-coloring of the kinggraph. Just remove an outer zone, color the remaining graph recursively, add the removed zone back, and use the color of the zone you removed to decide which colors to assign to its vertices. Unfortunately, I don’t know the computational complexity of testing whether a circle graph is 3-colorable. There was a conference paper by Walter Unger in 1992 that claimed to have a polynomial time algorithm, but without enough details and it was never published in a journal. I think we have to consider the problem of finding a coloring as still being open.</p>

<p>The same method also leads to an easy calculation of the number of 4-colorings (in the same sense) of the usual kind of chessboard with  squares, or of a king’s graph with  vertices. In this case, the zones are just the rows and columns of the chessboard. We can use one color for the rows and two for the columns, or vice versa, so the number of 3-colorings of the zones (accounting for the fact that the 2-colorings get counted twice) is . And once the coloring of the zones is chosen, the coloring of the chessboard itself is uniquely determined by the color of any of its squares, so the total number of chessboard colorings is .</p>

<p>(<a href="https://mathstodon.xyz/@11011110/101911453128265954">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-04-11T21:28:00Z</updated>
    <published>2019-04-11T21:28:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-04-16T01:45:00Z</updated>
    </source>
  </entry>
</feed>
