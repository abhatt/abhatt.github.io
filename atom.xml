<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-01-26T03:38:57Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2101.09147</id>
    <link href="http://arxiv.org/abs/2101.09147" rel="alternate" type="text/html"/>
    <title>A superstatistical formulation of complexity measures</title>
    <feedworld_mtime>1611532800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jesús Fuentes, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Obreg=oacute=n:Octavio.html">Octavio Obregón</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2101.09147">PDF</a><br/><b>Abstract: </b>It is discussed how the superstatistical formulation of effective Boltzmann
factors can be related to the concept of Kolmogorov complexity, generating an
infinite set of complexity measures (CMs) for quantifying information. At this
level, the information is treated according to its background, which means that
the CM depends on the inherent attributes of the information scenario. While
the basic Boltzmann factor directly produces the standard complexity measure
(SCM), it succeeds in the description of large-scale scenarios where the data
components are not interrelated with themselves, thus adopting the behaviour of
a gas. What happens in scenarios in which the presence of sources and sinks of
information cannot be neglected, needs of a CM other than the one produced by
the ordinary Boltzmann factor. We introduce a set of flexible CMs, without free
parameters, that converge asymptotically to the Kolmogorov complexity, but also
quantify the information in scenarios with a reasonable small density of
states. We prove that these CMs are obtained from a generalised relative
entropy and we suggest why such measures are the only compatible
generalisations of the SCM.
</p></div>
    </summary>
    <updated>2021-01-25T22:37:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-01-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2101.09054</id>
    <link href="http://arxiv.org/abs/2101.09054" rel="alternate" type="text/html"/>
    <title>Adversarial Laws of Large Numbers and Optimal Regret in Online Classification</title>
    <feedworld_mtime>1611532800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alon:Noga.html">Noga Alon</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ben=Eliezer:Omri.html">Omri Ben-Eliezer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dagan:Yuval.html">Yuval Dagan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moran:Shay.html">Shay Moran</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Naor:Moni.html">Moni Naor</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yogev:Eylon.html">Eylon Yogev</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2101.09054">PDF</a><br/><b>Abstract: </b>Laws of large numbers guarantee that given a large enough sample from some
population, the measure of any fixed sub-population is well-estimated by its
frequency in the sample. We study laws of large numbers in sampling processes
that can affect the environment they are acting upon and interact with it.
Specifically, we consider the sequential sampling model proposed by Ben-Eliezer
and Yogev (2020), and characterize the classes which admit a uniform law of
large numbers in this model: these are exactly the classes that are
\emph{online learnable}. Our characterization may be interpreted as an online
analogue to the equivalence between learnability and uniform convergence in
statistical (PAC) learning.
</p>
<p>The sample-complexity bounds we obtain are tight for many parameter regimes,
and as an application, we determine the optimal regret bounds in online
learning, stated in terms of \emph{Littlestone's dimension}, thus resolving the
main open question from Ben-David, P\'al, and Shalev-Shwartz (2009), which was
also posed by Rakhlin, Sridharan, and Tewari (2015).
</p></div>
    </summary>
    <updated>2021-01-25T22:37:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-01-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2101.09024</id>
    <link href="http://arxiv.org/abs/2101.09024" rel="alternate" type="text/html"/>
    <title>Online Packing to Minimize Area or Perimeter</title>
    <feedworld_mtime>1611532800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Beretta:Lorenzo.html">Lorenzo Beretta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abrahamsen:Mikkel.html">Mikkel Abrahamsen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2101.09024">PDF</a><br/><b>Abstract: </b>We consider online packing problems where we get a stream of axis-parallel
rectangles. The rectangles have to be placed in the plane without overlapping,
and each rectangle must be placed without knowing the subsequent rectangles.
The goal is to minimize the perimeter or the area of the axis-parallel bounding
box of the rectangles. We either allow rotations by 90 degrees or translations
only.
</p>
<p>For the perimeter version we give algorithms with an absolute competitive
ratio slightly less than 4 when only translations are allowed and when
rotations are also allowed.
</p>
<p>We then turn our attention to minimizing the area and show that the
asymptotic competitive ratio of any algorithm is at least $\Omega(\sqrt{n})$,
where $n$ is the number of rectangles in the stream, and this holds with and
without rotations. We then present algorithms that match this bound in both
cases. We also show that the competitive ratio cannot be bounded as a function
of OPT. We then consider two special cases.
</p>
<p>The first is when all the given rectangles have aspect ratios bounded by some
constant. The particular variant where all the rectangles are squares and we
want to minimize the area of the bounding square has been studied before and an
algorithm with a competitive ratio of 8 has been given~[Fekete and Hoffmann,
Algorithmica, 2017]. We improve the analysis of the algorithm and show that the
ratio is at most 6, which is tight.
</p>
<p>The second special case is when all edges have length at least 1. Here, the
$\Omega(\sqrt n)$ lower bound still holds, and we turn our attention to lower
bounds depending on OPT. We show that any algorithm has an asymptotic
competitive ratio of at least $\Omega(\sqrt{OPT})$ for the translational case
and $\Omega(\sqrt[4]{OPT})$ when rotations are allowed. For both versions, we
give algorithms that match the respective lower bounds.
</p></div>
    </summary>
    <updated>2021-01-25T22:54:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-01-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2101.09005</id>
    <link href="http://arxiv.org/abs/2101.09005" rel="alternate" type="text/html"/>
    <title>An in-place truncated Fourier transform</title>
    <feedworld_mtime>1611532800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Coxon:Nicholas.html">Nicholas Coxon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2101.09005">PDF</a><br/><b>Abstract: </b>We show that simple modifications to van der Hoeven's forward and inverse
truncated Fourier transforms allow the algorithms to be performed in-place, and
with only a linear overhead in complexity.
</p></div>
    </summary>
    <updated>2021-01-25T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-01-25T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/01/22/bracing-squaregraphs</id>
    <link href="https://11011110.github.io/blog/2021/01/22/bracing-squaregraphs.html" rel="alternate" type="text/html"/>
    <title>Bracing squaregraphs (and other rhombus tilings)</title>
    <summary>A bookshelf or other structure made only of vertical and horizontal beams will easily fall over unless its joints are very strong, because axis-parallel structures are not inherently rigid. The vertical beams can tilt away from being perpendicular to the horizontals, without changing the relative spacing of the joints, and that can lead to books all over the floor. Here’s an example from a 2011 earthquake at the Smithsonian that didn’t get quite that far, but did damage some shelves beyond repair:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A bookshelf or other structure made only of vertical and horizontal beams will easily fall over unless its joints are very strong, because axis-parallel structures are not inherently <a href="https://en.wikipedia.org/wiki/Structural_rigidity">rigid</a>. The vertical beams can tilt away from being perpendicular to the horizontals, without changing the relative spacing of the joints, and that can lead to books all over the floor. Here’s an example <a href="https://www.si.edu/newsdesk/photos/earthquake-damage-botany-library">from a 2011 earthquake at the Smithsonian</a> that didn’t get quite that far, but did damage some shelves beyond repair:</p>

<p style="text-align: center;"><img alt="Damaged bookshelves in the Botany and Horticulture Library at the Smithsonian's National Museum of Natural History after the August 2011 Virginia earthquake, photographed by James DiLoreto, from https://www.si.edu/newsdesk/photos/earthquake-damage-botany-library" src="https://11011110.github.io/blog/assets/2021/nhb2011-01160-botany_library.jpg" style="border-style: solid; border-color: black;" width="65%"/></p>

<p>Triangular bookshelves would be annoying for different reasons, but they wouldn’t collapse like this, because triangular structures are more rigid: there is only one triangle that three sides of fixed lengths can form, unlike squares and rectangles which can flex into rhombi and parallelograms without changing their side lengths. So the standard solution to the bookshelf rigidity problem is to add <a href="https://en.wikipedia.org/wiki/Cross_bracing">cross bracing</a>, diagonal beams built into shelves or other rectangular structures that make them similarly rigid. But which parts to brace? Even if every vertical and horizontal segment of a square bookshelf is allowed to flex independently of the other ones on its same line, bracing all the squares of the bookshelf would be too many. The vertical segments in each row of squares must stay parallel (in any flex small enough to avoid self-crossings), and similarly the horizontal segments in each column of squares must stay parallel. So a square grid with \(r\) rows and \(c\) columns has only \(r+c-1\) degrees of freedom in its shape (the relative angles among the verticals of each of the \(r\) rows and the horizontals of each of the \(c\) columns), far fewer than the \(rc\) braces that would be obtained by bracing all the squares.</p>

<p style="text-align: center;"><img alt="Degrees of freedom of a flexible square grid" src="https://11011110.github.io/blog/assets/2021/grid-flex.svg"/></p>

<p>A beautiful theory showing how to minimally brace any square (or rectangular) grid, connecting this <a href="https://en.wikipedia.org/wiki/Grid_bracing">grid bracing problem</a> to the connectivity of bipartite graphs, was developed in the late 1970s and early 1980s by Ethan Bolker, <a href="https://en.wikipedia.org/wiki/Henry_Crapo_(mathematician)">Henry Crapo</a>, <a href="https://en.wikipedia.org/wiki/Jenny_Baglivo">Jenny Baglivo</a>, and Jack Graver.<sup id="fnref:bc"><a class="footnote" href="https://11011110.github.io/blog/2021/01/22/bracing-squaregraphs.html#fn:bc">1</a></sup> <sup id="fnref:bg"><a class="footnote" href="https://11011110.github.io/blog/2021/01/22/bracing-squaregraphs.html#fn:bg">2</a></sup> Their idea was to represent the grid and its bracing more abstractly, as a graph, whose vertices represent the rows and columns of grid squares. A braced square can be represented as an edge in this graph:</p>

<p style="text-align: center;"><img alt="Representing a braced square grid as a graph" src="https://11011110.github.io/blog/assets/2021/grid-bracing.svg"/></p>

<p>An edge in this graph, or more generally any chain of edges, fixes the relative angles between the vertical edges in the rows that it connects, and the horizontal edges of the columns. So if the whole graph is connected, as it is in the figure, all of these angles are fixed, and the grid is made rigid. In particular, any spanning tree of the complete bipartite graph on the rows and columns (such as the spanning tree shown in the figure) provides a bracing pattern that will suffice to make the grid rigid. It is also necessary for rigidity that the bracing pattern contain a spanning tree: any set of braces including a cycle is redundant, with one of the braces removable without changing the possible motions of the braced grid, and any forest that is not a tree has too few braces to eliminate all of the degrees of freedom. So a grid is braced rigidly if and only if its graph is connected, and the minimal rigid bracings are exactly the spanning trees.</p>

<p>The same theory can be (and has been) generalized in multiple ways. A grid is “double braced” if every brace is redundant: you can remove any one brace and the whole structure will stay rigid. This is true if and only if the corresponding graph has the property that you can remove any one edge and the whole graph will remain connected, which is true exactly for the connected <a href="https://en.wikipedia.org/wiki/Bridge_(graph_theory)">bridgeless graphs</a>. A version with directed graphs applies to bracing by strings or wires, strong under tension but useless under compression. These constrain the sides of the squares from turning only in one direction: if one side turns clockwise, the other side is forced to turn clockwise, or vice versa, but not both ways. So we can represent a tension brace in a square by a directed edge. The edge is directed from the square’s row to its column when a clockwise turn of the vertical sides in the row would force a clockwise turn of the horizontal sides in the column, and in the other direction otherwise. Then, the whole structure is rigid under this sort of tension bracing if and only if the resulting directed graph is strongly connected.</p>

<p>For this theory to work, it is necessary that the braced structure consist of quadrilaterals with parallel sides, but they don’t have to be squares: the same thing works for grids of rectangles, rhombi, or parallelograms. It would work for the deformed square grid in the right of the second figure, for instance. It’s also not necessary for the quadrilaterals to be connected in the pattern of a square grid. In 2006, Ture Wester observed that the same method should work for the rhombic version of the Penrose tiling, for instance, but was very vague about boundary conditions (not distinguishing carefully between infinite tilings and finite patches of them).<sup id="fnref:w"><a class="footnote" href="https://11011110.github.io/blog/2021/01/22/bracing-squaregraphs.html#fn:w">3</a></sup> The correct boundary conditions are that this works for any tiling of a disk in the plane by finitely many parallel-sided quadrilaterals. For such tilings, one can group the quadrilaterals into zones, sequences of quadrilaterals connected edge-to-edge on opposite sides, so that each quadrilateral belongs to two zones (giving it a zone by itself if two opposite sides are both on the boundary of the disk). Without bracing, the shared parallel sides in each zone can turn independently of any other motion of the tiling; this is the part that requires that the tiled area be a disk rather than an annulus or more complicated shape, so that the two parts of the graph separated by each zone are disconnected from each other and can move independently. And the overall shape of the tiling is completely determined by the angles of the shared sides of all of its zones. Therefore, the number of degrees of freedom (factoring out motions in which the tiling translates without rotation, or rotates rigidly) is exactly one less than the number of zones. Any set of braced quadrilaterals can be represented as a subgraph of the intersection graph of the zones, and after the calculation of degrees of freedom, the same argument as for grids shows that the tiling is rigid if this subgraph connects all the zones, that it is double braced if this subgraph is connected and bridgeless, or that it is tension braced if the directed version of this subgraph is strongly connected.</p>

<p>So as Wester stated, this does work for rhombic Penrose tilings, as long as one considers disk-shaped patches of the tilings. Similar, it works for (simply-connected) polyominoes, or disk-shaped patches of the <a href="https://en.wikipedia.org/wiki/Rhombille_tiling">rhombille tiling</a>. It also works for <a href="https://en.wikipedia.org/wiki/Squaregraph">squaregraphs</a>, planar graphs in which all interior vertices have degree at least four and all interior faces are quadrilaterals, as long as those quadrilaterals are drawn with parallel sides. One of my old papers shows that these drawings always exist,<sup id="fnref:e"><a class="footnote" href="https://11011110.github.io/blog/2021/01/22/bracing-squaregraphs.html#fn:e">4</a></sup> and another shows how to optimize them to avoid sharp angles.<sup id="fnref:ew"><a class="footnote" href="https://11011110.github.io/blog/2021/01/22/bracing-squaregraphs.html#fn:ew">5</a></sup>. In all of these cases, the tiling can be made rigid by bracing tiles forming a spanning tree of its zones, doubly rigid by bracing tiles forming a bridgeless spanning subgraph, or rigid for tension bracing by adding braces that form a strongly connected graph.</p>

<p>However, some algorithmic aspects of this theory may depend more strongly on the fact that for square grids, the intersection graphs of their zones have a very simple structure. Square grids have complete bipartite zone intersection graphs, but more general tilings of disks by parallel-sided quadrilaterals have arbitrary <a href="https://en.wikipedia.org/wiki/Circle_graph">circle graphs</a> and squaregraphs have triangle-free circle graphs. Extending a partial bracing to a minimal rigid bracing is just a matter of extending a forest to a spanning tree, easy in all graphs, but the corresponding problem for tension bracing is more complicated. Gabow and Jordán solve it for square grids (equivalently, adding as few edges as possible to a bipartite directed graph to make it strongly connected, while respecting its given bipartition) in linear time.<sup id="fnref:gj"><a class="footnote" href="https://11011110.github.io/blog/2021/01/22/bracing-squaregraphs.html#fn:gj">6</a></sup> But it is not at all obvious that it’s as easy to extend a directed subgraph of a circle graph to a minimal strongly connected subgraph of the same circle graph.</p>

<div class="footnotes">
  <ol>
    <li id="fn:bc">
      <p>Bolker, Ethan D., and Crapo, Henry (1977), “How to brace a one-story building”, <em>Environment and Planning B: Planning and Design</em> 4 (2): 125–152, <a href="https://doi.org/10.1068/b040125">doi:10.1068/b040125</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2021/01/22/bracing-squaregraphs.html#fnref:bc">↩</a></p>
    </li>
    <li id="fn:bg">
      <p>Baglivo, Jenny A., and Graver, Jack E. (1983), “3.10 Bracing structures”, <em>Incidence and Symmetry in Design and Architecture</em>, Cambridge University Press, pp. 76–87. <a class="reversefootnote" href="https://11011110.github.io/blog/2021/01/22/bracing-squaregraphs.html#fnref:bg">↩</a></p>
    </li>
    <li id="fn:w">
      <p>Wester, Ture (2006), “<a href="http://new.math.uiuc.edu/oldnew/quasicrystals/papers/TureWester.pdf">The structural morphology of Penrose and quasicrystal patterns, part I</a>”, <em>Adaptables2006, TU/e, International Conference On Adaptable Building Structures, Eindhoven, The Netherlands, 3–5 July 2006</em>, 10-290. <a class="reversefootnote" href="https://11011110.github.io/blog/2021/01/22/bracing-squaregraphs.html#fnref:w">↩</a></p>
    </li>
    <li id="fn:e">
      <p>Eppstein, David (2004), “Algorithms for drawing media”, <em>Proc. 12th Int. Symp. Graph Drawing</em>, Springer, LNCS 3383, pp. 173–183, <a href="https://arxiv.org/abs/cs.DS/0406020">arXiv:cs.DS/0406020</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2021/01/22/bracing-squaregraphs.html#fnref:e">↩</a></p>
    </li>
    <li id="fn:ew">
      <p>Eppstein, David, and Wortman, Kevin (2011), “Optimal angular resolution for face-symmetric drawings”, <em>J. Graph Algorithms and Applications</em> 15 (4): 551–564, <a href="https://doi.org/10.7155/jgaa.00238">doi:10.7155/jgaa.00238</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2021/01/22/bracing-squaregraphs.html#fnref:ew">↩</a></p>
    </li>
    <li id="fn:gj">
      <p>Gabow, Harold N., and Jordán, Tibor (2000), “How to make a square grid framework with cables rigid”, <em>SIAM Journal on Computing</em> 30 (2): 649–680, <a href="https://doi.org/10.1137/S0097539798347189">doi:10.1137/S0097539798347189</a>. <a class="reversefootnote" href="https://11011110.github.io/blog/2021/01/22/bracing-squaregraphs.html#fnref:gj">↩</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/105603974591107625">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2021-01-22T23:32:00Z</updated>
    <published>2021-01-22T23:32:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-01-23T08:03:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/01/22/oxford-warwick-postdoc-in-complexity-theory-at-university-of-oxford-university-of-warwick-apply-by-february-28-2021/</id>
    <link href="https://cstheory-jobs.org/2021/01/22/oxford-warwick-postdoc-in-complexity-theory-at-university-of-oxford-university-of-warwick-apply-by-february-28-2021/" rel="alternate" type="text/html"/>
    <title>Oxford-Warwick Postdoc in Complexity Theory at University of Oxford / University of Warwick (apply by February 28, 2021)</title>
    <summary>Rahul Santhanam (Oxford) and Igor Oliveira (Warwick) invite expressions of interest for a joint postdoctoral position in computational complexity theory. Funding is available for 20 months, with the possibility of an extension. The start date is negotiable. To be considered, please send an email to Rahul Santhanam and Igor Oliveira with your CV &amp; Publications. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Rahul Santhanam (Oxford) and Igor Oliveira (Warwick) invite expressions of interest for a joint postdoctoral position in computational complexity theory.<br/>
Funding is available for 20 months, with the possibility of an extension. The start date is negotiable.<br/>
To be considered, please send an email to Rahul Santhanam and Igor Oliveira with your CV &amp; Publications. Informal enquiries are welcome.</p>
<p>Website: <a href="https://www.dcs.warwick.ac.uk/~igorcarb/complexity-meetings.html">https://www.dcs.warwick.ac.uk/~igorcarb/complexity-meetings.html</a><br/>
Email: igorcarb@gmail.com</p></div>
    </content>
    <updated>2021-01-22T19:26:00Z</updated>
    <published>2021-01-22T19:26:00Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-01-26T03:37:38Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1995922000817154646</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1995922000817154646/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/01/alan-selman-1941-2021.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1995922000817154646" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1995922000817154646" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/01/alan-selman-1941-2021.html" rel="alternate" type="text/html"/>
    <title>Alan Selman (1941-2021)</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p/><span style="text-align: center;"><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-4M0SuOy0o4s/X_y99qhI9aI/AAAAAAAB6E0/ZRefljNynqkOfgg4Kj3zCOk-dPyEp-TKACPcBGAsYHg/s2258/00000429.jpg" style="margin-left: auto; margin-right: auto;"><img border="0" height="246" src="https://1.bp.blogspot.com/-4M0SuOy0o4s/X_y99qhI9aI/AAAAAAAB6E0/ZRefljNynqkOfgg4Kj3zCOk-dPyEp-TKACPcBGAsYHg/w400-h174/00000429.jpg" width="550"/></a></td></tr><tr><td class="tr-caption" style="text-align: center;">From a 1994 Dagstuhl Workshop. Selman is the one wearing a cap.</td></tr></tbody></table></span><div>Alan Selman, one of the early leaders in structural complexity and the co-founder and first chair of what is now the Computational Complexity Conference, passed away this morning. He was one of the true greats in our field both for his research and his service.<p/><p>Selman was a good colleague and a friend. I hosted his sabbatical at the University of Chicago in 1998 which <a href="https://doi.org/10.1007/s00224-001-0003-0">produced a paper</a> with Selman's student and my later postdoc Pavan Aduri. In Spring of 1999 Selman ran a NSF workshop in Chicago on <a href="https://cse.buffalo.edu/~selman/report/Report.html">Challenges for Theory of Computing</a>.</p><p>In a desire to create a community of complexity theorists and foster publications of their results, Selman led the efforts to establish the Structure in Complexity Theory conference, first held in 1986 in Berkeley, California. As a student in Berkeley I attended that meeting and the next twenty-five. The conference would join the IEEE in 1987, in 1996 renamed the IEEE Conference and Computational Complexity and in 2015 drop from the IEEE to become the Computational Complexity Conference, still going strong. Alan served as the first conference chair and as PC co-chair of the first meeting. </p><p>For all his service for the field, Selman received the ACM SIGACT Distinguished Service Award in 2002.</p><p>Selman joined University at Buffalo in 1990 to serve six years as department chair and then as a professor until he retired in 2014. Lane Hemaspaandra wrote a highly recommended <a href="https://arxiv.org/abs/1406.4106">appreciation</a> for Selman and his research in honor of his retirement where he mentions some of Selman's research programs, including his seminal work on P-Selective sets, non-deterministic functions and his work with Joachim Grollman on one-way functions. Selman came down hard on anyone who got the wrong number of l's in Grollman, so we would often joking cite it as Grollman and Sellman or just Grollman et Al.</p><p>In my <a href="https://doi.org/10.1137/S0097539794268315">favorite Selman paper</a>, in work with Hemaspaandra, Ashish Naik and Mitsu Ogihara, looks at witness reduction. If there is a set A in P such that for all satisfiable formula φ there is a unique satisfying assignment a of φ such that (φ,a) is in A then the polynomial-time hierarchy collapses. The more general question of whether NP=UP implies the polynomial-time hierarchy collapses <a href="https://blog.computationalcomplexity.org/2003/12/does-npup.html">remains open</a>.</p><p>Also <a href="https://doi.org/10.1016/0022-0000(92)90023-C">Selman's paper with Steve Homer</a> giving an oracle where Σ<sub>2</sub><sup>P</sup>-complete sets were isomorphic was instrumental to my own work on the isomorphism conjecture.</p><p>Bill wanted me to mention the Selman paper that most influenced him. Selman and Theodore Baker and <a href="https://doi.org/10.1016/0304-3975(79)90043-4">gave the first oracle</a> separating the second level of the polynomial-time hierarchy in 1979. It would take <a href="https://doi.org/10.1109/SFCS.1985.49">Yao</a> and <a href="https://doi.org/10.1145/12130.12132">Håstad</a> over five more years to get the whole hierarchy infinite relative to an oracle. The Baker-Selman proof could easily extend to show that AM games did not sit in Σ<sub>2</sub><sup>P</sup>, a bit surprising as MA is in Σ<sub>2</sub><sup>P</sup>.</p><p>In addition to his research, Selman wrote an <a href="https://amzn.to/3oBKWsD">introductory theory textbook</a> with Homer as well as <a href="https://amzn.to/38zspaQ">editor</a> and <a href="https://amzn.to/3qeA8kj">co-editor</a> of two editions of Complexity Theory Retrospective.</p><p>It would be no exaggeration to say the field of computational complexity and my own research within it would have been much different without Alan.</p><p>Alan drove a car with a "P NE NP" license plate. One day someone came up to him in a parking lot and said "Yes, but can you prove it?" Possibly the one thing in complexity he couldn't do.</p></div></div>
    </content>
    <updated>2021-01-22T16:44:00Z</updated>
    <published>2021-01-22T16:44:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-01-25T18:51:25Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5862964813565889129</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5862964813565889129/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/01/presidential-quiz-three-ways-to-take-it.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5862964813565889129" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5862964813565889129" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/01/presidential-quiz-three-ways-to-take-it.html" rel="alternate" type="text/html"/>
    <title>Presidential Quiz:  Three ways to take it</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> Every four years around the time of the inaugural I post a presidential Quiz! I do that today, and I will post the answers on Monday.  I am tempted to joke that I am posting it AFTER Joltin Joe gets sworn in just in case something happens; however, I always posted it after the prez is sworn in. </p><p>The quiz is here: <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/prezquiz.pdf">quiz</a></p><p><b> GRADING CRITERIA</b></p><p>33 questions, 3 points each, and 1 free point.</p><p>If the answer is a list of L elts and you get x correct, you get x/L points. If any are wrong then 0 points.</p><p>You can take the quiz one of three ways.</p><p>1) Take it WITHOUT using the web and see how many you can get right. Take 3 hours.</p><p>WARNING- its a hard quiz so this may not be fun. </p><p>2) Take it and use the web and try to do it fast. Stop when you want. Your Score is as follows:</p><p>If  R is the number if points and  T be how many minutes you took,  your score is </p><p> (180R/T)+ 1.</p><p>If  you get all 33 right in 60 minutes then you get a 100. You could get more than 100 if you do it faster.</p><p>3) The answer key has all kinds of other information in it and is fun to read. So do not take the quiz and enjoy  reading the answers on Monday. That's what I did. </p><p><br/></p><p>I was curious if Joltin Joe would be sworn in by Joseph or Joe. I was routing for Joe so he would be the second president sworn in by his nickname (Jimmy Carter was the first--his real name is James). When I am sworn in as president I will use <i>Bill</i> and hence join the nickname-club. Lance does not have a nickname, so my veep will be sworn in by his actual name. Would we win? Is  America ready for a 2-Phd ticket? </p><p><br/></p><p><br/></p><p><br/></p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2021-01-22T05:53:00Z</updated>
    <published>2021-01-22T05:53:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-01-25T18:51:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5264</id>
    <link href="https://www.scottaaronson.com/blog/?p=5264" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5264#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5264" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Sufficiently amusing that I had no choice</title>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"><div class="wp-block-embed__wrapper">
<blockquote class="twitter-tweet"><p dir="ltr" lang="en">BREAKING: President Biden signs executive order banning people from saying “Quantum computers solve problems by just trying all possible solutions in parallel” <a href="https://t.co/zeAZvmKA1T">pic.twitter.com/zeAZvmKA1T</a></p>— Olivia Lanes (@Liv_Lanes) <a href="https://twitter.com/Liv_Lanes/status/1352350146881867781?ref_src=twsrc%5Etfw">January 21, 2021</a></blockquote>
</div></figure></div>
    </content>
    <updated>2021-01-22T04:09:45Z</updated>
    <published>2021-01-22T04:09:45Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Speaking Truth to Parallelism"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-01-22T04:09:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=18015</id>
    <link href="https://rjlipton.wordpress.com/2021/01/21/science-advisor/" rel="alternate" type="text/html"/>
    <title>Science Advisor</title>
    <summary>Resources for a new term from our vantage point Crop from Broad Institute src Eric Lander has been appointed director of the US Office of Science and Technology Policy, a post newly elevated to Cabinet status. He is thus the top science advisor in Joe Biden’s cabinet. Today we congratulate Eric, whom we both have […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Resources for a new term from our vantage point</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2021/01/lander.jpg"><img alt="" class="alignright wp-image-18017" height="157" src="https://rjlipton.files.wordpress.com/2021/01/lander.jpg?w=135&amp;h=157" width="135"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Crop from Broad Institute <a href="https://www.broadinstitute.org/bios/eric-s-lander">src</a></font></td>
</tr>
</tbody>
</table>
<p/><p>
Eric Lander has been <a href="https://buildbackbetter.gov/wp-content/uploads/2021/01/OSTP-Appointment.pdf">appointed</a> director of the US Office of Science and Technology Policy, a post newly elevated to Cabinet status. He is thus the top science <a href="https://www.sciencemag.org/news/2021/01/biden-appoints-geneticist-eric-lander-science-advisor">advisor</a> in Joe Biden’s cabinet.</p>
<p>
Today we congratulate Eric, whom we both have known personally, and survey some sources of science advice at his career’s roots.</p>
<p>
Peter Cameron, who was Eric’s doctoral advisor at Oxford University, says in his <a href="https://cameroncounts.wordpress.com">blog</a> that: </p>
<blockquote><p><b> </b> <em> I have had so many congratulatory emails that it almost seems as if I have done something good myself <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\dots}"/> </em>
</p></blockquote>
<p>
I found out about Eric’s appointment while working on this post. Eric is a longtime friend, who while not close is someone that I have always been impressed with. He is a mathematician who turned molecular biologist—we interacted when I worked on <a href="https://science.sciencemag.org/content/268/5210/542">DNA computing</a>. Eric previously worked closely with Biden during the Barack Obama presidency. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<p>
<a href="https://rjlipton.wordpress.com/2021/01/21/science-advisor/landerobamabiden/" rel="attachment wp-att-18026"><img alt="" class="aligncenter wp-image-18026" height="200" src="https://rjlipton.files.wordpress.com/2021/01/landerobamabiden.jpg?w=540&amp;h=200" width="540"/></a>
</p></td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Obama archives <a href="https://obamawhitehouse.archives.gov/blog/2017/01/09/celebrating-contributions-presidents-council-advisors-science-and-technology">source</a> (note Biden next to Obama at left, Lander across from Obama)</font>
</td>
</tr>
</tbody></table>
<p/><p><br/>
Ken found out first from reading his Princeton Class of 1981 news on Facebook. He says: </p>
<blockquote><p><b> </b> <em> Eric was my Resident Advisor in Foulke Hall my freshman year, 1977–78. I originally had the ground-floor double room next to his, but I swapped roommates one door further down with another lover of mathematics and Broadway musicals. His RA group of 16 in the staircase included now-Justice Elena Kagan. Eric brought all of us down for meetings in the early weeks; blessing the roommate swap and discussing compatibility aspects in general was a subject of one of them. I got to Oxford just as Eric was leaving, and my first interaction with Peter Neumann was actually Neumann saying Eric had neglected to do something and could I get him in touch before he returned to the US? Kagan also came to Oxford along with three other ’81-ers whom I associated with more. </em>
</p></blockquote>
<p>
</p><p/><h2> A Wellspring of Advice </h2><p/>
<p/><p>
Eric did a swap himself his first weeks in Oxford. As Cameron relates in a followup <a href="https://cameroncounts.wordpress.com/2021/01/19/family/">post</a>:</p>
<blockquote><p><b> </b> <em> He arrived in Oxford on a Rhodes Scholarship to do research in algebraic topology. But before the term started, he had changed his mind and decided to do coding theory instead. By chance, it happened that I was the only person in Oxford at the time who claimed to know anything about coding theory. <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\dots}"/> So I got to supervise Eric. </em>
</p></blockquote>
<p/><p>
Peter had a good problem ready about how to combine two strands of applying design theory to codes.</p>
<blockquote><p><b> </b> <em> Eric, with a good background in algebraic number theory, took to it immediately. The coding theorists had taken an integer matrix and considered its row space over the finite field with <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{p}"/> elements. Eric observed that, if instead you took the row space over the <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{p}"/>-adic numbers, then you could reduce it modulo arbitrary powers of <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{p}"/>, and get a chain of codes, with the property that duality reversed the order in the chain (so if the power of <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{p}"/> involved was odd then the code in the middle was self-dual).</em></p><em>
</em><p><em>
Eric’s thesis took off from there, and at the end he turned it into a book with the title <em>Symmetric Designs: An Algebraic Approach</em>. </em>
</p></blockquote>
<p/><p>
Of course, coding theory and “stringology” feed into genomics, and from there into the broad reach of science. Eric has no shortage of sources across the spectrum. But the wellspring of his career was our general area, not to mention that both of us followed him in several geographic and academic <a href="https://cs.stanford.edu/people/eroberts/courses/soco/projects/2003-04/dna-computing/history.htm">respects</a>. </p>
<p>
Many of our peer bloggers step out to give general advice on science. Some conspicuously often take their advice and recommendations on natural sciences openly national. Others address it within smaller communities, but their ideas can be equally valuable. All may be worthy of consultation.</p>
<p>
</p><p/><h2> Blogs </h2><p/>
<p/><p>
The one rule we’re setting out now is that in order to be advising the advisor, the blogs must stay current. There are tons of terrific blogs that have stopped publishing altogether, or whose last <em>new</em> post is many moons ago. As for those who try to be reasonably current, Ken and I know how hard it is to do. So we took a three-week horizon—that is, who has posted something this year, 2021. That said, here are some of our favorite blogs on math and CS theory—after the first they are alphabetical by writer(s).</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://terrytao.wordpress.com/tag/model-theory/">What’s New</a> Terence Tao <br/>
The best math blog of all time. If you must read one, then this is the one. If you read two or more math blogs, then this is still the one. If you read two or more posts on this blog, then you qualify as a mathematician.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://www.scottaaronson.com/blog/">Shtetl Optimized</a> Scott Aaronson <br/>
Wonderful blog. A brilliant combination of results, comments, and opinions. We have “encoded” his name in the previous section—see if you can spot where and how.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://francisbach.com">Machine Learning Research Blog</a> Francis Bach <br/>
Focused on connections between optimization and learning. I conjecture that the key to solving some of our deep questions—P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{&lt;}"/>NP—could be resolved by machine-learning technology. I recall a year ago while talking with learning experts at Chicago that they said: We think SAT should have an algorithm that runs in <img alt="{2^{c\sqrt n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bc%5Csqrt+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{2^{c\sqrt n}}"/> time for some <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{c}"/>.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://johncarlosbaez.wordpress.com/">Azimuth</a> John Carlos Baez <br/>
Often goes into physics and policy, such as today’s third <a href="https://johncarlosbaez.wordpress.com/2021/01/21/us-environmental-policy-part-3/">post</a> in a series on environmental policy and climate change. But <a href="https://johncarlosbaez.wordpress.com/2021/01/17/categories-of-nets/">two</a> recent <a href="https://johncarlosbaez.wordpress.com/2021/01/20/categories-of-nets-part-2/">posts</a> were on Petri nets and higher abstractions of them.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet}"/> <a href="https://windowsontheory.org/">Windows on Theory</a> Boaz Barak <br/>
This was originally a joint blog by researchers at the Microsoft Silicon Valley Research Center before it <a href="https://rjlipton.wordpress.com/2014/09/27/microsoft-closes-svc/">closed</a> in 2014. Last week’s <a href="https://windowsontheory.org/2021/01/15/ml-theory-with-bad-drawings/">post</a> is also on machine learning and theory.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://micromath.wordpress.com">Mathematics under the Microscope</a> Alexandre Borovik <br/>
See his <a href="https://www.openbookpublishers.com/10.11647/OBP.0168.pdf">book</a> with Tony Gardiner, <em>The Essence of Mathematics</em>. The spirit of the book is seen in this quote from George Pólya: <i>It is better to solve one problem in five different ways than to solve five problems in one way.</i></p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://agtb.wordpress.com">Turing’s Invisible Hand</a> Felix Brandt, Michal Feldman, Jason Hartline, Bobby Kleinberg, Kevin Leyton-Brown, Noam Nisan, Vijay Vazirani <br/>
They have an annotated version of John Nash’s 1955 <a href="https://agtb.wordpress.com/2012/02/17/john-nashs-letter-to-the-nsa/">letter</a> to the NSA about the complexity of crypto, which beat Kurt Gödel’s “lost letter” by a whole year. As we <a href="https://rjlipton.wordpress.com/2012/04/01/introducing-techplex-com/">joked</a> on 4/1/12, if we had known about it, GLL would have been NLL.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://cameroncounts.wordpress.com">Peter Cameron’ Blog</a> Peter Cameron <br/>
This is where I found out about the appointment of Lander to Biden’s cabinet. Peter is at St. Andrews and emeritus from Queen Mary University of London. Ken wrote about him in his <a href="https://rjlipton.wordpress.com/2021/01/01/peter-m-neumann-1940-2020/">memorial</a> for Peter Neumann.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://quomodocumque.wordpress.com">Quomodocumque</a> Jordan Ellenberg <br/>
He <a href="https://quomodocumque.wordpress.com/2021/01/15/am-i-supposed-to-say-something-about-the-invasion-of-the-united-states-capitol/">asks</a>: Am I Supposed To Say Something About The Invasion Of The United States Capitol? He does. We haven’t. (We are mulling a post on quantitative matters from the pandemic and election that have become political footballs.)</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://11011110.github.io/blog/">11011110</a> David Eppstein—the blog name is his initials DE in hexadecimal and his surname has a double-p.<br/>
Right now he has a wonderful <a href="https://11011110.github.io/blog/2021/01/15/linkage.html">list</a> of open questions and known results. For example there is a discussion of USA flag arrangements, and also the recent claimed solution of an almost 50 year old conjecture: A proof of the Erdős-Faber-Lóvasz <a href="https://arxiv.org/abs/2101.04698">conjecture</a> by Dong Yeap Kang, Tom Kelly, Daniela Kuhn, Abhishek Methuku, Deryk Osthus.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://explainingmaths.wordpress.com">Explaining mathematics</a> Joel Feinstein <br/>
He asks: When proving there exists statements, is it enough to give just one example or do you have to prove it using the definitions, and so on? <a href="https://explainingmaths.wordpress.com/2021/01/09/proving-there-exists-statements/">Read on</a> for more.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://blog.computationalcomplexity.org">Computational Complexity</a> Lance Fortnow and Bill Gasarch <br/>
The CS theory blog that started it all. Continues to be one of the top blogs. Lance’s <a href="https://blog.computationalcomplexity.org/2021/01/the-ethics-board.html">post</a> on Tuesday says that “the way of most suggestions I make in my blog [is] a quick road to nowhere,” but the one in that post went somewhere.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="http://jdh.hamkins.org">logic and more</a> Joel Hamkins <br/>
He discusses the math tea argument—one heard at an afternoon tea. I miss these very much, even though I do not drink tea. The argument is: There must be some real numbers that we cannot define, since there are uncountably many real numbers, but only countably many definitions. Is it correct? <a href="http://jdh.hamkins.org/definability-and-the-math-tea-argument-warsaw-22-january-2021/">Read on</a> about the talk he is giving tomorrow “in” Warsaw for an explanation.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://gilkalai.wordpress.com">Combinatorics and more</a> Gil Kalai <br/>
Gil’s wonderful blog is a great place to see announcements of new results. He’s had a year-long series, “To cheer you up in difficult times”; its 18th <a href="https://gilkalai.wordpress.com/2021/01/19/what-if-they-are-all-wrong/">installment</a> links to a wonderful, thoughtful, entertaining, and provocative post by Igor Pak about conjectures. The 17th <a href="https://gilkalai.wordpress.com/2021/01/14/to-cheer-you-up-in-difficult-times-17-amazing-the-erdos-faber-lovasz-conjecture-for-large-n-was-proved-by-dong-yeap-kang-tom-kelly-daniela-kuhn-abhishek-methuku-and-deryk-osthus/">installment</a> was about the Erdős-Faber-Lóvasz news. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="http://m-phi.blogspot.com">M-Phi</a> Many authors <br/>
All of the recent entries have been by Richard Pettigrew but they have a long list of previous contributors. The recent posts catch Ken’s eye because they employ the <a href="https://en.wikipedia.org/wiki/Brier_score">Brier score</a> to reason philosophically about inaccuracy. Ken has employed his group’s novel <a href="https://rjlipton.wordpress.com/2019/11/29/predicating-predictivity/">adaptation</a> of the Brier score in chess cheating cases all through the pandemic. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://dustingmixon.wordpress.com">Short, Fat Matrices</a> Dustin Mixon <br/>
He discusses a problem by Mario Krenn. The <a href="https://mariokrenn.wordpress.com/graph-theory-question/">problem</a> has consequences for quantum computation—and comes with cash prizes—one is €3,000.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://vzn1.wordpress.com/">Turing Machine</a> VZN <br/>
Just nipped under with a New Year’s Day <a href="https://vzn1.wordpress.com/2021/01/01/collatz-search-for-overarching-strategy/">post</a> on the Collatz <img alt="{3n+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3n%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{3n+1}"/> conjecture.  Ken used to know VZN’s full name but can’t find it now.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://noncommutativeanalysis.wordpress.com">Noncommutative Analysis</a> Orr Shalit <br/>
The issues here are important to quantum computation, since for operators <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{A}"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{B}"/>, <img alt="{AB = BA}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAB+%3D+BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{AB = BA}"/> is usually not true.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://lucatrevisan.wordpress.com">in theory</a> Luca Trevisan <br/>
The only theory blog—I believe—that quotes Homer Simpson: “Marge, I agree with you—in theory. In theory, communism works. In theory.” </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bullet }"/> <a href="https://www.math.columbia.edu/~woit/wordpress/">Not Even Wrong</a> Peter Woit <br/>
Mathematical physics, for the most part, growing out from his 2005 <a href="https://www.amazon.com/Not-Even-Wrong-Failure-Physical/dp/0465092764">book</a> of that title critiquing string theory.</p>
<p>
We also link to sites such as John Awbrey’s <a href="https://inquiryintoinquiry.com/about/">Inquiry Into Inquiry</a> and <a href="https://pinkiguana2.wordpress.com/news/">Pink Iguana</a> that grow in beehive style, and sites with higher-volume politics and culture content such as <a href="https://priorprobability.com/">prior probability</a> by Enrique Guerra-Pujol.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We would be grateful for suggestions of additional mathematics and computing blogs that an advisor’s staff might consult. </p>
<p>
[added Obama-era photo to intro]</p></font></font></div>
    </content>
    <updated>2021-01-21T22:45:38Z</updated>
    <published>2021-01-21T22:45:38Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Advice"/>
    <category term="blogging"/>
    <category term="Eric Lander"/>
    <category term="genetic code"/>
    <category term="genome"/>
    <category term="Joe Biden"/>
    <category term="Presidential Cabinet"/>
    <category term="science"/>
    <category term="science policy"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2021-01-26T03:37:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=21024</id>
    <link href="https://gilkalai.wordpress.com/2021/01/21/amazing-simpler-and-more-general-proofs-for-the-g-theorem-by-stavros-argyrios-papadakis-and-vasiliki-petrotou-and-by-karim-adiprasito-stavros-argyrios-papadakis-and-vasiliki-petrotou/" rel="alternate" type="text/html"/>
    <title>Amazing:  Simpler and more general proofs for the g-theorem by Stavros Argyrios Papadakis and Vasiliki Petrotou, and by Karim Adiprasito, Stavros Argyrios Papadakis, and Vasiliki Petrotou.</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Stavros Argyrios Papadakis, Vasiliki Petrotou, and Karim Adiprasito In 2018, I reported here about Karim Adiprasito’s proof of the g-conjecture for simplicial spheres.  This conjecture by McMullen from 1970 was considered a holy grail of algebraic combinatorics and it resisted … <a href="https://gilkalai.wordpress.com/2021/01/21/amazing-simpler-and-more-general-proofs-for-the-g-theorem-by-stavros-argyrios-papadakis-and-vasiliki-petrotou-and-by-karim-adiprasito-stavros-argyrios-papadakis-and-vasiliki-petrotou/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2021/01/g-sphere.png"><img alt="" class="alignnone size-large wp-image-21044" height="214" src="https://gilkalai.files.wordpress.com/2021/01/g-sphere.png?w=640&amp;h=214" width="640"/></a></p>
<p><span style="color: #ff0000;">Stavros Argyrios Papadakis, Vasiliki Petrotou, and Karim Adiprasito</span></p>
<p>In 2018, <a href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/">I reported here</a> about Karim Adiprasito’s proof of the g-conjecture for simplicial spheres.  This conjecture by McMullen from 1970 was considered a holy grail of algebraic combinatorics and it resisted attacks by many researchers over the years.</p>
<p>Today’s post  reports on two developments. The first from December 2020 is a second proof for the <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="g"/>-conjecture for spheres by Stavros Argyrios Papadakis and Vasiliki Petrotou. (Here is a link to <a href="https://arxiv.org/abs/2012.09815">the arXive paper</a>.) A second proof to a major difficult theorem is always very very important and exciting.  The proof seems considerably simpler than Karim Adiprasito’s proof. The miracle that enables simplification was working with <em>characteristic two</em> in contrast to Adirasito’s proof which is characteristic free, and which therefore applies in greater generality.</p>
<p>However, the two teams joined forces, and in January 2021 posted a proof  (which seems even simpler) by Karim Adiprasito, Stavros Argyrios Papadakis and Vasiliki Petrotou of the <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="g"/>-conjecture largely extended to pseudomanifolds. (Here is a link to <a href="https://arxiv.org/abs/2101.07245">the arXived paper</a>.)</p>
<p>I was too slow to report on these developments separately, so let me report here on both.  I am thankful to Karim Adiprasito for telling me about both results and some further conversations.</p>
<p>I hope that with these new proofs more people in the community will be able to absorb and understand the ideas, go carefully over the proofs, and apply the methods to a large number of outstanding problems beyond the <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="g"/>-conjecture. (A few of which are <a href="https://gilkalai.wordpress.com/2018/06/20/beyond-the-g-conjecture-algebraic-combinatorics-of-cellular-spaces-i/">discussed in this post</a>.)</p>
<h2>December 2020: Stavros Argyrios Papadakis and Vasiliki Petrotou present a second proof of the g-conjecture.</h2>
<p>A few weeks ago Stavros Argyrios Papadakis and Vasiliki Petrotou uploaded a paper on the arXive <a href="https://arxiv.org/abs/2012.09815">The characteristic 2 anisotropicity of simplicial spheres.</a>   The paper presents a second proof for McMullen’s <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="g"/>-conjecture for simplicial spheres.</p>
<p>Stavros Argyrios Papadakis and Vasiliki Petrotou: <a href="https://arxiv.org/abs/2012.09815">The characteristic 2 anisotropicity of simplicial spheres</a></p>
<p><strong><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:</strong> <span class="abstract-full has-text-grey-dark mathjax" id="2012.09815v1-abstract-full">Assume <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="D"/> is a simplicial sphere, and <img alt="k_1" class="latex" src="https://s0.wp.com/latex.php?latex=k_1&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k_1"/> is a field. We say that <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="D"/> is generically anisotropic over <img alt="k_1" class="latex" src="https://s0.wp.com/latex.php?latex=k_1&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k_1"/> if, for a certain purely transcendental field extension <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k"/> of <img alt="k_1" class="latex" src="https://s0.wp.com/latex.php?latex=k_1&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k_1"/>, a certain Artinian reduction <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="A"/> of the Stanley-Reisner ring <img alt="k[D]" class="latex" src="https://s0.wp.com/latex.php?latex=k%5BD%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k[D]"/> has the following property: All nonzero homogeneous elements <img alt="u" class="latex" src="https://s0.wp.com/latex.php?latex=u&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="u"/> of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="A"/> of degree less or equal to <img alt="(\dim D +1)/2" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cdim+D+%2B1%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="(\dim D +1)/2"/> have nonzero square. We prove, using suitable differential operators, that, if the field <img alt="k_1" class="latex" src="https://s0.wp.com/latex.php?latex=k_1&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k_1"/> has characteristic 2, then every simplicial sphere <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="D"/> is generically anisotropic over <img alt="k_1" class="latex" src="https://s0.wp.com/latex.php?latex=k_1&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k_1"/>. As an application, we give a second proof of a recent result of Adiprasito, known as McMullen’s <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="g"/>-conjecture for simplicial spheres. We also prove that the simplicial spheres of dimension 1 are generically anisotropic over any field <img alt="k_1" class="latex" src="https://s0.wp.com/latex.php?latex=k_1&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k_1"/>.</span></p>
<p>(GK) The <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="g"/>-conjecture is about relations between face numbers of simplicial spheres. The new proof, like Karim’s proof and most earlier attacks goes through an algebraic property, the <strong>Lefschetz  property</strong>. And here this property is proved for fields of coefficients of characteristic two. The proof relies on a formula whose discovery was assisted by computer experimentation using the Grayson-Stillman computer algebra program <a href="https://en.wikipedia.org/wiki/Macaulay2">Macaulay II</a>.</p>
<h2>January 2021: Karim Adiprasito, Stavros Argyrios Papadakis, and Vasiliki Petrotou present a new proof for the <em>g</em>-theorem extended to general pseudomanifolds, cycles, and doubly-Cohen Macualay complexes.</h2>
<p>A few days ago Karim, Stavros Argyrios, and Vasiliki uploaded a new joint paper with yet a further simplification of the argument and far-reaching extensions to pseudomanifolds, cycles, and doubly Cohen Macaulay complexes.</p>
<p>Karim Adiprasito, Stavros Argyrios Papadakis and Vasiliki Petrotou, <a href="https://arxiv.org/abs/2101.07245">Anisotropy, biased pairings, and the Lefschetz property for pseudomanifolds and cycles</a></p>
<p><strong><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:</strong> <span class="abstract-full has-text-grey-dark mathjax" id="2101.07245v1-abstract-full">We prove the hard Lefschetz property for pseudomanifolds and cycles in any characteristic with respect to an appropriate Artinian reduction. The proof is a combination of Adiprasito’s biased pairing theory and a generalization of a formula of Papadakis-Petrotou to arbitrary characteristic. In particular, we prove the Lefschetz theorem for doubly Cohen Macaulay complexes, solving a generalization of the <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="g"/>-conjecture due to Stanley. We also provide a simplified presentation of the characteristic 2 case of the Papadakis-Petrotou formula, and generalize it to pseudomanifolds and cycles.</span></p>
<h2>A few more comments on both papers</h2>
<p>A crucial ingredient in these works is the need to understand the behaviour of Stanley-Reisner ring w.r.t. generic systems of parameters. Finding the right tools to use “genericity” is a crucial question. Adiprasito considered in his 2018 paper the <strong>Hall-Laman property</strong> which is related to the connection with framework rigidity and the notion of generic rigidity. This property is crucial (under somewhat smaller generality) in the newest APP paper.  It is also closely related to the generic anisotropicity property studied by Papadakis and Vasiliki Petrotou.</p>
<p>Exploring the use of genericity and the connections with rigidity in the study of face numbers go back to works from the 80s and 90s by Stanley, Kalai, Björner and Kalai, Billera, Whitely, Lee, Tay and Whitely, and others. The reference to Hall is based on  Hall’s famous marriage theorems (that has some roots also in Jacobi’s work) and its connections with generic determinants that were considered in the works of  Tutte, Edmonds, Lovàsz, Rabin and Vazirani, Karp, Upfal, and Wigderson, and others. The reference to Laman refers to Laman’s 1970 theorem that gives a characterization for planar generic rigidity (we discussed it briefly in <a href="https://gilkalai.wordpress.com/2009/12/06/four-derandomization-problems/">this post on derandomization</a>).</p>
<p>Another crucial idea both in Adiprasito’s 2018 proof and the Papadakis- Petrotou proof is the nondegeneracy (in a strong sense) of a Poincaré pairing. Both proofs use the property that the Poincaré pairing does not degenerate at ideals (something Karim calls the <b>biased pairing property</b>) as well infinitesimal deformations of the linear system of parameters. Karim told me that both proofs, however, face distinct difficulties: while his proof is geometrically difficult, and the Papadakis- Petrotou paper is restricted by the characteristic of the field. Through combining, they managed to circumvent both these difficulties!</p>
<p>While, the Lefschetz property  is extended to arbitrary characteristics and to very general classes of simplicial complexes, the generic anisotropicity property itself is still open beyond characteristic two. The new paper also offers a new understanding of the formula that was achieved originally by Stavros and Vasiliki with computer experimentation, and relates it to old results by Carl Lee.</p>
<p>I am quite happy that the new proof extends to the exciting uncharted territory of pseudomanifolds, as there are a lot we want to understand regarding their Stanley-Reisner rings. For example, it is a long dream of mine to be able to identify Goresky-MacPherson’s intersection cohomology of a simplicial pseudomanifold <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="K"/>, (for arbitrary perversities) through the Stanley-Reisner ring.</p>
<p>For earlier posts on the g-conjecture <a href="https://gilkalai.wordpress.com/tag/g-conjecture/">click here</a>. See especially the guest posts by Eran Nevo.</p>
<h2>Hilda Geiringer</h2>
<p>An interesting historical comment is that Laman’s 1970 theorem about generic planar rigidity was proved already in 1927 by the famous applied mathematician and statistician <a href="https://en.wikipedia.org/wiki/Hilda_Geiringer">Hilda Pollaczek-Geiringer</a>. Here is an <a href="https://www.lancaster.ac.uk/media/lancaster-university/content-assets/documents/maths/events-abstracts/slides/bond-node-structures-2017/Servatius-slides-Bond-node-structures-Lancaster-2017.pdf">English exposition of her proof and some of her other works on rigidity</a> by Brigitte Servatius.</p></div>
    </content>
    <updated>2021-01-21T10:55:16Z</updated>
    <published>2021-01-21T10:55:16Z</published>
    <category term="Algebra"/>
    <category term="Combinatorics"/>
    <category term="Geometry"/>
    <category term="g-conjecture"/>
    <category term="Hilda Geiringer"/>
    <category term="Karim Adiprasito"/>
    <category term="Stavros Argyrios Papadakis"/>
    <category term="Vasiliki Petrotou"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2021-01-26T03:37:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5256</id>
    <link href="https://www.scottaaronson.com/blog/?p=5256" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5256#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5256" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">A day to celebrate</title>
    <summary xml:lang="en-US">The reason I’m celebrating is presumably obvious to all: today is my daughter Lily’s 8th birthday! (She had a tiny Star Wars-themed party, dressed in her Rey costume.) A second reason I’m celebrating yesterday: I began teaching (via Zoom, of course) the latest iteration of my graduate course on Quantum Complexity Theory! A third reason: […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>The reason I’m celebrating is presumably obvious to all: today is my daughter Lily’s 8<sup>th</sup> birthday!  (She had a tiny <em>Star Wars</em>-themed party, dressed in her Rey costume.)</p>



<p>A second reason I’m celebrating yesterday: I began teaching (via Zoom, of course) the latest iteration of my graduate course on Quantum Complexity Theory!</p>



<p>A third reason: I’m now scheduled to get my first covid vaccine shot on Monday!  (Texas is working through its “Phase 1b,” which includes both the over-65 and those with underlying conditions—in my case, mild type-2 diabetes.)  I’d encourage everyone to do as I did: don’t lie to jump the line, but don’t sacrifice your place either.  Just follow the stated rules and get vaccinated the first microsecond you can, and urge all your friends and loved ones to do the same.  A crush of demand is actually <em>good</em> if it encourages the providers to expand their hours (they’re taking off weekends! they took off MLK Day!) and not to waste a single dose.</p>



<p>Anyway, people can use this thread to talk about whatever they like, but one thing that would interest me especially is readers’ experiences with vaccination: if you’ve gotten one by now, how hard did you have to look for an appointment, how orderly or chaotic was the process where you live, and what advice can you offer?</p>



<p>Incidentally, to the several commenters on this blog who expressed <em>absolute certainty</em> (as recently as yesterday) that Trump would reverse the election result and be inaugurated instead of Biden, and who confidently accused the rest of us of living in a manufactured media bubble that prevented them from seeing that: I respect that, whatever else is said about you, no one can ever again accuse you of being fair-weather friends!</p>



<p>Congratulations to the new President!  There are difficult months ahead, but today the arc of the universe bent slightly toward sanity and goodness.</p>



<p><strong><span class="has-inline-color has-vivid-red-color">Update (Jan 21):</span></strong> WOOHOO!  Yet another reason to celebrate: Scott Alexander is finally back in business, now blogging at <a href="https://astralcodexten.substack.com/">Astral Codex Ten</a> on Substack.</p></div>
    </content>
    <updated>2021-01-20T19:00:59Z</updated>
    <published>2021-01-20T19:00:59Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-01-22T04:09:45Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2344881105581863703</id>
    <link href="https://blog.computationalcomplexity.org/feeds/2344881105581863703/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/01/the-ethics-board.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2344881105581863703" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2344881105581863703" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/01/the-ethics-board.html" rel="alternate" type="text/html"/>
    <title>The Ethics Board</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Back in 2014 I recommended a <a href="https://blog.computationalcomplexity.org/2014/03/should-we-have-tcs-ethics-board.html">TCS ethics board</a> mainly to deal with plagiarism and who should get credit for a result. It went the way of most suggestions I make in my blog, a quick road to nowhere. Bill <a href="https://blog.computationalcomplexity.org/2014/03/should-we-have-tcs-ethics-board.html?showComment=1396496899643#c955985184567246644">asked</a> "Does any other branch of CS have an ethics board? How have they worked?"</p><p>The NeurIPS conference created a such a board for the <a href="https://neuripsconf.medium.com/what-we-learned-from-neurips-2020-reviewing-process-e24549eea38f">reviewing process</a>, though with a broader mission.</p><p/><blockquote><p>We appointed an ethics advisor and invited a pool of 22 ethics reviewers (listed <a href="https://neurips.cc/Conferences/2020/ProgramCommittee">here</a>) with expertise in fields such as AI policy, fairness and transparency, and ethics and machine learning. Reviewers could flag papers for ethical concerns, such as submissions with undue risk of harm or methods that might increase unfair bias through improper use of data, etc. Papers that received strong technical reviews yet were flagged for ethical reasons were assessed by the pool of ethics reviewers.</p><p>Thirteen papers met these criteria and received ethics reviews. Only four papers were rejected because of ethical considerations, after a thorough assessment that included the original technical reviewers, the area chair, the senior area chair and also the program chairs. Seven papers flagged for ethical concerns were conditionally accepted, meaning that the final decision is pending the assessment of the area chair once the camera ready version is submitted. Some of these papers require a thorough revision of the broader impact section to include a clearer discussion of potential risks and mitigations, and others require changes to the submission such as the removal of problematic datasets. Overall, we believe that the ethics review was a successful and important addition to the review process. Though only a small fraction of papers received detailed ethical assessments, the issues they presented were important and complex and deserved the extended consideration. In addition, we were very happy with the high quality of the assessments offered by the ethics reviewers, and the area chairs and senior area chairs also appreciated the additional feedback.</p></blockquote><p/><div>Without seeing the process I cannot say what criteria were used to reject the four papers. There could be legitimate reasons if the authors did violate professional ethics or even inadvertently based their results on biased data sets. But there's a fine line to rejecting papers because you don't like the outcome or the questions they ask. No easy answers here.</div></div>
    </content>
    <updated>2021-01-19T12:10:00Z</updated>
    <published>2021-01-19T12:10:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-01-25T18:51:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/2021/01/19/what-if-they-are-all-wrong/</id>
    <link href="https://gilkalai.wordpress.com/2021/01/19/what-if-they-are-all-wrong/" rel="alternate" type="text/html"/>
    <title>Igor Pak: What if they are all wrong?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Originally posted on <a href="https://igorpak.wordpress.com/2020/12/10/what-if-they-are-all-wrong/">Igor Pak's blog</a>: <br/>Conjectures are a staple of mathematics. They are everywhere, permeating every area, subarea and subsubarea. They are diverse enough to avoid a single general adjective. They come in al shapes and sizes. Some…</div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wpcom-reblog-snapshot"><div class="reblogger-note"><div class="reblogger-note-content"><blockquote><p><span style="color: #0000ff;">To cheer you up in difficult times</span>, here is a wonderful thoughtful, entertaining, and provocative post by <strong>Igor Pak</strong> about conjectures. See also <a href="https://gilkalai.wordpress.com/2008/11/19/about-conjectures-shmuel-weinberger/">Shmuel Weinberger’s take</a> on conjectures.</p>
</blockquote></div></div><div class="reblog-post"><p class="reblog-from"><img alt="" class="avatar avatar-32" height="32" src="https://2.gravatar.com/avatar/28ad5e53cacd5f67ae8b4d80bbcff03d?s=32&amp;d=identicon&amp;r=PG" width="32"/><a href="https://igorpak.wordpress.com/2020/12/10/what-if-they-are-all-wrong/">Igor Pak's blog</a></p><div class="reblogged-content">
<p/>

<p><em><strong><span class="has-inline-color has-vivid-cyan-blue-color">Conjectures</span></strong></em>are a staple of mathematics.  They are everywhere, permeating every area, subarea and subsubarea.  They are diverse enough to avoid a single general adjective.  They come in al shapes and sizes.  Some of them are famous, classical, general, important, inspirational, far-reaching, audacious, exiting or popular, while others are speculative, narrow, technical, imprecise, far-fetched, misleading or recreational.  That’s a lot of beliefs about unproven claims, yet we persist in dispensing them, inadvertently revealing our experience, intuition and biases.</p>

<p/>

<p/>

<p>The conjectures also vary in attitude.  Like a finish line ribbon they all appear equally vulnerable to an outsider, but in fact differ widely from race to race.  <em>Some </em>are eminently reachable, the only question being who will get there first (think <a href="https://en.wikipedia.org/wiki/100_metres">100 meter dash</a>).  <em>Others </em>are barely on the horizon, requiring both great effort, variety of tools, and an extended time commitment (think <a href="https://en.wikipedia.org/wiki/Ironman_Triathlon">ironman triathlon</a>).  The most celebrated <em>third…</em></p>
</div><p class="reblog-source"><a href="https://igorpak.wordpress.com/2020/12/10/what-if-they-are-all-wrong/">View original post</a> <span class="more-words">4,844 more words</span></p></div></div></div>
    </content>
    <updated>2021-01-19T08:34:06Z</updated>
    <published>2021-01-19T08:34:06Z</published>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Geometry"/>
    <category term="What is Mathematics"/>
    <category term="Igor Pak"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2021-01-26T03:37:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=18000</id>
    <link href="https://rjlipton.wordpress.com/2021/01/18/edmund-clarke-1945-2020/" rel="alternate" type="text/html"/>
    <title>Edmund Clarke, 1945–2020</title>
    <summary>If only model checking could fight the virus Edmund Clarke passed away due to COVID-19 complications. Ed will be missed. He was a winner of the 2007 Turing award for his seminal work on model checking. This was joint with Allen Emerson and Joseph Sifakis. They were cited for “developing Model Checking into a highly […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>If only model checking could fight the virus</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wordpress.com/2021/01/18/edmund-clarke-1945-2020/ed/" rel="attachment wp-att-18003"><img alt="" class="alignright  wp-image-18003" src="https://rjlipton.files.wordpress.com/2021/01/ed.jpg?w=134" width="134"/></a></p>
<p>
Edmund Clarke passed away <a href="https://spectrum.ieee.org/the-institute/ieee-member-news/edmund-melson-clarke-creator-of-model-checking-dies-at-75">due</a> to COVID-19 complications. Ed will be missed. He was a winner of the 2007 Turing <a href="https://web.archive.org/web/20081228210748/http://www.acm.org/press-room/news-releases/turing-award-07/">award</a> for his seminal work on <a href="https://en.wikipedia.org/wiki/Model_checking#Overview">model checking</a>. This was joint with Allen Emerson and Joseph Sifakis. They were cited for “developing Model Checking into a highly effective verification technology that is widely adopted in the hardware and software industries.” </p>
<p>
Today I thought we might highlight some of his contributions.<br/>
<span id="more-18000"/></p>
<p>
Ed was someone that I knew since the late 1970’s. We met in 1977 at POPL—a conference that I used to regularly attend—where Ed gave a talk. He was a student of Bob Constable; Ken knew Bob at Cornell the next decade but does not recall meeting Ed. As related in this short IEEE <a href="https://spectrum.ieee.org/the-institute/ieee-member-news/edmund-melson-clarke-creator-of-model-checking-dies-at-75">bio</a>, Ed had his bachelor’s and master’s degrees in mathematics and started as a mathematics PhD at Cornell before changing to computer science. His POPL <a href="https://dl.acm.org/doi/10.1145/512950.512952">paper</a> was on exactly what his Wikipedia <a href="https://en.wikipedia.org/wiki/Edmund_M._Clarke">bio</a> notes about his thesis work under Constable: it found programming language constructs that were tough nuts for Tony Hoare’s program verification logics. </p>
<p>
The IEEE bio continues: </p>
<blockquote><p><b> </b> <em> After graduating in 1976, Clarke joined Duke as a computer science professor. In 1978 he began teaching computer science at Harvard. While there, Clarke and his doctoral student Allen Emerson conducted research on methods that could be used to effectively verify how a system performs without errors. In 1981 they published a paper on model checking, “Design and Synthesis of Synchronization Skeletons Using Branching Time Temporal Logic,” in <a href="https://link.springer.com/book/10.1007/BFb0025769">Logics of Programs</a>. </em>
</p></blockquote>
<p>
</p><p/><h2> Model Checking </h2><p/>
<p>
</p><p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2021/01/18/edmund-clarke-1945-2020/over-2/" rel="attachment wp-att-18002"><img alt="" class="alignright size-full wp-image-18002" src="https://rjlipton.files.wordpress.com/2021/01/over.png?w=600"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
Model Checking (MC) is related to verification technology (VT). But it is different. MC was initially used mostly for hardware, although it is used for software too. MC also can and is used for partial properties. This to me is the main and most interesting difference. See <a href="https://www.cs.cmu.edu/~emc/15414-f12/lecture/intro_mc.pdf">slides</a> and the <a href="https://mitpress.mit.edu/books/model-checking-second-edition">book</a> by Ed, Orna Grumberg, Daniel Kroening, Doron Peled, and Helmut Veith.</p>
<p>
I have long had doubts about the claims of VT. This goes back to my 1979 <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/social.pdf">paper</a> with Rich DeMillo and Alan Perlis. We had several issues with the claims of VT, issues that still hold today.</p>
<p>
The brilliant insight of Ed and his colleagues is that these issues are avoided for the most part by MC. Here are the main ones:</p>
<ol>
<li>
What is correct? A key issue with VT is how do you capture the notion of correctness? We argued even for almost trivial algorithms it is hard to get this right. For sorting type algorithms we noted that even a published account gets the correctness wrong: they left out that the output was not only in sorted order, but also was a permutation of the input. <p/>
</li><li>
How do you prove them? Okay suppose you believe that you have captured what correctness means. How do you know that it always holds? VT tries to prove the universal sentence: For all inputs, the algorithm always satisfies the property. The difficulty is that proofs in mathematics are different than proofs that arise in VT. This difference reduces the ability to trust proofs. We trust math proofs for all sorts of reasons that do not apply to VT.
</li></ol>
<p>
The point of MC is that there are answers to these: </p>
<ol>
<li>
What is correct? MC uses a variety of tools that makes correctness more likely to be captured. I especially like the ability to give partial notions of correctness. It may be hard to state exactly what you want hardware to do, but it may be easy to state something that you want it to satisfy. A server’s correctness may be difficult to capture, but requiring the server to avoid stopping completely, may be still quite useful. <p/>
</li><li>
How do you prove them? MC uses automatic tools rather than proofs. This allows tremendous leverage that makes the MC much more reliable than any proof based system. This cannot be stressed enough. Checking via a general tool is immensely more believable than any proof.
</li></ol>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Our thoughts and condolences go out to Ed’s family and friends.</p>
<p/></font></font></div>
    </content>
    <updated>2021-01-19T01:00:00Z</updated>
    <published>2021-01-19T01:00:00Z</published>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="People"/>
    <category term="Results"/>
    <category term="Ed Clarke"/>
    <category term="model checking"/>
    <category term="Proofs"/>
    <category term="verification"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2021-01-26T03:37:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/007</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/007" rel="alternate" type="text/html"/>
    <title>TR21-007 |  Almost Optimal Inapproximability of Multidimensional Packing Problems | 

	Sai Sandeep</title>
    <summary>Multidimensional packing problems generalize the classical packing problems such as Bin Packing, Multiprocessor Scheduling by allowing the jobs to be $d$-dimensional vectors. While the approximability of the scalar problems is well understood, there has been a significant gap between the approximation algorithms and the hardness results for the multidimensional variants. In this paper, we close this gap by giving almost tight hardness results for these problems.
1. We show that Vector Bin Packing has no $\Omega( \log d)$ factor asymptotic approximation algorithm when $d$ is a large constant, assuming $P \neq NP$. This matches the $\ln d + O(1)$ factor approximation algorithms (Chekuri, Khanna SICOMP 2004, Bansal, Caprara, Sviridenko SICOMP 2009, Bansal, Eliáš, Khan SODA 2016) upto constants. 
2. We show that Vector Scheduling has no polynomial time algorithm with an approximation ratio of $\Omega\left( (\log d)^{1-\epsilon}\right)$ when $d$ is part of the input, assuming NP has no quasipolynomial time algorithms. This almost matches the $O\left( \frac{\log d}{\log \log d}\right)$ factor algorithms(Harris, Srinivasan JACM 2019, Im, Kell, Kulkarni, Panigrahi SICOMP 2019). We also show that the problem is NP-hard to approximate within $(\log \log d)^{\omega(1)}$. 
3. We show that Vector Bin Covering is NP-hard to approximate within $\Omega\left( \frac{\log d}{\log \log d}\right)$ when $d$ is part of the input, almost matching the $O(\log d)$ factor algorithm (Alon et al., Algorithmica 1998). 

	Previously, no hardness results that grow with $d$ were known for Vector Scheduling and Vector Bin Covering when $d$ is part of the input and for Vector Bin Packing when $d$ is a fixed constant.</summary>
    <updated>2021-01-18T16:02:07Z</updated>
    <published>2021-01-18T16:02:07Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-01-26T03:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/006</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/006" rel="alternate" type="text/html"/>
    <title>TR21-006 |  How Limited Interaction Hinders Real Communication (and What It Means for Proof and Circuit Complexity) | 

	Susanna de Rezende, 

	Jakob Nordström, 

	Marc Vinyals</title>
    <summary>We obtain the first true size-space trade-offs for the cutting planes proof system, where the upper bounds hold for size and total space for derivations with constant-size coefficients, and the lower bounds apply to length and formula space (i.e., number of inequalities in memory) even for derivations with exponentially large coefficients. These are also the first trade-offs to hold uniformly for resolution, polynomial calculus and cutting planes, thus capturing the main methods of reasoning used in current state-of-the-art SAT solvers.

We prove our results by a reduction to communication lower bounds in a round-efficient version of the  real communication model of [Krají$\check{c}$ek '98], drawing on and extending techniques in [Raz and McKenzie '99] and [Göös et al. '15]. Such lower bounds are in turn established by a reduction to trade-offs between cost and number of rounds in the game of [Dymond and Tompa '85] played on directed acyclic graphs.

As a by-product of the techniques developed to show these proof complexity trade-off results, we also obtain a separation between $\textrm{monotone-AC}^{i-1}$ and $\textrm{monotone-NC}^{i}$, and an exponential separation between $\textrm{monotone-AC}^{i-1}$ and $\textrm{monotone-AC}^{i}$, improving exponentially over the superpolynomial separation in [Raz and McKenzie '99].</summary>
    <updated>2021-01-18T15:55:43Z</updated>
    <published>2021-01-18T15:55:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-01-26T03:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7963</id>
    <link href="https://windowsontheory.org/2021/01/15/ml-theory-with-bad-drawings/" rel="alternate" type="text/html"/>
    <title>ML Theory with bad drawings</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This semester I am teaching a seminar on the theory of machine learning. For the first lecture, I would like to talk about what is the theory of machine learning. I decided to write this (very rough!) blog post mainly to organize my own thoughts. In any science, ML included, the goals of theory and … <a class="more-link" href="https://windowsontheory.org/2021/01/15/ml-theory-with-bad-drawings/">Continue reading <span class="screen-reader-text">ML Theory with bad drawings</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This semester I am teaching a <a href="https://boazbk.github.io/mltheoryseminar/">seminar on the theory of machine learning</a>. For the first lecture, I would like to talk about what is the theory of machine learning. I decided to write this (very rough!) blog post mainly to organize my own thoughts.</p>



<p>In any science, ML included, the goals of theory and practice are not disjoint. We study the same general phenomena from different perspectives. We can think of questions in computation at a high level as trying to map the unknown terrain of the computational cost of achieving certain quality of output, given some conditions on the input.</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/h8ZOrcE.png"/></figure>



<p>Practitioners aim to find points on this terrain’s practically relevant regions, while theoreticians are more interested in its broad landscape, including at points far out into infinity. Both theoreticians and practitioners care about <em>discontinuities</em>, when small changes in one aspect correspond to large changes in another. As theoreticians, we care about <em>computational/statistical tradeoffs</em>, particularly about points where a small difference in quality yields an exponential difference in time or sample complexity. In practice, models such as GPT-3 demonstrate that a quantitative increase in computational resources can correspond to a qualitative increase in abilities.</p>



<p>Since theory and practice study the same phenomenon in different ways, their relation can vary. Sometimes theory is forward-looking or <em>prescriptive</em> – giving “proof of concepts” results that can inspire future application or impossibility results that can rule out certain directions. Sometimes it is backward-looking or <em>descriptive</em> – explaining phenomena uncovered by experiments and putting them in a larger context.</p>



<h2>What is machine learning?</h2>



<p>Before we talk about what is machine-learning theory, we should talk about what is machine learning. It’s common to see claims of the form “machine learning is X”:</p>



<ul><li>Machine learning is just statistics</li><li>Machine learning is just optimization</li><li>Machine learning is just approximation or “curve fitting”</li></ul>



<p>and probably many more.</p>



<p>I view machine learning as addressing the following setup:</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/KPvtSl6.png"/></figure>



<p>There is a system <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="f"/> that interacts with the world around it in some manner, and we have some sense of whether this interaction is successful or unsuccessful.</p>



<p>For example, a self-driving car is “successful” if it gets passengers from point A to point B safely, quickly, and comfortably. It is “unsuccessful” if it gets into accidents, takes a long time, or drives in a halting or otherwise uncomfortable manner.</p>



<h3>Three levels of indirection</h3>



<p>The system <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="f"/> is the “machine.” It is “learning” since we <em>adapt</em> <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="f"/> so that it becomes more successful. Ideally, we would set <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="f"/> to be the most successful system. However, what we actually do is at least <em>thrice-removed</em> from this ideal:</p>



<ol><li><strong>The model gap:</strong> We do not optimize overall possible systems, but rather a small subset of such systems (e.g., ones that belong to a certain family of models).</li><li><strong>The metric gap:</strong> In almost all cases, we do not optimize the actual measure of success we care about, but rather another metric that is at best correlated with it.</li><li><strong>The algorithm gap:</strong> We don’t even optimize the latter metric since it will almost always be non-convex, and hence the system we end up with depends on our starting point and the particular algorithms we use.</li></ol>



<p>The magic of machine learning is that sometimes (though not always!) we can still get good results despite these gaps. Much of the theory of machine learning is about understanding under what conditions can we bridge some of these gaps.</p>



<p>The above discussion explains the “machine Learning is just X” takes. The expressivity of our models falls under <em>approximation theory</em>. The gap between the success we want to achieve and the metric we can measure often corresponds to the difference between <em>population</em> and <em>sample</em> performance, which becomes a question of <em>statistics</em>. The study of our algorithms’ performance falls under <em>optimization</em>.</p>



<p>The <strong>metric gap</strong> is perhaps the widest of them all. While in some settings (e.g., designing systems to play video games) we can directly measure a system’s success, this is typically the exception rather than rule. Often:</p>



<ul><li>The data we have access to is not the data the system will run on and might not even come from the same distribution.</li><li>The measure of success that we care about is not necessarily well defined or accessible to us. Even if it was, it is not necessarily in a form that we can directly optimize.</li></ul>



<p>Nevertheless, the hope is that if we optimize the hell out of the metrics we can measure, the system will perform well in the way we care about. In other words:</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/tDKqZZC.jpg"/></figure>



<p>A priori, it is not clear that this should be the case, and indeed it’s not always is. Part of the magic of auto-differentiation is that it allows optimization of more complex metrics that match more closely with the success metric we have in mind. But, except for very special circumstances, the two metrics can never be the same. The mismatch between the goal we have and the metric we optimize can manifest in one of the following general ways:</p>



<ul><li><strong>“No free lunch”</strong> or <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">Goodhart’s law</a>: If we optimize a metric <img alt="\mathcal{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="\mathcal{M}"/> then we will get a system that does very well at <img alt="\mathcal{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="\mathcal{M}"/> and not at all well in any other measure. For example, if we optimize accuracy in predicting images, then we may <a href="https://arxiv.org/abs/1805.12152">not do well</a> on slightly perturbed versions of these images.</li><li><strong>“It’s not the destination, it’s the journey”</strong> or <a href="https://en.wikipedia.org/wiki/Anna_Karenina_principle">Anna Karenina principle</a>: All successful systems are similar to one another, and hence if we make our system successful with respect to a metric <img alt="\mathcal{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="\mathcal{M}"/> then it is likely to also be successful with respect to related measures. For example, image classifiers trained on ImageNet have been successfully used for very different images, and there is also evidence that success in ImageNet translates into success on a related distribution (i.e., <a href="https://arxiv.org/abs/1902.10811">ImageNet v2</a>).</li></ul>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/mzSqGVe.png"/></figure>



<p>At the moment, we have no good way to predict when a system will behave according to Goodhart’s law versus the Anna Karenina principle. It seems that when it comes to learning <em>representations</em>, machine learning systems follow the Anna Karenina principle: all successful models tend to learn very similar representations of their data. In contrast, when it comes to making <em>decisions</em>, we get manifestations of Goodhart’s law, and optimizing for one metric can give very different results than the other.</p>



<p>The <strong>model gap</strong> is the gap between the set of all possible systems and the set that we actually optimize over. Even if a system can be captured as a finite function (say a function mapping <img alt="32 \times 32" class="latex" src="https://s0.wp.com/latex.php?latex=32+%5Ctimes+32&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="32 \times 32"/> pixel images to <img alt="10" class="latex" src="https://s0.wp.com/latex.php?latex=10&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="10"/> classes), a simple counting argument shows that the vast majority of these functions require far too many gates to be efficiently computable by any reasonable computational model. (In case you are curious, the counting argument also works for <em>quantum</em> circuits.) Hence we necessarily have to deal with a subclass of all possible functions.</p>



<p>This raises the question of whether we should expect a realizable system to <em>exist</em>, let alone for us to find it. Often machine learning is used in <em>artifical intelligence</em> applications, where we are trying to mimic human performance. In such cases, human performance is an “existence proof” that some reasonably-sized circuit is successful in the goal. But whether this circuit can be embedded in our model family is still an open question.</p>



<p>Remember when I said that sometimes it’s not about the journey but about the destination? I lied. The <strong>algorithm gap</strong> implies that in modern machine learning, there is a certain sense in which it is always about the journey. In modern machine learning, the system <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="f"/> is typically parameterized by a vector <img alt="w \in \mathbb{R}^N" class="latex" src="https://s0.wp.com/latex.php?latex=w+%5Cin+%5Cmathbb%7BR%7D%5EN&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="w \in \mathbb{R}^N"/> of real numbers. Hence the <em>metric</em> we optimize over is to minimize some loss function <img alt="\mathcal{L}(w)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BL%7D%28w%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="\mathcal{L}(w)"/>. We use <em>local search algorithms</em>, which start off at some vector <img alt="w_0" class="latex" src="https://s0.wp.com/latex.php?latex=w_0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="w_0"/> chosen via some distribution, and then iteratively takes small steps <img alt="w_1,w_2,w_3,\ldots" class="latex" src="https://s0.wp.com/latex.php?latex=w_1%2Cw_2%2Cw_3%2C%5Cldots&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="w_1,w_2,w_3,\ldots"/>. For each <img alt="w_i" class="latex" src="https://s0.wp.com/latex.php?latex=w_i&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="w_i"/>, the next step <img alt="w_{i+1}" class="latex" src="https://s0.wp.com/latex.php?latex=w_%7Bi%2B1%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="w_{i+1}"/> is chosen from some distribution of vectors close to <img alt="w_i" class="latex" src="https://s0.wp.com/latex.php?latex=w_i&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="w_i"/> such that (hopefully) in expectation <img alt="\mathcal{L}(w_{i+1}) &lt; \mathcal{L}(w_i)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BL%7D%28w_%7Bi%2B1%7D%29+%3C+%5Cmathcal%7BL%7D%28w_i%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="\mathcal{L}(w_{i+1}) &lt; \mathcal{L}(w_i)"/>.</p>



<p>Modern machine learning systems are <em>non convex</em>, which means that the final point <img alt="w_t" class="latex" src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" title="w_t"/> we end up in depends on the starting point, the algorithms, and the randomness. Hence, we can’t have a neat “separation of concerns” and decouple the <strong>architecture</strong>, <strong>metric</strong>, and <strong>algorithm</strong>. When we say that a system obeys the “Anna Karenina principle,” we really mean that for <em>natural algorithms</em> to optimize <em>natural metrics</em> on <em>natural architectures</em>, successful outputs (ones that do well on the metric) are likely to be similar to one another. The use of the “natural” qualifier is a warning sign that we don’t fully understand the conditions under which this happens, but it is clear that some conditions are necessary. Due to non-convexity, it is typically possible to find a “bad minima” that would be very good in some specific metric but terrible in other ones.</p>



<h2>Types of theory for machine learning (and for CS in general)</h2>



<p>Given the above discussion, what kind of theoretical results should we expect in machine learning? Let’s try to classify the type of results we see in general theoretical computer science. In the discussion below, I will focus on the <em>limitations</em> of these theoretical results and use humorous names, but make no mistake: all of these categories correspond to valuable theoretical insights.</p>



<h3>End to end analysis</h3>



<p>The <em>quicksort</em> algorithm provides a canonical example of algorithm analysis. At this point, we have a reasonably complete understanding of quicksort. We can analyze the distribution of its running time down to the constant.</p>



<p>Hence we have an efficient algorithm, used in practice, with rigoroulsy proven theorems that precisely characterize its performance. This is the “gold standard” of analysis, but also an unrealistic and unachievable goal in almost any other setting.</p>



<h3>Proof of concept</h3>



<p>A more common situation is that we have algorithms that work in practice and algorithms with rigorous analysis, but they are not the same algorithms. A canonical example is linear programming. The simplex algorithm often works well in practice but was known to take exponential time on certain instances. For a long time, it was an open question whether or not there is an algorithm for linear programming that take polynomial time in the worst case.</p>



<p>In 1979, Khachiyan gave the <em>Ellipsoid</em> algorithm that runs in polynomial time, but with a polynomial so large that it is impractical. Still, the Ellipsoid algorithm was a great breakthrough, giving hope for better algorithms and a new approach for defining progress measures for linear programming instances. Indeed in 1984, Karmarkar came up with the <em>interior points</em> algorithm, with much better time dependence.</p>



<p>The interior-point algorithm is practical and often outperforms the simplex method on large enough instances. However, the algorithm as implemented is not identical to the one analyzed- implementations use different step sizes and other heuristics for which we do not have a precise analysis.</p>



<p>Nevertheless, even if (unlike quicksort) the rigorously analyzed algorithm is not identical to the practical implementations, the story of linear programming shows how crucial “proofs of concept” can be to introducing new ideas and techniques.</p>



<p>The flip side of “proof of concept” results are <em>impossiblity results</em> that rule out even “proof of concept ” algorithms. Impossibility results always come with fine print and caveats (for example, NP-hardness results always refer to <em>worst case</em> complexity). However, they still teach us about the structure of the problem and help define the contours of what we can expect to achieve.</p>



<h2>Character witness</h2>



<p>“End to end analysis” is when we can prove the guarantees we need on algorithms we actually want to use. “Proof of concept” is when we prove the guarantees we need on impractical algorithms. A “character witness” result is when we prove something positive about an algorithm people use in practice, even if that positive property falls short of the guarantees we actually want.</p>



<p>While the term “character witness” sounds derogatory, such results can sometimes yield truly profound insights. A canonical example again comes from linear programming. While the simplex algorithm can be exponential in the worst case, in a seminal work, Spielman and Teng showed that it does run in polynomial-time if the input is slightly perturbed- this is so-called <em>smoothed analysis</em>. While the actual polynomial and the level of perturbation do not yield practical bounds, this is still an important result. It gives formal meaning to the intuition that the simplex only fails on “pathological” instances and initiated a new mode of analyzing algorithms between worst-case and average-case complexity.</p>



<p>In machine learning, a “character witness” result can take many forms. For example, some “character witness” results are analyses of algorithms under certain assumptions on the data, that even if not literally true, seem like they could be “morally true”. Another type of “character witness” result shows that an algorithm would yield the right results if it is allowed to run for an infinite or exponentially long time. Evaluating the significance of such results can be challenging. The main question is whether the analysis teaches us something we didn’t know before.</p>



<p>A third type of “character witness” results are quantitative bounds that are too weak for practical use but are still non-vacuous. For example, approximation algorithms with too big of an approximation factor, or generalization bounds with too big of a guaranteed gap. In such cases, one would hope that these bounds will be at least correlated with performance: algorithms with better bounds will also have higher quality output.</p>



<h2>Toy problems</h2>



<p>The name “toy problem” also sounds derogatory, but toy problems or toy models can be extremely important in science, and machine learning is no different. A toy model is a way to abstract the salient issues of a model to enable analysis. Results on “toy models” can teach us about general principles that hold in more complex models.</p>



<p>When choosing a toy model, it is important not to mistake models that share superficial similarity with models that keep the salient issues we want to study. For example, consider the following two variants of deep neural networks:</p>



<ul><li>Networks that have standard architecture except that we make them extremely wide, with the width tending to infinity independently of all other parameters.</li><li>Networks where all activation functions are linear.</li></ul>



<p>Since the practical intuition is that bigger models are better, it may seem that such “ultra-wide” models are not toy models at all and should capture state of the art deep networks. However, the neural tangent kernel results show that these models become kernel models that do not learn their representation at all.</p>



<p>Intuitively, making activation functions linear seems pointless since the composition of linear functions is linear, and hence such linear networks are no more expressive than a layer one linear net. Thus such linear networks seem too much of a “toy model” (maybe a “happy meal model”?). Yet, it turns out that despite their limited expressivity, deep linear networks capture an essential feature of deep networks- the bias induced by the gradient descent algorithm. For example, running gradient descent on a depth two linear network translate to regularizing by a proxy of <em>rank</em>. In general, gradient descent on a deep linear network induces a very different geometry on the manifold of linear functions.</p>



<p>Hence, although the first model seems much more “real” than the second one, there are some deep learning questions where the second model is more relevant.</p>



<h3>Theory without theorems</h3>



<p>One might think that the whole point of theory is to provide rigorous results: if we are not going to prove theorems, we might as well use benchmarks. Yet, there are important theoretical insights we can get from experiments. A favorite example of mine is the Zhang et al result that deep neural networks can fit random labels. This simple experiment ruled out in one fell swoop a whole direction for proving generalization bounds on deep nets. A theory work does not have to involve theorems: well-chosen experiments can provide important theoretical insights.</p>



<h2>Conclusion</h2>



<p>The above was a stream-of-consciousness and very rough personal overview of questions and results in ML theory. In the <a href="https://boazbk.github.io/mltheoryseminar/">coming seminar</a> we will see results of all the types above, as well as many open questions.</p>



<p><strong>Acknowledgements:</strong> Thanks to Yamini Bansal and Preetum Nakkiran for helpful comments (though they are not to blame for any mistakes!)</p></div>
    </content>
    <updated>2021-01-15T21:41:55Z</updated>
    <published>2021-01-15T21:41:55Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-01-26T03:37:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/01/15/linkage</id>
    <link href="https://11011110.github.io/blog/2021/01/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Rigid heptagon linkage (\(\mathbb{M}\)). Improvements in the size of unit distance graphs whose unit distance representation is forced to contain a regular heptagon, from 59 to 35 edges. Based on a math stackexchange question. See also an old page on the same problem from Erich Friedman’s site, moved from its old location at Stetson University.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://cp4space.hatsya.com/2020/12/31/rigid-heptagon-linkage/">Rigid heptagon linkage</a> (<a href="https://mathstodon.xyz/@11011110/105484618560730198">\(\mathbb{M}\)</a>). Improvements in the size of unit distance graphs whose unit distance representation is forced to contain a regular heptagon, from 59 to 35 edges. Based on <a href="https://math.stackexchange.com/questions/3954719/is-this-braced-heptagon-a-rigid-graph">a math stackexchange question</a>. See also <a href="https://erich-friedman.github.io/mathmagic/0100.html">an old page on the same problem</a> from <a href="https://erich-friedman.github.io/">Erich Friedman’s site</a>, moved from its old location at Stetson University.</p>
  </li>
  <li>
    <p><a href="https://shitpost.plover.com/g/graphviz-usa.html">How Graphviz thinks the USA is laid out</a> (<a href="https://mathstodon.xyz/@11011110/105487958342573170">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=25611053">via</a>).</p>
  </li>
  <li>
    <p><a href="https://carlschwan.eu/2020/12/29/adding-comments-to-your-static-blog-with-mastodon/">Adding comments to your static blog with Mastodon</a> (<a href="https://mathstodon.xyz/@11011110/105496435649985707">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=25570268">via</a>). It’s a cute method for using JavaScript to pull the comments onto the blog page itself, but the method I’ve been using (just add a link from the page to the Mastodon thread and let people follow it from there to Mastodon) seems simpler.</p>
  </li>
  <li>
    <p><a href="https://xkcd.com/2407/">xkcd on depth-first and breadth-first search</a> (<a href="https://mathstodon.xyz/@11011110/105499187435512986">\(\mathbb{M}\)</a>), just in time for my lecture reviewing these algorithms.</p>
  </li>
  <li>
    <p><a href="https://www.alfonsobeato.net/math/the-many-ways-of-splitting-a-rectangle-in-many/">The many ways of splitting a rectangle — or, how to use mathematics to make using Zoom much more complicated for no particular benefit</a> (<a href="https://mathstodon.xyz/@11011110/105507831712183048">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=25633447">via</a>). I am very fond of rectangle partition problems but I don’t want to have to think about them just to talk to multiple people online.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Doubly_triangular_number">Doubly triangular number</a> (<a href="https://mathstodon.xyz/@11011110/105511346991936371">\(\mathbb{M}\)</a>), new Wikipedia article on triangular numbers with a triangular-number index. These numbers come up in counting pairs of pairs of things, for instance in the illustration, which describes colorings of the corners of a square (up to symmetry) as pairs of colorings of pairs of opposite corners.</p>

    <p style="text-align: center;"><img alt="Coloring the corners of a square by combining colorings of pairs of opposite corners" src="https://11011110.github.io/blog/assets/2021/Square_3-colorings.svg"/></p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/some-math-problems-seem-impossible-that-can-be-a-good-thing-20201118/">How assigning impossible-to-solve problems can get mathematics students (or researchers) to take a step back and look at the bigger picture</a> (<a href="https://mathstodon.xyz/@11011110/105518753589309024">\(\mathbb{M}\)</a>). Patrick Honner in <em>Quanta</em>. I think it needs interactivity, though. It would be mean to do this on a problem set or exam.</p>
  </li>
  <li>
    <p><a href="http://www.ams.org/publicoutreach/math-imagery/2020-Exhibition">Mathematical Art Exhibition from the January 2020 Joint Mathematical Meetings</a> (<a href="https://mathstodon.xyz/@11011110/105521691843483164">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=25687129">via</a>).</p>
  </li>
  <li>
    <p>My latest puzzle (a belated Christmas present to myself) is the <a href="https://hanayama-toys.com/product/cast-twist/">Hanayama Twist</a> (<a href="https://mathstodon.xyz/@11011110/105527935339032381">\(\mathbb{M}\)</a>). I’m very pleased with it: an elegant symmetric two-piece design, solid feel in the hand, and a solution that is surprisingly complicated but not tediously long. My only complaint is that the solution is very linear, with almost no ways to go wrong if you keep moving on from things you’ve already done. Anyway <a href="https://11011110.github.io/blog/assets/2021/twist-map.svg">here’s a map I drew to help me</a>, also used as an example of an implicit graph in my graph algorithms lectures.</p>
  </li>
  <li>
    <p>In pre-covid lectures I hand-wrote notes as I talked, both to keep content fresh and to avoid racing through it too quickly. When we locked down I tried pre-recorded lectures with prepared slides, but it took too long to record and I missed the spontaneity. This term I’m back to live zoom lectures with prepared slides, and it seems to work: zoom chat keeps it spontaneous and I haven’t found myself going faster than when we were in person. Lesson learned, just in time to (I hope) unlock in fall. (<a href="https://mathstodon.xyz/@11011110/105540249087507369">\(\mathbb{M}\)</a>; see discussion for Pat Morin’s home whiteboard cat interruption.)</p>
  </li>
  <li>
    <p><a href="https://bookzoompa.wordpress.com/2020/12/17/three-foldings-artful-modern-and-retro/">Two useful folds and a decorative one</a> (<a href="https://mathstodon.xyz/@11011110/105541359073675174">\(\mathbb{M}\)</a>). Paula Beardall Krieg. The useful ones seal a foil snack bag and wrap a sandwich securely in paper, without needing any fasteners.</p>
  </li>
  <li>
    <p><a href="https://xenaproject.wordpress.com/2020/09/19/thoughts-on-the-pythagorean-theorem/">Thoughts on the Pythagorean theorem</a> (<a href="https://mathstodon.xyz/@11011110/105547435011690191">\(\mathbb{M}\)</a>). Or, what did Euclid actually mean by saying that two squares are equal to a third square? And how does this view relate to type-theoretic foundations? From the xena automatic theorem-proving project. Both the name and the horrifying illustrations for the blog posts come from the author’s daughter. For some heavier going, see <a href="https://xenaproject.wordpress.com/2020/06/05/the-sphere-eversion-project/">the post on perfectoid spaces and sphere eversion</a>.</p>
  </li>
  <li>
    <p><a href="http://danbliss.blogspot.com/2011/11/">Regular star patterns for expanded US flags</a> (<a href="https://mathstodon.xyz/@11011110/105552860512312493">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=25772259">via</a>). I suspect that the likelihood of quickly adding Puerto Rico or the District of Columbia as states is not high, but just in case, there are some nice regular point arrangements available.</p>
  </li>
  <li>
    <p>The figure below shows <a href="https://en.wikipedia.org/wiki/Desargues_configuration">two pentagons inscribed in each other</a>: each vertex of one pentagon lies on a line through a side of the other pentagon (<a href="https://mathstodon.xyz/@11011110/105555337730874472">\(\mathbb{M}\)</a>). You can’t do this with quadrilaterals in the Euclidean plane, but <a href="https://en.wikipedia.org/wiki/M%C3%B6bius%E2%80%93Kantor_configuration">you can in the complex projective plane</a>. From <a href="https://mathstodon.xyz/@christianp/105553391372028649">a thread of fun math facts</a> for Christian Lawson-Perfect’s birthday.</p>

    <p style="text-align: center;"><img alt="Two mutually-inscribed pentagons" src="https://11011110.github.io/blog/assets/2021/Mutually-inscribed-pentagons.svg"/></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2101.04698">New preprint claims a proof of the Erdős-Faber-Lovász conjecture for all sufficiently large \(k\)</a> (<a href="https://mathstodon.xyz/@11011110/105561900948206748">\(\mathbb{M}\)</a>, <a href="https://gilkalai.wordpress.com/2021/01/14/to-cheer-you-up-in-difficult-times-17-amazing-the-erdos-faber-lovasz-conjecture-for-large-n-was-proved-by-dong-yeap-kang-tom-kelly-daniela-kuhn-abhishek-methuku-and-deryk-osthus/">via</a>), by Dong Yeap Kang, Tom Kelly, Daniela Kühn, Abhishek Methuku, and Deryk Osthus. The conjecture states that the union of \(k\) edge-disjoint \(k\)-cliques is \(k\)-colorable. See <a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Faber%E2%80%93Lov%C3%A1sz_conjecture">its Wikipedia article</a> for a real-world-ish formulation with faculty committees as cliques and chairs in a common meeting room as colors.</p>
  </li>
</ul></div>
    </content>
    <updated>2021-01-15T18:18:00Z</updated>
    <published>2021-01-15T18:18:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-01-23T08:03:40Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-25562705.post-8763851996229403535</id>
    <link href="http://aaronsadventures.blogspot.com/feeds/8763851996229403535/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=25562705&amp;postID=8763851996229403535" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/8763851996229403535" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/8763851996229403535" rel="self" type="application/atom+xml"/>
    <link href="http://aaronsadventures.blogspot.com/2021/01/how-to-estimate-uncertainty-of.html" rel="alternate" type="text/html"/>
    <title>How to Estimate the Uncertainty of Predictions</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><!--wp:paragraph {"align":"center"}--><p class="has-text-align-center" style="text-align: center;"><i>This is a post about a new paper <a href="https://arxiv.org/abs/2101.01739">Online Multivalid Learning: Means, Moments, and Prediction Intervals</a>, that is joint work with Varun Gupta, Christopher Jung, Georgy Noarov, and Mallesh Pai. It is <a href="https://toc4fairness.org/how-to-estimate-the-uncertainty-of-predictions">cross-posted to the new TOC4Fairness blog</a>. </i></p><!--/wp:paragraph--> <!--wp:paragraph--><p>Suppose you go and train the latest, greatest machine learning architecture to predict something important. Say (to pick an example entirely out of thin air) you are in the midst of a pandemic, and want to predict the severity of patients' symptoms in 2 days time, so as to triage scarce medical resources. Since you will be using these predictions to make decisions, you would like them to be accurate in various ways: for example, at the very least, you will want your predictions to be calibrated, and you may also want to be able to accurately quantify the uncertainty of your predictions (say with 95% prediction intervals). It is a fast moving situation, and data is coming in dynamically --- and you need to make decisions as you go. What can you do? </p><!--/wp:paragraph--> <!--wp:paragraph--><p>The first thing you might do is <a href="https://twitter.com/Aaroth/status/1272545845603434497">ask on twitter</a>! What you will find is that the standard tool for quantifying uncertainty in settings like this is <a href="https://jmlr.csail.mit.edu/papers/volume9/shafer08a/shafer08a.pdf">conformal prediction</a>. The conformal prediction literature has a number of elegant techniques for endowing arbitrary point prediction methods with <em>marginal prediction intervals</em>: i.e intervals $(\ell(x), u(x))$ such that over the randomness of some data distribution over labelled examples $(x,y)$: $\Pr_{(x,y)}\left[y \in [\ell(x), u(x)]\right] \approx 0.95$ These would be 95% marginal prediction intervals --- but in general you could pick your favorite coverage probability $1-\delta$.  </p><!--/wp:paragraph--> <!--wp:paragraph--><p>Conformal prediction has a lot going for it --- its tools are very general and flexible, and lead to practical algorithms. But it also has two well known shortcomings:</p><!--/wp:paragraph--> <!--wp:list {"ordered":true}--><ol><li><strong>Strong Assumptions</strong>. Like many tools from statistics and machine learning, conformal prediction methods require that the future look like the past. In particular, they require that the data be drawn i.i.d. from some distribution --- or at least be <em>exchangable</em> (i.e. their distribution should be invariant to permutation). This is sometimes the case --- but it often is not. In our pandemic scenario, the distribution on patient features might quickly change in unexpected ways as the disease moves between different populations, as might the relationship between features and outcomes, as treatments advance. In other settings in which consequential decisions are being made about people --- like lending and hiring decisions --- people might intentionally manipulate their features in response to the predictive algorithms you deploy, in an attempt to get the outcome they want. Or you might be trying to predict outcomes in time series data, in which there are explicit dependencies across time. In all of these scenarios, exchangeability is violated.</li><li><strong>Weak Guarantees</strong>. Marginal coverage guarantees are <em>averages over people</em>. 95% marginal coverage means that the true label falls within the predicted interval for 95% of people. It need not mean anything for <em>people like you</em>. For example, if you are part of a demographic group that makes up less than 5% of the population, it is entirely consistent with the guarantees of a 95% marginal prediction interval that labels for people from your demographic group fall outside of their intervals 100% of the time. This can be both an accuracy and a <strong><em>fairness</em> </strong>concern --- marginal prediction works well for "typical" members of a population, but not necessarily for everyone else. </li></ol><!--/wp:list--> <!--wp:paragraph--><p>What kinds of improvements might we hope for? Lets start with how to strengthen the guarantee:</p><!--/wp:paragraph--> <!--wp:paragraph--><p><strong>Multivalidity</strong> Ideally, we would want <em>conditional</em> guarantees --- i.e. the promise that for every $x$, that we would have $\Pr_{y}\left[y \in [\ell(x), u(x)] | x \right] \approx 0.95$. In other words, that somehow for each individual, the prediction interval was valid for them specifically, over the "unrealized" (or unmeasured) randomness of the world. Of course this is too much to hope for. In a rich feature space, we have likely never seen anyone exactly like you before (i.e. with your feature vector $x$). So strictly speaking, we have no information at all about your conditional label distribution. We still have to average over people. But we don't have to average over everybody. An important idea that has been investigated in <a href="https://arxiv.org/abs/1711.08513">several </a><a href="https://arxiv.org/abs/1711.05144">different </a><a href="https://arxiv.org/abs/1805.12317">contexts </a>in recent years in the theory literature on fairness is that we might articulate a very rich collection of (generally intersecting) demographic groups $G$ corresponding to relevant subsets of the data domain, and ask for things that we care about to hold true as averaged over any group $S \in G$ in the collection. In the case of prediction intervals, this would correspond to asking for something like that simultaneously for every demographic group $S \in G$, $\Pr_{(x,y)}\left[y \in [\ell(x), u(x)] | x \in S \right] \approx 0.95$. Note here that an individual might be a member of many different demographic groups, and can interpret the guarantees of their prediction interval as averages over any of those demographic groups, at their option. This is what we can achieve --- at least for any such group that isn't too small.  </p><!--/wp:paragraph--> <!--wp:paragraph--><p>And what kinds of assumptions do we need?</p><!--/wp:paragraph--> <!--wp:paragraph--><p><strong>Adversarial Data </strong>Actually, its not clear that we need any! Many learning problems which initially appear to require distributional assumptions turn out to be solvable even in the worst case over data sequences --- i.e. even if a clever adversary, with full knowledge of your algorithm, and with the intent only to sabotage your learning guarantees, is allowed to adaptively choose data to present to your algorithm. This is the case for <a href="https://academic.oup.com/biomet/article-abstract/85/2/379/298827">calibrated weather prediction</a>, as well as <a href="http://proceedings.mlr.press/v48/syrgkanis16.pdf">general contextual prediction</a>. It turns out to be the case for us as well. Instead of promising coverage probabilities of $1-\delta + O(1/T)$ after $T$ rounds <em>on the underlying distribution</em>, as<a href="https://www.stat.cmu.edu/~ryantibs/papers/conformal.pdf"> conformal prediction is able to</a>, (for us there is no underlying distribution) we offer <em>empirical</em> coverage rates of $1-\delta \pm O(1/\sqrt{T})$. This kind of guarantee is quite similar to what<a href="https://www.stat.cmu.edu/~ryantibs/papers/conformal.pdf"> conformal prediction guarantees about empirical coverage</a>. </p><!--/wp:paragraph--> <!--wp:paragraph--><p><strong>More Generally </strong>Our techniques are not specific to prediction intervals. We can do the same thing for predicting label means, and predicting variances of the residuals of arbitrary prediction methods. For mean prediction, this corresponds to an algorithm for providing <a href="https://arxiv.org/abs/1711.08513">multi-calibrated predictions in the sense of Hebert-Johnson et al</a>, in an online adversarial environment. For variances and other higher moments, it corresponds to an online algorithm for making <a href="https://arxiv.org/abs/2008.08037">mean-conditioned moment multicalibrated predictions in the sense of Jung et al</a>.</p><!--/wp:paragraph--> <!--wp:paragraph--><p><strong>Techniques</strong> At the risk of boring my one stubbornly remaining reader, let me say a few words about how we do it. We generalize an idea that dates back to an argument that<a href="https://dash.harvard.edu/bitstream/handle/1/3203773/fudenberg_calibrate.pdf"> Fudenberg and Levine first made in 1995</a> --- and is closely related to <a href="http://www.ma.huji.ac.il/hart/papers/calib-minmax.pdf">an earlier, beautiful argument by Sergiu Hart</a> --- but that I just learned about this summer, and thought was just amazing. It applies broadly to solving any prediction task that would be easy, if only you were facing a known data distribution. This is the case for us. If, for each arriving patient at our hospital, a wizard <em>told us</em> their "true" distribution over outcome severity, we could easily make calibrated predictions by always predicting the mean of this distribution --- and we could similarly read off correct 95% coverage intervals from the CDF of the distribution. So what? That's not the situation we are in, of course. Absent a wizard, we first need to commit to some learning algorithm, and only then will the adversary decide what data to show us. </p><!--/wp:paragraph--> <!--wp:paragraph--><p>But lets put our game theory hats on. Suppose we've been making predictions for awhile. We can write down some measure of our error so far --- say the maximum, over all demographic groups in $G$, of the deviation of our empirical coverage so far from our 95% coverage target.  For the next round, define a zero sum game, in which we (the learner) want to minimize the <em>increase</em> in this measure of error, and the adversary wants to maximize it. The defining feature of zero-sum games is that how well you can do in them is independent of which player has to announce their distribution on play first --- this is the celebrated <a href="https://en.wikipedia.org/wiki/Minimax_theorem">Minimax Theorem</a>. So to evaluate how well the learner could do in this game, we can think about the situation involving a Wizard above, in which for each arriving person, before we have to make a prediction for them, we get to observe their true label distribution. Of course in this scenario we can do well, because for all of our goals, our measure of success is based on how well our predictions match observed properties of these distributions. The Minimax theorem tells us that (at least in principle --- it doesn't give us the algorithm), there must therefore also be a learning algorithm that can do just as well, but against an adversary. </p><!--/wp:paragraph--> <!--wp:paragraph--><p>The minimax argument is slick, but non-constructive. To actually pin down a concrete algorithm, we need to solve for the equilibrium in the corresponding game. That's what we spend much of the paper doing, for each of the prediction tasks that we study. For multicalibration, we get a simple, elementary algorithm --- but for the prediction interval problem, although we get a polynomial time algorithm, it involves solving a linear program with a separation oracle at each round. Finding more efficient and practical ways to do this strikes me as an important problem. </p><!--/wp:paragraph--> <!--wp:paragraph--><p>Finally, I had more fun writing this paper --- learning about old techniques from the game theoretic calibration literature --- than I've had in awhile. I hope a few people enjoy reading it!</p><!--/wp:paragraph--><p> </p></div>
    </content>
    <updated>2021-01-15T14:01:00Z</updated>
    <published>2021-01-15T14:01:00Z</published>
    <author>
      <name>Aaron</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/09952936358739421126</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-25562705</id>
      <category term="game theory"/>
      <category term="news"/>
      <author>
        <name>Aaron</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/09952936358739421126</uri>
      </author>
      <link href="http://aaronsadventures.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://aaronsadventures.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <title>Adventures in Computation</title>
      <updated>2021-01-19T11:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1242</id>
    <link href="https://toc4fairness.org/how-to-estimate-the-uncertainty-of-predictions/" rel="alternate" type="text/html"/>
    <title>How to Estimate the Uncertainty of Predictions</title>
    <summary>This is a post about a new paper Online Multivalid Learning: Means, Moments, and Prediction Intervals, that is joint work with Varun Gupta, Christopher Jung, Georgy Noarov, and Mallesh Pai. ...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="has-text-align-center">This is a post about a new paper <em><a href="https://arxiv.org/abs/2101.01739">Online Multivalid Learning: Means, Moments, and Prediction Intervals</a></em>, that is joint work with Varun Gupta, Christopher Jung, Georgy Noarov, and Mallesh Pai.  </p>



<p>Suppose you go and train the latest, greatest machine learning architecture to predict something important. Say (to pick an example entirely out of thin air) you are in the midst of a pandemic, and want to predict the severity of patients’ symptoms in 2 days time, so as to triage scarce medical resources. Since you will be using these predictions to make decisions, you would like them to be accurate in various ways: for example, at the very least, you will want your predictions to be calibrated, and you may also want to be able to accurately quantify the uncertainty of your predictions (say with 95% prediction intervals). It is a fast moving situation, and data is coming in dynamically — and you need to make decisions as you go. What can you do? </p>



<p>The first thing you might do is <a href="https://twitter.com/Aaroth/status/1272545845603434497">ask on twitter</a>! What you will find is that the standard tool for quantifying uncertainty in settings like this is <a href="https://jmlr.csail.mit.edu/papers/volume9/shafer08a/shafer08a.pdf">conformal prediction</a>. The conformal prediction literature has a number of elegant techniques for endowing arbitrary point prediction methods with <em>marginal prediction intervals</em>: i.e intervals <img alt="(\ell(x), u(x))" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cell%28x%29%2C+u%28x%29%29&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="(\ell(x), u(x))"/> such that over the randomness of some data distribution over labelled examples <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="(x,y)"/>: <img alt="\Pr_{(x,y)}\left[y \in [\ell(x), u(x)]\right] \approx 0.95" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr_%7B%28x%2Cy%29%7D%5Cleft%5By+%5Cin+%5B%5Cell%28x%29%2C+u%28x%29%5D%5Cright%5D+%5Capprox+0.95&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="\Pr_{(x,y)}\left[y \in [\ell(x), u(x)]\right] \approx 0.95"/> These would be 95% marginal prediction intervals — but in general you could pick your favorite coverage probability <img alt="1-\delta" class="latex" src="https://s0.wp.com/latex.php?latex=1-%5Cdelta&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="1-\delta"/>.  </p>



<p>Conformal prediction has a lot going for it — its tools are very general and flexible, and lead to practical algorithms. But it also has two well known shortcomings:</p>



<ol><li><strong>Strong Assumptions</strong>. Like many tools from statistics and machine learning, conformal prediction methods require that the future look like the past. In particular, they require that the data be drawn i.i.d. from some distribution — or at least be <em>exchangable</em> (i.e. their distribution should be invariant to permutation). This is sometimes the case — but it often is not. In our pandemic scenario, the distribution on patient features might quickly change in unexpected ways as the disease moves between different populations, as might the relationship between features and outcomes, as treatments advance. In other settings in which consequential decisions are being made about people — like lending and hiring decisions — people might intentionally manipulate their features in response to the predictive algorithms you deploy, in an attempt to get the outcome they want. Or you might be trying to predict outcomes in time series data, in which there are explicit dependencies across time. In all of these scenarios, exchangeability is violated.</li><li><strong>Weak Guarantees</strong>. Marginal coverage guarantees are <em>averages over people</em>. 95% marginal coverage means that the true label falls within the predicted interval for 95% of people. It need not mean anything for <em>people like you</em>. For example, if you are part of a demographic group that makes up less than 5% of the population, it is entirely consistent with the guarantees of a 95% marginal prediction interval that labels for people from your demographic group fall outside of their intervals 100% of the time. This can be both an accuracy and a <strong><em>fairness</em> </strong>concern — marginal prediction works well for “typical” members of a population, but not necessarily for everyone else. </li></ol>



<p>What kinds of improvements might we hope for? Lets start with how to strengthen the guarantee:</p>



<p><strong>Multivalidity</strong> Ideally, we would want <em>conditional</em> guarantees — i.e. the promise that for every <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="x"/>, that we would have <img alt="\Pr_{y}\left[y \in [\ell(x), u(x)] | x \right] \approx 0.95" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr_%7By%7D%5Cleft%5By+%5Cin+%5B%5Cell%28x%29%2C+u%28x%29%5D+%7C+x+%5Cright%5D+%5Capprox+0.95&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="\Pr_{y}\left[y \in [\ell(x), u(x)] | x \right] \approx 0.95"/>. In other words, that somehow for each individual, the prediction interval was valid for them specifically, over the “unrealized” (or unmeasured) randomness of the world. Of course this is too much to hope for. In a rich feature space, we have likely never seen anyone exactly like you before (i.e. with your feature vector <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="x"/>). So strictly speaking, we have no information at all about your conditional label distribution. We still have to average over people. But we don’t have to average over everybody. An important idea that has been investigated in <a href="https://arxiv.org/abs/1711.08513">several </a><a href="https://arxiv.org/abs/1711.05144">different </a><a href="https://arxiv.org/abs/1805.12317">contexts </a>in recent years in the theory literature on fairness is that we might articulate a very rich collection of (generally intersecting) demographic groups <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="G"/> corresponding to relevant subsets of the data domain, and ask for things that we care about to hold true as averaged over any group <img alt="S \in G" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Cin+G&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="S \in G"/> in the collection. In the case of prediction intervals, this would correspond to asking for something like that simultaneously for every demographic group <img alt="S \in G" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Cin+G&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="S \in G"/>, <img alt="\Pr_{(x,y)}\left[y \in [\ell(x), u(x)] | x \in S \right] \approx 0.95" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr_%7B%28x%2Cy%29%7D%5Cleft%5By+%5Cin+%5B%5Cell%28x%29%2C+u%28x%29%5D+%7C+x+%5Cin+S+%5Cright%5D+%5Capprox+0.95&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="\Pr_{(x,y)}\left[y \in [\ell(x), u(x)] | x \in S \right] \approx 0.95"/>. Note here that an individual might be a member of many different demographic groups, and can interpret the guarantees of their prediction interval as averages over any of those demographic groups, at their option. This is what we can achieve — at least for any such group that isn’t too small. </p>



<p>And what kinds of assumptions do we need?</p>



<p><strong>Adversarial Data </strong>Actually, its not clear that we need any! Many learning problems which initially appear to require distributional assumptions turn out to be solvable even in the worst case over data sequences — i.e. even if a clever adversary, with full knowledge of your algorithm, and with the intent only to sabotage your learning guarantees, is allowed to adaptively choose data to present to your algorithm. This is the case for <a href="https://academic.oup.com/biomet/article-abstract/85/2/379/298827">calibrated weather prediction</a>, as well as <a href="http://proceedings.mlr.press/v48/syrgkanis16.pdf">general contextual prediction</a>. It turns out to be the case for us as well. Instead of promising coverage probabilities of <img alt="1-\delta + O(1/T)" class="latex" src="https://s0.wp.com/latex.php?latex=1-%5Cdelta+%2B+O%281%2FT%29&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="1-\delta + O(1/T)"/> after <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="T"/> rounds <em>on the underlying distribution</em>, as<a href="https://www.stat.cmu.edu/~ryantibs/papers/conformal.pdf"> conformal prediction is able to</a>, we offer <em>empirical</em> coverage rates of <img alt="1-\delta \pm O(1/\sqrt{T})" class="latex" src="https://s0.wp.com/latex.php?latex=1-%5Cdelta+%5Cpm+O%281%2F%5Csqrt%7BT%7D%29&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="1-\delta \pm O(1/\sqrt{T})"/> (since for us there is no underlying distribution). This kind of guarantee is quite similar to what<a href="https://www.stat.cmu.edu/~ryantibs/papers/conformal.pdf"> conformal prediction guarantees about empirical coverage</a>. </p>



<p><strong>More Generally </strong>Our techniques are not specific to prediction intervals. We can do the same thing for many other distributional quantities. We work this out in the case of predicting label means, and predicting variances of the residuals of arbitrary prediction methods. For mean prediction, this corresponds to an algorithm for providing <a href="https://arxiv.org/abs/1711.08513">multi-calibrated predictions in the sense of Hebert-Johnson et al</a>, in an online adversarial environment. For variances and other higher moments, it corresponds to an online algorithm for making <a href="https://arxiv.org/abs/2008.08037">mean-conditioned moment multicalibrated predictions in the sense of Jung et al</a>.</p>



<p><strong>Techniques</strong> At the risk of boring my one stubbornly remaining reader, let me say a few words about how we do it. We generalize an idea that dates back to an argument that<a href="https://dash.harvard.edu/bitstream/handle/1/3203773/fudenberg_calibrate.pdf"> Fudenberg and Levine first made in 1995</a> — and is closely related to <a href="http://www.ma.huji.ac.il/hart/papers/calib-minmax.pdf">an earlier, beautiful argument by Sergiu Hart</a> — but that I just learned about this summer, and thought was just amazing. It applies broadly to solving any prediction task that would be easy, if only you were facing a known data distribution. This is the case for us. If, for each arriving patient at our hospital, a wizard <em>told us</em> their “true” distribution over outcome severity, we could easily make calibrated predictions by always predicting the mean of this distribution — and we could similarly read off correct 95% coverage intervals from the CDF of the distribution. So what? That’s not the situation we are in, of course. Absent a wizard, we first need to commit to some learning algorithm, and only then will the adversary decide what data to show us. </p>



<p>But lets put our game theory hats on. Suppose we’ve been making predictions for awhile. We can write down some measure of our error so far — say the maximum, over all demographic groups in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" title="G"/>, of the deviation of our empirical coverage so far from our 95% coverage target.  For the next round, define a zero sum game, in which we (the learner) want to minimize the <em>increase</em> in this measure of error, and the adversary wants to maximize it. The defining feature of zero-sum games is that how well you can do in them is independent of which player has to announce their distribution on play first — this is the celebrated <a href="https://en.wikipedia.org/wiki/Minimax_theorem">Minimax Theorem</a>. So to evaluate how well the learner could do in this game, we can think about the situation involving a Wizard above, in which for each arriving person, before we have to make a prediction for them, we get to observe their true label distribution. Of course in this scenario we can do well, because for all of our goals, our measure of success is based on how well our predictions match observed properties of these distributions. The Minimax theorem tells us that (at least in principle — it doesn’t give us the algorithm), there must therefore also be a learning algorithm that can do just as well, but against an adversary. </p>



<p>The minimax argument is slick, but non-constructive. To actually pin down a concrete algorithm, we need to solve for the equilibrium in the corresponding game. That’s what we spend much of the paper doing, for each of the prediction tasks that we study. For multicalibration, we get a simple, elementary algorithm — but for the prediction interval problem, although we get a polynomial time algorithm, it involves solving a linear program with a separation oracle at each round. Finding more efficient and practical ways to do this strikes me as an important problem. </p>



<p>Finally, I had more fun writing this paper — learning about old techniques from the game theoretic calibration literature — than I’ve had in awhile. I hope a few people enjoy reading it!</p>



<p/>



<p/></div>
    </content>
    <updated>2021-01-15T14:00:00Z</updated>
    <published>2021-01-15T14:00:00Z</published>
    <category term="Blog"/>
    <category term="multicalibration"/>
    <category term="papers"/>
    <category term="subgroup fairness"/>
    <category term="uncertainty"/>
    <author>
      <name>Aaron Roth</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-01-26T03:38:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/01/14/assistant-professor-at-university-of-toronto-toronto-canada-apply-by-january-28-2021/</id>
    <link href="https://cstheory-jobs.org/2021/01/14/assistant-professor-at-university-of-toronto-toronto-canada-apply-by-january-28-2021/" rel="alternate" type="text/html"/>
    <title>Assistant Professor at University of Toronto, Toronto, Canada (apply by January 28, 2021)</title>
    <summary>The Department of Computer Science at the University of Toronto invites applications for up to two full-time tenure stream positions in the areas of Security and Cryptography. The appointments will be at the rank of Assistant Professor and will commence on July 1, 2021, or shortly thereafter. Website: https://jobs.utoronto.ca/job/Toronto-Assistant-Professor-Security-and-Cryptography-ON/543569117/ Email: recruit@cs.toronto.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at the University of Toronto invites applications for up to two full-time tenure stream positions in the areas of Security and Cryptography. The appointments will be at the rank of Assistant Professor and will commence on July 1, 2021, or shortly thereafter.</p>
<p>Website: <a href="https://jobs.utoronto.ca/job/Toronto-Assistant-Professor-Security-and-Cryptography-ON/543569117/">https://jobs.utoronto.ca/job/Toronto-Assistant-Professor-Security-and-Cryptography-ON/543569117/</a><br/>
Email: recruit@cs.toronto.edu</p></div>
    </content>
    <updated>2021-01-14T22:40:03Z</updated>
    <published>2021-01-14T22:40:03Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-01-26T03:37:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/01/14/faculty-position-in-algorithms-and-complexity-at-university-of-edinburgh-apply-by-february-21-2021/</id>
    <link href="https://cstheory-jobs.org/2021/01/14/faculty-position-in-algorithms-and-complexity-at-university-of-edinburgh-apply-by-february-21-2021/" rel="alternate" type="text/html"/>
    <title>Faculty position in Algorithms and Complexity at University of Edinburgh (apply by February 21, 2021)</title>
    <summary>The School of Informatics at the University of Edinburgh invites applicants for Lecturer (“Assistant Professor”), and Reader (“Associate Professor”) in Algorithms and Complexity. For a full advert for the post, and how to apply, please see the link below. Website: https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/295 Email: kousha@inf.ed.ac.uk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The School of Informatics at the University of Edinburgh invites applicants for Lecturer (“Assistant Professor”), and Reader (“Associate Professor”) in Algorithms and Complexity.</p>
<p>For a full advert for the post, and how to apply, please see the link below.</p>
<p>Website: <a href="https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/295">https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/295</a><br/>
Email: kousha@inf.ed.ac.uk</p></div>
    </content>
    <updated>2021-01-14T18:21:26Z</updated>
    <published>2021-01-14T18:21:26Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-01-26T03:37:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17987</id>
    <link href="https://rjlipton.wordpress.com/2021/01/14/priming-random-restrictions/" rel="alternate" type="text/html"/>
    <title>Priming Random Restrictions</title>
    <summary>Can we expand the base of their use? Technion commemoration src Bella Subbotovskaya was doing Boolean complexity lower bounds in 1961. She originated the method of restrictions of Boolean functions and proved that the formula size of the parity function of variables is at least . The parity bound was improved to quadratic in 1971 […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Can we expand the base of their use?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2021/01/bella.png"><img alt="" class="alignright wp-image-17989" height="231" src="https://rjlipton.files.wordpress.com/2021/01/bella.png?w=135&amp;h=231" width="135"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Technion commemoration <a href="https://history.math.technion.ac.il/sites/CMS/archive/year_2006-2007/different-approaches/">src</a></font></td>
</tr>
</tbody>
</table>
<p>
Bella Subbotovskaya was doing Boolean complexity lower bounds in 1961. She <a href="https://en.wikipedia.org/wiki/Bella_Subbotovskaya">originated</a> the method of <em>restrictions</em> of Boolean functions and proved that the formula size of the parity function of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n}"/> variables is at least <img alt="{n^{3/2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B3%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n^{3/2}}"/>. The parity bound was improved to quadratic in 1971 by Valeriy Khrapchenko, who passed away only last year and was the only child of the Soviet literature and arts leader Mikhail Khrapchenko. Then Johan Håstad <a href="https://www.csc.kth.se/~johanh/shrinkgeneral.pdf">strengthened</a> the whole method to quadratic.</p>
<p>
Today we discuss not possible further sharpenings but rather how to extend the ways of applying it.</p>
<p>
Subbotovskaya was most unfortunately killed in a mysterious manner in 1982. George Szpiro in 2007 wrote an <a href="http://www.ams.org/notices/200710/tx071001326p.pdf">article</a> reviewing the circumstances amid her questioning by the KGB for co-founding and hosting the “Jewish People’s University” amid rampant anti-Semitism in Soviet academies. She was also a talented violist and vocalist and investigated computer-assisted musical composition and analysis. See also her MacTutor <a href="https://mathshistory.st-andrews.ac.uk/Biographies/Subbotovskaya/">biography</a>.</p>
<p>
As presented by Stasys Jukna in his 2012 <a href="http://www.thi.cs.uni-frankfurt.de/~jukna/boolean/BFC-draft.pdf">book</a> <em>Boolean Function Complexity</em>, Subbotovskaya gave an algorithm for optimizing the trimming of a formula over the <img alt="{\wedge,\vee,\neg}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwedge%2C%5Cvee%2C%5Cneg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\wedge,\vee,\neg}"/> basis at its leaves by substituting for <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{m}"/> of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n}"/> variables, one at a time. She used an averaging argument that readily extends to give the same-order bounds on random restrictions. Random restrictions have other advantages that have led to wonderful work besides those above, including the recent <a href="https://eccc.weizmann.ac.il/report/2018/107/">oracle separation</a> of <img alt="{\mathsf{BQP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BBQP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{BQP}}"/> from the polynomial hierarchy. We want to discuss targeting the restrictions toward possible particular sensitivities of the Boolean functions computed by the formulas.</p>
<p>
</p><p/><h2> The Method </h2><p/>
<p/><p>
Subbotovskaya’s argument considers every <img alt="{\wedge}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwedge%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\wedge}"/> or <img alt="{\vee}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvee%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\vee}"/> gate <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{g}"/>, in a minimal formula <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\phi}"/> computing the function <img alt="{f(x_1,\dots,x_n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x_1%2C%5Cdots%2Cx_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{f(x_1,\dots,x_n)}"/>, that has <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_i}"/> or <img alt="{\bar{x}_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7Bx%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bar{x}_i}"/> as an input, for some <img alt="{i = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{i = 1}"/> to <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n}"/>. Note that because <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\phi}"/> is a formula, one of the two possible assignments <img alt="{a_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{a_i}"/> to <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_i}"/> renders the other input <img alt="{T_{g,i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7Bg%2Ci%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{T_{g,i}}"/> to <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{g}"/> immaterial. If <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\phi}"/> has <img alt="{s_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{s_n}"/> leaves, then we can not only choose <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{i}"/> so that <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_i}"/> or <img alt="{\bar{x}_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7Bx%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bar{x}_i}"/> occurs at least <img alt="{\frac{s_n}{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bs_n%7D%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\frac{s_n}{n}}"/> times, we can set it to wipe out at least half of the subtrees <img alt="{T_{g,i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7Bg%2Ci%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{T_{g,i}}"/>. </p>
<p>
The final note is that doing so does not double-cancel any variable: if <img alt="{T_{g_i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7Bg_i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{T_{g_i}}"/> contains <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_i}"/> or <img alt="{\bar{x}_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7Bx%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bar{x}_i}"/>, then assigning <img alt="{1 - a_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+-+a_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{1 - a_i}"/> to that occurrence leaves the function computed by <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{g}"/> unchanged—but that contradicts the minimality of <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\phi}"/>. Hence no subformula <img alt="{T_{g,i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7Bg%2Ci%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{T_{g,i}}"/> contains <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_i}"/> or <img alt="{\bar{x}_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7Bx%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\bar{x}_i}"/>. The upshot is that we can set <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_i}"/> so that the resulting formula <img alt="{\phi'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\phi'}"/> in <img alt="{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n-1}"/> variables has <img alt="{s_{n-1} \leq s_n - \frac{3s_n}{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs_%7Bn-1%7D+%5Cleq+s_n+-+%5Cfrac%7B3s_n%7D%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{s_{n-1} \leq s_n - \frac{3s_n}{2n}}"/> leaves. It is convenient to weaken this inequality by </p>
<p align="center"><img alt="\displaystyle  s_{n-1} \leq s_n\left(1 - \frac{3}{2}\frac{1}{n}\right) \leq s_n\left(1 - \frac{1}{n}\right)^{3/2}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s_%7Bn-1%7D+%5Cleq+s_n%5Cleft%281+-+%5Cfrac%7B3%7D%7B2%7D%5Cfrac%7B1%7D%7Bn%7D%5Cright%29+%5Cleq+s_n%5Cleft%281+-+%5Cfrac%7B1%7D%7Bn%7D%5Cright%29%5E%7B3%2F2%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  s_{n-1} \leq s_n\left(1 - \frac{3}{2}\frac{1}{n}\right) \leq s_n\left(1 - \frac{1}{n}\right)^{3/2}, "/></p>
<p>so that by iterating we can exploit the identity that for any <img alt="{k \leq n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%5Cleq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{k \leq n}"/>, </p>
<p align="center"><img alt="\displaystyle  \left(1 - \frac{1}{n}\right)\left(1 - \frac{1}{n-1}\right)\cdots\left(1 - \frac{1}{k+1}\right) = \frac{k}{n}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%281+-+%5Cfrac%7B1%7D%7Bn%7D%5Cright%29%5Cleft%281+-+%5Cfrac%7B1%7D%7Bn-1%7D%5Cright%29%5Ccdots%5Cleft%281+-+%5Cfrac%7B1%7D%7Bk%2B1%7D%5Cright%29+%3D+%5Cfrac%7Bk%7D%7Bn%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  \left(1 - \frac{1}{n}\right)\left(1 - \frac{1}{n-1}\right)\cdots\left(1 - \frac{1}{k+1}\right) = \frac{k}{n}. "/></p>
<p>The upshot is that for any <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{m}"/>, we can set <img alt="{n-m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n-m}"/> variables so that the size <img alt="{s_{m}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs_%7Bm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{s_{m}}"/> of the resulting formula in <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{m}"/> variables obeys the bound </p>
<p align="center"><img alt="\displaystyle  s_{m} \leq s_n\left(\frac{m}{n}\right)^{3/2},\qquad\text{so}\qquad s_n \geq s_{m}\left(\frac{n}{m}\right)^{3/2}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s_%7Bm%7D+%5Cleq+s_n%5Cleft%28%5Cfrac%7Bm%7D%7Bn%7D%5Cright%29%5E%7B3%2F2%7D%2C%5Cqquad%5Ctext%7Bso%7D%5Cqquad+s_n+%5Cgeq+s_%7Bm%7D%5Cleft%28%5Cfrac%7Bn%7D%7Bm%7D%5Cright%29%5E%7B3%2F2%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  s_{m} \leq s_n\left(\frac{m}{n}\right)^{3/2},\qquad\text{so}\qquad s_n \geq s_{m}\left(\frac{n}{m}\right)^{3/2}. "/></p>
<p>Because the parity function is such that any way of setting <img alt="{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n-1}"/> variables leaves the formula needing (at least) one read of the remaining variable, we can carry this all the way down to <img alt="{m=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{m=1}"/> to deduce <img alt="{s_n \geq n^{3/2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs_n+%5Cgeq+n%5E%7B3%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{s_n \geq n^{3/2}}"/>. Note: this is concrete, not asymptotic. </p>
<p>
Via induction on gates <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{g}"/> deeper than those at the leaves, and techniques that adapt to how closely the two subtrees of <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{g}"/> are balanced, Håstad increased the exponent from <img alt="{3/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{3/2}"/> to <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{2}"/> in all cases, on pain of carrying some lower-order terms that make the bounds asymptotic. His lemmas rely more on the restrictions being random, including one that estimates the probability that the restriction already leaves a formula dependent on only one variable. </p>
<p>
</p><p/><h2> An Intuitive Framing </h2><p/>
<p/><p>
For sake of exposition we wave away the lower-order terms and write <img alt="{\gtrdot}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgtrdot%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\gtrdot}"/> for the numerical inequalities. We frame the restrictions with notation that can help us target subsets <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{I}"/> of variables to restrict, outside of which <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{f}"/> remains sensitive.</p>
<blockquote><p><b>Definition 1</b> <em> Let <img alt="{f : \{0,1\}^n \rightarrow \{0,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%3A+%5C%7B0%2C1%5C%7D%5En+%5Crightarrow+%5C%7B0%2C1%5C%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{f : \{0,1\}^n \rightarrow \{0,1\}}"/> be a Boolean function. We say that 	</em></p><em>
<p align="center"><img alt="\displaystyle  \textsf{free}(f,I,\alpha) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctextsf%7Bfree%7D%28f%2CI%2C%5Calpha%29+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  \textsf{free}(f,I,\alpha) "/></p>
<p>holds provided <img alt="{I \subset [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI+%5Csubset+%5Bn%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{I \subset [n]}"/> and <img alt="{\alpha: I \rightarrow \{0,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%3A+I+%5Crightarrow+%5C%7B0%2C1%5C%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\alpha: I \rightarrow \{0,1\}}"/> and for some <img alt="{x \neq y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cneq+y%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x \neq y}"/> in <img alt="{\{0,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\{0,1\}^n}"/> the following hold: </p>
<ol>
<li>
The inequality <img alt="{f(x) \neq f(y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29+%5Cneq+f%28y%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{f(x) \neq f(y)}"/> holds. <p/>
</li><li>
For all <img alt="{k \in I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%5Cin+I%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{k \in I}"/>, 	<p/>
<p align="center"><img alt="\displaystyle  x_k = y_k = \alpha(k). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x_k+%3D+y_k+%3D+%5Calpha%28k%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  x_k = y_k = \alpha(k). "/></p>
</li></ol>
</em><p><em/>
</p></blockquote>
<p/><p>
Thus <img alt="{\textsf{free}(f,I,\alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctextsf%7Bfree%7D%28f%2CI%2C%5Calpha%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\textsf{free}(f,I,\alpha)}"/> holds provided the value <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{f(x)}"/> is not determined by just knowing <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x}"/> on the set of positions in <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{I}"/>. The remaining <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{m}"/> positions are needed.</p>
<blockquote><p><b>Theorem 2 (Main Theorem of Random Restriction Theory)</b> <em> Let <img alt="{f : \{0,1\}^n \rightarrow \{0,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%3A+%5C%7B0%2C1%5C%7D%5En+%5Crightarrow+%5C%7B0%2C1%5C%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{f : \{0,1\}^n \rightarrow \{0,1\}}"/> be a Boolean function. Suppose that for a constant positive fraction of <img alt="{I,\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%2C%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{I,\alpha}"/> with <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{I}"/> of size <img alt="{n-m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-m%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n-m}"/>, 	</em></p><em>
<p align="center"><img alt="\displaystyle  \textsf{free}(f,I,\alpha) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctextsf%7Bfree%7D%28f%2CI%2C%5Calpha%29+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  \textsf{free}(f,I,\alpha) "/></p>
<p>holds. Then 	 	</p>
<p align="center"><img alt="\displaystyle  L(f) \gtrdot \frac{n^2}{m^2}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++L%28f%29+%5Cgtrdot+%5Cfrac%7Bn%5E2%7D%7Bm%5E2%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  L(f) \gtrdot \frac{n^2}{m^2}. "/></p>
</em><p><em/>
</p></blockquote>
<p>
</p><p/><h2> An Example and Nonexample </h2><p/>
<p/><p>
To see how this scheme applies in the case of the parity function, we can set <img alt="{m=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{m=1}"/>. No matter which inputs are selected, the value of the function stays undetermined after <img alt="{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n-1}"/> inputs are set. That is, the following is always true: 	</p>
<p align="center"><img alt="\displaystyle  \textsf{free}(\textit{parity},I,\alpha), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctextsf%7Bfree%7D%28%5Ctextit%7Bparity%7D%2CI%2C%5Calpha%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  \textsf{free}(\textit{parity},I,\alpha), "/></p>
<p>for all <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{I}"/> of size at most <img alt="{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n-1}"/> and all <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\alpha}"/>. Thus the main theorem says that the formula lower bound for the parity function is order <img alt="{n^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n^2}"/>. </p>
<p>
Note that the only property of the parity function <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{f}"/> being used is the global way it satisfies <img alt="{\textsf{free}(f,I,\alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctextsf%7Bfree%7D%28f%2CI%2C%5Calpha%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\textsf{free}(f,I,\alpha)}"/>. We want to look for other patterns that can yield good bounds. Of course, patterns of sensitivity of Boolean functions have been looked at in many ways. We want to try to build a bridge from them to number theory.</p>
<p>
For a <em>non-</em>example, consider the set <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{E}"/> of even numbers. Let us number the variables so that <img alt="{x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_1}"/> stands for the ones place in binary notation, <img alt="{x_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_2}"/> for the twos place, and so on. Then <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{E}"/> depends only on <img alt="{x_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x_1}"/>. Whether <img alt="{\textsf{free}(f,I,\alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctextsf%7Bfree%7D%28f%2CI%2C%5Calpha%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\textsf{free}(f,I,\alpha)}"/> holds depends entirely on <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{1}"/> not belonging to <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{I}"/>. If <img alt="{m = n/c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+n%2Fc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{m = n/c}"/> for some <img alt="{c &gt; 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc+%3E+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{c &gt; 1}"/> then it holds with constant probability, and the framework gives </p>
<p align="center"><img alt="\displaystyle  L(E) \gtrdot c^2. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++L%28E%29+%5Cgtrdot+c%5E2.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  L(E) \gtrdot c^2. "/></p>
<p>Well, OK, we really know <img alt="{L(E) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%28E%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{L(E) = 1}"/> so this is where the overhead hidden by <img alt="{\gtrdot}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgtrdot%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\gtrdot}"/> can’t be ignored. But at least this illustrates how the framework doesn’t get too excited about a frequently alternating numerical function. Similar remarks apply when the function is multiples of <img alt="{2^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{2^k}"/> where <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{k}"/> is small. </p>
<p>
</p><p/><h2> A Prime Objective </h2><p/>
<p/><p>
We would like to apply the random restrictions method to the Boolean function <img alt="{\pi(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\pi(x)}"/> that identifies whether the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n}"/>-bit binary string <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{x}"/> denotes a prime number. It has been known for decades that the Boolean circuit complexity of <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\pi}"/> is polynomial. This follows from the existence of a polynomial random algorithm for <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\pi}"/> due to <a href="https://en.wikipedia.org/wiki/Solovay-Strassen_primality_test">Solvay-Strassen</a> or the later <a href="https://en.wikipedia.org/wiki/Miller-Rabin_primality_test">Miller-Rabin</a> algorithm and Adleman’s <a href="https://ieeexplore.ieee.org/abstract/document/4567965">connection</a> between such algorithms and Boolean circuit complexity.</p>
<p>
There are <a href="https://www.sciencedirect.com/science/article/pii/S0022000000917252">strong</a> lower <a href="https://www.sciencedirect.com/science/article/pii/S0304397504001884">bounds</a> on special circuit models, but nothing so general as formulas, let alone unrestricted circuits. Certainly <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\pi}"/> is a harder function that parity, but we don’t know of a quadratic formula lower bound for it. Can we prove one in the framework?</p>
<p/><p>
Our intuition comes from considering various ways in which the primes are dense and uniformly—but not too regularly—distributed. Two simple ways are:</p>
<ol>
<li>
The average size gap between prime numbers is <img alt="{O(\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{O(\log n)}"/>. <p/>
</li><li>
The maximum size gap between prime numbers is <img alt="{O(\log^{2} n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog%5E%7B2%7D+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{O(\log^{2} n)}"/>.
</li></ol>
<p>
The first is of course a consequence of the prime number theorem. The second follows from the widely believed Cramér <a href="https://en.wikipedia.org/wiki/Cramer%27s_conjecture">conjecture</a>. </p>
<p>
We will not really need this conjecture—we will not need it to hold everywhere. Our basic framework will only need it to hold for a positive fraction of small intervals of numbers that we sample. What we need instead is for a positive-fraction version to hold under a more liberal notion of “gap.” </p>
<p>
Here is an outline to try to prove a formula size lower bound of <img alt="{n^{2-\epsilon}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B2-%5Cepsilon%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n^{2-\epsilon}}"/> on <img alt="{\pi(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\pi(x)}"/>, for some <img alt="{\epsilon &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\epsilon &gt; 0}"/>. Let 	</p>
<p align="center"><img alt="\displaystyle  t = n^{1-\epsilon}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++t+%3D+n%5E%7B1-%5Cepsilon%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  t = n^{1-\epsilon}. "/></p>
<p>We will use the random restriction method for <img alt="{p = 1/t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+1%2Ft%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{p = 1/t}"/>. Apply the method. The issue is now if we leave only <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{m}"/> input bits unset, then what is the probability that 	</p>
<p align="center"><img alt="\displaystyle  \textsf{free}(\pi,I,\alpha)? " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctextsf%7Bfree%7D%28%5Cpi%2CI%2C%5Calpha%29%3F+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  \textsf{free}(\pi,I,\alpha)? "/></p>
<p>Certainly we cannot always leave <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{1}"/> bit unset like with the XOR function. Look at this: 	</p>
<p align="center"><img alt="\displaystyle  11*111. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++11%2A111.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  11*111. "/></p>
<p>The input is either 	</p>
<p align="center"><img alt="\displaystyle  111111 = 63 \text{ or } 110111 = 55 . " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++111111+%3D+63+%5Ctext%7B+or+%7D+110111+%3D+55+.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  111111 = 63 \text{ or } 110111 = 55 . "/></p>
<p>And both are not a prime. In general, our finger has come to rest on the question of what is known or can be shown about the behavior of the set of primes on “hypercubic” sets—that is, sets that add or subtract all sums from a selected subset of the powers of <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{2}"/>.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
There must be other lower bounds on the primes. We cannot seem to find them. Any help?</p>
<p/></font></font></div>
    </content>
    <updated>2021-01-14T16:51:43Z</updated>
    <published>2021-01-14T16:51:43Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="People"/>
    <category term="primes"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="Bella Subbotovskaya"/>
    <category term="circuit complexity"/>
    <category term="formula complexity"/>
    <category term="Johan Hastad"/>
    <category term="lower bounds"/>
    <category term="random restrictions"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2021-01-26T03:37:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=20949</id>
    <link href="https://gilkalai.wordpress.com/2021/01/14/to-cheer-you-up-in-difficult-times-17-amazing-the-erdos-faber-lovasz-conjecture-for-large-n-was-proved-by-dong-yeap-kang-tom-kelly-daniela-kuhn-abhishek-methuku-and-deryk-osthus/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 17: Amazing! The Erdős-Faber-Lovász conjecture (for large n) was proved by Dong Yeap Kang, Tom Kelly, Daniela Kühn, Abhishek Methuku, and Deryk Osthus!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Dong Yeap Kang, Tom Kelly, Daniela Kühn, Abhishek Methuku, and Deryk Osthus have just uploaded a paper to the arXive, A proof of the Erdős-Faber-Lovász conjecture. (I am thankful to Nati Linial and Ryan Alweiss for telling me about it.) … <a href="https://gilkalai.wordpress.com/2021/01/14/to-cheer-you-up-in-difficult-times-17-amazing-the-erdos-faber-lovasz-conjecture-for-large-n-was-proved-by-dong-yeap-kang-tom-kelly-daniela-kuhn-abhishek-methuku-and-deryk-osthus/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Dong Yeap Kang, Tom Kelly, Daniela Kühn, Abhishek Methuku, and Deryk Osthus have just uploaded a paper to the arXive, <a href="https://arxiv.org/abs/2101.04698">A proof of the Erdős-Faber-Lovász conjecture</a>. (I am thankful to Nati Linial and Ryan <span class="qu"><span class="gD">Alweiss for telling me about it.)</span></span></p>
<p>Here is one formulation of the conjecture:</p>
<p><strong>Erdős-Faber-Lovász Conjecture:</strong> Let <img alt="F" class="latex" src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="F"/> be a family of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k"/>-subsets of <img alt="\{1,2,\dots,n\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots%2Cn%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\{1,2,\dots,n\}"/>. Suppose that every two sets in <img alt="F" class="latex" src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="F"/> have at most one element in common, then <img alt="F" class="latex" src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="F"/> can be divided into at most <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> families so that every two sets in each of these families are disjoint.</p>
<p>Using some standard hypergraph jargon the conjecture can be stated as follows:</p>
<p><strong>Erdős-Faber-Lovász Conjecture: </strong>The chromatic index of any linear hypergraph on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> vertices is at most <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/>.</p>
<p>Here a linear hypergraph is a hypergraph where every two edges share at most one vertex. The chromatic index of a hypergraph is the number of colors needed to color the edges so that  every two intersecting edges have distinct colors.</p>
<p>The new result asserts</p>
<p><strong>Theorem</strong>  (Kang, Kelly, Kühn, Methuku, and Osthus): For every sufficiently large <em>n</em>, every linear hypergraph <em>H</em> on <em>n</em> vertices has chromatic index at most <em>n</em>.</p>
<p>A stability versions of this result, which confirm a prediction of Jeff Kahn, is also provided. Of course, it will be interesting to settle the conjecture for all values of n.</p>
<p>This is an amazing breakthrough! Congratulations!</p>
<p><a href="https://gilkalai.files.wordpress.com/2021/01/efl3.png"><img alt="" class="alignnone size-full wp-image-20963" src="https://gilkalai.files.wordpress.com/2021/01/efl3.png?w=640"/></a></p>
<p>(from Wikipedea)</p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2021/01/efl.png"><img alt="" class="alignnone size-full wp-image-20959" height="194" src="https://gilkalai.files.wordpress.com/2021/01/efl.png?w=640&amp;h=194" width="640"/></a></p>
<p><span style="color: #800000;"><strong>Daniella Kühn, Deryk Osthus, Tom Kelly, and Abhishek Methuku</strong>  (I will add a picture of <strong>Dong Yeap Kang</strong> when I will find Update: found! see below.)</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2021/01/kang.jpg"><img alt="" class="alignnone size-thumbnail wp-image-20969" height="150" src="https://gilkalai.files.wordpress.com/2021/01/kang.jpg?w=150&amp;h=150" width="150"/></a></p>
<h2>A little more</h2>
<p>Background and links: Here is the <a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Faber%E2%80%93Lov%C3%A1sz_conjecture">Wikipedea</a> article. We mentioned the conjecture in <a href="https://gilkalai.wordpress.com/2011/06/30/around-borsuks-conjecture-1-some-problems/">this post</a> and <a href="https://gilkalai.wordpress.com/2013/09/04/around-borsuks-conjecture-3-how-to-save-borsuks-conjecture/">this one</a>.</p>
<p><strong>Matching and Fractional version</strong>. In 1982 Paul Seymour proved that any linear hypergraph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="H"/> has a matching of size <img alt="e(H)/n" class="latex" src="https://s0.wp.com/latex.php?latex=e%28H%29%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="e(H)/n"/>. In 1992 Jeff Kahn and Paul Seymour proved that the fractional chromatic index of any linear hypergraph on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> vertices is at most <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/>.</p>
<p><strong>Approximate version via the semi random method.</strong> In 1992 Jeff Kahn proved that chromatic index of any linear hypergraph on <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> vertices is at most <img alt="n(1+o(1))" class="latex" src="https://s0.wp.com/latex.php?latex=n%281%2Bo%281%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n(1+o(1))"/>. Kahn used the Rödl nibble (aka semi-random) method. Kahn extended the result to list-coloring.</p>
<h3 style="text-align: center;"><a href="https://gilkalai.files.wordpress.com/2021/01/jeffk.png"><img alt="" class="alignnone size-full wp-image-20960" src="https://gilkalai.files.wordpress.com/2021/01/jeffk.png?w=640"/></a></h3>
<h3>Open problems</h3>
<p>There are many related open questions and some are mentioned in the paper. It will be interesting to prove EFL conjecture for all values of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/>. EFL-conjecture extends to  beautiful generalization of Vizing’s theorem which is still open. Also the EFL-conjecture for <em>list coloring </em>is still open<em>. </em>See also this 1994 article by Jeff Kahn on <a href="http://www.mathunion.org/ICM/ICM1994.2/Main/icm1994.2.1353.1362.ocr.pdf">Hypergraphs matching, covering and coloring problems</a>.</p>
<p>Another interesting problem is:</p>
<p><strong>The restricted Larman’s conjecture:</strong> Let <img alt="F" class="latex" src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="F"/> be an intersecting family of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k"/>-subsets of <img alt="\{1,2,\dots,n\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots%2Cn%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\{1,2,\dots,n\}"/>.  Then <img alt="F" class="latex" src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="F"/> can be divided into at most <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> 2-intersecting families, namely so that every two sets in each of these families have at least <img alt="2" class="latex" src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="2"/> elements in common.</p>
<p><strong>Little Update:</strong> A few more details on the last problem. As far as I know for the restricted Larman conjecture it is not even known that <img alt="F" class="latex" src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="F"/> can always be divided into <img alt="(1+o(1))" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2Bo%281%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="(1+o(1))"/> 2-intersecting families.</p>
<p>Now, call G strongly 2-intersecting if the intersection of all sets in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="G"/> has at least two elements.  Furedi and Seymour proved that F can be <em>fractionally covered</em> by <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> strongly 2-intersecting subfamilies. They conjectured that F can always be covered by <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="n"/> strongly 2-intersecting families, however Jeff Kahn and I disproved this conjecture.</p></div>
    </content>
    <updated>2021-01-14T13:51:35Z</updated>
    <published>2021-01-14T13:51:35Z</published>
    <category term="Combinatorics"/>
    <category term="Updates"/>
    <category term="Abhishek Methuku"/>
    <category term="Daniela K&#xFC;hn"/>
    <category term="Deryk Osthus"/>
    <category term="Dong Yeap Kang"/>
    <category term="Erdos-Faber-Lovasz conjecture"/>
    <category term="Tom Kelly"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2021-01-26T03:37:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/01/14/postdoc-at-hse-university-apply-by-february-14-2021/</id>
    <link href="https://cstheory-jobs.org/2021/01/14/postdoc-at-hse-university-apply-by-february-14-2021/" rel="alternate" type="text/html"/>
    <title>Postdoc at HSE University (apply by February 14, 2021)</title>
    <summary>HSE University’s Faculty of Computer Science now receives applications for the postdoctoral positions in several laboratories. At present, there are ten open postdoctoral positions in ten out of twelve Faculty’s laboratories. Research areas range from algebraic topology and bioinformatics to data analysis, neural networks and process mining. Website: https://cs.hse.ru/en/news/433773574.html Email: abasov@hse.ru</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>HSE University’s Faculty of Computer Science now receives applications for the postdoctoral positions in several laboratories.<br/>
At present, there are ten open postdoctoral positions in ten out of twelve Faculty’s laboratories. Research areas range from algebraic topology and bioinformatics to data analysis, neural networks and process mining.</p>
<p>Website: <a href="https://cs.hse.ru/en/news/433773574.html">https://cs.hse.ru/en/news/433773574.html</a><br/>
Email: abasov@hse.ru</p></div>
    </content>
    <updated>2021-01-14T12:42:07Z</updated>
    <published>2021-01-14T12:42:07Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-01-26T03:37:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1276</id>
    <link href="https://toc4fairness.org/launching-toc4fairness/" rel="alternate" type="text/html"/>
    <title>Launching TOC4Fairness</title>
    <summary>I am excited to launch the Simons Foundation’s Collaboration on the Theory of Algorithmic Fairness, funded by the Simons Foundation. This is a large-scale multi-institutional effort to accelerate the (already ...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am excited to launch the <a href="https://toc4fairness.org/">Simons Foundation’s Collaboration on the Theory of Algorithmic Fairness</a>, funded by<a href="https://www.simonsfoundation.org/"> the Simons Foundation</a>. This is a large-scale multi-institutional effort to accelerate the (already powerful) impact of TOC on the emerging area of algorithmic fairness. Beyond the ambitious research goals of this project (which we will discuss in future posts), we hope it will play an important role in community building and bridge building to other fields of research. In addition to launching <a href="https://toc4fairness.org/category/blog/">this blog</a> and <a href="https://toc4fairness.org/">our site</a>, we are also launching a <a href="https://toc4fairness.org/category/events/">research seminar</a> that will feature a diverse set of talks. We are very exited to have  <a href="https://toc4fairness.org/inaugural-meeting-toc4fairness-seminar-annette-zimmermann/">Annette Zimmermann</a> as our inaugural speaker (a week from today). </p>



<p>If you want to join our seminar, please email toc4fairness-director@cs.stanford.edu and we will add you to our email list (which we will be careful not to overuse).</p></div>
    </content>
    <updated>2021-01-13T15:45:36Z</updated>
    <published>2021-01-13T15:45:36Z</published>
    <category term="Blog"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-01-26T03:38:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/005</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/005" rel="alternate" type="text/html"/>
    <title>TR21-005 |  Robust testing of low-dimensional functions | 

	Anindya De, 

	Elchanan Mossel, 

	Joe Neeman</title>
    <summary>A natural problem in high-dimensional inference is to decide if a classifier $f:\mathbb{R}^n \rightarrow \{-1,1\}$ depends on a small number of linear directions of its input data. Call a function $g: \mathbb{R}^n \rightarrow \{-1,1\}$, a linear $k$-junta if it is completely determined by some $k$-dimensional subspace of the input space. A recent work of the authors showed that linear $k$-juntas are testable. Thus there exists an algorithm to distinguish between: 
1. $f: \mathbb{R}^n \rightarrow \{-1,1\}$ which is a linear $k$-junta with surface area $s$, 
2. $f$ is $\epsilon$-far from any linear $k$-junta with surface area $(1+\epsilon)s$, where the query complexity of the algorithm is independent of the ambient dimension $n$.
  Following the surge of interest in noise-tolerant property testing, in this paper we prove a noise-tolerant (or robust) version of this result. Namely, we give an algorithm which given any $c&gt;0$, $\epsilon&gt;0$, distinguishes between 
1. $f: \mathbb{R}^n \rightarrow \{-1,1\}$ has correlation at least $c$ with some linear $k$-junta with surface area $s$. 
2. $f$ has correlation at most $c-\epsilon$ with any linear $k$-junta with surface area at most $s$. The query complexity of our tester is $k^{\mathrm{poly}(s/\epsilon)}$.

  Using our techniques, we also obtain a fully noise tolerant tester with the same query complexity for any class $\mathcal{C}$ of linear $k$-juntas with surface area bounded by $s$. As a consequence, we obtain a fully noise tolerant tester with query complexity $k^{O(\mathrm{poly}(\log k/\epsilon))}$ for the class of intersection of $k$-halfspaces (for constant $k$) over the Gaussian space. Our query complexity is independent of the ambient dimension $n$. Previously, no non-trivial noise tolerant testers were known even for a single halfspace.</summary>
    <updated>2021-01-12T23:28:41Z</updated>
    <published>2021-01-12T23:28:41Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-01-26T03:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://sarielhp.org/blog/?p=9406</id>
    <link href="https://sarielhp.org/blog/?p=9406" rel="alternate" type="text/html"/>
    <title>How to have irritating files in subdirectory…</title>
    <summary>If you are formatting a paper for lipics, but don’t want all their files in the paper directory, add the following to the top of the main latex file: This is under the assumption that lipics/ subdirectory contains the .cls file.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>If you are formatting a paper for lipics, but don’t want all their files in the paper directory, add the following to the top of the main latex file: </p>



<pre class="wp-block-code"><code>\makeatletter
\def\input@path{{lipics/}{../lipics/}} 
\makeatother
\documentclass[a4paper,USenglish,cleveref,autoref,thm-restate]%
{socg-lipics-v2019}</code></pre>



<p>This is under the assumption that lipics/ subdirectory contains the .cls file.</p></div>
    </content>
    <updated>2021-01-12T15:53:53Z</updated>
    <published>2021-01-12T15:53:53Z</published>
    <category term="Tweet"/>
    <category term="latex"/>
    <category term="Research"/>
    <author>
      <name>Sariel</name>
    </author>
    <source>
      <id>https://sarielhp.org/blog</id>
      <link href="https://sarielhp.org/blog/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://sarielhp.org/blog" rel="alternate" type="text/html"/>
      <subtitle>Sariel's blog</subtitle>
      <title>Vanity of Vanities, all is Vanity</title>
      <updated>2021-01-26T03:37:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3510</id>
    <link href="https://agtb.wordpress.com/2021/01/11/call-for-proposals-ec-2021-workshops-and-tutorials/" rel="alternate" type="text/html"/>
    <title>CALL FOR PROPOSALS: EC 2021 WORKSHOPS AND TUTORIALS</title>
    <summary>The EC 2021 conference invites proposals for tutorials and workshops to be held in conjunction with the ACM Conference on Economics and Computation (ACM EC). EC’21 will be held either virtually or in a hybrid format. In the latter case, tutorial/workshop organizers will have the opportunity to decide whether to hold their event in person […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="http://ec21.sigecom.org/">The EC 2021 conference</a> invites proposals for tutorials and workshops to be held in conjunction with the ACM Conference on Economics and Computation (ACM EC). EC’21 will be held either virtually or in a hybrid format. In the latter case, tutorial/workshop organizers will have the opportunity to decide whether to hold their event in person or remotely.</p>



<h3>Tutorials</h3>



<p>Tutorials provide an opportunity to educate the community about emerging topics of interest, or about topics from related fields that merit additional attention from the EC community.  A tutorial is an opportunity to invite colleagues and young researchers to get excited about a well-defined topic, to prepare them to dive into the literature and to guide them to the most exciting developments and open problems. Typically, tutorials run for half a day (3-3.5 hours) and consist of a series of presentations by experts in the field.</p>



<p>Tutorial proposals should contain:</p>



<ul><li>the title of the tutorial</li><li>the names, contact information, and short biographies of the organizers</li><li>a description of the tutorial theme</li><li>the organization/format of the tutorial</li><li>any related tutorials that have been run</li><li>required facilities for the tutorial</li></ul>



<p>Tutorial proposals should be emailed to <a href="mailto:ec21-tutorial-chairs@acm.org" rel="noreferrer noopener" target="_blank">ec21-tutorial-chairs@acm.org</a>.</p>



<h3>Workshops</h3>



<p>Workshops provide an opportunity to bring together researchers to discuss emerging areas of research in an informal forum. Workshop schedules should be designed to promote discussion and debate. A workshop may include invited talks, contributed talks, panel discussions, poster sessions, open problem sessions, presentations of work in progress, or any other activities that stimulate new ideas for research. It is up to the workshop organizers to determine the format and technical content of each workshop and to solicit contributions, but we encourage workshops that devote some time to contributed content.</p>



<p>Workshop proposals should contain:</p>



<ul><li>the title of the workshop</li><li>the names, contact information, and short biographies of the organizers</li><li>the names of confirmed or candidate participants</li><li>a description of the workshop theme</li><li>the reviewing process for participants</li><li>the organization/format of the workshop</li><li>any previous versions of the workshop</li><li>required facilities for the workshop</li><li>the desired workshop length (half-day, full day, etc.)</li></ul>



<p>For accepted workshops, the desired length will be honored as closely as possible.</p>



<p>We especially encourage proposals that bring together participants with diverse backgrounds and experience.</p>



<p>Workshop proposals should be emailed to <a href="mailto:ec21-workshop-chairs@acm.org" rel="noreferrer noopener" target="_blank">ec21-workshop-chairs@acm.org</a>.</p>



<h3>Key dates:</h3>



<p>March 1, 2021: Due date for submitting workshop or tutorial proposal</p>



<p>March 22, 2021: Tutorial &amp; workshop proposal accept/reject notifications</p>



<p>July 19, 2021: Conference Tutorials</p>



<p>July 20-22, 2021: Conference technical program</p>



<p>July 23, 2021: Conference Workshops</p>



<h3>Tutorial co-chairs</h3>



<p>Shengwu Li, Harvard University</p>



<p>Sigal Oren, Ben-Gurion University</p>



<h3>Workshop co-chairs</h3>



<p>Hu Fu, University of British Columbia</p>



<p>Annie Liang, Northwestern University</p>



<p/></div>
    </content>
    <updated>2021-01-11T08:41:27Z</updated>
    <published>2021-01-11T08:41:27Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Noam Nisan</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2021-01-26T03:37:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6412374969669821012</id>
    <link href="https://blog.computationalcomplexity.org/feeds/6412374969669821012/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/01/the-acm-history-committee-call-for.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6412374969669821012" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6412374969669821012" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/01/the-acm-history-committee-call-for.html" rel="alternate" type="text/html"/>
    <title>The ACM History Committee call for proposals looks wrong</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> In November I (and prob everyone in the ACM) got an email that was a call for proposal from the ACM History committee. <a href="https://history.acm.org/wp-content/uploads/2020/11/ACM-fellowship_CFP_2021-final-1.pdf">Here</a> is a pointer to it. </p><p>One of the passages in it just seems wrong to me:</p><p><i>This fellowship program is designed to support research and/or curatorial projects related to ACM's professional and educational activities and/or to ACM's rich institutional history including its organization, SIG activities, and conferences. </i></p><p>I will give  examples of history projects that are interesting but do not fit the description. I challenge you to give me a history project that is interesting that does fit the bill. </p><p>1) Compare and contrast how NP-completeness developed in America and in the USSR. For the USSR side it would be an expansion of  Trakhtenbrot's article <a href="https://drdoane.com/wp-content/uploads/2020/08/survey_of_russian_approaches_to_perebor.pdf">here</a>. OH, no good, Leonid Levin was not a member of the ACM.</p><p>2) Measure how various CS fields have changed by looking at the topics on the CALL FOR PAPERS for a conference. This would be a MASSIVE expansion of my blog post on how CCC call for papers, changed , see <a href="https://blog.computationalcomplexity.org/2011/05/how-has-structures-oh-i-mean-ccc.html">here</a>. OH, I could only do ACM conferences. STOC but not FOCS. Okay, it makes perfect sense to study only ACM conference. Oh wait. IT MAKES NO SENSE WHATSOEVER.</p><p>3) When did mathematicians begin looking at P vs NP seriously? (e.g.,  In  The Handbook of Mathematical Logic from 1977 only one article mentions P vs NP: Michael Rabin's article on Decidable theories mentioned that even decidable theories may take a long time to decide and noted the importance of the P vs NP problem). How did MATH and CS  interact early on and now? This would need  one to look at math journals. How many of those are ACM? I would guess very few. </p><p>4) When did engineers begin looking at P vs NP seriously, or even notice it? Same issue as the last item. </p><p>5) Looking at how Programming lang design has changed one would have to only look at conference and journals that were ACM. And for those that were ACM but then dropped ACM you might only be able to use them up to the cutoff year. </p><p>6) Which academic studies eventually lead to practical products people can use? This is a really broad topic so one could narrow it down to just academic studies that appeared in ACM journals or conferences. Is that a good way to narrow the focus? Spoiler alert: NO.</p><p>7) I recently filled out a survey about the future of theory and if it is insular (the topic of another post surely). Most of the questions were about ``STOC-FOCS'' The people who did the survey clearly do not care that one is ACM and one is IEEE. Does anyone? I ask non-rhetorically. </p><p>Despite the capitol letters, I am not so much mad as puzzled. So I ask non-rhetorically: </p><p>Q1) Did the ACM really mean for people to do history in a way where you can only use ACM materials? </p><p>Q2) If no then please rewrite the Call for Proposals. </p><p>Q3) If yes then give examples of studies that would be interesting. </p><p>I am not asking to be snarky, I really want to know. And I note that <i>interesting</i> is subjective. </p><p>(ADDED LATER- two historians who have worked with this kind of history left comments that indicate the grant is FINE with non-ACM stuff, so Q1 above seems to have the answer NO. Given that they should rewrite the call for proposal next time they do this. ALSO- the historians left pointers to VERY INTERESTING papers they wrote.) </p><p><i><br/></i></p><p><br/></p></div>
    </content>
    <updated>2021-01-11T04:39:00Z</updated>
    <published>2021-01-11T04:39:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-01-25T18:51:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/004</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/004" rel="alternate" type="text/html"/>
    <title>TR21-004 |  Junta Distance Approximation with Sub-Exponential Queries | 

	Vishnu Iyer, 

	Avishay Tal, 

	Michael Whitmeyer</title>
    <summary>Leveraging tools of De, Mossel, and Neeman [FOCS, 2019], we show two different results pertaining to the tolerant testing of juntas. Given black-box access to a Boolean function $f:\{\pm1\}^{n} \to \{\pm1\}$ we give a poly$(k, \frac{1}{\varepsilon})$ query algorithm that distinguishes between functions that are $\gamma$-close to $k$-juntas and $(\gamma+\varepsilon)$-far from $k'$-juntas, where $k' = O(\frac{k}{\varepsilon^2})$. In the non-relaxed setting, we extend our ideas to give a  $2^{\tilde{O}(\sqrt{k}/\varepsilon)}$ (adaptive) query algorithm that distinguishes between functions that are $\gamma$-close to $k$-juntas and $(\gamma+\varepsilon)$-far from $k$-juntas. To the best of our knowledge, this is the first subexponential-in-$k$ query algorithm for approximating the distance of $f$ to being a $k$-junta (previous results of Blais, Canonne, Eden,  Levi,  and  Ron [SODA, 2018] and De, Mossel, and Neeman [FOCS, 2019] required exponentially many queries in $k$). Our techniques are Fourier analytical and introduce the new notion of "normalized influences'' that might be of independent interest.</summary>
    <updated>2021-01-10T16:21:56Z</updated>
    <published>2021-01-10T16:21:56Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-01-26T03:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=20474</id>
    <link href="https://gilkalai.wordpress.com/2021/01/10/open-problem-session-of-huji-combsem-problem-5-gil-kalai-the-3%e1%b5%88-problem/" rel="alternate" type="text/html"/>
    <title>Open problem session of HUJI-COMBSEM: Problem #5, Gil Kalai – the 3ᵈ problem</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This post continues to describe problems presented at our open problems session back in November 2020. Here is the first post in the series.  Today’s problem was presented by me, and it was an old 1989 conjecture of mine. A … <a href="https://gilkalai.wordpress.com/2021/01/10/open-problem-session-of-huji-combsem-problem-5-gil-kalai-the-3%e1%b5%88-problem/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This post continues to describe problems presented at our open problems session back in November 2020. Here is the <a href="https://gilkalai.wordpress.com/2020/11/25/open-problem-session-of-huji-combsem-problem-1-nati-linial-turan-type-theorems-for-simplicial-complexes/">first post</a> in the series.  Today’s problem was presented by me, and it was <a href="https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/content/pdf/10.1007/BF01788696.pdf&amp;casa_token=tLZCajryjNcAAAAA:ij5u7eLRf5IBH0sym5BHY8q5l_H3H175bvo-ydaVfwU5nWzmOTSD0_4yQDAYwk9H-R_rxT5n1fHsxxmo-A">an old 1989 conjecture of mine</a>.</p>
<p>A convex set K is centrally symmetric if <img alt="x \in K" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+K&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="x \in K"/> implies that <img alt="-x \in K" class="latex" src="https://s0.wp.com/latex.php?latex=-x+%5Cin+K&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="-x \in K"/>.</p>
<h3><strong>Conjecture:</strong> Let P be a centrally symmetric d-polytope. Then P has at least 3ᵈ non-empty faces.</h3>
<p>Here we count P itself as a face.</p>
<p><span style="color: #008000;"><strong>Before we continue</strong> let me mention</span> <a href="https://www.him.uni-bonn.de/programs/current-trimester-program/interplay-high-dimensional-geometry-probability/interplay-high-dimensional-geometry-probability-winterschool/">a winter school on “The Interplay between High-Dimensional Geometry and Probability”,</a> <span style="color: #008000;">January 11-15. Among other exciting lectures Bo’az Klartag will give 3 lectures on Yuansi Chen’s work on the KLS conjecture, that we discussed in <a href="https://gilkalai.wordpress.com/2020/12/21/to-cheer-you-up-in-difficult-times-15-yuansi-chen-achieved-a-major-breakthrough-on-bourgains-slicing-problem-and-the-kannan-lovasz-and-simonovits-conjecture/">this post</a>.</span></p>
<p><strong>Now back to the 3ᵈ conjecture. </strong>A case of equality is the <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="d"/>-dimensional cube <img alt="C_d" class="latex" src="https://s0.wp.com/latex.php?latex=C_d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="C_d"/>. The faces of <img alt="C_d" class="latex" src="https://s0.wp.com/latex.php?latex=C_d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="C_d"/> corresponds to (-1,1,*)-vectors of length <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="d"/>. Given such a vector it corresponds to a face of the cube whose vertices are obtained by replacing the *’s with ±1 in all possible ways.  Of course the dual of <img alt="C_d" class="latex" src="https://s0.wp.com/latex.php?latex=C_d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="C_d"/> also has <img alt="3^d" class="latex" src="https://s0.wp.com/latex.php?latex=3%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="3^d"/> non-empty faces.</p>
<p><a href="https://gilkalai.files.wordpress.com/2021/01/octahedral_prism.png"><img alt="" class="alignnone size-medium wp-image-20912" height="300" src="https://gilkalai.files.wordpress.com/2021/01/octahedral_prism.png?w=300&amp;h=300" width="300"/></a></p>
<p> </p>
<p><a href="https://en.wikipedia.org/wiki/Schlegel_diagram" title="Schlegel diagram"><span style="color: #ff0000;">Schlegel diagram</span></a><span style="color: #ff0000;"> of the <a href="https://en.wikipedia.org/wiki/Octahedral_prism" style="color: #ff0000;" title="Octahedral prism">octahedral prism</a>, a 4-dimensional Hanner polytope.  (attribution: </span><span class="mw-mmv-source-author"><span class="mw-mmv-author mw-mmv-source"><span style="color: #ff0000;">Robert Webb’s <a class="extiw" href="https://en.wikipedia.org/wiki/Stella_(software)" style="color: #ff0000;" title="en:Stella (software)">Stella software</a> as the creator of this image along with a link to the website: <a class="external free" href="http://www.software3d.com/Stella.php" rel="nofollow" style="color: #ff0000;">http://www.software3d.com/Stella.php</a>. via Wikipedea.)</span> </span></span></p>
<h3>Some comments</h3>
<p>Here are some points raised in the discussion and further comments.</p>
<ol>
<li>There are many cases of equality – all <a href="https://en.wikipedia.org/wiki/Hanner_polytope"><em>Hanner polytopes</em></a>. Those are obtained from intervals by taking the two operations, a) Cartesian product, b) moving from a polytope P to its polar-dual P*, and apply them in all possible ways.</li>
<li><span style="color: #0000ff;">Nati asked if a <img alt="(2+\epsilon)^d" class="latex" src="https://s0.wp.com/latex.php?latex=%282%2B%5Cepsilon%29%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="(2+\epsilon)^d"/> lower bound is known. To the best of my knowledge even this is not known.</span></li>
<li>Gideon asked about the connections with <a href="https://en.wikipedia.org/wiki/Mahler_volume">Mahler’s conjecture</a> that for every d-dimentional centrally symmetric body K, <img alt="vol(K)vol(K*) \ge 4^n/n!" class="latex" src="https://s0.wp.com/latex.php?latex=vol%28K%29vol%28K%2A%29+%5Cge+4%5En%2Fn%21&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="vol(K)vol(K*) \ge 4^n/n!"/>  . Indeed the cases of equality are conjectured to be the same – the class of Hanner polytopes. (Mahler’s conjecture and its relations to combinatorics would deserve a separate post.) The recent paper <a href="https://www.sciencedirect.com/science/article/pii/S0001870818303372?casa_token=YEJdSwTFFaIAAAAA:k-e1q7dtnSZslAg5ZZYtJJQrgLiCbDE7_uNBITsrrUxOkCc5A8ThPF5CPTIcD4HUhTcVlUqeaAM" id="1oYidvdGYaQJ"><span dir="ltr">Flag numbers and floating bodies</span>‏</a> by <span dir="ltr"><a href="https://scholar.google.com/citations?user=MqLwWBgAAAAJ&amp;hl=iw&amp;oi=sra">F Besau</a>, C Schütt, EM Werner looks very relevant.</span></li>
<li>For simplicial polytopes the conjecture follows from results of Stanley (1986) and is related t0 a result by Barany and Lovasz (1982).</li>
<li>The conjecture is related to a 1979 theorem of Figiel, Lindenstrauss, and Milman that asserts that for every centrally symmetric <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="d"/> polytope <img alt="\log f_0(P) \log f_{d-1}(P) \ge \gamma d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog+f_0%28P%29+%5Clog+f_%7Bd-1%7D%28P%29+%5Cge+%5Cgamma+d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\log f_0(P) \log f_{d-1}(P) \ge \gamma d"/>, for some universal constant <img alt="\gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\gamma"/>.</li>
<li>A somewhat more general conjecture would be that the number of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k"/>-faces of the barycentric subdivision of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="K"/> is always as large as the number of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k"/>-faces of the barycentric subdivision of <img alt="C_d" class="latex" src="https://s0.wp.com/latex.php?latex=C_d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="C_d"/>. The case <img alt="k=0" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k=0"/> is the original conjecture and I regard the case <img alt="k=d-1" class="latex" src="https://s0.wp.com/latex.php?latex=k%3Dd-1&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="k=d-1"/> (sometimes referred to as the “flag-number conjecture”) as even closer to Mahler’s conjecture. See the paper by Schmidt and Ziegler, <a href="https://www.mi.fu-berlin.de/math/groups/discgeom/ziegler/Preprintfiles/127PREPRINT.pdf">Ten Problems in Geometry.</a></li>
<li>In <a href="https://arxiv.org/abs/0708.3661">this paper</a> by Raman Sanyal, Axel Werner, and Günter M. Ziegler, the conjecture is proved for <img alt="d \le 4" class="latex" src="https://s0.wp.com/latex.php?latex=d+%5Cle+4&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="d \le 4"/>. The proof is rather involved and rely on an extension of the lower bound theorem. (It does not extend to polyhedral spheres.)  The paper also gives counterexamples for two much stronger conjectures that I made in my 1989 paper.</li>
</ol>
<h3>Some further comments</h3>
<p><span id="more-20474"/></p>
<ol>
<li>Hanner polytopes form an exciting family of polytopes. They have the maximum Banach-Mazur distance from the Euclidean ball, and it is conjectured that only these polytopes attain this maximum. They also have the 2-3 Helly-property (namely every three pairwise intersecting translates have a point in common. It was proved by Lima and Jensen that this property holds only by Hanner polytopes!</li>
<li>The proof for the conjecture for d=4 involves the “extended lower bound inequality”.</li>
<li><span style="color: #0000ff;">Another conjecture of mine of a similar spirit is: a polyhedral d-manifold (more generally, a regular CW manifold) in dimension <em>d</em> which is not a sphere has at least <img alt="2^{(3d+4)/2}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B%283d%2B4%29%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="2^{(3d+4)/2}"/> faces. (Including the empty face.)</span></li>
<li>Flag <img alt="(d-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="(d-1)"/>-dimensional spheres also have at least <img alt="3^d" class="latex" src="https://s0.wp.com/latex.php?latex=3%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="3^d"/> faces. This follows from a theorem by Roy Meshulam.</li>
<li>Completely balanced <img alt="(d-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="(d-1)"/>-dimensional spheres also have at least <img alt="3^d" class="latex" src="https://s0.wp.com/latex.php?latex=3%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="3^d"/> faces. (I think.) (What about zonotopes, you may ask.)</li>
<li>The class of spheres in items 4 and 5 are simplicial. So an extensions of these classes to classes of polyhedral spheres (and regular CW spheres) would be interesting.</li>
<li>d-Polytopes with no triangular 2-faces also have at least <img alt="3^d" class="latex" src="https://s0.wp.com/latex.php?latex=3%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="3^d"/> non-empty faces this follows from a theorem of Blind and Blind.</li>
<li>Looking around in papers that referred to my old paper I discovered the following appealing class of polytopes and interesting conjecture about them. A polytope P is 2-level if for every facet F of P there is a hyperplane parallel to the hyperplane through F that contains all vertices not in F. The conjecture is that for such a d-polytope P, <img alt="f_0(P)f_{d-1}(P)\le d2^{d+1}" class="latex" src="https://s0.wp.com/latex.php?latex=f_0%28P%29f_%7Bd-1%7D%28P%29%5Cle+d2%5E%7Bd%2B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="f_0(P)f_{d-1}(P)\le d2^{d+1}"/>. This conjecture was made in the paper <a href="https://arxiv.org/abs/1703.01943">Enumeration of 2-level polytopes by</a>  Bohn,  Faenza,  Fiorini,  Fisikopoulos, Macchia, and Pashkovich. (<strong>Update:</strong> Giulia commented that the conjecture on 2-level polytopes by Bohn et al. was recently solved by Andrey Kupavskii and Stefan Weltge: <a href="https://arxiv.org/abs/2008.07153" rel="nofollow ugc">https://arxiv.org/abs/2008.07153</a>.)</li>
<li>Interesting classes of polytopes arising from graphs that are very near the conjecture can be found in the paper <a href="https://arxiv.org/abs/1201.5790" id="KdEkliExsEIJ"><span dir="ltr">Face numbers of centrally symmetric polytopes from split graphs</span>‏</a> by <span dir="ltr">Freij, Henze, Schmitt, and Ziegler. See also Independence complexes of perfect graphs by Freij and Henze in <a href="https://gilkalai.files.wordpress.com/2021/01/documents05_vol3.pdf">this report</a>.</span></li>
</ol>
<p><strong>Update (Jan 12,2021):</strong> Looking at old correspondence with Ragnar Freij, Matthias Henze, and Günter Ziegler, I came across the following conjecture that related the flag number conjecture and Mahler’s conjecture. Let P be a centrally symmetric d-polytope. Let <img alt="1+m(P)=vol(K)/vol(K*)/ (4^d/d!)" class="latex" src="https://s0.wp.com/latex.php?latex=1%2Bm%28P%29%3Dvol%28K%29%2Fvol%28K%2A%29%2F+%284%5Ed%2Fd%21%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="1+m(P)=vol(K)/vol(K*)/ (4^d/d!)"/>, and let <img alt="1+fn(P)=mf(P)/(2^dd!)." class="latex" src="https://s0.wp.com/latex.php?latex=1%2Bfn%28P%29%3Dmf%28P%29%2F%282%5Edd%21%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="1+fn(P)=mf(P)/(2^dd!)."/> For a centrally symmetric $d$-polytope <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="P"/>, Mahler’s conjecture asserts that <img alt="m(P) \ge 0" class="latex" src="https://s0.wp.com/latex.php?latex=m%28P%29+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="m(P) \ge 0"/> and the flag number conjecture asserts that <img alt="fn(P) \ge 0" class="latex" src="https://s0.wp.com/latex.php?latex=fn%28P%29+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="fn(P) \ge 0"/>.</p>
<h3 style="text-align: center;"><strong>Conjecture:</strong>  fn(<em>P</em>) ≥ 4 m(<em>P</em>)</h3>
<p>It is also conjectured that equality holds for Jensen’s polytopes of perfect graphs.</p>
<p> </p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2021-01-10T15:23:15Z</updated>
    <published>2021-01-10T15:23:15Z</published>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Geometry"/>
    <category term="Open problems"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2021-01-26T03:37:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/003</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/003" rel="alternate" type="text/html"/>
    <title>TR21-003 |  Inverse-Exponential Correlation Bounds and Extremely Rigid Matrices from a New Derandomized XOR Lemma | 

	Lijie Chen, 

	Xin Lyu</title>
    <summary>In this work we prove that there is a function $f \in \textrm{E}^\textrm{NP}$ such that, for every sufficiently large $n$ and $d = \sqrt{n}/\log n$, $f_n$ ($f$ restricted to $n$-bit inputs) cannot be $(1/2 + 2^{-d})$-approximated by $\textrm{F}_2$-polynomials of degree $d$. We also observe that a minor improvement (e.g., improving $d$ to $n^{1/2+\varepsilon}$ for any $\varepsilon &gt; 0$) over our result will imply $\textrm{E}^\textrm{NP}$ cannot be computed by depth-$3$ $\textrm{AC}^0$-circuits of $2^{n^{1/2 + \varepsilon}}$ size, which is a notoriously hard open question in complexity theory. 
	
	Using the same proof techniques, we are also able to construct extremely rigid matrices over $\textrm{F}_2$ in $\textrm{P}^\textrm{NP}$. More specifically, we show that for every constant $\varepsilon \in (0,1)$, there is a $\textrm{P}^\textrm{NP}$ algorithm which on input $1^n$ outputs an $n\times n$ $\textrm{F}_2$-matrix $H_n$ satisfying $\mathcal{R}_{H_n}(2^{\log^{1 - \varepsilon} n}) \ge (1/2 - \exp(-\log^{2/3 \cdot \varepsilon} n) ) \cdot n^2$, for every sufficiently large $n$. This improves the recent $\textrm{P}^\textrm{NP}$ constructions of rigid matrices in [Alman and Chen, FOCS 2019] and [Bhangale et al., FOCS 2020], which only gives  $\Omega(n^2)$ rigidity.
	
	The key ingredient in the proof of our new results is a new derandomized XOR lemma based on approximate linear sums, which roughly says that given an $n$-input function $f$ which cannot be $0.99$-approximated by certain linear sum of $s$ many functions in $\mathcal{F}$ within $\ell_1$-distance, one can construct a new function $\textrm{Amp}^f$ with $\widetilde{O}(n)$ input bits, which cannot be $(1/2+s^{\Omega(1)})$-approximated by $\mathcal{F}$-functions. Taking $\mathcal{F}$ to be a function collection containing low-degree $\textrm{F}_2$-polynomials or low-rank $\textrm{F}_2$-matrices, our results are then obtained by first using the algorithmic method to construct a function which is weakly hard against linear sums of $\mathcal{F}$ in the above sense, and then apply the derandomized XOR lemma to $f$.
	
	We obtain our new derandomized XOR lemma by giving a generalization of the famous hardcore lemma by Impagliazzo. Our generalization in some sense constructs a non-Boolean hardcore of a weakly hard function $f$ with respect to $\mathcal{F}$-functions, from the weak inapproximability of $f$ by any linear sum of $\mathcal{F}$ with bounded $\ell_p$-norm. This generalization recovers the original hardcore lemma by considering the $\ell_{\infty}$-norm. Surprisingly, when we switch to the $\ell_1$-norm, we immediately rediscover Levin's proof of Yao's XOR Lemma. That is, these first two proofs of Yao's XOR Lemma can be unified with our new perspective. For proving the correlation bounds, our new derandomized XOR lemma indeed works with the $\ell_{4/3}$-norm.</summary>
    <updated>2021-01-08T21:03:46Z</updated>
    <published>2021-01-08T21:03:46Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-01-26T03:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/002</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/002" rel="alternate" type="text/html"/>
    <title>TR21-002 |  Fooling Constant-Depth Threshold Circuits | 

	Pooya Hatami, 

	William Hoza, 

	Avishay Tal, 

	Roei Tell</title>
    <summary>We present new constructions of pseudorandom generators (PRGs) for two of the most widely-studied non-uniform circuit classes in complexity theory. Our main result is a construction of the first non-trivial PRG for linear threshold (LTF) circuits of arbitrary constant depth and super-linear size. This PRG fools circuits with depth $d\in\mathbb{N}$ and $n^{1+\delta}$ wires, where $\delta = 2^{-O(d)}$, using seed length $O(n^{1-\delta})$ and with error $2^{-n^{\delta}}$. This tightly matches the best known lower bounds for this circuit class. As a consequence of our result, all the known hardness for LTF circuits has now effectively been translated into pseudorandomness. This brings the extensive effort in the last decade to construct PRGs and deterministic circuit-analysis algorithms for this class to the point where any subsequent improvement would yield breakthrough lower bounds.
    
Our second contribution is a PRG for De Morgan formulas of size $s$ whose seed length is $s^{1/3+o(1)} \cdot \mathrm{polylog}(1/\epsilon)$ for error $\epsilon$. In particular, our PRG can fool formulas of sub-cubic size $s=n^{3-\Omega(1)}$ with an exponentially small error $\epsilon=\exp({-n^{\Omega(1)}})$. This significantly improves the inverse-polynomial error of the previous state-of-the-art for such formulas by Impagliazzo, Meka, and Zuckerman (FOCS 2012), and again tightly matches the best currently-known lower bounds for this class.
    
In both settings, a key ingredient in our constructions is a pseudorandom restriction procedure that has tiny failure probability, but simplifies the function to a non-natural "hybrid computational model" that combines several computational models. As part of our proofs we also construct "extremely low-error" PRGs for related circuit classes; for example, we construct a PRG for the class of functions computable by an arbitrary function of $s$ linear threshold functions that can handle even the extreme setting of parameters $s=n/\mathrm{polylog}(n)$ and $\epsilon=2^{-n/\mathrm{polylog}(n)}$.</summary>
    <updated>2021-01-08T21:01:25Z</updated>
    <published>2021-01-08T21:01:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-01-26T03:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/01/08/samuel-eilenberg-assistant-professor-at-university-of-warsaw-apply-by-february-12-2020/</id>
    <link href="https://cstheory-jobs.org/2021/01/08/samuel-eilenberg-assistant-professor-at-university-of-warsaw-apply-by-february-12-2020/" rel="alternate" type="text/html"/>
    <title>Samuel Eilenberg Assistant Professor at University of Warsaw (apply by February 12, 2020)</title>
    <summary>The Faculty of Mathematics, Informatics and Mechanics at University of Warsaw (MIM UW) invites applications for positions of an assistant professor (“adiunkt” in Polish) in Computer Science, starting on 1st October 2021 (or 1st Feb 2022). Note: compared to a standard assistant professor position, Samuel Eilenberg Assistant Professor comes with reduced teaching load and increased […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Faculty of Mathematics, Informatics and Mechanics at University of Warsaw (MIM UW) invites applications for positions of an assistant professor (“adiunkt” in Polish) in Computer Science, starting on 1st October 2021 (or 1st Feb 2022).</p>
<p>Note: compared to a standard assistant professor position, Samuel Eilenberg Assistant Professor comes with reduced teaching load and increased salary.</p>
<p>Website: <a href="https://www.mimuw.edu.pl/sites/default/files/konkursy/wmim_1210_ek_01_2021_en.pdf">https://www.mimuw.edu.pl/sites/default/files/konkursy/wmim_1210_ek_01_2021_en.pdf</a><br/>
Email: kowalik@mimuw.edu.pl</p></div>
    </content>
    <updated>2021-01-08T17:14:00Z</updated>
    <published>2021-01-08T17:14:00Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-01-26T03:37:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/01/08/assistant-professor-at-university-of-warsaw-apply-by-february-12-2021/</id>
    <link href="https://cstheory-jobs.org/2021/01/08/assistant-professor-at-university-of-warsaw-apply-by-february-12-2021/" rel="alternate" type="text/html"/>
    <title>Assistant professor at University of Warsaw (apply by February 12, 2021)</title>
    <summary>The Faculty of Mathematics, Informatics and Mechanics at University of Warsaw (MIM UW) invites applications for positions of an assistant professor (“adiunkt” in Polish) in Computer Science, starting on 1st October 2021 (or 1st Feb 2022). Website: https://www.mimuw.edu.pl/sites/default/files/konkursy/wmim_1210_ek_03_2021_en.pdf Email: kowalik@mimuw.edu.pl</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Faculty of Mathematics, Informatics and Mechanics at University of Warsaw (MIM UW) invites applications for positions of an assistant professor (“adiunkt” in Polish) in Computer Science, starting on 1st October 2021 (or 1st Feb 2022).</p>
<p>Website: <a href="https://www.mimuw.edu.pl/sites/default/files/konkursy/wmim_1210_ek_03_2021_en.pdf">https://www.mimuw.edu.pl/sites/default/files/konkursy/wmim_1210_ek_03_2021_en.pdf</a><br/>
Email: kowalik@mimuw.edu.pl</p></div>
    </content>
    <updated>2021-01-08T17:11:22Z</updated>
    <published>2021-01-08T17:11:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-01-26T03:37:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5247</id>
    <link href="https://www.scottaaronson.com/blog/?p=5247" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5247#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5247" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">To all Trumpists who comment on this blog</title>
    <summary xml:lang="en-US">The violent insurrection now unfolding in Washington DC is precisely the thing you called me nuts, accused me of “Trump Derangement Syndrome,” for warning about since 2016. Crazy me, huh, always seeing brownshirts around the corner? And you called the other side violent anarchists? This is all your doing. So own it. Wallow in it. […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>The violent insurrection now unfolding in Washington DC is precisely the thing you called me nuts, accused me of “Trump Derangement Syndrome,” for warning about since 2016.  Crazy me, huh, always seeing brownshirts around the corner?  And you called the <em>other</em> side violent anarchists?  This is all your doing.  So own it.  Wallow in it.  May you live the rest of your lives in shame.</p>



<p><strong><span class="has-inline-color has-vivid-red-color">Update (Jan. 7):</span></strong> As someone who hasn’t always agreed with BLM’s slogans and tactics, I viewed the stunning passivity of the police yesterday against white insurrectionists in the Capitol as one of the strongest arguments imaginable for BLM’s main contentions.</p></div>
    </content>
    <updated>2021-01-06T21:01:45Z</updated>
    <published>2021-01-06T21:01:45Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-01-22T04:09:45Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-44450853695391906</id>
    <link href="https://blog.computationalcomplexity.org/feeds/44450853695391906/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/01/my-survey-on-hilberts-10th-for.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/44450853695391906" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/44450853695391906" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/01/my-survey-on-hilberts-10th-for.html" rel="alternate" type="text/html"/>
    <title>My Survey on Hilbert's 10th for particular (d,n) is  ready for you to help me on!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> Hilbert's 10th problem is  (in modern terminology) to find an algorithm that will, given a poly </p><p>p(x1,...,xn) in Z[x1,...,xn], determine if it has a solution in the integers. </p><p>This was shown undecidable by the combined efforts of Davis-Putnam-Robinson and Matiyasevich. </p><p>I posted <a href="https://blog.computationalcomplexity.org/2020/05/why-is-there-no-dn-grid-for-hilberts.html">here</a> about the question of: For which (d,n) is H10 undecidable when restricted to degree d and number of vars n?</p><p>I was  invited to make an article out of the blog post and what I learned from the comments  for  the Algorithms column of BEATCS. That first draft is</p><p><a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/h10_final.pdf">here</a><br/></p><p><br/></p><p>Did I miss an important reference? (Note- I had meant to get out Matiyasevich's book on H10 but have been unable to because of the Pandemic, so if you have it my have stuff I need to know.) </p><p>Did I misspell Matiyasevich? </p><p>Did I say something stupid?</p><p>Please leave comments or email me directly if you have suggestions. </p><p>Incidentally I am usually the one who is asking someone else to do an open problems column, a book review, a guest blog. Nice to be the askee instead of the asker for a change of pace. </p><p><br/></p></div>
    </content>
    <updated>2021-01-06T01:13:00Z</updated>
    <published>2021-01-06T01:13:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-01-25T18:51:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17976</id>
    <link href="https://rjlipton.wordpress.com/2021/01/05/predictions-for-2021/" rel="alternate" type="text/html"/>
    <title>Predictions For 2021</title>
    <summary>This year is a Blum integer, 43*47 2017 article, not via Zoom Allan Lichtman correctly predicted the 2020 presidential election, based on a 7-6 edge in “keys” to Joe Biden. His model, which he developed in 1981 with the late Vladimir Keilis-Borok, simply says that the incumbent party will lose the presidential election if 6 […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>This year is a Blum integer, 43*47</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2021/01/lichtman2017.png"><img alt="" class="alignright wp-image-17978" height="120" src="https://rjlipton.files.wordpress.com/2021/01/lichtman2017.png?w=180&amp;h=120" width="180"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">2017 <a href="https://bethesdamagazine.com/bethesda-magazine/march-april-2017/how-bethesdas-allan-lichtman-predicted-the-election-for-trump/">article</a>, not via Zoom</font></td>
</tr>
</tbody>
</table>
<p>
Allan Lichtman correctly predicted the 2020 presidential election, based on a 7-6 edge in “<a href="https://en.wikipedia.org/wiki/The_Keys_to_the_White_House">keys</a>” to Joe Biden. His model, which he <a href="https://www.pnas.org/content/78/11/7230">developed</a> in 1981 with the late Vladimir Keilis-Borok, simply says that the incumbent party will lose the presidential election if 6 or more keys go against them. It has been right in every election since 1984.</p>
<p>
Today we make some predictions for the new year, 2021.<br/>
<span id="more-17976"/></p>
<p>
Lichtman has not ventured a prediction for today’s Senate runoff elections in Georgia. Last November 19, he penned an <a href="https://thehill.com/opinion/campaign/526780-time-to-jettison-horse-race-polls">article</a> eviscerating the performance of poll aggregation in the November 3 election. We have considered writing a post about that and about statistical predictions during the pandemic, in the direction of taking more moderate assessments of how various polls, predictions, and policies have fared.</p>
<p>
Polls of today’s races currently show a 1–2 percentage point edge for the Democratic candidates, but there are multiple caveats: The difference is just about one standard deviation, well within the margin of error even after aggregation. The polls have gyrated with multiple lead flips this past month; two polls from the past few days collected <a href="https://projects.fivethirtyeight.com/georgia-senate-polls/?cid=rrpromo">here</a> show both Republican candidates tied or ahead. Many pollsters have <a href="https://fivethirtyeight.com/videos/why-many-pollsters-are-sitting-out-the-georgia-runoffs/">avoided</a> these races, and the five most recent polls all have sample sizes well under 1,000. The count beginning tonight may show a zigzag blue-to-red-to-“blur” shift for reasons of which votes are tallied when that we discussed generally <a href="https://rjlipton.wordpress.com/2020/11/03/the-election-night-time-warp/">here</a>.</p>
<p>
With that said, let us address non-election predictions.</p>
<p>
</p><p/><h2> Previous Predictions </h2><p/>
<p/><p>
Back in <a href="https://rjlipton.wordpress.com/2019/01/06/predictions-for-2019/">2019</a> we made some predictions that were easy:</p>
<ul>
<li>
<em>No circuit lower bound <img alt="{1000n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1000n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{1000n}"/> or better will be proved for SAT.</em> Well that’s a freebie. <p/>
</li><li>
<em>A computer scientist will win a Nobel Prize.</em> No—indeed, less close than other years. <p/>
</li><li>
<em>At least five claims that <img alt="{{\mathsf{P}=\mathsf{NP}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathsf%7BP%7D%3D%5Cmathsf%7BNP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{{\mathsf{P}=\mathsf{NP}}}"/> and five that <img alt="{{\mathsf{P} \neq \mathsf{NP}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathsf%7BP%7D+%5Cneq+%5Cmathsf%7BNP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{{\mathsf{P} \neq \mathsf{NP}}}"/> will be made.</em> Gerhard Woeginger’s claims <a href="https://www.win.tue.nl/~gwoegi/P-versus-NP.htm">page</a> is still paused at 2016, so we can only judge from our own window of communications made to us or commented in the blog. All we can say is that the number in each case is “order-of” <img alt="{5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{5}"/>. <p/>
</li><li>
<em>A “provably” secure crypto-system will be broken.</em> For this one we don’t have to check any claims. We just pocket the “yes” answer.
</li></ul>
<p>
We skipped 2020—maybe that was smart of us? Our point about predictions in 2019 was the importance of “<em>when</em>” as opposed to “<em>what</em>.” With regard to some predictions, we can take the pandemic is as a global postponement of “when.”</p>
<p>
We claim complete and ongoing timeliness with another 2019 prediction, however. In full, we wrote:</p>
<ul>
<li>
<em>Quantum supremacy will be proved—finally.</em> But be careful: there is a problem with this whole direction. See the next section.
</li></ul>
<p>
The section two years ago talked about the difficulties of proving such a claim. A claim was duly made in October 2019, which we evaluated <a href="https://rjlipton.wordpress.com/2019/10/27/quantum-supremacy-at-last/">here</a>, but arguments over “proof” have not abated. They have just recently been summarized by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/12/29/the-argument-against-quantum-computers-a-very-short-introduction/">here</a>, and also <a href="https://www.scottaaronson.com/blog/?p=5159">here</a> by Scott Aaronson in regard to an independent <a href="https://science.sciencemag.org/content/370/6523/1460">claim</a> by researchers from USTC in China.</p>
<p>
</p><p/><h2> Predictions for 2021 </h2><p/>
<p/><p>
Here are some new predictions for 2021. We will try and skip easy ones like the above. We will try to make some that are surprising. We’ve made predictions about evidence for life on exoplanets before; we do something different there too. We do not venture any about the course of the pandemic.</p>
<ol>
<li>
<em>Quantum algorithms: <img alt="{\mathsf{BQP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BBQP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{BQP}}"/> will be proved to be in sub-exponential time.</em> <p/>
</li><li>
<em>Further work with <a href="https://en.wikipedia.org/wiki/AlphaFold">AlphaFold</a> will lead to a proof of a sub-exponential time algorithm for protein folding.</em> <p/>
</li><li>
<em>In consequence or independently, a SAT algorithm will be discovered that runs in sub-exponential time, thereby refuting various forms of the Exponential Time Hypothesis.</em> What do we mean by “sub-exponential” time here? Dick says the time for the SAT algorithm will be <img alt="{2^{\sqrt{n}\log n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B%5Csqrt%7Bn%7D%5Clog+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{2^{\sqrt{n}\log n}}"/>. Ken more modestly says time <img alt="{2^{O(n/\log n)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7BO%28n%2F%5Clog+n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{2^{O(n/\log n)}}"/>. <p/>
</li><li>
<em>Another Clay prize problem (besides <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{P}}"/> versus <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\mathsf{NP}}"/>) will be claimed as solved, and then retracted.</em> <p/>
</li><li>
<em>A new kind of sorting network of size <img alt="{O(n \log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n+%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{O(n \log n)}"/> will be discovered, inspired by a connection to <img alt="{O(n\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{O(n\log n)}"/> integer <a href="https://rjlipton.wordpress.com/2019/03/29/integer-multiplication-in-nlogn-time/">multiplication</a><a>.</a></em><a> <p/>
</a></li><li><a>
<em>A new factoring algorithm will be discovered that beats the number field sieve.</em> <p/>
</a></li><li><a>
<em>A lower bound argument will show that clique requires formula size <img alt="{n^{10}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B10%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{n^{10}}"/> over the <img alt="{\vee,\wedge,\neg}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvee%2C%5Cwedge%2C%5Cneg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="{\vee,\wedge,\neg}"/> basis.</em> <p/>
</a></li><li><a>
<em>Significant chemical evidence will be observed for the existence of life on a</em> </a><a href="https://www.nytimes.com/2020/09/14/science/venus-life-clouds.html">non</a>–<a href="https://en.wikipedia.org/wiki/Perseverance_(rover)">exoplanet</a>. <p/>
</li><li>
<em>Dogs will reach 25% of the proficiency of cats at <a href="https://www.boredpanda.com/cat-and-dog-challenge/?utm_source=google&amp;utm_medium=organic&amp;utm_campaign=organic">navigating</a> home obstacle courses, but not before the third quarter of 2021.</em> <p/>
</li><li>
<em>Privacy-preserving apps for doodling during Zoom meetings will become hot sellers by midyear.</em>
</li></ol>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What are your predictions for 2021? </p>
<p/></font></font></div>
    </content>
    <updated>2021-01-05T20:25:13Z</updated>
    <published>2021-01-05T20:25:13Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Allen Lichtman"/>
    <category term="elections"/>
    <category term="exponential-time hypothesis"/>
    <category term="polls"/>
    <category term="predictions"/>
    <category term="quantum advantage"/>
    <category term="quantum supremacy"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2021-01-26T03:37:34Z</updated>
    </source>
  </entry>
</feed>
