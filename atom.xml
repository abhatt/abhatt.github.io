<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-07-03T16:21:40Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16070</id>
    <link href="https://rjlipton.wordpress.com/2019/07/03/mathematics-of-gerrymandering/" rel="alternate" type="text/html"/>
    <title>Mathematics of Gerrymandering</title>
    <summary>Can theory help? [ art: Bill Hennessy ] John Roberts is the Chief Justice of the United States. Today I will discuss the recent Supreme Court decision on gerrymandering. The 5-4 decision in Rucho v. Common Cause takes the courts out of deciding if redistricting was done fairly. Roberts, penning the majority argument, felt that […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Can theory help?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/07/03/mathematics-of-gerrymandering/unknown-124/" rel="attachment wp-att-16073"><img alt="" class="alignright size-full wp-image-16073" src="https://rjlipton.files.wordpress.com/2019/07/unknown.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ art: Bill Hennessy ]</font></td>
</tr>
</tbody>
</table>
<p>
John Roberts is the Chief Justice of the United States.</p>
<p>
Today I will discuss the recent Supreme Court <a href="https://www.scotusblog.com/case-files/cases/rucho-v-common-cause-2/">decision</a> on gerrymandering.</p>
<p>
The 5-4 decision in Rucho v. Common Cause takes the courts out of deciding if redistricting was done fairly. Roberts, penning the majority argument, felt that it was hard, if not impossible, for courts to determine whether districts were reasonably drawn. That is, whether partisan motives dominated when they were created.</p>
<p>
I will explain what <a href="https://en.wikipedia.org/wiki/Gerrymandering">gerrymandering</a> is, and how computational methods may play a role. I must add a takeaway: </p>
<blockquote><p><b> </b> <em> <i>The current view of computational methods to avoid gerrymandering may be based on incorrect assumptions.</i> </em>
</p></blockquote>
<p>More on this later.</p>
<p>
</p><p/><h2> How It Works </h2><p/>
<p/><p>
You probably know that gerrymandering is used, negatively, to describe creating voting districts that do not reflect the voters will. The term was coined as part of an attack on the then Governor of Massachusetts in 1812. Then district shapes looked like a salamander. Since his name was Elbridge Gerry, it became <i>gerrymandering</i>. He was a Democratic-Republican and was not re-elected. </p>
<p>
<a href="https://rjlipton.wordpress.com/2019/07/03/mathematics-of-gerrymandering/gerry/" rel="attachment wp-att-16071"><img alt="" class="aligncenter size-full wp-image-16071" src="https://rjlipton.files.wordpress.com/2019/07/gerry.png?w=600"/></a></p>
<p>
Here is a figure from our friends at Wikipedia that presents examples of gerrymandering. </p>
<p>
<a href="https://rjlipton.wordpress.com/2019/07/03/mathematics-of-gerrymandering/divide/" rel="attachment wp-att-16072"><img alt="" class="aligncenter  wp-image-16072" src="https://rjlipton.files.wordpress.com/2019/07/divide.png?w=270" width="270"/></a></p>
<p>
By redistricting in the above, one can achieve anything from districts all won by the majority, to most won by the majority. These examples, show how the party who controls the districts can control the outcome.</p>
<p>
Well that is an overstatement. They can control the believed leanings of the voters in the districts. In the above example, they can control how yellow a district is. Real life is complicated by other factors: </p>
<ol>
<li>
A candidate may win because they are just more popular. That is a green candidate could still win in a yellow district. <p/>
</li><li>
A candidate may win because of random fluctuations. If the voter margin is small enough, random fluctuations could change the “expected” outcome.
</li></ol>
<p>
The latter is a danger for gerrymanderers. This <a href="https://www.brennancenter.org/blog/what-is-extreme-gerrymandering">site</a> on gerrymandering says: </p>
<blockquote><p><b> </b> <em> The trick is not to spread your voters out so much that districts become vulnerable to flipping to the other party in the normal give and take of electoral politics. </em>
</p></blockquote>
<p>
</p><p/><h2> How We Model It </h2><p/>
<p/><p>
Since Roberts is not our intended audience we will use mathematical definitions. I am sure Roberts and the rest of the Supreme Court justices are smart, but we have our own methods. We do not use legal jargon such as “prima facie” and suspect they do not use math jargon like “prime” numbers.</p>
<p>
So let the yellow party have <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> fraction of the voters. Suppose the voters have to be divided into <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/> districts of the same size. A division is just a vector <img alt="{y=(y_{1},\dots,y_{d})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%3D%28y_%7B1%7D%2C%5Cdots%2Cy_%7Bd%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y=(y_{1},\dots,y_{d})}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  y_{1} + \cdots + y_{d} = 1, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y_%7B1%7D+%2B+%5Ccdots+%2B+y_%7Bd%7D+%3D+1%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  y_{1} + \cdots + y_{d} = 1, "/></p>
<p>and each <img alt="{y_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y_{i}}"/> is non-negative. For such a vector <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> the number that yellow <i>wins</i> is the number of indices <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  y_{k} \ge \frac{1}{2d}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y_%7Bk%7D+%5Cge+%5Cfrac%7B1%7D%7B2d%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  y_{k} \ge \frac{1}{2d}. "/></p>
<p>Note, we assume that <img alt="{1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/2}"/> of the voters makes a district a win. We can change this to strictly larger than <img alt="{1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/2}"/>, but will leave it for now.</p>
<blockquote><p><b>Definition 1</b> <em> Define <img alt="{{\rm MaxWin}(d, \alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+MaxWin%7D%28d%2C+%5Calpha%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\rm MaxWin}(d, \alpha)}"/> to the maximum over all <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{y}"/> of the number of wins; and define <img alt="{{\rm MinWin}(d, \alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\rm MinWin}(d, \alpha)}"/> to be the minimum number of wins. </em>
</p></blockquote>
<p>Note, we do not care who is doing the redistricting. Nor do we care about the geometry. For example 	</p>
<p align="center"><img alt="\displaystyle  {\rm MaxWin}(5, 0.60) = 5 \text{ and } {\rm MinWin}(5, 0.60) = 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MaxWin%7D%285%2C+0.60%29+%3D+5+%5Ctext%7B+and+%7D+%7B%5Crm+MinWin%7D%285%2C+0.60%29+%3D+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MaxWin}(5, 0.60) = 5 \text{ and } {\rm MinWin}(5, 0.60) = 1. "/></p>
<p>What can we say about these functions? Here are some simple observations.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> If <img alt="{\alpha \ge 0.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%5Cge+0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha \ge 0.5}"/>, then <img alt="{{\rm MaxWin}(d, \alpha) = d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+MaxWin%7D%28d%2C+%5Calpha%29+%3D+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\rm MaxWin}(d, \alpha) = d}"/>. Just place <img alt="{\alpha }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha }"/> fraction of the voters in each district.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> If <img alt="{\alpha &gt; 0.5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%3E+0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha &gt; 0.5}"/>, then <img alt="{{\rm MinWin}(d, \alpha) \ge 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%5Cge+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\rm MinWin}(d, \alpha) \ge 1}"/>. No matter how the districts are drawn there must be at least one where yellow has a majority. </p>
<p>
An advantage of these functions is that now we can discuss growth rates, not just present examples. A strength of theory is that we have replaced statements like “this algorithm is fast” by formulas for their running time. Another advantage is that these functions are <i>independent of geometry</i>. Previously I thought the dominating issue was how regions looked. Now I believe the issue is how close one gets to the best and worst case: <img alt="{\rm MaxWin}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crm+MaxWin%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rm MaxWin}"/> and <img alt="{\rm MinWin}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crm+MinWin%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rm MinWin}"/>. </p>
<blockquote><p><b>Lemma 2</b> <em> Suppose that <img alt="{\alpha &gt; 1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%3E+1%2F2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha &gt; 1/2}"/>. Then 	</em></p><em>
<p align="center"><img alt="\displaystyle  {\rm MinWin}(d, \alpha) = d-\lfloor 2(1-\alpha) d \rfloor " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%3D+d-%5Clfloor+2%281-%5Calpha%29+d+%5Crfloor+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MinWin}(d, \alpha) = d-\lfloor 2(1-\alpha) d \rfloor "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Let <img alt="{\beta = 1-\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta+%3D+1-%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta = 1-\alpha}"/>. Let’s create the arrangement that makes green win as many districts as possible. If <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/> regions are mostly green then that takes <img alt="{\frac{g}{2d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bg%7D%7B2d%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{g}{2d}}"/> of the <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/> green voters. This implies that 	</p>
<p align="center"><img alt="\displaystyle  \frac{g}{2d} \le \beta. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bg%7D%7B2d%7D+%5Cle+%5Cbeta.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{g}{2d} \le \beta. "/></p>
<p>So it follows 	</p>
<p align="center"><img alt="\displaystyle  g \le 2\beta d. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++g+%5Cle+2%5Cbeta+d.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  g \le 2\beta d. "/></p>
<p>This proves that <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/> is equal to <img alt="{\lfloor 2\beta d \rfloor}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clfloor+2%5Cbeta+d+%5Crfloor%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lfloor 2\beta d \rfloor}"/>. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
It may help to set <img alt="{\alpha = 1/2 + \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%3D+1%2F2+%2B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha = 1/2 + \epsilon}"/> where <img alt="{\epsilon&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon&gt;0}"/>. Let’s agree to ignore the rounding off and delete the floor and ceiling functions. Then 	</p>
<p align="center"><img alt="\displaystyle  {\rm MinWin}(d, \alpha) = d-2(1-\alpha) d " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%3D+d-2%281-%5Calpha%29+d+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MinWin}(d, \alpha) = d-2(1-\alpha) d "/></p>
<p>and so 	</p>
<p align="center"><img alt="\displaystyle  {\rm MinWin}(d, \alpha) = 2\epsilon d. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%3D+2%5Cepsilon+d.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MinWin}(d, \alpha) = 2\epsilon d. "/></p>
<p>Thus for <img alt="{\epsilon = 1/10}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3D+1%2F10%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon = 1/10}"/> we get that 	</p>
<p align="center"><img alt="\displaystyle  {\rm MaxWin}(d, \alpha) = d \text{ and } {\rm MinWin}(d, \alpha) = 0.2d. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+MaxWin%7D%28d%2C+%5Calpha%29+%3D+d+%5Ctext%7B+and+%7D+%7B%5Crm+MinWin%7D%28d%2C+%5Calpha%29+%3D+0.2d.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  {\rm MaxWin}(d, \alpha) = d \text{ and } {\rm MinWin}(d, \alpha) = 0.2d. "/></p>
<p>This says that independent of any geometry if yellow has a ten percent majority, then best case if they set the districts they could win all, and if green sets the districts the worst they can get is twenty percent of the districts.</p>
<p>
</p><p/><h2> How Algorithms Can Help </h2><p/>
<p/><p>
There is long-term and continuing interest in algorithms that automate redistricting. The hope is that automated systems will be able to create districts that are fair. A trouble with this research is that there is no universal notion of what makes districts fair. The mantra is: </p>
<blockquote><p><b> </b> <em> <i>A redistricting is fair if and only if the districts satisfies some geometric criterion</i>. </em>
</p></blockquote>
<p>An explicit statement from a <a href="https://bdistricting.com/about.html">site</a> on such algorithms is: </p>
<blockquote><p><b> </b> <em> <i>The best district map is the one where people have the lowest average distance to the center of their district</i>. </em>
</p></blockquote>
<p>Of course the name “gerrymandering” came from how districts looked. Somehow this enshrined the notion that districts must look right. I feel this could be wrong.</p>
<p>
Here is a quote from a recent <a href="http://district.cs.brown.edu">paper</a> on an algorithm for redistricting. </p>
<blockquote><p><b> </b> <em> We propose a method for redistricting, decomposing a geographical area into subareas, called districts, so that the populations of the districts are as close as possible and the districts are compact and contiguous. Each district is the intersection of a polygon with the geographical area. The polygons are convex and the average number of sides per polygon is less than six. </em>
</p></blockquote>
<p>The authors are Philip Klein and Neal Young, who are well known researchers on various aspects of algorithms. They do interesting work, their paper is interesting, but the assumption that geometry is the key I do not get.</p>
<p>
</p><p/><h2> How To Do Better? </h2><p/>
<p/><p>
I think that we need to go beyond geometry to understand and avoid gerrymandering. The connection between geometry and fairness is driven—I believe—by tradition. Voters in the same district probably want to be near each other. In the past being near each other was probably important, since travel was so difficult. Perhaps today location is less of an issue then it was before cars, phones, cell phones, internet access, and email. Perhaps districts can be fair and yet do not look good. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
An analogy to <a href="https://en.wikipedia.org/wiki/Fair_cake-cutting">cake cutting</a> may occur to you. Recall in the cake cutting problem success is <i>not</i> measured in how the pieces of the cake look. It is only measured by whether the parties cutting the cake are happy. Is there some way to push this analogy? I just came across a <a href="https://arxiv.org/pdf/1710.08781.pdf">paper</a> using the cake cutting method: <i>A Partisan Districting Protocol With Provably Nonpartisan Outcomes</i> by Wesley Pegden, Ariel Procaccia, and Dingli Yu. More in the future.</p>
<p>
Can algorithmic methods help? Is geometry the fundamental issue? </p></font></font></div>
    </content>
    <updated>2019-07-03T13:51:13Z</updated>
    <published>2019-07-03T13:51:13Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="cake-cutting"/>
    <category term="districts"/>
    <category term="fair"/>
    <category term="geometry"/>
    <category term="gerrymander"/>
    <category term="gerrymandering"/>
    <category term="reasonable"/>
    <category term="voters"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-07-03T16:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1136</id>
    <link href="https://ptreview.sublinear.info/?p=1136" rel="alternate" type="text/html"/>
    <title>News for June 2019</title>
    <summary>We’ve got four papers this month. A mix of distribution testing, matrix problems, and a different paper on the power of sampling. On the Complexity of Estimating the Effective Support Size, by Oded Goldreich (ECCC). In distribution testing, a classic problem is that of approximating the support size. By a (now) classic result of Valiant-Valiant, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We’ve got four papers this month. A mix of distribution testing, matrix problems, and a different paper on the power of sampling.</p>



<p><strong>On the Complexity of Estimating the Effective Support Size</strong>, by Oded Goldreich (<a href="https://eccc.weizmann.ac.il/report/2019/088/">ECCC</a>). In distribution testing, a classic problem is that of approximating the support size. By a (now) classic result of <a href="http://theory.stanford.edu/~valiant/papers/VV_stoc11.pdf">Valiant-Valiant</a>, the complexity of this problem is \(\Theta(n/\log n)\). This paper raises the question of approximating the “effective” support, and that too with more than just samples from the distribution. The \(\epsilon\)-support of discrete distribution \(\mathcal{D}\) is the smallest support among any distribution \(\mathcal{D}’\) such that \(\|\mathcal{D} – \mathcal{D}’\|_1 \leq \epsilon\) (or TV-distance). Denote this as \(supp_\epsilon(\mathcal{D})\). One can also consider a bicriteria version. Given approximation parameter \(f\) and thresholds \(\epsilon_1 &lt; \epsilon_2\), we need to provide a number in the range \([supp_{\epsilon_2}(\mathcal{D}), f\cdot supp_{\epsilon_1}(\mathcal{D})]\). The primary model studied allows for random samples and evaluation queries (where one gets the probability of any known element of the domain). In this model, for arbitrary \(\epsilon_1, \epsilon_2\), there is a continuum of algorithms, trading off query complexity with approximation. At one end, for \(f = O(\log n)\), the query complexity is \(\widetilde{O}(1/\epsilon_1)\). At the other end, for \(f=1\), the query complexity is \(O(\log^* n)\). (Here, \(n = supp_{\epsilon_1}(\mathcal{D})\).) There are lower bounds showing the necessity of evaluation queries for subpolynomial query complexities.</p>



<p><strong>Communication and Memory Efficient Testing of Discrete Distributions</strong>, by Ilias Diakonikolas, Themis Gouleakis, Daniel M. Kane, and Sankeerth Rao (<a href="https://arxiv.org/abs/1906.04709">arXiv</a>). This paper adds additional computational constraints to the distribution testing problem. In the streaming setting, the algorithm is only allowed a single pass over the random samples. It has \(m\) bits of storage, much smaller than \(n\), the distribution size. The aim is to minimize the number of samples required for uniformity (and closeness) testing. For uniformity testing in the streaming setting, the paper gives an algorithm that uses \(\widetilde{O}(m + n/m)\) samples. The standard collision algorithm requires \(\Theta(\sqrt{n})\) storage (to store the samples), while this result gives a non-trivial bound for \(m \ll \sqrt{n}\). There are lower bounds showing that these bounds are basically tight. In the distributed distribution testing problem, there are a number of processors, each holding \(\ell\) samples. A referee asks a question to the processor, whose answers are broadcast to everyone. The aim is to minimize communication cost. For uniformity testing in this setting, there is a protocol using \(O(\sqrt{n\log n/\ell})\) bits of communication. As a sanity check, note that for \(\ell = \sqrt{n}\), one processor could simply run the collision algorithm locally to report the result. </p>



<p><strong>Querying a Matrix through Matrix-Vector Products</strong> by Xiaoming Sun, David P. Woodruff, Guang Yang, and Jialin Zhang (<a href="https://arxiv.org/pdf/1906.05736.pdf">arXiv</a>). Consider \(n \times d\) matrix \(M\) over some field \(\mathbb{F}\). One gets access to this matrix through matrix-vector products, and wishes to test some matrix property. This is a natural model in many settings, and generalizes the classic setting of query access. A subtle point is that one can only right multiply with “query” vectors, and there are problems where left multiplication can change the complexity. (A nice example in the paper is testing if a square matrix is symmetric. With both left and right multiplications, this is easy, since we can directly access rows and columns. By only accessing columns, this is non-trivial.) This paper studies a number of problems, broadly classified as linear algebra problems, statistics problems, and graph problems. Some highlights are: testing symmetry can be done in \(O(1)\) queries, and the maximum eigenvalue can be approximated in \(O(\log n)\) queries adaptively (but there is an \(\Omega(n)\) non-adaptive lower bound). For graph problems, here’s an interesting discovery. If \(M\) is the adjacency matrix, connectivity requires \(\Omega(n/\log n)\) queries. But if \(M\) is the signed edge-vertex matrix, then this can be done in \(poly(\log n)\) queries. This paper provides a number of interesting directions and problems to study.</p>



<p><strong>The Adversarial Robustness of Sampling</strong> by Omri Ben-Eliezer and Eylon Yogev (arXiv). This isn’t a property testing paper, but how can one ignore a paper on understanding the power of sampling? It’s convenient to think of the following setting. An algorithm gets a stream of \(n\) numbers, and has to answer some questions about the stream (say, the median or other quantiles). The simplest strategy is to take a small random sample of the stream. But what if an adversary was generating the stream, depending on the current sample? Under what circumstances is the sample still “representative” of the stream? The specific results of this paper require getting into set systems and VC dimension, which I’ll leave for the sake of simplicity. Let’s go back to the median question. To get an approximate median, a constant number of samples suffice. A consequence of the main result is that if one takes \(O(\log n)\) samples, then this is robust to adversarial streams. On the other hand, lower bounds show that constant sized samples can be fooled by an adversary. The paper is a really interesting read, and is a nice take on “standard facts” that we take for granted.</p>



<p/></div>
    </content>
    <updated>2019-07-03T00:54:36Z</updated>
    <published>2019-07-03T00:54:36Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Seshadhri</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-07-03T01:30:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01495</id>
    <link href="http://arxiv.org/abs/1907.01495" rel="alternate" type="text/html"/>
    <title>Isomorphism Problem for $S_d$-graphs</title>
    <feedworld_mtime>1562112000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Deniz Ağaoğlu <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01495">PDF</a><br/><b>Abstract: </b>An $H$-graph is the intersection graph of connected subgraphs of a suitable
subdivision of a fixed graph $H$. We focus on $S_d$-graphs as a special case. A
graph $G$ is an $S_d$-graph when it is the intersection graph of connected
subgraphs of a subdivision of a fixed star $S_d$. It is useful to mention that,
for an $S_d$-graph $G$ with some proper maximal clique $C \in G$, each
connected component of $G-C$ is an interval graph and the partial order on the
connected components of $G-C$ has a chain cover of size $\leq d$. Considering
the recognition algorithm given by Chaplick et al., we give an FPT-time
algorithm to solve the isomorphism problem for $S_d$-graphs with bounded clique
size. Then, we give a polynomial time reduction to $S_d$-graph isomorphism from
the isomorphism problem for posets of width $d$. Finally, we show that the
graph isomorphism problem for $S_d$-graphs can be solved in FPT-time with
parameter $d$, even when the clique size is unbounded.
</p></div>
    </summary>
    <updated>2019-07-03T01:22:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01258</id>
    <link href="http://arxiv.org/abs/1907.01258" rel="alternate" type="text/html"/>
    <title>A hybrid algorithm framework for small quantum computers with application to finding Hamiltonian cycles</title>
    <feedworld_mtime>1562112000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ge:Yimin.html">Yimin Ge</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dunjko:Vedran.html">Vedran Dunjko</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01258">PDF</a><br/><b>Abstract: </b>Recent works have shown that quantum computers can polynomially speed up
certain SAT-solving algorithms even when the number of available qubits is
significantly smaller than the number of variables. Here we generalise this
approach. We present a framework for hybrid quantum-classical algorithms which
utilise quantum computers significantly smaller than the problem size. Given an
arbitrarily small ratio of the quantum computer to the instance size, we
achieve polynomial speedups for classical divide-and-conquer algorithms,
provided that certain criteria on the time- and space-efficiency are met. We
demonstrate how this approach can be used to enhance Eppstein's algorithm for
the cubic Hamiltonian cycle problem, and achieve a polynomial speedup for any
ratio of the number of qubits to the size of the graph.
</p></div>
    </summary>
    <updated>2019-07-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01243</id>
    <link href="http://arxiv.org/abs/1907.01243" rel="alternate" type="text/html"/>
    <title>Geometric Crossing-Minimization -- A Scalable Randomized Approach</title>
    <feedworld_mtime>1562112000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Radermacher:Marcel.html">Marcel Radermacher</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rutter:Ignaz.html">Ignaz Rutter</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01243">PDF</a><br/><b>Abstract: </b>We consider the minimization of edge-crossings in geometric drawings of
graphs $G=(V, E)$, i.e., in drawings where each edge is depicted as a line
segment. The respective decision problem is NP-hard [Bienstock, '91]. In
contrast to theory and the topological setting, the geometric setting did not
receive a lot of attention in practice. Prior work [Radermacher et al.,
ALENEX'18] is limited to the crossing-minimization in geometric graphs with
less than $200$ edges. The described heuristics base on the primitive operation
of moving a single vertex $v$ to its crossing-minimal position, i.e., the
position in $\mathbb{R}^2$ that minimizes the number of crossings on edges
incident to $v$.
</p>
<p>In this paper, we introduce a technique to speed-up the computation by a
factor of $20$. This is necessary but not sufficient to cope with graphs with a
few thousand edges. In order to handle larger graphs, we drop the condition
that each vertex $v$ has to be moved to its crossing-minimal position and
compute a position that is only optimal with respect to a small random subset
of the edges. In our theoretical contribution, we consider drawings that
contain for each edge $uv \in E$ and each position $p \in \mathbb{R}^2$ for $v$
$o(|E|)$ crossings. In this case, we prove that with a random subset of the
edges of size $\Theta(k \log k)$ the co-crossing number of a degree-$k$ vertex
$v$, i.e., the number of edge pairs $uv \in E, e \in E$ that do not cross, can
be approximated by an arbitrary but fixed factor $\delta$ with high
probability. In our experimental evaluation, we show that the randomized
approach reduces the number of crossings in graphs with up to $13\,000$ edges
considerably. The evaluation suggests that depending on the degree-distribution
different strategies result in the fewest number of crossings.
</p></div>
    </summary>
    <updated>2019-07-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01241</id>
    <link href="http://arxiv.org/abs/1907.01241" rel="alternate" type="text/html"/>
    <title>On the VC-dimension of convex sets and half-spaces</title>
    <feedworld_mtime>1562112000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grelier:Nicolas.html">Nicolas Grelier</a>, Saeed Gh. Ilchi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Miltzow:Tillmann.html">Tillmann Miltzow</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Smorodinsky:Shakhar.html">Shakhar Smorodinsky</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01241">PDF</a><br/><b>Abstract: </b>A family $S$ of convex sets in the plane defines a hypergraph $H = (S,E)$ as
follows. Every subfamily $S'\subset S$ defines a hyperedge of $H$ if and only
if there exists a halfspace $h$ that fully contains $S'$, and no other set of
$S$ is fully contained in $h$. In this case, we say that $h$ realizes $S'$. We
say a set $S$ is shattered, if all its subsets are realized. The VC-dimension
of a hypergraph $H$ is the size of the largest shattered set. We show that the
VC-dimension for \emph{pairwise disjoint} convex sets in the plane is bounded
by $3$, and this is tight. In contrast, we show the VC-dimension of convex sets
in the plane (not necessarily disjoint) is unbounded. We also show that the
VC-dimension is unbounded for pairwise disjoint convex sets in $\mathbb{R}^d$,
for $d\geq 3$. We focus on, possibly intersecting, segments in the plane and
determine that the VC-dimension is always at most $5$. And this is tight, as we
construct a set of five segments that can be shattered. We give two exemplary
applications. One for a geometric set cover problem and one for a range-query
data structure problem, to motivate our findings.
</p></div>
    </summary>
    <updated>2019-07-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01228</id>
    <link href="http://arxiv.org/abs/1907.01228" rel="alternate" type="text/html"/>
    <title>A Constant-Factor Approximation Algorithm for Vertex Guarding a WV-Polygon</title>
    <feedworld_mtime>1562112000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Stav Ashur, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Filtser:Omrit.html">Omrit Filtser</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Katz:Matthew_J=.html">Matthew J. Katz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01228">PDF</a><br/><b>Abstract: </b>The problem of vertex guarding a simple polygon was first studied by Subir K.
Ghosh (1987), who presented a polynomial-time $O(\log n)$-approximation
algorithm for placing as few guards as possible at vertices of a simple $n$-gon
$P$, such that every point in $P$ is visible to at least one of the guards.
Ghosh also conjectured that this problem admits a polynomial-time algorithm
with constant approximation ratio. Due to the centrality of guarding problems
in the field of computational geometry, much effort has been invested
throughout the years in trying to resolve this conjecture. Despite some
progress (surveyed below), the conjecture remains unresolved to date. In this
paper, we confirm the conjecture for the important case of weakly visible
polygons, by presenting a $(2+\varepsilon)$-approximation algorithm for
guarding such a polygon using vertex guards. A simple polygon $P$ is weakly
visible if it has an edge $e$, such that every point in $P$ is visible from
some point on $e$. We also present a $(2+\varepsilon)$-approximation algorithm
for guarding a weakly visible polygon $P$, where guards may be placed anywhere
on $P$'s boundary (except in the interior of the edge $e$). Finally, we present
a $3c$-approximation algorithm for vertex guarding a polygon $P$ that is weakly
visible from a chord, given a subset $G$ of $P$'s vertices that guards $P$'s
boundary whose size is bounded by $c$ times the size of a minimum such subset.
</p>
<p>Our algorithms are based on an in-depth analysis of the geometric properties
of the regions that remain unguarded after placing guards at the vertices to
guard the polygon's boundary. It is plausible that our results will enable
Bhattacharya et al. to complete their grand attempt to prove the original
conjecture, as their approach is based on partitioning the underlying simple
polygon into a hierarchy of weakly visible polygons.
</p></div>
    </summary>
    <updated>2019-07-03T01:28:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01218</id>
    <link href="http://arxiv.org/abs/1907.01218" rel="alternate" type="text/html"/>
    <title>Representing fitness landscapes by valued constraints to understand the complexity of local search</title>
    <feedworld_mtime>1562112000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaznatcheev:Artem.html">Artem Kaznatcheev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen:David_A=.html">David A. Cohen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jeavons:Peter_G=.html">Peter G. Jeavons</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01218">PDF</a><br/><b>Abstract: </b>Local search is widely used to solve combinatorial optimisation problems and
to model biological evolution, but the performance of local search algorithms
on different kinds of fitness landscapes is poorly understood. Here we
introduce a natural approach to modelling fitness landscapes using valued
constraints. This allows us to investigate minimal representations (normal
forms) and to consider the effects of the structure of the constraint graph on
the tractability of local search. First, we show that for fitness landscapes
representable by binary Boolean valued constraints there is a minimal necessary
constraint graph that can be easily computed. Second, we consider landscapes as
equivalent if they allow the same (improving) local search moves; we show that
a minimal normal form still exists, but is NP-hard to compute. Next we consider
the complexity of local search on fitness landscapes modelled by valued
constraints with restricted forms of constraint graph. In the binary Boolean
case, we prove that a tree-structured constraint graph gives a tight quadratic
bound on the number of improving moves made by any local search; hence, any
landscape that can be represented by such a model will be tractable for local
search. We build two families of examples to show that both the conditions in
our tractability result are essential. With domain size three, even just a path
of binary constraints can model a landscape with an exponentially long sequence
of improving moves. With a treewidth two constraint graph, even with a maximum
degree of three, binary Boolean constraints can model a landscape with an
exponentially long sequence of improving moves.
</p></div>
    </summary>
    <updated>2019-07-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01129</id>
    <link href="http://arxiv.org/abs/1907.01129" rel="alternate" type="text/html"/>
    <title>New Results for the Complexity of Resilience for Binary Conjunctive Queries with Self-Joins</title>
    <feedworld_mtime>1562112000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Freire:Cibele.html">Cibele Freire</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gatterbauer:Wolfgang.html">Wolfgang Gatterbauer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Immerman:Neil.html">Neil Immerman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meliou:Alexandra.html">Alexandra Meliou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01129">PDF</a><br/><b>Abstract: </b>The resilience of a Boolean query is the minimum number of tuples that need
to be deleted from the input tables in order to make the query false. A
solution to this problem immediately translates into a solution for the more
widely known problem of deletion propagation with source-side effects. In this
paper, we give several novel results on the hardness of the resilience problem
for $\textit{binary conjunctive queries with self-joins}$ (i.e. conjunctive
queries with relations of maximal arity 2) with one repeated relation. Unlike
in the self-join free case, the concept of triad is not enough to fully
characterize the complexity of resilience. We identify new structural
properties, namely chains, confluences and permutations, which lead to various
$NP$-hardness results. We also give novel involved reductions to network flow
to show certain cases are in $P$. Overall, we give a dichotomy result for the
restricted setting when one relation is repeated at most 2 times, and we cover
many of the cases for 3. Although restricted, our results provide important
insights into the problem of self-joins that we hope can help solve the general
case of all conjunctive queries with self-joins in the future.
</p></div>
    </summary>
    <updated>2019-07-03T01:21:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01117</id>
    <link href="http://arxiv.org/abs/1907.01117" rel="alternate" type="text/html"/>
    <title>Exploring Feasible Design Spaces for Heterogeneous Constraints</title>
    <feedworld_mtime>1562112000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mirzendehdel:Amir_M=.html">Amir M. Mirzendehdel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Behandish:Morad.html">Morad Behandish</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nelaturi:Saigopal.html">Saigopal Nelaturi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01117">PDF</a><br/><b>Abstract: </b>We demonstrate an approach of exploring design spaces to simultaneously
satisfy kinematics- and physics-based requirements. We present a classification
of constraints and solvers to enable postponing optimization as far down the
design workflow as possible. The solvers are organized into two broad classes
of design space 'pruning' and 'exploration' by considering the types of
constraints they can satisfy. We show that pointwise constraints define
feasible design subspaces that can be represented and computed as first-class
entities by their maximal feasible elements. The design space is pruned upfront
by intersecting maximal elements, without premature optimization. To solve for
other constraints, we apply topology optimization (TO), starting from the
pruned feasible space. The optimization is steered by a topological sensitivity
field (TSF) that measures the global changes in violation of constraints with
respect to local topological punctures. The TSF for global objective functions
is augmented with TSF for global constraints, and penalized/filtered to
incorporate local constraints, including set constraints converted to
differentiable (in)equality constraints. We demonstrate application of the
proposed workflow to nontrivial examples in design and manufacturing. Among
other examples, we show how to explore pruned design spaces via TO to
simultaneously satisfy physics-based constraints (e.g., minimize compliance and
mass) as well as kinematics-based constraints (e.g., maximize accessibility for
machining).
</p></div>
    </summary>
    <updated>2019-07-03T01:26:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01076</id>
    <link href="http://arxiv.org/abs/1907.01076" rel="alternate" type="text/html"/>
    <title>The Polynomial Complexity of Vector Addition Systems with States</title>
    <feedworld_mtime>1562112000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zuleger:Florian.html">Florian Zuleger</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01076">PDF</a><br/><b>Abstract: </b>Vector addition systems are an important model in theoretical computer
science and have been used in a variety of areas. In this paper, we consider
vector addition systems with states over a parameterized initial configuration.
For these systems, we are interested in the standard notion of computational
complexity, i.e., we want to understand the length of the longest trace for a
fixed vector addition system with states depending on the size of the initial
configuration. We show that the asymptotic complexity of a given vector
addition system with states is either $\Theta(N^k)$ for some computable integer
$k$, where $N$ is the size of the initial configuration, or at least
exponential. We further show that $k$ can be computed in polynomial time in the
size of the considered vector addition system. Finally, we show that $1 \le k
\le 2^n$, where $n$ is the dimension of the considered vector addition system.
</p></div>
    </summary>
    <updated>2019-07-03T01:22:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01032</id>
    <link href="http://arxiv.org/abs/1907.01032" rel="alternate" type="text/html"/>
    <title>On Slicing Sorted Integer Sequences</title>
    <feedworld_mtime>1562112000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pibiri:Giulio_Ermanno.html">Giulio Ermanno Pibiri</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01032">PDF</a><br/><b>Abstract: </b>Representing sorted integer sequences in small space is a central problem for
large-scale retrieval systems such as Web search engines. Efficient query
resolution, e.g., intersection or random access, is achieved by carefully
partitioning the sequences. In this work we describe and compare two different
partitioning paradigms: partitioning by cardinality and partitioning by
universe. Although the ideas behind such paradigms have been known in the
coding and algorithmic community since many years, inverted index compression
has extensively adopted the former paradigm, whereas the latter has received
only little attention. As a result, an experimental comparison between these
two is missing for the setting of inverted index compression. We also propose
and implement a solution that recursively slices the universe of representation
of a sequence to achieve compact storage and attain to fast query execution.
Albeit larger than some state-of-the-art representations, this slicing approach
substantially improves the performance of list intersections and unions while
operating in compressed space, thus offering an excellent space/time trade-off
for the problem.
</p></div>
    </summary>
    <updated>2019-07-03T01:25:23Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01018</id>
    <link href="http://arxiv.org/abs/1907.01018" rel="alternate" type="text/html"/>
    <title>Information Kernels</title>
    <feedworld_mtime>1562112000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Epstein:Samuel.html">Samuel Epstein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01018">PDF</a><br/><b>Abstract: </b>Given a set X of finite strings, one interesting question to ask is whether
there exists a member of X which is simple conditional to all other members of
X. Conditional simplicity is measured by low conditional Kolmogorov complexity.
We prove the affirmative to this question for sets that have low mutual
information with the halting sequence. There are two results with respect to
this question. One is dependent on the maximum conditional complexity between
two elements of X, the other is dependent on the maximum expected value of the
conditional complexity of a member of X relative to each member of X.
</p></div>
    </summary>
    <updated>2019-07-03T01:20:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01006</id>
    <link href="http://arxiv.org/abs/1907.01006" rel="alternate" type="text/html"/>
    <title>Enumeration of Preferred Extensions in Almost Oriented Digraphs</title>
    <feedworld_mtime>1562112000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gaspers:Serge.html">Serge Gaspers</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Ray.html">Ray Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01006">PDF</a><br/><b>Abstract: </b>In this paper, we present enumeration algorithms to list all preferred
extensions of an argumentation framework. This task is equivalent to
enumerating all maximal semikernels of a directed graph. For directed graphs on
$n$ vertices, all preferred extensions can be enumerated in $O^*(3^{n/3})$ time
and there are directed graphs with $\Omega(3^{n/3})$ preferred extensions. We
give faster enumeration algorithms for directed graphs with at most
$0.8004\cdot n$ vertices occurring in $2$-cycles. In particular, for oriented
graphs (digraphs with no 2-cycles) one of our algorithms runs in time
$O(1.2321^n)$, and we show that there are oriented graphs with $\Omega(3^{n/6})
&gt; \Omega(1.2009^n)$ preferred extensions.
</p>
<p>A combination of three algorithms leads to the fastest enumeration times for
various proportions of the number of vertices in $2$-cycles. The most
innovative one is a new 2-stage sampling algorithm, combined with a new
parameterized enumeration algorithm, analyzed with a combination of the recent
monotone local search technique (STOC 2016) and an extension thereof (ICALP
2017).
</p></div>
    </summary>
    <updated>2019-07-03T01:22:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01005</id>
    <link href="http://arxiv.org/abs/1907.01005" rel="alternate" type="text/html"/>
    <title>Algorithms and data structures for matrix-free finite element operators with MPI-parallel sparse multi-vectors</title>
    <feedworld_mtime>1562112000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Davydov:Denis.html">Denis Davydov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kronbichler:Martin.html">Martin Kronbichler</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01005">PDF</a><br/><b>Abstract: </b>Traditional solution approaches for problems in quantum mechanics scale as
$\mathcal O(M^3)$, where $M$ is the number of electrons. Various methods have
been proposed to address this issue and obtain linear scaling $\mathcal O(M)$.
One promising formulation is the direct minimization of energy. Such methods
take advantage of physical localization of the solution, namely that the
solution can be sought in terms of non-orthogonal orbitals with local support.
In this work a numerically efficient implementation of sparse parallel vectors
within the open-source finite element library deal.II is proposed. The main
algorithmic ingredient is the matrix-free evaluation of the Hamiltonian
operator by cell-wise quadrature. Based on an a-priori chosen support for each
vector we develop algorithms and data structures to perform (i) matrix-free
sparse matrix multivector products (SpMM), (ii) the projection of an operator
onto a sparse sub-space (inner products), and (iii) post-multiplication of a
sparse multivector with a square matrix. The node-level performance is analyzed
using a roofline model. Our matrix-free implementation of finite element
operators with sparse multivectors achieves the performance of 157 GFlop/s on
Intel Cascade Lake architecture. Strong and weak scaling results are reported
for a typical benchmark problem using quadratic and quartic finite element
bases.
</p></div>
    </summary>
    <updated>2019-07-03T01:22:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.01004</id>
    <link href="http://arxiv.org/abs/1907.01004" rel="alternate" type="text/html"/>
    <title>Symmetry Detection and Classification in Drawings of Graphs</title>
    <feedworld_mtime>1562112000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Luca:Felice_De.html">Felice De Luca</a>, Md Iqbal Hossain, Stephen Kobourov <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.01004">PDF</a><br/><b>Abstract: </b>Symmetry is a key feature observed in nature (from flowers and leaves, to
butterflies and birds) and in man-made objects (from paintings and sculptures,
to manufactured objects and architectural design). Rotational, translational,
and especially reflectional symmetries, are also important in drawings of
graphs. Detecting and classifying symmetries can be very useful in algorithms
that aim to create symmetric graph drawings and in this paper we present a
machine learning approach for these tasks. Specifically, we show that deep
neural networks can be used to detect reflectional symmetries with 92%
accuracy. We also build a multi-class classifier to distinguish between
reflectional horizontal, reflectional vertical, rotational, and translational
symmetries. Finally, we make available a collection of images of graph drawings
with specific symmetric features that can be used in machine learning systems
for training, testing and validation purposes. Our datasets, best trained ML
models, source code are available online.
</p></div>
    </summary>
    <updated>2019-07-03T01:26:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8952301722851173857</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8952301722851173857/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8952301722851173857" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8952301722851173857" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html" rel="alternate" type="text/html"/>
    <title>Local Kid Makes History</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="separator" style="clear: both; text-align: center;">
</div>
<a href="https://1.bp.blogspot.com/-OpUgtDyqMf0/XRuOhVHWTFI/AAAAAAABplw/Tz0jTV3EQCo9w0aZ1bsI9xsJiec3OfytgCLcBGAs/s1600/Huang.jpg" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img border="0" height="200" src="https://1.bp.blogspot.com/-OpUgtDyqMf0/XRuOhVHWTFI/AAAAAAABplw/Tz0jTV3EQCo9w0aZ1bsI9xsJiec3OfytgCLcBGAs/s200/Huang.jpg" width="163"/></a>The <a href="https://www.scottaaronson.com/blog/?p=4229">blogosphere</a> is <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">blowing</a> <a href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/">up</a> over Hao Huang's just <a href="https://arxiv.org/abs/1907.00847">posted proof</a> of the sensitivity conjecture, what was one of the more <a href="https://blog.computationalcomplexity.org/2017/12/razors-edge.html">frustrating open questions</a> in complexity.<br/>
<br/>
Huang, an assistant professor in the math department at Emory, settled an open question about the hypercube. The hypercube is a graph on N=2<sup>n</sup> vertices where each vertex corresponds to an n-bit string and their are edges between vertices corresponding to strings that differ in a single bit. Think of the set of the strings of odd parity, N/2 vertices with no edges between them. Add any other vertex and it would have n neighbors. Huang showed that no matter how you placed those N/2+1 vertices in the hypercube, some vertex will have at least n<sup>1/2</sup> neighbors. By an <a href="https://doi.org/10.1016/0097-3165(92)90060-8">old result</a> of Gotsman and Linial, Huang's theorem implies the sensitivity conjecture.<br/>
<br/>
I won't go through the shockingly simple proof, the <a href="https://arxiv.org/abs/1907.00847">paper</a> is well written, or you can read the blogs I linked to above or even just Ryan O'Donnell's <a href="https://twitter.com/BooleanAnalysis/status/1145837576487612416">tweet</a>.<br/>
<br/>
I have nothing more to say than wow, just wow.</div>
    </content>
    <updated>2019-07-02T17:05:00Z</updated>
    <published>2019-07-02T17:05:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-03T13:51:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7530</id>
    <link href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/" rel="alternate" type="text/html"/>
    <title>Sensitivity conjecture proved!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-jetpack-markdown"><p>In a recent breakthrough, <a href="http://www.mathcs.emory.edu/~hhuan30/">Hao Huang</a> gave a <a href="https://arxiv.org/abs/1907.00847">6 page paper</a> proving the longstanding sensitivity conjecture. (Hat tip, <a href="https://www.scottaaronson.com/blog/?p=4229">Scott Aaronson</a> and <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">Gil Kalai</a>. See this <a href="https://cstheory.stackexchange.com/questions/27714/sensitivity-block-sensitivity-conjecture-implications">stackexchange post</a> and <a href="https://eccc.weizmann.ac.il/report/2016/062/">this paper of Avishai</a> for some links to the literature on this.)</p>
<p>The proof is beautiful and simple. I will write a few words here, but it is probably easier for you to just read the <a href="https://arxiv.org/abs/1907.00847">paper</a>. The sensitivity conjecture <a href="https://www.sciencedirect.com/science/article/pii/0097316592900608">was known</a> to follow from the following statement: let <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> be the <em>Boolean Cube</em> which is the degree <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> graph on <img alt="N=2^n" class="latex" src="https://s0.wp.com/latex.php?latex=N%3D2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N=2^n"/> vertices identified with <img alt="\{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\}^n"/> such that for every <img alt="x,y\in \{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in \{0,1\}^n"/>, <img alt="x \sim y" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Csim+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \sim y"/> if their Hamming distance is one. Then, the maximum degree of every subgraph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> of <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> of size <img alt="&gt;N/2" class="latex" src="https://s0.wp.com/latex.php?latex=%3EN%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="&gt;N/2"/> is at least <img alt="\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt{n}"/>.</p>
<p>Hao proves the above statement by showing that there is a <em>signing</em> of the <img alt="N\times N" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ctimes+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\times N"/> adjacency matrix of <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> that turns it into a matrix with <img alt="N/2" class="latex" src="https://s0.wp.com/latex.php?latex=N%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N/2"/> eigenvalues equaling <img alt="+\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%2B%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+\sqrt{n}"/> and <img alt="N/2" class="latex" src="https://s0.wp.com/latex.php?latex=N%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N/2"/> eigenvalues equaling <img alt="-\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=-%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-\sqrt{n}"/>. That is, he shows (using a simple but clever inductive argument, see the 5 line proof of his Lemma 2.2) that there is an <img alt="N\times N" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ctimes+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\times N"/> matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> with entries in <img alt="\{ 0, \pm 1 \}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B+0%2C+%5Cpm+1+%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{ 0, \pm 1 \}"/> whose nonzero entries correspond to the edges of the Boolean cube, and such that all the <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/> eigenvalues of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> are <img alt="\pm \sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm \sqrt{n}"/> and they sum up to zero. (Note that this makes sense since <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> should have the same <em>Frobenius norm</em> as  the adjacency matrix of <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/>. The Frobenius norm squared is both the sum of squares of entries, which is <img alt="N\cdot n" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ccdot+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\cdot n"/> for <img alt="G_n" class="latex" src="https://s0.wp.com/latex.php?latex=G_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_n"/> which is a degree <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> graph, and also equal to the sum of squares of the eigenvalues, which is <img alt="N\cdot n" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ccdot+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\cdot n"/> if all eigenvalues are <img alt="\pm \sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm+%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\pm \sqrt{n}"/>.)</p>
<p>Once you have such a signing, the result follows from <a href="https://en.wikipedia.org/wiki/Min-max_theorem#Cauchy_interlacing_theorem">Cauchy’s Interlace Theorem</a> that says that for every <img alt="N\times N" class="latex" src="https://s0.wp.com/latex.php?latex=N%5Ctimes+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N\times N"/> matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and any <img alt="M\times M" class="latex" src="https://s0.wp.com/latex.php?latex=M%5Ctimes+M&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M\times M"/> matrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> that is a principle sub-matrix of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>,</p>
<p><img alt="\lambda_{1+N-M}(A) \leq \lambda_1(B) \leq \lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_%7B1%2BN-M%7D%28A%29+%5Cleq+%5Clambda_1%28B%29+%5Cleq+%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_{1+N-M}(A) \leq \lambda_1(B) \leq \lambda_1(A)"/></p>
<p>where <img alt="\lambda_1(A) \geq \lambda_2(A) \cdots \geq \lambda_N(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28A%29+%5Cgeq+%5Clambda_2%28A%29+%5Ccdots+%5Cgeq+%5Clambda_N%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(A) \geq \lambda_2(A) \cdots \geq \lambda_N(A)"/> are the eigenvalues of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="\lambda_1(B)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B)"/> is the maximum eigenvalue of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>. A corollary of this (which is the only fact we need) is that if <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> has its top eigenvalue <img alt="\lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(A)"/> with multiplicity <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> (i.e., <img alt="\lambda_1(A)=\lambda_K(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28A%29%3D%5Clambda_K%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(A)=\lambda_K(A)"/>), then every principle sub-matrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> of order larger than <img alt="N-K" class="latex" src="https://s0.wp.com/latex.php?latex=N-K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N-K"/> will satisfy <img alt="\lambda_1(B) = \lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29+%3D+%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B) = \lambda_1(A)"/>. (In fact, we only need <img alt="\lambda_1(B) \geq \lambda_1(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29+%5Cgeq+%5Clambda_1%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B) \geq \lambda_1(A)"/>.)</p>
<p>Indeed, suppose that <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> is a subgraph of the Boolean cube of size <img alt="M&gt;N/2" class="latex" src="https://s0.wp.com/latex.php?latex=M%3EN%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M&gt;N/2"/>. Then the principle submatrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> corresponding to the vertices of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> satisfies <img alt="\lambda_1(B) \geq \lambda_{1+N-M}(A) = \sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda_1%28B%29+%5Cgeq+%5Clambda_%7B1%2BN-M%7D%28A%29+%3D+%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda_1(B) \geq \lambda_{1+N-M}(A) = \sqrt{n}"/> (since <img alt="M&gt;N/2" class="latex" src="https://s0.wp.com/latex.php?latex=M%3EN%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="M&gt;N/2"/> and the first <img alt="N/2" class="latex" src="https://s0.wp.com/latex.php?latex=N%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N/2"/> eigenvalues of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> are <img alt="+\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%2B%5Csqrt%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="+\sqrt{n}"/>).
But it’s easy to show that for every matrix <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> the maximum eigenvalue of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> is upper bounded by the maximum <img alt="\ell_1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_1"/> norm of its rows, which in our case is the maximum degree of the graph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/>.</p>
</div></div>
    </content>
    <updated>2019-07-02T16:18:34Z</updated>
    <published>2019-07-02T16:18:34Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-07-03T16:20:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3401</id>
    <link href="https://agtb.wordpress.com/2019/07/02/papafest-september-6-8-columbia/" rel="alternate" type="text/html"/>
    <title>PapaFest (September 6-8 @ Columbia)</title>
    <summary>Announcing a conference celebrating Christos Papadimitriou, September 6-8, 2019, at Columbia University.  Registration is free.  Confirmed invited speakers include: Sanjeev Arora, Michael Collins, Michael I. Jordan, Anna Karlin,  Jon Kleinberg, Elias Koutsoupias, Adi Livnat, Noam Nisan, Prabhakar Raghavan, Scott Shenker, Eva Tardos, John Tsitsiklis, Leslie Valiant, Umesh Vazirani, and Santosh Vempala. More details here. Advertisements</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Announcing a conference celebrating Christos Papadimitriou, September 6-8, 2019, at Columbia University.  Registration is free.  Confirmed invited speakers include: Sanjeev Arora, Michael Collins, Michael I. Jordan, Anna Karlin,  Jon Kleinberg, Elias Koutsoupias, Adi Livnat, Noam Nisan, Prabhakar Raghavan, Scott Shenker, Eva Tardos, John Tsitsiklis, Leslie Valiant, Umesh Vazirani, and Santosh Vempala.</p>
<p>More details <a href="http://papafest.cs.columbia.edu/">here.</a></p></div>
    </content>
    <updated>2019-07-02T12:47:57Z</updated>
    <published>2019-07-02T12:47:57Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>timroughgarden</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-07-03T16:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/07/02/the-autumn-school-on-machine-learning/</id>
    <link href="https://cstheory-events.org/2019/07/02/the-autumn-school-on-machine-learning/" rel="alternate" type="text/html"/>
    <title>The Autumn school on Machine Learning</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">October 3-11, 2019 Tbilisi, Georgia https://cte.ibsu.edu.ge/autumn/ Registration deadline: October 3, 2019 The school will be organized by the International Black Sea University with the support of Shota Rustaveli National Science Foundation of Georgia (SRNSFG). The intended audience of the autumn school includes BSc, MSc and PhD students, researchers as well as industry professionals from the … <a class="more-link" href="https://cstheory-events.org/2019/07/02/the-autumn-school-on-machine-learning/">Continue reading <span class="screen-reader-text">The Autumn school on Machine Learning</span></a></div>
    </summary>
    <updated>2019-07-02T09:09:23Z</updated>
    <published>2019-07-02T09:09:23Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-07-03T16:21:14Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-6337479962158243575</id>
    <link href="http://processalgebra.blogspot.com/feeds/6337479962158243575/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=6337479962158243575" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6337479962158243575" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/6337479962158243575" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/07/phd-position-at-tu-wirn-formal-methods.html" rel="alternate" type="text/html"/>
    <title>PhD position at TU Wirn: Formal methods applied to the specification and monitoring of large-scale, spatially-distributed, stochastic systems</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="_5pbx userContent _3576" id="js_3b"><i>Interesting PhD position at TU Wien with <a class="profileLink" href="http://www.eziobartocci.com/" title="Ezio Bartocci">Ezio Bartocci</a> and <a href="https://lauranenzi.github.io/">Laura Nenzi</a>. Spread the news! </i><br/><br/> The <a href="http://ti.tuwien.ac.at/">Institute of Computer Engineering</a> at the Technische Universität Wien (TU Wien) is seeking a candidate for a  research assistant position (PhD student, 4 years). The position is  available from September (a starting date until Fall 2019 is intended)  and the successful candidate will be a PhD student of the <a href="https://logic-cs.at/phd/">LogiCS Doctoral Program</a> and she/he will be supervised by Prof. Ezio Bartocci &lt;<a href="https://l.facebook.com/l.php?u=http%3A%2F%2Fwww.eziobartocci.com%2F%3Ffbclid%3DIwAR0DbRlQ3WbZCS1HzoZXYIRYXBsRDz2tCxE2G_6APz6K76RRDmLVMIkgBOg&amp;h=AT3xOIDKhxhBw2_daqAKot9Y3qtCNlITUpSxTEttEVYsbYoofL5LKQ7MD72mx8Nf3f0zPGNE5AY-FvqTQsTVZMllhO6DR94ug3vsjG3H84L4h8RDLdPWJxht8otBFNix1De-G1NEeihv6M6l-3cp" rel="noopener nofollow" target="_blank">http://www.eziobartocci.com/</a>&gt; and co-supervised by Dr. Laura Nenzi &lt;<a href="https://l.facebook.com/l.php?u=https%3A%2F%2Flauranenzi.github.io%2F%3Ffbclid%3DIwAR0O-FIXoCWcyMBVUqn5K-Ejd0vxQQJFYQ7ni1qBAdy9Ez01d6CDolZcb6U&amp;h=AT1RfdebNNlmUThAy2WWm6AclixjQ6sGfMnjrc5C-e4EbEglPtsVHAvYqJHIPfOZfHtYPGxz__so98GKEhDQZkGKQWB2z2fBom5MdlaCvrImUyjEZ5wotHeR5-w6sF4BkAIL-PGzihR9ZVsmSasc" rel="noopener nofollow" target="_blank">https://lauranenzi.github.io/</a>&gt;<br/> The successful applicant will carry out his/her PhD in the research  area of formal methods applied to the specification and monitoring of  large-scale, spatially-distributed, stochastic systems.<br/> The position in funded by the ÖAW and the FWF &lt;<a href="https://l.facebook.com/l.php?u=https%3A%2F%2Fm.fwf.ac.at%2Fen%2Fresearch-funding%2Fpersonnel-costs%2F%3Ffbclid%3DIwAR10rZDtpakXdwSo_WXE4A9GuFDbfkJoVYoCTgpZuBDmCMPVOmC8ZAo7Cyg&amp;h=AT13vFq0Svw4kLAe0VMNoonNMZyo8o6gdfK_-O0_LFJNhJavAH7Zt2YCyKMEKHuymeDiRrW6PggMAbBH0FyhcksLJJ0py3YWXi5vgwUwD0r_i3SFPvATFXhyZukxJL770ABLvhkdvgFQyiFvm5I8" rel="noopener nofollow" target="_blank">https://m.fwf.ac.at/en/research-funding/personnel-costs/</a>&gt;  for the recently acquired YIRG grant: “High-dimensional statistical  learning: new methods to advance economic and sustainability policies”,  an interdisciplinary project to be led for the TU part by PhD Laura  Nenzi.<br/> TASK DESCRIPTION (leader Laura Nenzi):   <br/> Formal  methods provide precise formal specification languages that can be  easily interpreted by humans and verification algorithms that can check  in an automatic way the value of satisfaction of interesting properties.  One of the main problems of such techniques is the curse of  dimensionality. A possibility to treat the problem is to use approximate  methods such as statistical model checking. However, even these  methodologies can be unfeasible for very-large-scale stochastic systems.  A new research line consists of exploiting machine learning techniques  and Bayesian inference to identify relevant data and decrease the  computational cost, permitting the application of such powerful formal  analysis on very complex systems. An important aspect that will be  covered in the study is the spatial configuration of such systems, a key  feature in several real case studies that are considering in the  project. The methodology will be principally applied to tackle questions  related to sustainable urban mobility and thus responsible consumption.<br/> APPLICATION<br/> Please apply your application following  the instructions in the DK LogiCS admission portal. <a href="https://l.facebook.com/l.php?u=https%3A%2F%2Flogic-cs.at%2Fphd%2Fadmission%2F%3Ffbclid%3DIwAR3oZZ1EmwtB7RHLErRrlbfY-HBeprkDbr8y-WyttxBelPGVrFY46hZuy3o&amp;h=AT2erabItYmdcemt5VHuXftBV82JOmliZPV-SIiYfhedKPgLyH9PR_pf1dJ3EHa-SQgsBTWJqgjsgzUJPauzRI4h_2t1t8Ci_NW6DannlCzLkriOSguTjs3IfU4p0eBWTTEvJmljKFMYpbZ36tKn" rel="noopener nofollow" target="_blank">https://logic-cs.at/phd/admission/</a> &lt;<a href="https://logic-cs.at/phd/admission/?fbclid=IwAR1rL9Zavpr2JH9oOonuC0OZ0wPUsoFxWi0usVFZPXQJzSJeSQr97rk490c" rel="noopener nofollow" target="_blank">https://logic-cs.at/phd/admission/</a>&gt;,  by indicating in the application form: Prof. Ezio Bartocci and Dr.  Laura Nenzi as supervisors. While it is not necessary to have the Master  degree at the moment of the application, it is instead mandatory to  complete it before starting the PhD.<br/> CONTACT DETAILS<br/> For  further information and inquiries about this post please contact Laura  Nenzi, e-mail: laura.nenzi@gmail.com  .</div></div>
    </content>
    <updated>2019-07-02T08:47:00Z</updated>
    <published>2019-07-02T08:47:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-07-02T12:00:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/07/02/papafest-for-christos-70th-birthday/</id>
    <link href="https://cstheory-events.org/2019/07/02/papafest-for-christos-70th-birthday/" rel="alternate" type="text/html"/>
    <title>PapaFest for Christos’ 70th birthday</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">September 6-8, 2019 Columbia University http://papafest.cs.columbia.edu/ We are happy to invite you to Columbia University to celebrate Christos Papadimitriou’s contributions to science on the occasion of his 70th birthday, through a mix of talks, panels, and fun activities. One of world’s leading computer scientists, Christos is best known for his work in computational complexity, helping … <a class="more-link" href="https://cstheory-events.org/2019/07/02/papafest-for-christos-70th-birthday/">Continue reading <span class="screen-reader-text">PapaFest for Christos’ 70th birthday</span></a></div>
    </summary>
    <updated>2019-07-02T08:32:49Z</updated>
    <published>2019-07-02T08:32:49Z</published>
    <category term="other"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-07-03T16:21:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4229</id>
    <link href="https://www.scottaaronson.com/blog/?p=4229" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4229#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4229" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Sensitivity Conjecture resolved</title>
    <summary xml:lang="en-US">The Sensitivity Conjecture, which I blogged about here, says that, for every Boolean function f:{0,1}n→{0,1}, the sensitivity of f—that is, the maximum, over all 2n input strings x∈{0,1}n, of the number of input bits such that flipping them changes the value of f—is at most polynomially smaller than a bunch of other complexity measures of […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Sensitivity Conjecture, which I blogged about <a href="https://www.scottaaronson.com/blog/?p=453">here</a>, says that, for every Boolean function f:{0,1}<sup>n</sup>→{0,1}, the <em>sensitivity</em> of f—that is, the maximum, over all 2<sup>n</sup> input strings x∈{0,1}<sup>n</sup>, of the number of input bits such that flipping them changes the value of f—is at most polynomially smaller than a bunch of other complexity measures of f, including f’s block sensitivity, degree as a real polynomial, and classical and quantum query complexities.  (For more, see for example <a href="http://www.cs.columbia.edu/~rocco/Teaching/S12/Readings/BdW.pdf">this survey</a> by Buhrman and de Wolf.  Or for quick definitions of the relevant concepts, <a href="https://cstheory.stackexchange.com/questions/19902/boolean-functions-where-sensitivity-equals-block-sensitivity">see here</a>.)</p>



<p>Ever since it was posed by Nisan and Szegedy in 1989, this conjecture has stood as one of the most frustrating and embarrassing open problems in all of combinatorics and theoretical computer science.  It seemed so easy, and so similar to other statements that had 5-line proofs.  But a lot of the best people in the field sank months into trying to prove it.  For whatever it’s worth, I also sank … well, at least weeks into it.</p>



<p>Now <a href="http://www.mathcs.emory.edu/~hhuan30/">Hao Huang</a>, a mathematician at Emory University, has posted a <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">6-page preprint</a> on his homepage that finally proves the Sensitivity Conjecture, in the form s(f)≥√deg(f).  (I thank Ryan O’Donnell for tipping me off to this.)  Within the preprint, the proof itself is about a page and a half.</p>



<p>Whenever there’s an announcement like this, ~99% of the time either the proof is wrong, or at any rate it’s way too complicated for outsiders to evaluate it quickly.  This is one of the remaining 1% of cases.  I’m rather confident that the proof is right.  Why?  Because I read and understood it.  It took me about half an hour.  If you’re comfortable with concepts like <em>induced subgraph</em> and <em>eigenvalue</em>, you can do the same.</p>



<p>From pioneering work by Gotsman and Linial in 1992, it was known that to prove the Sensitivity Conjecture, it suffices to prove the following even simpler combinatorial conjecture:</p>



<blockquote class="wp-block-quote"><p>Let S be any subset of the n-dimensional Boolean hypercube, {0,1}<sup>n</sup>, which has size 2<sup>n-1</sup>+1.  Then there must be a point in S with at least ~n<sup>c</sup> neighbors in S.</p></blockquote>



<p>Here c&gt;0 is some constant (say 1/2), and two points in S are “neighbors” if and only they differ in a single coordinate.  Note that if S had size 2<sup>n-1</sup>, then the above statement would be false—as witnessed, for example, by the set of all n-bit strings with an even number of 1’s.</p>



<p>Huang proceeds by proving the Gotsman-Linial Conjecture.  And the way he proves Gotsman-Linial is … well, at this point maybe I should just let you <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">read the damn preprint</a> yourself.  I can’t say it more simply than he does.</p>



<p>If I had to try anyway, I’d say: Huang constructs a 2<sup>n</sup>×2<sup>n</sup> matrix, called A<sub>n</sub>, that has 0’s where there are no edges between the corresponding vertices of the Boolean hypercube, and either 1’s or -1’s where there <em>are</em> edges—with a simple, weird pattern of 1’s and -1’s that magically makes everything work.  He then lets H be an induced subgraph of the Boolean hypercube of size 2<sup>n-1</sup>+1.  He lower-bounds the maximum degree of H by the largest eigenvalue of the corresponding (2<sup>n-1</sup>+1)×(2<sup>n-1</sup>+1) submatrix of A<sub>n</sub>.  Finally, he lower-bounds that largest eigenvalue by … no, I don’t want to spoil it!  Read it yourself!</p>



<p>Paul Erdös famously spoke of a book, maintained by God, in which was written the simplest, most beautiful proof of each theorem.  The highest compliment Erdös could give a proof was that it “came straight from the book.”  In this case, I find it hard to imagine that even God knows how to prove the Sensitivity Conjecture in any simpler way than this.</p>



<p>Indeed, the question is: how could such an elementary 1.5-page argument have been overlooked for 30 years?  I don’t have a compelling answer to that, besides noting that “short” and “elementary” often have little to do with “obvious.”  Once you start looking at the spectral properties of this matrix A<sub>n</sub>, the pieces snap together in precisely the right way—but how would you know to look at that?</p>



<p>By coincidence, earlier today I finished reading my first PG Wodehouse novel (<em><a href="http://www.gutenberg.org/files/10554/10554-h/10554-h.htm">Right Ho, Jeeves!</a></em>), on the gushing recommendation of a friend.  I don’t know how I’d missed Wodehouse for 38 years.  His defining talent is his ability to tie together five or six plot threads in a way that feels perfect and inevitable even though you didn’t see it coming.  This produces a form of pleasure that’s nearly indistinguishable from the pleasure one feels in reading a “proof from the book.”  So my pleasure centers are pretty overloaded today—but in such depressing times for the world, I’ll take pleasure wherever I can get it.</p>



<p>Huge congratulations to Hao!</p>



<p><strong>Added thought:</strong> What this really is, is one of the purest illustrations I’ve seen in my career of the power and glory of the P≠NP phenomenon.  We talk all the time about how proofs are easier to verify than to find.  In practice, though, it can be far from obvious that that’s true.  Consider your typical STOC/FOCS paper: writing it probably took the authors several months, while fully understanding the thing from scratch would probably take … <em>also</em> several months!  If there’s a gap, it’s only by a factor of 4 or 5 or something.  Whereas in this case, I don’t know how long Huang spent searching for the proof, but the combined search efforts of the community add up to years or decades.  The ratio of the difficulty of finding to the difficulty of completely grasping is in the hundreds of thousands or millions.</p>



<p><strong>Another added thought:</strong> Because Hao actually proves a stronger statement than the original Sensitivity Conjecture, it has additional implications, a few of which Hao mentions in his preprint.  Here’s one he didn’t mention: any randomized algorithm to guess the parity of an n-bit string, which succeeds with probability at least 2/3 on the majority of strings, must make at least ~√n queries to the string, while any such quantum algorithm must make at least ~n<sup>1/4</sup> queries.  For more, see the paper <a href="https://arxiv.org/pdf/1312.0036.pdf">Weak Parity</a> by me, Ambainis, Balodis, and Bavarian (Section 6).</p></div>
    </content>
    <updated>2019-07-02T05:15:43Z</updated>
    <published>2019-07-02T05:15:43Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-02T19:48:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17499</id>
    <link href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/" rel="alternate" type="text/html"/>
    <title>Amazing: Hao Huang Proved the Sensitivity Conjecture!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Today’s arXived amazing paper by Hao Huang’s Induced subgraphs of hypercubes and a proof of the Sensitivity Conjecture Contains an amazingly short and beautiful proof of a famous open problem from the theory of computing – the sensitivity conjecture posed … <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Today’s arXived amazing paper by Hao Huang’s</p>
<p><a href="https://arxiv.org/abs/1907.00847">Induced subgraphs of hypercubes and a proof of the Sensitivity Conjecture</a></p>
<p>Contains an amazingly short and beautiful proof of a famous open problem from the theory of computing – the sensitivity conjecture posed by Noam Nisan and Mario Szegedi</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/hao-huang-chicago.jpg"><img alt="" class="alignnone size-medium wp-image-17505" height="225" src="https://gilkalai.files.wordpress.com/2019/07/hao-huang-chicago.jpg?w=300&amp;h=225" width="300"/></a></p>
<p><span style="color: #ff0000;"><strong>Hao Huang</strong></span></p>
<p><strong>Abstract: </strong>In this paper, we show that every <img alt="2^{n-1}+1" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bn-1%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{n-1}+1"/>-vertex induced subgraph of the <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-dimensional cube graph has maximum degree at least <img alt="\sqrt n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sqrt n"/>. This result is best possible, and improves a logarithmic lower bound shown by Chung, Füredi, Graham and Seymour in 1988. As a direct consequence, we prove that the sensitivity and degree of a boolean function are polynomially related, solving an outstanding foundational problem in theoretical computer science, the Sensitivity Conjecture of Nisan and Szegedy.</p>
<p>The proof relies on important relation between the two problems  by Gotsman and Linial. It uses beautifully Cauchy’s interlace theorem (for eigenvalues).</p>
<p>Thanks to Noga Alon for telling me about the breakthrough. For more on the conjecture and a polymath project devoted to solve it see <a href="https://www.scottaaronson.com/blog/?p=453">this post</a> on Aaronson’s Shtetl Optimized (SO).  Updates: See also <a href="https://rjlipton.wordpress.com/2016/10/05/congratulations-noam/">this post on GLL</a>, and this <a href="https://www.scottaaronson.com/blog/?p=4229">new lovely post on SO;</a> and <a href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/">this post by Boaz Barak </a>on WOT (Window on Theory), explains the main ingredient of Huang’s proof. Here is <a href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html">a post by Lance Fortnow</a> on CC (Computational Complexity) mentioning a <a href="https://twitter.com/BooleanAnalysis/status/1145837576487612416">remarkable tweet</a> by Ryan O’Donnell (see below the fold).</p>
<p>Also today on the arXive a paper by <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pat%C3%A1kov%C3%A1%2C+Z">Zuzana (Zuzka) Patáková</a> and me: <a href="https://arxiv.org/abs/1907.00885">Intersection Patterns of Planar Sets</a>. Like one of my very first papers “Intersection patterns of convex sets” the new paper deals with face numbers of nerves of geometric sets.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/kp1.png"><img alt="" class="alignnone size-full wp-image-17510" src="https://gilkalai.files.wordpress.com/2019/07/kp1.png?w=640"/></a><span id="more-17499"/></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/kp2.png"><img alt="" class="alignnone size-full wp-image-17511" src="https://gilkalai.files.wordpress.com/2019/07/kp2.png?w=640"/></a></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/ro.png"><img alt="" class="alignnone size-full wp-image-17515" height="675" src="https://gilkalai.files.wordpress.com/2019/07/ro.png?w=640&amp;h=675" width="640"/></a></p></div>
    </content>
    <updated>2019-07-02T04:07:15Z</updated>
    <published>2019-07-02T04:07:15Z</published>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Hao Huang"/>
    <category term="sensitivity conjecture"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-03T16:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00872</id>
    <link href="http://arxiv.org/abs/1907.00872" rel="alternate" type="text/html"/>
    <title>Improved hardness for H-colourings of G-colourable graphs</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wrochna:Marcin.html">Marcin Wrochna</a>, Stanislav Živný <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00872">PDF</a><br/><b>Abstract: </b>We present new results on approximate colourings of graphs and, more
generally, approximate H-colourings and promise constraint satisfaction
problems.
</p>
<p>First, we show NP-hardness of colouring $k$-colourable graphs with
$\binom{k}{\lfloor k/2\rfloor}-1$ colours for every $k\geq 4$. This improves
the result of Bul\'in, Krokhin, and Opr\v{s}al [STOC'19], who gave NP-hardness
of colouring $k$-colourable graphs with $2k-1$ colours for $k\geq 3$, and the
result of Huang [APPROX-RANDOM'13], who gave NP-hardness of colouring
$k$-colourable graphs with $2^{k^{1/3}}$ colours for sufficiently large $k$.
Thus, for $k\geq 4$, we improve from known linear/sub-exponential gaps to
exponential gaps.
</p>
<p>Second, we show that the topology of the box complex of H alone determines
whether H-colouring of G-colourable graphs is NP-hard for all (non-bipartite,
H-colourable) G. This formalises the topological intuition behind the result of
Krokhin and Opr\v{s}al [FOCS'19] that 3-colouring of G-colourable graphs is
NP-hard for all (3-colourable, non-bipartite) G. We use this technique to
establish NP-hardness of H-colouring of G-colourable graphs for H that include
but go beyond $K_3$, including square-free graphs and circular cliques (leaving
$K_4$ and larger cliques open).
</p>
<p>Underlying all of our proofs is a very general observation that adjoint
functors give reductions between promise constraint satisfaction problems.
</p></div>
    </summary>
    <updated>2019-07-02T23:23:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00847</id>
    <link href="http://arxiv.org/abs/1907.00847" rel="alternate" type="text/html"/>
    <title>Induced subgraphs of hypercubes and a proof of the Sensitivity Conjecture</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Hao.html">Hao Huang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00847">PDF</a><br/><b>Abstract: </b>In this paper, we show that every $(2^{n-1}+1)$-vertex induced subgraph of
the $n$-dimensional cube graph has maximum degree at least $\sqrt{n}$. This
result is best possible, and improves a logarithmic lower bound shown by Chung,
F\"uredi, Graham and Seymour in 1988. As a direct consequence, we prove that
the sensitivity and degree of a boolean function are polynomially related,
solving an outstanding foundational problem in theoretical computer science,
the Sensitivity Conjecture of Nisan and Szegedy.
</p></div>
    </summary>
    <updated>2019-07-02T23:23:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00845</id>
    <link href="http://arxiv.org/abs/1907.00845" rel="alternate" type="text/html"/>
    <title>Graph-based Nearest Neighbor Search: From Practice to Theory</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Liudmila Prokhorenkova <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00845">PDF</a><br/><b>Abstract: </b>Graph-based approaches are empirically shown to be very successful for
approximate nearest neighbor (ANN) search. However, there has been very little
research on their theoretical guarantees. In this work, we consider both
low-dimensional (d &lt;&lt; log(n)) and high-dimensional (d &gt;&gt; log(n)) regimes and
rigorously analyze the performance of graph-based nearest neighbor algorithms
when the dataset is uniformly distributed on a d-dimensional sphere. For both
regimes, we provide the conditions which guarantee that a graph-based algorithm
solves the ANN problem in just one iteration. In the low-dimensional regime, we
also show that it is possible to solve the exact nearest neighbor problem.
Finally, we discuss how the "small-world" property affects the performance of
graph-based approaches.
</p></div>
    </summary>
    <updated>2019-07-02T23:43:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00817</id>
    <link href="http://arxiv.org/abs/1907.00817" rel="alternate" type="text/html"/>
    <title>The directed 2-linkage problem with length constraints</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bang=Jensen:J=oslash=rgen.html">Jørgen Bang-Jensen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bellitto:Thomas.html">Thomas Bellitto</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lochet:William.html">William Lochet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yeo:Anders.html">Anders Yeo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00817">PDF</a><br/><b>Abstract: </b>The {\sc weak 2-linkage} problem for digraphs asks for a given digraph and
vertices $s_1,s_2,t_1,t_2$ whether $D$ contains a pair of arc-disjoint paths
$P_1,P_2$ such that $P_i$ is an $(s_i,t_i)$-path. This problem is NP-complete
for general digraphs but polynomially solvable for acyclic digraphs
\cite{fortuneTCS10}. Recently it was shown \cite{bercziESA17} that if $D$ is
equipped with a weight function $w$ on the arcs
</p>
<p>which satisfies that all edges have positive weight, then there is a
polynomial algorithm for the variant of the weak-2-linkage problem when both
paths have to be shortest paths in $D$. In this paper we consider the unit
weight case and prove that for every pair constants $k_1,k_2$, there is a
polynomial algorithm which decides whether the input digraph $D$ has a pair of
arc-disjoint paths $P_1,P_2$ such that $P_i$ is an $(s_i,t_i)$-path and the
length of $P_i$ is no more than $d(s_i,t_i)+k_i$, for $i=1,2$, where
$d(s_i,t_i)$ denotes the length of the shortest $(s_i,t_i)$-path. We prove
that, unless the exponential time hypothesis (ETH) fails, there is no
polynomial algorithm for deciding the existence of a solution $P_1,P_2$ to the
{\sc weak 2-linkage} problem where each path $P_i$ has length at most
$d(s_i,t_i)+ c\log^{1+\epsilon}{}n$ for some constant $c$.
</p>
<p>We also prove that the {\sc weak 2-linkage} problem remains NP-complete if we
require one of the two paths to be a shortest path while the other path has no
restriction on the length.
</p></div>
    </summary>
    <updated>2019-07-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00676</id>
    <link href="http://arxiv.org/abs/1907.00676" rel="alternate" type="text/html"/>
    <title>Space-Efficient Vertex Separators for Treewidth</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kammer:Frank.html">Frank Kammer</a>, Johannes Meintrup, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sajenko:Andrej.html">Andrej Sajenko</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00676">PDF</a><br/><b>Abstract: </b>Practical applications that use treewidth algorithms have graphs with
treewidth k = O(\sqrt[3]n). Given such n-vertex graphs we present a word-RAM
algorithm to compute vertex separators using only O(n) bits of working memory.
As an application of our algorithm, we show an O(1)- approximation algorithm
for tree decomposition. Our algorithm computes a tree decomposition in c^k
n(log^* n) log log n time using O(n) bits for some constant c.
</p>
<p>We finally show that our tree-decomposition algorithm can be used to solve
several monadic second-order problems using O(n) bits as long as the treewidth
of the graph is smaller than c' log n for some constant 0 &lt; c' &lt; 1.
</p></div>
    </summary>
    <updated>2019-07-02T23:44:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00605</id>
    <link href="http://arxiv.org/abs/1907.00605" rel="alternate" type="text/html"/>
    <title>Online Multidimensional Packing Problems in the Random-Order Model</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>David Naori, Danny Raz Computer Science Department, Technion, Israel) <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00605">PDF</a><br/><b>Abstract: </b>We study online multidimensional variants of the generalized assignment
problem which are used to model prominent real-world applications, such as the
assignment of virtual machines with multiple resource requirements to physical
infrastructure in cloud computing. These problems can be seen as an extension
of the well known secretary problem and thus the standard online worst-case
model cannot provide any performance guarantee. The prevailing model in this
case is the random-order model, which provides a useful realistic and robust
alternative. Using this model, we study the $d$-dimensional generalized
assignment problem, where we introduce a novel technique that achieves an
$O(d)$-competitive algorithms and prove a matching lower bound of $\Omega(d)$.
Furthermore, our algorithm improves upon the best-known competitive-ratio for
the online (one-dimensional) generalized assignment problem and the online
knapsack problem.
</p></div>
    </summary>
    <updated>2019-07-02T23:47:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00533</id>
    <link href="http://arxiv.org/abs/1907.00533" rel="alternate" type="text/html"/>
    <title>Learning to Link</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Balcan:Maria=Florina.html">Maria-Florina Balcan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dick:Travis.html">Travis Dick</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lang:Manuel.html">Manuel Lang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00533">PDF</a><br/><b>Abstract: </b>Clustering is an important part of many modern data analysis pipelines,
including network analysis and data retrieval. There are many different
clustering algorithms developed by various communities, and it is often not
clear which algorithm will give the best performance on a specific clustering
task. Similarly, we often have multiple ways to measure distances between data
points, and the best clustering performance might require a non-trivial
combination of those metrics. In this work, we study data-driven algorithm
selection and metric learning for clustering problems, where the goal is to
simultaneously learn the best algorithm and metric for a specific application.
The family of clustering algorithms we consider is parameterized linkage based
procedures that includes single and complete linkage. The family of distance
functions we learn over are convex combinations of base distance functions. We
design efficient learning algorithms which receive samples from an
application-specific distribution over clustering instances and simultaneously
learn both a near-optimal distance and clustering algorithm from these classes.
We also carry out a comprehensive empirical evaluation of our techniques
showing that they can lead to significantly improved clustering performance.
</p></div>
    </summary>
    <updated>2019-07-02T23:44:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00529</id>
    <link href="http://arxiv.org/abs/1907.00529" rel="alternate" type="text/html"/>
    <title>Exponential-time quantum algorithms for graph coloring problems</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shimizu:Kazuya.html">Kazuya Shimizu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mori:Ryuhei.html">Ryuhei Mori</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00529">PDF</a><br/><b>Abstract: </b>The fastest known classical algorithm deciding the $k$-colorability of
$n$-vertex graph requires running time $\Omega(2^n)$ for $k\ge 5$. In this
work, we present an exponential-space quantum algorithm computing the chromatic
number with running time $O(1.9140^n)$ using quantum random access memory
(QRAM). Our approach is based on Ambainis et al's quantum dynamic programming
with applications of Grover's search to branching algorithms. We also present a
polynomial-space quantum algorithm not using QRAM for the graph $20$-coloring
problem with running time $O(1.9575^n)$. In the polynomial-space quantum
algorithm, we essentially show $(4-\epsilon)^n$-time classical algorithms that
can be improved quadratically by Grover's search.
</p></div>
    </summary>
    <updated>2019-07-02T23:43:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00524</id>
    <link href="http://arxiv.org/abs/1907.00524" rel="alternate" type="text/html"/>
    <title>Approximate $\mathbb{F}_2$-Sketching of Valuation Functions</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yaroslavtsev:Grigory.html">Grigory Yaroslavtsev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Samson.html">Samson Zhou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00524">PDF</a><br/><b>Abstract: </b>We study the problem of constructing a linear sketch of minimum dimension
that allows approximation of a given real-valued function $f \colon
\mathbb{F}_2^n \rightarrow \mathbb R$ with small expected squared error. We
develop a general theory of linear sketching for such functions through which
we analyze their dimension for most commonly studied types of valuation
functions: additive, budget-additive, coverage, $\alpha$-Lipschitz submodular
and matroid rank functions. This gives a characterization of how many bits of
information have to be stored about the input $x$ so that one can compute $f$
under additive updates to its coordinates.
</p>
<p>Our results are tight in most cases and we also give extensions to the
distributional version of the problem where the input $x \in \mathbb{F}_2^n$ is
generated uniformly at random. Using known connections with dynamic streaming
algorithms, both upper and lower bounds on dimension obtained in our work
extend to the space complexity of algorithms evaluating $f(x)$ under long
sequences of additive updates to the input $x$ presented as a stream. Similar
results hold for simultaneous communication in a distributed setting.
</p></div>
    </summary>
    <updated>2019-07-02T23:47:43Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00523</id>
    <link href="http://arxiv.org/abs/1907.00523" rel="alternate" type="text/html"/>
    <title>Geodesic Centroidal Voronoi Tessellations: Theories, Algorithms and Applications</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Ye:Zipeng.html">Zipeng Ye</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yi:Ran.html">Ran Yi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Minjing.html">Minjing Yu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Yong=Jin.html">Yong-Jin Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/He:Ying.html">Ying He</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00523">PDF</a><br/><b>Abstract: </b>Nowadays, big data of digital media (including images, videos and 3D
graphical models) are frequently modeled as low-dimensional manifold meshes
embedded in a high-dimensional feature space. In this paper, we summarized our
recent work on geodesic centroidal Voronoi tessellations(GCVTs), which are
intrinsic geometric structures on manifold meshes. We show that GCVT can find a
widely range of interesting applications in computer vision and graphics, due
to the efficiency of search, location and indexing inherent in these intrinsic
geometric structures. Then we present the challenging issues of how to build
the combinatorial structures of GCVTs and establish their time and space
complexities, including both theoretical and algorithmic results.
</p></div>
    </summary>
    <updated>2019-07-02T23:50:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00484</id>
    <link href="http://arxiv.org/abs/1907.00484" rel="alternate" type="text/html"/>
    <title>Bayesian Generalized Network Design</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Emek:Yuval.html">Yuval Emek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kutten:Shay.html">Shay Kutten</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lavi:Ron.html">Ron Lavi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shi:Yangguang.html">Yangguang Shi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00484">PDF</a><br/><b>Abstract: </b>We study network coordination problems, as captured by the setting of
generalized network design (Emek et al., STOC 2018), in the face of uncertainty
resulting from partial information that the network users hold regarding the
actions of their peers. This uncertainty is formalized using Alon et al.'s
Bayesian ignorance framework (TCS 2012). While the approach of Alon et al. is
purely combinatorial, the current paper takes into account computational
considerations: Our main technical contribution is the development of
(strongly) polynomial time algorithms for local decision making in the face of
Bayesian uncertainty.
</p></div>
    </summary>
    <updated>2019-07-02T23:45:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00465</id>
    <link href="http://arxiv.org/abs/1907.00465" rel="alternate" type="text/html"/>
    <title>Fast prototyping of an SDR WLAN 802.11b receiver for an indoor positioning system</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Erick.html">Erick Schmidt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akopian:David.html">David Akopian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00465">PDF</a><br/><b>Abstract: </b>Indoor positioning systems (IPS) are emerging technologies due to an
increasing popularity and demand in location based service (LBS). Because
traditional positioning systems such as GPS are limited to outdoor
applications, many IPS have been proposed in literature. WLAN-based IPS are the
most promising due to its proven accuracy and infrastructure deployment.
Several WLAN-based IPS have been proposed in the past, from which the best
results have been shown by so-called fingerprint-based systems. This paper
proposes an indoor positioning system which extends traditional WLAN
fingerprinting by using received signal strength (RSS) measurements along with
channel estimates as an effort to improve classification accuracy for scenarios
with a low number of Access Points (APs). The channel estimates aim to
characterize complex indoor environments making it a unique signature for
fingerprinting-based IPS and therefore improving pattern recognition in
radio-maps. Since commercial WLAN cards offer limited measurement information,
software-defined radio (SDR) as an emerging trend for fast prototyping and
research integration is chosen as the best cost-effective option to extract
channel estimates. Therefore, this paper first proposes an 802.11b WLAN SDR
beacon receiver capable of measuring RSS and channel estimates. The SDR is
designed using LabVIEW (LV) environment and leverages several inherent platform
acceleration features that achieve real-time capturing. The receiver achieves a
fast-rate measurement capture of 9 packets per second per AP. The
classification of the propose IPS uses a support vector machine (SVM) for
offline training and online navigation. Several tests are conducted in a
cluttered indoor environment with a single AP in 802.11b legacy mode. Finally,
navigation accuracy results are discussed.
</p></div>
    </summary>
    <updated>2019-07-02T23:26:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00463</id>
    <link href="http://arxiv.org/abs/1907.00463" rel="alternate" type="text/html"/>
    <title>Exploiting Acceleration Features of LabVIEW platform for Real-Time GNSS Software Receiver Optimization</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Erick.html">Erick Schmidt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akopian:David.html">David Akopian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00463">PDF</a><br/><b>Abstract: </b>This paper presents the new generation of LabVIEW-based GPS receiver testbed
that is based on National Instruments' (NI) LabVIEW (LV) platform in
conjunction to C/C++ dynamic link libraries (DLL) used inside the platform for
performance execution. This GPS receiver has been optimized for real-time
operation and has been developed for fast prototyping and easiness on future
additions and implementations to the system. The receiver DLLs are divided into
three baseband modules: acquisition, tracking, and navigation. The openness of
received baseband modules allows for extensive research topics such as signal
quality improvement on GPS-denied areas, signal spoofing, and signal
interferences. The hardware used in the system was chosen with an effort to
achieve portability and mobility in the SDR receiver. Several acceleration
factors that accomplish real-time operation and that are inherent to LabVIEW
mechanisms, such as multithreading, parallelization and dedicated
loop-structures, are discussed. The proposed SDR also exploits C/C++
optimization techniques for single-instruction multiple-data (SIMD) capable
processors in software correlators for real-time operation of GNSS tracking
loops. It is demonstrated that LabVIEW-based solutions provide competitive
real-time solutions for fast prototyping of receiver algorithms.
</p></div>
    </summary>
    <updated>2019-07-02T23:25:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00460</id>
    <link href="http://arxiv.org/abs/1907.00460" rel="alternate" type="text/html"/>
    <title>A Reduced Complexity Cross-correlation Interference Mitigation Technique on a Real-time Software-defined Radio GPS L1 Receiver</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Erick.html">Erick Schmidt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ruble:Zach_A=.html">Zach A. Ruble</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akopian:David.html">David Akopian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pack:Daniel_J=.html">Daniel J. Pack</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00460">PDF</a><br/><b>Abstract: </b>The U.S. global position system (GPS) is one of the existing global
navigation satellite systems (GNSS) that provides position and time information
for users in civil, commercial and military backgrounds. Because of its
reliance on many applications nowadays, it's crucial for GNSS receivers to have
robustness to intentional or unintentional interference. Because most
commercial GPS receivers are not flexible, software-defined radio emerged as a
promising solution for fast prototyping and research on interference mitigation
algorithms. This paper provides a proposed minimum mean-squared error (MMSE)
interference mitigation technique which is enhanced for computational
feasibility and implemented on a real-time capable GPS L1 SDR receiver. The GPS
SDR receiver SW has been optimized for real-time operation on National
Instruments' LabVIEW (LV) platform in conjunction with C/C++ dynamic link
libraries (DLL) for improved efficiency. Performance results of said algorithm
with real signals and injected interference are discussed. The proposed SDR
receiver gains in terms of BER curves for several interferers are demonstrated.
</p></div>
    </summary>
    <updated>2019-07-02T23:23:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00412</id>
    <link href="http://arxiv.org/abs/1907.00412" rel="alternate" type="text/html"/>
    <title>Upper bounds on the graph minor theorem</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Martin Krombholz, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rathjen:Michael.html">Michael Rathjen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00412">PDF</a><br/><b>Abstract: </b>Lower bounds on the proof-theoretic strength of the graph minor theorem were
found over 30 years ago by Friedman, Robertson and Seymour 1987, but upper
bounds have always been elusive. We present recently found upper bounds on the
graph minor theorem and other theorems appearing in the Graph Minors series.
Further, we give some ideas as to how the lower bounds on some of these
theorems might be improved.
</p></div>
    </summary>
    <updated>2019-07-02T23:26:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.00317</id>
    <link href="http://arxiv.org/abs/1907.00317" rel="alternate" type="text/html"/>
    <title>Waiting is not easy but worth it: the online TSP on the line revisited</title>
    <feedworld_mtime>1562025600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Pei-Chuan Chen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Erik_D=.html">Erik D. Demaine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liao:Chung=Shou.html">Chung-Shou Liao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wei:Hao=Ting.html">Hao-Ting Wei</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.00317">PDF</a><br/><b>Abstract: </b>We consider the online traveling salesman problem on the real line (OLTSPL)
in which a salesman begins at the origin, traveling at no faster than unit
speed along the real line, and wants to serve a sequence of requests, arriving
online over time on the real line and return to the origin as quickly as
possible. The problem has been widely investigated for more than two decades,
but was just optimally solved by a deterministic algorithm with a competitive
ratio of $(9+\sqrt{17})/8$, reported in~[Bjelde A. et al., in Proc. SODA 2017,
pp.994--1005].
</p>
<p>In this study we present lower bounds and upper bounds for randomized
algorithms in the OLTSPL. Precisely, we show, for the first time, that a simple
randomized \emph{zealous} algorithm can improve the optimal deterministic
algorithm. Here an algorithm is called zealous if waiting strategies are not
allowed to use for the salesman as long as there are unserved requests.
Moreover, we incorporate a natural waiting scheme into the randomized
algorithm, which can even achieve the lower bound we propose for any randomized
algorithms, and thus it is optimal. We also consider randomized algorithms
against a \emph{fair} adversary, i.e. an adversary with restricted power that
requires the salesman to move within the convex hull of the origin and the
requests released so far. The randomized non-zealous algorithm can outperform
the optimal deterministic algorithm against the fair adversary as well.
</p></div>
    </summary>
    <updated>2019-07-02T23:29:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-02T01:30:00Z</updated>
    </source>
  </entry>
</feed>
