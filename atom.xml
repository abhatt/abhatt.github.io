<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-04-19T20:21:24Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08914</id>
    <link href="http://arxiv.org/abs/1904.08914" rel="alternate" type="text/html"/>
    <title>Quantum Lower Bounds for Approximate Counting via Laurent Polynomials</title>
    <feedworld_mtime>1555632000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aaronson:Scott.html">Scott Aaronson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kothari:Robin.html">Robin Kothari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kretschmer:William.html">William Kretschmer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thaler:Justin.html">Justin Thaler</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08914">PDF</a><br/><b>Abstract: </b>This paper proves new limitations on the power of quantum computers to solve
approximate counting -- that is, multiplicatively estimating the size of a
nonempty set $S\subseteq [N]$. Given only a membership oracle for $S$, it is
well known that approximate counting takes $\Theta(\sqrt{N/|S|})$ quantum
queries. But what if a quantum algorithm is also given "QSamples"---i.e.,
copies of the state $|S\rangle = \sum_{i\in S}|i\rangle$---or even the ability
to apply reflections about $|S\rangle$? Our first main result is that, even
then, the algorithm needs either $\Theta(\sqrt{N/|S|})$ queries or else
$\Theta(\min\{|S|^{1/3},\sqrt{N/|S|}\})$ reflections or samples. We also give
matching upper bounds. We prove the lower bound using a novel generalization of
the polynomial method of Beals et al. to Laurent polynomials, which can have
negative exponents. We lower-bound Laurent polynomial degree using two methods:
a new "explosion argument" and a new formulation of the dual polynomials
method. Our second main result rules out the possibility of a black-box Quantum
Merlin-Arthur (or QMA) protocol for proving that a set is large. We show that,
even if Arthur can make $T$ quantum queries to the set $S$, and also receives
an $m$-qubit quantum witness from Merlin in support of $S$ being large, we have
$Tm=\Omega(\min\{|S|,\sqrt{N/|S|}\})$. This resolves the open problem of giving
an oracle separation between SBP and QMA. Note that QMA is "stronger" than the
queries+QSamples model in that Merlin's witness can be anything, rather than
just the specific state $|S\rangle$, but also "weaker" in that Merlin's witness
cannot be trusted. Intriguingly, Laurent polynomials also play a crucial role
in our QMA lower bound, but in a completely different manner than in the
queries+QSamples lower bound. This suggests that the "Laurent polynomial
method" might be broadly useful in complexity theory.
</p></div>
    </summary>
    <updated>2019-04-19T01:20:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08832</id>
    <link href="http://arxiv.org/abs/1904.08832" rel="alternate" type="text/html"/>
    <title>A doubly exponential upper bound on noisy EPR states for binary games</title>
    <feedworld_mtime>1555632000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yao:Penghui.html">Penghui Yao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08832">PDF</a><br/><b>Abstract: </b>This paper initiates the study of a class of entangled-games, mono-state
games, denoted by $(G,\psi)$, where $G$ is a two-player one-round game and
$\psi$ is a bipartite state independent of the game $G$. In the mono-state game
$(G,\psi)$, the players are only allowed to share arbitrary copies of $\psi$.
This paper provides a doubly exponential upper bound on the copies of $\psi$
for the players to approximate the value of the game to an arbitrarily small
constant precision for any mono-state binary game $(G,\psi)$, if $\psi$ is a
noisy EPR state, which is a two-qubit state with completely mixed states as
marginals and maximal correlation less than $1$. In particular, it includes
$(1-\epsilon)|\Psi\rangle\langle\Psi|+\epsilon\frac{I_2}{2}\otimes\frac{I_2}{2}$,
an EPR state with an arbitrary depolarizing noise $\epsilon&gt;0$. This paper
develops a series of new techniques about the Fourier analysis on matrix spaces
and proves a quantum invariance principle and a hypercontractive inequality of
random operators. The structure of the proofs is built the recent framework
about the decidability of the non-interactive simulation of joint
distributions, which is completely different from all previous
optimization-based approaches or "Tsirelson's problem"-based approaches. This
novel approach provides a new angle to study the decidability of the complexity
class MIP$^*$, a longstanding open problem in quantum complexity theory.
</p></div>
    </summary>
    <updated>2019-04-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08819</id>
    <link href="http://arxiv.org/abs/1904.08819" rel="alternate" type="text/html"/>
    <title>New Subgraph Isomorphism Algorithms: Vertex versus Path-at-a-time Matching</title>
    <feedworld_mtime>1555632000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hassaan:Mosab.html">Mosab Hassaan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gouda:Karam.html">Karam Gouda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08819">PDF</a><br/><b>Abstract: </b>Graphs are widely used to model complicated data semantics in many
application domains. In this paper, two novel and efficient algorithms Fast-ON
and Fast-P are proposed for solving the subgraph isomorphism problem. The two
algorithms are based on Ullman algorithm [Ullmann 1976], apply vertex-at-a-time
matching manner and path-at-a-time matching manner respectively, and use
effective heuristics to cut the search space. Comparing to the well-known
algorithms, Fast-ON and Fast-P achieve up to 1-4 orders of magnitude speed-up
for both dense and sparse graph data.
</p></div>
    </summary>
    <updated>2019-04-19T01:24:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08746</id>
    <link href="http://arxiv.org/abs/1904.08746" rel="alternate" type="text/html"/>
    <title>Advancing Through Terrains</title>
    <feedworld_mtime>1555632000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Froese:Vincent.html">Vincent Froese</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Renken:Malte.html">Malte Renken</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08746">PDF</a><br/><b>Abstract: </b>We study terrain visibility graphs, a well-known graph class closely related
to polygon visibility graphs in computational geometry, for which a precise
graph-theoretical characterization is still unknown. Over the last decade,
terrain visibility graphs attracted quite some attention in the context of time
series analysis with various practical applications in areas such as physics,
geography and medical sciences. We make progress in understanding terrain
visibility graphs by providing several graph-theoretic results. For example, we
show that they can contain arbitrary large holes but not large antiholes.
Moreover, we obtain two algorithmic results which are interesting from a
practical perspective. We devise a fast shortest path algorithm on arbitrary
induced subgraphs of terrain visibility graphs and a polynomial-time algorithm
for Dominating Set on special terrain visibility graphs (called funnel
visibility graphs).
</p></div>
    </summary>
    <updated>2019-04-19T01:25:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-04-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08624</id>
    <link href="http://arxiv.org/abs/1904.08624" rel="alternate" type="text/html"/>
    <title>On conflict-free chromatic guarding of simple polygons</title>
    <feedworld_mtime>1555632000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Onur Çağırıcı, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghosh:Subir_Kumar.html">Subir Kumar Ghosh</a>, Petr Hliněný, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roy:Bodhayan.html">Bodhayan Roy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08624">PDF</a><br/><b>Abstract: </b>We study the problem of colouring the vertices of a polygon, such that every
viewer can see a unique colour. The goal is to minimize the number of colours
used. This is also known as the conflict-free chromatic guarding problem with
vertex guards (which is quite different from point guards considered in other
papers). We study the problem in two scenarios of a set of viewers. In the
first scenario, we assume that the viewers are all points of the polygon. We
solve the related problem of minimizing the number of guards and approximate
(up to only an additive error) the number of colours in the special case of
funnels. We also give an upper bound of O(log n) colours on weak-visibility
polygons which generalizes to all simple polygons. In the second scenario, we
assume that the viewers are only the vertices of the polygon. We show a lower
bound of 3 colours in the general case of simple polygons and conjecture that
this is tight. We also prove that already deciding whether 1 or 2 colours are
enough is NP-complete.
</p></div>
    </summary>
    <updated>2019-04-19T01:25:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-04-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08415</id>
    <link href="http://arxiv.org/abs/1904.08415" rel="alternate" type="text/html"/>
    <title>An Exponential Lower Bound for the Runtime of the cGA on Jump Functions</title>
    <feedworld_mtime>1555632000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Doerr:Benjamin.html">Benjamin Doerr</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08415">PDF</a><br/><b>Abstract: </b>In the first runtime analysis of an estimation-of-distribution algorithm
(EDA) on the multi-modal jump function class, Hasen\"ohrl and Sutton (GECCO
2018) proved that the runtime of the compact genetic algorithm with suitable
parameter choice on jump functions with high probability is at most polynomial
(in the dimension) if the jump size is at most logarithmic (in the dimension),
and is at most exponential in the jump size if the jump size is
super-logarithmic. The exponential runtime guarantee was achieved with a
hypothetical population size that is also exponential in the jump size.
Consequently, this setting cannot lead to a better runtime.
</p>
<p>In this work, we show that any choice of the hypothetical population size
leads to a runtime that, with high probability, is at least exponential in the
jump size. This result might be the first non-trivial exponential lower bound
for EDAs that holds for arbitrary parameter settings.
</p></div>
    </summary>
    <updated>2019-04-19T01:22:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15768</id>
    <link href="https://rjlipton.wordpress.com/2019/04/18/a-reason-why-circuit-lower-bounds-are-hard/" rel="alternate" type="text/html"/>
    <title>A Reason Why Circuit Lower Bounds Are Hard</title>
    <summary>And a possible approach to avoid this obstacle Valentine Kabanets is a famous complexity theorist from Simon Fraser University. He has been at the forefront of lower bounds for over two decades. Today we draw attention to this work and raise an idea about trying to unravel what makes circuit lower bounds hard. He is […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>And a possible approach to avoid this obstacle</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2019/04/kabanetssfu.jpg"><img alt="" class="alignright wp-image-15769" height="200" src="https://rjlipton.files.wordpress.com/2019/04/kabanetssfu.jpg?w=129&amp;h=200" width="129"/></a></p>
<p>
Valentine Kabanets is a famous complexity theorist from Simon Fraser University. He has been at the forefront of lower bounds for over two decades. </p>
<p>
Today we draw attention to this work and raise an idea about trying to unravel what makes circuit lower bounds hard.</p>
<p>
He is the common author on <a href="https://eccc.weizmann.ac.il/report/2019/022/">two</a> new <a href="https://eccc.weizmann.ac.il/report/2019/018/">papers</a> on the Minimum Circuit Size Problem (MCSP), which belongs to <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> but is not known to be complete or in <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/>. We <a href="https://rjlipton.wordpress.com/2015/03/05/news-on-intermediate-problems/">posted</a> on MCSP four years ago and mentioned his 1999 <a href="http://eccc.hpi-web.de/report/1999/045">paper</a> with Jin-Yi Cai, which gives evidence for MCSP truly being neither complete nor in <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/>. This “intermediate” status and the problem’s simplicity have raised hopes that direct attacks might succeed. The new papers prove direct lower bounds against some restricted circuit/formula models, including constant-depth circuits with mod-<img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> gates for <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> prime. But they stop short of mod-<img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> for <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> composite and other barrier cases.</p>
<p>
He has a nifty research <a href="https://www.cs.sfu.ca/~kabanets/research.html">statement</a> on his home page. It shows how derandomization, pseudorandomness, circuit complexity, and crypto combine into his two current projects. In a clickable tab for the third heading, he puts the meta-issue in pithy terms:</p>
<blockquote><p><b> </b> <em> <i>Why is proving circuit lower bounds so difficult?</i> </em>
</p></blockquote>
<p/><p>
His first answer tab speaks a connection we have also often emphasized here:</p>
<blockquote><p><b> </b> <em> Traditionally, designing efficient algorithms is the subject of the theory of algorithms, while lower bounds are sought in complexity theory. It turns out, however, that there is a deep connection between the two directions: better algorithms (for a certain class of problems) also yield strong lower bounds (for related problems), and vice versa: strong lower bounds translate into more efficient algorithms. </em>
</p></blockquote>
<p/><p>
Of course we agree, and we love connections shown in the new papers to problems such as distinguishing a very slightly biased coin from a true one. But we will try to supplement the algorithmic view of circuit lower bounds with a direct look at the underlying logic.</p>
<p>
</p><p/><h2> Logical Structure of Lower Bounds </h2><p/>
<p/><p>
Okay we all know that circuit lower bounds are hard. For all Kabanets’ success and beautiful work—he like the rest of the complexity field—are unable to prove what we believe is true. They cannot in the full circuit model prove anything close to what is believed to be true for at least a half a century: There are explicit Boolean functions that cannot be computed by any linear size circuit.</p>
<p>
We feel that the logical structure of lower bounds statements gives insight into their difficulty. Perhaps this is almost a tautology. Of course the logical structure of any mathematical statement helps us understand its inherent difficulty. But we believe more: That this structure can reveal quite a bit about lower bounds. Let’s take a look at lower bounds and see if this belief holds up.</p>
<p>
In particular let’s compare the two main approaches to proving lower bounds: non-uniform and uniform. Our claim is that they have different logical structure, and that this difference explains why there is such a gap between the two. While lower bounds—non-uniform or uniform—are hard, uniform ones are at least possible now. Non-uniform lower bounds are really very difficult.</p>
<p>
Here is one example. To prove an explicit size lower bound for Boolean circuits—we’ll be content with just a linear one—we must give a particular family of Boolean functions <img alt="{f_{n}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7Bn%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{n}(x)}"/> (each of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> inputs) so that:</p>
<ol>
<li>
Given <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> we can evaluate <img alt="{f_{n}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7Bn%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{n}(x)}"/> in polynomial time; <p/>
</li><li>
There is no Boolean circuit of size <img alt="{\alpha n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha n}"/> that correctly computes <img alt="{f_{n}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7Bn%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{n}(x)}"/> on all <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>.
</li></ol>
<p>
Here <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is a constant and <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is assumed to be large enough. The terrific <a href="http://www.wisdom.weizmann.ac.il/~ranraz/publications/P5nlb.pdf">paper</a> of Kazuo Iwama, Oded Lachish, Hiroki Morizumi, and Ran Raz gives explicit Boolean functions whose size for circuits with the usual <em>not</em> and binary <em>and</em> and <em>or</em> operators exceeds <img alt="{5n-o(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5n-o%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5n-o(n)}"/>. </p>
<p>
</p><p/><h2> An Approach </h2><p/>
<p/><p>
Let’s look at the above example more carefully. Suppose that in place of a single Boolean function on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> inputs we have a list of them: </p>
<p align="center"><img alt="\displaystyle  f_{n,1}(x),\dots,f_{n,m}(x). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f_%7Bn%2C1%7D%28x%29%2C%5Cdots%2Cf_%7Bn%2Cm%7D%28x%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f_{n,1}(x),\dots,f_{n,m}(x). "/></p>
<p>Can we prove the following? </p>
<p align="center"><img alt="\displaystyle  \exists n_{0}\ \forall n &gt; n_{0} \ \exists f_{n,k} \ \forall C \in \mathsf{SIZE}(\alpha n) \ \neg\mathsf{compute}(C,f_{n,k}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cexists+n_%7B0%7D%5C+%5Cforall+n+%3E+n_%7B0%7D+%5C+%5Cexists+f_%7Bn%2Ck%7D+%5C+%5Cforall+C+%5Cin+%5Cmathsf%7BSIZE%7D%28%5Calpha+n%29+%5C+%5Cneg%5Cmathsf%7Bcompute%7D%28C%2Cf_%7Bn%2Ck%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \exists n_{0}\ \forall n &gt; n_{0} \ \exists f_{n,k} \ \forall C \in \mathsf{SIZE}(\alpha n) \ \neg\mathsf{compute}(C,f_{n,k}). "/></p>
<p>The first thing to note is the effect of letting the number <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> of functions vary:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> If <img alt="{\bf m = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m = 1}"/>, this just becomes our original explicit circuit lower bound problem. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> If <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> is a huge value, however, this becomes the exponential lower bound shown by Claude Shannon—a known quantity. </p>
<p>
In our terms, the latter takes <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> equal to <img alt="{2^{2^{n}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B2%5E%7Bn%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{2^{n}}}"/>, so that given <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> our function list is just the list of all Boolean functions. If all we care about is an <img alt="{\alpha n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha n}"/> lower bound, then the high end of the range can be something like <img alt="{m = 2^{2\alpha n\log(n)} = n^{2\alpha n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+2%5E%7B2%5Calpha+n%5Clog%28n%29%7D+%3D+n%5E%7B2%5Calpha+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = 2^{2\alpha n\log(n)} = n^{2\alpha n}}"/>. So at the high end we have a simple counting argument for the proof but have traded away explicitness. The question will be about the tradeoffs for <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> in-between the extremes.</p>
<p>
</p><p/><h2> An Analogy </h2><p/>
<p/><p>
The above idea that we can model the lower bound methods by controlling the length of the list of the functions is the key to our approach. Perhaps it may help to note an analogy to other famous hard problems of constructing explicit objects. In particular, let’s look at constructing transcendental numbers. Recall these are real numbers that are not algebraic: they are not roots of polynomials with integer coefficients. They include <img alt="{\pi = 3.14159\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+%3D+3.14159%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi = 3.14159\dots}"/> and <img alt="{e = 2.71828\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be+%3D+2.71828%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e = 2.71828\dots}"/></p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The <a href="https://en.wikipedia.org/wiki/Liouville_number">Liouville</a> numbers of Joseph Liouville. 	</p>
<p align="center"><img alt="\displaystyle  x = \sum_{k=1}^\infty \frac{a_k}{b^{k!}}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+%5Csum_%7Bk%3D1%7D%5E%5Cinfty+%5Cfrac%7Ba_k%7D%7Bb%5E%7Bk%21%7D%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x = \sum_{k=1}^\infty \frac{a_k}{b^{k!}}. "/></p>
<p>These are explicit numbers that were proved by him in 1844 to be transcendental. In terms of our model <img alt="{\bf m=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m=1}"/>.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The great <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi}"/> and <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e}"/> puzzle. This is the observation that of <img alt="{\pi + e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+%2B+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi + e}"/> or <img alt="{\pi - e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+-+e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pi - e}"/>, at least one is a transcendental number. In our terms this gives <img alt="{\bf m=2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m=2}"/>.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The famous theorem of Georg Cantor—read as proving the existence of transcendental numbers since algebraic ones are countable.</p>
<p>
Here the high end of the range is as extreme as can be. Cantor’s `list’ of numbers is uncountable—in our model, <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> is the cardinality of the real numbers. Note, the fact that his <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> is huge, really huge, may explain why some at the time were unimpressed by this result. They wanted the ‘list’ to be small, actually they wanted <img alt="{\bf m=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m=1}"/>. See <a href="https://www.jstor.org/stable/2975129?seq=1#page_scan_tab_contents">this</a> for a discussion of the history of these ideas.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> The theorem by Waim Zudilin, in a 2001 <a href="https://iopscience.iop.org/article/10.1070/RM2001v056n04ABEH000427/meta">paper</a>, that at least one of the numbers <img alt="{\zeta(5), \zeta(7), \zeta(9), \zeta(11)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Czeta%285%29%2C+%5Czeta%287%29%2C+%5Czeta%289%29%2C+%5Czeta%2811%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\zeta(5), \zeta(7), \zeta(9), \zeta(11)}"/> must be irrational. It is for “irrational” not “transcendental,” but exemplified <img alt="{\bf m = 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m+%3D+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m = 4}"/> in a highly nontrivial manner. The technical point that makes this work is interactions among these numbers that cannot be captured just by considering any one of them separately. This has <img alt="{\bf m = 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m+%3D+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m = 4}"/>.</p>
<p>
</p><p/><h2> Joining Functions </h2><p/>
<p/><p>
The issue is this: Suppose that we have a list of several boolean functions <img alt="{f_{1}(x),\dots,f_{m}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B1%7D%28x%29%2C%5Cdots%2Cf_%7Bm%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{1}(x),\dots,f_{m}(x)}"/>. Then we can join them together to form one function <img alt="{g(x,y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x,y)}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  g(x,1) = f_{1}(x), \cdots, g(x,m) = f_{m}(x). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++g%28x%2C1%29+%3D+f_%7B1%7D%28x%29%2C+%5Ccdots%2C+g%28x%2Cm%29+%3D+f_%7Bm%7D%28x%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  g(x,1) = f_{1}(x), \cdots, g(x,m) = f_{m}(x). "/></p>
<p>Clearly the function <img alt="{g(x,y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x,y)}"/> is easy implies that all of the <img alt="{f_{y}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7By%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{y}(x)}"/> are easy. This join trick shows that we can encode several boolean functions into one function. Note, we can even make <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> have only order <img alt="{\log(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log(n)}"/> where <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> has <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> bits.</p>
<p>
Thus we can join any collection of functions to make a “universal” one that is at least as hard as the worst of the single functions. More precisely, 	</p>
<p align="center"><img alt="\displaystyle  \mathsf{complexity}(g) \ge \mathsf{complexity}(f_{y}) \text{ for } y=1,\dots,m. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7Bcomplexity%7D%28g%29+%5Cge+%5Cmathsf%7Bcomplexity%7D%28f_%7By%7D%29+%5Ctext%7B+for+%7D+y%3D1%2C%5Cdots%2Cm.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{complexity}(g) \ge \mathsf{complexity}(f_{y}) \text{ for } y=1,\dots,m. "/></p>
<p>Here <img alt="{\mathsf{complexity}(h)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bcomplexity%7D%28h%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{complexity}(h)}"/> is the circuit complexity of the boolean function <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h}"/>.</p>
<p>
If <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> is bigger than <img alt="{2^{O(n)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7BO%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{O(n)}}"/>, that is if <img alt="{m = 2^{\omega(n)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+2%5E%7B%5Comega%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = 2^{\omega(n)}}"/>, then the joined function has more than linearly many variables. Can we possibly establish nontrivial interactions among so many functions, say <img alt="{{\bf m} = n^{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+m%7D+%3D+n%5E%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\bf m} = n^{2n}}"/>?</p>
<p>
One can also try to get this effect with fewer or no additional variables by taking the XOR of some subset of functions in the list. If this is done randomly for each input length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> then one can expect hard functions to show up for many <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. If this process can then be <em>de-randomized</em>, then this may yield an explicit hard function. We wonder how this idea might meld with Andy Yao’s famous XOR Lemma and conditions to <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.441.2818&amp;rep=rep1&amp;type=pdf">de-randomize</a> it.</p>
<p>
</p><p/><h2> Joining Numbers </h2><p/>
<p/><p>
Ken and I thought about the above simple fact about joins, which seems special to functions. Joining by interleaving the decimal expansions is not an arithmetic operation. However, it appears that there may be a similar result possible for transcendental numbers. </p>
<blockquote><p><b>Lemma 1</b> <em> Suppose that <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> and <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\beta}"/> are real numbers. Then 	</em></p><em>
<p align="center"><img alt="\displaystyle  \alpha + i\beta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Calpha+%2B+i%5Cbeta+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  \alpha + i\beta "/></p>
</em><p><em>is a transcendental complex number if at least one of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> or <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\beta}"/> are transcendental. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Let <img alt="{\gamma = \alpha + i\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgamma+%3D+%5Calpha+%2B+i%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\gamma = \alpha + i\beta}"/> be an algebraic number. Thus there must be a polynomial <img alt="{q(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q(x)}"/> with integer coefficients so that 	</p>
<p align="center"><img alt="\displaystyle  q(\gamma) = q(\alpha + i\beta) = 0. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++q%28%5Cgamma%29+%3D+q%28%5Calpha+%2B+i%5Cbeta%29+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  q(\gamma) = q(\alpha + i\beta) = 0. "/></p>
<p>Then it follows by complex conjugation that 	</p>
<p align="center"><img alt="\displaystyle  q(\alpha - i\beta) = 0. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++q%28%5Calpha+-+i%5Cbeta%29+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  q(\alpha - i\beta) = 0. "/></p>
<p>	 Therefore <img alt="{\alpha + i\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%2B+i%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha + i\beta}"/> and <img alt="{\alpha -i\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+-i%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha -i\beta}"/> are both algebraic; thus, so is their sum which is <img alt="{2\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2\alpha}"/>. Thus <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is algebraic. It follows that <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/> is also algebraic. This shows that <img alt="{\gamma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\gamma}"/> is transcendental. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
A question: Can we show that we can do a “join” operation for three or more numbers? That is given numbers <img alt="{x_{1},\dots,x_{m}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7B1%7D%2C%5Cdots%2Cx_%7Bm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{1},\dots,x_{m}}"/> can we construct a number <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> that is transcendental if and only if at least one of <img alt="{x_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i}}"/> is transcendental?</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Is the <img alt="{\bf m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m}"/> model useful? Is it possible for it to succeed where a direct explicit argument (<img alt="{{\bf m} = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+m%7D+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\bf m} = 1}"/>) does not? Does it need <img alt="{{\bf m} \gg 2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+m%7D+%5Cgg+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\bf m} \gg 2^n}"/> to rise above technical dependence on the <img alt="{\bf m = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbf+m+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bf m = 1}"/> case via the join construction?</p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/04/valentine-sandan-test-action-small.jpeg"><img alt="" class="aligncenter wp-image-15770" height="158" src="https://rjlipton.files.wordpress.com/2019/04/valentine-sandan-test-action-small.jpeg?w=235&amp;h=158" width="235"/></a>
</td>
</tr>
<tr>
<td class="caption alignright">
<font size="-2">Maybe the barriers just need 3-Dan martial-arts treatment.  <a href="https://www.vancouverwestaikikai.com/programs/intro-beginner.shtml">Source</a>—our congrats.<br/>
</font>
</td>
</tr>
</tbody></table></font></font></div>
    </content>
    <updated>2019-04-18T22:16:11Z</updated>
    <published>2019-04-18T22:16:11Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="circuit complexity"/>
    <category term="circuits"/>
    <category term="lower bounds"/>
    <category term="transcendental numbers"/>
    <category term="Valentine Kabanets"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-04-19T20:20:39Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-4286404438772500234</id>
    <link href="http://processalgebra.blogspot.com/feeds/4286404438772500234/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=4286404438772500234" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/4286404438772500234" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/4286404438772500234" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/04/the-complexity-of-identifying.html" rel="alternate" type="text/html"/>
    <title>The Complexity of Identifying Characteristic Formulae</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">One of the classic results in concurrency theory is the Hennessy-Milner Theorem. This result states that<br/><ol><li>two bisimilar states in a labelled transition system satisfy exactly the same formulae in a multi-modal logic now called Hennessy-Milner logic, and </li><li>two states in a labelled transition system that satisfy a mild finiteness constraint (called image finiteness)  and enjoy the same properties expressible in Hennessy-Milner logic are bisimilar.</li></ol>See, for instance, Section 1.2 in <a href="http://homepages.inf.ed.ac.uk/cps/chapbisim.pdf">these notes by Colin Stirling</a> for an exposition of that result. A consequence of the Hennessy-Milner Theorem is that whenever two states <i>p </i>and <i>q </i>in a labelled transition system are <i>not</i> bisimilar, one can come up with a formula in Hennessy-Milner logic that <i>p </i>satisfies, but<i> q </i>does not<i>. </i>Moreover, for each state <i>p </i>in a finite, loop-free labelled transition systems, it is possible to construct a formula <i>F(p) </i>in Hennessy-Milner logic that completely characterizes <i>p</i> up to bisimilarity. This means that, for each state <i>q</i>, <i>p</i> is bisimilar to <i>q</i> if, and only if, <i>q</i> satisfies <i>F(p)</i>. The formula<i> F(p) </i>is called a characteristic formula for<i> p </i>up to bisimilarity.<i> </i>One can obtain a similar result for states in finite labelled transition systems by extending Hennessy-Milner logic with greatest fixed points. <i><br/></i><br/><br/>Characteristic formulae have a long history in concurrency theory. However, to be best of my knowledge, the complexity of determining whether a formula is characteristic had not been studied before <a href="https://sites.google.com/view/antonisachilleos">Antonis Achilleos</a> first addressed the problem in <a href="https://arxiv.org/abs/1605.01004">this conference paper</a>. In that paper, Antonis focused on the complexity of the problem of determining whether a formula <i>F</i> is complete, in the sense that, for each formula <i>G</i>, it can derive either <i>G</i> or its negation.<br/><br/>Our recent preprint    <a href="http://icetcs.ru.is/theofomon/CharFormComplexity.pdf"><i>The   Complexity of Identifying Characteristic Formulae</i></a> extends the results originally obtained by Antonis to a variety of modal logics, possibly including least and greatest fixed-point operators. In the paper, we show that completeness, characterization, and validity have the same complexity — with some exceptions for which there are, in general, no complete formulae. So, for most modal logics of interest, the problem is coNP-complete or PSPACE-complete, and becomes EXPTIME-complete for modal logics with fixed points. To prove our upper bounds, we present a nondeterministic procedure with an oracle for validity that combines tableaux and a test for bisimilarity, and determines whether a formula is complete.<br/><br/>I think that there is still a lot of work that can be done in studying this problem, with respect to a variety of other notions of equivalence considered in concurrency theory, so stay tuned for further updates. </div>
    </content>
    <updated>2019-04-18T17:19:00Z</updated>
    <published>2019-04-18T17:19:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-04-18T17:19:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/060</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/060" rel="alternate" type="text/html"/>
    <title>TR19-060 |  Gentle Measurement of Quantum States and Differential Privacy | 

	Scott Aaronson, 

	Guy Rothblum</title>
    <summary>In differential privacy (DP), we want to query a database about $n$ users, in a way that "leaks at most $\varepsilon$ about any individual user," even conditioned on any outcome of the query.  Meanwhile, in gentle measurement, we want to measure $n$ quantum states, in a way that "damages the states by at most $\alpha$," even conditioned on any outcome of the measurement.  In both cases, we can achieve the goal by techniques like deliberately adding noise to the outcome before returning it.  This paper proves a new and general connection between the two subjects. Specifically, we show that on products of $n$ quantum states, any measurement that is $\alpha$-gentle for small $\alpha$ is also $O( \alpha)$-DP, and any product measurement that is $\varepsilon$-DP is also $O(\varepsilon\sqrt{n})$-gentle.

Illustrating the power of this connection, we apply it to the recently studied problem of shadow tomography.  Given an unknown $d$-dimensional quantum state $\rho$, as well as known two-outcome measurements $E_{1},\ldots,E_{m}$, shadow tomography asks us to estimate $\Pr\left[  E_{i}\text{ accepts }\rho\right]  $, for every $i\in\left[ m\right]  $, by measuring few copies of $\rho$. Using our connection theorem, together with a quantum analog of the so-called private multiplicative weights algorithm of Hardt and Rothblum, we give a protocol to solve this problem using $O\left( \left(  \log m\right)  ^{2}\left(  \log d\right)  ^{2}\right)$ copies of $\rho$, compared to Aaronson's previous bound of $\widetilde{O} \left(\left(  \log m\right) ^{4}\left( \log d\right)\right) $.  Our protocol has the advantages of being online (that is, the $E_{i}$'s are processed one at a time), gentle, and conceptually simple.

Other applications of our connection include new lower bounds for shadow tomography from lower bounds on DP, and a result on the safe use of estimation algorithms as subroutines inside larger quantum algorithms.</summary>
    <updated>2019-04-18T12:48:21Z</updated>
    <published>2019-04-18T12:48:21Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-19T20:20:34Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2053726780224405945</id>
    <link href="https://blog.computationalcomplexity.org/feeds/2053726780224405945/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/physics-of-everday-life.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2053726780224405945" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2053726780224405945" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/physics-of-everday-life.html" rel="alternate" type="text/html"/>
    <title>Physics of Everday Life</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Based on <a href="https://www.scottaaronson.com/blog/?p=3654">Scott's review</a>, I read through Stephen Pinker's <a href="https://www.amazon.com/Enlightenment-Now-Science-Humanism-Progress-ebook/dp/B073TJBYTB/ref=as_li_ss_tl?crid=2O1U6VZR84R2Q&amp;keywords=enlightenment+now&amp;qid=1554897483&amp;s=gateway&amp;sprefix=engligh,aps,597&amp;sr=8-1&amp;linkCode=ll1&amp;tag=computation09-20&amp;linkId=8f668f77297b7cd8b57a85dca27802b0&amp;language=en_US">Enlightenment Now</a>. I can't top Scott's exposition of the book, but it is pretty incredible how far humanity has gone when you step back to look at the big picture.<br/>
<br/>
One line intrigued me, one that Pinker credits to a book called <a href="https://www.amazon.com/Big-Picture-Origins-Meaning-Universe/dp/1101984252/ref=as_li_ss_tl?ie=UTF8&amp;linkCode=ll1&amp;tag=computation09-20&amp;linkId=6c644c72e1d0c1f818a5907f9b221ce1&amp;language=en_US">The Big Picture</a> by Sean Carroll<br/>
<blockquote class="tr_bq">
The laws of physics underlying everyday life (that is excluding extreme values of energy and gravitation like black holes, dark matter and the Big Bang) are <i>completely known.</i></blockquote>
Hasn't this statement almost always been true, in the sense that the leading minds would make this claim at many times in history. The ancient Greeks probably believed they understood physics that underlies everyday life. So did physicists after Newton. Life back then not today. My everyday life involves using a GPS device that requires understanding relativistic effects and computer chips that needed other scientific advances.<br/>
<br/>
Is it possible we could do more in everyday life if we knew more physics? I'd certainly use a teleporter in everyday life.<br/>
<br/>
And is the statement even true today? We all use public key cryptography, even to read this blog. It's not completely clear if we understand the physics enough to know how or if large-scale quantum computers capable of breaking those systems can be built.<br/>
<br/>
Everday life is relative.</div>
    </content>
    <updated>2019-04-18T11:40:00Z</updated>
    <published>2019-04-18T11:40:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-04-19T18:07:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/059</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/059" rel="alternate" type="text/html"/>
    <title>TR19-059 |  Samplers and extractors for unbounded functions | 

	Rohit Agrawal</title>
    <summary>Blasiok (SODA'18) recently introduced the notion of a subgaussian sampler, defined as an averaging sampler for approximating the mean of functions $f:\{0,1\}^m \to \mathbb{R}$ such that $f(U_m)$ has subgaussian tails, and asked for explicit constructions. In this work, we give the first explicit constructions of subgaussian samplers (and in fact averaging samplers for the broader class of subexponential functions) that match the best-known constructions of averaging samplers for $[0,1]$-bounded functions in the regime of parameters where the approximation error $\varepsilon$ and failure probability $\delta$ are subconstant. Our constructions are established via an extension of the standard notion of randomness extractor (Nisan and Zuckerman, JCSS'96) where the error is measured by an arbitrary divergence rather than total variation distance, and a generalization of Zuckerman's equivalence (Random Struct. Alg.'97) between extractors and samplers. We believe that the framework we develop, and specifically the notion of an extractor for the Kullback-Leibler (KL) divergence, are of independent interest. In particular, KL-extractors are stronger than both standard extractors and subgaussian samplers, but we show that they exist with essentially the same parameters (constructively and non-constructively) as standard extractors.</summary>
    <updated>2019-04-18T00:27:56Z</updated>
    <published>2019-04-18T00:27:56Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-19T20:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08391</id>
    <link href="http://arxiv.org/abs/1904.08391" rel="alternate" type="text/html"/>
    <title>Samplers and extractors for unbounded functions</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Agrawal:Rohit.html">Rohit Agrawal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08391">PDF</a><br/><b>Abstract: </b>Blasiok (SODA'18) recently introduced the notion of a subgaussian sampler,
defined as an averaging sampler for approximating the mean of functions
$f:\{0,1\}^m \to \mathbb{R}$ such that $f(U_m)$ has subgaussian tails, and
asked for explicit constructions. In this work, we give the first explicit
constructions of subgaussian samplers (and in fact averaging samplers for the
broader class of subexponential functions) that match the best-known
constructions of averaging samplers for $[0,1]$-bounded functions in the regime
of parameters where the approximation error $\varepsilon$ and failure
probability $\delta$ are subconstant. Our constructions are established via an
extension of the standard notion of randomness extractor (Nisan and Zuckerman,
JCSS'96) where the error is measured by an arbitrary divergence rather than
total variation distance, and a generalization of Zuckerman's equivalence
(Random Struct. Alg.'97) between extractors and samplers. We believe that the
framework we develop, and specifically the notion of an extractor for the
Kullback-Leibler (KL) divergence, are of independent interest. In particular,
KL-extractors are stronger than both standard extractors and subgaussian
samplers, but we show that they exist with essentially the same parameters
(constructively and non-constructively) as standard extractors.
</p></div>
    </summary>
    <updated>2019-04-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08382</id>
    <link href="http://arxiv.org/abs/1904.08382" rel="alternate" type="text/html"/>
    <title>A Faster Local Algorithm for Detecting Bounded-Size Cuts with Applications to Higher-Connectivity Problems</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Forster:Sebastian.html">Sebastian Forster</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Liu.html">Liu Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08382">PDF</a><br/><b>Abstract: </b>Consider the following "local" cut-detection problem in a directed graph: We
are given a starting vertex $s$ and need to detect whether there is a cut with
at most $k$ edges crossing the cut such that the side of the cut containing $s$
has at most $\Delta$ interior edges. If we are given query access to the input
graph, then this problem can in principle be solved in sublinear time without
reading the whole graph and with query complexity depending on $k$ and
$\Delta$. We design an elegant randomized procedure that solves a slack variant
of this problem with $O(k^2 \Delta)$ queries, improving in particular a
previous bound of $O((2(k+1))^{k+2} \Delta)$ by Chechik et al. [SODA 2017]. In
this slack variant, the procedure must successfully detect a component
containing $s$ with at most $k$ outgoing edges and $\Delta$ interior edges if
such a component exists, but the component it actually detects may have up to
$O(k \Delta)$ interior edges.
</p>
<p>Besides being of interest on its own, such cut-detection procedures have been
used in many algorithmic applications for higher-connectivity problems. Our new
cut-detection procedure therefore almost readily implies (1) a faster vertex
connectivity algorithm which in particular has nearly linear running time for
polylogarithmic value of the vertex connectivity, (2) a faster algorithm for
computing the maximal $k$-edge connected subgraphs, and (3) faster property
testing algorithms for higher edge and vertex connectivity, which resolves two
open problems, one by Goldreich and Ron [STOC '97] and one by Orenstein and Ron
[TCS 2011].
</p></div>
    </summary>
    <updated>2019-04-18T23:27:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08380</id>
    <link href="http://arxiv.org/abs/1904.08380" rel="alternate" type="text/html"/>
    <title>Low-Latency Graph Streaming Using Compressed Purely-Functional Trees</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dhulipala:Laxman.html">Laxman Dhulipala</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shun:Julian.html">Julian Shun</a>, Guy Blelloch <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08380">PDF</a><br/><b>Abstract: </b>Due to the dynamic nature of real-world graphs, there has been a growing
interest in the graph-streaming setting where a continuous stream of graph
updates is mixed with arbitrary graph queries. In principle, purely-functional
trees are an ideal choice for this setting due as they enable safe parallelism,
lightweight snapshots, and strict serializability for queries. However,
directly using them for graph processing would lead to significant space
overhead and poor cache locality.
</p>
<p>This paper presents C-trees, a compressed purely-functional search tree data
structure that significantly improves on the space usage and locality of
purely-functional trees. The key idea is to use a chunking technique over trees
in order to store multiple entries per tree-node. We design
theoretically-efficient and practical algorithms for performing batch updates
to C-trees, and also show that we can store massive dynamic real-world graphs
using only a few bytes per edge, thereby achieving space usage close to that of
the best static graph processing frameworks.
</p>
<p>To study the efficiency and applicability of our data structure, we designed
Aspen, a graph-streaming framework that extends the interface of Ligra with
operations for updating graphs. We show that Aspen is faster than two
state-of-the-art graph-streaming systems, Stinger and LLAMA, while requiring
less memory, and is competitive in performance with the state-of-the-art static
graph frameworks, Galois, GAP, and Ligra+. With Aspen, we are able to
efficiently process the largest publicly-available graph with over two hundred
billion edges in the graph-streaming setting using a single commodity multicore
server with 1TB of memory.
</p></div>
    </summary>
    <updated>2019-04-18T23:29:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08355</id>
    <link href="http://arxiv.org/abs/1904.08355" rel="alternate" type="text/html"/>
    <title>JGraphT -- A Java library for graph data structures and algorithms</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Michail:Dimitrios.html">Dimitrios Michail</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kinable:Joris.html">Joris Kinable</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Naveh:Barak.html">Barak Naveh</a>, John V Sichi <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08355">PDF</a><br/><b>Abstract: </b>Mathematical software and graph-theoretical algorithmic packages to
efficiently model, analyze and query graphs are crucial in an era where
large-scale spatial, societal and economic network data are abundantly
available. One such package is JGraphT, a programming library which contains
very efficient and generic graph data-structures along with a large collection
of state-of-the-art algorithms. The library is written in Java with stability,
interoperability and performance in mind. A distinctive feature of this library
is the ability to model vertices and edges as arbitrary objects, thereby
permitting natural representations of many common networks including
transportation, social and biological networks. Besides classic graph
algorithms such as shortest-paths and spanning-tree algorithms, the library
contains numerous advanced algorithms: graph and subgraph isomorphism; matching
and flow problems; approximation algorithms for NP-hard problems such as
independent set and TSP; and several more exotic algorithms such as Berge graph
detection. Due to its versatility and generic design, JGraphT is currently used
in large-scale commercial, non-commercial and academic research projects. In
this work we describe in detail the design and underlying structure of the
library, and discuss its most important features and algorithms. A
computational study is conducted to evaluate the performance of JGraphT versus
a number of similar libraries. Experiments on a large number of graphs over a
variety of popular algorithms show that JGraphT is highly competitive with
other established libraries such as NetworkX or the BGL.
</p></div>
    </summary>
    <updated>2019-04-18T23:27:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08343</id>
    <link href="http://arxiv.org/abs/1904.08343" rel="alternate" type="text/html"/>
    <title>The power word problem</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lohrey:Markus.html">Markus Lohrey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wei=szlig=:Armin.html">Armin Weiß</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08343">PDF</a><br/><b>Abstract: </b>In this work we introduce a new succinct variant of the word problem in a
finitely generated group $G$, which we call the power word problem: the input
word may contain powers $p^x$, where $p$ is a finite word over generators of
$G$ and $x$ is a binary encoded integer. The power word problem is a
restriction of the compressed word problem, where the input word is represented
by a straight-line program (i.e., an algebraic circuit over $G$). The main
result of the paper states that the power word problem for a finitely generated
free group $F$ is AC$^0$-Turing-reducible to the word problem for $F$.
Moreover, the following hardness result is shown: For a wreath product $G \wr
\mathbb{Z}$, where $G$ is either free of rank at least two or finite
non-solvable, the power word problem is complete for coNP. This contrasts with
the situation where $G$ is abelian: then the power word problem is shown to be
in TC$^0$.
</p></div>
    </summary>
    <updated>2019-04-18T23:21:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08255</id>
    <link href="http://arxiv.org/abs/1904.08255" rel="alternate" type="text/html"/>
    <title>Online Matching with General Arrivals</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gamlath:Buddhima.html">Buddhima Gamlath</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kapralov:Michael.html">Michael Kapralov</a>, Andreas Maggiori, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Svensson:Ola.html">Ola Svensson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wajc:David.html">David Wajc</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08255">PDF</a><br/><b>Abstract: </b>The online matching problem was introduced by Karp, Vazirani and Vazirani
nearly three decades ago. In that seminal work, they studied this problem in
bipartite graphs with vertices arriving only on one side, and presented optimal
deterministic and randomized algorithms for this setting. In comparison, more
general arrival models, such as edge arrivals and general vertex arrivals, have
proven more challenging and positive results are known only for various
relaxations of the problem. In particular, even the basic question of whether
randomization allows one to beat the trivially-optimal deterministic
competitive ratio of $\frac{1}{2}$ for either of these models was open. In this
paper, we resolve this question for both these natural arrival models, and show
the following.
</p>
<p>1. For edge arrivals, randomization does not help --- no randomized algorithm
is better than $\frac{1}{2}$ competitive.
</p>
<p>2. For general vertex arrivals, randomization helps --- there exists a
randomized $(\frac{1}{2}+\Omega(1))$-competitive online matching algorithm.
</p></div>
    </summary>
    <updated>2019-04-18T23:26:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08178</id>
    <link href="http://arxiv.org/abs/1904.08178" rel="alternate" type="text/html"/>
    <title>Novel Dense Subgraph Discovery Primitives: Risk Aversion and Exclusion Queries</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsourakakis:Charalampos_E=.html">Charalampos E. Tsourakakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Tianyi.html">Tianyi Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kakimura:Naonori.html">Naonori Kakimura</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pachocki:Jakub.html">Jakub Pachocki</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08178">PDF</a><br/><b>Abstract: </b>In the densest subgraph problem, given a weighted undirected graph
$G(V,E,w)$, with non-negative edge weights, we are asked to find a subset of
nodes $S\subseteq V$ that maximizes the degree density $w(S)/|S|$, where $w(S)$
is the sum of the edge weights induced by $S$. This problem is a well studied
problem, known as the {\em densest subgraph problem}, and is solvable in
polynomial time. But what happens when the edge weights are negative? Is the
problem still solvable in polynomial time? Also, why should we care about the
densest subgraph problem in the presence of negative weights?
</p>
<p>In this work we answer the aforementioned question. Specifically, we provide
two novel graph mining primitives that are applicable to a wide variety of
applications. Our primitives can be used to answer questions such as "how can
we find a dense subgraph in Twitter with lots of replies and mentions but no
follows?", "how do we extract a dense subgraph with high expected reward and
low risk from an uncertain graph"? We formulate both problems mathematically as
special instances of dense subgraph discovery in graphs with negative weights.
We study the hardness of the problem, and we prove that the problem in general
is NP-hard. We design an efficient approximation algorithm that works well in
the presence of small negative weights, and also an effective heuristic for the
more general case. Finally, we perform experiments on various real-world
uncertain graphs, and a crawled Twitter multilayer graph that verify the value
of the proposed primitives, and the practical value of our proposed algorithms.
</p>
<p>The code and the data are available at \url{https://github.com/negativedsd}.
</p></div>
    </summary>
    <updated>2019-04-18T23:29:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08150</id>
    <link href="http://arxiv.org/abs/1904.08150" rel="alternate" type="text/html"/>
    <title>A Brief Note on Single Source Fault Tolerant Reachability</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lokshtanov:Daniel.html">Daniel Lokshtanov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Misra:Pranabendu.html">Pranabendu Misra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Saket.html">Saket Saurabh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zehavi:Meirav.html">Meirav Zehavi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08150">PDF</a><br/><b>Abstract: </b>Let $G$ be a directed graph with $n$ vertices and $m$ edges, and let $s \in
V(G)$ be a designated source vertex. We consider the problem of single source
reachability (SSR) from $s$ in presence of failures of edges (or vertices).
Formally, a spanning subgraph $H$ of $G$ is a {\em $k$-Fault Tolerant
Reachability Subgraph ($k$-FTRS)} if it has the following property. For any set
$F$ of at most $k$ edges (or vertices) in $G$, and for any vertex $v\in V(G)$,
the vertex $v$ is reachable from $s$ in $G-F$ if and only if it is reachable
from $s$ in $H - F$. Baswana et.al. [STOC 2016, SICOMP 2018] showed that in the
setting above, for any positive integer $k$, we can compute a $k$-FTRS with
$2^k n$ edges. In this paper, we give a much simpler algorithm for computing a
$k$-FTRS, and observe that it extends to higher connectivity as well. Our
results follow from a simple application of \emph{important separators}, a well
known technique in Parameterized Complexity.
</p></div>
    </summary>
    <updated>2019-04-18T23:23:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08112</id>
    <link href="http://arxiv.org/abs/1904.08112" rel="alternate" type="text/html"/>
    <title>A Lower Bound for Relaxed Locally Decodable Codes</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gur:Tom.html">Tom Gur</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lachish:Oded.html">Oded Lachish</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08112">PDF</a><br/><b>Abstract: </b>A locally decodable code (LDC) C:{0,1}^k -&gt; {0,1}^n is an error correcting
code wherein individual bits of the message can be recovered by only querying a
few bits of a noisy codeword. LDCs found a myriad of applications both in
theory and in practice, ranging from probabilistically checkable proofs to
distributed storage. However, despite nearly two decades of extensive study,
the best known constructions of O(1)-query LDCs have super-polynomial
blocklength.
</p>
<p>The notion of relaxed LDCs is a natural relaxation of LDCs, which aims to
bypass the foregoing barrier by requiring local decoding of nearly all
individual message bits, yet allowing decoding failure (but not error) on the
rest. State of the art constructions of O(1)-query relaxed LDCs achieve
blocklength n = O(k^{1+ \gamma}) for an arbitrarily small constant \gamma.
</p>
<p>We prove a lower bound which shows that O(1)-query relaxed LDCs cannot
achieve blocklength n = k^{1+ o(1)}. This resolves an open problem raised by
Ben-Sasson, Goldreich, Harsha, Sudan, and Vadhan (STOC 2004).
</p></div>
    </summary>
    <updated>2019-04-18T23:21:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08078</id>
    <link href="http://arxiv.org/abs/1904.08078" rel="alternate" type="text/html"/>
    <title>Approximating Cumulative Pebbling Cost is Unique Games Hard</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blocki:Jeremiah.html">Jeremiah Blocki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Seunghoon.html">Seunghoon Lee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Samson.html">Samson Zhou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08078">PDF</a><br/><b>Abstract: </b>The cumulative pebbling complexity of a directed acyclic graph $G$ is defined
as $\mathsf{cc}(G) = \min_P \sum_i |P_i|$, where the minimum is taken over all
legal (parallel) black pebblings of $G$ and $|P_i|$ denotes the number of
pebbles on the graph during round $i$. Intuitively, $\mathsf{cc}(G)$ captures
the amortized Space-Time complexity of pebbling $m$ copies of $G$ in parallel.
The cumulative pebbling complexity of a graph $G$ is of particular interest in
the field of cryptography as $\mathsf{cc}(G)$ is tightly related to the
amortized Area-Time complexity of the data-independent memory hard function
(iMHF) $f_{G,H}$ [AS15] defined using a constant indegree directed acyclic
graph (DAG) $G$ and a random oracle $H(\cdot)$. A secure iMHF should have
amortized Space-Time complexity as high as possible e.g., to deter brute-force
password attacker who wants to find $x$ such that $f_{G,H}(x) = h$. Thus, to
analyze the (in)security of a candidate iMHF $f_{G,H}$, it is crucial to
estimate the value $\mathsf{cc}(G)$ but currently, upper and lower bounds for
leading iMHF candidates differ by several orders of magnitude. Blocki and Zhou
recently showed that is $\mathsf{NP}$-Hard to compute $\mathsf{cc}(G)$, but
their techniques do not even rule out an efficient $(1+\epsilon)$-approximation
algorithm for any constant $\epsilon&gt;0$. We show that for any constant $c&gt;0$,
it is Unique Games hard to approximate $\mathsf{cc}(G)$ to within a factor of
$c$.
</p>
<p>(See the paper for the full abstract.)
</p></div>
    </summary>
    <updated>2019-04-18T23:21:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08053</id>
    <link href="http://arxiv.org/abs/1904.08053" rel="alternate" type="text/html"/>
    <title>A scaled space-filling curve index applied to tropical rain forest tree distributions</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Markus Wilhelm Jahn, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bradley:Patrick_Erik.html">Patrick Erik Bradley</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08053">PDF</a><br/><b>Abstract: </b>In order to be able to process the increasing amount of spatial data,
efficient methods for their handling need to be developed. One major challenge
for big spatial data is access. This can be achieved through space-filling
curves, as they have the property that nearby points on the curve are also
nearby in space. It is demonstrated on a tropical rain forest tree data set of
2.5 million points taken from a multi-dimensional space that the recently
constructed scaled Gray-Hilbert curve index performs better than its standard
static version, saving a significant amount of space for a projection of the
data set onto 8 attributes. The relative efficiency of the scaled Gray-Hilbert
curve in comparison with the best static version is seen to depend on the
distribution of the point cloud. A local sparsity measure derived from
properties of the corresponding trees can distinguish point clouds with
different tail distributions.
</p></div>
    </summary>
    <updated>2019-04-18T23:31:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.08037</id>
    <link href="http://arxiv.org/abs/1904.08037" rel="alternate" type="text/html"/>
    <title>Improved Distributed Expander Decomposition and Nearly Optimal Triangle Enumeration</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chang:Yi=Jun.html">Yi-Jun Chang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saranurak:Thatchaphol.html">Thatchaphol Saranurak</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.08037">PDF</a><br/><b>Abstract: </b>An $(\epsilon,\phi)$-expander decomposition of a graph $G=(V,E)$ is a
clustering of the vertices $V=V_{1}\cup\cdots\cup V_{x}$ such that (1) each
cluster $V_{i}$ induces subgraph with conductance at least $\phi$, and (2) the
number of inter-cluster edges is at most $\epsilon|E|$. In this paper, we give
an improved distributed expander decomposition in the CONGEST model.
Specifically, we construct an $(\epsilon,\phi)$-expander decomposition with
$\phi=(\epsilon/\log n)^{2^{O(k)}}$ in $O(n^{2/k}\cdot\text{poly}(1/\phi,\log
n))$ rounds for any $\epsilon\in(0,1)$ and positive integer $k$. For example, a
$(0.01,1/\text{poly}\log n)$-expander decomposition can be computed in
$O(n^{\gamma})$ rounds, for any constant $\gamma&gt;0$. Previously, the algorithm
by Chang, Pettie, and Zhang can construct a $(1/6,1/\text{poly}\log
n)$-expander decomposition using $\tilde{O}(n^{1-\delta})$ rounds for any
$\delta&gt;0$, with a caveat that the algorithm is allowed to throw away a set of
edges which forms a subgraph with arboricity at most $n^{\delta}$. Our
algorithm does not have this caveat.
</p>
<p>By modifying the distributed algorithm for routing on expanders by Ghaffari,
Kuhn and Su [PODC'17], we obtain a triangle enumeration algorithm using
$\tilde{O}(n^{1/3})$ rounds. This matches the lower bound by Izumi and Le Gall
[PODC'17] and Pandurangan, Robinson and Scquizzato [SPAA'18] of
$\tilde{\Omega}(n^{1/3})$ which holds even in the CONGESTED-CLIQUE model. To
the best of our knowledge, this provides the first non-trivial example for a
problem that has essentially the same complexity (up to a polylogarithmic
factor) in both CONGEST and CONGESTED-CLIQUE.
</p>
<p>The key technique in our proof is the first distributed approximation
algorithm for finding a low conductance cut that is as balanced as possible.
Previous distributed sparse cut algorithms do not have this nearly most
balanced guarantee.
</p></div>
    </summary>
    <updated>2019-04-18T23:31:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07964</id>
    <link href="http://arxiv.org/abs/1904.07964" rel="alternate" type="text/html"/>
    <title>3D Shape Synthesis for Conceptual Design and Optimization Using Variational Autoencoders</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Wentai.html">Wentai Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Zhangsihao.html">Zhangsihao Yang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Haoliang.html">Haoliang Jiang</a>, Suyash Nigam, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yamakawa:Soji.html">Soji Yamakawa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Furuhata:Tomotake.html">Tomotake Furuhata</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shimada:Kenji.html">Kenji Shimada</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kara:Levent_Burak.html">Levent Burak Kara</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07964">PDF</a><br/><b>Abstract: </b>We propose a data-driven 3D shape design method that can learn a generative
model from a corpus of existing designs, and use this model to produce a wide
range of new designs. The approach learns an encoding of the samples in the
training corpus using an unsupervised variational autoencoder-decoder
architecture, without the need for an explicit parametric representation of the
original designs. To facilitate the generation of smooth final surfaces, we
develop a 3D shape representation based on a distance transformation of the
original 3D data, rather than using the commonly utilized binary voxel
representation. Once established, the generator maps the latent space
representations to the high-dimensional distance transformation fields, which
are then automatically surfaced to produce 3D representations amenable to
physics simulations or other objective function evaluation modules. We
demonstrate our approach for the computational design of gliders that are
optimized to attain prescribed performance scores. Our results show that when
combined with genetic optimization, the proposed approach can generate a rich
set of candidate concept designs that achieve prescribed functional goals, even
when the original dataset has only a few or no solutions that achieve these
goals.
</p></div>
    </summary>
    <updated>2019-04-18T23:32:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07957</id>
    <link href="http://arxiv.org/abs/1904.07957" rel="alternate" type="text/html"/>
    <title>Almost-Smooth Histograms and Sliding-Window Graph Algorithms</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krauthgamer:Robert.html">Robert Krauthgamer</a>, David Reitblat <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07957">PDF</a><br/><b>Abstract: </b>We study algorithms for the sliding-window model, an important variant of the
data-stream model, in which the goal is to compute some function of a
fixed-length suffix of the stream. We explore the smooth histogram framework of
Braverman and Ostrovsky (FOCS 2007) for reducing the sliding-window model to
the insertion-only streaming model, and extend it to the family of subadditive
functions. Specifically, we show that if a subadditive function can be
approximated in the ordinary (insertion-only) streaming model, then it could be
approximated also in the sliding-window model with approximation ratio larger
by factor $2+\epsilon$ and space complexity larger by factor
$O(\epsilon^{-1}\log w)$, where $w$ is the window size.
</p>
<p>We then consider graph streams and show that many graph problems are
subadditive, including maximum matching and minimum vertex-cover, thereby
deriving sliding-window algorithms for them almost for free (using known
insertion-only algorithms). One concrete example is a
$\mathrm{polylog}(n)$-space algorithm for estimating maximum-matching size in
bounded-arboricity graphs with $n$ vertices, whose approximation ratio differs
by a factor of $2$ from the insertion-only algorithm of McGregor and
Vorotnikova (SODA 2018).
</p>
<p>We also use the same framework to improve the analysis of a known
sliding-window algorithm for approximating minimum vertex-cover in general
graphs. We improve the approximation ratio $8+\epsilon$ of van Handel (MSc
Thesis 2016) to $4+\epsilon$ using the same space complexity
$\tilde{O}_\epsilon(n)$.
</p></div>
    </summary>
    <updated>2019-04-18T23:30:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07949</id>
    <link href="http://arxiv.org/abs/1904.07949" rel="alternate" type="text/html"/>
    <title>Extractors for small zero-fixing sources</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Pavel Pudlak, Vojtech Rodl <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07949">PDF</a><br/><b>Abstract: </b>A random variable $X$ is an $(n,k)$-zero-fixing source if for some subset
$V\subseteq[n]$, $X$ is the uniform distribution on the strings $\{0,1\}^n$
that are zero on every coordinate outside of $V$. An $\epsilon$-extractor for
$(n,k)$-zero-fixing sources is a mapping $F:\{0,1\}^n\to\{0,1\}^m$, for some
$m$, such that $F(X)$ is $\epsilon$-close in statistical distance to the
uniform distribution on $\{0,1\}^m$ for every $(n,k)$-zero-fixing source $X$.
Zero-fixing sources were introduced by Cohen and Shinkar in [10] in connection
with the previously studied extractors for bit-fixing sources. They
constructed, for every $\mu&gt;0$, an efficiently computable extractor that
extracts a positive fraction of entropy, i.e., $\Omega(k)$ bits, from
$(n,k)$-zero-fixing sources where $k\geq(\log\log n)^{2+\mu}$.
</p>
<p>In this paper we present two different constructions of extractors for
zero-fixing sources that are able to extract a positive fraction of entropy for
$k$ essentially smaller than $\log\log n$. The first extractor works for $k\geq
C\log\log\log n$, for some constant $C$. The second extractor extracts a
positive fraction of entropy for $k\geq \log^{(i)}n$ for any fixed $i\in
\mathbb{N}$, where $\log^{(i)}$ denotes $i$-times iterated logarithm. The
fraction of extracted entropy decreases with $i$. The first extractor is a
function computable in polynomial time in~$n$ (for $\epsilon=o(1)$, but not too
small); the second one is computable in polynomial time when
$k\leq\alpha\log\log n/\log\log\log n$, where $\alpha$ is a positive constant.
</p></div>
    </summary>
    <updated>2019-04-18T23:20:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1904.07902</id>
    <link href="http://arxiv.org/abs/1904.07902" rel="alternate" type="text/html"/>
    <title>Heuristic algorithms for the Longest Filled Common Subsequence Problem</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mincu:Radu_Stefan.html">Radu Stefan Mincu</a>, Alexandru Popa University of Bucharest, Romania, National Institute for Research and Development in Informatics, Bucharest, Romania) <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1904.07902">PDF</a><br/><b>Abstract: </b>At CPM 2017, Castelli et al. define and study a new variant of the Longest
Common Subsequence Problem, termed the Longest Filled Common Subsequence
Problem (LFCS). For the LFCS problem, the input consists of two strings $A$ and
$B$ and a multiset of characters $\mathcal{M}$. The goal is to insert the
characters from $\mathcal{M}$ into the string $B$, thus obtaining a new string
$B^*$, such that the Longest Common Subsequence (LCS) between $A$ and $B^*$ is
maximized. Casteli et al. show that the problem is NP-hard and provide a
3/5-approximation algorithm for the problem.
</p>
<p>In this paper we study the problem from the experimental point of view. We
introduce, implement and test new heuristic algorithms and compare them with
the approximation algorithm of Casteli et al. Moreover, we introduce an Integer
Linear Program (ILP) model for the problem and we use the state of the art ILP
solver, Gurobi, to obtain exact solution for moderate sized instances.
</p></div>
    </summary>
    <updated>2019-04-18T23:30:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1807.02740</id>
    <link href="http://arxiv.org/abs/1807.02740" rel="alternate" type="text/html"/>
    <title>Data-driven Upsampling of Point Clouds</title>
    <feedworld_mtime>1555545600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Wentai.html">Wentai Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Haoliang.html">Haoliang Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Zhangsihao.html">Zhangsihao Yang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yamakawa:Soji.html">Soji Yamakawa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shimada:Kenji.html">Kenji Shimada</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kara:Levent_Burak.html">Levent Burak Kara</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1807.02740">PDF</a><br/><b>Abstract: </b>High quality upsampling of sparse 3D point clouds is critically useful for a
wide range of geometric operations such as reconstruction, rendering, meshing,
and analysis. In this paper, we propose a data-driven algorithm that enables an
upsampling of 3D point clouds without the need for hard-coded rules. Our
approach uses a deep network with Chamfer distance as the loss function,
capable of learning the latent features in point clouds belonging to different
object categories. We evaluate our algorithm across different amplification
factors, with upsampling learned and performed on objects belonging to the same
category as well as different categories. We also explore the desirable
characteristics of input point clouds as a function of the distribution of the
point samples. Finally, we demonstrate the performance of our algorithm in
single-category training versus multi-category training scenarios. The final
proposed model is compared against a baseline, optimization-based upsampling
method. Results indicate that our algorithm is capable of generating more
uniform and accurate upsamplings.
</p></div>
    </summary>
    <updated>2019-04-18T23:31:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-04-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4166</id>
    <link href="https://www.scottaaronson.com/blog/?p=4166" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4166#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4166" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Just says in P</title>
    <summary xml:lang="en-US">Recently a Twitter account started called justsaysinmice. The only thing this account does, is to repost breathless news articles about medical research breakthroughs that fail to mention that the effect in question was only observed in mice, and then add the words “IN MICE” to them. Simple concept, but it already seems to be changing […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Recently a Twitter account started called <a href="https://twitter.com/justsaysinmice">justsaysinmice</a>.  The only thing this account does, is to repost breathless news articles about medical research breakthroughs that fail to mention that the effect in question was only observed in mice, and then add the words “IN MICE” to them.  Simple concept, but it already seems to be changing the conversation about science reporting.</p>



<p>It occurred to me that we could do something analogous for quantum computing.  While my own deep-seated aversion to Twitter prevents me from doing it myself, which of my readers is up for starting an account that just reposts one overhyped QC article after another, while appending the words “A CLASSICAL COMPUTER COULD ALSO DO THIS” to each one?</p></div>
    </content>
    <updated>2019-04-17T19:14:17Z</updated>
    <published>2019-04-17T19:14:17Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Speaking Truth to Parallelism"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-04-17T19:58:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17286</id>
    <link href="https://gilkalai.wordpress.com/2019/04/17/gothenburg-stockholm-lancaster-mitzpe-ramon-and-israeli-election-day-2019/" rel="alternate" type="text/html"/>
    <title>Gothenburg, Stockholm, Lancaster, Mitzpe Ramon, and Israeli Election Day 2019</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Lancaster – Watching the outcomes of the Israeli elections (photo: Andrey Kupavskii) Sweden I just came back from a trip to Sweden and the U.K. I was invited to Gothenburg to be the opponent for a Ph. D. Candidate  Malin … <a href="https://gilkalai.wordpress.com/2019/04/17/gothenburg-stockholm-lancaster-mitzpe-ramon-and-israeli-election-day-2019/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/04/dsc5390.jpg"><img alt="" class="alignnone size-medium wp-image-17287" height="200" src="https://gilkalai.files.wordpress.com/2019/04/dsc5390.jpg?w=300&amp;h=200" width="300"/></a> <a href="https://gilkalai.files.wordpress.com/2019/04/hand.png"><img alt="" class="alignnone size-medium wp-image-17288" height="251" src="https://gilkalai.files.wordpress.com/2019/04/hand.png?w=300&amp;h=251" width="300"/></a></p>
<p><span style="color: #ff0000;">Lancaster – Watching the outcomes of the Israeli elections (photo: Andrey Kupavskii)</span></p>
<h3>Sweden</h3>
<p>I just came back from a trip to Sweden and the U.K. I was invited to Gothenburg to be the opponent for a Ph. D. Candidate  Malin Palö Forsström (by now Dr. Malin Palö Forsström),  who wrote her excellent Ph. D. thesis under the supervision of Jeff Steif in Chalmers University. We also used the opportunity for a lovely mini-mini-workshop</p>
<p>From Gothenburg I took the train to Stockholm to spend the weekend with Anders Björner and we talked about some old projects regarding algebraic shifting.  We had dinner with several colleagues including Svante Linusson who is a candidate for the European parliament!</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/acg80s.jpeg"><img alt="" class="alignnone size-full wp-image-17296" src="https://gilkalai.files.wordpress.com/2019/04/acg80s.jpeg?w=640"/></a> <a href="https://gilkalai.files.wordpress.com/2019/04/20190407_194045.jpg"><img alt="" class="alignnone size-medium wp-image-17297" height="168" src="https://gilkalai.files.wordpress.com/2019/04/20190407_194045.jpg?w=300&amp;h=168" width="300"/></a></p>
<p><span style="color: #ff0000;">Stockholm: With Anders and Cristins in the late 80s (left, I think this was also when I was an opponent), Svante Linusson ten days ago (right)</span></p>
<h3>The United Kingdom</h3>
<p>The <a href="https://www.lancaster.ac.uk/maths/bmc2019/">British Mathematical Colloquium at Lancaster</a> was a lovely 4-day general meeting, an opportunity to meet some old and new friends (and Internet MO friend <a href="https://mathoverflow.net/users/763/yemon-choi">Yemon Choi</a> in real life), and to learn about various new developments. I am aware of the fact that my list of unfulfilled promises is longer than those of most politicians, but I do hope to come back to some mathematics from this trip to Sweden and to Lancaster.</p>
<h3>Election Day</h3>
<p>Last week’s Tuesday was election day in Israel,  and as much as I like to participate (and to devote a post to election day here on the blog – in <a href="https://gilkalai.wordpress.com/2009/02/10/majority-rules-the-story-of-achnais-oven/">2009</a>, <a href="https://gilkalai.wordpress.com/2013/01/22/election-day/">2012</a>, and <a href="https://gilkalai.wordpress.com/2015/03/17/election-day-2/">2015</a>) I had to miss the election, for the first time since 1985. (I still tried to follow the outcomes in real time.)</p>
<h3>The Negev, Israel</h3>
<p>And we are now spending a three-day vacation and doing some mild hiking in Mitzpe Ramon, in the Negev, the Israeli desert.  The view around here is spectacular. I first fell in love with the sights of the Negev when I spent six months here when I was 19 (in the army). Since then we have been caming here many times over the years, and in 2002 the annual meeting of the Israeli Mathematical Union took place here, in the same hotel.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/04/img-20190416-wa0036.jpg"><img alt="" class="alignnone size-medium wp-image-17298" height="300" src="https://gilkalai.files.wordpress.com/2019/04/img-20190416-wa0036.jpg?w=169&amp;h=300" width="169"/></a> <a href="https://gilkalai.files.wordpress.com/2019/04/fb_img_1555444073776-e1555444196265.jpg"> <img alt="" class="alignnone size-medium wp-image-17299" height="165" src="https://gilkalai.files.wordpress.com/2019/04/fb_img_1555444073776-e1555444196265.jpg?w=300&amp;h=165" width="300"/></a></p>
<p><span style="color: #ff0000;">Ein Ovdat (left). The 2002 Annual meeting of the IMU (right). A large number of Israeli mathematicians come to a substantial fraction of these annual events.</span></p>
<h3>The stance of the main Israeli parties on quantum computing</h3>
<p>One anecdote about the Israeli election is that both major political parties of Israel, the Likud, led by Benjamin (Bibi) Netanyahu that won 35 seats in the parliament and will probably lead the coalition, and the newly formed “Blue-and-White” party, led by Benny (Benjamin) Gantz that also won 35 seats and will probably lead the opposition, stand behind quantum computing! <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/03/bw-quantum.png"><img alt="" class="alignnone size-medium wp-image-17121" height="233" src="https://gilkalai.files.wordpress.com/2019/03/bw-quantum.png?w=300&amp;h=233" width="300"/></a><a href="https://gilkalai.files.wordpress.com/2019/04/qcbibi.png"> <img alt="" class="alignnone size-medium wp-image-17302" height="258" src="https://gilkalai.files.wordpress.com/2019/04/qcbibi.png?w=300&amp;h=258" width="300"/></a></p>
<p><span style="color: #ff0000;">Left – A paragraph from “Blue and White’s” charter with a pledge to quantum computing (I thank Noam Lifshitz for telling me about it). Right –  a news item (<a href="https://en.globes.co.il/en/article-government-allocates-nis-300m-for-quantum-computing-1001244244">click for the article</a>) about the quantum computing vision of Netanyahu and the Likud party.</span></p>
<p> </p></div>
    </content>
    <updated>2019-04-17T19:10:12Z</updated>
    <published>2019-04-17T19:10:12Z</published>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Updates"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-04-19T20:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4227</id>
    <link href="https://lucatrevisan.wordpress.com/2019/04/17/online-optimization-for-complexity-theorists/" rel="alternate" type="text/html"/>
    <title>Online Optimization for Complexity Theorists</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Last year I took some time off to study online convex optimization in some detail. The reason for doing that was similar to the reason why at some point I took time off to study spectral graph theory: it was … <a href="https://lucatrevisan.wordpress.com/2019/04/17/online-optimization-for-complexity-theorists/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
 Last year I took some time off to study online convex optimization in some detail. The reason for doing that was similar to the reason why at some point I took time off to study spectral graph theory: it was coming up in several papers that I wanted to understand, and I felt that I was missing out by not mastering an important tool. In particular, I wanted to understand: </p>
<ol>
<li> The <a href="https://dl.acm.org/citation.cfm?id=1496770.1496899">Barak-Hardt-Kale</a> proof of the <a href="https://ieeexplore.ieee.org/document/492584">Impagliazzo hard-core lemma</a>.
</li><li> The online convex optimization viewpoint on the <a href="https://ieeexplore.ieee.org/document/548459">Frieze-Kannan weak regularity lemma</a>, on the dense model theorem of <a href="https://ieeexplore.ieee.org/document/4690942">(RTTV)</a>, and on the abstract weak regularity lemma of <a href="https://ieeexplore.ieee.org/document/5231258">(TTV)</a> that were described to me by Madhur Tulsiani a few years ago. Furthermore, I wanted to see if Russel Impagliazzo’s subsequent improvements to the dense model theorem and to the abstract weak regularity lemma could be recovered from this point of view.
</li><li> The <a href="https://dl.acm.org/citation.cfm?doid=2906142.2837020">Arora-Kale</a> algorithms for semidefinite programming, including their nearly linear-time algorithm for approximating the Goemans-Williamson relaxation of Max Cut.
</li><li> The meaning of the sentence “multiplicative weights and gradient descent are both special cases of follow-the-regularized-leader, using negative entropy and <img alt="{\ell_2^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2^2}"/> as regularizer, respectively.”
</li><li> The <a href="https://arxiv.org/abs/1506.04838">AllenZhu-Liao-Orecchia</a> online optimization proof of the Batson-Spielman-Srivastava sparsification result.
</li></ol>
<p>
I am happy to say that, except for the “furthermore” part of (2), I achieved my goals. To digest this material a bit better, I came up with the rather ambitious plan of writing a series of posts, in which I would alternate between (i) explaining a notion or theorem from online convex optimization (at a level that someone learning about optimization or machine learning might find useful) and (ii) explaining a complexity-theoretic application. Now that a very intense Spring semester is almost over, I plan to get started on this plan, although it is not clear that I will see it through the end. So stay tuned for the forthcoming first episode, which will be about the good old multiplicative weights algorithm.</p>
<p/></div>
    </content>
    <updated>2019-04-17T15:27:23Z</updated>
    <published>2019-04-17T15:27:23Z</published>
    <category term="theory"/>
    <category term="online optimization"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-04-19T20:20:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4224</id>
    <link href="https://lucatrevisan.wordpress.com/2019/04/16/the-early-years-of-computing-in-italy/" rel="alternate" type="text/html"/>
    <title>The Early Years of Computing in Italy</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Here are in theory‘s first ever book reviews! The books are Giorgio Garuzzo Quando in Italia si facevano i computer Available for free at Amazon.com and Amazon.it. Giorgio Ausiello The Making of a New Science Available from Springer, as a … <a href="https://lucatrevisan.wordpress.com/2019/04/16/the-early-years-of-computing-in-italy/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Here are <i>in theory</i>‘s first ever book reviews! The books are</p>
<p>Giorgio Garuzzo<br/>
<i>Quando in Italia si facevano i computer</i><br/>
Available for free at <a href="https://www.amazon.com/gp/product/B017PTTUKY">Amazon.com</a> and <a href="https://www.amazon.it/Quando-facevano-computer-Giorgio-Garuzzo-ebook/dp/B017PTTUKY">Amazon.it</a>.</p>
<p>Giorgio Ausiello<br/>
<i>The Making of a New Science</i><br/>
Available from <a href="https://www.springer.com/us/book/9783319626796">Springer</a>, as a DRM-free PDF through your academic library.</p>
<p>Both books talk about the early years of computing in Italy, on the industrial and academic side, respectively. They briefly intersect with the story of Olivetti’s Elea computer.</p>
<p><span id="more-4224"/></p>
<p>Olivetti was a company that was founded in 1908 to make typewriters, and then branched out to other office/business machines and avionics. In the 1930s, Adriano Olivetti, a son of the founder Camillo Olivetti, took over the company. Adriano Olivetti was an unusual figure of entrepreneur deeply interested in arts, humanities and social sciences, with a utopian vision of a company reinvesting its profits in its community. In the 1950s, he led the company to develop the Elea, the first Italian computer. The Elea was made with transistors, and it came out before IBM had built its own first transistor-based computer.</p>
<p>The development of Elea was led by Mario Tchou. Mario Tchou was a Chinese-Italian born and raised in Rome, who studied electrical engineering at the Sapienza University of Rome and then at Brooklyn Polytechnic, eventually becoming an assistant professor at Columbia University. Olivetti persuaded Tchou to move back to Italy and lead the development of Elea, whose first prototype came out in 1957. </p>
<p>As production was ramping up, tragedy struck: Adriano Olivetti died in 1960, and Mario Tchou died in 1961. To shore up the finances of the company, the new CEO Roberto Olivetti brought in a series of new investors, who pushed to spin off the computer business.</p>
<p>At that point, Olivetti was working on another revolutionary machine, the P101, a programmable desktop calculator billed as the “first desktop computer,” which came out in 1964, attracting huge interest. Nonetheless the company spun off its “computer” division into a joint venture with GE, eventually divesting of it completely. Fortunately, they kept control of the P101 project, because those working on it were careful in branding it internally as a “calculator” (not part of the of deal with GE) rather than a “computer.”</p>
<p>These events are narrated, with a fascinating insider view, in Garuzzo’s book.</p>
<p>Giorgio Ausiello is one of the founding fathers of academic computer science in Italy. His book is a professional memoir that starts in the 1960s, at the time in which he started working on his undergraduate thesis at the Istituto Nazionale per le Applicazioni del Calcolo (INAC, later renamed IAC) at the National Research Council in Rome. At that point INAC had one of Italy’s few computers, a machine bought in 1954 from the Ferranti company in Manchester (when it was installed, it was Italy’s <i>second</i> computer).</p>
<p>As narrated in a <a href="https://lucatrevisan.wordpress.com/2017/10/23/corrado-bohm/">previous post</a>, Mauro Picone, the mathematician who was leading INAC, brought Corrado Bohm to Rome to work on this computer, and Ausiello started to work with Bohm at the time in which he was just starting to think about models of computation and lambda-calculus.</p>
<p>Later, Ausiello visited Berkeley in the 1968-69 academic year, when Manuel Blum and Dick Karp had just joined the faculty. Ausiello took part in the first STOC, which was held in Marina del Rey in May 1969, and, later that month, he witnessed the occupation of <a href="https://en.wikipedia.org/wiki/People%27s_Park_(Berkeley)">People’s Park</a> in Berkeley.</p>
<p>The Fall of 1969 marks the start of the first Italian undergraduate programs in Computer Science, in just four universities:  Bari, <del datetime="2019-04-17T11:04:18-07:00">Milan,</del> Pisa and Torino. Back in Italy from Berkeley, Ausiello continued to work at the National Research Council in Rome.</p>
<p>The book continues with a behind-the-scene narration of the events that led to the founding of the EATCS professional society, the ICALP conference and the TCS journal. There is also another trip to Berkeley in the 1980s, featuring Silvio Micali and Vijay Vazirani working on their matching algorithm, and Shafi Goldwasser just arriving in Berkeley.</p>
<p>Methodically documented and very detail-oriented, the book is a fascinating read, although it leaves you sometimes wanting to hear more about the personalities and the stories of the people involved and less about the attendance lists of certain meetings.</p>
<p>Even when it comes to the dryer details, however, I am happy that the books documents them and makes them available to future generations that will not have any living memory of the 1960s and 1970s.</p>
<p>I should also mention that Alon Rosen has recently interviewed <a href="https://www.youtube.com/watch?v=vKCE7QnsFcw&amp;t=67s">Christos Papadimitriou</a> and <a href="https://www.youtube.com/watch?v=-GQnK6ys6C0&amp;t=20s">Avi Wigderson</a> and those (<i>long</i>) interviews are full of good stories. Finally, the Simons Foundation site has an <a href="https://www.simonsfoundation.org/2013/02/14/laszlo-lovasz/">interview of Laszlo Lovasz</a> in conversation with Avi Wigderson which I very highly recommend everybody to watch.</p></div>
    </content>
    <updated>2019-04-17T00:52:21Z</updated>
    <published>2019-04-17T00:52:21Z</published>
    <category term="Berkeley"/>
    <category term="history"/>
    <category term="Italy"/>
    <category term="theory"/>
    <category term="Giorgio Ausiello"/>
    <category term="Giorgio Garuzzo"/>
    <category term="P101"/>
    <category term="Elea"/>
    <category term="Olivetti"/>
    <category term="Mario Tchou"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-04-19T20:20:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/058</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/058" rel="alternate" type="text/html"/>
    <title>TR19-058 |  Extractors for small zero-fixing sources | 

	Pavel Pudlak, 

	Vojtech Rodl</title>
    <summary>A random variable $X$ is an $(n,k)$-zero-fixing source if for some subset $V\subseteq[n]$, $X$ is the uniform distribution on the strings $\{0,1\}^n$ that are zero on every coordinate outside of $V$. An $\epsilon$-extractor for $(n,k)$-zero-fixing sources is a mapping $F:\{0,1\}^n\to\{0,1\}^m$, for some $m$, such that $F(X)$ is $\epsilon$-close in statistical distance to the uniform distribution on $\{0,1\}^m$ for every $(n,k)$-zero-fixing source $X$. Zero-fixing sources were introduced by Cohen and Shinkar in~2015 in connection with the previously studied extractors for bit-fixing sources. They constructed, for every $\mu&gt;0$, an efficiently computable extractor that extracts a positive fraction of entropy, i.e., $\Omega(k)$ bits, from $(n,k)$-zero-fixing sources where $k\geq(\log\log n)^{2+\mu}$. 

In this paper we present two different constructions of extractors for zero-fixing sources that are able to extract a positive fraction of entropy for $k$ essentially smaller than $\log\log n$. The first extractor works for $k\geq C\log\log\log n$, for some constant $C$. The second extractor extracts a positive fraction of entropy for $k\geq \log^{(i)}n$ for any fixed $i\in \N$, where $\log^{(i)}$ denotes $i$-times iterated logarithm. The fraction of extracted entropy decreases with $i$. The first extractor is a function computable in polynomial time in~$n$ (for $\epsilon=o(1)$, but not too small); the second one is computable in polynomial time when $k\leq\alpha\log\log n/\log\log\log n$, where $\alpha$ is a positive constant.</summary>
    <updated>2019-04-16T15:10:03Z</updated>
    <published>2019-04-16T15:10:03Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-19T20:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/04/16/tensors-algebra-computation-applications/</id>
    <link href="https://cstheory-events.org/2019/04/16/tensors-algebra-computation-applications/" rel="alternate" type="text/html"/>
    <title>Tensors: Algebra-Computation-Applications</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">June 3-14, 2019 U. Colorado Boulder and Colorado State U https://thetensor.space/workshops/2019/02/13/TACA-2019.html The Department of Mathematics at Colorado State University and the Department of Computer Science at the University of Colorado, Boulder invite interested participants to attend a workshop and conference on Tensors: Algebra, Computation, and Applications (TACA). The central theme of tensors is meant to … <a class="more-link" href="https://cstheory-events.org/2019/04/16/tensors-algebra-computation-applications/">Continue reading <span class="screen-reader-text">Tensors: Algebra-Computation-Applications</span></a></div>
    </summary>
    <updated>2019-04-16T15:01:44Z</updated>
    <published>2019-04-16T15:01:44Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-04-19T20:21:10Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/04/15/linkage</id>
    <link href="https://11011110.github.io/blog/2019/04/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>“You know how the \hat command in LaTeΧ puts a caret above a letter? … Well I was thinking it would be funny if someone made a package that made the \hat command put a picture of an actual hat on the symbol instead?” And then Matthew Scroggs and Adam Townsend went ahead and did it ().</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://aperiodical.com/2019/03/realhats-writing-a-latex-package/">“You know how the \hat command in LaTeΧ puts a caret above a letter? … Well I was thinking it would be funny if someone made a package that made the \hat command put a picture of an actual hat on the symbol instead?”</a>
And then Matthew Scroggs and Adam Townsend went ahead and <a href="https://ctan.org/pkg/realhats">did it</a> (<a href="https://mathstodon.xyz/@11011110/101849504150959463"/>).</p>
  </li>
  <li>
    <p><a href="https://syntopia.github.io/Polytopia/polytopes.html">Generating 4d polyhedra from their symmetries</a> (<a href="https://mathstodon.xyz/@11011110/101860652773207990"/>, <a href="https://web.archive.org/web/20190306075446/https://plus.google.com/+RoiceNelson/posts/13EEovjAjh3">via</a>), by Mikael Hvidtfeldt Christensen.</p>
  </li>
  <li>
    <p><a href="https://windowsontheory.org/2019/04/03/focs-2019-real-website-and-submission-server/">Windows on Theory</a> and <a href="https://www.scottaaronson.com/blog/?p=4154">Scott Aaronson</a> both warn about a fake web site for <a href="http://focs2019.cs.jhu.edu/">FOCS 2019</a>, whose submission deadline just passed (<a href="https://mathstodon.xyz/@11011110/101864693573223236"/>).</p>
  </li>
  <li>
    <p><a href="http://service.ifam.uni-hannover.de/~geometriewerkstatt/gallery/index.html">GeometrieWerkstatt Gallery</a> (<a href="https://mathstodon.xyz/@11011110/101872198999374479"/>). A collection of weirdly-shaped mathematical surfaces, mostly of constant mean curvature.</p>
  </li>
  <li>
    <p><a href="http://focs2019.cs.jhu.edu/awards/">Sandi Irani wins IEEE TCMF Distinguished Service Award</a> (<a href="https://mathstodon.xyz/@11011110/101877216457233962"/>). The award recognizes her work chairing the <a href="https://www.ics.uci.edu/~irani/safetoc.html">ad hoc committee to combat harassment and discrimination in the theory of computing community</a>, and then getting many theory conferences to follow its recommendations.</p>
  </li>
  <li>
    <p><a href="http://web.colby.edu/thegeometricviewpoint/2014/04/25/periodic-billiard-paths/">Periodic billiard paths</a> (<a href="https://mathstodon.xyz/@11011110/101883476235740072"/>). If the boundary of a given polygon is made of mirrors, these are paths that a laser beam could take that would eventually reflect back to the starting point and angle and then repeat infinitely. It remains a heavily-studied open question whether such paths exist in every triangle. This blog post from 2014 provides a proof that they do exist in polygons whose vertex angles are all rational multiples of .</p>
  </li>
  <li>
    <p><a href="https://retractionwatch.com/2019/04/08/with-a-badly-handled-tweet-plos-angers-scientists-after-a-blog-disappears/">PLOS disappears one (or maybe more) of its hosted blogs</a> (<a href="https://mathstodon.xyz/@11011110/101894568161561631"/>) without any warning to the blog author, without any attempt at keeping old blog links still working, and with only a belated apology.</p>
  </li>
  <li>
    <p><a href="https://slate.com/news-and-politics/2019/03/scotus-gerrymandering-case-mathematicians-brief-elena-kagan.html">The Supreme Court’s math problem</a> (<a href="https://mathstodon.xyz/@11011110/101900050555580515"/>, <a href="https://www.metafilter.com/180163/The-Supreme-Courts-Math-Problem">via</a>). Jordan Ellenberg explains why, in testing for gerrymandering, asking about deviation from proportional representation is the wrong question. Democratic systems naturally concentrate power to the majority rather than being proportional. The right question is whether that concentration is at the natural level, or is artificially accelerated in one direction or another.</p>
  </li>
  <li>
    <p><a href="https://blog.archive.org/2019/04/10/official-eu-agencies-falsely-report-more-than-550-archive-org-urls-as-terrorist-content/">EU falsely calls Internet Archive’s major collection pages, scholarly articles, and copies of US government publications “terrorism” and demands they be taken down from the internet</a> (<a href="https://mathstodon.xyz/@11011110/101908397856087187"/>, <a href="https://boingboing.net/2019/04/11/one-hour-service.html">see also</a>). The EU is about to vote to require terrorism takedowns to happen within an hour, and these requests are coming on European times when all Internet Archive employees (in California) are asleep, making manual review of these bad takedowns difficult.</p>
  </li>
  <li>
    <p><a href="https://www.siam.org/Conferences/CM/Main/apocs20">SIAM-ACM Conference on Algorithmic Principles of Computer Systems, APOCS</a> (<a href="https://mathstodon.xyz/@11011110/101909431804808574"/>). This is a new conference to be held with SODA, next January in Salt Lake City, covering “all areas of algorithms and architectures that offer insight into the performance and design of computer systems”. Submission titles and abstracts are due August 9 (with full papers due a week later) so if this is an area you’re interested in there’s still plenty of time to come up with something to submit.</p>
  </li>
  <li>
    <p><a href="https://blog.computationalcomplexity.org/2019/04/elwyn-berlekamp-died-april-9-2019.html">Sad news from Berkeley</a>: <a href="https://en.wikipedia.org/wiki/Elwyn_Berlekamp">Elwyn Berlekamp</a> has died (<a href="https://mathstodon.xyz/@11011110/101921251002340100"/>, <a href="https://aperiodical.com/2019/04/elwyn-berlekamp-has-left-us/">see also</a>). Berlekamp made significant contributions to combinatorial game theory (motivated, as I understand it, by the mathematical study of Go endgames), coding theory, and algorithms for polynomials.</p>
  </li>
  <li>
    <p><a href="https://www.berlintransitmap.de/">An unofficially-proposed new Berlin transit map replaces stylized axis-parallel and diagonal line segments with smooth curves</a> (<a href="https://mathstodon.xyz/@11011110"/>, <a href="https://www.metafilter.com/180431/Berlin-Transit-Map-now-with-pleasing-Curves">via</a>). The old design was seen as “out of style”, “too robotized”, and too difficult to follow routes. There’s still a strong preference for axis-parallel and diagonal lines in the new map, but the connections between them have been smoothed out.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-04-15T17:43:00Z</updated>
    <published>2019-04-15T17:43:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-04-16T01:45:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kintali.wordpress.com/?p=1225</id>
    <link href="https://kintali.wordpress.com/2019/04/15/a-personal-story-of-a-founder/" rel="alternate" type="text/html"/>
    <title>A Personal Story of a Founder</title>
    <summary>Disclaimer: This blog post is not intended to offend University of Pennsylvania or IIT Kharagpur or Yahoo or any individuals or parties involved. The goal of this blog post is to point out some of the inefficiencies and acknowledge them as one of the motivations behind developing TrueCerts platform. The year was 2005. I was applying for a PhD program in Computer Science in […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="graf graf--p graf-after--p" id="7e4b"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Disclaimer:</em></strong><em class="markup--em markup--p-em"> This blog post is not intended to offend </em><a class="markup--anchor markup--p-anchor" href="https://en.wikipedia.org/wiki/University_of_Pennsylvania" rel="nofollow noopener" target="_blank"><em class="markup--em markup--p-em">University of Pennsylvania</em></a><em class="markup--em markup--p-em"> or </em><a class="markup--anchor markup--p-anchor" href="https://en.wikipedia.org/wiki/Indian_Institute_of_Technology_Kharagpur" rel="nofollow noopener" target="_blank"><em class="markup--em markup--p-em">IIT Kharagpur</em></a><em class="markup--em markup--p-em"> or </em><a class="markup--anchor markup--p-anchor" href="https://en.wikipedia.org/wiki/Yahoo!" rel="nofollow noopener" target="_blank"><em class="markup--em markup--p-em">Yahoo</em></a><em class="markup--em markup--p-em"> or any individuals or parties involved. The goal of this blog post is to point out some of the inefficiencies and acknowledge them as one of the motivations behind developing </em><a class="markup--anchor markup--p-anchor" href="https://truecerts.co/" rel="nofollow noopener" target="_blank"><em class="markup--em markup--p-em">TrueCerts</em></a><em class="markup--em markup--p-em"> platform.</em></p>
<p class="graf graf--p graf-after--p" id="822b">The year was 2005. I was applying for a PhD program in Computer Science in the top US universities. I have applied to 14 US universities. On Dec 2nd 2015, I received the following email (see the screenshot below) from the University of Pennsylvania (UPenn), Penn Engineering, Office of Academic Programs, Graduate Admissions. I have redacted the name, email address and the phone numbers in the emails, to preserve their privacy.</p>
<p><img alt="upenn1" class="alignnone size-full wp-image-1226" src="https://kintali.files.wordpress.com/2019/04/upenn1.png?w=660"/></p>
<p>Here are the photos of the original transcript (I received from IIT Kharagpur when I graduated) and the additional transcripts (I received from IIT Kharagpur when I requested them for my PhD application). They are all <strong class="markup--strong markup--p-strong">laminated by IIT Kharagpur</strong> and sent to me. Feel free to laugh at my appearance on the transcript. I do too <img alt="&#x1F609;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f609.png" style="height: 1em;"/></p>
<p><img alt="kgp" class="alignnone size-full wp-image-1227" src="https://kintali.files.wordpress.com/2019/04/kgp.jpeg?w=660"/></p>
<p class="graf graf--p graf-after--figure" id="e20e">IIT Kharagpur stated the following in their transcripts policy.</p>
<p class="graf graf--p graf--startsWithDoubleQuote graf-after--p" id="60be"><em class="markup--em markup--p-em">“Institute does not take responsibility of sending the duplicate copy of grade cards (transcripts) directly to other institutions/organizations, in connection with the applicants’ admission/employment etc.”</em></p>
<p class="graf graf--p graf-after--p" id="a381">My reply to the above email and the response from UPenn are shown in the following screenshot.</p>
<p><img alt="upenn2" class="alignnone size-full wp-image-1228" src="https://kintali.files.wordpress.com/2019/04/upenn2.png?w=660"/></p>
<p class="graf graf--p graf-after--figure" id="1fc0">In Summary, UPenn was concerned that my transcript is laminated and opened. Surprised at their response (“Your application will not go any further with the opened transcript”), I have spent couple of hours searching online and discovered that there is a lot of scam involving fake degrees and fake transcripts. There are “professionals” in India and China creating the “highest quality fakes”. These fakes are often laminated. So, UPenn decided not to process any applications with opened and laminated credentials. All my credentials are valid and correct, but my application was not processed because IIT Kharagpur has no way to “securely send” valid transcripts and UPenn has no way to “efficiently validate applicants’ transcripts”.</p>
<p class="graf graf--p graf-after--p" id="0588">I have applied to 14 universities and some of them rejected me because ‘they found a better candidate’ or ‘the research group is not looking for new PhD students’ etc etc. But my UPenn application not going further because of an “inefficient and broken system” is frustrating, to say the least.</p>
<p class="graf graf--p graf-after--p" id="291f">After a week, I have recovered from this frustration and went back to my daily routine of reading research papers on Theoretical Computer Science. I said to myself “I will get into one of the remaining 13 universities and I have to focus on research and resolve the <a class="markup--anchor markup--p-anchor" href="https://en.wikipedia.org/wiki/P_versus_NP_problem" rel="nofollow noopener" target="_blank">P vs NP problem</a>” <img alt="&#x1F609;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f609.png" style="height: 1em;"/></p>
<p class="graf graf--p graf-after--p" id="bc4f"><strong class="markup--strong markup--p-strong">On a lighter note:</strong> There is a simple way to verify that my transcript is valid — ‘Simply open it and look at my grades’. I have received several B’s, some C’s and even couple of D’s. My CGPA is just average. Nobody in their right senses would create a fake transcript with those grades <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/> During the last decade, whenever I met any IITian I first set them up telling <a class="markup--anchor markup--p-anchor" href="http://shivakintali.org/" rel="nofollow noopener" target="_blank">my credentials</a> (B-Tech from IIT Kharagpur, Masters from USC, PhD from GeorgiaTech, Taught at Princeton) and after they say “wow”, I bet with them that their CGPA at IIT is greater than mine. I never lost till date. I take pride in this fact <img alt="&#x1F609;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f609.png" style="height: 1em;"/> In my defense, I was an all-rounder at IIT Kharagpur, balancing studies, serving as a ‘secretary of fine arts, modeling and dramatics’ of my hostel, painting, learning guitar and many more things.</p>
<p class="graf graf--p graf-after--p" id="d9e1"><strong class="markup--strong markup--p-strong">A second incident:</strong> During summer 2010 (at the end of my fourth year as a PhD student at GeorgiaTech), I was offered an internship at Yahoo labs and the Yahoo HR team said they want to verify all my credentials (my IIT B-Tech degree, USC Master’s degree, work experience). Yahoo uses a third-party service to rigorously verify all credentials of potential employees / interns. <a class="markup--anchor markup--p-anchor" href="https://www.thedailybeast.com/farewell-yahoo-ceo-scott-thompson-ousted-for-a-resume-lie" rel="nofollow noopener" target="_blank">Yahoo fired their own CEO</a> when they found that he lied in his resume. This process is very rigorous, but very time-consuming. The <strong class="markup--strong markup--p-strong">verification of all my credentials took more than couple of months</strong>. Meanwhile, I was waiting with my fingers-crossed (figuratively speaking) and hoping these verifications happen soon, so that I can start my internship and earn some serious summer money for two months and see a bank balance of more than $1,000 dollars for the first time during my grad school <img alt="&#x1F609;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f609.png" style="height: 1em;"/></p>
<p class="graf graf--p graf-after--p" id="f5fc">Later that year, when I discovered Bitcoin white paper and the underlying Blockchain, my first thought was to use the technology to build a ‘document integrity platform’ to issue tamper-proof credentials (degrees, transcripts, employment certificates, Visas, Identity documents, driver’s license etc), which can be verified instantaneously and securely on the blockchain.</p>
<p class="graf graf--p graf-after--p" id="96cb">Early 2011, I got busy with writing thesis and joined the CS department Princeton University in September 2011. I have spent the first couple of years teaching at Princeton, mining Bitcoin, keeping track of Blockchain news and hoping that somebody will develop a ‘document integrity platform’. To my relief, some entrepreneurs tried to develop a ‘credential verification solutions’. To my frustration, none of those solutions are perfect. So I started preparing myself to become a full-time entrepreneur and left Princeton in summer 2015.</p>
<p class="graf graf--p graf-after--p" id="5810">Today, I am very glad we have a complete data integrity solution (for universities, employers and enterprises) and I am very excited that we are preventing fraud and corruption in several areas using our <a class="markup--anchor markup--p-anchor" href="https://truecerts.co/" rel="nofollow noopener" target="_blank">TrueCerts</a> platform.</p>
<p class="graf graf--p graf-after--p" id="e378">Every week I read several stories about fraud and corruption online (Eg: the recent <a class="markup--anchor markup--p-anchor" href="https://en.wikipedia.org/wiki/2019_college_admissions_bribery_scandal" rel="nofollow noopener" target="_blank">college admissions scandal</a>). I approach the involved parties and explain how such instances can be rigorously prevented using technology.</p>
<p class="graf graf--p graf-after--p graf--trailing" id="d84e">I feel very fortunate to have discovered an exciting vision towards a fraud-free and efficient future. This discovery happened through the above mentioned unfortunate events. Sometimes the lowest points in your life have the greatest potential to show you the right path to your highest points.</p></div>
    </content>
    <updated>2019-04-15T04:35:57Z</updated>
    <published>2019-04-15T04:35:57Z</published>
    <category term="blockchain"/>
    <category term="Education"/>
    <category term="IIT Kharagpur"/>
    <category term="upenn"/>
    <category term="Yahoo"/>
    <author>
      <name>kintali</name>
    </author>
    <source>
      <id>https://kintali.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/e1376dd220aa259d0efd0638d7619231?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://kintali.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kintali.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kintali.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kintali.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computational Complexity, Polyhedral Combinatorics, Algorithms and Graph Theory</subtitle>
      <title>My Brain is Open</title>
      <updated>2019-04-19T20:20:43Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3262168094346690140</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3262168094346690140/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/good-article-terrible-headline.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3262168094346690140" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3262168094346690140" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/good-article-terrible-headline.html" rel="alternate" type="text/html"/>
    <title>Good article, terrible headline</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">About a month ago (after my P NP poll appeared) I got email from Jacob Aron asking me some questions about it. One thing he was excited about was that the number of people who thought P vs NP would be solved in the next decade had increased from 11% to 22%. I told him that this also surprised me and <i>there had been no major advances to warrant that increase.</i><br/>
<i><br/></i>
Then the article came out. Here is the pointer to the headline and the first few lines, the rest is behind a paywall<br/>
<br/>
<a href="https://www.newscientist.com/article/2198151-we-could-solve-the-biggest-problem-in-maths-in-the-next-decade/">here</a><br/>
<br/>
You may notice that the headline is<br/>
<br/>
<i>We could solve the biggest problem in math in the next decade</i><br/>
<i><br/></i>
I emailed Jacob to send me the article, which he did. The article was fine, even quoting me as saying that the increase of people who thought it would be solved soon was unwarranted.<br/>
<br/>
1) So, article fine, headline terrible.<br/>
<br/>
2)  A more honest headline would be<br/>
<br/>
<i>The Complexity Theory Community slightly more optimistic about when P vs NP will be resolved for no apparent reason.</i><br/>
<i><br/></i>
3) More bad science:<a href="https://www.newscientist.com/article/mg22329780-400-turings-oracle-the-computer-that-goes-beyond-logic/">here</a><br/>
<br/>
Headline is<br/>
<br/>
<i>Turing's Oracle: The computer that goes beyond logic</i><br/>
<br/>
I think the article was about how a Turing Machine with an oracle for HALT can solve HALT. (If I am wrong about this let me know in the comments and I'll correct it.)<br/>
<br/>
4) More bad science:<a href="https://www.quantamagazine.org/finally-a-problem-that-only-quantum-computers-will-ever-be-able-to-solve-20180621/">here</a><br/>
<br/>
Headline<br/>
<br/>
<i>Finally, a problem that only Quantum Computers will ever be able to solve.</i><br/>
<i><br/></i>
This was about the oracle such that BQP is not in PH. Really!<br/>
<br/>
5) I invite you to add your own.<br/>
<br/>
6) OKAY, so why is the press SO BAD at reporting on our field? And is it just our field? I have one explanation, though I am sure there are many.<br/>
<br/>
Our field is about showing the LIMITS of computation. Its hard to make that sexy so they ... lie? exaggerate. They themselves don't really understand our field? Note:<br/>
<br/>
To explain to someone who does not really know CS why its important to have an oracle where BQP is not in PH is hard<br/>
<br/>
To explain this to someone IN CS but not in Theory is still hard!<br/>
<br/>
To explain this to someone IN CS and even in CS Theory, but not complexity (e.g., algorithms) might be hard, though it may depend on the person.<br/>
<br/>
7) The old saying is `I don't care if you get the story wrong so long as you spell my name right' And indeed, they did spell my name right. So there is that! But more seriously and less about me or even the article that refers to my poll--- is it bad that science reporting is often wrong?<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-04-15T04:08:00Z</updated>
    <published>2019-04-15T04:08:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-04-19T18:07:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://minimizingregret.wordpress.com/?p=116</id>
    <link href="https://minimizingregret.wordpress.com/2019/04/15/reinforcement-learning-without-rewards/" rel="alternate" type="text/html"/>
    <link href="https://videos.files.wordpress.com/ro0BDWO4/cheetah-pretty_hd.mp4" length="19415040" rel="enclosure" type="video/mp4"/>
    <title>Reinforcement learning without rewards</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">by Abby van Soest and Elad Hazan, based on this paper  When humans interact with the environment, we receive a series of signals that indicate the value of our actions. We know that chocolate tastes good, sunburns feel bad, and certain actions generate praise or disapproval from others. Generally speaking, we learn from these signals … <a class="more-link" href="https://minimizingregret.wordpress.com/2019/04/15/reinforcement-learning-without-rewards/">Continue reading <span class="screen-reader-text">Reinforcement learning without rewards</span> <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>by <a href="http://www.abbyvansoest.com/">Abby van Soest</a> and Elad Hazan, based on <a href="https://arxiv.org/abs/1812.02690">this paper</a> </em></p>
<p>When humans interact with the environment, we receive a series of signals that indicate the value of our actions. We know that chocolate tastes good, sunburns feel bad, and certain actions generate praise or disapproval from others. Generally speaking, we learn from these signals and adapt our behavior in order to get more positive “rewards” and fewer negative ones.</p>
<p><i>Reinforcement learning</i> (RL) is a sub-field of machine learning that formally models this setting of learning through interaction in a reactive environment. In RL, we have an <b>agent</b> and an <b>environment</b>. The agent observes its position (or “state”) in the environment and takes actions that transition it to a new state. The environment looks at an agent’s state and hands out rewards based on a hidden set of criteria.</p>
<p style="text-align: center;"><img alt="" height="145" src="https://minimizingregret.files.wordpress.com/2019/04/null.png?w=360&amp;h=145" title="" width="360"/></p>
<p><i>Source: <a href="http://incompleteideas.net/book/bookdraft2017nov5.pdf">Reinforcement Learning: An Introduction</a>. Sutton &amp; Barto, 2017.</i></p>
<p>Typically, the goal of RL is for the agent to learn behavior that maximizes<i> </i>the total reward it receives from the environment. This methodology has led to some notable successes: machines have learned how to<a href="https://deepmind.com/research/publications/playing-atari-deep-reinforcement-learning/"> play Atari games</a>, how to <a href="https://sigmoidal.io/alphago-how-it-uses-reinforcement-learning-to-beat-go-masters/">beat human masters</a> of Go, and how to write <a href="https://www.theverge.com/2019/2/14/18224704/ai-machine-learning-language-models-read-write-openai-gpt2">long-form responses</a> to an essay prompt.</p>
<h2>But what can we learn without an external reward signal?</h2>
<p>It seems like a paradoxical question to ask, given that RL is all about rewards. But even though the reward paradigm is fundamentally flexible in many ways, it is also brittle and limits the agent’s ability to learn about its environment. This is due to several reasons. First, a reward signal directs the agents towards a single specific goal that may not generalize. Second, the reward signal may be sparse and uninformative, as we illustrate below.</p>
<p>Imagine that you want a robot to learn to navigate through the following maze.</p>
<p><b>Case 1: Sparse Rewards.</b> The agent gets a reward of +1 when it exits the maze, and a reward of 0 everywhere else. The agent doesn’t learn anything until it stumbles upon the exit.</p>
<p style="text-align: center;">⇒ Clear reward signals are not always available.</p>
<p><b>Case 2: Misleading Rewards.</b> The agent gets a reward of +1 at the entrance and a reward of +10 at the exit. The agent incorrectly learns to sit at the entrance because it hasn’t explored its environment sufficiently.</p>
<p style="text-align: center;">⇒ Rewards can <i>prevent</i> discovery of the full environment.</p>
<p>These issues are easy to overcome in the small maze on the left. But what about the maze on the right? As the size of the environment grows, it’ll get harder and harder to find the correct solution — the intractability of the problem scales exponentially.</p>
<p style="text-align: center;"><img alt="" height="238" src="https://minimizingregret.files.wordpress.com/2019/04/image.png?w=244&amp;h=238" title="" width="244"/><img alt="pasted image 0.png" class="alignnone size-full wp-image-130" src="https://minimizingregret.files.wordpress.com/2019/04/pasted-image-0.png?w=1100"/></p>
<p>So what we find is that there is power<i> </i>in being able to learn effectively in the <b>absence</b> of rewards. This intuition is supported by a body of research that shows learning fails when rewards aren’t dense or are <a href="https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/NgHaradaRussell-shaping-ICML1999.pdf">poorly shaped</a>; and fixing these problems can require substantial engineering effort.</p>
<p>By enabling agents to discover the environment without the requirement of a reward signal, we create a more<b> flexible and generalizable</b> form of reinforcement learning. This framework can be considered a form of “unsupervised” RL. Rather than relying on explicit and inherently limited signals (or “labels”), we can deal with a broad, unlabelled pool of data. Learning from this pool facilitates a more general extraction of knowledge from the environment.</p>
<h2>Our new approach: Maximum Entropy</h2>
<p>In <a href="https://arxiv.org/abs/1812.02690">recent work</a>, we propose finding a policy that maximizes entropy (which we refer to as a MaxEnt policy), or another related and concave function of the distribution. This objective is reward-independent and favors exploration.</p>
<p>In the video below, a two-dimensional cheetah robot learns to run backwards and forwards, move its legs fast and in all different directions, and even do flips. The cheetah doesn’t have access to any external rewards; it only uses signals from the MaxEnt policy.</p>
<p> </p>
<div class="video-player" id="v-ro0BDWO4-1" style="width: 1100px; height: 620px;">
</div>
<p>Entropy is a function of the distribution over states. A high entropy distribution visits all states with near-equal frequency — it’s a <i>uniform</i> distribution. On the other hand, a low entropy distribution is biased toward visiting some states more frequently than others. (In the maze example, a low entropy distribution would result from the agent sitting at the entrance of the maze forever.)</p>
<p><img alt="slAdX3I4FcseBWeJbioHb_g.png" class=" size-full wp-image-129 aligncenter" src="https://minimizingregret.files.wordpress.com/2019/04/sladx3i4fcsebwejbiohb_g.png?w=1100"/></p>
<p>So given that policy <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\pi"/> creates a distribution <img alt="d_\pi" class="latex" src="https://s0.wp.com/latex.php?latex=d_%5Cpi&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="d_\pi"/> over states, the problem we are hoping to solve is:</p>
<p style="text-align: center;"><img alt="\pi^* = \arg \max_{\pi} \text{entropy}(d_\pi) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi%5E%2A+%3D+%5Carg+%5Cmax_%7B%5Cpi%7D+%5Ctext%7Bentropy%7D%28d_%5Cpi%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\pi^* = \arg \max_{\pi} \text{entropy}(d_\pi) "/></p>
<p>When we know all the states, actions, and dynamics of a given environment, finding the policy with maximum entropy is a concave optimization problem. This type of problem can be easily and exactly solved by convex programming.</p>
<p>But we very rarely have all that knowledge available to use. In practice, one of several complications usually arise:</p>
<ol>
<li>The states are <b>non-linearly approximated </b>by a neural network or some other function approximator.</li>
<li>The transition dynamics are unknown.</li>
<li>The state space is intractably large. (As an interesting example, the game of Go has more than<b> one googol or <img alt="10^{100}" class="latex" src="https://s0.wp.com/latex.php?latex=10%5E%7B100%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="10^{100}"/></b> possible states. That’s more than the number of atoms in the universe, according to <a href="https://ai.googleblog.com/2016/01/alphago-mastering-ancient-game-of-go.html">this blog</a> from 2016, and definitely more than can fit on a computer.)</li>
</ol>
<p>In such cases, the problem of finding a max-entropy policy becomes non-convex and computationally hard.</p>
<p>So what to do? If we look at many practical RL problems (Atari, OpenAI Gym), we see that there are many known, efficient solvers that can construct an optimal (or nearly-optimal) policy when they are <i>given a reward signal</i>.</p>
<p>We thus consider an <i>oracle model</i>: let’s assume that we have access to one of these solvers, so that we can pass it an explicit reward vector and receive an optimal policy in return. Can we now maximize entropy in a provably efficient way? In other words, is it possible to reduce this high complexity optimization problem to that of “standard” RL?</p>
<p>Our approach does exactly that! It is based on the Frank-Wolfe method. This is a gradient-based optimization algorithm that is particularly suited for oracle-based optimization. Instead of moving in the direction of the steepest decline of the objective function, the Frank-Wolfe method iteratively moves in the direction of the optimal point in the direction of the gradient. This is depicted below (and deserves a separate post…). The Frank-Wolfe method is a projection-free algorithm, see <a href="https://drive.google.com/file/d/1GIDnw7T-NT4Do3eC0B5kYJlzwOs6nzIO/view">this exposition</a> about its theoretical properties.</p>
<p><img alt="" height="345" src="https://minimizingregret.files.wordpress.com/2019/04/unnamed-file.png?w=616&amp;h=345" title="" width="616"/></p>
<p>For the exact specification of the algorithm and its performance guarantee, see<a href="https://arxiv.org/abs/1812.02690"> our paper</a>.</p>
<h2>Experiments</h2>
<p>To complement the theory, we also created some experiments to test the MaxEnt algorithm on simulated robotic locomotion tasks (<a href="https://github.com/abbyvansoest/maxent/tree/refactor">open source code available here</a>). We used test environments from <a href="https://gym.openai.com/">OpenAI Gym</a> and <a href="https://github.com/openai/mujoco-py">Mujoco</a> and trained MaxEnt experts for various environments.</p>
<p>These are some results from the Humanoid experiment, where the agent is a human-like bipedal robot. The behavior of the MaxEnt agent (blue) is baselined against a random agent (orange), who explores by sampling randomly from the environment. This random approach is often used in practice for epsilon-greedy RL exploration.</p>
<p style="text-align: center;"><img alt="" height="332" src="https://minimizingregret.files.wordpress.com/2019/04/null-1.png?w=442&amp;h=332" title="" width="442"/></p>
<p>In this figure, we see that over the course of 25 epochs, the MaxEnt agent progressively increases the total entropy over the state space.</p>
<p style="text-align: center;"><img alt="" height="345" src="https://minimizingregret.files.wordpress.com/2019/04/null-2.png?w=460&amp;h=345" title="" width="460"/></p>
<p>Here, we see a visualization of the Humanoid’s coverage of the $xy$-plane, where the shown plane is of size 40-by-40. After one epoch, there is <b>minimal</b> coverage of the area. But by the 5th, 10th, and 15th epoch, we see that the agent has learned to visit all the different states in the plane, obtaining full and nearly uniform coverage of the grid!</p>
<div><a href="https://minimizingregret.wordpress.com/2019/04/15/reinforcement-learning-without-rewards/"><img alt="cheetah-pretty" height="120" src="https://videos.files.wordpress.com/ro0BDWO4/cheetah-pretty_std.original.jpg" width="160"/></a></div></div>
    </content>
    <updated>2019-04-15T01:03:27Z</updated>
    <published>2019-04-15T01:03:27Z</published>
    <category term="Uncategorized"/>
    <category term="machine learning"/>
    <category term="reinforcement learning"/>
    <author>
      <name>Elad Hazan</name>
    </author>
    <source>
      <id>https://minimizingregret.wordpress.com</id>
      <logo>https://minimizingregret.files.wordpress.com/2017/08/cropped-pu1.png?w=32</logo>
      <link href="https://minimizingregret.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://minimizingregret.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://minimizingregret.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://minimizingregret.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Google Princeton AI and Hazan Lab @ Princeton University</subtitle>
      <title>Minimizing Regret</title>
      <updated>2019-04-19T20:21:15Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/04/14/monochromatic-grids-colored</id>
    <link href="https://11011110.github.io/blog/2019/04/14/monochromatic-grids-colored.html" rel="alternate" type="text/html"/>
    <title>Monochromatic grids in colored grids</title>
    <summary>Color the points of an grid with two colors. How big a monochromatic grid-like subset can you find? By “grid-like” I mean that it should be possible to place equally many horizontal and vertical lines, partitioning the plane into cells each of which contains a single point.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Color the points of an  grid with two colors. How big a monochromatic grid-like subset can you find? By “grid-like” I mean that it should be possible to place equally many horizontal and vertical lines, partitioning the plane into  cells each of which contains a single point.</p>

<p>So for the coloring of the  grid below, there are several  monochromatic grid-like subsets. The image below shows one, and the completely red and blue southwest and northeast quadrants provide two others.
The blue quadrant prevents any red grid-like subset from being larger than , and vice versa, so these are the largest grid-like subsets in this grid.</p>

<p style="text-align: center;"><img alt="Monochromatic grid-like subset in a colored grid" src="https://11011110.github.io/blog/assets/2019/subgrid.svg"/></p>

<p>It’s not hard to prove that there always exists a monochromatic grid-like subset of size at least .
Just use vertical and horizontal lines to partition the big grid into blocks of that size. If one of those blocks is monochromatic, then it’s the grid-like subset you’re looking for. And if not, you can choose a red point from each block to get a grid-like subset of the same size.</p>

<p>In the other direction, there exist colorings of an  grid for which the largest monochromatic grid-like subset has size only a little bigger, . To find such a coloring, partition the big grid into square blocks of size , and make each block monochromatic with a randomly chosen color.</p>

<p style="text-align: center;"><img alt="Coloring a grid by dividing into square blocks and coloring each block randomly" src="https://11011110.github.io/blog/assets/2019/blocked-coloring.svg"/></p>

<p>Now, consider any partition by axis-parallel lines into (irregular) rectangles, each containing one of the points of a grid-like subset.  Only one row or column of the rectangles can cross each line of the partition into square blocks, so the number of rectangles that include parts of two or more square blocks is . Any remaining rectangles of the partition must come from a grid-like subset of square blocks that are all colored the same as each other. But with a random coloring, the expected size of this largest monochromatic subset of square blocks is . Therefore, the number of rectangles that stay within a single square block is limited to the total number of points in this grid-like subset of square blocks, which is again .</p>

<p>I’m not sure how to eliminate the remaining  gap between these two bounds, or which way it should go.</p>

<p>One application of these ideas involves the theory of <a href="https://en.wikipedia.org/wiki/Superpattern">superpatterns</a>, permutations that contain as a <a href="https://en.wikipedia.org/wiki/Permutation_pattern">pattern</a> every smaller permutation up to some size .
If  is a superpattern for the permutations of size , then we can obtain a point set by interpreting the position and value of each element of  as Cartesian coordinates. This point set includes a grid-like subset of size , coming from a permutation of size  that translates to a grid-like set of points.
If the elements of the superpattern are colored with two colors, there still exists a monochromatic grid-like subset of size .
And this monochromatic grid-like subset corresponds to a superpattern, for permutations of size . So, whenever the elements of a superpattern are colored with two (or finitely many) colors, there remains a monochromatic subset of elements that is still a superpattern for permutations of some smaller but non-constant size.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/101927319466372642">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-04-14T17:02:00Z</updated>
    <published>2019-04-14T17:02:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-04-16T01:45:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/057</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/057" rel="alternate" type="text/html"/>
    <title>TR19-057 |  Proof Complexity of Symmetry Learning in QBF | 

	Joshua Blinkhorn, 

	Olaf Beyersdorff</title>
    <summary>For quantified Boolean formulas (QBF), a resolution system with a symmetry rule was recently introduced by Kauers and Seidl (Inf. Process. Lett. 2018). In this system, many formulas hard for QBF resolution admit short proofs.

Kauers and Seidl apply the symmetry rule on symmetries of the original formula. Here we propose a new formalism where symmetries are dynamically recomputed during the proof on restrictions of the original QBF. This presents a theoretical model for the potential use of symmetry learning as an inprocessing rule in QCDCL solving.

We demonstrate the power of symmetry learning by proving an exponential separation between Q-resolution with the symmetry rule and Q-resolution with our new symmetry learning rule. In fact, we show that bounding the number of symmetry recomputations gives rise to a hierarchy of QBF resolution systems of strictly increasing strength.</summary>
    <updated>2019-04-14T10:26:19Z</updated>
    <published>2019-04-14T10:26:19Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-04-19T20:20:34Z</updated>
    </source>
  </entry>
</feed>
