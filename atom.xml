<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-12-03T13:21:58Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1485483742428466612</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1485483742428466612/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/12/julia-robinsons-100th-birthday.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1485483742428466612" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1485483742428466612" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/12/julia-robinsons-100th-birthday.html" rel="alternate" type="text/html"/>
    <title>Julia Robinson's 100th birthday</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">On Dec 8, 1919 Julia Robinson was born, so today is close to her 100th birthday (she passed away at<br/>
<div>
the age of 65 on July 30, 1985).</div>
<div>
<br/></div>
<div>
So time for some facts about her</div>
<div>
<br/></div>
<div>
1) She got her PhD from Tarski where she proved the undecidability of the theory of the rationals.</div>
<div>
<br/></div>
<div>
2) She is probably best known for her work on Hilbert's tenth problem (which we call H10)</div>
<div>
<br/></div>
<div>
In todays' terminology H10 would be stated as:</div>
<div>
<br/>
Find an algorithm that will, given p in Z[x_1,...,x_n] determine if it has an integer solution.</div>
<div>
<br/></div>
<div>
Hilbert posed it to inspire deep research in Number Theory. There are some cases that are</div>
<div>
solvable (the topic of a later blog post) but the general problem is undecidable. This is not what Hilbert was aiming for. I wonder if he would be happy with the resolution.</div>
<div>
<br/></div>
<div>
The Davis-Putnam-Robinson paper showed that the decision problem for exponential diophantine equations was undecidable. It was published in 1961. The paper is <a href="https://www.jstor.org/stable/1970289?seq=1#metadata_info_tab_contents">here</a>.  Martin Davis predicted that the proof that H10 was undecidable would be by a young Russian mathematician. He was proven correct when Yuri Maityasevich supplied the missing piece needed to complete the proof.  </div>
<div>
<br/></div>
<div>
I often read `H10 was resolved by Davis-Putnam-Robinson and Maityasevich' or sometimes they put all four names in alphabetical order. I like that--- it really was a joint effort.</div>
<div>
<br/></div>
<div>
3) She was inducted (a proof by induction?) into the National Academy of Sciences in 1975.</div>
<div>
<br/></div>
<div>
4) She was elected to be president of the American Math Society in 1982.  </div>
<div>
<br/></div>
<div>
5) She got a MacAuthor Fellowship prize in 1985 (Often called the MacAuthor Genius award.)</div>
<div>
At the time it was worth $60,000.  Its now $625,000.</div>
<div>
<br/></div>
<div>
6) She also did work in Game Theory.</div>
<div>
<br/></div>
<div>
7) The Julia Robinson Math Festival is named in her honor (hmmm- is that a tautology?) Its purpose is to inspire K-12 students to get involved in math. For more on it see <a href="https://en.wikipedia.org/wiki/Julia_Robinson_Mathematics_Festival">here</a>. </div>
<div>
<br/></div>
<div>
<br/></div>
<div>
<br/></div></div>
    </content>
    <updated>2019-12-02T23:01:00Z</updated>
    <published>2019-12-02T23:01:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-12-03T11:42:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/12/02/postdoc-at-boston-college-apply-by-january-15-2020-2/</id>
    <link href="https://cstheory-jobs.org/2019/12/02/postdoc-at-boston-college-apply-by-january-15-2020-2/" rel="alternate" type="text/html"/>
    <title>Postdoc at Boston College (apply by January 15, 2020)</title>
    <summary>Applications are invited for a postdoc position hosted by Hsin-Hao Su at Boston College. Areas of specific interests include but not limited to distributed graph algorithms, local algorithms, dynamic graph algorithms, gossip algorithms, and MPC algorithms. The position can start at any time in 2020 after February. The length of the position is for a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a postdoc position hosted by Hsin-Hao Su at Boston College. Areas of specific interests include but not limited to distributed graph algorithms, local algorithms, dynamic graph algorithms, gossip algorithms, and MPC algorithms. The position can start at any time in 2020 after February. The length of the position is for a period of up to two years.</p>
<p>Website: <a href="https://sites.google.com/site/distributedhsinhao/postdoc">https://sites.google.com/site/distributedhsinhao/postdoc</a><br/>
Email: suhx@bc.edu</p></div>
    </content>
    <updated>2019-12-02T22:37:53Z</updated>
    <published>2019-12-02T22:37:53Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-12-03T13:20:39Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-857009480691482743</id>
    <link href="http://processalgebra.blogspot.com/feeds/857009480691482743/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=857009480691482743" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/857009480691482743" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/857009480691482743" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/12/faculty-positions-at-department-of.html" rel="alternate" type="text/html"/>
    <title>Faculty positions at the Department of Computer Science, Reykjavik University</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div><i>This job ad could be of interest to you or to someone you know. Feel free to spread it as you see fit. Thanks! </i></div><div> </div><div>The Department of Computer Science at Reykjavik University invites applications for several full-time faculty positions.</div><br/>We  are looking for energetic, highly qualified academics who are eager to  develop their own research programs, strengthen existing research within  the department and build bridges with industry. Of particular interest  are candidates in the areas of machine learning, data science, computer  security and software systems, broadly construed, but exceptionally  qualified candidates from all areas of computer science are encouraged  to apply.<br/><br/>Candidates should have a proven international research  record that is commensurate with the level of the position for which  they apply. The successful applicants will play a full part in the  teaching and administrative activities of the department; in particular,  they will teach courses and supervise students at both graduate and  undergraduate level. Applicants having a demonstrated history of  excellence in teaching are preferred. A PhD in computer science or a  related field is required.<br/><br/>Salary and rank are commensurate with  experience. An appointment at assistant-professor level is permanent  track, with the expectation that a successful candidate will qualify for  promotion to associate professor within six years.<br/><br/>The positions  are open until filled, with the earliest available starting date in  August 2020. Later starting dates can be negotiated.<br/><br/>The review of the applications will begin on Monday, 17 February 2020, and will continue until the positions are filled.<br/><div><br/></div><div>See <a href="http://radningar.hr.is/storf/viewjobonweb.aspx?jobid=3558" target="_blank">http://radningar.hr.is/storf/viewjobonweb.aspx?jobid=3558</a> for further information on how to apply for the position and on the required documents. </div><br/><div><b>About the department, Reykjavik University and Iceland</b></div><div><br/></div>The  Department of Computer Science at Reykjavik University has about 650  full-time-equivalent students and 22 faculty members. It provides an  excellent working environment that encourages and supports independence  in academic endeavours, and in which a motivated academic can have  impact at all levels. The department offers undergraduate and graduate  programs in computer science and software engineering, as well as a  combined-degree undergraduate program in discrete mathematics and  computer science. The doctoral program within the department received  its ministerial accreditation in 2009 and has been active ever since.<br/><br/>The  department is home to several research centres producing high-quality  collaborative research in areas such as artificial intelligence,  financial technology, language technology, software systems, and  theoretical computer science, among others; for more information on  those research centres, see <a href="https://en.ru.is/research/units/" target="_blank">https://en.ru.is/research/units/</a>.<br/><br/>On  the Times Higher Education rankings for 2020, Reykjavík University is  ranked in first place along with six other universities for the average  number of citations per faculty. Overall, according to that list, RU is  ranked among the 300 best universities world-wide, 52nd out of all  universities established fewer than 50 years ago, 14th among  universities with fewer than 5000 students, and first among Icelandic  universities.<br/><br/>Iceland is well known for its breathtaking natural  beauty, with volcanoes, geysers, hot springs, lava fields and glaciers  offering a dramatic landscape. It is consistently ranked as one of the  best places in the world to live. It offers a high quality of life, is  one of the safest places in the world, has high gender equality, and  strong health-care and social-support systems. It is in fourth position  in the 2019 UN World Happiness Report, which ranks the world's countries  by their happiness level.<br/><br/>For further information about the Department of Computer Science at Reykjavik University and its activities, see <a href="http://en.ru.is/scs/" target="_blank">http://en.ru.is/scs/</a>.</div>
    </content>
    <updated>2019-12-02T22:35:00Z</updated>
    <published>2019-12-02T22:35:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-12-03T11:18:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/12/02/postdoc-at-epfl-apply-by-january-15-2020/</id>
    <link href="https://cstheory-jobs.org/2019/12/02/postdoc-at-epfl-apply-by-january-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at EPFL (apply by January 15, 2020)</title>
    <summary>Applications are invited for a postdoctoral position in theoretical computer science in the School of Computer and Communication Sciences at EPFL. The position is for a period of up to two years, and comes with a competitive salary as well as a generous travel allowance. Website: https://theory.epfl.ch/kapralov/postdoc.html Email: michael.kapralov@epfl.ch</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a postdoctoral position in theoretical computer science in the School of Computer and Communication Sciences at EPFL. The position is for a period of up to two years, and comes with a competitive salary as well as a generous travel allowance.</p>
<p>Website: <a href="https://theory.epfl.ch/kapralov/postdoc.html">https://theory.epfl.ch/kapralov/postdoc.html</a><br/>
Email: michael.kapralov@epfl.ch</p></div>
    </content>
    <updated>2019-12-02T20:34:01Z</updated>
    <published>2019-12-02T20:34:01Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-12-03T13:20:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/12/02/assistant-or-associate-professor-at-university-of-massachusetts-amherst-apply-by-december-31-2019/</id>
    <link href="https://cstheory-jobs.org/2019/12/02/assistant-or-associate-professor-at-university-of-massachusetts-amherst-apply-by-december-31-2019/" rel="alternate" type="text/html"/>
    <title>assistant or associate professor at University of Massachusetts, Amherst (apply by December 31, 2019)</title>
    <summary>The College of Information and Computer Sciences at the University of Massachusetts Amherst invites applications for tenure-track faculty in Theoretical Computer Science at the Associate and Assistant Professor levels. Exceptional candidates at other ranks may be considered. Website: http://careers.umass.edu/amherst/en-us/job/502778/assistantassociate-professortheory Email: facrec@cs.umass.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The College of Information and Computer Sciences at the University of Massachusetts<br/>
Amherst invites applications for tenure-track faculty in Theoretical Computer Science at the<br/>
Associate and Assistant Professor levels. Exceptional candidates at other ranks may be<br/>
considered.</p>
<p>Website: <a href="http://careers.umass.edu/amherst/en-us/job/502778/assistantassociate-professortheory">http://careers.umass.edu/amherst/en-us/job/502778/assistantassociate-professortheory</a><br/>
Email: facrec@cs.umass.edu</p></div>
    </content>
    <updated>2019-12-02T18:13:19Z</updated>
    <published>2019-12-02T18:13:19Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-12-03T13:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4439</id>
    <link href="https://www.scottaaronson.com/blog/?p=4439" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4439#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4439" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Two updates</title>
    <summary xml:lang="en-US">Two weeks ago, I blogged about the claim of Nathan Keller and Ohad Klein to have proven the Aaronson-Ambainis Conjecture. Alas, Keller and Klein tell me that they’ve now withdrawn their preprint (though it may take another day for that to show up on the arXiv), because of what looks for now like a fatal […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><ol><li>Two weeks ago, I <a href="https://www.scottaaronson.com/blog/?p=4414">blogged about</a> the <a href="https://arxiv.org/abs/1911.03748">claim</a> of Nathan Keller and Ohad Klein to have proven the Aaronson-Ambainis Conjecture.  Alas, Keller and Klein tell me that they’ve now withdrawn their preprint (though it may take another day for that to show up on the arXiv), because of what looks for now like a fatal flaw, in Lemma 5.3, discovered by Paata Ivanishvili.  (My own embarrassment over having missed this flaw is <em>slightly</em> mitigated by most of the experts in discrete Fourier analysis having missed it as well!)  Keller and Klein are now working to fix the flaw, and I wholeheartedly wish them success.</li><li>In unrelated news, I was saddened to read that <a href="https://en.wikipedia.org/wiki/Virgil_Griffith">Virgil Griffith</a>—cryptocurrency researcher, former Integrated Information Theory researcher, and <a href="https://www.scottaaronson.com/blog/?p=1893">onetime contributor to <em>Shtetl-Optimized</em></a>—was <a href="https://www.forbes.com/sites/jasonbrett/2019/11/29/us-authorities-arrest-virgil-griffith-for-teaching-cryptocurrency-and-blockchain/#1a19647142cb">arrested at LAX</a> for having traveled to North Korea to teach the DPRK about cryptocurrency, against the admonitions of the US State Department.  I didn’t know Virgil well, but I did meet him in person at least once, and I liked <a href="http://www.scottaaronson.com/response-p1.pdf">his</a> <a href="http://www.scottaaronson.com/response-p2.pdf">essays</a> for this blog about how, after spending years studying IIT under Giulio Tononi himself, he became disillusioned with many aspects of it and evolved to a position not far from mine (though not identical either).<br/>Personally, I despise the North Korean regime for the obvious reasons—I regard it as not merely evil, but <em>cartoonishly</em> so—and I’m mystified by Virgil’s <a href="https://twitter.com/nicksdjohnson/status/1201212127945605122">apparently sincere belief</a> that he could bring peace between the North and South by traveling to North Korea to give a lecture about blockchain.  Yet, however world-historically naïve he may have been, his intentions appear to have been good.  More pointedly—and here I’m asking not in a legal sense but in a human one—if giving aid and comfort to the DPRK is treasonous, then isn’t the current occupant of the Oval Office a million times guiltier of that particular treason (to say nothing of others)?  It’s like, what does “treason” even mean anymore?  In any case, I hope some plea deal or other arrangement can be worked out that won’t end Virgil’s productive career.</li></ol>



<p/></div>
    </content>
    <updated>2019-12-02T15:31:12Z</updated>
    <published>2019-12-02T15:31:12Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-12-02T20:32:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=18705</id>
    <link href="https://gilkalai.wordpress.com/2019/12/02/tyi-41-how-many-steps-does-it-take-for-a-simple-random-walk-on-the-discrete-cube-to-reach-the-uniform-distribution/" rel="alternate" type="text/html"/>
    <title>TYI 41: How many steps does it take for a simple random walk on the discrete cube to reach the uniform distribution?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Aeiel Yadin’s homepage contains great lecture notes on harmonic functions on groups and on various other topics. I have a lot of things to discuss and to report; exciting developments in the analysis of Boolean functions; much to report on … <a href="https://gilkalai.wordpress.com/2019/12/02/tyi-41-how-many-steps-does-it-take-for-a-simple-random-walk-on-the-discrete-cube-to-reach-the-uniform-distribution/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://www.math.bgu.ac.il/~yadina/"><img alt="" class="alignnone size-medium wp-image-18724" height="300" src="https://gilkalai.files.wordpress.com/2019/11/ayadin.png?w=244&amp;h=300" width="244"/></a></p>
<p><span style="color: #ff0000;">Aeiel Yadin’s <a href="https://www.math.bgu.ac.il/~yadina/">homepage</a> contains great lecture notes on harmonic functions on groups and on various other topics.</span></p>
<p>I have a lot of things to discuss and to report; exciting developments in the analysis of Boolean functions; much to report on algebraic, geometric and probabilistic combinatorics following our Oberwolfach summer meeting; much to tell about our Kazhdan seminar on quantum computation and symplectic geometry; a lot of exciting math and TCS activities in Israel; exciting things that Avi Wigderson’s told me on non commutative optimization and moment maps; and, of course, last but not least, the exciting <strong>Google supremacy demonstration</strong> that I most recently wrote about in my post <a href="https://gilkalai.wordpress.com/2019/11/13/gils-collegial-quantum-supremacy-skepticism-faq/" rel="bookmark"><strong>Gil’s Collegial Quantum Supremacy Skepticism FAQ</strong>.</a>  In particular, the unbelievable local-to-global fidelity <strong><span style="color: #ff0000;">Formula (77), </span></strong>and<span style="color: #0000ff;"><strong> (NEW) </strong></span><strong>a poem by Peter Shor for quantum computer skeptics</strong>. More poems are most welcome!</p>
<p>With all these excitements, plans, and blog duties it looks that this is the right time to take a pause for a Test Your Intuition post. (Based on chats with <a href="http://www.math.tau.ac.il/~asafnach/">Asaf Nachmias</a>, <a href="https://www.dpmms.cam.ac.uk/~jh2129/">Jonathan Hermon</a> and <a href="http://www.wisdom.weizmann.ac.il/~itai/">Itai Benjamini</a>.)</p>
<h2>Approaching the uniform distribution on the discrete cube with a lazy simple random walk.</h2>
<p>Consider the discrete cube as a graph: the vertices are all the 0-1 vertices of length <img alt="n " class="latex" src="https://s0.wp.com/latex.php?latex=n+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n "/>, two vertices are adjacent if they differ in one coordinate.</p>
<p>A (lazy) simple random walk is described as follows: You start at the all 0 vertex. At each step when you are at vertex <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> you stay where you are with probability 1/2 and, with probability 1/2,  you move to a neighbor  of <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> chosen uniformly at random.</p>
<p>Your position after <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> steps is a random variable describing a probability distribution <img alt="D_t" class="latex" src="https://s0.wp.com/latex.php?latex=D_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_t"/> on the vertices of the discrete cube. Now, lets fix once and for all the value of <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/> to be 0.1.</p>
<p><strong>Test your intuition:</strong> How many steps <em><strong>T(n)</strong></em> does it take until <img alt="D_t" class="latex" src="https://s0.wp.com/latex.php?latex=D_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_t"/> is <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-close to the uniform distribution <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> in <a href="https://en.wikipedia.org/wiki/Total_variation_distance_of_probability_measures">total variation distance</a>.  (The total variation distance is 1/2 the <img alt="L^1" class="latex" src="https://s0.wp.com/latex.php?latex=L%5E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L^1"/> distance).</p>
<h3>Others measure of proximity</h3>
<p>We can also ask: How many steps <em><strong>M(n)</strong></em> does it take until <img alt="D_t(x)" class="latex" src="https://s0.wp.com/latex.php?latex=D_t%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_t(x)"/> is close to the uniform distribution <em>for every</em> <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>? Namely, for every <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>,</p>
<p><img alt="(1-\epsilon)/2^n \le D_t(x) \le (1+\epsilon)/2^n" class="latex" src="https://s0.wp.com/latex.php?latex=%281-%5Cepsilon%29%2F2%5En+%5Cle+D_t%28x%29+%5Cle+%281%2B%5Cepsilon%29%2F2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(1-\epsilon)/2^n \le D_t(x) \le (1+\epsilon)/2^n"/></p>
<p>For this question there is a simple analysis based on the <a href="https://en.wikipedia.org/wiki/Coupon_collector%27s_problem">coupon collector problem</a>.</p>
<p>We can also consider intermediate measures of proximity, like the entropy:</p>
<p>How many steps <em><strong>H(n)</strong></em> it takes until the entropy of <img alt="D_t(x)" class="latex" src="https://s0.wp.com/latex.php?latex=D_t%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_t(x)"/> is <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>-close to the <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> the entropy of the uniform distribution?</p>
<p>Let me try now to test your more detailed intuition: For the public opinion poll below we say that <span style="color: #0000ff;"><em>X behaves like Y</em></span> if their ratio tends to one as <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> tends to infinity, and that <span style="color: #0000ff;"><em>X is really smaller than Y</em></span> if their ratio X/Y tends to a limit smaller than 1.</p>
<a name="pd_a_10464820"/><div class="CSS_Poll PDS_Poll" id="PDI_container10464820" style="display: inline-block;"/><div id="PD_superContainer"/><noscript>&lt;a href="https://polldaddy.com/p/10464820" target="_blank"&gt;Take Our Poll&lt;/a&gt;</noscript>
<h3><span style="color: #0000ff;">NEW: Share your knowledge</span></h3>
<p>Let’s try something new: “Share your knowledge (SYK):” What other distances between probability distributions do you recommend? Tell us about them!</p>
<h2>A theorem by Ajtai-Komlos-Szemeredi and a problem by Itai Benjamini</h2>
<p>Ajtai, Komlos and Szemeredi proved that when you choose every edge of the discrete <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-cube with probability greater than <img alt="1/n" class="latex" src="https://s0.wp.com/latex.php?latex=1%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/n"/> a giant component emerges! Now, choose every edge with probability <img alt="2/n" class="latex" src="https://s0.wp.com/latex.php?latex=2%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2/n"/>  and start a simple random walk from a vertex of the giant component. Itai Benjamini conjectured that it will take roughly <img alt="n^2" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n^2"/> steps to approximately reach the stationary distribution. This seems very difficult.</p>
<p> </p></div>
    </content>
    <updated>2019-12-02T06:15:20Z</updated>
    <published>2019-12-02T06:15:20Z</published>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Test your intuition"/>
    <category term="discrete cube"/>
    <category term="random walk"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-12-03T13:20:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/174</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/174" rel="alternate" type="text/html"/>
    <title>TR19-174 |  Exponential Resolution Lower Bounds for Weak Pigeonhole Principle and Perfect Matching Formulas over Sparse Graphs | 

	Susanna de Rezende, 

	Jakob Nordström, 

	Kilian Risse, 

	Dmitry Sokolov</title>
    <summary>We show exponential lower bounds on resolution proof length for pigeonhole principle (PHP) formulas and perfect matching formulas over highly unbalanced, sparse expander graphs, thus answering the challenge to establish strong lower bounds in the regime between balanced constant-degree expanders as in [Ben-Sasson and Wigderson '01] and highly unbalanced, dense graphs as in [Raz '04] and [Razborov '03, '04]. We obtain our results by revisiting Razborov's pseudo-width method for PHP formulas over dense graphs and extending it to sparse graphs. This further demonstrates the power of the pseudo-width method, and we believe it could potentially be useful for attacking also other longstanding open problems for resolution and other proof systems.</summary>
    <updated>2019-12-02T01:04:07Z</updated>
    <published>2019-12-02T01:04:07Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-12-03T13:20:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.13294</id>
    <link href="http://arxiv.org/abs/1911.13294" rel="alternate" type="text/html"/>
    <title>Classification of distributed binary labeling problems</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Balliu:Alkida.html">Alkida Balliu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brandt:Sebastian.html">Sebastian Brandt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Efron:Yuval.html">Yuval Efron</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hirvonen:Juho.html">Juho Hirvonen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maus:Yannic.html">Yannic Maus</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Olivetti:Dennis.html">Dennis Olivetti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suomela:Jukka.html">Jukka Suomela</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.13294">PDF</a><br/><b>Abstract: </b>We present a complete classification of the deterministic distributed time
complexity for a family of graph problems: binary labeling problems in trees.
These are locally checkable problems that can be encoded with an alphabet of
size two in the edge labeling formalism. Examples of binary labeling problems
include sinkless orientation, sinkless and sourceless orientation, 2-vertex
coloring, perfect matching, and the task of coloring edges of red and blue such
that all nodes are incident to at least one red and at least one blue edge.
More generally, we can encode e.g. any cardinality constraints on indegrees and
outdegrees.
</p>
<p>We study the deterministic time complexity of solving a given binary labeling
problem in trees, in the usual LOCAL model of distributed computing. We show
that the complexity of any such problem is in one of the following classes:
$O(1)$, $\Theta(\log n)$, $\Theta(n)$, or unsolvable. In particular, a problem
that can be represented in the binary labeling formalism cannot have time
complexity $\Theta(\log^* n)$, and hence we know that e.g. any encoding of
maximal matchings has to use at least three labels (which is tight).
</p>
<p>Furthermore, given the description of any binary labeling problem, we can
easily determine in which of the four classes it is and what is an
asymptotically optimal algorithm for solving it. Hence the distributed time
complexity of binary labeling problems is decidable, not only in principle, but
also in practice: there is a simple and efficient algorithm that takes the
description of a binary labeling problem and outputs its distributed time
complexity.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.13268</id>
    <link href="http://arxiv.org/abs/1911.13268" rel="alternate" type="text/html"/>
    <title>Adversarially Robust Low Dimensional Representations</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Awasthi:Pranjal.html">Pranjal Awasthi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chatziafratis:Vaggos.html">Vaggos Chatziafratis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Xue.html">Xue Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vijayaraghavan:Aravindan.html">Aravindan Vijayaraghavan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.13268">PDF</a><br/><b>Abstract: </b>Adversarial or test time robustness measures the susceptibility of a machine
learning system to small perturbations made to the input at test time. This has
attracted much interest on the empirical side, since many existing ML systems
perform poorly under imperceptible adversarial perturbations to the test
inputs. On the other hand, our theoretical understanding of this phenomenon is
limited, and has mostly focused on supervised learning tasks.
</p>
<p>In this work we study the problem of computing adversarially robust
representations of data. We formulate a natural extension of Principal
Component Analysis (PCA) where the goal is to find a low dimensional subspace
to represent the given data with minimum projection error, and that is in
addition robust to small perturbations measured in $\ell_q$ norm (say
$q=\infty$). Unlike PCA which is solvable in polynomial time, our formulation
is computationally intractable to optimize as it captures the well-studied
sparse PCA objective.
</p>
<p>We show the following algorithmic and statistical results.
</p>
<p>- Polynomial time algorithms in the worst-case that achieve constant factor
approximations to the objective while only violating the robustness constraint
by a constant factor.
</p>
<p>- We prove that our formulation (and algorithms) also enjoy significant
statistical benefits in terms of sample complexity over standard PCA on account
of a "regularization effect", that is formalized using the well-studied spiked
covariance model.
</p>
<p>- Surprisingly, we show that our algorithmic techniques can also be made
robust to corruptions in the training data, in addition to yielding
representations that are robust at test time! Here an adversary is allowed to
corrupt potentially every data point up to a specified amount in the $\ell_q$
norm. We further apply these techniques for mean estimation and clustering
under adversarial corruptions to the training data.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.13161</id>
    <link href="http://arxiv.org/abs/1911.13161" rel="alternate" type="text/html"/>
    <title>Tight Bounds for Planar Strongly Connected Steiner Subgraph with Fixed Number of Terminals (and Extensions)</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chitnis:Rajesh.html">Rajesh Chitnis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldmann:Andreas_Emil.html">Andreas Emil Feldmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hajiaghayi:MohammadTaghi.html">MohammadTaghi Hajiaghayi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marx:D=aacute=niel.html">Dániel Marx</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.13161">PDF</a><br/><b>Abstract: </b>(see paper for full abstract)
</p>
<p>Given a vertex-weighted directed graph $G=(V,E)$ and a set $T=\{t_1, t_2,
\ldots t_k\}$ of $k$ terminals, the objective of the SCSS problem is to find a
vertex set $H\subseteq V$ of minimum weight such that $G[H]$ contains a
$t_{i}\rightarrow t_j$ path for each $i\neq j$. The problem is NP-hard, but
Feldman and Ruhl [FOCS '99; SICOMP '06] gave a novel $n^{O(k)}$ algorithm for
the SCSS problem, where $n$ is the number of vertices in the graph and $k$ is
the number of terminals. We explore how much easier the problem becomes on
planar directed graphs:
</p>
<p>- Our main algorithmic result is a $2^{O(k)}\cdot n^{O(\sqrt{k})}$ algorithm
for planar SCSS, which is an improvement of a factor of $O(\sqrt{k})$ in the
exponent over the algorithm of Feldman and Ruhl.
</p>
<p>- Our main hardness result is a matching lower bound for our algorithm: we
show that planar SCSS does not have an $f(k)\cdot n^{o(\sqrt{k})}$ algorithm
for any computable function $f$, unless the Exponential Time Hypothesis (ETH)
fails.
</p>
<p>The following additional results put our upper and lower bounds in context:
</p>
<p>- In general graphs, we cannot hope for such a dramatic improvement over the
$n^{O(k)}$ algorithm of Feldman and Ruhl: assuming ETH, SCSS in general graphs
does not have an $f(k)\cdot n^{o(k/\log k)}$ algorithm for any computable
function $f$.
</p>
<p>- Feldman and Ruhl generalized their $n^{O(k)}$ algorithm to the more general
Directed Steiner Network (DSN) problem; here the task is to find a subgraph of
minimum weight such that for every source $s_i$ there is a path to the
corresponding terminal $t_i$. We show that, assuming ETH, there is no
$f(k)\cdot n^{o(k)}$ time algorithm for DSN on acyclic planar graphs.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.13144</id>
    <link href="http://arxiv.org/abs/1911.13144" rel="alternate" type="text/html"/>
    <title>Shortest Path Centrality and the All-pairs Shortest Paths Problem via Sample Complexity</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lima:Alane_M=_de.html">Alane M. de Lima</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Silva:Murilo_V=_G=_da.html">Murilo V. G. da Silva</a>, André L. Vignatti <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.13144">PDF</a><br/><b>Abstract: </b>In this paper we are interested in the all-pairs shortest paths problem
(APSP) for an input graph $G$ assumed to be connected undirected with non
negative real edge weights. In the exact deterministic case, it is an open
question whether this problem admits a $\mathcal{O}(n^{3-c})$ time algorithm,
for any constant $c&gt;0$, even in the case where edge weights are natural
numbers. There is a variety of approximation algorithms for the problem and the
time complexity of the fastest one depends on the graph being sparse or dense
and also on the corresponding approximation guarantee. In this paper we deal
with a version of the APSP that fits neither in the exact nor the approximate
case. We give a $O(n^2 \log n)$ randomized algorithm for APSP such that for
every pair of vertices the algorithm either computes the exact shortest path or
does not compute any shortest path, depending on a certain measure of
``importance'' (or centrality) of the shortest path in question.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.13104</id>
    <link href="http://arxiv.org/abs/1911.13104" rel="alternate" type="text/html"/>
    <title>Proper Hierarchies in Polylogarithmic Time and Absence of Complete Problems</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Ferrarotti:Flavio.html">Flavio Ferrarotti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gonz=aacute=lez:Sen=eacute=n.html">Senén González</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schewe:Klaus=Dieter.html">Klaus-Dieter Schewe</a>, José María Turull-Torres <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.13104">PDF</a><br/><b>Abstract: </b>The polylogarithmic time hierarchy structures sub-linear time complexity. In
recent work it was shown that all classes $\tilde{\Sigma}_{m}^{\mathit{plog}}$
or $\tilde{\Pi}_{m}^{\mathit{plog}}$ ($m \in \mathbb{N}$) in this hierarchy can
be captured by semantically restricted fragments of second-order logic. In this
paper the descriptive complexity theory of polylogarithmic time is taken
further showing that there are strict hierarchies inside each of the classes of
the hierarchy. A straightforward consequence of this result is that there are
no complete problems for these complexity classes, not even under polynomial
time reductions. As another consequence we show that the polylogarithmic time
hierarchy itself is strict.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.13099</id>
    <link href="http://arxiv.org/abs/1911.13099" rel="alternate" type="text/html"/>
    <title>Numerics on the trajectory of nodule displacements by external compressions of the breast</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nascimento:Marcelo_Zanchetta_do.html">Marcelo Zanchetta do Nascimento</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Batista:Val=eacute=rio_Ramos.html">Valério Ramos Batista</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.13099">PDF</a><br/><b>Abstract: </b>We present a fast and reliable algorithm that gives precise location of
breast tumours for a partial mastectomy. Our algorithm is fully implemented in
the Surface Evolver, which is a general-purpose simulator of physical
experiments. By starting from the X-rays images that show a tumour one takes
its 2D coordinates in each view. These views are called CC (Craniocaudal) and
MLO (Mediolateral Oblique). Together with some measurements of the patient's
breast, that coordinates are given as input to our simulator. From this point
on the simulator reproduces all main steps of taking mammography with a virtual
transparent breast that matches the patient's. The virtual mammography
procedure is graphically displayed on the computer screen, so that users can
track the virtual tumour inside the breast. As output we have the coordinates
of the tumour position when the woman lies on the operating table for the
surgery. With these coordinates the surgeon can make a small incision into the
breast and reach the tumour for its removal. After a simple plastic correction
the whole structure of the breast will be preserved.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.13097</id>
    <link href="http://arxiv.org/abs/1911.13097" rel="alternate" type="text/html"/>
    <title>A spiking neural algorithm for the Network Flow problem</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Abdullahi Ali, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kwisthout:Johan.html">Johan Kwisthout</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.13097">PDF</a><br/><b>Abstract: </b>It is currently not clear what the potential is of neuromorphic hardware
beyond machine learning and neuroscience. In this project, a problem is
investigated that is inherently difficult to fully implement in neuromorphic
hardware by introducing a new machine model in which a conventional Turing
machine and neuromorphic oracle work together to solve such types of problems.
We show that the P-complete Max Network Flow problem is intractable in models
where the oracle may be consulted only once (`create-and-run' model) but
becomes tractable using an interactive (`neuromorphic co-processor') model of
computation. More in specific we show that a logspace-constrained Turing
machine with access to an interactive neuromorphic oracle with linear space,
time, and energy constraints can solve Max Network Flow. A modified variant of
this algorithm is implemented on the Intel Loihi chip; a neuromorphic manycore
processor developed by Intel Labs. We show that by off-loading the search for
augmenting paths to the neuromorphic processor we can get energy efficiency
gains, while not sacrificing runtime resources. This result demonstrates how
P-complete problems can be mapped on neuromorphic architectures in a
theoretically and potentially practically efficient manner.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.13091</id>
    <link href="http://arxiv.org/abs/1911.13091" rel="alternate" type="text/html"/>
    <title>Hybrid Decision Trees: Longer Quantum Time is Strictly More Powerful</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Xiaoming.html">Xiaoming Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zheng:Yufan.html">Yufan Zheng</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.13091">PDF</a><br/><b>Abstract: </b>In this paper, we introduce the hybrid query complexity, denoted as
$\mathrm{Q}(f;q)$, which is the minimal query number needed to compute $f$,
when a classical decision tree is allowed to call $q'$-query quantum
subroutines for any $q'\leq q$. We present the following results:
</p>
<p>$\bullet$ There exists a total Boolean function $f$ such that
$\mathrm{Q}(f;1) = \widetilde{\mathcal{O}}(\mathrm{R}(f)^{4/5})$.
</p>
<p>$\bullet$ $\mathrm{Q}(f;q) = \Omega(\mathrm{bs}(f)/q +
\sqrt{\mathrm{bs}(f)})$ for any Boolean function $f$; the lower bound is tight
when $f$ is the ${\rm O{\small R}}$ function.
</p>
<p>$\bullet$ $\mathrm{Q}(g \circ {\rm X{\small OR}}_{C \log n};1) =
\widetilde{\Omega}(\sqrt{n})$ for some sufficiently large constant $C$, where
$g := {\rm B{\small OOL}S{\small IMON}}_n$ is a variant of Simon's problem.
Note that $\mathrm{Q}(g\circ {\rm X{\small OR}}_{C \log n}) =
\mathcal{O}(\mathrm{polylog}\; n)$. Therefore an exponential separation is
established. Furthermore, this open the road to prove the conjecture $\forall
k,\,\mathrm{Q}(g \circ {\rm X{\small OR}}_{C \log^{k+1} n};\log^{k} n) =
\widetilde{\Omega}(\sqrt{n})$, which would imply the oracle separation
$\mathsf{HP}(\mathsf{QSIZE}(n^\alpha))^\mathfrak{O} \subsetneq
\mathsf{BQP}^\mathfrak{O}$ for any $\alpha$, where
$\mathsf{HP}(\mathsf{QSIZE}(n^\alpha))$ is a complexity class that contains
$\mathsf{BQTIME}(n^\alpha)^{\mathsf{BPP}}$ and
$\mathsf{BPP}^{\mathsf{BQTIME}(n^\alpha)}$ in any relativized world.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.13085</id>
    <link href="http://arxiv.org/abs/1911.13085" rel="alternate" type="text/html"/>
    <title>Minimization of Weighted Completion Times in Path-based Coflow Scheduling</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eckl:Alexander.html">Alexander Eckl</a>, Luisa Peter, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schiffer:Maximilian.html">Maximilian Schiffer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Albers:Susanne.html">Susanne Albers</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.13085">PDF</a><br/><b>Abstract: </b>Coflow scheduling models communication requests in parallel computing
frameworks where multiple data flows between shared resources need to be
completed before computation can continue. In this paper, we introduce
Path-based Coflow Scheduling, a generalized problem variant that considers
coflows as collections of flows along fixed paths on general network topologies
with node capacity restrictions. For this problem, we minimize the coflows'
total weighted completion time. We show that flows on paths in the original
network can be interpreted as hyperedges in a hypergraph and transform the
path-based scheduling problem into an edge scheduling problem on this
hypergraph. We present a $(2\lambda + 1)$-approximation algorithm when node
capacities are set to one, where $\lambda$ is the maximum number of nodes in a
path. For the special case of simultaneous release times for all flows, our
result improves to a $(2\lambda)$-approximation. Furthermore, we generalize the
result to arbitrary node constraints and obtain a $(2\lambda\Delta + 1)$- and a
$(2\lambda\Delta)$-approximation in the case of general and zero release times,
where $\Delta$ captures the capacity disparity between nodes.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.13014</id>
    <link href="http://arxiv.org/abs/1911.13014" rel="alternate" type="text/html"/>
    <title>SOSD: A Benchmark for Learned Indexes</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kipf:Andreas.html">Andreas Kipf</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marcus:Ryan.html">Ryan Marcus</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Renen:Alexander_van.html">Alexander van Renen</a>, Mihail Stoian, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kemper:Alfons.html">Alfons Kemper</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kraska:Tim.html">Tim Kraska</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Neumann:Thomas.html">Thomas Neumann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.13014">PDF</a><br/><b>Abstract: </b>A groundswell of recent work has focused on improving data management systems
with learned components. Specifically, work on learned index structures has
proposed replacing traditional index structures, such as B-trees, with learned
models. Given the decades of research committed to improving index structures,
there is significant skepticism about whether learned indexes actually
outperform state-of-the-art implementations of traditional structures on
real-world data. To answer this question, we propose a new benchmarking
framework that comes with a variety of real-world datasets and baseline
implementations to compare against. We also show preliminary results for
selected index structures, and find that learned models indeed often outperform
state-of-the-art implementations, and are therefore a promising direction for
future research.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12995</id>
    <link href="http://arxiv.org/abs/1911.12995" rel="alternate" type="text/html"/>
    <title>SAT-Encodings for Treecut Width and Treedepth</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ganian:Robert.html">Robert Ganian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lodha:Neha.html">Neha Lodha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ordyniak:Sebastian.html">Sebastian Ordyniak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Szeider:Stefan.html">Stefan Szeider</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12995">PDF</a><br/><b>Abstract: </b>In this paper we propose, implement, and test the first practical
decomposition algorithms for the width parameters treecut width and treedepth.
These two parameters have recently gained a lot of attention in the theoretical
research community as they offer the algorithmic advantage over treewidth by
supporting so-called fixed-parameter algorithms for certain problems that are
not fixed-parameter tractable with respect to treewidth. However, the existing
research has mostly been theoretical. A main obstacle for any practical or
experimental use of these two width parameters is the lack of any practical or
implemented algorithm for actually computing the associated decompositions. We
address this obstacle by providing the first practical decomposition
algorithms.
</p>
<p>Our approach for computing treecut width and treedepth decompositions is
based on efficient encodings of these decomposition methods to the
propositional satisfiability problem (SAT). Once an encoding is generated, any
satisfiability solver can be used to find the decomposition. Moreover, we
propose new characterisations for treecut width and treedepth that are based on
sequences of partitions of the vertex set, a method that was pioneered for
clique-width. We implemented and systematically tested our encodings on various
benchmark instances, including famous named graphs and random graphs of various
density. It turned out that for the considered width parameters, our
partition-based SAT encoding even outperforms the best existing SAT encoding
for treewidth.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12988</id>
    <link href="http://arxiv.org/abs/1911.12988" rel="alternate" type="text/html"/>
    <title>Empty Squares in Arbitrary Orientation Among Points</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bae:Sang_Won.html">Sang Won Bae</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yoon:Sang_Duk.html">Sang Duk Yoon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12988">PDF</a><br/><b>Abstract: </b>This paper studies empty squares in arbitrary orientation among a set $P$ of
$n$ points in the plane. We prove that the number of empty squares with four
contact pairs is between $\Omega(n)$ and $O(n^2)$, and that these bounds are
tight, provided $P$ is in a certain general position. A contact pair of a
square is a pair of a point $p\in P$ and a side $\ell$ of the square with $p\in
\ell$. The upper bound $O(n^2)$ also applies to the number of empty squares
with four contact points, while we construct a point set among which there is
no square of four contact points. These combinatorial results are based on new
observations on the $L_\infty$ Voronoi diagram with the axes rotated and its
close connection to empty squares in arbitrary orientation. We then present an
algorithm that maintains a combinatorial structure of the $L_\infty$ Voronoi
diagram of $P$, while the axes of the plane continuously rotates by $90$
degrees, and simultaneously reports all empty squares with four contact pairs
among $P$ in an output-sensitive way within $O(s\log n)$ time and $O(n)$ space,
where $s$ denotes the number of reported squares. Several new algorithmic
results are also obtained: a largest empty square among $P$ and a square
annulus of minimum width or minimum area that encloses $P$ over all
orientations can be computed in worst-case $O(n^2 \log n)$ time.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12959</id>
    <link href="http://arxiv.org/abs/1911.12959" rel="alternate" type="text/html"/>
    <title>An Optimal Streaming Algorithm for Non-monotone Submodular Maximization</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ene:Alina.html">Alina Ene</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nguyen:Huy_L=.html">Huy L. Nguyen</a>, Andrew Suh <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12959">PDF</a><br/><b>Abstract: </b>We study the problem of maximizing a non-monotone submodular function subject
to a size constraint in the streaming model. Our main contribution is a
single-pass streaming algorithm that uses $k\cdot\mathrm{poly}(1/\epsilon)$
memory, where $k$ is the size constraint. At the end of the stream, we
post-process the output of the algorithm using any offline algorithm for
submodular maximization, and we obtain a solution whose approximation guarantee
is $\frac{\alpha}{1+\alpha}-\epsilon$, where $\alpha$ is the approximation of
the offline algorithm. If we use an exact (exponential time) post-processing
algorithm, we obtain a $\frac{1}{2}-\epsilon$ approximation, almost matching
the lower bound of [Alaluf-Feldman, 2019]. If we post-process with the
algorithm of [Buchbinder-Feldman, Math of OR 2019] that achieves the currently
best approximation guarantee $\alpha=0.385$, we obtain a $0.2779$ approximation
in polynomial time, improving over the previously best polynomial-time
approximation of $0.2335$ due to [Alaluf-Feldman, 2019]. In addition to its
improved approximation guarantee, our algorithm enjoys a fast update time and
overall running time.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12884</id>
    <link href="http://arxiv.org/abs/1911.12884" rel="alternate" type="text/html"/>
    <title>Efficient Recognition of Graph Languages</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Campbell:Graham.html">Graham Campbell</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Plump:Detlef.html">Detlef Plump</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12884">PDF</a><br/><b>Abstract: </b>Graph transformation is the rule-based modification of graphs, and is a
discipline dating back to the 1970s. In general, to match the left-hand graph
of a fixed rule within a host graph requires polynomial time, but to improve
matching performance, D\"orr proposed to equip rules and host graphs with
distinguished root nodes. This model was implemented by Plump and Bak, but
unfortunately, such rules are not invertible. We address this problem by
defining rootedness using a partial function into a two-point set rather than
pointing graphs with root nodes, meaning derivations are natural double
pushouts. Moreover, we give a sufficient condition on rules to give constant
time rule application on graphs of bounded degree, and that, the graph class of
trees can be recognised in linear time, given an input graph of bounded degree.
Finally, we define a new notion of confluence up to garbage and non-garbage
critical pairs, showing it is sufficient to require strong joinability of only
the non-garbage critical pairs to establish confluence up to garbage. Finally,
this new result, presented for conventional graph transformation systems, can
be lifted to our rooted setting by encoding node labels and rootedness as
looped edges.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12865</id>
    <link href="http://arxiv.org/abs/1911.12865" rel="alternate" type="text/html"/>
    <title>Threshold-Based Graph Reconstruction Using Discrete Morse Theory</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fasy:Brittany_Terese.html">Brittany Terese Fasy</a>, Sushovan Majhi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wenk:Carola.html">Carola Wenk</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12865">PDF</a><br/><b>Abstract: </b>Discrete Morse theory has recently been applied in metric graph
reconstruction from a given density function concentrated around an (unknown)
underlying embedded graph. We propose a new noise model for the density
function to reconstruct a connected graph both topologically and geometrically.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12778</id>
    <link href="http://arxiv.org/abs/1911.12778" rel="alternate" type="text/html"/>
    <title>PERMUTATION Strikes Back: The Power of Recourse in Online Metric Matching</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Varun.html">Varun Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krishnaswamy:Ravishankar.html">Ravishankar Krishnaswamy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sandeep:Sai.html">Sai Sandeep</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12778">PDF</a><br/><b>Abstract: </b>In the classical Online Metric Matching problem, we are given a metric space
with $k$ servers. A collection of clients arrive in an online fashion, and upon
arrival, a client should irrevocably be matched to an as-yet-unmatched server.
The goal is to find an online matching which minimizes the total cost, i.e.,
the sum of distances between each client and the server it is matched to. We
know deterministic algorithms~\cite{KP93,khuller1994line} that achieve a
competitive ratio of $2k-1$, and this bound is tight for deterministic
algorithms. The problem has also long been considered in specialized metrics
such as the line metric or metrics of bounded doubling dimension, with the
current best result on a line metric being a deterministic $O(\log k)$
competitive algorithm~\cite{raghvendra2018optimal}. Obtaining (or refuting)
$O(\log k)$-competitive algorithms in general metrics and constant-competitive
algorithms on the line metric have been long-standing open questions in this
area.
</p>
<p>In this paper, we investigate the robustness of these lower bounds by
considering the Online Metric Matching with Recourse problem where we are
allowed to change a small number of previous assignments upon arrival of a new
client. Indeed, we show that a small logarithmic amount of recourse can
significantly improve the quality of matchings we can maintain. For general
metrics, we show a simple \emph{deterministic} $O(\log k)$-competitive
algorithm with $O(\log k)$-amortized recourse, an exponential improvement over
the $2k-1$ lower bound when no recourse is allowed. We next consider the line
metric, and present a deterministic algorithm which is $3$-competitive and has
$O(\log k)$-recourse, again a substantial improvement over the best known
$O(\log k)$-competitive algorithm when no recourse is allowed.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12737</id>
    <link href="http://arxiv.org/abs/1911.12737" rel="alternate" type="text/html"/>
    <title>LL(1) Parsing with Derivatives and Zippers</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Edelmann:Romain.html">Romain Edelmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hamza:Jad.html">Jad Hamza</a>, Viktor Kunčak <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12737">PDF</a><br/><b>Abstract: </b>In this paper, we present an efficient, functional, and formally verified
parsing algorithm for LL(1) context-free expressions based on the concept of
derivatives of formal languages. Parsing with derivatives is an elegant parsing
technique, which, in the general case, suffers from cubic worst-case time
complexity and slow performance in practice. We specialise the parsing with
derivatives algorithm to LL(1) context-free expressions, where alternatives can
be chosen given a single token of lookahead. We formalise the notion of LL(1)
expressions and show how to efficiently check the LL(1) property. Next, we
present a novel linear-time parsing with derivatives algorithm for LL(1)
expressions operating on a zipper-inspired data structure. We prove the
algorithm correct in Coq and present an implementation as a parser combinators
framework in Scala, with enumeration and pretty printing capabilities.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12638</id>
    <link href="http://arxiv.org/abs/1911.12638" rel="alternate" type="text/html"/>
    <title>Quantum Lower Bounds for 2D-Grid and Dyck Language</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ambainis:Andris.html">Andris Ambainis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Balodis:Kaspars.html">Kaspars Balodis</a>, Jānis Iraids, Krišjānis Prūsis, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Smotrovs:Juris.html">Juris Smotrovs</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12638">PDF</a><br/><b>Abstract: </b>We show quantum lower bounds for two problems. First, we consider the problem
of determining if a sequence of parentheses is a properly balanced one (a Dyck
word), with a depth of at most $k$. It has been known that, for any $k$,
$\tilde{O}(\sqrt{n})$ queries suffice, with a $\tilde{O}$ term depending on
$k$. We prove a lower bound of $\Omega(c^k \sqrt{n})$, showing that the
complexity of this problem increases exponentially in $k$. This is interesting
as a representative example of star-free languages for which a surprising
$\tilde{O}(\sqrt{n})$ query quantum algorithm was recently constructed by
Aaronson et al.
</p>
<p>Second, we consider connectivity problems on directed/undirected grid in 2
dimensions, if some of the edges of the grid may be missing. By embedding the
"balanced parentheses" problem into the grid, we show a lower bound of
$\Omega(n^{1.5-\epsilon})$ for the directed 2D grid and
$\Omega(n^{2-\epsilon})$ for the undirected 2D grid. The directed problem is
interesting as a black-box model for a class of classical dynamic programming
strategies including the one that is usually used for the well-known edit
distance problem. We also show a generalization of this result to more than 2
dimensions.
</p></div>
    </summary>
    <updated>2019-12-02T23:20:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12520</id>
    <link href="http://arxiv.org/abs/1911.12520" rel="alternate" type="text/html"/>
    <title>Schur Polynomials do not have small formulas if the Determinant doesn't!</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chaugule:Prasad.html">Prasad Chaugule</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Mrinal.html">Mrinal Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Limaye:Nutan.html">Nutan Limaye</a>, Chandra Kanta Mohapatra, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/She:Adrian.html">Adrian She</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Srinivasan:Srikanth.html">Srikanth Srinivasan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12520">PDF</a><br/><b>Abstract: </b>Schur Polynomials are families of symmetric polynomials that have been
classically studied in Combinatorics and Algebra alike. They play a central
role in the study of Symmetric functions, in Representation theory [Sta99], in
Schubert calculus [LM10] as well as in Enumerative combinatorics [Gas96, Sta84,
Sta99]. In recent years, they have also shown up in various incarnations in
Computer Science, e.g, Quantum computation [HRTS00, OW15] and Geometric
complexity theory [IP17].
</p>
<p>However, unlike some other families of symmetric polynomials like the
Elementary Symmetric polynomials, the Power Symmetric polynomials and the
Complete Homogeneous Symmetric polynomials, the computational complexity of
syntactically computing Schur polynomials has not been studied much. In
particular, it is not known whether Schur polynomials can be computed
efficiently by algebraic formulas. In this work, we address this question, and
show that unless \emph{every} polynomial with a small algebraic branching
program (ABP) has a small algebraic formula, there are Schur polynomials that
cannot be computed by algebraic formula of polynomial size. In other words,
unless the algebraic complexity class $\mathrm{VBP}$ is equal to the complexity
class $\mathrm{VF}$, there exist Schur polynomials which do not have polynomial
size algebraic formulas.
</p>
<p>As a consequence of our proof, we also show that computing the determinant of
certain \emph{generalized} Vandermonde matrices is essentially as hard as
computing the general symbolic determinant. To the best of our knowledge, these
are one of the first hardness results of this kind for families of polynomials
which are not \emph{multilinear}. A key ingredient of our proof is the study of
composition of \emph{well behaved} algebraically independent polynomials with a
homogeneous polynomial, and might be of independent interest.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12427</id>
    <link href="http://arxiv.org/abs/1911.12427" rel="alternate" type="text/html"/>
    <title>Tree search algorithms for the Sequential Ordering Problem</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Libralesso:Luc.html">Luc Libralesso</a>, Abdel-Malik Bouhassoun, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cambazard:Hadrien.html">Hadrien Cambazard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jost:Vincent.html">Vincent Jost</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12427">PDF</a><br/><b>Abstract: </b>We present a study of several generic tree search techniques applied to the
Sequential Ordering Problem. This study enables us to propose a simple and
competitive tree search algorithm. It consists of an iterative Beam Search
algorithm that favors search over inference and integrates dynamic programming
inspired cuts. It proves optimality on half of the SOPLIB instances and finds
new best known solutions on 6 among 7 open instances of the benchmark in a
small amount of time.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12411</id>
    <link href="http://arxiv.org/abs/1911.12411" rel="alternate" type="text/html"/>
    <title>Roundtrip Spanners with $(2k-1)$ Stretch</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Ruoxu Cen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Duan:Ran.html">Ran Duan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12411">PDF</a><br/><b>Abstract: </b>A roundtrip spanner of a directed graph $G$ is a subgraph of $G$ preserving
roundtrip distances approximately for all pairs of vertices. Despite extensive
research, there is still a small stretch gap between roundtrip spanners in
directed graphs and undirected spanners. For a directed graph with real edge
weights in $[1,W]$, we first propose a new deterministic algorithm that
constructs a roundtrip spanner with $(2k-1)$ stretch and $O(k n^{1+1/k}\log
(nW))$ edges for every integer $k\ge 1$, then remove the dependence of size on
$W$ to give a roundtrip spanner with $(2k-1+o(1))$ stretch and $O(k
n^{1+1/k}\log n)$ edges. While keeping the edge size small, our result improves
the previous $2k+\epsilon$ stretch roundtrip spanners in directed graphs
[Roditty, Thorup, Zwick'02; Zhu, Lam'18], and almost match the undirected
$(2k-1)$-spanner with $O(k n^{1+1/k})$ edges [Alth\"ofer et al. '93] which is
optimal under Erd\"os conjecture.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1911.12383</id>
    <link href="http://arxiv.org/abs/1911.12383" rel="alternate" type="text/html"/>
    <title>Geometry-Driven Detection, Tracking and Visual Analysis of Viscous and Gravitational Fingers</title>
    <feedworld_mtime>1575244800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Jiayi.html">Jiayi Xu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dutta:Soumya.html">Soumya Dutta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/He:Wenbin.html">Wenbin He</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moortgat:Joachim.html">Joachim Moortgat</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shen:Han=Wei.html">Han-Wei Shen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1911.12383">PDF</a><br/><b>Abstract: </b>Viscous and gravitational flow instabilities cause a displacement front to
break up into finger-like fluids. The detection and evolutionary analysis of
these fingering instabilities are critical in multiple scientific disciplines
such as fluid mechanics and hydrogeology. However, previous detection methods
of the viscous and gravitational fingers are based on density thresholding,
which is sensitive to the user-specified threshold value. Also, the geometric
structures of fingers and their evolution are little studied. In this work, we
explore the topological and geometric detection and evolution of the fingers in
detail to elucidate the dynamics of the instability. We first detect finger
cores in three-dimensional (3D) scalar fields to capture the central structures
of fingers guided by a ridge voxel detection method; then, we skeletonize
finger cores to reveal their overall topological and geometric structures by a
Reeb-graph skeletonization method. From the identified finger skeletons, we
design a spanning contour tree-based method to capture how fingers branch in 3D
space. Then, to display different facets of finger branches, we employ various
tree-based visualization methods to plot the finger branches in a plane.
Finally, to track the evolution of time-varying fingers and their branches, we
nest tree-based geometric glyphs of fingers on a tracking graph. The
geometric-glyph augmented tracking graph allows us to study how the fingers
grow, merge, and split over time. Feedbacks from earth scientists demonstrate
the usefulness of our approach to analyze the evolution of fingers.
</p></div>
    </summary>
    <updated>2019-12-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-12-02T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2019/12/01/tropical-geometry-berkovich-spaces-arithmetic-d-modules-and-p-adic-local-systems/</id>
    <link href="https://cstheory-events.org/2019/12/01/tropical-geometry-berkovich-spaces-arithmetic-d-modules-and-p-adic-local-systems/" rel="alternate" type="text/html"/>
    <title>Tropical Geometry, Berkovich Spaces, Arithmetic D-Modules and p-adic Local Systems</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">June 15-19, 2020 Imperial College of London (UK) https://www-fourier.ujf-grenoble.fr/~pulitaa/Imperial-Conference/Imperial-Conference.html Registration deadline: March 31, 2020 With this workshop we would like to promote the interaction between the following five fields: Berkovich spaces Tropical geometry p-adic differential equations Arithmetic D-modules and representations of p-adic Lie groups Arithmetic applications of p-adic local systems While the first two are … <a class="more-link" href="https://cstheory-events.org/2019/12/01/tropical-geometry-berkovich-spaces-arithmetic-d-modules-and-p-adic-local-systems/">Continue reading <span class="screen-reader-text">Tropical Geometry, Berkovich Spaces, Arithmetic D-Modules and p-adic Local Systems</span></a></div>
    </summary>
    <updated>2019-12-01T16:59:41Z</updated>
    <published>2019-12-01T16:59:41Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2019-12-03T13:21:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5474</id>
    <link href="https://adamsheffer.wordpress.com/2019/12/01/teenagers-doing-mathematical-research/" rel="alternate" type="text/html"/>
    <title>Teenagers doing Mathematical Research</title>
    <summary>I’d like to ramble about another program that our group is running. We are searching for unusually promising high-school-age students and mentor each in a serious research project. We started doing this already before our REU program. However, I never advertised this program before, because I felt that we were still learning how to do […]</summary>
    <updated>2019-12-01T15:27:45Z</updated>
    <published>2019-12-01T15:27:45Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2019-12-03T13:21:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/173</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/173" rel="alternate" type="text/html"/>
    <title>TR19-173 |  Extractor Lower Bounds, Revisited | 

	Divesh Aggarwal, 

	Siyao  Guo, 

	Maciej Obremski, 

	Joao Ribeiro, 

	Noah Stephens-Davidowitz</title>
    <summary>We revisit the fundamental problem of determining seed length lower bounds for strong extractors and natural variants thereof. These variants stem from a ``change in quantifiers'' over the seeds of the extractor: While a strong extractor requires that the average output bias (over all seeds) is small for all input sources with sufficient min-entropy, a somewhere extractor only requires that there exists a seed whose output bias is small. More generally, we study what we call probable extractors, which on input a source with sufficient min-entropy guarantee that a large enough fraction of seeds have small enough associated output bias. Such extractors have played a key role in many constructions of pseudorandom objects, though they are often defined implicitly and have not been studied extensively.

Prior known techniques fail to yield good seed length lower bounds when applied to the variants above. Our novel approach yields significantly improved lower bounds for somewhere and probable extractors. To complement this, we construct a somewhere extractor that implies our lower bound for such functions is tight in the high min-entropy regime. Surprisingly, this means that a random function is far from an optimal somewhere extractor in this regime. The techniques that we develop also yield an alternative, simpler proof of the celebrated optimal lower bound for strong extractors originally due to Radhakrishnan and Ta-Shma (SIAM J. Discrete Math., 2000).</summary>
    <updated>2019-12-01T14:42:42Z</updated>
    <published>2019-12-01T14:42:42Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-12-03T13:20:26Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/11/30/linkage</id>
    <link href="https://11011110.github.io/blog/2019/11/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Hoffman’s packing puzzle, and its connection to the inequality of arithmetic and geometric means (). The one I have is not quite so colorful as the illustration for this new Wikipedia article. My father-in-law made it for me some 30 years ago; you can see it in a corner of the photo at this post. I don’t unpack it very often, though, because I lost track of the handwritten table of solutions that I made when I first got it and it’s quite difficult to re-pack.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Hoffman%27s_packing_puzzle">Hoffman’s packing puzzle, and its connection to the inequality of arithmetic and geometric means</a> (<a href="https://mathstodon.xyz/@11011110/103151390413241726"/>). The one I have is not quite so colorful as the illustration for this new Wikipedia article. My father-in-law made it for me some 30 years ago; you can see it in a corner of the photo at <a href="https://11011110.github.io/blog/2018/05/17/book-arrival.html">this post</a>. I don’t unpack it very often, though, because I lost track of the handwritten table of solutions that I made when I first got it and it’s quite difficult to re-pack.</p>
  </li>
  <li>
    <p><a href="https://www.wired.com/story/iran-internet-shutoff/">How the Iranian government shut off the internet</a> (<a href="https://mathstodon.xyz/@11011110/103155401533962129"/>). According to this story, they have effected “a near-total internet and mobile data blackout” in an attempt to quell gasoline-price protests.</p>
  </li>
  <li>
    <p><a href="https://agtb.wordpress.com/2019/11/19/a-market-for-tcs-papers/">A Market for TCS Papers??</a> (<a href="https://mathstodon.xyz/@11011110/103162041586643628"/>, with Vijay Vazirani, on the “Turing’s Invisible Hand” blog.) The current situation with theoretical computer science conference reviewing is a mess of long publication delays and reviewer overload caused by repeated submissions and rejections. Vijay and I argue that it should instead be treated as a matching market with pooled submissions and stable matching, getting better results for less time and effort.</p>
  </li>
  <li>
    <p><a href="https://www.siam.org/conferences/cm/program/accepted-papers/soda20-accepted-papers">SODA 2020 accepted papers</a> (<a href="https://mathstodon.xyz/@11011110/103167433760168313"/>). It only lists titles and authors, but if you notice a title you find intriguing you can find find more detail elsewhere. However, this depends on avoiding obscure titles; if, say, you found a breakthrough on clustered planarity showing that it’s in polynomial time, but you titled your paper “Atomic Embeddability, Clustered Planarity, and Thickenability”, others might not notice.</p>
  </li>
  <li>
    <p>Did you know that <a href="https://en.wikipedia.org/wiki/William_Chapple_(surveyor)">William Chapple</a> (<a href="https://mathstodon.xyz/@11011110/103174753258552519"/>) discovered Euler’s formula for circumcenter-incenter distance before Euler, Poncelet’s porism on families of triangles inscribed and circumscribed by the same two circles before Poncelet, and was the first to publish a proof that Euclid missed, on the existence of orthocenters of triangles? Did you know that a street in Witheridge is named for him? Have you even heard of William Chapple before? Or Witheridge? Now you have.</p>
  </li>
  <li>
    <p><a href="https://boingboing.net/2019/11/21/portal-icosahedron-sculpture-l.html">Portal Icosahedron by Anthony James</a> (<a href="https://mathstodon.xyz/@11011110/103177399066941274"/>). An icosahedral frame, infinity mirrors, and LED lighting create a view into an infinite icosahedral grid, creating an effect that, in the jargon of the art world, “is both esoteric and industrial, orphic and distinctly concrete”. Whatever that’s supposed to mean.</p>
  </li>
  <li>
    <p><a href="https://www.theregister.co.uk/2019/11/20/org_registry_sale_shambles/">Get ready to change all of your bookmarks for non-profit organizations</a> (<a href="https://mathstodon.xyz/@11011110/103186257585749674"/>, <a href="https://www.metafilter.com/184269/Seems-bad">via</a>) as the top-level .org domain name registry is sold to profiteers, drops its own non-profit status, and eliminates price caps on domain name renewals.</p>
  </li>
  <li>
    <p><a href="ttp://thelaborastory.com/stories/professor-ian-wanless-eliyahu-rips/">Ian Wanless on mathematician Eliyahu Rips and his Ig Nobel Prize for Literature</a> (<a href="https://mathstodon.xyz/@11011110/103189764743270099"/>). An entertaining general-audience talk; audio only.</p>
  </li>
  <li>
    <p><a href="https://math.indiana.edu/research/gallery/tree.html">Charles Darwin’s first drawing of an evolutionary tree</a> (<a href="https://mathstodon.xyz/@11011110/103196622232243519"/>).</p>
  </li>
  <li>
    <p><a href="https://boingboing.net/2019/11/24/bechdelgrams-are-beautiful.html">Bechdelgrams illustrate of whether a movie passes the Bechdel test</a> (<a href="https://mathstodon.xyz/@11011110/103208740086306490"/>). A nice use of color to highlight the information you’re looking for in a social network: Here, the network consists of interactions between characters in a film, and the women and conversations not about men are given distinctive colors to show the test criteria: does the film have at least two named female characters, who speak to each other, about something other than men?</p>
  </li>
  <li>
    <p><a href="https://boingboing.net/2019/11/27/paper-sculptures-of-microorgan.html">Rogan Brown creates intricate paper sculptures inspired by microorganisms</a> (<a href="https://mathstodon.xyz/@11011110/103211347688747567"/>).</p>
  </li>
  <li>
    <p>Some recent open-access conference proceedings (<a href="https://mathstodon.xyz/@11011110/103222522284012005"/>): <a href="http://drops.dagstuhl.de/opus/portals/lipics/index.php?semnr=16123">27th European Symp. on Algorithms (ESA)</a>; <a href="http://drops.dagstuhl.de/opus/portals/lipics/index.php?semnr=16131">30th Int. Symp. on Algorithms and Computation (ISAAC)</a>; <a href="http://www.jcdcgg.u-tokai.ac.jp/JCDCG3_2019_abstracts_v1.pdf">22nd Japan Conf. on Discrete and Computational Geometry, Graphs, and Games (JCDCGGG)</a>. JCDCGGG is not very selective (think CCCG but more so), but I have <a href="https://erikdemaine.org/papers/MinimalUnunfoldable_JCDCGGG2019/">a paper there with several co-authors on ununfoldable polyhedra with few vertices</a>.</p>
  </li>
  <li>
    <p><a href="https://slate.com/technology/2019/11/nefertiti-bust-neues-museum-3d-printing.html">The Nefertiti bust meets the 21st century</a> (<a href="https://mathstodon.xyz/@11011110/103228129647767519"/>, <a href="https://news.ycombinator.com/item?id=21670786">via</a>). Interesting essay on claims of intellectual property on ancient artifacts (in this case a high-resolution 3d scan of a bust of Nefertiti), clearly invalid under both US law and still-being-implemented EU law and “dangerously close to committing copy fraud”.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-11-30T10:10:00Z</updated>
    <published>2019-11-30T10:10:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-11-30T18:11:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2019-11-29-Analysis-Nakamoto/</id>
    <link href="https://decentralizedthoughts.github.io/2019-11-29-Analysis-Nakamoto/" rel="alternate" type="text/html"/>
    <title>Security proof for Nakamoto Consensus</title>
    <summary>Bitcoin’s underlying consensus protocol, now known as Nakamoto consensus, is an extremely simple and elegant solution to the Byzantine consensus problem. One may expect this simple protocol to come with a simple security proof. But that turns out not to be the case. The Bitcoin white paper did not provide...</summary>
    <updated>2019-11-29T21:05:00Z</updated>
    <published>2019-11-29T21:05:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Ittai Abraham</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2019-12-03T01:48:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/29/postdoc-at-university-of-waterloo-apply-by-december-31-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/29/postdoc-at-university-of-waterloo-apply-by-december-31-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Waterloo (apply by December 31, 2019)</title>
    <summary>The Algorithms &amp; Complexity group at the University of Waterloo is offering one postdoctoral position starting in the Fall of 2020. We seek candidates from all areas of TCS. Interested applicants should have their CV, research statement, and three recommendation letters emailed to theory.waterloo@gmail.com. Applications are due December 31st. Questions should be sent to the […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Algorithms &amp; Complexity group at the University of Waterloo is offering one postdoctoral position starting in the Fall of 2020. We seek candidates from all areas of TCS.<br/>
Interested applicants should have their CV, research statement, and three recommendation letters emailed to theory.waterloo@gmail.com. Applications are due December 31st.<br/>
Questions should be sent to the email above.</p>
<p>Website: <a href="https://algcomp.uwaterloo.ca/#MoreInfo">https://algcomp.uwaterloo.ca/#MoreInfo</a><br/>
Email: theory.waterloo@gmail.com</p></div>
    </content>
    <updated>2019-11-29T20:24:00Z</updated>
    <published>2019-11-29T20:24:00Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-12-03T13:20:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16420</id>
    <link href="https://rjlipton.wordpress.com/2019/11/29/predicating-predictivity/" rel="alternate" type="text/html"/>
    <title>Predicating Predictivity</title>
    <summary>Plus predicaments of error modeling Cropped from Bacon Sandwich source Sir David Spiegelhalter is a British statistician. He is a strong voice for the public understanding of statistics. His work extends to all walks of life, including risk, coincidences, murder, and sex. Today we talk about extending one of his inventions. His invention has to […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><span style="color: #0044cc;"><br/>
<em>Plus predicaments of error modeling</em><br/>
</span></p>
<table class="image alignright">
<tbody>
<tr>
<td><a href="https://rjlipton.wordpress.com/2019/11/29/predicating-predictivity/spiegelhalterbacon/" rel="attachment wp-att-16422"><img alt="" class="alignright wp-image-16422" height="168" src="https://rjlipton.files.wordpress.com/2019/11/spiegelhalterbacon.jpg?w=200&amp;h=168" width="200"/></a></td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Bacon Sandwich <a href="https://www.youtube.com/watch?v=4szyEbU94ig">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Sir David Spiegelhalter is a British statistician. He is a strong voice for the public understanding of statistics. His work extends to all walks of life, including <a href="https://www.regulation.org.uk/library/2017-Spiegelhalter-Risk_and_Uncertainty_Communication.pdf">risk</a>, <a href="https://understandinguncertainty.org/coincidences">coincidences</a>, <a href="https://www.spectator.co.uk/2019/04/i-could-have-stopped-harold-shipmans-killing-spree-and-saved-175-lives/">murder</a>, and <a href="https://www.ft.com/content/f8793aaa-dfa1-11e4-a06a-00144feab7de">sex</a>.</p>
<p>
Today we talk about extending one of his inventions.</p>
<p>
His invention has to do with grading the performance of people and models that make predictions. A <b>scoring rule</b> grades how often predictions are right. But it may not tell how difficult the situations are. It is easy to look good with predictions when they start with a high chance of success. A weather forecaster predicting sunny-versus-rainy will be right more often in Las Vegas than in Boston. Quoting this FiveThirtyEight <a href="https://fivethirtyeight.com/features/which-city-has-the-most-unpredictable-weather/">item</a>:</p>
<blockquote><p><b> </b> <em> If you want to have an easy life as a weather forecaster, you should get a job in Las Vegas, Phoenix or Los Angeles. Predict that it won’t rain in one of those cities, and you’ll be right about 90 percent of the time. </em>
</p></blockquote>
<p/><p>
In a 1986 <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.4780050506">paper</a>, for a particular scoring rule <a href="https://www.semanticscholar.org/paper/VERIFICATION-OF-FORECASTS-EXPRESSED-IN-TERMS-OF-Brier/feee6551179612b9691f021b583d8a99b81b9b86">defined</a> by Glenn Brier in 1950, Spiegelhalter worked out how to equalize the forecaster grading. He applied his <b>Z-test</b> not to weather as Brier was concerned with but to medical prognoses and clinical trials. </p>
<p>
What I am doing with a small group of graduate students in Buffalo is trying to turn Spiegelhalter’s kind of Z-test around once more. If a forecaster fares poorly, we will try to flag not the model but the behavior of the subjects being modeled. In weather we would want to tell when Mother Nature, not the models, has gone off the rails. Well, we are actually looking for ways to tell when a human being has left the bounds of human predictability for reasons that are inhuman—such as cheating with a computer at chess. And maybe it can shed more light on whether our computers can possibly “cheat” with quantum mechanics.</p>
<p>
</p><p/><h2> Prediction Scores </h2><p/>
<p/><p>
Let’s consider situations <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> in which the number <img alt="{\ell = \ell_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%3D+%5Cell_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell = \ell_t}"/> is usually more than <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>, that is, usually more than “rain” or “no rain.” The forecaster lays down projections <img alt="{\vec{q} = \vec{q}_t = (q_1,\dots,q_\ell)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7Bq%7D+%3D+%5Cvec%7Bq%7D_t+%3D+%28q_1%2C%5Cdots%2Cq_%5Cell%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\vec{q} = \vec{q}_t = (q_1,\dots,q_\ell)}"/> for the chance of each outcome. If outcome <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> happens, then the <em>Brier score</em> for that forecast is <a name="Brier"/></p><a name="Brier">
<p align="center"><img alt="\displaystyle  B^{\vec{q}}(r) = (1 - q_r)^2 + \sum_{j \neq r} q_j^2. \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++B%5E%7B%5Cvec%7Bq%7D%7D%28r%29+%3D+%281+-+q_r%29%5E2+%2B+%5Csum_%7Bj+%5Cneq+r%7D+q_j%5E2.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  B^{\vec{q}}(r) = (1 - q_r)^2 + \sum_{j \neq r} q_j^2. \ \ \ \ \ (1)"/></p>
</a><p><a name="Brier"/> If the forecaster was certain that <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> would happen and so put <img alt="{q_r = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_r+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_r = 1}"/>, all other <img alt="{q_j = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_j+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_j = 0}"/>, then the score would be zero. Thus lower is better for the Brier score. </p>
<p>
If you put probability <img alt="{q_r &lt; 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_r+%3C+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_r &lt; 1}"/> on the outcome that happened, then you get penalized both for the difference and for the remaining probability which you put on outcomes that did not happen. It is possible to <em>decompose</em> the score in another way that changes the emphasis: </p>
<p align="center"><img alt="\displaystyle  B^{\vec{q}}(r) = 1 + Q - 2q_r \qquad\text{where}\qquad Q = \sum_{j=1}^\ell q_j^2. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++B%5E%7B%5Cvec%7Bq%7D%7D%28r%29+%3D+1+%2B+Q+-+2q_r+%5Cqquad%5Ctext%7Bwhere%7D%5Cqquad+Q+%3D+%5Csum_%7Bj%3D1%7D%5E%5Cell+q_j%5E2.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  B^{\vec{q}}(r) = 1 + Q - 2q_r \qquad\text{where}\qquad Q = \sum_{j=1}^\ell q_j^2. "/></p>
<p>
Then <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> is a fixed measure of how you spread your forecasts around, while all the variability in your score comes from how much stock you placed in the outcome that happened. The worst case is having put <img alt="{q_r = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_r+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_r = 0}"/>, whereupon your Brier penalty is <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>. </p>
<p>
We would like our forecasts always to be perfect, but reality gives us situations that are inherently nondeterministic—with unknown “true probabilities” <img alt="{\vec{p}_t = (p_1,\dots,p_\ell)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7Bp%7D_t+%3D+%28p_1%2C%5Cdots%2Cp_%5Cell%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\vec{p}_t = (p_1,\dots,p_\ell)}"/>. The vital point is that the forecaster should not try to hit <img alt="{r = r_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%3D+r_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r = r_t}"/> on the nose at every time <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> but rather to match the true probabilities. Once we postulate <img alt="{\vec{p}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7Bp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\vec{p}}"/>, the <em>expected Brier score</em> is </p>
<p align="center"><img alt="\displaystyle  \begin{array}{rcl}  \mathsf{E}_{\vec{p}}[B^{\vec{q}}] &amp;=&amp; \sum_{i=1}^\ell p_i B^{\vec{q}}(i)\\ &amp;=&amp; \sum_{i=1}^\ell p_i (1 - 2q_i + Q)\\ &amp;=&amp; 1 + Q - 2\sum_{i=1}^\ell p_i q_i. \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++%5Cmathsf%7BE%7D_%7B%5Cvec%7Bp%7D%7D%5BB%5E%7B%5Cvec%7Bq%7D%7D%5D+%26%3D%26+%5Csum_%7Bi%3D1%7D%5E%5Cell+p_i+B%5E%7B%5Cvec%7Bq%7D%7D%28i%29%5C%5C+%26%3D%26+%5Csum_%7Bi%3D1%7D%5E%5Cell+p_i+%281+-+2q_i+%2B+Q%29%5C%5C+%26%3D%26+1+%2B+Q+-+2%5Csum_%7Bi%3D1%7D%5E%5Cell+p_i+q_i.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{rcl}  \mathsf{E}_{\vec{p}}[B^{\vec{q}}] &amp;=&amp; \sum_{i=1}^\ell p_i B^{\vec{q}}(i)\\ &amp;=&amp; \sum_{i=1}^\ell p_i (1 - 2q_i + Q)\\ &amp;=&amp; 1 + Q - 2\sum_{i=1}^\ell p_i q_i. \end{array} "/></p>
<p>This is uniquely minimized by setting <img alt="{q_i = p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i+%3D+p_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i = p_i}"/> for each <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, which defines <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> as a <b>strictly proper</b> scoring rule. Without the second term <img alt="{\sum_{j \neq r} q_j^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bj+%5Cneq+r%7D+q_j%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sum_{j \neq r} q_j^2}"/> in (<a href="https://rjlipton.wordpress.com/feed/#Brier">1</a>) the rule would not be proper for <img alt="{\ell &gt; 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%3E+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell &gt; 2}"/>. When <img alt="{\vec{q} = \vec{p}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7Bq%7D+%3D+%5Cvec%7Bp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\vec{q} = \vec{p}}"/>, <img alt="{Q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Q}"/> becomes equal to <img alt="{P = \sum_{j=1}^\ell p_j^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP+%3D+%5Csum_%7Bj%3D1%7D%5E%5Cell+p_j%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P = \sum_{j=1}^\ell p_j^2}"/>. Thus <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> represents an unavoidable prediction penalty from the intrinsic variance. If all <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/> are equal, <img alt="{p_i = \frac{1}{\ell}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i+%3D+%5Cfrac%7B1%7D%7B%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i = \frac{1}{\ell}}"/>, then the expected score cannot be less than <img alt="{1 - \frac{1}{\ell}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+-+%5Cfrac%7B1%7D%7B%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1 - \frac{1}{\ell}}"/>. </p>
<p>
A second example, the log-likelihood prediction scoring rule, is in the original longer <a href="https://cse.buffalo.edu/~regan/GLL/wspiegelhalterLong.pdf">draft</a> of this post.</p>
<p/><h2> Spiegelhalter’s Z </h2><p/>
<p/><p>
Spiegelhalter’s <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/>-score neatly drops out the unavoidable penalty term by taking the difference of the score with the expectation. Schematically it is defined as </p>
<p align="center"><img alt="\displaystyle  \mathsf{Z}[B] = \frac{B - \mathsf{E}[B]}{\sqrt{\mathsf{Var}[B]}}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BZ%7D%5BB%5D+%3D+%5Cfrac%7BB+-+%5Cmathsf%7BE%7D%5BB%5D%7D%7B%5Csqrt%7B%5Cmathsf%7BVar%7D%5BB%5D%7D%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{Z}[B] = \frac{B - \mathsf{E}[B]}{\sqrt{\mathsf{Var}[B]}}, "/></p>
<p>where <img alt="{\mathsf{Var}[B]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BVar%7D%5BB%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{Var}[B]}"/> means the projected variance <img alt="{\mathsf{E}_{\vec{p}}[B^2] - (\mathsf{E}_{\vec{p}}[B])^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BE%7D_%7B%5Cvec%7Bp%7D%7D%5BB%5E2%5D+-+%28%5Cmathsf%7BE%7D_%7B%5Cvec%7Bp%7D%7D%5BB%5D%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{E}_{\vec{p}}[B^2] - (\mathsf{E}_{\vec{p}}[B])^2}"/>. However, here is where it is important to notate the whole series of forecasting situations <img alt="{t = 1,\dots,T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%3D+1%2C%5Cdots%2CT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t = 1,\dots,T}"/> with outcomes <img alt="{r_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r_t}"/> for each <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/>. The actual statistic is <a name="ZB"/></p><a name="ZB">
<p align="center"><img alt="\displaystyle  \mathsf{Z}_{\vec{p}}[B^{\vec{q}}] = \frac{\sum_{t=1}^T B^{\vec{q}_t}(r_t) - \mathsf{E}_{\vec{p}_t}[B^{\vec{q}_t}]}{\sqrt{\sum_{t=1}^T \mathsf{Var}_{\vec{p}_t}[B^{\vec{q}_t}]}}. \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BZ%7D_%7B%5Cvec%7Bp%7D%7D%5BB%5E%7B%5Cvec%7Bq%7D%7D%5D+%3D+%5Cfrac%7B%5Csum_%7Bt%3D1%7D%5ET+B%5E%7B%5Cvec%7Bq%7D_t%7D%28r_t%29+-+%5Cmathsf%7BE%7D_%7B%5Cvec%7Bp%7D_t%7D%5BB%5E%7B%5Cvec%7Bq%7D_t%7D%5D%7D%7B%5Csqrt%7B%5Csum_%7Bt%3D1%7D%5ET+%5Cmathsf%7BVar%7D_%7B%5Cvec%7Bp%7D_t%7D%5BB%5E%7B%5Cvec%7Bq%7D_t%7D%5D%7D%7D.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{Z}_{\vec{p}}[B^{\vec{q}}] = \frac{\sum_{t=1}^T B^{\vec{q}_t}(r_t) - \mathsf{E}_{\vec{p}_t}[B^{\vec{q}_t}]}{\sqrt{\sum_{t=1}^T \mathsf{Var}_{\vec{p}_t}[B^{\vec{q}_t}]}}. \ \ \ \ \ (2)"/></p>
</a><p><a name="ZB"/> The denominator presumes that the forecast situations are independent so that the variances add. The numerator expands to be </p>
<p align="center"><img alt="\displaystyle  \sum_{t=1}^T \left(2\sum_{i=1}^{\ell_t} p_{i,t} q_{i,t}\right) - 2q_{r,t}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bt%3D1%7D%5ET+%5Cleft%282%5Csum_%7Bi%3D1%7D%5E%7B%5Cell_t%7D+p_%7Bi%2Ct%7D+q_%7Bi%2Ct%7D%5Cright%29+-+2q_%7Br%2Ct%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \sum_{t=1}^T \left(2\sum_{i=1}^{\ell_t} p_{i,t} q_{i,t}\right) - 2q_{r,t}. "/></p>
<p>
The original application is a confidence test of the “null hypothesis” that the projections <img alt="{\vec{q}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\vec{q}}"/> are good. Thus we plug in <img alt="{p_{i,t} = q_{i,t}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_%7Bi%2Ct%7D+%3D+q_%7Bi%2Ct%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_{i,t} = q_{i,t}}"/> for all <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> and <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> so that we test </p>
<p align="center"><img alt="\displaystyle  \mathsf{Z}_{\vec{q}}[B^{\vec{q}}] = 2\frac{\sum_{t=1}^T \left(\sum_{i=1}^{\ell_t} q_{i,t}^2 \right) - q_{r,t}}{\sqrt{\sum_{t=1}^T \mathsf{Var}_{\vec{q}_t}[B^{\vec{q}_t}]}}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BZ%7D_%7B%5Cvec%7Bq%7D%7D%5BB%5E%7B%5Cvec%7Bq%7D%7D%5D+%3D+2%5Cfrac%7B%5Csum_%7Bt%3D1%7D%5ET+%5Cleft%28%5Csum_%7Bi%3D1%7D%5E%7B%5Cell_t%7D+q_%7Bi%2Ct%7D%5E2+%5Cright%29+-+q_%7Br%2Ct%7D%7D%7B%5Csqrt%7B%5Csum_%7Bt%3D1%7D%5ET+%5Cmathsf%7BVar%7D_%7B%5Cvec%7Bq%7D_t%7D%5BB%5E%7B%5Cvec%7Bq%7D_t%7D%5D%7D%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{Z}_{\vec{q}}[B^{\vec{q}}] = 2\frac{\sum_{t=1}^T \left(\sum_{i=1}^{\ell_t} q_{i,t}^2 \right) - q_{r,t}}{\sqrt{\sum_{t=1}^T \mathsf{Var}_{\vec{q}_t}[B^{\vec{q}_t}]}}. "/></p>
<p>
To illustrate, suppose we do ten independent trials of an event with four outcomes whose true probabilities are <img alt="{(0.1,0.2,0.3,0.4)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%280.1%2C0.2%2C0.3%2C0.4%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(0.1,0.2,0.3,0.4)}"/>. The sum in parentheses is <img alt="{10(0.01 + 0.04 + 0.09 + 0.16) = 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B10%280.01+%2B+0.04+%2B+0.09+%2B+0.16%29+%3D+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{10(0.01 + 0.04 + 0.09 + 0.16) = 3}"/>. If the outcomes conform exactly to these probabilities then <img alt="{q_{r,t}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_%7Br%2Ct%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_{r,t}}"/> equals <img alt="{0.1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0.1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0.1}"/> once, <img alt="{0.2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0.2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0.2}"/> twice, <img alt="{0.3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0.3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0.3}"/> three times, and <img alt="{0.4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0.4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0.4}"/> four times. This exactly cancels the <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/>, so <img alt="{\vec{q} = \vec{p}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7Bq%7D+%3D+%5Cvec%7Bp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\vec{q} = \vec{p}}"/> makes <img alt="{\mathsf{Z}_{\vec{q}}[B^{\vec{q}}] = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BZ%7D_%7B%5Cvec%7Bq%7D%7D%5BB%5E%7B%5Cvec%7Bq%7D%7D%5D+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{Z}_{\vec{q}}[B^{\vec{q}}] = 0}"/>, as expected. Most trials will give a nonzero numerator, but in the long run, the numerator divided by <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> tends toward zero and the denominator scales to match it, thus keeping the <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>-statistic normally distributed.</p>
<p>
A high <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>, on the other hand—highly positive or highly negative—indicates that the forecasting is way off. That (<a href="https://rjlipton.wordpress.com/feed/#ZB">2</a>) is an aggregate statistic over independent trials justifies treating the <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>-values as <a href="https://en.wikipedia.org/wiki/Standard_score">standard</a> <a href="https://en.wikipedia.org/wiki/Z-test">scores</a>. This applies also to <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>-tests made similarly from other scoring rules besides the Brier score. The test thus becomes a verdict on the model. High <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>-values on certain subsets of the data may reveal biases. </p>
<p>
Our idea is the opposite. Suppose we know that the forecasts are true, or suppose they have biases that are known and correctable over moderately large data sets. We may then be able to fit <img alt="{\mathsf{Z}[B]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BZ%7D%5BB%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{Z}[B]}"/> as an unbiased estimator (of zero) over large training sets. Then it can become a judgment of whether the data has become unnatural. </p>
<p>
</p><p/><h2> Why This Z? </h2><p/>
<p/><p>
As I have detailed in <a href="https://rjlipton.wordpress.com/2019/08/15/predicting-chess-and-horses/">numerous</a> <a href="https://rjlipton.wordpress.com/2013/09/17/littlewoods-law/">posts</a> <a href="https://rjlipton.wordpress.com/2018/10/18/london-calling/">on</a> <a href="https://rjlipton.wordpress.com/2013/07/27/thirteen-sigma/">this</a> <a href="https://rjlipton.wordpress.com/2011/10/12/empirical-humility/">blog</a>, my system for detecting cheating with computers at chess already provides several statistical <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/>-scores. Why would I want another one?</p>
<p>
The motive involves the presence of multiple strong chess-playing programs, each with its own quirks and distribution of values for moves. They are used in two different ways:</p>
<ol>
<li>
As inputs telling the relative values <img alt="{v_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v_i}"/> of moves <img alt="{m_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m_i}"/>, which my model converts into its probability projections <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i}"/>. <p/>
</li><li>
As output predicates telling how often the player chose the move recommended by a specific program and/or quantifying the magnitude of error for different played moves.
</li></ol>
<p>
Having multiple engines helps point 1. My intent to blend the <em>values</em> <img alt="{v_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v_i}"/> from different engines has been blunted by issues I discussed <a href="https://rjlipton.wordpress.com/2018/09/07/sliding-scale-problems/">here</a>.  Thus I now have to train my model separately (and expensively) for each (new version of each) program. I can then blend the <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i}"/>, but point 2 still remains at issue: My tests measure concordance with a specific program. Originally the program Rybka 3 was primary and Houdini 4B secondary. Now Stockfish 7 is primary and Komodo 10.0 secondary—until I update to their latest versions. The second engine is supposed to confirm a positive result from the first one.  This already means that my model is not trying to detect exactly which program was used.</p>
<p>
Nevertheless, my results often vary between testing engines. The engines <a href="https://rjlipton.wordpress.com/2014/12/28/the-new-chess-world-champion/">compete</a> against each other and may be crafted to disagree on certain kinds of moves. They agree with each other barely 75–80% in my tests. I would like to factor these differences out. </p>
<p>
The Spiegelhalter <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>-test appeals because its reference is not to a particular chess program, but to the prediction quality of my model itself—which per point 1 can be informed by many programs in concert. It gives a way to <em>predicate predictivity</em>. A high value will attest that the sequence of played moves falls outside the range of predictability for human players of the same rated skill level. </p>
<p>
</p><p/><h2> The Method </h2><p/>
<p/><p>
To harness <img alt="{\mathsf{Z}[F]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BZ%7D%5BF%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{Z}[F]}"/> for some scoring rule <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/>, we need to quantify the nature of my model’s <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i}"/> projections. In fact, my model has a clear bias toward conservatism in judging the frequency of particular non-optimal moves. This is discussed in my August <a href="https://rjlipton.wordpress.com/2019/08/15/predicting-chess-and-horses/">post</a> on my model upgrade and shown graphically in an appended <a href="https://cse.buffalo.edu/~regan/chess/computer/ModelTradeoffs.png">note</a> on why the conservative setting of a “gradient” parameter is needed to preserve dynamical stability. The fitting offsets this in a way that creates an opposite bias elsewhere. I hope to correct both biases at the same stroke by a specific means of modeling how the <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i}"/> err with respect to the postulated true probabilities <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/>.</p>
<p>
We postulate an original source of error terms <img alt="{\epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon_i}"/> all <a href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">i.i.d.</a> as <img alt="{\mathcal{N}(0,\delta^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BN%7D%280%2C%5Cdelta%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{N}(0,\delta^2)}"/>, where <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> governs the magnitude of Gaussian noise. This noise can be <em>transformed</em> and related in various ways, e.g.:</p>
<ol>
<li>
<img alt="{q_i = p_i \pm \epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i+%3D+p_i+%5Cpm+%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i = p_i \pm \epsilon_i}"/>, <p/>
</li><li>
<img alt="{q_i = p_i(1 \pm \epsilon_i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i+%3D+p_i%281+%5Cpm+%5Cepsilon_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i = p_i(1 \pm \epsilon_i)}"/>, <p/>
</li><li>
<img alt="{\frac{1}{q_i} = \frac{1}{p_i} \pm \epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7Bq_i%7D+%3D+%5Cfrac%7B1%7D%7Bp_i%7D+%5Cpm+%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{1}{q_i} = \frac{1}{p_i} \pm \epsilon_i}"/>, <p/>
</li><li>
<img alt="{\log(\frac{1}{q_i}) = \log(\frac{1}{p_i}) \pm \epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28%5Cfrac%7B1%7D%7Bq_i%7D%29+%3D+%5Clog%28%5Cfrac%7B1%7D%7Bp_i%7D%29+%5Cpm+%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log(\frac{1}{q_i}) = \log(\frac{1}{p_i}) \pm \epsilon_i}"/>, <p/>
</li><li>
<img alt="{\log(\frac{1}{q_i}) = \log(\frac{1}{p_i})(1 \pm \epsilon_i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28%5Cfrac%7B1%7D%7Bq_i%7D%29+%3D+%5Clog%28%5Cfrac%7B1%7D%7Bp_i%7D%29%281+%5Cpm+%5Cepsilon_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log(\frac{1}{q_i}) = \log(\frac{1}{p_i})(1 \pm \epsilon_i)}"/>, <p/>
</li><li>
<img alt="{\ln(\frac{q_i}{1 - q_i}) = \ln(\frac{p_i}{1 - p_i}) \pm \epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cln%28%5Cfrac%7Bq_i%7D%7B1+-+q_i%7D%29+%3D+%5Cln%28%5Cfrac%7Bp_i%7D%7B1+-+p_i%7D%29+%5Cpm+%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ln(\frac{q_i}{1 - q_i}) = \ln(\frac{p_i}{1 - p_i}) \pm \epsilon_i}"/>.
</li></ol>
<p>
There are further forms to consider and it is not yet clear from data within my model which one most applies. We would be interested in examples where these representations have been employed and in observations about their natures. </p>
<p>
Given the error terms, we can write each <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/> as a function of <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i}"/> and <img alt="{\epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon_i}"/>. One issue is having at most <img alt="{\ell-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell-1}"/> degrees of freedom among <img alt="{\epsilon_1,\dots,\epsilon_\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_1%2C%5Cdots%2C%5Cepsilon_%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon_1,\dots,\epsilon_\ell}"/>, owing to the constraint that the <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i}"/> as well as <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/> sum to <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. We handle this by choosing some fixed <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> as the “pivot” and using the constraints to eliminate <img alt="{p_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_k}"/> and <img alt="{q_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_k}"/>, leaving the other error terms free. In all cases, the proposed method of defining what we notate as <img alt="{\mathsf{Z}_{\vec{q},\vec{\epsilon}}[F]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BZ%7D_%7B%5Cvec%7Bq%7D%2C%5Cvec%7B%5Cepsilon%7D%7D%5BF%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{Z}_{\vec{q},\vec{\epsilon}}[F]}"/> is:</p>
<ul>
<li>
Substitute the terms with <img alt="{q_i,\epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%2C%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i,\epsilon_i}"/> for each free <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/> into <img alt="{\mathsf{Z}_{\vec{p}}[F^{\vec{q}}]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BZ%7D_%7B%5Cvec%7Bp%7D%7D%5BF%5E%7B%5Cvec%7Bq%7D%7D%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{Z}_{\vec{p}}[F^{\vec{q}}]}"/>. <p/>
</li><li>
Compute the expectation over <img alt="{\epsilon_i \sim \mathcal{N}(0,\delta^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_i+%5Csim+%5Cmathcal%7BN%7D%280%2C%5Cdelta%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon_i \sim \mathcal{N}(0,\delta^2)}"/> for the numerator and denominator of (<a href="https://rjlipton.wordpress.com/feed/#ZB">2</a>), separately. <p/>
</li><li>
Holding the other previously-fitted model parameters in place, fit <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> so that <img alt="{\mathsf{Z}_{\vec{q},\vec{\epsilon}}[F]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BZ%7D_%7B%5Cvec%7Bq%7D%2C%5Cvec%7B%5Cepsilon%7D%7D%5BF%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{Z}_{\vec{q},\vec{\epsilon}}[F]}"/> is zero over the training set (or sets, for each level of Elo rating <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/>, so <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> becomes a function of <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R}"/>).
</li></ul>
<p>
If the resulting <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>-scores parameterized by <img alt="{\delta_R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta_R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta_R}"/> make sense, the last step will be adjusting them to conform to normal distribution, via the resampling process mentioned recently <a href="https://rjlipton.wordpress.com/2019/08/20/our-trip-to-monte-carlo/">here</a> and earlier <a href="https://rjlipton.wordpress.com/2011/10/12/empirical-humility/">here</a>. We are not there yet. But observations from Spiegelhalter tests with <img alt="{\vec{q} = \vec{p}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7Bq%7D+%3D+%5Cvec%7Bp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\vec{q} = \vec{p}}"/> (equivalently, with <img alt="{\delta_R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta_R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta_R}"/> fixed to zero) suggest that the resulting single, authoritative, “pure” predictivity test may rival the sharpness of my current tests involving specific chess programs.</p>
<p>
</p><p/><h2> Error Quirks and Queries </h2><p/>
<p/><p>
To see a key wrinkle, consider the first error form. It is symmetrical: <img alt="{p_i = q_i \pm \epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i+%3D+q_i+%5Cpm+%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i = q_i \pm \epsilon_i}"/>. When we substitute <img alt="{q_i + \epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i+%2B+%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i + \epsilon_i}"/> for <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/> and take <img alt="{\mathsf{E}_{\epsilon_i \sim \mathcal{N}(0,\delta^2)}[\cdots]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BE%7D_%7B%5Cepsilon_i+%5Csim+%5Cmathcal%7BN%7D%280%2C%5Cdelta%5E2%29%7D%5B%5Ccdots%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{E}_{\epsilon_i \sim \mathcal{N}(0,\delta^2)}[\cdots]}"/>, the symmetry of <img alt="{\epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon_i}"/> around <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> makes it drop out of the numerator of (<a href="https://rjlipton.wordpress.com/feed/#ZB">2</a>), and out of everything in the denominator except one place where <img alt="{p_i^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i^2}"/> becomes <img alt="{(q_i^2 + 2\epsilon q_i + \epsilon_i^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28q_i%5E2+%2B+2%5Cepsilon+q_i+%2B+%5Cepsilon_i%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(q_i^2 + 2\epsilon q_i + \epsilon_i^2)}"/>. There is hence nothing for <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> to fit and we are basically left with the original Spiegelhalter <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>. </p>
<p>
In the second form, however, we get <img alt="{p_i = q_i \cdot \frac{1}{1 + \epsilon_i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i+%3D+q_i+%5Ccdot+%5Cfrac%7B1%7D%7B1+%2B+%5Cepsilon_i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i = q_i \cdot \frac{1}{1 + \epsilon_i}}"/>. If we presume <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> small enough to make the distribution of <img alt="{\mathcal{N}(0,\delta^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BN%7D%280%2C%5Cdelta%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{N}(0,\delta^2)}"/> outside <img alt="{(-1,1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%2C1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1,1)}"/> negligible, then we can use the series expansion to approximate </p>
<p align="center"><img alt="\displaystyle  p_i \approx q_i(1 - \epsilon_i + \epsilon_i^2 - \epsilon_i^3 + \epsilon_i^4). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p_i+%5Capprox+q_i%281+-+%5Cepsilon_i+%2B+%5Cepsilon_i%5E2+-+%5Cepsilon_i%5E3+%2B+%5Cepsilon_i%5E4%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  p_i \approx q_i(1 - \epsilon_i + \epsilon_i^2 - \epsilon_i^3 + \epsilon_i^4). "/></p>
<p>Under normal expectation, the odd-power terms drop out (so their signs don’t matter) and we get </p>
<p align="center"><img alt="\displaystyle  \mathsf{E}_{\epsilon_i \sim \mathcal{N}(0,\delta^2)}[q_i(1 - \epsilon_i + \epsilon_i^2 - \epsilon_i^3 + \epsilon_i^4)] = q_i(1 + \delta^2 + 3\delta^4). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BE%7D_%7B%5Cepsilon_i+%5Csim+%5Cmathcal%7BN%7D%280%2C%5Cdelta%5E2%29%7D%5Bq_i%281+-+%5Cepsilon_i+%2B+%5Cepsilon_i%5E2+-+%5Cepsilon_i%5E3+%2B+%5Cepsilon_i%5E4%29%5D+%3D+q_i%281+%2B+%5Cdelta%5E2+%2B+3%5Cdelta%5E4%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{E}_{\epsilon_i \sim \mathcal{N}(0,\delta^2)}[q_i(1 - \epsilon_i + \epsilon_i^2 - \epsilon_i^3 + \epsilon_i^4)] = q_i(1 + \delta^2 + 3\delta^4). "/></p>
<p>This credits <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i}"/> as being greater than <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i}"/>. Provided the projections for the substituted indices <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> were generally slightly conservative, this has hope of correcting them.</p>
<p>
Already, however, we have traipsed over some pitfalls of methodology. One is that the normal expectation </p>
<p align="center"><img alt="\displaystyle  \mathsf{E}_{\epsilon \sim \mathcal{N}(0,\delta^2)}[\frac{1}{1+\epsilon}] = +\infty, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BE%7D_%7B%5Cepsilon+%5Csim+%5Cmathcal%7BN%7D%280%2C%5Cdelta%5E2%29%7D%5B%5Cfrac%7B1%7D%7B1%2B%5Cepsilon%7D%5D+%3D+%2B%5Cinfty%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{E}_{\epsilon \sim \mathcal{N}(0,\delta^2)}[\frac{1}{1+\epsilon}] = +\infty, "/></p>
<p>regardless of how small <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/> is. For any <img alt="{\delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta}"/>, regions around the pole <img alt="{\epsilon = -1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3D+-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon = -1}"/> get some fixed finite probability. Another is the simple paradox of our second form saying:</p>
<blockquote><p><b> </b> <em> <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{q_i}"/> is an unbiased estimator of <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{p_i}"/>, but <img alt="{p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{p_i}"/> is not an unbiased (or even finite) estimator of <img alt="{q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{q_i}"/>. </em>
</p></blockquote>
<p/><p>
A third curiosity comes from the fourth error form. It gives <img alt="{q_i = p_i e^{\epsilon_i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq_i+%3D+p_i+e%5E%7B%5Cepsilon_i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q_i = p_i e^{\epsilon_i}}"/>, so <img alt="{p_i = q_i e^{-\epsilon_i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_i+%3D+q_i+e%5E%7B-%5Cepsilon_i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_i = q_i e^{-\epsilon_i}}"/>. We have </p>
<p align="center"><img alt="\displaystyle  \mathsf{E}_{\epsilon \sim \mathcal{N}(0,\delta^2)}[e^{b\epsilon}] = e^{0.5b^2 \delta^2} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BE%7D_%7B%5Cepsilon+%5Csim+%5Cmathcal%7BN%7D%280%2C%5Cdelta%5E2%29%7D%5Be%5E%7Bb%5Cepsilon%7D%5D+%3D+e%5E%7B0.5b%5E2+%5Cdelta%5E2%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{E}_{\epsilon \sim \mathcal{N}(0,\delta^2)}[e^{b\epsilon}] = e^{0.5b^2 \delta^2} "/></p>
<p>exactly, without approximation. Again the sign of <img alt="{\epsilon_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon_i}"/> does not matter. So we get </p>
<p align="center"><img alt="\displaystyle  \mathsf{E}_{\vec{\epsilon}}[p_i] = q_i e^{0.5\delta^2} &gt; q_i. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BE%7D_%7B%5Cvec%7B%5Cepsilon%7D%7D%5Bp_i%5D+%3D+q_i+e%5E%7B0.5%5Cdelta%5E2%7D+%3E+q_i.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{E}_{\vec{\epsilon}}[p_i] = q_i e^{0.5\delta^2} &gt; q_i. "/></p>
<p>But by the original fourth equation we get </p>
<p align="center"><img alt="\displaystyle  \mathsf{E}_{\vec{\epsilon}}[q_i] = p_i e^{0.5\delta^2} &gt; p_i. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BE%7D_%7B%5Cvec%7B%5Cepsilon%7D%7D%5Bq_i%5D+%3D+p_i+e%5E%7B0.5%5Cdelta%5E2%7D+%3E+p_i.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{E}_{\vec{\epsilon}}[q_i] = p_i e^{0.5\delta^2} &gt; p_i. "/></p>
<p>So we have <img alt="{\mathsf{E}[q_i] &gt; p_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BE%7D%5Bq_i%5D+%3E+p_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{E}[q_i] &gt; p_i}"/> and <img alt="{\mathsf{E}[p_i] &gt; q_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BE%7D%5Bp_i%5D+%3E+q_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{E}[p_i] &gt; q_i}"/>, with both expectations being over the same noise terms. This is like the famous Lake Wobegon <a href="https://trustedadvisor.com/trustmatters/lake-wobegon-syndrome-believing-were-all-above-average">syndrome</a>. What it indicates is the need for care in where and how to apply these error representations.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Have you seen this idea of directly testing (un)predictability in the literature? Might it improve the currently much-debated statistical tests for quantum supremacy?</p>
<p>
Which error model seems most likely to apply? Where have the paradoxes in our last section been noted?</p>
<p/><p><br/>
[some wording tweaks]</p></div>
    </content>
    <updated>2019-11-29T14:35:27Z</updated>
    <published>2019-11-29T14:35:27Z</published>
    <category term="All Posts"/>
    <category term="chess"/>
    <category term="detection"/>
    <category term="Ideas"/>
    <category term="cheating"/>
    <category term="David Spiegelhalter"/>
    <category term="predictability"/>
    <category term="predictive modeling"/>
    <category term="statistics"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-12-03T13:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://corner.mimuw.edu.pl/?p=1093</id>
    <link href="http://corner.mimuw.edu.pl/?p=1093" rel="alternate" type="text/html"/>
    <title>Call for Invited Talk Nominations: HALG 2020</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">5th Highlights of Algorithms conference (HALG 2020) ETH Zurich, June 3-5, 2020​http://2020.highlightsofalgorithms.org/ The HALG 2020 conference seeks high-quality nominations for invited talks that will highlight recent advances in algorithmic research. Similarly to previous years, there are two categories of invited talks: A. survey … <a href="http://corner.mimuw.edu.pl/?p=1093">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>

5th Highlights of Algorithms conference (HALG 2020)</p>



<p>ETH Zurich, June 3-5, 2020<br/>​<br/><a href="http://2020.highlightsofalgorithms.org/" rel="noreferrer noopener" target="_blank">http://2020.highlightsofalgorithms.org/</a></p>



<p/>



<p>The HALG 2020 conference seeks high-quality nominations for invited talks that will highlight recent advances in algorithmic research. Similarly to previous years, there are two categories of invited talks:</p>



<p>A. survey (60 minutes): a survey of an algorithmic topic that has seen exciting developments in last couple of years.</p>



<p>B. paper (30 minutes): a significant algorithmic result appearing in a paper in 2019 or later.</p>



<p>To nominate, please email <a href="mailto:halg2020.nominations@gmail.com" rel="noreferrer noopener" target="_blank">halg2020.nominations@gmail.com</a> the following information:</p>



<ol><li>Basic details: speaker name + topic (for survey talk) or paper’s title, authors, conference/arxiv + preferable speaker (for paper talk).</li><li>Brief justification: Focus on the benefits to the audience, e.g., quality of results, importance/relevance of topic, clarity of talk, speaker’s presentation skills.</li></ol>



<p>All nominations will be reviewed by the Program Committee (PC) to select speakers that will be invited to the conference.</p>



<p>Nominations deadline: December 20, 2020 (for full consideration).</p></div>
    </content>
    <updated>2019-11-29T13:30:10Z</updated>
    <published>2019-11-29T13:30:10Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>sank</name>
    </author>
    <source>
      <id>http://corner.mimuw.edu.pl</id>
      <link href="http://corner.mimuw.edu.pl/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="http://corner.mimuw.edu.pl" rel="alternate" type="text/html"/>
      <subtitle>University of Warsaw</subtitle>
      <title>Banach's Algorithmic Corner</title>
      <updated>2019-12-02T23:55:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/11/28/tenure-track-professor-at-university-of-british-columbia-apply-by-december-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/11/28/tenure-track-professor-at-university-of-british-columbia-apply-by-december-15-2019/" rel="alternate" type="text/html"/>
    <title>Tenure-Track Professor at University of British Columbia (apply by December 15, 2019)</title>
    <summary>The Department of Computer Science at the University of British Columbia is inviting applications for at least three positions at the rank of Assistant Professor. We invite applications from candidates of outstanding scientific talent in all areas of computer science. Appointment at a higher rank will be considered for an applicant of exceptional qualifications. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at the University of British Columbia is inviting applications for at least three positions at the rank of Assistant Professor. We invite applications from candidates of outstanding scientific talent in all areas of computer science. Appointment at a higher rank will be considered for an applicant of exceptional qualifications.</p>
<p>Website: <a href="https://www.cs.ubc.ca/our-department/employment/faculty-sessional-positions/tenure-track-faculty-positions-research-stre-0">https://www.cs.ubc.ca/our-department/employment/faculty-sessional-positions/tenure-track-faculty-positions-research-stre-0</a><br/>
Email: research-recruiting-chair@cs.ubc.ca</p></div>
    </content>
    <updated>2019-11-28T23:16:33Z</updated>
    <published>2019-11-28T23:16:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-12-03T13:20:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/172</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/172" rel="alternate" type="text/html"/>
    <title>TR19-172 |  Schur Polynomials do not have small formulas if the Determinant doesn&amp;#39;t!  | 

	Chandra Kanta Mohapatra, 

	Mrinal Kumar, 

	Nutan Limaye, 

	Srikanth Srinivasan, 

	Prasad Chaugule, 

	Adrian She</title>
    <summary>Schur Polynomials are families of symmetric polynomials that have been
classically studied in Combinatorics and Algebra alike. They play a central
role in the study of Symmetric functions, in Representation theory [Sta99], in
Schubert calculus [LM10] as well as in Enumerative combinatorics [Gas96, Sta84,
Sta99]. In recent years, they have also shown up in various incarnations in
Computer Science, e.g, Quantum computation [HRTS00, OW15] and Geometric
complexity theory [IP17].
  However, unlike some other families of symmetric polynomials like the
Elementary Symmetric polynomials, the Power Symmetric polynomials and the
Complete Homogeneous Symmetric polynomials, the computational complexity of
syntactically computing Schur polynomials has not been studied much. In
particular, it is not known whether Schur polynomials can be computed
efficiently by algebraic formulas. In this work, we address this question, and
show that unless \emph{every} polynomial with a small algebraic branching
program (ABP) has a small algebraic formula, there are Schur polynomials that
cannot be computed by algebraic formula of polynomial size. In other words,
unless the algebraic complexity class $\mathrm{VBP}$ is equal to the complexity
class $\mathrm{VF}$, there exist Schur polynomials which do not have polynomial
size algebraic formulas.
  As a consequence of our proof, we also show that computing the determinant of
certain \emph{generalized} Vandermonde matrices is essentially as hard as
computing the general symbolic determinant. To the best of our knowledge, these
are one of the first hardness results of this kind for families of polynomials
which are not \emph{multilinear}. A key ingredient of our proof is the study of
composition of \emph{well behaved} algebraically independent polynomials with a homogeneous polynomial, and might be of independent interest.</summary>
    <updated>2019-11-28T06:40:42Z</updated>
    <published>2019-11-28T06:40:42Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-12-03T13:20:26Z</updated>
    </source>
  </entry>
</feed>
