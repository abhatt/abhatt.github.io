<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-11-15T09:39:32Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-378272747883656707</id>
    <link href="http://blog.computationalcomplexity.org/feeds/378272747883656707/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/11/when-did-computer-science-theory-get-so.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/378272747883656707" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/378272747883656707" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/11/when-did-computer-science-theory-get-so.html" rel="alternate" type="text/html"/>
    <title>When did Computer Science Theory Get so Hard?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> I posted on <a href="https://blog.computationalcomplexity.org/2019/07/when-did-math-get-so-hard.html">When did Math get so hard?</a> a commenter pointed out that one can also ask </p><p><br/></p><p><i>When did Computer Science Theory Get so Hard?</i></p><p>For the Math-question I could only speculate. For CS- I WAS THERE! When I was in Grad School one could learn all of Complexity theory in a year-long course (a hard one, but still!). The main tools were logic and combinatorics. No Fourier Transforms over finite fields. I am NOT going to say</p><p><i>Those were the good old days.</i></p><p>I will say that it was easier to make a contribution without knowing much. Oddly enough, it is MORE common for ugrads and grad students to publish NOW then it was THEN, so that may be a pair of ducks.</p><p><b>Random Thoughts on This Question</b></p><p>1) The Graph Minor Theorem was when P lost its innocence. Before the GMT most (though not all)  problems in P had easy-to-understand  algorithms using algorithmic paradigms (e.g., Dynamic  Programming) and maybe some combinatorics. Computational Number Theory used.... Number Theory (duh), but I don't think it was hard number theory. One exception was Miller's Primality test which needed to assume the Extended Riemann Hypothesis- but you didn't have to understand ERH to use it. </p><p>1.5) GMT again. This did not only give hard-deep-math algorithms to get problems in P. It  also pointed to  how hard proving P NE NP would be--- to rule out something like a GMT-type result to get SAT in P seems rather hard. </p><p>2) Oracle Constructions were fairly easy diagonalizations. It was bummed out that I never had to use an infinite injury priority argument. That is, I knew some complicated recursion theory, but it was never used. </p><p>2.5) Oracles again. Dana Angluin had a paper which used some complicated combinatorics to construct an oracle, see <a href="https://www.sciencedirect.com/science/article/pii/0304397580900274?via%3Dihub">here</a>. Later Andy Yao showed that there is an oracle A such that  PH^A NE  PSPACE^A. You might know that result better as</p><p><i>Constant depth circuits for parity must have exponential size. </i></p><p>I think we now care about circuits more than oracles, see my post <a href="https://blog.computationalcomplexity.org/2015/04/the-new-oracle-result-new-circuit.html">here</a> about that issue. Anyway, oracle results since then have used hard combinatorial and other math arguments. </p><p>3) The PCP result was a leap forward for difficulty. I don't know which paper to pick as THE Leap since there were several. And papers after that were also rather difficult.  </p><p>4) I had a blog post <a href="https://blog.computationalcomplexity.org/2021/04/do-any-np-reductions-use-deep.html#comment-form">here</a> where I asked if REDUCTIONS ever use hard math. Some of the comments are relevant here:</p><p>Stella Biderman: The deepest part of the original PCP theorem is the invention of the VC paradigm in the 1990's.</p><p>Eldar: Fourier Theory was introduced to CS with Hastad's Optimal Approximation results. Today it might not be considered deep, but I recall when it was.</p><p>Also there are Algebraic Geometry codes which use downright arcane mathematics...</p><p>Hermann Gruber refers to Comp Topology and Comp Geometry and points to the result that 3-manifold knot genus is NP-complete, see <a href="https://dl.acm.org/doi/10.1145/509907.510016">here</a>.</p><p>Anonymous (they leave many comments) points to the deep math reductions in arithmetic versions of P/NP classes, and Mulmuley's work (Geometric Complexity Theory).</p><p>Timothy Chow points out that `deep' could mean several things and points to a math overflow post on the issue of depth, <a href="https://mathoverflow.net/questions/139607/what-are-some-deep-theorems-and-why-are-they-considered-deep">here</a>.</p><p>Marzio De Biasi points out that even back in 1978 there was a poly reduction that required a good amount of number theory: the NPC of the Diophantine binary quad equation</p><p>ax^2 + by + c = 0 </p><p>by Manders and Adelman, see <a href="https://www.sciencedirect.com/science/article/pii/0022000078900442?via%3Dihub">here</a>.</p><p>(Bill Comment) I tend to think this is an outlier- for the most part, CS theory back in the 1970's did not hard math. </p><p>4) Private Info Retrieval (PIR). k databases each have the same n-bit string and cannot talk to each other. a server wants the ith bit and (in the info-theoretic case) wants the DBs to know NOTHING about the question i. </p><p>Easy results (to understand) 2-server, n^{1/3}. <a href="http://www.cs.umd.edu/~gasarch/TOPICS/pir/first.pdf">here</a>.</p><p>Hard results: 2-server n^{O(\sqrt{loglogn/log n)},  <a href="https://www.cs.princeton.edu/~zdvir/papers/DvirGopi14.pdf">here</a>.</p><p>(I have a website on PIR, not maintained,  <a href="http://www.cs.umd.edu/~gasarch/TOPICS/pir/pir.html">here</a>.)</p><p>5) Babai's algorithm for GI in quasi-poly time used hard math. </p><p>6) If I knew more CS theory I am sure I would have more papers listed.</p><p>But now its your turn: </p><p>When did you realize Gee, <b>CS theory is harder than (a) you thought, (b) it used to be.</b></p><p><b><br/></b></p><p><br/></p><p><br/></p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2021-11-15T03:50:00Z</updated>
    <published>2021-11-15T03:50:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-11-15T09:33:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/15/faculty-at-northwestern-university-apply-by-december-10-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/15/faculty-at-northwestern-university-apply-by-december-10-2021/" rel="alternate" type="text/html"/>
    <title>Faculty at Northwestern University (apply by December 10, 2021)</title>
    <summary>We invite candidates to apply for new positions as Assistant, Associate and Full Professor of Computer Science. We are interested in applications from outstanding candidates in all areas of Computer Science. See the website for cross-cutting areas of interest. Website: https://www.mccormick.northwestern.edu/computer-science/careers/ Email: nu.cstheory@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We invite candidates to apply for new positions as Assistant, Associate and Full Professor of Computer Science. We are interested in applications from outstanding candidates in all areas of Computer Science. See the website for cross-cutting areas of interest.</p>
<p>Website: <a href="https://www.mccormick.northwestern.edu/computer-science/careers/">https://www.mccormick.northwestern.edu/computer-science/careers/</a><br/>
Email: nu.cstheory@gmail.com</p></div>
    </content>
    <updated>2021-11-15T01:34:05Z</updated>
    <published>2021-11-15T01:34:05Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-15T09:37:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/14/postdoc-at-university-of-waterloo-apply-by-december-31-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/14/postdoc-at-university-of-waterloo-apply-by-december-31-2021/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Waterloo (apply by December 31, 2021)</title>
    <summary>The Algorithms &amp; Complexity group at the University of Waterloo is offering postdoctoral positions starting in the Fall of 2022. We seek candidates from all areas of theoretical computer science. Interested applicants should have their CV, research statement, and three recommendation letters emailed to theory.waterloo@gmail.com. Applications are due December 31st. Website: https://algcomp.uwaterloo.ca/positions/ Email: theory.waterloo@gmail.com</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Algorithms &amp; Complexity group at the University of Waterloo is offering postdoctoral positions starting in the Fall of 2022. We seek candidates from all areas of theoretical computer science.</p>
<p>Interested applicants should have their CV, research statement, and three recommendation letters emailed to theory.waterloo@gmail.com. Applications are due December 31st.</p>
<p>Website: <a href="https://algcomp.uwaterloo.ca/positions/">https://algcomp.uwaterloo.ca/positions/</a><br/>
Email: theory.waterloo@gmail.com</p></div>
    </content>
    <updated>2021-11-14T20:59:51Z</updated>
    <published>2021-11-14T20:59:51Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-15T09:37:52Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/11/14/random-independent-sets</id>
    <link href="https://11011110.github.io/blog/2021/11/14/random-independent-sets.html" rel="alternate" type="text/html"/>
    <title>Random independent sets in bounded-treewidth graphs</title>
    <summary>This week my student Daniel Frishberg posted our new preprint “Rapid mixing of the hardcore Glauber dynamics and other Markov chains in bounded-treewidth graphs”, arXiv:2111.03898. Despite the somewhat-technical title and content, it’s on an easy-to-explain problem, of generating random combinatorial objects (like independent sets in graphs) using random walks. Start with an undirected graph and an empty subset of its vertices, and then repeatedly choose a random vertex, flipping whether it is in or out of the subset whenever the resulting subset remains independent. How many of these steps does it take until the resulting random distribution on independent sets is nearly uniform?</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This week my student Daniel Frishberg posted our new preprint “Rapid mixing of the hardcore Glauber dynamics and other Markov chains in bounded-treewidth graphs”, <a href="https://arxiv.org/abs/2111.03898">arXiv:2111.03898</a>. Despite the somewhat-technical title and content, it’s on an easy-to-explain problem, of generating random combinatorial objects (like independent sets in graphs) using random walks. Start with an undirected graph and an empty subset of its vertices, and then repeatedly choose a random vertex, flipping whether it is in or out of the subset whenever the resulting subset remains independent. How many of these steps does it take until the resulting random distribution on independent sets is nearly uniform?</p>

<p>In general, this can take exponentially many steps, but our paper proves that in graphs of bounded <a href="https://en.wikipedia.org/wiki/Treewidth">treewidth</a> it is only polynomial. Our proof’s exponent depends on the treewidth, but maybe a better proof can get the dependence on treewidth out of the exponent and into the constant factor of the polynomial instead. However, if all you want to do is generate a random independent sets, this is not the right way to do it. The point of the paper is less about fast algorithms and more about the connectivity of the space of independent sets. So if you do want a fast algorithm for random generation, what should you do?</p>

<p>This is, unfortunately, an area where some care is required and much of the literature does not take the required care. Problematic issues include:</p>

<ul>
  <li>
    <p>What is the model of computation for arithmetic operations? Much of the literature for the design and analysis of graph algorithms assumes without much attention that all arithmetic operations take unit time. This is a reasonable assumption for small numbers (of at most polynomial magnitude), as occur in many algorithms including the random walk above. In those cases it is a close match to the kind of operation that can be done in a single instruction on a modern CPU. It is not a reasonable assumption for counting algorithms dealing with numbers of exponential magnitude. Counting is an important subproblem for exact random generation, so we need large numbers. Typically, the number of independent sets is linear in the input size, the number of bits required to store this number is linear, and the amount of time needed to perform a single operation on a number this large should again be assumed to involve a bignum-package subroutine. The slow steps are multiplications, which can by <a href="https://www.jstor.org/stable/10.4007/annals.2021.193.2.4">recent results of Harvey and van der Hoeven</a> be assumed to take \(O(n\log n)\) time.</p>
  </li>
  <li>
    <p>What is the model for generating random numbers? If random numbers are generated as bits, this only allows the direct generation of random choices with probabilities that are <a href="https://en.wikipedia.org/wiki/Dyadic_rational">dyadic rational</a>. For independent sets, we need other probabilities. <a href="https://en.wikipedia.org/wiki/Rejection_sampling">Rejection sampling</a> leads to an algorithm whose running time is itself a random variable, so we need to use expected time or high-probability bounds instead of worst-case time analysis.</p>
  </li>
  <li>
    <p>How is the input presented? For the random-walk method, it is just a graph, but for other algorithms taking advantage of low treewidth we need a good <a href="https://en.wikipedia.org/wiki/Tree_decomposition">tree decomposition</a>, and finding one is nontrivial. We should either state explicitly that a tree decomposition is given and that its width rather than the graph width controls the algorithm’s runtime, or factor in the time to find a decomposition and the width of decomposition that we find.</p>
  </li>
</ul>

<p>With that all said, how might we go about computing a random independent set for a given \(n\)-vertex graph of treewidth \(w\), achieving the best theoretical performance?</p>

<p>First, we should find an approximate tree decomposition. There are many known algorithms for this problem, but I think the right choice is the one from the recent paper “An improvement of Reed’s treewidth approximation”, Belbasi and Fürer, WALCOM 2021, <a href="https://arxiv.org/abs/2010.03105">arXiv:2010.03105</a>. It finds a tree decomposition of width at most \(5w\), in time \(O(2^{8.8w}n\log n)\). There are other algorithms with a linear dependence on \(n\), but much worse dependence on \(w\), and the \(n\log n\) part of the bound will be dominated by later steps. We can also bootstrap this decomposition, using dynamic programming on it to find a better decomposition, but I think this is too expensive for the savings it produces.</p>

<p>Second, we should count independent sets. Root the tree decomposition, so that we can talk about the subtree descending from any bag and the subgraph of the given graph that it corresponds to. Then for each bag of the decomposition (in bottom-up order), and each independent subset of the bag, we want to count the number of independent sets in the corresponding subgraph that intersect the bag in the given subset. These independent sets are formed by combining choices of independent sets in child nodes. Therefore, we need to find the numbers of independent sets in each child node that are consistent with the choice of subset at the parent, and multiply them together. Each subset of a bag contributes to exactly one such computation at its parent, so the total number of arithmetic operations for this computation is the product of the number of bags and the number of subsets per bag. With bignum arithmetic, the total time for computing all of these counts is \(O(2^{5w}n^2\log n)\). Our new preprint cites a paper for this subproblem that isn’t sufficiently careful about bignum arithmetic, but still somehow ends up with a slower cubic total time bound; I think they’re just being sloppy and overcounting somehow.</p>

<p>Third, we can then reverse the counting process and step downward through the tree decomposition choosing how the random independent set intersects each bag. When we do this for a bag, we already know the intersection of the independent set with the parent bag. Therefore, all we have to do is choose among the subsets of the child bag that are consistent with that already-made choice, using probabilities that are proportional to the numbers of independent sets that can be formed for each consistent subset. We know these numbers because we already computed them in the second stage. So it’s just a single random choice per bag, which (because it involves bignum probabilities that are not dyadic rational) can reasonably be assumed to take a random amount of time whose expectation is linear. For the overall algorithm, the total expected time is \(O(n^2)\). Also, this stage of the algorithm can be repeated over and over, generating new random independent sets, without having to generate new tree decompositions or new counts.</p>

<p>Putting it all together, it appears that the total time for randomly generating independent sets, using dynamic programming on the tree decomposition to count these sets, and assuming fast bignum arithmetic, is \(O(2^{O(w)}n^2\log n)\) for the preprocessing stages of the algorithm, and then \(O(n^2)\) for each successive generated set.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/107278583702646630">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2021-11-14T16:41:00Z</updated>
    <published>2021-11-14T16:41:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-11-15T01:55:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/14/postdoc-at-princeton-university-apply-by-december-1-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/14/postdoc-at-princeton-university-apply-by-december-1-2021/" rel="alternate" type="text/html"/>
    <title>Postdoc at Princeton University  (apply by December 1, 2021)</title>
    <summary>Princeton ORFE invites applications for a postdoctoral position, starting June 1, 2022, in deep learning theory supported through an NSF Grant of ORFE Assistant Professor Boris Hanin. The position is for one year with the possibility of reappointment for up to two years additional years based on satisfactory performance and availability of funding. Website: https://puwebp.princeton.edu/AcadHire/apply/application.xhtml?listingId=22221 […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Princeton ORFE invites applications for a postdoctoral position, starting June 1, 2022, in deep learning theory supported through an NSF Grant of ORFE Assistant Professor Boris Hanin. The position is for one year with the possibility of reappointment for up to two years additional years based on satisfactory performance and availability of funding.</p>
<p>Website: <a href="https://puwebp.princeton.edu/AcadHire/apply/application.xhtml?listingId=22221">https://puwebp.princeton.edu/AcadHire/apply/application.xhtml?listingId=22221</a><br/>
Email: Bhanin@princeton.edu</p></div>
    </content>
    <updated>2021-11-14T13:07:41Z</updated>
    <published>2021-11-14T13:07:41Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-15T09:37:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=956</id>
    <link href="https://emanueleviola.wordpress.com/2021/11/14/i-doubt-that-there-will-be-eight-i-highly-doubt-there-will-be-eight/" rel="alternate" type="text/html"/>
    <title>“I doubt that there will be eight, I highly doubt there will be eight.”</title>
    <summary>Says campaign strategist at 1:13 on this clip from almost exactly 3 years ago. For background readers can look at this tag. Where are we today? (Official communication.) Union Twist, 1158 Beacon Street in Newton Centre/Four Corners, has been unanimously approved by the City Council for its Special Permit. Union Twist plans to demolish the […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://www.nbcboston.com/news/local/newton-voters-reject-measures-to-ban-or-limit-marijuana-shops/104470/">Says campaign strategist at 1:13 on this clip from almost exactly 3 years ago.</a></p>



<p>For background readers can look <a href="https://emanueleviola.wordpress.com/tag/marijuana/">at this tag</a>.</p>



<p>Where are we today?  (Official communication.)</p>



<ul><li>Union Twist, 1158 Beacon Street in Newton Centre/Four Corners, has been unanimously approved by the City Council for its Special Permit. Union Twist plans to demolish the current building on the site consisting of a dry cleaner and restaurant and build a new 2,300-square foot, one story retail building with 22 on-site parking spaces. For at least the first six months of operation, there will be an appointment only requirement for customers at the store. As their Special Permit has been approved, they can move forward with their state Cannabis Control Commission (CCC) licensing approval process.</li></ul>



<ul><li>Garden Remedies, Newton’s first adult-use retail marijuana store, opened at 697 Washington Street in Newtonville more than two years ago in May 2019. Since opening, Garden Remedies has sold to customers by appointment only. The request from Garden Remedies to amend its current Special Permit to remove the appointment only condition for their retail shop was approved by the City Council Land Use Committee. (The vote was 5-0, with three abstentions.) The full City Council will vote on lifting the appointment only condition at their meeting this Monday, Nov. 15.</li></ul>



<ul><li>Redi, Newton’s second adult-use retail marijuana establishment (formerly known as Cypress Tree) opened in July 2021 at 24 Eliot Street at the intersection with Boylston Street/Route 9 in Upper Falls. (It was (formerly known as Cypress Tree.) The Special Permit approved by the City Council requires that Redi’s retail customers must have an appointment to shop or pick-up products for at least the first six months of operation. </li></ul>



<ul><li>Ascend, 1089 Washington Street/58 Cross Street just outside West Newton Square, has a signed provisional HCA and an approved Special Permit. Construction is nearing completion and they are awaiting licensing approval by the CCC to open.</li></ul>



<ul><li>MedMen, 232 Boylston Street/ Rte. 9 in Chestnut Hill (at the former Shreve, Crump &amp; Low location), has a signed provisional Host Community Agreement (HCA) and an approved Special Permit. They are both awaiting licensing approval by the CCC to open as well as a building permit from the City of Newton to begin work on the building.</li></ul>



<ul><li>Green Lady, 740 Beacon Street in Newton Centre, a woman and minority owned business, has a signed provisional HCA and the City Council Land Use Committee is currently hearing its Special Permit application. If their Special Permit is approved, they can then move forward with their CCC licensing approval process </li></ul>



<ul><li>Verilife, 131 Rumford Avenue in Auburndale, has a signed provisional HCA and the City Council Land Use Committee is currently hearing its Special Permit application. If their Special Permit is approved, they can then move forward with their CCC licensing approval process.</li></ul>



<ul><li>Nuestra, 1185 Chestnut Street in Newton Upper Falls, has a signed provisional HCA. Nuestra is a Cannabis Control Commission certified Economic Empowerment Applicant. They have not yet started the City Council Special Permit approval process which they need to do before moving forward in the state licensing approval process.</li></ul>



<p/></div>
    </content>
    <updated>2021-11-14T10:11:08Z</updated>
    <published>2021-11-14T10:11:08Z</published>
    <category term="Uncategorized"/>
    <category term="marijuana"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2021-11-15T09:38:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/14/tenure-track-assistant-professor-position-in-security-and-privacy-at-graz-university-of-technology-apply-by-november-30-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/14/tenure-track-assistant-professor-position-in-security-and-privacy-at-graz-university-of-technology-apply-by-november-30-2021/" rel="alternate" type="text/html"/>
    <title>Tenure-Track Assistant Professor Position in Security and Privacy at Graz University of Technology (apply by November 30, 2021)</title>
    <summary>The department for computer science and biomedical engineering at Graz University of Technology invites applications for the position of a tenure track professor of Security &amp; Privacy. The position will be part of a IAIK, which provides a research environment with more than 60 researchers in Security &amp; Privacy. Website: https://www.tugraz.at/fakultaeten/csbme/news/jobs-grants-calls/tenure-track-professor-in-security-and-privacy/ Email: Stefan.Mangard@iaik.tugraz.at</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The department for computer science and biomedical engineering at Graz University of Technology invites applications for the position of a tenure track professor of Security &amp; Privacy. The position will be part of a IAIK, which provides a research environment with more than 60 researchers in Security &amp; Privacy.</p>
<p>Website: <a href="https://www.tugraz.at/fakultaeten/csbme/news/jobs-grants-calls/tenure-track-professor-in-security-and-privacy/">https://www.tugraz.at/fakultaeten/csbme/news/jobs-grants-calls/tenure-track-professor-in-security-and-privacy/</a><br/>
Email: Stefan.Mangard@iaik.tugraz.at</p></div>
    </content>
    <updated>2021-11-14T06:14:43Z</updated>
    <published>2021-11-14T06:14:43Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-15T09:37:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/14/tenure-track-faculty-at-cuny-baruch-college-apply-by-december-13-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/14/tenure-track-faculty-at-cuny-baruch-college-apply-by-december-13-2021/" rel="alternate" type="text/html"/>
    <title>Tenure-Track Faculty  at CUNY: Baruch College (apply by December 13, 2021)</title>
    <summary>We are forming a computer science program at CUNY’s Baruch College. Joining at the beginning of this process will give you a chance to influence how the program will look like: the research and teaching directions, the type of faculty that will be hired, and so on. We hope to have a diverse group of […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are forming a computer science program at CUNY’s Baruch College. Joining at the beginning of this process will give you a chance to influence how the program will look like: the research and teaching directions, the type of faculty that will be hired, and so on. We hope to have a diverse group of computer scientists. Women and underrepresented minorities are encouraged to apply!</p>
<p>Website: <a href="https://www.mathjobs.org/jobs/list/18748">https://www.mathjobs.org/jobs/list/18748</a><br/>
Email: adam.sheffer@baruch.cuny.edu</p></div>
    </content>
    <updated>2021-11-14T02:52:39Z</updated>
    <published>2021-11-14T02:52:39Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-15T09:37:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/158</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/158" rel="alternate" type="text/html"/>
    <title>TR21-158 |  Extremely Deep Proofs | 

	Noah Fleming, 

	Toniann Pitassi, 

	Robert Robere</title>
    <summary>We further the study of supercritical tradeoffs in proof and circuit complexity, which is a type of tradeoff between complexity parameters where restricting one complexity parameter forces another to exceed its worst-case upper bound. In particular, we prove a new family of supercritical tradeoffs between depth and size for Resolution, Res(k), and Cutting Planes proofs. For each of these proof systems we construct, for each c &lt;= n^{1-epsilon}, a formula with n^{O(c)} clauses and n variables that has a proof of size n^{O(c)} but in which any proof of size no more than roughly exponential in n^{1-epsilon}/c must necessarily have depth approximately n^c. By setting c = o(n^{1-epsilon}) we therefore obtain exponential lower bounds on proof depth; this far exceeds the trivial worst-case upper bound of n. In doing so we give a simplified proof of a supercritical depth/width tradeoff for tree-like Resolution from [Razborov16]. Finally, we outline several conjectures that would imply similar supercritical tradeoffs between size and depth in circuit complexity via lifting theorems.</summary>
    <updated>2021-11-14T02:27:35Z</updated>
    <published>2021-11-14T02:27:35Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-11-15T09:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/157</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/157" rel="alternate" type="text/html"/>
    <title>TR21-157 |  The Complexity of Average-Case Dynamic Subgraph Counting | 

	Monika Henzinger, 

	Andrea Lincoln, 

	Barna Saha</title>
    <summary>Statistics of small subgraph counts such as triangles, four-cycles, and $s$-$t$ paths of short lengths reveal important structural properties of the underlying graph. These problems have been widely studied in social network analysis. In most relevant applications, the graphs are not only massive but also change dynamically over time. Most of these problems become hard in the dynamic setting when considering the worst case. In this paper, we ask whether the question of small subgraph counting over dynamic graphs is hard also in the average case.

We consider the simplest possible average case model where the updates follow an \ErdRen~graph: each update selects a pair of vertices $(u,v)$ uniformly at random and flips the existence of the edge $(u,v)$. 
We develop new lower bounds and matching algorithms in this model for counting four-cycles, counting triangles through a specified point $s$, or a random queried point, and $st$ paths of length $3$, $4$ and $5$. Our results indicate while computing $st$ paths of length $3$, and $4$ are easy in the average case with $O(1)$ update time (note that they are hard in the worst case), it becomes hard when considering $st$ paths of length $5$.

 We introduce new techniques which allow us to get average-case hardness for these graph problems from the worst-case hardness of the Online Matrix vector problem (OMv). Our techniques rely on recent advances in fine-grained average-case complexity. Our techniques advance this literature, giving the ability to prove new lower bounds on average-case dynamic algorithms.</summary>
    <updated>2021-11-14T02:26:23Z</updated>
    <published>2021-11-14T02:26:23Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-11-15T09:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/156</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/156" rel="alternate" type="text/html"/>
    <title>TR21-156 |  Applications of Random Algebraic Constructions to Hardness of Approximation | 

	Boris Bukh, 

	Karthik  C. S., 

	Bhargav Narayanan</title>
    <summary>In this paper, we show how one may (efficiently) construct two types of extremal combinatorial objects whose existence was previously conjectural.
   
(*) Panchromatic Graphs: For fixed integer k, a k-panchromatic graph is, roughly speaking, a balanced bipartite graph with one partition class equipartitioned into k colour classes in which the common neighbourhoods of panchromatic k-sets of vertices are much larger than those of k-sets that repeat a colour. The question of their existence was raised by Karthik and Manurangsi [Combinatorica 2020].

(*) Threshold Graphs: For fixed integer k, a k-threshold graph is, roughly speaking, a balanced bipartite graph in which the common neighbourhoods of k-sets of vertices on one side are much larger than those of (k+1)-sets. The question of their existence was raised by Lin [JACM 2018].

Concretely, we provide probability distributions over graphs from which we can efficiently sample these objects in near linear time. These probability distributions are defined via varieties cut out by (carefully chosen) random polynomials, and the analysis of these constructions relies on machinery from algebraic geometry (such as the Lang–Weil estimate, for example). The technical tools developed to accomplish this might be of independent interest.

As applications of our constructions, we show the following conditional time lower bounds on the parameterized set intersection problem where, given a collection of n sets over universe [n] and a parameter k, the goal is to find k sets with the largest intersection.

(*) Assuming ETH, for any computable function F, no $n^{o(k)}$-time algorithm can approximate the parameterized set intersection problem up to factor F(k). This improves considerably on the previously best-known result under ETH due to Lin [JACM 2018], who ruled out any $n^{o(\sqrt{k})}$ time approximation algorithm for this problem.

(*) Assuming SETH, for every $\varepsilon&gt;0$ and any computable function F, no $n^{k-\varepsilon}$-time algorithm can approximate the parameterized set intersection problem up to factor F(k). No result of comparable strength was previously known under SETH, even for solving this problem exactly.</summary>
    <updated>2021-11-14T02:25:04Z</updated>
    <published>2021-11-14T02:25:04Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-11-15T09:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.06395</id>
    <link href="http://arxiv.org/abs/2111.06395" rel="alternate" type="text/html"/>
    <title>Kalman Filtering with Adversarial Corruptions</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Sitan.html">Sitan Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koehler:Frederic.html">Frederic Koehler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moitra:Ankur.html">Ankur Moitra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yau:Morris.html">Morris Yau</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.06395">PDF</a><br/><b>Abstract: </b>Here we revisit the classic problem of linear quadratic estimation, i.e.
estimating the trajectory of a linear dynamical system from noisy measurements.
The celebrated Kalman filter gives an optimal estimator when the measurement
noise is Gaussian, but is widely known to break down when one deviates from
this assumption, e.g. when the noise is heavy-tailed. Many ad hoc heuristics
have been employed in practice for dealing with outliers. In a pioneering work,
Schick and Mitter gave provable guarantees when the measurement noise is a
known infinitesimal perturbation of a Gaussian and raised the important
question of whether one can get similar guarantees for large and unknown
perturbations.
</p>
<p>In this work we give a truly robust filter: we give the first strong provable
guarantees for linear quadratic estimation when even a constant fraction of
measurements have been adversarially corrupted. This framework can model
heavy-tailed and even non-stationary noise processes. Our algorithm robustifies
the Kalman filter in the sense that it competes with the optimal algorithm that
knows the locations of the corruptions. Our work is in a challenging Bayesian
setting where the number of measurements scales with the complexity of what we
need to estimate. Moreover, in linear dynamical systems past information decays
over time. We develop a suite of new techniques to robustly extract information
across different time steps and over varying time scales.
</p></div>
    </summary>
    <updated>2021-11-14T23:05:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.06362</id>
    <link href="http://arxiv.org/abs/2111.06362" rel="alternate" type="text/html"/>
    <title>Non-Uniform $k$-Center and Greedy Clustering</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Tanmay Inamdar, Kasturi Varadarajan <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.06362">PDF</a><br/><b>Abstract: </b>The Non-Uniform $k$-Center (NU$k$C) is a generalization of the famous
$k$-center clustering problem, where we want to cover the given set of points
in a metric space, using the specified number of balls of the specified radii.
In the $t$-NU$k$C, we assume that the number of distinct radii is equal to $t$,
and we are allowed to use $k_i$ balls of radius $r_i$, for $1 \le i \le t$.
This problem was introduced by Chakrabarty et al. [ACM Trans.\ Alg.\
16(4):46:1-46:19], who showed that a constant approximation for $t$-NU$k$C is
not possible if $t$ is unbounded. On the other hand, they gave a bicriteria
approximation that violates the number of allowed balls as well as the given
radii by a constant factor. They also conjectured that a constant approximation
for $t$-NU$k$C should be possible if $t$ is a fixed constant. Since then, there
has been steady progress towards resolving this conjecture -- currently, a
constant approximation for $3$-NU$k$C is known via the results of Chakrabarty
and Negahbani [IPCO 2021], and Jia et al. [To appear in SOSA 2022]. We push the
horizon by giving an $O(1)$-approximation for the Non-Uniform $k$-Center for
$4$ distinct types of radii. Our result is obtained via a novel combination of
tools and techniques from the $k$-center literature, which also demonstrates
that the different generalizations of $k$-center involving non-uniform radii,
and multiple coverage constraints (i.e., colorful $k$-center), are closely
interlinked with each other. We hope that our ideas will contribute towards a
deeper understanding of the $t$-NU$k$C problem, eventually bringing us closer
to the resolution of the CGK conjecture.
</p></div>
    </summary>
    <updated>2021-11-14T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.06348</id>
    <link href="http://arxiv.org/abs/2111.06348" rel="alternate" type="text/html"/>
    <title>Enhanced Formulation for Guillotine 2D Cutting Problems</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Becker:Henrique.html">Henrique Becker</a>, Olinto Araujo, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Buriol:Luciana_S=.html">Luciana S. Buriol</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.06348">PDF</a><br/><b>Abstract: </b>We advance the state of the art in Mixed-Integer Linear Programming (MILP)
formulations for Guillotine 2D Cutting Problems by (i) adapting a previously
known reduction to our preprocessing phase and by (ii) enhancing a previous
formulation by cutting down its size and symmetries. Our focus is the
Guillotine 2D Knapsack Problem with orthogonal and unrestricted cuts,
constrained demand, unlimited stages, and no rotation -- however, the
formulation may be adapted to many related problems. The code is available.
Concerning the set of 59 instances used to benchmark the original formulation,
and summing the statistics for all models generated, the enhanced formulation
has only a small fraction of the variables and constraints of the original
model (respectively, 3.07% and 8.35%). The enhanced formulation also takes
about 4 hours to solve all instances while the original formulation takes 12
hours to solve 53 of them (the other six runs hit a three-hour time limit
each). We integrate, to both formulations, a pricing framework proposed for the
original formulation; the enhanced formulation keeps a significant advantage in
this situation. Finally, in a recently proposed set of 80 harder instances, the
enhanced formulation (with and without the pricing framework) found: 22 optimal
solutions for the unrestricted problem (5 already known, 17 new); 22 optimal
solutions for the restricted problem (all are new and they are not the same 22
of the optimal unrestricted solutions); better lower bounds for 25 instances;
better upper bounds for 58 instances.
</p></div>
    </summary>
    <updated>2021-11-14T23:05:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.06338</id>
    <link href="http://arxiv.org/abs/2111.06338" rel="alternate" type="text/html"/>
    <title>On the parameterized complexity of Compact Set Packing</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gadekar:Ameet.html">Ameet Gadekar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.06338">PDF</a><br/><b>Abstract: </b>The Set Packing problem is, given a collection of sets $\mathcal{S}$ over a
ground set $\mathcal{U}$, to find a maximum collection of sets that are
pairwise disjoint. The problem is among the most fundamental NP-hard
optimization problems that have been studied extensively in various
computational regimes. The focus of this work is on parameterized complexity,
Parameterized Set Packing (PSP): Given $r \in {\mathbb N}$, is there a
collection $ \mathcal{S}' \subseteq \mathcal{S}: |\mathcal{S}'| = r$ such that
the sets in $\mathcal{S}'$ are pairwise disjoint? Unfortunately, the problem is
not fixed parameter tractable unless $\mathsf{W[1] = FPT}$, and, in fact, an
"enumeration" running time of $|\mathcal{S}|^{\Omega(r)}$ is required unless
the exponential time hypothesis (ETH) fails. This paper is a quest for
tractable instances of Set Packing from parameterized complexity perspectives.
We say that the input $(\mathcal{U},\mathcal{S})$ is "compact" if
$|\mathcal{U}| = f(r)\cdot\Theta(\textsf{poly}( \log |\mathcal{S}|))$, for some
$f(r) \ge r$. In the Compact Set Packing problem, we are given a compact
instance of PSP. In this direction, we present a "dichotomy" result of PSP:
When $|\mathcal{U}| = f(r)\cdot o(\log |\mathcal{S}|)$, PSP is in
$\textsf{FPT}$, while for $|\mathcal{U}| = r\cdot\Theta(\log (|\mathcal{S}|))$,
the problem is $W[1]$-hard; moreover, assuming ETH, Compact PSP does not even
admit $|\mathcal{S}|^{o(r/\log r)}$ time algorithm.
</p></div>
    </summary>
    <updated>2021-11-14T23:00:15Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.06308</id>
    <link href="http://arxiv.org/abs/2111.06308" rel="alternate" type="text/html"/>
    <title>Online Discrepancy with Recourse for Vectors and Graphs</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Anupam.html">Anupam Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gurunathan:Vijaykrishna.html">Vijaykrishna Gurunathan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krishnaswamy:Ravishankar.html">Ravishankar Krishnaswamy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Amit.html">Amit Kumar</a>, Sahil Singla <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.06308">PDF</a><br/><b>Abstract: </b>The vector-balancing problem is a fundamental problem in discrepancy theory:
given T vectors in $[-1,1]^n$, find a signing $\sigma(a) \in \{\pm 1\}$ of each
vector $a$ to minimize the discrepancy $\| \sum_{a} \sigma(a) \cdot a
\|_{\infty}$. This problem has been extensively studied in the static/offline
setting. In this paper we initiate its study in the fully-dynamic setting with
recourse: the algorithm sees a stream of T insertions and deletions of vectors,
and at each time must maintain a low-discrepancy signing, while also minimizing
the amortized recourse (the number of times any vector changes its sign) per
update.
</p>
<p>For general vectors, we show algorithms which almost match Spencer's
$O(\sqrt{n})$ offline discrepancy bound, with ${O}(n\cdot poly\!\log T)$
amortized recourse per update. The crucial idea is to compute a basic feasible
solution to the linear relaxation in a distributed and recursive manner, which
helps find a low-discrepancy signing. To bound recourse we argue that only a
small part of the instance needs to be re-computed at each update.
</p>
<p>Since vector balancing has also been greatly studied for sparse vectors, we
then give algorithms for low-discrepancy edge orientation, where we dynamically
maintain signings for 2-sparse vectors. Alternatively, this can be seen as
orienting a dynamic set of edges of an n-vertex graph to minimize the absolute
difference between in- and out-degrees at any vertex. We present a
deterministic algorithm with $O(poly\!\log n)$ discrepancy and $O(poly\!\log
n)$ amortized recourse. The core ideas are to dynamically maintain an
expander-decomposition with low recourse and then to show that, as the
expanders change over time, a natural local-search algorithm converges quickly
(i.e., with low recourse) to a low-discrepancy solution. We also give strong
lower bounds for local-search discrepancy minimization algorithms.
</p></div>
    </summary>
    <updated>2021-11-14T23:02:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.06299</id>
    <link href="http://arxiv.org/abs/2111.06299" rel="alternate" type="text/html"/>
    <title>Approximating Sparsest Cut in Low-Treewidth Graphs via Combinatorial Diameter</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chalermsook:Parinya.html">Parinya Chalermsook</a>, Matthias Kaul, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mnich:Matthias.html">Matthias Mnich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spoerhase:Joachim.html">Joachim Spoerhase</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Uniyal:Sumedha.html">Sumedha Uniyal</a>, Daniel Vaz <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.06299">PDF</a><br/><b>Abstract: </b>The fundamental sparsest cut problem takes as input a graph $G$ together with
the edge costs and demands, and seeks a cut that minimizes the ratio between
the costs and demands across the cuts. For $n$-node graphs~$G$ of
treewidth~$k$, \chlamtac, Krauthgamer, and Raghavendra (APPROX 2010) presented
an algorithm that yields a factor-$2^{2^k}$ approximation in time $2^{O(k)}
\cdot \operatorname{poly}(n)$. Later, Gupta, Talwar and Witmer (STOC 2013)
showed how to obtain a $2$-approximation algorithm with a blown-up run time of
$n^{O(k)}$. An intriguing open question is whether one can simultaneously
achieve the best out of the aforementioned results, that is, a factor-$2$
approximation in time $2^{O(k)} \cdot \operatorname{poly}(n)$.
</p>
<p>In this paper, we make significant progress towards this goal, via the
following results:
</p>
<p>(i) A factor-$O(k^2)$ approximation that runs in time $2^{O(k)} \cdot
\operatorname{poly}(n)$, directly improving the work of Chlamt\'a\v{c} et al.
while keeping the run time single-exponential in $k$.
</p>
<p>(ii) For any $\varepsilon&gt;0$, a factor-$O(1/\varepsilon^2)$ approximation
whose run time is $2^{O(k^{1+\varepsilon}/\varepsilon)} \cdot
\operatorname{poly}(n)$, implying a constant-factor approximation whose run
time is nearly single-exponential in $k$ and a factor-$O(\log^2 k)$
approximation in time $k^{O(k)} \cdot \operatorname{poly}(n)$.
</p>
<p>Key to these results is a new measure of a tree decomposition that we call
combinatorial diameter, which may be of independent interest.
</p></div>
    </summary>
    <updated>2021-11-14T23:03:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.06267</id>
    <link href="http://arxiv.org/abs/2111.06267" rel="alternate" type="text/html"/>
    <title>The Harmless Set Problem</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gaikwad:Ajinkya.html">Ajinkya Gaikwad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maity:Soumen.html">Soumen Maity</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.06267">PDF</a><br/><b>Abstract: </b>Given a graph $G = (V,E)$, a threshold function $t~ :~ V \rightarrow
\mathbb{N}$ and an integer $k$, we study the Harmless Set problem, where the
goal is to find a subset of vertices $S \subseteq V$ of size at least $k$ such
that every vertex $v\in V$ has less than $t(v)$ neighbors in $S$. We enhance
our understanding of the problem from the viewpoint of parameterized
complexity. Our focus lies on parameters that measure the structural properties
of the input instance. We show that the problem is W[1]-hard parameterized by a
wide range of fairly restrictive structural parameters such as the feedback
vertex set number, pathwidth, treedepth, and even the size of a minimum vertex
deletion set into graphs of pathwidth and treedepth at most three. We also show
that the Harmless Set problem with majority thresholds is W[1]-hard when
parameterized by the treewidth of the input graph. We prove that the Harmless
Set problem can be solved in polynomial time on graph with bounded cliquewidth.
On the positive side, we obtain fixed-parameter algorithms for the problem with
respect to neighbourhood diversity and twin cover. We show that the problem
parameterized by the solution size is fixed parameter tractable on planar
graphs. We thereby resolve two open questions stated in C. Bazgan and M. Chopin
(2014) concerning the complexity of Harmless Set parameterized by the treewidth
of the input graph and on planar graphs with respect to the solution size.
</p></div>
    </summary>
    <updated>2021-11-14T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.06213</id>
    <link href="http://arxiv.org/abs/2111.06213" rel="alternate" type="text/html"/>
    <title>Enhanced Fast Boolean Matching based on Sensitivity Signatures Pruning</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jiaxi Zhang, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Ni:Liwei.html">Liwei Ni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zheng:Shenggen.html">Shenggen Zheng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Hao.html">Hao Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zou:Xiangfu.html">Xiangfu Zou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Feng.html">Feng Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Luo:Guojie.html">Guojie Luo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.06213">PDF</a><br/><b>Abstract: </b>Boolean matching is significant to digital integrated circuits design. An
exhaustive method for Boolean matching is computationally expensive even for
functions with only a few variables, because the time complexity of such an
algorithm for an n-variable Boolean function is $O(2^{n+1}n!)$. Sensitivity is
an important characteristic and a measure of the complexity of Boolean
functions. It has been used in analysis of the complexity of algorithms in
different fields. This measure could be regarded as a signature of Boolean
functions and has great potential to help reduce the search space of Boolean
matching.
</p>
<p>In this paper, we introduce Boolean sensitivity into Boolean matching and
design several sensitivity-related signatures to enhance fast Boolean matching.
First, we propose some new signatures that relate sensitivity to Boolean
equivalence. Then, we prove that these signatures are prerequisites for Boolean
matching, which we can use to reduce the search space of the matching problem.
Besides, we develop a fast sensitivity calculation method to compute and
compare these signatures of two Boolean functions. Compared with the
traditional cofactor and symmetric detection methods, sensitivity is a series
of signatures of another dimension. We also show that sensitivity can be easily
integrated into traditional methods and distinguish the mismatched Boolean
functions faster. To the best of our knowledge, this is the first work that
introduces sensitivity to Boolean matching. The experimental results show that
sensitivity-related signatures we proposed in this paper can reduce the search
space to a very large extent, and perform up to 3x speedup over the
state-of-the-art Boolean matching methods.
</p></div>
    </summary>
    <updated>2021-11-14T22:38:13Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.06169</id>
    <link href="http://arxiv.org/abs/2111.06169" rel="alternate" type="text/html"/>
    <title>Faster Goal-Oriented Shortest Path Search for Bulk and Incremental Detailed Routing</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ahrens:Markus.html">Markus Ahrens</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Henke:Dorothee.html">Dorothee Henke</a>, Stefan Rabenstein, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vygen:Jens.html">Jens Vygen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.06169">PDF</a><br/><b>Abstract: </b>We develop new algorithmic techniques for VLSI detailed routing. First, we
improve the goal-oriented version of Dijkstra's algorithm to find shortest
paths in huge incomplete grid graphs with edge costs depending on the direction
and the layer, and possibly on rectangular regions. We devise estimates of the
distance to the targets that offer better trade-offs between running time and
quality than previously known methods, leading to an overall speed-up. Second,
we combine the advantages of the two classical detailed routing approaches -
global shortest path search and track assignment with local corrections - by
treating input wires (such as the output of track assignment) as reservations
that can be used at a discount by the respective net. We show how to implement
this new approach efficiently.
</p></div>
    </summary>
    <updated>2021-11-14T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.06163</id>
    <link href="http://arxiv.org/abs/2111.06163" rel="alternate" type="text/html"/>
    <title>A 2-Approximation for the Bounded Treewidth Sparsest Cut Problem in FPT Time</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen=Addad:Vincent.html">Vincent Cohen-Addad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/M=ouml=mke:Tobias.html">Tobias Mömke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Verdugo:Victor.html">Victor Verdugo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.06163">PDF</a><br/><b>Abstract: </b>In the non-uniform sparsest cut problem, we are given a supply graph G and a
demand graph D, both with the same set of nodes V. The goal is to find a cut of
V that minimizes the ratio of the total capacity on the edges of G crossing the
cut over the total demand of the crossing edges of D. In this work, we study
the non-uniform sparsest cut problem for supply graphs with bounded treewidth
k. For this case, Gupta, Talwar and Witmer [STOC 2013] obtained a
2-approximation with polynomial running time for fixed k, and the question of
whether there exists a c-approximation algorithm for a constant c independent
of k, that runs in FPT time, remained open. We answer this question in the
affirmative. We design a 2-approximation algorithm for the non-uniform sparsest
cut with bounded treewidth supply graphs that runs in FPT time, when
parameterized by the treewidth. Our algorithm is based on rounding the optimal
solution of a linear programming relaxation inspired by the Sherali-Adams
hierarchy. In contrast to the classic Sherali-Adams approach, we construct a
relaxation driven by a tree decomposition of the supply graph by including a
carefully chosen set of lifting variables and constraints to encode information
of subsets of nodes with super-constant size, and at the same time we have a
sufficiently small linear program that can be solved in FPT time.
</p></div>
    </summary>
    <updated>2021-11-14T23:00:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.06101</id>
    <link href="http://arxiv.org/abs/2111.06101" rel="alternate" type="text/html"/>
    <title>A d-Dimensional Binary Search for Integer Pareto Frontiers</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gafni:Yotam.html">Yotam Gafni</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.06101">PDF</a><br/><b>Abstract: </b>For finite integer $d$-cubes, we consider the problem of learning a
classification $I$ that respects Pareto domination. The setup is natural in
dynamic programming settings. We show that a generalization of the binary
search algorithm achieves an optimal $\theta(n^{d-1})$ worst-case run time for
$d\geq 2$.
</p></div>
    </summary>
    <updated>2021-11-14T23:05:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.06026</id>
    <link href="http://arxiv.org/abs/2111.06026" rel="alternate" type="text/html"/>
    <title>A Note on the Maximum Number of Minimal Connected Dominating Sets in a Graph</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abu=Khzam:Faisal_N=.html">Faisal N. Abu-Khzam</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.06026">PDF</a><br/><b>Abstract: </b>We prove constructively that the maximum possible number of minimal connected
dominating sets in a connected undirected graph of order $n$ is in
$\Omega(1.489^n)$. This improves the previously known lower bound of
$\Omega(1.4422^n)$ and reduces the gap between lower and upper bounds for
input-sensitive enumeration of minimal connected dominating sets in general
graphs as well as some special graph classes.
</p></div>
    </summary>
    <updated>2021-11-14T22:37:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.06006</id>
    <link href="http://arxiv.org/abs/2111.06006" rel="alternate" type="text/html"/>
    <title>ConTesse: Accurate Occluding Contours for Smooth Surfaces</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Chenxi.html">Chenxi Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/B=eacute=nard:Pierre.html">Pierre Bénard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hertzmann:Aaron.html">Aaron Hertzmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hoshyari:Shayan.html">Shayan Hoshyari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.06006">PDF</a><br/><b>Abstract: </b>This paper proposes a method for computing the visible occluding contours of
smooth surfaces. First, new necessary and sufficient conditions are introduced
for when a sampled occluding contour is valid, that is, when it may be assigned
consistent visibility. Previous methods do not guarantee these conditions,
which helps explain why smooth contour visibility has been such a challenging
problem in the past. The paper then proposes an algorithm that, given a smooth
subdivision surface, finds sampled contours satisfying these conditions, and
then generates a new triangle mesh matching the given occluding contours. The
contours of the output triangle mesh may then be rendered with standard
non-photorealistic rendering algorithms, using the mesh for visibility
computation.
</p></div>
    </summary>
    <updated>2021-11-14T23:07:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.05996</id>
    <link href="http://arxiv.org/abs/2111.05996" rel="alternate" type="text/html"/>
    <title>A Few Identities of the Takagi Function on Dyadic Rationals</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Monroe:Laura.html">Laura Monroe</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.05996">PDF</a><br/><b>Abstract: </b>The number of unbalanced interior nodes of divide-and-conquer trees on $n$
leaves is known to form a sequence of dilations of the Takagi function on
dyadic rationals. We use this fact to derive identities on the Takagi function,
and on the Hamming weight of an integer in terms of the Takagi function.
</p></div>
    </summary>
    <updated>2021-11-14T23:06:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.05896</id>
    <link href="http://arxiv.org/abs/2111.05896" rel="alternate" type="text/html"/>
    <title>Generating faster algorithms for d-Path Vertex Cover</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Radovan Červený, Ondřej Suchý <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.05896">PDF</a><br/><b>Abstract: </b>For a constant $d$, the $d$-Path Vertex Cover problem ($d$-PVC) is as
follows: Given an undirected graph and an integer $k$, find a subset of at most
$k$ vertices of the graph, such that their deletion results in a graph not
containing a path on $d$ vertices as a subgraph. We develop a framework to
automatically generate parameterized branching algorithms for the problem and
obtain algorithms outperforming those previously known for $3 \le d \le 8$.
E.g., we show that $5$-PVC can be solved in $O(2.7^k\cdot n^{O(1)})$ time.
</p></div>
    </summary>
    <updated>2021-11-14T23:05:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.05881</id>
    <link href="http://arxiv.org/abs/2111.05881" rel="alternate" type="text/html"/>
    <title>Exponential separations between learning with and without quantum memory</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Sitan.html">Sitan Chen</a>, Jordan Cotler, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Hsin=Yuan.html">Hsin-Yuan Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jerry.html">Jerry Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.05881">PDF</a><br/><b>Abstract: </b>We study the power of quantum memory for learning properties of quantum
systems and dynamics, which is of great importance in physics and chemistry.
Many state-of-the-art learning algorithms require access to an additional
external quantum memory. While such a quantum memory is not required a priori,
in many cases, algorithms that do not utilize quantum memory require much more
data than those which do. We show that this trade-off is inherent in a wide
range of learning problems. Our results include the following:
</p>
<p>(1) We show that to perform shadow tomography on an $n$-qubit state rho with
$M$ observables, any algorithm without quantum memory requires $\Omega(\min(M,
2^n))$ samples of rho in the worst case. Up to logarithmic factors, this
matches the upper bound of [HKP20] and completely resolves an open question in
[Aar18, AR19].
</p>
<p>(2) We establish exponential separations between algorithms with and without
quantum memory for purity testing, distinguishing scrambling and depolarizing
evolutions, as well as uncovering symmetry in physical dynamics. Our
separations improve and generalize prior work of [ACQ21] by allowing for a
broader class of algorithms without quantum memory.
</p>
<p>(3) We give the first tradeoff between quantum memory and sample complexity.
We prove that to estimate absolute values of all $n$-qubit Pauli observables,
algorithms with $k &lt; n$ qubits of quantum memory require at least
$\Omega(2^{(n-k)/3})$ samples, but there is an algorithm using $n$-qubit
quantum memory which only requires $O(n)$ samples.
</p>
<p>The separations we show are sufficiently large and could already be evident,
for instance, with tens of qubits. This provides a concrete path towards
demonstrating real-world advantage for learning algorithms with quantum memory.
</p></div>
    </summary>
    <updated>2021-11-14T22:37:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2111.05874</id>
    <link href="http://arxiv.org/abs/2111.05874" rel="alternate" type="text/html"/>
    <title>A Hierarchy for Replica Quantum Advantage</title>
    <feedworld_mtime>1636848000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Sitan.html">Sitan Chen</a>, Jordan Cotler, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Hsin=Yuan.html">Hsin-Yuan Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jerry.html">Jerry Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2111.05874">PDF</a><br/><b>Abstract: </b>We prove that given the ability to make entangled measurements on at most $k$
replicas of an $n$-qubit state $\rho$ simultaneously, there is a property of
$\rho$ which requires at least order $2^n / k^2$ measurements to learn.
However, the same property only requires one measurement to learn if we can
make an entangled measurement over a number of replicas polynomial in $k, n$.
Because the above holds for each positive integer $k$, we obtain a hierarchy of
tasks necessitating progressively more replicas to be performed efficiently. We
introduce a powerful proof technique to establish our results, and also use
this to provide new bounds for testing the mixedness of a quantum state.
</p></div>
    </summary>
    <updated>2021-11-14T22:59:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-11-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19328</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/11/13/popl-2022-et-tu-brute/" rel="alternate" type="text/html"/>
    <title>POPL 2022—Et Tu, Brute?</title>
    <summary>Some things just cannot wait. Men must stand up now for women’s equality— Rick Goings Kathleen Booth, Cicely Popplewell, Grace Hopper, and Jean Sammet were four pioneers of the field of Programming Languages. They are credited for (co-)creating the first assembly language, programming manual, compiler, and widest-use language (COBOL), the last alongside Mary Hawes and […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Some things just cannot wait. Men must stand up now for women’s equality— Rick Goings</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wpcomstaging.com/2021/11/13/popl-2022-et-tu-brute/boothpopplewellhoppersammet/" rel="attachment wp-att-19330"><img alt="" class="alignright size-full wp-image-19330" height="231" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/11/BoothPopplewellHopperSammet.png?resize=185%2C231&amp;ssl=1" width="185"/></a></p>
<p>
Kathleen Booth, Cicely Popplewell, Grace Hopper, and Jean Sammet were four pioneers of the field of Programming Languages. They are credited for (co-)creating the first assembly language, programming manual, compiler, and widest-use language (COBOL), the last alongside Mary Hawes and Gertrude Tierney. Popplewell’s name heads the proceedings of the 1962 <a href="https://hal.inria.fr/IFIP">IFIP</a> conference, while Sammet wrote a defining textbook of the field, <em>Programming Languages: History and Fundamentals</em>, in 1969. </p>
<p>
Today Ken and I wonder why the 56-person strong programming committee for the 2022 Principles of Programming Languages conference has only six women.</p>
<p>
If you were asked to name <b>a</b> <em>principle</em> of programming languages, there’s a good chance you’d think of the <a href="https://en.wikipedia.org/wiki/Liskov_substitution_principle">Liskov substitution principle</a>, which is named for Barbara Liskov. Of all fields of computing, we would hope that this would be the leader toward gender balance. It is true that across the board in computer science, we are struggling to get over 20% female representation. But we should be doing better than <img alt="{6/56 = 10.714...\%}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B6%2F56+%3D+10.714...%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> now.	</p>
<p>
</p><p/><h2> The Full Committee </h2><p/>
<p/><p>
Here is the full POPL committee. We have starred the six women—whom we salute.</p>
<ol>
<p/><li>
<a href="https://thakur.cs.ucdavis.edu">Aditya V. Thakur</a> <p/>
</li><li>
<a href="https://www.lambdabetaeta.eu">Alex Kavvos</a> <p/>
</li><li>
<a href="https://people.eecs.berkeley.edu/~akcheung/">Alvin Cheung</a>	 <p/>
</li><li>
<b>*</b><a href="https://www.ccs.neu.edu/home/amal/">Amal Ahmed	</a> <p/>
</li><li>
<a href="https://www.linkedin.com/in/andrew-kennedy-3324287/?originalSubdomain=uk">Andrew Kennedy</a>	 <p/>
</li><li>
<a href="https://www.cs.ox.ac.uk/people/anthony.lin/">Anthony W. Lin</a>	 <p/>
</li><li>
<a href="https://www.fos.kuis.kyoto-u.ac.jp/~igarashi/index.html.en">Atsushi Igarashi</a>	 <p/>
</li><li>
<a href="https://cs.au.dk/~spitters/">Bas Spitters</a> <p/>
</li><li>
<a href="https://scholar.google.de/citations?user=KEt1bfkAAAAJ&amp;hl=en">Benjamin Lucien Kaminski</a>	 <p/>
</li><li>
<a href="https://www.cs.ox.ac.uk/people/luke.ong/">C.-H. Luke Ong</a>	 <p/>
</li><li>
<b>*</b><a href="https://caterinaurban.github.io">Caterina Urban</a> <p/>
</li><li>
<a href="https://users.cs.northwestern.edu/~chrdimo/">Christos Dimoulas</a> <p/>
</li><li>
<a href="https://homes.luddy.indiana.edu/ccshan/">Chung-chieh Shan</a> <p/>
</li><li>
<a href="https://www.kth.se/profile/dbro">David Broman</a>	 <p/>
</li><li>
<a href="https://dimitriv.github.io">Dimitrios Vytiniotis</a>	 <p/>
</li><li>
<a href="https://www.cs.toronto.edu/~fanl/">Fan Long</a>	 <p/>
</li><li>
<a href="https://orcid.org/0000-0001-5011-3458">Filip Sieczkowski</a>	 <p/>
</li><li>
<a href="http://pauillac.inria.fr/~fpottier/">Francois Pottier</a>	 <p/>
</li><li>
<a href="https://cs.uiowa.edu/people/garrett-morris">Garrett Morris</a>	 <p/>
</li><li>
<b>*</b><a href="https://cs.nju.edu.cn/hongjin/">Hongjin Liang</a>	 <p/>
</li><li>
<a href="https://www.cs.ox.ac.uk/people/hongseok.yang/Public/Home.html">Hongseok Yang</a>	 <p/>
</li><li>
<a href="https://jamesrwilcox.com">James Wilcox</a>	 <p/>
</li><li>
<a href="https://www.cs.cmu.edu/~janh/">Jan Hoffmann</a>	 <p/>
</li><li>
<a href="https://johnwickerson.github.io">John Wickerson</a>	 <p/>
</li><li>
<a href="https://justinh.su">Justin Hsu</a>	 <p/>
</li><li>
<a href="https://www.cs.utexas.edu/people/faculty-researchers/ken-mcmillan">Ken McMillan</a>	 <p/>
</li><li>
<a href="https://scholar.google.co.kr/citations?user=bWY6MmgAAAAJ&amp;hl=ko">Kihong Heo</a> <p/>
</li><li>
<a href="https://www.fos.kuis.kyoto-u.ac.jp/~ksuenaga/">Kohei Suenaga</a>	 <p/>
</li><li>
<b>*</b><a href="https://www.kurims.kyoto-u.ac.jp/~kmuroya/">Koko Muroya</a>	 <p/>
</li><li>
<a href="https://lemonidas.github.io">Leonidas Lampropoulos</a>	 <p/>
</li><li>
<a href="https://www.cs.rhul.ac.uk/home/uxac009/">Matthew Hague</a>	 <p/>
</li><li>
<a href="https://www.microsoft.com/en-us/research/people/mattpark/">Matthew Parkinson</a>	 <p/>
</li><li>
<a href="https://people.csail.mit.edu/mcarbin/">Michael Carbin</a>	 <p/>
</li><li>
<a href="https://www.yale-nus.edu.sg/about/faculty/michael-d-adams/">Michael D. Adams</a>	 <p/>
</li><li>
<a href="https://michael-emmi.github.io">Michael Emmi</a> <p/>
</li><li>
<a href="https://www.cl.cam.ac.uk/~nk480/">Neel Krishnaswami</a> <p/>
</li><li>
<a href="https://www.imperial.ac.uk/people/n.wu">Nicolas Wu</a> <p/>
</li><li>
<b>*</b><a href="https://nikivazou.github.io">Niki Vazou</a>	 <p/>
</li><li>
<a href="https://www.cs.tau.ac.il/~orilahav/">Ori Lahav</a>	 <p/>
</li><li>
<a href="https://cs.illinois.edu/about/people/faculty/madhu">P. Madhusudan</a>	 <p/>
</li><li>
<a href="https://pavpanchekha.com">Pavel Panchekha</a>	 <p/>
</li><li>
<a href="https://katalog.uu.se/profile/?id=N11-35">Philipp Ruemmer</a>	 <p/>
</li><li>
<a href="https://pageperso.lis-lab.fr/pierre.clairambault/">Pierre Clairambault</a>	 <p/>
</li><li>
<a href="https://helloqirun.github.io">Qirun Zhang</a> <p/>
</li><li>
<a href="https://www.linkedin.com/in/rgrig/?originalSubdomain=uk">Radu Grigore</a>	 <p/>
</li><li>
<a href="https://www.cs.ox.ac.uk/people/ralf.hinze/">Ralf Hinze</a>	 <p/>
</li><li>
<a href="https://ranjitjhala.github.io">Ranjit Jhala</a>	 <p/>
</li><li>
<a href="https://bentnib.org">Robert Atkey</a>	 <p/>
</li><li>
<a href="https://scholar.harvard.edu/napadow/people/ronald-garcia-md-phd">Ronald Garcia</a>	 <p/>
</li><li>
<a href="https://www.cs.columbia.edu/~rgu/">Ronghui Gu</a> <p/>
</li><li>
<a href="http://www.cs.ox.ac.uk/people/samuel.staton/main.html">Sam Staton</a>	 <p/>
</li><li>
<b>*</b><a href="https://people.irisa.fr/Sandrine.Blazy/">Sandrine Blazy</a>	 <p/>
</li><li>
<a href="https://group-mmm.org/~s-katsumata/index-e.html">Shin-ya Katsumata</a> <p/>
</li><li>
<a href="https://waseda.pure.elsevier.com/en/persons/tachio-terauchi">Tachio Terauchi</a>	 <p/>
</li><li>
<a href="https://www.comp.nus.edu.sg/cs/bio/chinwn/">Wei-Ngan Chin</a>	 <p/>
</li><li>
<a href="https://www.linkedin.com/in/woosuk-lee-59609035/">Woosuk Lee</a><p/>
</li></ol>
<p>
</p><p/><h2> I Cannot Believe It </h2><p/>
<p/><p>
I have always enjoyed the POPL conference. I recall being there ages ago—I was there in 1980 on a <a href="https://www.researchgate.net/publication/262331842_Theoretical_and_empirical_studies_on_using_program_mutation_to_test_the_functional_correctness_of_programs">paper</a>, “Theoretical and Empirical Studies on Using Program Mutation to Test the Functional Correctness of Programs,” with Timothy Budd, Richard DeMillo, and Frederick Sayward.</p>
<p>
I had planned to do a long post on POPL 2022. This POPL is planned to be a real in-person conference for this coming 2022—not virtual. But I was upset to say the least by the above ratio. </p>
<p>
Ken and I were similarly stopped the week before Halloween. We had intended a post saluting those who aggregate theory of computing blogs and including a list of over <b>50</b> active blogs. We stopped it because, as noted at the end of the <a href="https://rjlipton.wpcomstaging.com/2021/11/01/quantum-trick-or-treat/">post</a> that Ken wrote instead, one has to stretch to reach even <b>4</b> mathematics/theory blogs by women. </p>
<p>
Counts of the most recent FOCS and STOC program committees give slightly better percentages. Slightly. For STOC 2022 we count 7 women out of 46, giving This is </p>
<p align="center"><img alt="\displaystyle  \frac{7}{46} = 0.152... " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B7%7D%7B46%7D+%3D+0.152...+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>This is just a notch better. FOCS 2022 manages to improve both the numerator and the denominator: </p>
<p align="center"><img alt="\displaystyle  \frac{8}{36} = 0.222... " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B8%7D%7B36%7D+%3D+0.222...+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>That’s double POPL, and over 20%. But it is still single-digits on a fairly large committee. </p>
<p>
</p><p/><h2> Planting a Field </h2><p/>
<p/><p>
We’ve led off this post with pioneers of generations back. What about 20–30 years back? That seems to be the time frame alluded to in this statement by Valerie King—whom both of us have known since the late 1980s—in the first-year <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1834336&amp;HistoricalAwards=false">report</a> to NSF of the inaugural <a href="https://sigact.org/tcswomen/">TCS Women meeting</a> in 2018:</p>
<blockquote><p><b> </b> <em> “I chaired the STOC program committee last year [<a href="http://acm-stoc.org/stoc2017/">2017</a>], and while there were plenty of women on the committee, what a disappointment it was [in 2017] to see rooms full of men with only a sprinkling of woman in sight. I remember a time when there were more women at FOCS and STOC and It’s hard not to wonder what’s happened, and to want to fix this problem. I think it can lead to a downward spiral, the fewer the women, the more women who do come fill uncomfortable and the fewer that come next time. </em></p><em>
</em><p><em>
Thanks to efforts of Barna [Saha], Sofya [Raskhodnikova] and Virginia [Vassilevska Williams], STOC 2018 seemed different. As I looked around the conference rooms, I actually saw women and it felt good.” </em>
</p></blockquote>
<p/><p>
So we wondered if we could take a snapshot of POPL 20 years ago. I (Ken writing this part) counted out the <a href="https://www.cs.cmu.edu/~mleone/language-people.html">“Language People”</a> list that is linked from Wikipedia’s own shorter <a href="https://en.wikipedia.org/wiki/List_of_programming_language_researchers">list</a> of programming language researchers. The longer, former list was compiled circa 2000 by Mark Leone, whom I knew as a student in a theory course I taught once in Cornell’s summer session, and who now works at NVIDIA. </p>
<p>
I count <b>319</b> names. I noticed Susan Horwitz, for whom we wrote a <a href="https://rjlipton.wpcomstaging.com/2014/12/02/susan-horwitz-1955-2014/">memorial</a> in 2014. I did not check whether others are still living, as I viewed this as a generation-ago snapshot. The list is not perfect—it <a href="https://en.wikipedia.org/wiki/CLU_(programming_language)">CLU</a>-lessly omits Liskov—but it serves the purpose. I included Horwitz in my quick count of women: </p>
<p align="center"><img alt="\displaystyle  17. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++17.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>That makes a ratio of <img alt="{17/319 = 0.05329...}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B17%2F319+%3D+0.05329...%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> Just barely over 5%. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Even with Ken’s little experiment, I cannot understand how the low ratio could be possible with POPL. Here are the <a href="https://sigplan.org/Resources/Policies/Diversity/">goals</a> for POPL. Gender equity is in the list, but is seventh. Hmmm. </p>
<p/><p><br/>
[Fixed count of POPL committee; “wide-use”-&gt;”widest-use” in intro]</p></font></font></div>
    </content>
    <updated>2021-11-13T22:39:05Z</updated>
    <published>2021-11-13T22:39:05Z</published>
    <category term="All Posts"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Barbara Liskov"/>
    <category term="Cicely Popplewell"/>
    <category term="Gender equity"/>
    <category term="gender gap"/>
    <category term="gender parity"/>
    <category term="Grace Hopper"/>
    <category term="Jean Sammet"/>
    <category term="Kathleen Booth"/>
    <category term="POPL 2022"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-11-15T09:37:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/155</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/155" rel="alternate" type="text/html"/>
    <title>TR21-155 |  Learning generalized depth-three arithmetic circuits in the non-degenerate case | 

	Vishwas Bhargava, 

	Ankit Garg, 

	Neeraj Kayal, 

	Chandan Saha</title>
    <summary>Consider a homogeneous degree $d$ polynomial $f = T_1 + \cdots + T_s$, $T_i = g_i(\ell_{i,1}, \ldots, \ell_{i, m})$ where $g_i$'s are homogeneous $m$-variate degree $d$ polynomials and $\ell_{i,j}$'s are linear polynomials in $n$ variables. We design a (randomized) learning algorithm that given black-box access to $f$, computes black-boxes for the $T_i$'s. The running time of the algorithm is $\text{poly}(n, m, d, s)$ and the algorithm works under some \emph{non-degeneracy} conditions on the linear forms and the $g_i$'s, and some additional technical assumptions $n \ge (md)^2, s \le n^{ d/4} $. The non-degeneracy conditions on $\ell_{i,j}$'s constitute non-membership in a variety, and hence are satisfied when the coefficients of $\ell_{i,j}$'s are chosen uniformly and randomly from a large enough set. The conditions on $g_i$'s are satisfied for random polynomials and also for natural polynomials common in the study of arithmetic complexity like determinant, permanent, elementary symmetric polynomial, iterated matrix multiplication. A particularly appealing algorithmic corollary is the following: Given black-box access to an $f = \mbox{Det}_{r}(L^{(1)}) + \ldots + \mbox{Det}_{r}(L^{(s)})$, where $L^{(k)} = (\ell_{i,j}^{(k)})_{i,j}$ with $\ell_{i,j}^{(k)}$'s being linear forms in $n$ variables chosen randomly, there is an algorithm which in time $\poly(n, r)$ outputs matrices $(M^{(k)})_k$ of linear forms \text{s.t.} there exists a permutation $\pi: [s] \rightarrow [s]$ with $\mbox{Det}_{r}(M^{(k)}) = \mbox{Det}_{r}(L^{(\pi(k))})$.
    
    Our work follows the works of Kayal-Saha(STOC'19) and Garg-Kayal-Saha(FOCS'20) which use lower bound methods in arithmetic complexity to design average case learning algorithms. It also vastly generalizes the result in \cite{Kayal-Saha'19} about learning depth-three circuits, which is a special case where each $g_i$ is just a monomial. At the core of our algorithm is the partial derivative method which can be used to prove lower bounds for generalized depth-three circuits. To apply the general framework in \cite{Kayal-Saha'19, Garg-Kayal-Saha'20}, we need to establish that the non-degeneracy conditions arising out of applying the framework with the partial derivative method are satisfied in the random case. We develop simple but general and powerful tools to establish this, which might be useful in designing average case learning algorithms for other arithmetic circuit models.</summary>
    <updated>2021-11-13T22:24:40Z</updated>
    <published>2021-11-13T22:24:40Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-11-15T09:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/13/postdoc-at-tel-aviv-university-apply-by-december-31-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/13/postdoc-at-tel-aviv-university-apply-by-december-31-2021/" rel="alternate" type="text/html"/>
    <title>Postdoc at Tel Aviv University (apply by December 31, 2021)</title>
    <summary>I (Gil Cohen) invite applications for a postdoctoral position at Tel Aviv University starting in September 2022. The exact date will be flexible. The position will have an initial appointment of one year, but will be extendible to two years contingent upon satisfactory performance and continued funding. ​ For more information please visit the accompanied […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I (Gil Cohen) invite applications for a postdoctoral position at Tel Aviv University starting in September 2022. The exact date will be flexible. The position will have an initial appointment of one year, but will be extendible to two years contingent upon satisfactory performance and continued funding. ​<br/>
For more information please visit the accompanied URL.</p>
<p>Website: <a href="https://www.gilcohen.org/postdoc2022">https://www.gilcohen.org/postdoc2022</a><br/>
Email: coheng@gmail.com</p></div>
    </content>
    <updated>2021-11-13T20:28:30Z</updated>
    <published>2021-11-13T20:28:30Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-15T09:37:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=105</id>
    <link href="https://dstheory.wordpress.com/2021/11/12/thursday-nov-18th-nicole-immorlica-from-msr/" rel="alternate" type="text/html"/>
    <title>Thursday Nov 18th — Nicole Immorlica from MSR</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The next Foundations of Data Science virtual talk will take place on Thursday, Nov 18th at 10:00 AM Pacific Time (13:00 Eastern Time, 19:00 Central European Time, 18:00 UTC). Nicole Immorlica from Microsoft Research will speak about “Communicating with Anecdotes”. Please register here to join the virtual talk. Abstract: Classic models of communication in economics typically assume<a class="more-link" href="https://dstheory.wordpress.com/2021/11/12/thursday-nov-18th-nicole-immorlica-from-msr/">Continue reading <span class="screen-reader-text">"Thursday Nov 18th — Nicole Immorlica from MSR"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="has-text-align-justify">The next <a href="https://sites.google.com/view/dstheory/home" rel="noreferrer noopener" target="_blank">Foundations of Data Science</a> virtual talk will take place on <strong>Thursday, Nov 18</strong>th at <strong>10:00 AM Pacific Time</strong> (13:00 Eastern Time, 19:00 Central European Time, 18:00 UTC). <strong><a href="https://immorlica.com/" rel="noreferrer noopener" target="_blank">Nicole Immorlica</a></strong> from<strong> Microsoft Research</strong> will speak about “Communicating with Anecdotes”.</p>



<p><a href="https://sites.google.com/view/dstheory" rel="noreferrer noopener" target="_blank">Please register here to join the virtual talk.</a></p>



<p class="has-text-align-justify"><strong>Abstract</strong>: Classic models of communication in economics typically assume agents can communicate any message.  However, many important communications, such as those in newspapers or politicians’ speeches, use data to convey information.  In this talk, we explore how the reliance on data impacts communication.  In our model, there are two Bayesian agents (a sender and a receiver) who wish to communicate. The receiver must take an action whose payoff depends on their personal preferences and an unknown state of the world. The sender has access to a collection of data points correlated with the state of the world and can send exactly one of these to the receiver in order to influence her choice of action. Importantly, the sender’s personal preferences may differ from the receiver’s, which affects the sender’s strategic choice of what to send. We show that in a Nash equilibrium even a small difference in preferences can lead to a significant bias in the communicated datum. This can significantly reduce informativeness of the communication, leading to substantial utility loss for both sides. One implication is informational homophily: a receiver can rationally prefer to obtain data from a poorly-informed sender with aligned preferences, rather than a knowledgeable expert whose preferences may differ from her own.  </p>



<p>Joint work with Nika Haghtalab, Brendan Lucier, Markus Mobius and Divya Mohan.</p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>
    </content>
    <updated>2021-11-12T17:48:13Z</updated>
    <published>2021-11-12T17:48:13Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2021-11-15T09:39:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/12/canada-research-chair-and-tenured-faculty-position-at-university-of-waterloo-apply-by-january-31-2022/</id>
    <link href="https://cstheory-jobs.org/2021/11/12/canada-research-chair-and-tenured-faculty-position-at-university-of-waterloo-apply-by-january-31-2022/" rel="alternate" type="text/html"/>
    <title>Canada Research Chair and tenured faculty position at University of Waterloo (apply by January 31, 2022)</title>
    <summary>Exceptional scholars and researchers at the rank of Full Professor or Associate Professor are sought who are eligible to apply for a Tier 1 Canada Research Chair (CRC). This call is open only to qualified individuals who self-identify as women, transgender, non-binary, or two-spirit. One position is open to all areas of computer science. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Exceptional scholars and researchers at the rank of Full Professor or Associate Professor are sought who are eligible to apply for a Tier 1 Canada Research Chair (CRC). This call is open only to qualified individuals who self-identify as women, transgender, non-binary, or two-spirit.</p>
<p>One position is open to all areas of computer science.</p>
<p>Website: <a href="https://cs.uwaterloo.ca/about/open-positions/crcs-tier1">https://cs.uwaterloo.ca/about/open-positions/crcs-tier1</a><br/>
Email: cs-recruiting@uwaterloo.ca</p></div>
    </content>
    <updated>2021-11-12T17:36:58Z</updated>
    <published>2021-11-12T17:36:58Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-15T09:37:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/11/tenure-track-faculty-at-stanford-university-apply-by-november-15-2021/</id>
    <link href="https://cstheory-jobs.org/2021/11/11/tenure-track-faculty-at-stanford-university-apply-by-november-15-2021/" rel="alternate" type="text/html"/>
    <title>Tenure-track Faculty at Stanford University (apply by November 15, 2021)</title>
    <summary>Stanford Data Science and the School of Engineering invite applications for a tenure-track appointment at the assistant professor or untenured associate professor level. We welcome candidates engaged in all aspects of data science and applications in one or more engineering disciplines. Application review begins Nov 15, 2021; search will remain open until the position is […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Stanford Data Science and the School of Engineering invite applications for a tenure-track appointment at the assistant professor or untenured associate professor level. We welcome candidates engaged in all aspects of data science and applications in one or more engineering disciplines.</p>
<p>Application review begins Nov 15, 2021; search will remain open until the position is filled.</p>
<p>Website: <a href="https://datascience.stanford.edu/tenure-track-faculty-position-soe">https://datascience.stanford.edu/tenure-track-faculty-position-soe</a><br/>
Email: SDSSoEfacultysearch@stanford.edu</p></div>
    </content>
    <updated>2021-11-11T17:15:22Z</updated>
    <published>2021-11-11T17:15:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-15T09:37:51Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/11/postdoc-at-northwestern-and-ttic-apply-by-january-1-2022/</id>
    <link href="https://cstheory-jobs.org/2021/11/11/postdoc-at-northwestern-and-ttic-apply-by-january-1-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at Northwestern and TTIC (apply by January 1, 2022)</title>
    <summary>Northwestern University and Toyota Technology Institute at Chicago invite applications for a postdoctoral position. The postdoc will conduct research in approximation algorithms and beyond-worst-case analysis of algorithms, working with Konstantin Makarychev and Yury Makarychev. The position will be based at Northwestern University, but the postdoc will be encouraged to spend some time at TTIC. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Northwestern University and Toyota Technology Institute at Chicago invite applications for a postdoctoral position. The postdoc will conduct research in approximation algorithms and beyond-worst-case analysis of algorithms, working with Konstantin Makarychev and Yury Makarychev. The position will be based at Northwestern University, but the postdoc will be encouraged to spend some time at TTIC.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/20466">https://academicjobsonline.org/ajo/jobs/20466</a><br/>
Email: yury@ttic.edu</p></div>
    </content>
    <updated>2021-11-11T15:12:06Z</updated>
    <published>2021-11-11T15:12:06Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-15T09:37:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2727537320196855723</id>
    <link href="http://blog.computationalcomplexity.org/feeds/2727537320196855723/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/11/20-years-of-algorithmic-game-theory.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/2727537320196855723" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/2727537320196855723" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/11/20-years-of-algorithmic-game-theory.html" rel="alternate" type="text/html"/>
    <title>20 Years of Algorithmic Game Theory</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Twenty years ago DIMACS hosted a <a href="http://dimacs.rutgers.edu/archive/Workshops/gametheory/program.html">Workshop on Computational Issues in Game Theory and Mechanism Design</a>. This wasn't the very beginning of algorithmic game theory, but it was quite the coming out party. From the <a href="http://dimacs.rutgers.edu/archive/Workshops/gametheory/announcement.html">announcement</a></p><p/><blockquote><p>The research agenda of computer science is undergoing significant changes due to the influence of the Internet. Together with the emergence of a host of new computational issues in mathematical economics, as well as electronic commerce, a new research agenda appears to be emerging. This area of research is collectively labeled under various titles, such as "Foundations of Electronic Commerce", Computational Economics", or "Economic Mechanisms in Computation" and deals with various issues involving the interplay between computation, game-theory and economics.</p><p>This workshop is intended to not only summarize progress in this area and attempt to define future directions for it, but also to help the interested but uninitiated, of which there seem many, understand the language, the basis principles and the major issues.</p><p/></blockquote><p>Working at the nearby NEC Research Institute at the time I attended as one of those "interested but unititated."</p><p>The workshop had talks from the current and rising stars in the field in both the theoretical computer science, AI and economics communities. The presentations included some classic early results including <a href="https://doi.org/10.1016/S0304-3975(03)00391-8">Competitive Analysis of Incentive Compatible Online Auctions</a>, <a href="https://doi.org/10.1145/506147.506153">How Bad is Selfish Routing?</a> and the seminal work on <a href="https://doi.org/10.1016/j.geb.2006.02.003">Competitive Auctions</a>. </p><p>Beyond the talks, just having the powerhouse of people at the meeting, established players, like Noam Nisan, Vijay Vazirani, Eva Tardos and Christos Papadimitriou, with several newcomers who are now the established players including Tim Roughgarden and Jason Hartline just to mention a few from theoretical computer science. </p><p>The highlight was a panel discussion on how to overcome the methodological differences between computer scientists and economic game theorists. The panelists were an all-star collection of  John Nash, Andrew Odlyzko, Christos Papadimitriou, Mark Satterthwaite, Scott Shenker and Michael Wellman. The discussion focused on things like competitive analysis though to me, in hindsight, the real difference is between the focus on models (game theory) vs theorems (CS). </p><div>Interest in these connections exploded after the workshop and a new field blossomed.</div></div>
    </content>
    <updated>2021-11-11T12:57:00Z</updated>
    <published>2021-11-11T12:57:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-11-15T09:33:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4588</id>
    <link href="https://lucatrevisan.wordpress.com/2021/11/10/online-optimization-post-7-matrix-multiplicative-weights-update/" rel="alternate" type="text/html"/>
    <title>Online Optimization Post 7: Matrix Multiplicative Weights Update</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This is the seventh in a series of posts on online optimization, where we alternate one post explaining a result from the theory of online convex optimization and one post explaining an “application” in computational complexity or combinatorics. The first … <a href="https://lucatrevisan.wordpress.com/2021/11/10/online-optimization-post-7-matrix-multiplicative-weights-update/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This is the seventh in a series of posts on online optimization, where we alternate one post explaining a result from the theory of online convex optimization and one post explaining an “application” in computational complexity or combinatorics. The first two posts were about the technique of <a href="https://lucatrevisan.wordpress.com/2019/04/24/online-optimization-post-1-multiplicative-weights/">Multiplicative Weights Updates</a> and its application to <a href="https://lucatrevisan.wordpress.com/2019/04/25/online-optimization-post-2-constructing-pseudorandom-sets/">“derandomizing” probabilistic arguments</a> based on combining a Chernoff bound and a union bound. The third and fourth post were about the <a href="https://lucatrevisan.wordpress.com/2019/05/06/online-optimization-post-3-follow-the-regularized-leader/">Follow-the-Regularized-Leader</a> framework, which unifies multiplicative weights and gradient descent, and a <a href="https://lucatrevisan.wordpress.com/2019/05/16/online-optimization-post-4-regularity-lemmas/">“gradient descent view” of the Frieze-Kannan Weak Regularity Lemma</a>. The fifth and sixth post were about the <a href="https://lucatrevisan.wordpress.com/2019/05/20/online-optimization-post-5-bregman-projections-and-mirror-descent/">constrained version of the Follow-the-Regularized-Leader</a> framework, and the <a href="https://lucatrevisan.wordpress.com/2021/10/20/online-optimization-post-6-the-impagliazzo-hard-core-set-lemma/">Impagliazzo Hard-Core Set Lemma</a>. Today we shall see the technique of Matrix Multiplicative Weights Updates.</p>
<p><b>1. Matrix Multiplicative Weights Update </b></p>
<p>In this post we consider the following generalization, introduced and studied by <a href="https://dl.acm.org/doi/10.1145/1250790.1250823">Arora and Kale</a>, of the “learning from expert advice” setting and the multiplicative weights update method. In the “experts” model, we have a repeated game in which, at each time step <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we have the option of following the advice of one of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> experts; if we follow the advice of expert <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> at time <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we incur a loss of <img alt="{\ell_t (i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_t+%28i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which is unknown to us (although, at time <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> we know the loss functions <img alt="{\ell_1(\cdot),\ldots,\ell_{t-1}(\cdot)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_1%28%5Ccdot%29%2C%5Cldots%2C%5Cell_%7Bt-1%7D%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>). We are allowed to choose a probabilistic strategy, whereby we follow the advice of expert <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with probability <img alt="{x_t(i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_t%28i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, so that our expected loss at time <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is <img alt="{\sum_{i=1}^n x_t(i) \ell_t(i)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bi%3D1%7D%5En+x_t%28i%29+%5Cell_t%28i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>In the matrix version, instead of choosing an expert <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> we are allowed to choose a unit <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-dimensional vector <img alt="{v_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and the loss incurred in choosing the vector <img alt="{v_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is <img alt="{v_t ^T L_t v_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_t+%5ET+L_t+v_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, where <img alt="{L_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is an unknown symmetric <img alt="{n\times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> matrix. We are also allowed to choose a probabilistic strategy, so that with probability <img alt="{x_t(j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_t%28j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> we choose the unit vector <img alt="{v_t^{(j)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_t%5E%7B%28j%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and we incur the expected loss</p>
<p align="center"><img alt="\displaystyle  \sum_j x_t (j) \cdot (v_t^{(j)})^T L_t v_t^{(j)} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_j+x_t+%28j%29+%5Ccdot+%28v_t%5E%7B%28j%29%7D%29%5ET+L_t+v_t%5E%7B%28j%29%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p><span id="more-4588"/></p>
<p>The above expression can also be written as</p>
<p align="center"><img alt="\displaystyle  X_t \bullet L_t " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X_t+%5Cbullet+L_t+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> where <img alt="{X_t = \sum_j x_t(j) v_t^{(j)}(v_t^{(j)})^T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_t+%3D+%5Csum_j+x_t%28j%29+v_t%5E%7B%28j%29%7D%28v_t%5E%7B%28j%29%7D%29%5ET%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and we used the Frobenius inner product among square matrices defined as <img alt="{A \bullet B = \sum_{i,j} A_{i,j} B_{i,j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Cbullet+B+%3D+%5Csum_%7Bi%2Cj%7D+A_%7Bi%2Cj%7D+B_%7Bi%2Cj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The matrices <img alt="{X_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that can be obtained as convex combinations of rank-1 matrices of the form <img alt="{vv^T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bvv%5ET%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> where <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a unit vector are called <em>density matrices</em> and can be characterized as the set of positive semidefinite matrices whose trace is 1.</p>
<p>It is possible to see the above game as the “quantum version” of the experts settings. A choice of a unit vector <img alt="{v_t^{(j)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_t%5E%7B%28j%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a <em>pure quantum state</em>, a probability distribution of pure quantum states, described by a density matrix, is a <em>mixed quantum state</em>. If <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a density matrix describing a mixed quantum state, <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a symmetric matrix, and <img alt="{L = \sum_i \lambda_i w_i w_i^T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL+%3D+%5Csum_i+%5Clambda_i+w_i+w_i%5ET%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the spectral decomposition of <img alt="{L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in terms of its eigenvalues <img alt="{\lambda_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and orthonormal eigenvectors <img alt="{w_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then <img alt="{X \bullet L}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%5Cbullet+L%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the expected outcome of a measurement of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the basis <img alt="{w_1,\ldots,w_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_1%2C%5Cldots%2Cw_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and such that <img alt="{\lambda_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the value of the measurement if the outcome is <img alt="{w_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>If you have no idea what the above paragraph means, that is perfectly ok because this view will not be particularly helpful in motivating the algorithm and analysis that we will describe. (Here I am reminded of the joke about the way people from Naples give directions: “How do I get to the post office?”, “Well, you see that road over there? After the a couple of blocks there is a pharmacy, where my uncle used to work, though now he is retired.” “Ok?” “Now, if you turn left after the pharmacy, after a while you get to a square with a big fountain and the church of St. Anthony where my niece got married. It was a beautiful ceremony, but the food at the reception was not great.” “Yes, I know that square”, “Good, don’t go there, the post office is not that way. Now, if you instead take that other road over there …”)</p>
<p>The main point of the above game, and of the Matrix Multiplicative Weights Update (MMWU) algorithm that plays it with bounded regret, is that it provides useful generalizations of the standard “experts” game and of the Multiplicative Weights Update (MWU) algorithm. For example, as we have already seen, MWU can provide a “derandomization” of the Chernoff bound; we will see that MMWU provides a derandomization of the <em>matrix</em> Chernoff bound. MWU can be used to approximate certain Linear Programming problems; MMWU can be used to approximate certain <em>Semidefinite Programming</em> problems.</p>
<p>To define and analyze the MMWU algorithm, we need to introduce certain operations on matrices. We will always work with real-valued symmetric matrices, but everything generalizes to complex-valued Hermitian matrices. If <img alt="{M = \sum_i \lambda_i w_i w_i^T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM+%3D+%5Csum_i+%5Clambda_i+w_i+w_i%5ET%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a symmetric matrix, <img alt="{\lambda_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are the eigenvalues of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and <img alt="{w_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are corresponding orthonormal eigenvectors, then we will define a number of operations and functions on <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that operate on the eigenvalues while leaving the eigenvectors unchanged.</p>
<p>The first operation is <em>matrix exponentiation</em>: we define</p>
<p align="center"><img alt="\displaystyle  e^X := \sum_i e^{\lambda_i} w_i w_i^T " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5EX+%3A%3D+%5Csum_i+e%5E%7B%5Clambda_i%7D+w_i+w_i%5ET+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> The operation always defines a positive definite matrix, and the resulting matrix satisfies a “Taylor expansion”</p>
<p align="center"><img alt="\displaystyle  e^X = \sum_{k=0}^\infty \frac1 {k!} X^k " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5EX+%3D+%5Csum_%7Bk%3D0%7D%5E%5Cinfty+%5Cfrac1+%7Bk%21%7D+X%5Ek+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> Indeed, it is more common to use the above expansion as the definition of the matrix exponential, and then derive the expression in terms of eigenvalues.</p>
<p>We also have the useful bounds</p>
<p align="center"><img alt="\displaystyle  e^X \succeq I + X" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5EX+%5Csucceq+I+%2B+X&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> which is true for every <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and</p>
<p align="center"><img alt="\displaystyle  e^X \preceq I + X +X^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5EX+%5Cpreceq+I+%2B+X+%2BX%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> which is true for all <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that <img alt="{X \preceq I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%5Cpreceq+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>Analogously, if <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is positive definite, we can define</p>
<p align="center"><img alt="\displaystyle  \log X := \sum_i (\log \lambda_i) \cdot w_i w_i^T " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clog+X+%3A%3D+%5Csum_i+%28%5Clog+%5Clambda_i%29+%5Ccdot+w_i+w_i%5ET+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>and we have a number of identities like <img alt="{\log e^X = X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+e%5EX+%3D+X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, <img alt="{\log X^k = k \log X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+X%5Ek+%3D+k+%5Clog+X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, <img alt="{e^{k X} = e^k \cdot X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%5E%7Bk+X%7D+%3D+e%5Ek+%5Ccdot+X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, where <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a scalar. We should be careful, however, not to take the analogy with real numbers too far: for example, if <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are two symmetric matrices, in general it is not trues that <img alt="{e^{A+B} = e^A \cdot e^B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%5E%7BA%2BB%7D+%3D+e%5EA+%5Ccdot+e%5EB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, in fact the above expression is actually always false except when <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> commute, in which case it is trivially true. We have, however, the following extremely useful fact.</p>
<blockquote><p><b>Theorem 1 (Golden-Thompson Inequality)</b> <em> </em></p>
<p><em/></p><em>
<p align="center"><img alt="\displaystyle  {\rm tr}(e^{A+B}) \leq {\rm tr}(e^A \cdot e^B) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+tr%7D%28e%5E%7BA%2BB%7D%29+%5Cleq+%7B%5Crm+tr%7D%28e%5EA+%5Ccdot+e%5EB%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</em><p><em/><em> </em></p></blockquote>
<p>The Golden-Thompson inequality will be all we need to generalize to this matrix setting everything we have proved about multiplicative weights. See <a href="https://terrytao.wordpress.com/2010/07/15/the-golden-thompson-inequality/">this post by Terry Tao</a> for a proof.</p>
<p>The <em>Von Neumann entropy</em> of a density matrix <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with eigenvalues <img alt="{\lambda_1,\cdots,\lambda_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1%2C%5Ccdots%2C%5Clambda_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is defined as</p>
<p align="center"><img alt="\displaystyle  S(X) = \sum_i \lambda_i \log \frac 1 {\lambda_i} = - {\rm tr}(X\log X) = - X \bullet \log X " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S%28X%29+%3D+%5Csum_i+%5Clambda_i+%5Clog+%5Cfrac+1+%7B%5Clambda_i%7D+%3D+-+%7B%5Crm+tr%7D%28X%5Clog+X%29+%3D+-+X+%5Cbullet+%5Clog+X+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> that is, if we view <img alt="{X = \sum_i \lambda_i v_i v_i^T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%5Csum_i+%5Clambda_i+v_i+v_i%5ET%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as the mixed quantum state in which the pure state <img alt="{v_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> has probability <img alt="{\lambda_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then <img alt="{S(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the entropy of the distribution over the pure states. Again, this is not a particularly helpful point of view, and in fact we will be interested in defining <img alt="{S(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> not just for density matrices <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> but for arbitrary positive definite matrices, and even positive semidefinite (with the convention that <img alt="{0 \log 0 = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%5Clog+0+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which is used also in the standard definition of entropy of a distribution).</p>
<p>We will be interested in using Von Neumann entropy as a regularizer, and hence we will want to know what is its Bregman divergence. Some calculations show that the Bregman divergence of the Von Neumann entropy, which is called the quantum relative entropy, is</p>
<p align="center"><img alt="\displaystyle  S(X_1|| X_2) = {\rm tr} (X_1 \cdot ( \log X_1 - \log X_2)) + {\rm tr}(X_2) - {\rm tr}(X_1) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S%28X_1%7C%7C+X_2%29+%3D+%7B%5Crm+tr%7D+%28X_1+%5Ccdot+%28+%5Clog+X_1+-+%5Clog+X_2%29%29+%2B+%7B%5Crm+tr%7D%28X_2%29+-+%7B%5Crm+tr%7D%28X_1%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p align="center"><img alt="\displaystyle  = X_1 \bullet(\log X_1 - \log X_2) + I \bullet (X_2 - X_1) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+X_1+%5Cbullet%28%5Clog+X_1+-+%5Clog+X_2%29+%2B+I+%5Cbullet+%28X_2+-+X_1%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> If <img alt="{X_1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{X_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are density matrices, the terms <img alt="{{\rm tr}(X_2) - {\rm tr}(X_1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+tr%7D%28X_2%29+-+%7B%5Crm+tr%7D%28X_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> cancel out; the above definition is valid for arbitrary positive definite matrices.</p>
<p>We will have to study the minima of various functions that take a matrix as an input, so it is good to understand how to compute the gradient of such functions. For example what is the gradient of the function <img alt="{{\rm tr}(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Crm+tr%7D%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>? Working through the definition we see that <img alt="{\nabla {\rm tr}(X) = I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cnabla+%7B%5Crm+tr%7D%28X%29+%3D+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and indeed we always have that the gradient of the function <img alt="{X \rightarrow A\bullet X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%5Crightarrow+A%5Cbullet+X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> everywhere. Somewhat less obvious is the calculation of the gradient of the Von Neumann entropy, which is</p>
<p align="center"><img alt="\displaystyle  \nabla (X \bullet \log X) = I + \log X " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cnabla+%28X+%5Cbullet+%5Clog+X%29+%3D+I+%2B+%5Clog+X+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p><b>2. Analysis in the Constrained FTRL Framework </b></p>
<p>Suppose that we play that we described above using agile mirror descent and using negative Von Neumann entropy (appropriately scaled) as a regularizer. That is, for some <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that we will choose later, we use the regularizer</p>
<p align="center"><img alt="\displaystyle  R(X) = c X \bullet \log X" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++R%28X%29+%3D+c+X+%5Cbullet+%5Clog+X&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> which has the Bregman divergence</p>
<p align="center"><img alt="\displaystyle  D(X_1,X_2) = c S(X_1 || X_2) = c X_1 \bullet (\log X_1 - \log X_2) + cI \bullet (X_2 - X_1) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%28X_1%2CX_2%29+%3D+c+S%28X_1+%7C%7C+X_2%29+%3D+c+X_1+%5Cbullet+%28%5Clog+X_1+-+%5Clog+X_2%29+%2B+cI+%5Cbullet+%28X_2+-+X_1%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and our feasible set is the set of density matrices</p>
<p align="center"><img alt="\displaystyle  \Delta := \{ X\in {\mathbb R}^{n\times n} : X \succeq {\bf 0} \wedge {\rm tr}(X) = 1 \} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5CDelta+%3A%3D+%5C%7B+X%5Cin+%7B%5Cmathbb+R%7D%5E%7Bn%5Ctimes+n%7D+%3A+X+%5Csucceq+%7B%5Cbf+0%7D+%5Cwedge+%7B%5Crm+tr%7D%28X%29+%3D+1+%5C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> To bound the regret, we just have to plug the above definitions into the machinery that we developed <a href="https://lucatrevisan.wordpress.com/2019/05/20/online-optimization-post-5-bregman-projections-and-mirror-descent/">in our fifth post</a>.</p>
<p>At time 1, we play the identity matrix scaled by n, which is a density matrix of maximum Von Neumann entropy <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>:</p>
<p align="center"><img alt="\displaystyle  X_1 := \arg\min_{X \in \Delta} R(X) = \frac 1n I " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X_1+%3A%3D+%5Carg%5Cmin_%7BX+%5Cin+%5CDelta%7D+R%28X%29+%3D+%5Cfrac+1n+I+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> At time <img alt="{t+1\geq 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%2B1%5Cgeq+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we play the matrix <img alt="{X_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> obtained as</p>
<p align="center"><img alt="\displaystyle  \hat X_{t+1} = \arg\min_{X} D(X,X_{t}) + X\bullet L_{t} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Chat+X_%7Bt%2B1%7D+%3D+%5Carg%5Cmin_%7BX%7D+D%28X%2CX_%7Bt%7D%29+%2B+X%5Cbullet+L_%7Bt%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p align="center"><img alt="\displaystyle  X_{t+1} = \arg\min_{X\in \Delta} D(X,\hat X_{t+1}) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X_%7Bt%2B1%7D+%3D+%5Carg%5Cmin_%7BX%5Cin+%5CDelta%7D+D%28X%2C%5Chat+X_%7Bt%2B1%7D%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and recall that we proved that, after <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> steps,</p>
<p align="center"><img alt="\displaystyle  Regret_T(X) \leq D(X,X_1) + \sum_{t=1}^T D(X_t,\hat X_{t+1}) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++Regret_T%28X%29+%5Cleq+D%28X%2CX_1%29+%2B+%5Csum_%7Bt%3D1%7D%5ET+D%28X_t%2C%5Chat+X_%7Bt%2B1%7D%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>If <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a density matrix with eigenvalues <img alt="{\lambda_1,\ldots,\lambda_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1%2C%5Cldots%2C%5Clambda_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then the first term is</p>
<p align="center"><img alt="\displaystyle  D \left( X, \frac 1n I \right) = c X \bullet (\log X - \log n^{-1} I) = c \sum_i \lambda_i \log \frac n{\lambda_i} = c \log n - c \sum_i \lambda_i \frac 1 {\lambda_i} \leq c\log n " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D+%5Cleft%28+X%2C+%5Cfrac+1n+I+%5Cright%29+%3D+c+X+%5Cbullet+%28%5Clog+X+-+%5Clog+n%5E%7B-1%7D+I%29+%3D+c+%5Csum_i+%5Clambda_i+%5Clog+%5Cfrac+n%7B%5Clambda_i%7D+%3D+c+%5Clog+n+-+c+%5Csum_i+%5Clambda_i+%5Cfrac+1+%7B%5Clambda_i%7D+%5Cleq+c%5Clog+n+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> To complete the analysis we have to understand <img alt="{\hat X_{t+1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Chat+X_%7Bt%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. We need to compute the gradient <img alt="{X \rightarrow D(X,X_{t}) + X\bullet L_{t} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%5Crightarrow+D%28X%2CX_%7Bt%7D%29+%2B+X%5Cbullet+L_%7Bt%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and set it to zero. The gradient of <img alt="{X\bullet L_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%5Cbullet+L_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is just <img alt="{L_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The gradient of <img alt="{D(X,X_{t})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%28X%2CX_%7Bt%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is</p>
<p align="center"><img alt="\displaystyle  \nabla D(X,X_t) = c \nabla X \bullet \log X - c \nabla X \bullet \log X_t - \nabla c X \bullet I " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cnabla+D%28X%2CX_t%29+%3D+c+%5Cnabla+X+%5Cbullet+%5Clog+X+-+c+%5Cnabla+X+%5Cbullet+%5Clog+X_t+-+%5Cnabla+c+X+%5Cbullet+I+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p align="center"><img alt="\displaystyle  = cI + c \log X - c \log X_t - cI " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+cI+%2B+c+%5Clog+X+-+c+%5Clog+X_t+-+cI+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> Meaning that we want to solve for</p>
<p align="center"><img alt="\displaystyle  c \log X - c\log X_t + L_t = 0 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%5Clog+X+-+c%5Clog+X_t+%2B+L_t+%3D+0+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and <img alt="{\hat X_{t+1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Chat+X_%7Bt%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> satisfies</p>
<p align="center"><img alt="\displaystyle \log X_t - \log \hat X_{t+1} = \frac 1c L_t " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clog+X_t+-+%5Clog+%5Chat+X_%7Bt%2B1%7D+%3D+%5Cfrac+1c+L_t+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p align="center"><img alt="\displaystyle  \hat X_{t+1} = e^{\log X_t - \frac 1c L_t } " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Chat+X_%7Bt%2B1%7D+%3D+e%5E%7B%5Clog+X_t+-+%5Cfrac+1c+L_t+%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and we can write</p>
<p align="center"><img alt="\displaystyle  D(X_t,\hat X_{t+1} ) = c \cdot \left( X_t \bullet (\log X_t - \log \hat X_{t+1})\right) + c {\rm tr}( \hat X_{t+1} )" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%28X_t%2C%5Chat+X_%7Bt%2B1%7D+%29+%3D+c+%5Ccdot+%5Cleft%28+X_t+%5Cbullet+%28%5Clog+X_t+-+%5Clog+%5Chat+X_%7Bt%2B1%7D%29%5Cright%29+%2B+c+%7B%5Crm+tr%7D%28+%5Chat+X_%7Bt%2B1%7D+%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p align="center"><img alt="\displaystyle  = c \cdot X_t \bullet \frac 1c L_t + c \cdot {\rm tr}(e^{\log X_t - \frac 1c L_t}) + c {\rm tr} \hat X_{t+1} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+c+%5Ccdot+X_t+%5Cbullet+%5Cfrac+1c+L_t+%2B+c+%5Ccdot+%7B%5Crm+tr%7D%28e%5E%7B%5Clog+X_t+-+%5Cfrac+1c+L_t%7D%29+%2B+c+%7B%5Crm+tr%7D+%5Chat+X_%7Bt%2B1%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> Then we can use Golden-Thompson and the fact that <img alt="{e^-\frac 1c L_t \preceq I - \frac 1c L_t + \frac 1{c^2} L^2_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%5E-%5Cfrac+1c+L_t+%5Cpreceq+I+-+%5Cfrac+1c+L_t+%2B+%5Cfrac+1%7Bc%5E2%7D+L%5E2_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which holds if <img alt="{L_t \preceq cI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t+%5Cpreceq+cI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, to write</p>
<p align="center"><img alt="\displaystyle  {\rm tr}(e^{\log X_t - \frac 1c L_t}) \leq {\rm tr}(e^{\log X_t} \cdot e^{-\frac 1c L_t} ) = X_t \bullet e^{-\frac 1c L_t} \leq X_t \bullet \left( I - \frac 1c L_t + \frac 1{c^2} L^2_t \right) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+tr%7D%28e%5E%7B%5Clog+X_t+-+%5Cfrac+1c+L_t%7D%29+%5Cleq+%7B%5Crm+tr%7D%28e%5E%7B%5Clog+X_t%7D+%5Ccdot+e%5E%7B-%5Cfrac+1c+L_t%7D+%29+%3D+X_t+%5Cbullet+e%5E%7B-%5Cfrac+1c+L_t%7D+%5Cleq+X_t+%5Cbullet+%5Cleft%28+I+-+%5Cfrac+1c+L_t+%2B+%5Cfrac+1%7Bc%5E2%7D+L%5E2_t+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> Combining everything together we have</p>
<p align="center"><img alt="\displaystyle  D(X_t,\hat X_{t+1} ) \leq \frac 1c X_t \bullet L_t^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%28X_t%2C%5Chat+X_%7Bt%2B1%7D+%29+%5Cleq+%5Cfrac+1c+X_t+%5Cbullet+L_t%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and so, provided <img alt="{\lambda_{\max} (L_t) \leq c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_%7B%5Cmax%7D+%28L_t%29+%5Cleq+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>,</p>
<p align="center"><img alt="\displaystyle  Regret_T \leq c \log n + \frac 1c \sum_{t=1}^T X_t \bullet L_t^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++Regret_T+%5Cleq+c+%5Clog+n+%2B+%5Cfrac+1c+%5Csum_%7Bt%3D1%7D%5ET+X_t+%5Cbullet+L_t%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> This is the best bound we can hope for, and it matches Theorem 1 in <a href="https://lucatrevisan.wordpress.com/2019/04/24/online-optimization-post-1-multiplicative-weights/">our first post</a> about the Xultiplicative Weights Update algorithm.</p>
<p>If we have <img alt="{L_t \preceq I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t+%5Cpreceq+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we can simplify it to</p>
<p align="center"><img alt="\displaystyle  Regret_T \leq c \log n + \frac T c = 2 \sqrt{T \log n} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++Regret_T+%5Cleq+c+%5Clog+n+%2B+%5Cfrac+T+c+%3D+2+%5Csqrt%7BT+%5Clog+n%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> where the last step comes from optimizing <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>We can also write, under the condition <img alt="{L_t \preceq c I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t+%5Cpreceq+c+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>,</p>
<p align="center"><img alt="\displaystyle  Regret_T (X) \leq c \log n + \frac 1c \sum_{t=1}^T (X_t \bullet |L_t| )||L_t|| " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++Regret_T+%28X%29+%5Cleq+c+%5Clog+n+%2B+%5Cfrac+1c+%5Csum_%7Bt%3D1%7D%5ET+%28X_t+%5Cbullet+%7CL_t%7C+%29%7C%7CL_t%7C%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> where <img alt="{|L_t|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CL_t%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is the “absolute value” of the matrix <img alt="{L_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> defined in the following way: if <img alt="{X = \sum_i \lambda_i v_i v_i^T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%5Csum_i+%5Clambda_i+v_i+v_i%5ET%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a symmetric matrix, then its absolute value is <img alt="{|X| = \sum_i |\lambda_i| \cdot v_i v_i^T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CX%7C+%3D+%5Csum_i+%7C%5Clambda_i%7C+%5Ccdot+v_i+v_i%5ET%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Allen-Zhu, Liao and Orecchia state the analysis in this way in their <a href="https://arxiv.org/abs/1506.04838">on generalizations of Matrix Multiplicative Weights</a>.</p>
<p>Our next post will discuss applications at length, but for now let us gain a bit of intuition about the usefulness of these regret bounds. Recall that, for every symmetric matrix <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we have</p>
<p align="center"><img alt="\displaystyle  \lambda_{\min} (M) = \min_{X \rm\ density\ matrix} \ \ X \bullet M " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_%7B%5Cmin%7D+%28M%29+%3D+%5Cmin_%7BX+%5Crm%5C+density%5C+matrix%7D+%5C+%5C+X+%5Cbullet+M+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> and so the regret bound can be reintepreted in the following way: if we let <img alt="{L_1,\ldots,L_T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_1%2C%5Cldots%2CL_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be the loss functions used in a game played against a MMWU algorithm, and the algorithm selects density matrices <img alt="{X_1,\ldots,X_T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_1%2C%5Cldots%2CX_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then</p>
<p align="center"><img alt="\displaystyle  \sum_{t=1}^T X_t \bullet L_t - \min_{X \rm \ density \ matrix} \ \ X \bullet \sum_{t=1}^T L_t \leq c \log n + \frac 1c \sum_{t=1}^T X_t \bullet L_t^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bt%3D1%7D%5ET+X_t+%5Cbullet+L_t+-+%5Cmin_%7BX+%5Crm+%5C+density+%5C+matrix%7D+%5C+%5C+X+%5Cbullet+%5Csum_%7Bt%3D1%7D%5ET+L_t+%5Cleq+c+%5Clog+n+%2B+%5Cfrac+1c+%5Csum_%7Bt%3D1%7D%5ET+X_t+%5Cbullet+L_t%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> that is,</p>
<p align="center"><img alt="\displaystyle  \sum_{t=1}^T X_t \bullet L_t - \lambda_{\min} \left( \sum_{t=1}^T L_t \right) \leq c \log n + \frac 1c \sum_{t=1}^T X_t \bullet L_t^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bt%3D1%7D%5ET+X_t+%5Cbullet+L_t+-+%5Clambda_%7B%5Cmin%7D+%5Cleft%28+%5Csum_%7Bt%3D1%7D%5ET+L_t+%5Cright%29+%5Cleq+c+%5Clog+n+%2B+%5Cfrac+1c+%5Csum_%7Bt%3D1%7D%5ET+X_t+%5Cbullet+L_t%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p> provided that <img alt="{L_t \preceq cI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t+%5Cpreceq+cI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. For example, switching <img alt="{L_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with <img alt="{-L_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-L_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, we have <a name="main"/></p>
<p><a name="main"/></p><a name="main">
<p align="center"><img alt="\displaystyle   \lambda_{\max} \left( \sum_{t=1}^T L_t \right) \leq \sum_{t=1}^T X_t \bullet L_t + \frac 1c \sum_{t=1}^T X_t \bullet L_t^2 + c\log n \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5Clambda_%7B%5Cmax%7D+%5Cleft%28+%5Csum_%7Bt%3D1%7D%5ET+L_t+%5Cright%29+%5Cleq+%5Csum_%7Bt%3D1%7D%5ET+X_t+%5Cbullet+L_t+%2B+%5Cfrac+1c+%5Csum_%7Bt%3D1%7D%5ET+X_t+%5Cbullet+L_t%5E2+%2B+c%5Clog+n+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</a><p><a name="main"/><a name="main"/> provided that <img alt="{L_t \succeq -cI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_t+%5Csucceq+-cI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which means that if we can choose a sequence of loss matrices that make the MMWU have small loss at each step, then we are guaranteed that the sum of such matrices cannot have any large eigenvalue.</p></div>
    </content>
    <updated>2021-11-10T12:11:57Z</updated>
    <published>2021-11-10T12:11:57Z</published>
    <category term="theory"/>
    <category term="matrix multiplicative weights update"/>
    <category term="online optimization"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2021-11-15T09:37:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/154</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/154" rel="alternate" type="text/html"/>
    <title>TR21-154 |  Explicit Binary Tree Codes with Sub-Logarithmic Size Alphabet | 

	Gil Cohen, 

	Inbar Ben Yaacov, 

	Tal Yankovitz</title>
    <summary>Since they were first introduced by Schulman (STOC 1993), the construction of tree codes remained an elusive open problem. The state-of-the-art construction by Cohen, Haeupler and Schulman (STOC 2018) has constant distance and $(\log n)^{e}$ colors for some constant $e &gt; 1$ that depends on the distance, where $n$ is the depth of the tree. Insisting on a constant number of colors at the expense of having vanishing distance, Gelles, Haeupler, Kol, Ron-Zewi, and Wigderson (SODA 2016) constructed a distance $\Omega(\frac1{\log n})$ tree code.

In this work we improve upon these prior works and construct a distance-$\delta$ tree code with $(\log{n})^{O(\sqrt{\delta})}$ colors. This is the first construction of a constant distance tree code with sub-logarithmic number of colors. Moreover, as a direct corollary we obtain a tree code with a constant number of colors and distance $\Omega\left(\frac1{(\log\log{n})^{2}}\right)$, exponentially improving upon the above-mentioned work by Gelles et al.</summary>
    <updated>2021-11-10T11:16:50Z</updated>
    <published>2021-11-10T11:16:50Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-11-15T09:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/11/09/christopher-strachey-professorship-of-computing-at-university-of-oxford-apply-by-february-28-2022/</id>
    <link href="https://cstheory-jobs.org/2021/11/09/christopher-strachey-professorship-of-computing-at-university-of-oxford-apply-by-february-28-2022/" rel="alternate" type="text/html"/>
    <title>Christopher Strachey Professorship of Computing at University of Oxford (apply by February 28, 2022)</title>
    <summary>The Strachey Professorship is the oldest chair in the Department of Computer Science, and is named for Christopher Strachey, who founded Oxford’s Programming Research Group in 1965. The Department seeks an internationally recognised research leader who will further the academic and strategic development of the department. Website: http://www.cs.ox.ac.uk/news/1988-full.html Email: head-of-dept@cs.ox.ac.uk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Strachey Professorship is the oldest chair in the Department of Computer Science, and is named for Christopher Strachey, who founded Oxford’s Programming Research Group in 1965. The Department seeks an internationally recognised research leader who will further the academic and strategic development of the department.</p>
<p>Website: <a href="http://www.cs.ox.ac.uk/news/1988-full.html">http://www.cs.ox.ac.uk/news/1988-full.html</a><br/>
Email: head-of-dept@cs.ox.ac.uk</p></div>
    </content>
    <updated>2021-11-09T18:24:49Z</updated>
    <published>2021-11-09T18:24:49Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-11-15T09:37:51Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/neurips2021/</id>
    <link href="https://differentialprivacy.org/neurips2021/" rel="alternate" type="text/html"/>
    <title>Conference Digest - NeurIPS 2021</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The accepted papers for <a href="https://neurips.cc/Conferences/2020">NeurIPS 2021</a> were recently announced, and there’s a huge amount of differential privacy content. 
We found one relevant workshop and 48 papers.
This is up from 31 papers last year, an over 50% increase!
It looks like there’s huge growth in interest on differentially private machine learning.
Impressively, at the time of this writing, all but five papers are already posted on arXiv!
For the full list of accepted papers, see <a href="https://neurips.cc/Conferences/2021/AcceptedPapersInitial">here</a>.
Please let us know if we missed relevant papers on differential privacy!</p>

<h2 id="workshops">Workshops</h2>

<ul>
  <li><a href="https://priml2021.github.io/">Privacy in Machine Learning (PriML) 2021</a></li>
</ul>

<h2 id="papers">Papers</h2>

<ul>
  <li>
    <p><a href="https://arxiv.org/abs/2103.08721">A Central Limit Theorem for Differentially Private Query Answering</a><br/>
Jinshuo Dong, Weijie Su, Linjun Zhang</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2108.02391">Adapting to function difficulty and growth conditions in private optimization</a><br/>
Hilal Asi, Daniel Levy, John Duchi</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2106.04378">Adaptive Machine Unlearning</a><br/>
Varun Gupta, Christopher Jung, Seth Neel, Aaron Roth, Saeed Sharifi-Malvajerdi, Chris Waites</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2110.13239">An Uncertainty Principle is a Price of Privacy-Preserving Microdata</a><br/>
John Abowd, Robert Ashmead, Ryan Cumings-Menon, Simson Garfinkel, Daniel Kifer, Philip Leclerc, William Sexton, Ashley Simpson, Christine Task, Pavel Zhuravlev</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2106.03408">Antipodes of Label Differential Privacy: PATE and ALIBI</a><br/>
Mani Malek Esmaeili, Ilya Mironov, Karthik Prasad, Igor Shilov, Florian Tramer</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2106.13329">Covariance-Aware Private Mean Estimation Without Private Covariance Estimation</a><br/>
Gavin Brown, Marco Gaboardi, Adam Smith, Jonathan Ullman, Lydia Zakynthinou</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.06062">Deep Learning with Label Differential Privacy</a><br/>
Badih Ghazi, Noah Golowich, Ravi Kumar, Pasin Manurangsi, Chiyuan Zhang</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.05855">Differential Privacy Dynamics of Langevin Diffusion and Noisy Gradient Descent</a><br/>
Rishav Chourasia, Jiayuan Ye, Reza Shokri</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2106.02674">Differentially Private Empirical Risk Minimization under the Fairness Lens</a><br/>
Cuong Tran, My Dinh, Ferdinando Fioretto</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2110.14153">Differentially Private Federated Bayesian Optimization with Distributed Exploration</a><br/>
Zhongxiang Dai, Bryan Kian Hsiang Low, Patrick Jaillet</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1905.03871">Differentially Private Learning with Adaptive Clipping</a><br/>
Galen Andrew, Om Thakkar, Swaroop Ramaswamy, Brendan McMahan</p>
  </li>
  <li>
    <p>Differentially Private Model Personalization<br/>
Prateek Jain, John Rush, Adam Smith, Shuang Song, Abhradeep Guha Thakurta</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2106.02900">Differentially Private Multi-Armed Bandits in the Shuffle Model</a><br/>
Jay Tenenbaum, Haim Kaplan, Yishay Mansour, Uri Stemmer</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2108.02831">Differentially Private n-gram Extraction</a><br/>
Kunho Kim, Sivakanth Gopi, Janardhan Kulkarni, Sergey Yekhanin</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2111.02516">Differential Privacy Over Riemannian Manifolds</a><br/>
Matthew Reimherr, Karthik Bharath, Carlos Soto</p>
  </li>
  <li>
    <p>Differentially Private Sampling from Distributions<br/>
Sofya Raskhodnikova, Satchit Sivakumar, Adam Smith, Marika Swanberg</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2107.05585">Differentially Private Stochastic Optimization: New Results in Convex and Non-Convex Settings</a><br/>
Raef Bassily, Cristóbal Guzmán, Michael Menart</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2111.01177">Don’t Generate Me: Training Differentially Private Generative Models with Sinkhorn Divergence</a><br/>
Tianshi Cao, Alex Bie, Arash Vahdat, Sanja Fidler, Karsten Kreis</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2010.09063">Enabling Fast Differentially Private SGD via Just-in-Time Compilation and Vectorization</a><br/>
Pranav Subramani, Nicholas Vadivelu, Gautam Kamath</p>
  </li>
  <li>
    <p>Exact Privacy Guarantees for Markov Chain Implementations of the Exponential Mechanism with Artificial Atoms<br/>
Jeremy Seeman, Matthew Reimherr, Aleksandra Slavković</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.03013">Fast and Memory Efficient Differentially Private-SGD via JL Projections</a><br/>
Zhiqi Bu, Sivakanth Gopi, Janardhan Kulkarni, Yin Tat Lee, Hanwen Shen, Uthaipon Tantipongpipat</p>
  </li>
  <li>
    <p>G-PATE: Scalable Differentially Private Data Generator via Private Aggregation of Teacher Discriminators<br/>
Yunhui Long, Boxin Wang, Zhuolin Yang, Bhavya Kailkhura, Aston Zhang, Carl Gunter, Bo Li</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2106.03365">Generalized Linear Bandits with Local Differential Privacy</a><br/>
Yuxuan Han, Zhipeng Liang, Yang Wang, Jiheng Zhang</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2008.11193">Individual Privacy Accounting via a Rényi Filter</a><br/>
Vitaly Feldman, Tijana Zrnic</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2104.00979">Information-constrained optimization: can adaptive processing of gradients help?</a><br/>
Jayadev Acharya, Clement Canonne, Prathamesh Mayekar, Himanshu Tyagi</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2106.00463">Instance-optimal Mean Estimation Under Differential Privacy</a><br/>
Ziyue Huang, Yuting Liang, Ke Yi</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2106.07153">Iterative Methods for Private Synthetic Data: Unifying Framework and New Methods</a><br/>
Terrance Liu, Giuseppe Vietri, Steven Wu</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.11845">Learning with User-Level Privacy</a><br/>
Daniel Levy, Ziteng Sun, Kareem Amin, Satyen Kale, Alex Kulesza, Mehryar Mohri, Ananda Theertha Suresh</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2106.13513">Littlestone Classes are Privately Online Learnable</a><br/>
Noah Golowich, Roi Livni</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2010.07778">Local Differential Privacy for Regret Minimization in Reinforcement Learning</a><br/>
Evrard Garcelon, Vianney Perchet, Ciara Pike-Burke, Matteo Pirotta</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2107.03940">Locally differentially private estimation of functionals of discrete distributions</a><br/>
Cristina Butucea, Yann Issartel</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2105.10675">Locally private online change point detection</a><br/>
Tom Berrett, Yi Yu</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2107.10870">Multiclass versus Binary Differentially Private PAC Learning</a><br/>
Satchit Sivakumar, Mark Bun, Marco Gaboardi</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2106.02848">Numerical Composition of Differential Privacy</a><br/>
Sivakanth Gopi, Yin Tat Lee, Lukas Wutschitz</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2107.11526">On the Sample Complexity of Privately Learning Axis-Aligned Rectangles</a><br/>
Menachem Sadigurschi, Uri Stemmer</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2106.03645">Photonic Differential Privacy with Direct Feedback Alignment</a><br/>
Ruben Ohana, Hamlet Medina, Julien Launay, Alessandro Cappelli, Iacopo Poli, Liva Ralaivola, Alain Rakotomamonjy</p>
  </li>
  <li>
    <p>Private and Non-private Uniformity Testing for Ranking Data<br/>
Róbert Busa-Fekete, Dimitris Fotakis, Emmanouil Zampetakis</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.07171">Private learning implies quantum stability</a><br/>
Yihui Quek, Srinivasan Arunachalam, John A Smolin</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2103.15352">Private Non-smooth ERM and SCO in Subquadratic Steps</a><br/>
Janardhan Kulkarni, Yin Tat Lee, Daogao Liu</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2106.02162">Privately Learning Mixtures of Axis-Aligned Gaussians</a><br/>
Ishaq Aden-Ali, Hassan Ashtiani, Christopher Liaw</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2106.00001">Privately Learning Subspaces</a><br/>
Vikrant Singhal, Thomas Steinke</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2111.02281">Privately Publishable Per-instance Privacy</a><br/>
Rachel Redberg, Yu-Xiang Wang</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2109.06153">Relaxed Marginal Consistency for Differentially Private Query Answering</a><br/>
Ryan McKenna, Siddhant Pradhan, Daniel Sheldon, Gerome Miklau</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2103.03279">Remember What You Want to Forget: Algorithms for Machine Unlearning</a><br/>
Ayush Sekhari, Jayadev Acharya, Gautam Kamath, Ananda Theertha Suresh</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2107.08763">Renyi Differential Privacy of The Subsampled Shuffle Model In Distributed Learning</a><br/>
Antonious Girgis, Deepesh Data, Suhas Diggavi</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.09159">Robust and differentially private mean estimation</a><br/>
Xiyang Liu, Weihao Kong, Sham Kakade, Sewoong Oh</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2110.04995">The Skellam Mechanism for Differentially Private Federated Learning</a><br/>
Naman Agarwal, Peter Kairouz, Ken Liu</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2110.11208">User-Level Differentially Private Learning via Correlated Sampling</a><br/>
Badih Ghazi, Ravi Kumar, Pasin Manurangsi</p>
  </li>
</ul></div>
    </summary>
    <updated>2021-11-09T15:00:00Z</updated>
    <published>2021-11-09T15:00:00Z</published>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2021-11-14T23:11:17Z</updated>
    </source>
  </entry>
</feed>
