<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-04-24T22:24:09Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-US">
    <id>https://www.let-all.com/blog/?p=39</id>
    <link href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/" rel="alternate" type="text/html"/>
    <title>Introducing ALT Highlights 2021</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The 32nd International Conference on Algorithmic Learning Theory (ALT 2021) just wrapped up, featuring a wide selection of exciting results at the frontiers of learning theory. The proceedings and all talk recordings are available online for perusal.  Did you miss out on the conference? Don’t have time to go through all the proceedings? Fear not, […]</p>
<p>The post <a href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/" rel="nofollow">Introducing ALT Highlights 2021</a> appeared first on <a href="https://www.let-all.com/blog" rel="nofollow">The Learning Theory Alliance Blog</a>.</p></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The 32nd International Conference on Algorithmic Learning Theory (<a href="http://algorithmiclearningtheory.org/alt2021/">ALT 2021</a>) just wrapped up, featuring a wide selection of exciting results at the frontiers of learning theory. The <a href="http://proceedings.mlr.press/v132/">proceedings</a> and all <a href="https://www.youtube.com/channel/UC7wMo5OivSnsQJNfZm8zmJQ/videos">talk recordings</a> are available online for perusal. </p>



<p>Did you miss out on the conference? Don’t have time to go through all the proceedings? Fear not, the <a href="https://let-all.com/">Learning Theory Alliance</a> is pleased to bring you ALT Highlights, a series of blog posts spotlighting various happenings at ALT, including plenary talks, tutorials, trends in learning theory, and more!</p>



<p>In order to reach a broad audience in learning theory, we’ll be releasing these posts across a number of different blogs. All content will be linked from this post, so be sure to bookmark this post so you don’t miss anything!</p>



<p>ALT Highlights will be brought to you by an amazing team of junior researchers, written by <a href="https://people.eecs.berkeley.edu/~kush/">Kush Bhatia</a>, <a href="https://www.comp.nus.edu.sg/~sutanu/">Sutanu Gayen</a>, <a href="https://web.stanford.edu/~mglasgow/">Margalit Glasgow</a>, <a href="https://sites.google.com/view/michal-moshkovitz">Michal Moshkovitz</a>, <a href="https://www.ttic.edu/students/">Keziah Naggita</a>, and <a href="https://sites.google.com/site/cyrusrashtchian/">Cyrus Rashtchian</a>, and overseen and edited by <a href="http://www.gautamkamath.com/">Gautam Kamath</a>. </p>



<p>Links to articles:<br/>1. <a href="https://hunch.net/?p=13762948">An Interview with Joelle Pineau</a></p>



<p>Next article coming April 26!</p>
<p>The post <a href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/" rel="nofollow">Introducing ALT Highlights 2021</a> appeared first on <a href="https://www.let-all.com/blog" rel="nofollow">The Learning Theory Alliance Blog</a>.</p></div>
    </content>
    <updated>2021-04-20T16:26:22Z</updated>
    <published>2021-04-20T16:26:22Z</published>
    <category term="ALT Highlights"/>
    <author>
      <name>admin</name>
    </author>
    <source>
      <id>https://www.let-all.com/blog</id>
      <logo>https://i1.wp.com/www.let-all.com/blog/wp-content/uploads/2021/04/logo.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://www.let-all.com/blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://www.let-all.com/blog" rel="alternate" type="text/html"/>
      <title>The Learning Theory Alliance Blog</title>
      <updated>2021-04-24T22:24:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1613</id>
    <link href="https://toc4fairness.org/ensuring-equity-in-high-stakes-online-advertising/" rel="alternate" type="text/html"/>
    <title>Ensuring equity in high-stakes online advertising</title>
    <summary>In this blog post, I outline how existing advertising platforms do not prevent high-stakes ads from reaching different demographics at different rates. The post then describes how pushing this responsibility ...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In this blog post, I outline how existing advertising platforms do not prevent high-stakes ads from reaching different demographics at different rates. The post then describes how pushing this responsibility down to advertisers rather than addressing it at the platform leaves manipulating a complex system to those least aware of the system’s inner workings. She then proposes a simpler, more unified solution to this problem: advertising slots should be either targetable or untargetable, and high-stakes ads should be in the untargeted segment. Finally, the post concludes with a discussion of how this segmentation need not cost these systems substantial revenue if reserve prices are used appropriately.</p>



<p/>



<p><a href="https://jamiemmt-cs.medium.com/ensuring-equity-in-online-advertising-for-employment-housing-and-credit-82931668c420">https://jamiemmt-cs.medium.com/ensuring-equity-in-online-advertising-for-employment-housing-and-credit-82931668c420</a></p></div>
    </content>
    <updated>2021-04-07T20:47:28Z</updated>
    <published>2021-04-07T20:47:28Z</published>
    <category term="Blog"/>
    <author>
      <name>jamiemorgenstern</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-04-24T22:24:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1551</id>
    <link href="https://toc4fairness.org/videos-up/" rel="alternate" type="text/html"/>
    <title>Videos Up</title>
    <summary>With a bit of a delay, we are starting to upload the videos of our seminar’s talks. The Inaugural Meeting of our seminar was devoted to a wonderful talk by ...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>With a bit of a delay, we are starting to upload the videos of our seminar’s talks. The <a href="https://toc4fairness.org/inaugural-meeting-toc4fairness-seminar-annette-zimmermann/">Inaugural Meeting</a> of our seminar was devoted to a wonderful talk by Dr. <a href="https://www.annette-zimmermann.com/">Annette Zimmermann</a>.  I highly recommend watching <a href="https://toc4fairness.org/inaugural-meeting-toc4fairness-seminar-annette-zimmermann-2/">the video</a>, and following up with some additional reading (some pointers below).</p>



<p>I won’t try to summarize the talk because I doubt that I can do it justice, but one of the themes (which I fully support) is that it is not enough to consider “fair” implementations of specific tasks. Instead, we (also) want to explore the right task to implement and if it is appropriate to implement any algorithmic task in any specific context. </p>



<p>As a side note, I loved Annette’s statement on ethics,  “if we can choose, we’re on the hook.” For me, it beautifully complements the paradigm that “ought implies can.” In other words, ethical imperatives only exist when the expected action is possible but every choice has ethical implications.   </p>



<hr class="wp-block-separator"/>



<p>Some resources for additional reading.</p>



<p><strong>Resources on exploitation</strong></p>



<p><strong>Introductory / very accessible for an interdisciplinary audience</strong></p>



<p>Nicholas Vrousalis, “Exploitation: A Primer,” <em>Philosophy Compass</em> 13, no. 2 (2018).</p>



<p><strong>Background</strong></p>



<p>G.A. Cohen, “The Labor Theory of Value and the Concept of Exploitation,” <em>Philosophy and Public Affairs</em> 8, no. 4 (1979): 338–360.</p>



<p>Joel Feinberg, <em>Harmless Wrongdoing</em>, Oxford: Oxford University Press (1988).`</p>



<p>Robert E. Goodin, “Exploiting a Situation and Exploiting a Person,” in Andrew Reeve (ed.), <em>Modern Theories of Exploitation</em>, London: Sage (1987), 166–200.</p>



<p>Ruth Sample, <em>Exploitation, What It Is and Why it is Wrong</em>, Lanham, MD: Rowman and Littlefield (2003).</p>



<p>Nicholas Vrousalis, “Exploitation, Vulnerability, and Social Domination,” <em>Philosophy and Public Affairs</em>, 41, no. 2 (2013): 131–157.</p>



<p>Alan Wertheimer, <em>Exploitation</em>, Princeton: Princeton University Press (1996).</p>



<p>Iris Marion Young, “Five Faces of Oppression,” in Thomas Wartenberg (ed.), <em>Rethinking Power</em>, Albany, NY: SUNY Press (1992).</p>



<p><strong>Resource on the political philosophy of AI (for a general audience)</strong></p>



<p>Annette Zimmermann, Elena Di Rosa, Hochan Kim, “<a href="http://bostonreview.net/science-nature-politics/annette-zimmermann-elena-di-rosa-hochan-kim-technology-cant-fix-algorithmic">Technology Can’t Fix Algorithmic Injustice</a>, <em>Boston Review</em> </p></div>
    </content>
    <updated>2021-03-25T22:50:07Z</updated>
    <published>2021-03-25T22:50:07Z</published>
    <category term="Blog"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-04-24T22:24:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1242</id>
    <link href="https://toc4fairness.org/how-to-estimate-the-uncertainty-of-predictions/" rel="alternate" type="text/html"/>
    <title>How to Estimate the Uncertainty of Predictions</title>
    <summary>This is a post about a new paper Online Multivalid Learning: Means, Moments, and Prediction Intervals, that is joint work with Varun Gupta, Christopher Jung, Georgy Noarov, and Mallesh Pai. ...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="has-text-align-center">This is a post about a new paper <em><a href="https://arxiv.org/abs/2101.01739">Online Multivalid Learning: Means, Moments, and Prediction Intervals</a></em>, that is joint work with Varun Gupta, Christopher Jung, Georgy Noarov, and Mallesh Pai.  For those that prefer watching to reading, you can also see <a href="https://youtu.be/8Hy09Ot2tDw">a talk I gave about this</a>. </p>



<p>Suppose you go and train the latest, greatest machine learning architecture to predict something important. Say (to pick an example entirely out of thin air) you are in the midst of a pandemic, and want to predict the severity of patients’ symptoms in 2 days time, so as to triage scarce medical resources. Since you will be using these predictions to make decisions, you would like them to be accurate in various ways: for example, at the very least, you will want your predictions to be calibrated, and you may also want to be able to accurately quantify the uncertainty of your predictions (say with 95% prediction intervals). It is a fast moving situation, and data is coming in dynamically — and you need to make decisions as you go. What can you do? </p>



<p>The first thing you might do is <a href="https://twitter.com/Aaroth/status/1272545845603434497">ask on twitter</a>! What you will find is that the standard tool for quantifying uncertainty in settings like this is <a href="https://jmlr.csail.mit.edu/papers/volume9/shafer08a/shafer08a.pdf">conformal prediction</a>. The conformal prediction literature has a number of elegant techniques for endowing arbitrary point prediction methods with <em>marginal prediction intervals</em>: i.e intervals <img alt="(\ell(x), u(x))" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cell%28x%29%2C+u%28x%29%29&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> such that over the randomness of some data distribution over labelled examples <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>: <img alt="\Pr_{(x,y)}\left[y \in [\ell(x), u(x)]\right] \approx 0.95" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr_%7B%28x%2Cy%29%7D%5Cleft%5By+%5Cin+%5B%5Cell%28x%29%2C+u%28x%29%5D%5Cright%5D+%5Capprox+0.95&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> These would be 95% marginal prediction intervals — but in general you could pick your favorite coverage probability <img alt="1-\delta" class="latex" src="https://s0.wp.com/latex.php?latex=1-%5Cdelta&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>.  </p>



<p>Conformal prediction has a lot going for it — its tools are very general and flexible, and lead to practical algorithms. But it also has two well known shortcomings:</p>



<ol><li><strong>Strong Assumptions</strong>. Like many tools from statistics and machine learning, conformal prediction methods require that the future look like the past. In particular, they require that the data be drawn i.i.d. from some distribution — or at least be <em>exchangable</em> (i.e. their distribution should be invariant to permutation). This is sometimes the case — but it often is not. In our pandemic scenario, the distribution on patient features might quickly change in unexpected ways as the disease moves between different populations, as might the relationship between features and outcomes, as treatments advance. In other settings in which consequential decisions are being made about people — like lending and hiring decisions — people might intentionally manipulate their features in response to the predictive algorithms you deploy, in an attempt to get the outcome they want. Or you might be trying to predict outcomes in time series data, in which there are explicit dependencies across time. In all of these scenarios, exchangeability is violated.</li><li><strong>Weak Guarantees</strong>. Marginal coverage guarantees are <em>averages over people</em>. 95% marginal coverage means that the true label falls within the predicted interval for 95% of people. It need not mean anything for <em>people like you</em>. For example, if you are part of a demographic group that makes up less than 5% of the population, it is entirely consistent with the guarantees of a 95% marginal prediction interval that labels for people from your demographic group fall outside of their intervals 100% of the time. This can be both an accuracy and a <strong><em>fairness</em> </strong>concern — marginal prediction works well for “typical” members of a population, but not necessarily for everyone else. </li></ol>



<p>What kinds of improvements might we hope for? Lets start with how to strengthen the guarantee:</p>



<p><strong>Multivalidity</strong> Ideally, we would want <em>conditional</em> guarantees — i.e. the promise that for every <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>, that we would have <img alt="\Pr_{y}\left[y \in [\ell(x), u(x)] | x \right] \approx 0.95" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr_%7By%7D%5Cleft%5By+%5Cin+%5B%5Cell%28x%29%2C+u%28x%29%5D+%7C+x+%5Cright%5D+%5Capprox+0.95&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>. In other words, that somehow for each individual, the prediction interval was valid for them specifically, over the “unrealized” (or unmeasured) randomness of the world. Of course this is too much to hope for. In a rich feature space, we have likely never seen anyone exactly like you before (i.e. with your feature vector <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>). So strictly speaking, we have no information at all about your conditional label distribution. We still have to average over people. But we don’t have to average over everybody. An important idea that has been investigated in <a href="https://arxiv.org/abs/1711.08513">several </a><a href="https://arxiv.org/abs/1711.05144">different </a><a href="https://arxiv.org/abs/1805.12317">contexts </a>in recent years in the theory literature on fairness is that we might articulate a very rich collection of (generally intersecting) demographic groups <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> corresponding to relevant subsets of the data domain, and ask for things that we care about to hold true as averaged over any group <img alt="S \in G" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Cin+G&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> in the collection. In the case of prediction intervals, this would correspond to asking for something like that simultaneously for every demographic group <img alt="S \in G" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Cin+G&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>, <img alt="\Pr_{(x,y)}\left[y \in [\ell(x), u(x)] | x \in S \right] \approx 0.95" class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr_%7B%28x%2Cy%29%7D%5Cleft%5By+%5Cin+%5B%5Cell%28x%29%2C+u%28x%29%5D+%7C+x+%5Cin+S+%5Cright%5D+%5Capprox+0.95&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>. Note here that an individual might be a member of many different demographic groups, and can interpret the guarantees of their prediction interval as averages over any of those demographic groups, at their option. This is what we can achieve — at least for any such group that isn’t too small. </p>



<p>And what kinds of assumptions do we need?</p>



<p><strong>Adversarial Data </strong>Actually, its not clear that we need any! Many learning problems which initially appear to require distributional assumptions turn out to be solvable even in the worst case over data sequences — i.e. even if a clever adversary, with full knowledge of your algorithm, and with the intent only to sabotage your learning guarantees, is allowed to adaptively choose data to present to your algorithm. This is the case for <a href="https://academic.oup.com/biomet/article-abstract/85/2/379/298827">calibrated weather prediction</a>, as well as <a href="http://proceedings.mlr.press/v48/syrgkanis16.pdf">general contextual prediction</a>. It turns out to be the case for us as well. Instead of promising coverage probabilities of <img alt="1-\delta + O(1/T)" class="latex" src="https://s0.wp.com/latex.php?latex=1-%5Cdelta+%2B+O%281%2FT%29&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> after <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> rounds <em>on the underlying distribution</em>, as<a href="https://www.stat.cmu.edu/~ryantibs/papers/conformal.pdf"> conformal prediction is able to</a>, we offer <em>empirical</em> coverage rates of <img alt="1-\delta \pm O(1/\sqrt{T})" class="latex" src="https://s0.wp.com/latex.php?latex=1-%5Cdelta+%5Cpm+O%281%2F%5Csqrt%7BT%7D%29&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/> (since for us there is no underlying distribution). This kind of guarantee is quite similar to what<a href="https://www.stat.cmu.edu/~ryantibs/papers/conformal.pdf"> conformal prediction guarantees about empirical coverage</a>. </p>



<p><strong>More Generally </strong>Our techniques are not specific to prediction intervals. We can do the same thing for many other distributional quantities. We work this out in the case of predicting label means, and predicting variances of the residuals of arbitrary prediction methods. For mean prediction, this corresponds to an algorithm for providing <a href="https://arxiv.org/abs/1711.08513">multi-calibrated predictions in the sense of Hebert-Johnson et al</a>, in an online adversarial environment. For variances and other higher moments, it corresponds to an online algorithm for making <a href="https://arxiv.org/abs/2008.08037">mean-conditioned moment multicalibrated predictions in the sense of Jung et al</a>.</p>



<p><strong>Techniques</strong> At the risk of boring my one stubbornly remaining reader, let me say a few words about how we do it. We generalize an idea that dates back to an argument that<a href="https://dash.harvard.edu/bitstream/handle/1/3203773/fudenberg_calibrate.pdf"> Fudenberg and Levine first made in 1995</a> — and is closely related to <a href="http://www.ma.huji.ac.il/hart/papers/calib-minmax.pdf">an earlier, beautiful argument by Sergiu Hart</a> — but that I just learned about this summer, and thought was just amazing. It applies broadly to solving any prediction task that would be easy, if only you were facing a known data distribution. This is the case for us. If, for each arriving patient at our hospital, a wizard <em>told us</em> their “true” distribution over outcome severity, we could easily make calibrated predictions by always predicting the mean of this distribution — and we could similarly read off correct 95% coverage intervals from the CDF of the distribution. So what? That’s not the situation we are in, of course. Absent a wizard, we first need to commit to some learning algorithm, and only then will the adversary decide what data to show us. </p>



<p>But lets put our game theory hats on. Suppose we’ve been making predictions for awhile. We can write down some measure of our error so far — say the maximum, over all demographic groups in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002"/>, of the deviation of our empirical coverage so far from our 95% coverage target.  For the next round, define a zero sum game, in which we (the learner) want to minimize the <em>increase</em> in this measure of error, and the adversary wants to maximize it. The defining feature of zero-sum games is that how well you can do in them is independent of which player has to announce their distribution on play first — this is the celebrated <a href="https://en.wikipedia.org/wiki/Minimax_theorem">Minimax Theorem</a>. So to evaluate how well the learner could do in this game, we can think about the situation involving a Wizard above, in which for each arriving person, before we have to make a prediction for them, we get to observe their true label distribution. Of course in this scenario we can do well, because for all of our goals, our measure of success is based on how well our predictions match observed properties of these distributions. The Minimax theorem tells us that (at least in principle — it doesn’t give us the algorithm), there must therefore also be a learning algorithm that can do just as well, but against an adversary. </p>



<p>The minimax argument is slick, but non-constructive. To actually pin down a concrete algorithm, we need to solve for the equilibrium in the corresponding game. That’s what we spend much of the paper doing, for each of the prediction tasks that we study. For multicalibration, we get a simple, elementary algorithm — but for the prediction interval problem, although we get a polynomial time algorithm, it involves solving a linear program with a separation oracle at each round. Finding more efficient and practical ways to do this strikes me as an important problem. </p>



<p>Finally, I had more fun writing this paper — learning about old techniques from the game theoretic calibration literature — than I’ve had in awhile. I hope a few people enjoy reading it!</p>



<p/>



<p/></div>
    </content>
    <updated>2021-01-15T14:00:00Z</updated>
    <published>2021-01-15T14:00:00Z</published>
    <category term="Blog"/>
    <category term="multicalibration"/>
    <category term="papers"/>
    <category term="subgroup fairness"/>
    <category term="uncertainty"/>
    <author>
      <name>Aaron Roth</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-04-24T22:24:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1276</id>
    <link href="https://toc4fairness.org/launching-toc4fairness/" rel="alternate" type="text/html"/>
    <title>Launching TOC4Fairness</title>
    <summary>I am excited to launch the Simons Foundation’s Collaboration on the Theory of Algorithmic Fairness, funded by the Simons Foundation. This is a large-scale multi-institutional effort to accelerate the (already ...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am excited to launch the <a href="https://toc4fairness.org/">Simons Foundation’s Collaboration on the Theory of Algorithmic Fairness</a>, funded by<a href="https://www.simonsfoundation.org/"> the Simons Foundation</a>. This is a large-scale multi-institutional effort to accelerate the (already powerful) impact of TOC on the emerging area of algorithmic fairness. Beyond the ambitious research goals of this project (which we will discuss in future posts), we hope it will play an important role in community building and bridge building to other fields of research. In addition to launching <a href="https://toc4fairness.org/category/blog/">this blog</a> and <a href="https://toc4fairness.org/">our site</a>, we are also launching a <a href="https://toc4fairness.org/category/events/">research seminar</a> that will feature a diverse set of talks. We are very exited to have  <a href="https://toc4fairness.org/inaugural-meeting-toc4fairness-seminar-annette-zimmermann/">Annette Zimmermann</a> as our inaugural speaker (a week from today). </p>



<p>If you want to join our seminar, please email toc4fairness-director@cs.stanford.edu and we will add you to our email list (which we will be careful not to overuse).</p></div>
    </content>
    <updated>2021-01-13T15:45:36Z</updated>
    <published>2021-01-13T15:45:36Z</published>
    <category term="Blog"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-04-24T22:24:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1620</id>
    <link href="https://toc4fairness.org/toc4fairness-seminar-noa-dagan-and-noam-barda/" rel="alternate" type="text/html"/>
    <title>TOC4Fairness Seminar – Noa Dagan and Noam Barda</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><strong>Date:</strong> Wednesday, April 21st 2021 9:00 am – 10:00 am Pacific Time <br/>

<strong>Location: </strong>Zoom meeting</div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><figure class="wp-block-gallery columns-2 is-cropped"><ul class="blocks-gallery-grid"><li class="blocks-gallery-item"><figure><img alt="" class="wp-image-1621" height="976" src="https://i2.wp.com/toc4fairness.org/wp-content/uploads/2021/04/Noa-Dagan-Pic.png?resize=800%2C976&amp;ssl=1" width="800"/></figure></li><li class="blocks-gallery-item"><figure><img alt="" class="wp-image-1622" height="800" src="https://i2.wp.com/toc4fairness.org/wp-content/uploads/2021/04/Noam_Barda_Pic.jpg?resize=800%2C800&amp;ssl=1" width="800"/></figure></li></ul></figure>



<p><strong>Date: </strong>Wednesday, April 21st, 2021<br/>9:00 am – 10:00 am Pacific Time<br/>12:00 pm – 1:00 pm Eastern Time</p>



<p><strong>Location: </strong>Weekly Seminar, Zoom </p>



<h3>Title: Fairness Considerations in Machine Learning Models – the Experience of a Large Healthcare Organization</h3>



<h3>Abstract:</h3>



<p>This talk will focus on various fairness considerations in both the development and the application of machine learning based prediction models, as experienced in Clalit Health Services, a large healthcare organization in Israel.</p>



<p>The application and performance of an algorithm for improving sub-population calibration in predictive models will be presented. The algorithm is meant to address concerns regarding potential unfairness of the models towards groups which are underrepresented in the training dataset and thus might receive uncalibrated scores. The algorithm was implemented on widely used risk models, including the ACC/AHA 2013 model for cardiovascular disease and the FRAX model for osteoporotic fractures.</p>



<p>This algorithm also played a major role in the development of a COVID-19 mortality risk prediction model at a time when individual level data of COVID-19 patients was not yet available in Israel. The development process for this predictor will be presented. The resulting predictor was widely used within Clalit Health Services for prevention purposes, with an intention to notify high-risk members of their increased risk for mortality should they get infected, for prioritization of COVID-19 RT-PCR tests, and for treatment decisions in confirmed cases.</p>



<p>This talk is based on several joint works with Guy Rothblum, Gal Yona, Uri Shalit, Eitan Bachmat and Ran Balicer among others.</p>



<h3>Bio: </h3>



<p><strong>Noa Dagan</strong> holds an MD and an MPH from the Hebrew University, and a Ph.D. in Computer Science from Ben-Gurion University. She is currently a postdoctoral fellow in the Department of Biomedical Informatics (DBMI), Harvard Medical School. Noa is the director of data and AI-driven medicine at the Clalit Research Institute – the research institute of Israel’s largest healthcare organization, insuring and treating over 50% of the Israeli population.</p>



<p><strong>Noam Barda </strong>holds an MD from Tel-Aviv University, a PhD co-advised in public health and computer science from Ben-Gurion University and a BSc in computer science from the Open University. He is a postdoctoral fellow in the Department of Biomedical Informatics (DBMI) at Harvard Medical School. He is the head of epidemiology and research at Clalit Research Institute.</p></div>
    </content>
    <updated>2020-04-21T16:00:00Z</updated>
    <published>2020-04-21T16:00:00Z</published>
    <category term="Events"/>
    <category term="seminar"/>
    <author>
      <name>saeedshm</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-04-24T22:24:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1579</id>
    <link href="https://toc4fairness.org/toc4fairness-seminar-eshwar-ram-arunachaleswaran/" rel="alternate" type="text/html"/>
    <title>TOC4Fairness Seminar – Eshwar Ram Arunachaleswaran</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><strong>Date:</strong> Wednesday, April 7th 2021 9:00 am – 10:00 am Pacific Time <br/>

<strong>Location: </strong>Zoom meeting</div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><figure class="wp-block-image size-large"><img alt="" class="wp-image-1584" height="494" src="https://i2.wp.com/toc4fairness.org/wp-content/uploads/2021/04/eshwar-1.jpeg?resize=388%2C494&amp;ssl=1" width="388"/></figure>



<p><strong>Date: </strong>Wednesday, April 7th, 2021<br/>9:00 am – 10:00 am Pacific Time<br/>12:00 pm – 1:00 pm Eastern Time</p>



<p><strong>Location: </strong>Weekly Seminar, Zoom </p>



<h3><strong>Title:  Pipeline Interventions</strong></h3>



<h3><strong>Abstract:</strong></h3>



<p>We introduce the pipeline intervention problem, defined by a layered directed acyclic graph and a set of stochastic matrices governing transitions between successive layers. The graph is a stylized model for how people from different populations are presented opportunities, eventually leading to some reward. In our model, individuals are born into an initial position (i.e. some node in the first layer of the graph) according to a fixed probability distribution, and then stochastically progress through the graph according to the transition matrices, until they reach a node in the final layer of the graph; each node in the final layer has a reward associated with it. The pipeline intervention problem asks how to best make costly changes to the transition matrices governing people’s stochastic transitions through the graph, subject to a budget constraint. We consider two objectives: social welfare maximization, and a fairness-motivated maximin objective that seeks to maximize the value to the population (starting node) with the least expected value. We consider two variants of the maximin objective that turn out to be distinct, depending on whether we demand a deterministic solution or allow randomization. For each objective, we give an efficient approximation algorithm (an additive FPTAS) for constant width networks. We also tightly characterize the “price of fairness” in our setting: the ratio between the highest achievable social welfare and the highest social welfare consistent with a maximin optimal solution. Finally we show that for polynomial width networks, even approximating the maximin objective to any constant factor is NP hard, even for networks with constant depth. This shows that the restriction on the width in our positive results is essential.</p>



<p>This is based on joint work with Sampath Kannan, Aaron Roth, and Juba Ziani.</p>



<h3><strong>Bio:</strong></h3>



<p>Eshwar Ram Arunachaleswaran is a PhD student at the University of Pennsylvania, advised by Professors Sampath Kannan and Anindya De. He is interested in problems from Algorithms and Complexity, with a focus on Algorithmic Fairness.</p></div>
    </content>
    <updated>2020-04-07T19:42:00Z</updated>
    <published>2020-04-07T19:42:00Z</published>
    <category term="Events"/>
    <category term="seminar"/>
    <author>
      <name>jubaziani</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-04-24T22:24:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1602</id>
    <link href="https://toc4fairness.org/toc4fairness-seminar-james-johndrow-and-kristian-lum-2/" rel="alternate" type="text/html"/>
    <title>TOC4Fairness Seminar – James Johndrow and Kristian Lum</title>
    <summary>Talk Announcement</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://toc4fairness.org/toc4fairness-seminar-james-johndrow-and-kristian-lum/">Talk Announcement </a></p>



<figure class="wp-block-embed is-type-rich is-provider-embed-handler wp-block-embed-embed-handler wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">

</div></figure></div>
    </content>
    <updated>2020-04-05T22:57:00Z</updated>
    <published>2020-04-05T22:57:00Z</published>
    <category term="Videos"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-04-24T22:24:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1591</id>
    <link href="https://toc4fairness.org/toc4fairness-seminar-michael-kim-2/" rel="alternate" type="text/html"/>
    <title>TOC4Fairness Seminar – Michael Kim</title>
    <summary>Talk Announcement</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://toc4fairness.org/toc4fairness-seminar-michael-kim/">Talk Announcement</a></p>



<figure class="wp-block-embed is-type-rich is-provider-embed-handler wp-block-embed-embed-handler wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">

</div></figure></div>
    </content>
    <updated>2020-04-05T22:53:00Z</updated>
    <published>2020-04-05T22:53:00Z</published>
    <category term="Videos"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-04-24T22:24:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1597</id>
    <link href="https://toc4fairness.org/toc4fairness-seminar-ana-andreea-stoica-2/" rel="alternate" type="text/html"/>
    <title>TOC4Fairness Seminar – Ana-Andreea Stoica</title>
    <summary>Talk Announcement</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://toc4fairness.org/toc4fairness-seminar-ana-andreea-stoica/">Talk Announcement</a></p>



<figure class="wp-block-embed is-type-rich is-provider-embed-handler wp-block-embed-embed-handler wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">

</div></figure></div>
    </content>
    <updated>2020-04-05T21:40:00Z</updated>
    <published>2020-04-05T21:40:00Z</published>
    <category term="Videos"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-04-24T22:24:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://toc4fairness.org/?p=1589</id>
    <link href="https://toc4fairness.org/toc4fairness-seminar-christopher-jung-2/" rel="alternate" type="text/html"/>
    <title>TOC4Fairness Seminar – Christopher Jung</title>
    <summary>Talk Announcement</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://toc4fairness.org/toc4fairness-seminar-christopher-jung-2/">Talk Announcement </a></p>



<figure class="wp-block-embed is-type-rich is-provider-embed-handler wp-block-embed-embed-handler wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">

</div></figure></div>
    </content>
    <updated>2020-04-05T21:23:00Z</updated>
    <published>2020-04-05T21:23:00Z</published>
    <category term="Videos"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://toc4fairness.org</id>
      <logo>https://i1.wp.com/toc4fairness.org/wp-content/uploads/2020/10/cropped-favicon.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://toc4fairness.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://toc4fairness.org" rel="alternate" type="text/html"/>
      <subtitle>a simons collaboration project</subtitle>
      <title>TOC for Fairness</title>
      <updated>2021-04-24T22:24:09Z</updated>
    </source>
  </entry>
</feed>
