<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-07-12T20:21:39Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16085</id>
    <link href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/" rel="alternate" type="text/html"/>
    <title>Tools and Sensitivity</title>
    <summary>Cutting right through a 30-year-old conjecture Cropped from Emory homepage Hao Huang is a mathematician and computer scientist at Emory University. Last week he released a paper of only six pages that solves the Boolean Sensitivity Conjecture, which goes back at least to a 1992 paper by Noam Nisan and Mario Szegedy. Today we discuss […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Cutting right through a 30-year-old conjecture</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/haohuangcropped/" rel="attachment wp-att-16086"><img alt="" class="alignright wp-image-16086" height="212" src="https://rjlipton.files.wordpress.com/2019/07/haohuangcropped.jpg?w=148&amp;h=212" width="148"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Emory <a href="http://www.mathcs.emory.edu/~hhuan30/">homepage</a></font></td>
</tr>
</tbody>
</table>
<p>
Hao Huang is a mathematician and computer scientist at Emory University. Last week he released a <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">paper</a> of only six pages that solves the Boolean Sensitivity Conjecture, which goes back at least to a 1992 <a href="https://www.researchgate.net/publication/2508255_On_the_Degree_of_Boolean_Functions_as_Real_Polynomials">paper</a> by Noam Nisan and Mario Szegedy.</p>
<p>
Today we discuss his brilliant proof and what it means for sensitivity of the <em>tools</em> one employs.</p>
<p>
Several of our blogging friends have <a href="https://www.scottaaronson.com/blog/?p=4229">covered</a> this <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">news</a> in <a href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html">posts</a> <a href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/">already</a>, and Ryan O’Donnell even summarized the proof in one <a href="https://twitter.com/BooleanAnalysis/status/1145837576487612416">tweet</a>. Scott Aaronson’s thread includes a <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813116">comment</a> by Huang on how he came by his proof. </p>
<p>
We will try to draw implications for the related matter of how <em>you</em> might come by proofs of <em>other</em> conjectures. We have previously <a href="https://rjlipton.wordpress.com/2016/04/09/missing-mate-in-ten/">discussed</a> the possibility of overlooking short solutions to major problems. Here we will discuss how to <em>find</em> them.</p>
<p>
</p><p/><h2> A Graph Puzzle </h2><p/>
<p/><p>
To get a flavor of what Huang proved, consider the graph of an ordinary <a href="https://commons.wikimedia.org/wiki/File:Cube_graph.png">cube</a>:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph/" rel="attachment wp-att-16087"><img alt="" class="aligncenter wp-image-16087" height="181" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph.png?w=192&amp;h=181" width="192"/></a></p>
<p/><p><br/>
The question is, <em>can you color 5 vertices red so that no red node has 3 red neighbors?</em> Your first impulse might be to color 4 nodes red according to parity so that none has a red neighbor, per below left:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph_tries/" rel="attachment wp-att-16088"><img alt="" class="aligncenter wp-image-16088" height="175" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph_tries.png?w=450&amp;h=175" width="450"/></a></p>
<p/><p><br/>
But then any 5th node will have 3 red neighbors. Another “greedy” idea is to pack a subgraph of the allowed degree 2 into half the cube, as at right. Any 5th node will again create a degree-3 vertex in the subgraph induced by the red nodes.</p>
<p>
The answer is that actually one can pack 6 nodes that induce a simple cycle:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph_solved/" rel="attachment wp-att-16089"><img alt="" class="aligncenter wp-image-16089" height="181" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph_solved.png?w=192&amp;h=181" width="192"/></a></p>
<p/><p><br/>
Now let’s up the dimension by one—that is, take <img alt="{n = 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 4}"/> and <img alt="{N = 2^n = 16}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+2%5En+%3D+16%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N = 2^n = 16}"/>. How many nodes can we color red and keep the induced degree 2? </p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/hypercube_graph/" rel="attachment wp-att-16091"><img alt="" class="aligncenter wp-image-16091" height="230" src="https://rjlipton.files.wordpress.com/2019/07/hypercube_graph-1.png?w=300&amp;h=230" width="300"/></a></p>
<p/><p><br/>
Again the parity trick gives us degree 0 with 8 nodes, but then we can’t add a 9th. We can greedily try to pack the outer cube with our 6-node solution, but then—perhaps surprisingly—we can add only 2 more red nodes from the inner cube. So we can only do 5 from the outer cube. We can get 9 overall by:</p>
<p><a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/hypercube_graph_try10/" rel="attachment wp-att-16092"><img alt="" class="aligncenter wp-image-16092" height="230" src="https://rjlipton.files.wordpress.com/2019/07/hypercube_graph_try10.png?w=300&amp;h=230" width="300"/></a></p>
<p/><p><br/>
The fact that one red node is isolated seems to give room to improve, but there is no way to make 10. </p>
<p>
</p><p/><h2> The Theorem </h2><p/>
<p/><p>
The calculations have left an interesting jump from degree 0 with eight red nodes and degree 2 with nine. How about degree 1? Can we do that with 9 nodes? We can pack four disjoint edges but then there is nowhere to stick an isolated node. </p>
<p>
So for 9 nodes, which is <img alt="{\frac{N}{2} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2} + 1}"/>, the best we can do is degree 2, which is <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. This is what Huang proved:</p>
<blockquote><p><b>Theorem 1</b> <em><a name="graphs"/> Every subgraph induced by <img alt="{\frac{N}{2} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\frac{N}{2} + 1}"/> nodes of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>-dimensional hypercube graph has a node of degree at least <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. </em>
</p></blockquote>
<p/><p>
This is completely tight. When <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is a perfect square there is a way to achieve <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/> as the maximum degree (shown <a href="https://pdfs.semanticscholar.org/3917/3e0cb4e028c94328f1355bf02febea132127.pdf">here</a>). Otherwise the least integer above <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/> is best. Thus every subgraph of the <img alt="{5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5}"/>-cube induced by 17 nodes has a node with three neighbors, but you can go as high as 257 nodes in the <img alt="{9}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B9%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{9}"/>-cube while keeping the maximum degree to 3.</p>
<p>
We will mention the relation to Boolean sensitivity only briefly. The nodes of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube correspond to truth assignments in <img alt="{\{0,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{0,1\}^n}"/>. Since every red node <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> has <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> neighbors in the cube but at most <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/> red neighbors, the color function is highly sensitive to bitflips. But every flip also changes the parity of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>. Hence the <em>exclusive-or</em> of the color function with the parity function has <em>low</em> sensitivity. </p>
<p>
But not too low: Huang proved it is at least <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. That was enough to prove the conjecture. I’ve cut two sections on Boolean sensitivity from this post’s <a href="https://cse.buffalo.edu/~regan/cse705/wsensitivity.pdf">original draft</a>—let’s just say the connection to the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube and graph degree was known since this 1992 <a href="https://www.sciencedirect.com/science/article/pii/0097316592900608">paper</a>. Here we’ll focus on what it took to prove this theorem.</p>
<p>
</p><p/><h2> The Proof </h2><p/>
<p/><p>
From my undergrad days I’ve kept an interest in spectral graph theory. One of the basic facts is that the degree <img alt="{d(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(G)}"/> of a graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is always at least as great as the largest eigenvalue <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda}"/> of its adjacency matrix <img alt="{A_G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_G}"/>. For a <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/>-regular graph they are equal. Huang’s first trick is to note that the classic proof of this also allows <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> values on edges:</p>
<blockquote><p><b>Lemma 2</b> <em> Let <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> be a symmetric matrix obtained from <img alt="{A_G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_G%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A_G}"/> by multiplying some entries by <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{-1}"/> and <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\lambda}"/> any of its eigenvalues. Then <img alt="{d(G) \geq |\lambda|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29+%5Cgeq+%7C%5Clambda%7C%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{d(G) \geq |\lambda|}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Choose an eigenvector <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> such that <img alt="{Av = \lambda v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAv+%3D+%5Clambda+v%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Av = \lambda v}"/> and take an index <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> that maximizes <img alt="{|v_i|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_i%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_i|}"/>. Then </p>
<p align="center"><img alt="\displaystyle  |\lambda v_i| = |(A v)_i| = |\sum_j A_{i,j} v_j| \leq |\sum_j A_{i,j}| \cdot |v_i| \leq \sum_{(i,j) \in E(G)} |A_{i,j}|\cdot |v_i| \leq d(G)|v_i|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5Clambda+v_i%7C+%3D+%7C%28A+v%29_i%7C+%3D+%7C%5Csum_j+A_%7Bi%2Cj%7D+v_j%7C+%5Cleq+%7C%5Csum_j+A_%7Bi%2Cj%7D%7C+%5Ccdot+%7Cv_i%7C+%5Cleq+%5Csum_%7B%28i%2Cj%29+%5Cin+E%28G%29%7D+%7CA_%7Bi%2Cj%7D%7C%5Ccdot+%7Cv_i%7C+%5Cleq+d%28G%29%7Cv_i%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |\lambda v_i| = |(A v)_i| = |\sum_j A_{i,j} v_j| \leq |\sum_j A_{i,j}| \cdot |v_i| \leq \sum_{(i,j) \in E(G)} |A_{i,j}|\cdot |v_i| \leq d(G)|v_i|. "/></p>
<p>Dividing out <img alt="{|v_i|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_i%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_i|}"/> gives the lemma. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p/><p><br/>
So now what we want to do is find conditions that force <img alt="{\lambda = \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda+%3D+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda = \sqrt{n}}"/> when <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is a <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/>-vertex subgraph of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube with <img alt="{m \geq \frac{N}{2} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%5Cgeq+%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m \geq \frac{N}{2} + 1}"/>, where <img alt="{N = 2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N = 2^n}"/>. The trick that Huang realized is that he could do this by making <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> sit inside a matrix <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/> with at least <img alt="{\frac{N}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2}}"/> eigenvalues of <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/>. </p>
<p>
To see how, form <img alt="{A_{N-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{N-1}}"/> by knocking out the last row and column of <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>. Since <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/> and <img alt="{A_{N-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{N-1}}"/> are both real and symmetric, their eigenvalues are real, so we can order them <img alt="{\lambda_1,\dots,\lambda_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1%2C%5Cdots%2C%5Clambda_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_1,\dots,\lambda_N}"/> and <img alt="{\mu_1,\dots,\mu_{N-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu_1%2C%5Cdots%2C%5Cmu_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu_1,\dots,\mu_{N-1}}"/> in nonincreasing order. The basic fact is that they always <em>interlace</em>: </p>
<p align="center"><img alt="\displaystyle  \lambda_1 \geq \mu_1 \geq \lambda_2 \geq \mu_2 \geq \lambda_3 \geq \cdots \geq \mu_{N-1} \geq \lambda_N. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_1+%5Cgeq+%5Cmu_1+%5Cgeq+%5Clambda_2+%5Cgeq+%5Cmu_2+%5Cgeq+%5Clambda_3+%5Cgeq+%5Ccdots+%5Cgeq+%5Cmu_%7BN-1%7D+%5Cgeq+%5Clambda_N.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \lambda_1 \geq \mu_1 \geq \lambda_2 \geq \mu_2 \geq \lambda_3 \geq \cdots \geq \mu_{N-1} \geq \lambda_N. "/></p>
<p>See <a href="https://arxiv.org/pdf/math/0502408.pdf">this</a> for a one-page proof. The neat point is that you can repeat this: if you get <img alt="{A''}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A''}"/> by knocking out another row and corresponding column, and <img alt="{[\nu_i]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B%5Cnu_i%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[\nu_i]}"/> are its eigenvalues in order, then </p>
<p align="center"><img alt="\displaystyle  \mu_1 \geq \nu_1 \geq \mu_2 \geq \nu_2 \geq \mu_3 \cdots. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmu_1+%5Cgeq+%5Cnu_1+%5Cgeq+%5Cmu_2+%5Cgeq+%5Cnu_2+%5Cgeq+%5Cmu_3+%5Ccdots.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mu_1 \geq \nu_1 \geq \mu_2 \geq \nu_2 \geq \mu_3 \cdots. "/></p>
<p>It follows that <img alt="{\lambda_1 \geq \nu_1 \geq \lambda_3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1+%5Cgeq+%5Cnu_1+%5Cgeq+%5Clambda_3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_1 \geq \nu_1 \geq \lambda_3}"/>. If you do this again, you get a matrix whose leading eigenvalue is still at least as big as <img alt="{\lambda_4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_4}"/>. Do it <img alt="{\frac{N}{2} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2} - 1}"/> times inside <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>, and you’re still above <img alt="{\lambda_{N/2}(A_N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_%7BN%2F2%7D%28A_N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_{N/2}(A_N)}"/>, which we just said we will arrange to be <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/>. Thus if we knock out the <img alt="{\frac{N}{2} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2} - 1}"/> white nodes, we will get the graph on the red nodes with adjacency matrix <img alt="{A_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_m}"/> and conclude: </p>
<p align="center"><img alt="\displaystyle  \lambda_1(A_N) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_1%28A_N%29+%5Cgeq+%5Clambda_1%28A_m%29+%5Cgeq+%5Clambda_%7BN%2F2%7D%28A_N%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \lambda_1(A_N) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) "/></p>
<p>Plugging into the lemma gives: </p>
<p align="center"><img alt="\displaystyle  d(G) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) = \sqrt{n}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d%28G%29+%5Cgeq+%5Clambda_1%28A_m%29+%5Cgeq+%5Clambda_%7BN%2F2%7D%28A_N%29+%3D+%5Csqrt%7Bn%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  d(G) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) = \sqrt{n}. "/></p>
<p>(In fact, as also <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813084">noted</a> on Scott’s blog, this case of interlacing can be inferred from simpler reasoning—but our point is that the interlacing theorem was in Huang’s bag of tricks.) </p>
<p>
</p><p/><h2> Building the Matrix </h2><p/>
<p/><p>
Finally, how do we lay hands on <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>? We want a matrix of trace zero such that <img alt="{A_N^2 = nI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%5E2+%3D+nI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N^2 = nI}"/>. Then all its eigenvalues are <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/> and <img alt="{-\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-\sqrt{n}}"/>.  They come in equal numbers because they sum to the trace which is zero. So we will have <img alt="{N/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N/2}"/> eigenvalues of <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/>, as needed. And we would want <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/> to be the matrix of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube but that doesn’t work: each <img alt="{i,j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i,j}"/> entry of its square counts all paths of length 2 from node <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> to node <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> and that number can be nonzero.</p>
<p>
This is where the trick of putting <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> on edges comes in, and we can explain it in a way familiar from quantum. We arrange that every 4-cycle of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube has exactly one edge with <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/>. Then the pairs of paths from one corner to the opposite corner will always <em>cancel</em>, leaving <img alt="{A^2_{i,j} = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E2_%7Bi%2Cj%7D+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^2_{i,j} = 0}"/> whenever <img alt="{i \neq j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%5Cneq+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i \neq j}"/>. And <img alt="{A^2_{i,j} = n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E2_%7Bi%2Cj%7D+%3D+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^2_{i,j} = n}"/> because there are <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> ways to go out and come back along the same edge, always contributing <img alt="{1\cdot 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%5Ccdot+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1\cdot 1}"/> or <img alt="{(-1)\cdot(-1) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5Ccdot%28-1%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1)\cdot(-1) = 1}"/> either way. Huang defines the needed labeling explicitly by the recursion: </p>
<p align="center"><img alt="\displaystyle  A_2 = \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix},\quad\text{and for } N &gt; 2,\quad A_N = \begin{bmatrix} A_{N/2} &amp; I \\ I &amp; -A_{N/2} \end{bmatrix}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A_2+%3D+%5Cbegin%7Bbmatrix%7D+0+%26+1+%5C%5C+1+%26+0+%5Cend%7Bbmatrix%7D%2C%5Cquad%5Ctext%7Band+for+%7D+N+%3E+2%2C%5Cquad+A_N+%3D+%5Cbegin%7Bbmatrix%7D+A_%7BN%2F2%7D+%26+I+%5C%5C+I+%26+-A_%7BN%2F2%7D+%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  A_2 = \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix},\quad\text{and for } N &gt; 2,\quad A_N = \begin{bmatrix} A_{N/2} &amp; I \\ I &amp; -A_{N/2} \end{bmatrix}. "/></p>
<p>This puts a <img alt="{-}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-}"/> sign on exactly one-fourth of the entries in the needed way. OK, we changed Huang’s subscripts for consistency with “<img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>” above and also to note that the basis could be <img alt="{A_1 = [0]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_1+%3D+%5B0%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_1 = [0]}"/>.  Anyway, he verifies <img alt="{A_N^2 = nI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%5E2+%3D+nI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N^2 = nI}"/> directly by simple algebra and induction.  That’s it—that’s the proof.</p>
<p>
Why was it hard to spot? Dick and I believe it was the <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> trick. In the 1980s, I thought about ways to convert undirected graphs into directed ones by putting arrows on the edges, but not <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> signs. The chance of thinking of it maybe rises with knowing quantum ideas such as interference and amplification. Now we can see, OK, <img alt="{A_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_2}"/> is the quantum NOT gate and the recursion treats signs in similar fashion to the recursion defining Hadamard matrices.  The matrix <img alt="{\frac{1}{\sqrt{n}}A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7DA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{1}{\sqrt{n}}A_N}"/> is unitary, so it defines a quantum operator. This all goes to our main point about having tools at one’s command—the more tools, the better. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Huang’s theorem still leaves a gap between a quadratic lower bound and his 4th-power upper bound (my longer <a href="https://cse.buffalo.edu/~regan/cse705/wsensitivity.pdf">draft</a> lays this out).  Can this gap be closed?  In discussing this, Huang notes that his spectral methods need not be confined to sub-matrices of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube, and our thoughts of involving quantum are similar. Can quantum tools improve the results even further?</p>
<p/></font></font></div>
    </content>
    <updated>2019-07-12T10:51:42Z</updated>
    <published>2019-07-12T10:51:42Z</published>
    <category term="algorithms"/>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="Teaching"/>
    <category term="trick"/>
    <category term="Boolean functions"/>
    <category term="Boolean sensitivity conjecture"/>
    <category term="complexity"/>
    <category term="concrete complexity"/>
    <category term="eigenvalues"/>
    <category term="Hao Huang"/>
    <category term="linear algebra"/>
    <category term="matrices"/>
    <category term="quantum"/>
    <category term="spectral methods"/>
    <category term="tricks"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-07-12T20:20:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05401</id>
    <link href="http://arxiv.org/abs/1907.05401" rel="alternate" type="text/html"/>
    <title>Computational Concentration of Measure: Optimal Bounds, Reductions, and More</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Etesami:Omid.html">Omid Etesami</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahloujifar:Saeed.html">Saeed Mahloujifar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahmoody:Mohammad.html">Mohammad Mahmoody</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05401">PDF</a><br/><b>Abstract: </b>Product measures of dimension $n$ are known to be concentrated in Hamming
distance: for any set $S$ in the product space of probability $\epsilon$, a
random point in the space, with probability $1-\delta$, has a neighbor in $S$
that is different from the original point in only
$O(\sqrt{n\ln(1/(\epsilon\delta))})$ coordinates. We obtain the tight
computational version of this result, showing how given a random point and
access to an $S$-membership oracle, we can find such a close point in
polynomial time. This resolves an open question of [Mahloujifar and Mahmoody,
ALT 2019]. As corollaries, we obtain polynomial-time poisoning and (in certain
settings) evasion attacks against learning algorithms when the original
vulnerabilities have any cryptographically non-negligible probability.
</p>
<p>We call our algorithm MUCIO ("MUltiplicative Conditional Influence
Optimizer") since proceeding through the coordinates, it decides to change each
coordinate of the given point based on a multiplicative version of the
influence of that coordinate, where influence is computed conditioned on
previously updated coordinates.
</p>
<p>We also define a new notion of algorithmic reduction between computational
concentration of measure in different metric probability spaces. As an
application, we get computational concentration of measure for high-dimensional
Gaussian distributions under the $\ell_1$ metric.
</p>
<p>We prove several extensions to the results above: (1) Our computational
concentration result is also true when the Hamming distance is weighted. (2) We
obtain an algorithmic version of concentration around mean, more specifically,
McDiarmid's inequality. (3) Our result generalizes to discrete random
processes, and this leads to new tampering algorithms for collective coin
tossing protocols. (4) We prove exponential lower bounds on the average running
time of non-adaptive query algorithms.
</p></div>
    </summary>
    <updated>2019-07-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05391</id>
    <link href="http://arxiv.org/abs/1907.05391" rel="alternate" type="text/html"/>
    <title>Walking Randomly, Massively, and Efficiently</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jakub Łącki, Slobodan Mitrović, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Onak:Krzysztof.html">Krzysztof Onak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sankowski:Piotr.html">Piotr Sankowski</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05391">PDF</a><br/><b>Abstract: </b>We introduce an approach that enables for efficiently generating many
independent random walks in big graph models, such as the Massive Parallel
Computation (MPC) model. We consider the case where the space per machine is
strongly sublinear in the number of vertices. In this case, many natural
approaches for graph problems struggle to overcome the $\Theta(\log n)$ MPC
round complexity barrier. We design a PageRank algorithm that break this
barrier even for directed graphs, and also show how to break this barrier for
bipartiteness and expansion testing.
</p>
<p>In the undirected case we start our random walks from the stationary
distribution, so we approximately know the empirical distribution of their next
steps. This way we can use doubling approach to prepare continuations of
sampled walks in advance. Our approach enables generating multiple random walks
of length $l$ in $\Theta(\log l)$ rounds on MPC. Moreover, we show that under
\textsc{2-Cycle} conjecture this round complexity is asymptotically tight. One
of the most important application of random walks is PageRank computation. We
show how to use our approach to compute approximate PageRank w.h.p. for
constant damping factor in $O(\log \log n)$ rounds on undirected graphs (with
$\tilde{O}(m)$ total space), and $\tilde{O}(\log \log n)$ rounds on directed
graphs (with $\tilde{O}(m+n^{1+o(1)})$ total space).
</p>
<p>Building on our random-walk primitive and traditional property testing
algorithms, we also show how to approximately test bipartiteness and expansion
in $O(\log\log(n))$ MPC rounds.
</p></div>
    </summary>
    <updated>2019-07-12T01:45:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05378</id>
    <link href="http://arxiv.org/abs/1907.05378" rel="alternate" type="text/html"/>
    <title>Quantum and Classical Algorithms for Approximate Submodular Function Minimization</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hamoudi:Yassine.html">Yassine Hamoudi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rebentrost:Patrick.html">Patrick Rebentrost</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rosmanis:Ansis.html">Ansis Rosmanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santha:Miklos.html">Miklos Santha</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05378">PDF</a><br/><b>Abstract: </b>Submodular functions are set functions mapping every subset of some ground
set of size $n$ into the real numbers and satisfying the diminishing returns
property. Submodular minimization is an important field in discrete
optimization theory due to its relevance for various branches of mathematics,
computer science and economics. The currently fastest strongly polynomial
algorithm for exact minimization [LSW15] runs in time $\widetilde{O}(n^3 \cdot
\mathrm{EO} + n^4)$ where $\mathrm{EO}$ denotes the cost to evaluate the
function on any set. For functions with range $[-1,1]$, the best
$\epsilon$-additive approximation algorithm [CLSW17] runs in time
$\widetilde{O}(n^{5/3}/\epsilon^{2} \cdot \mathrm{EO})$. In this paper we
present a classical and a quantum algorithm for approximate submodular
minimization. Our classical result improves on the algorithm of [CLSW17] and
runs in time $\widetilde{O}(n^{3/2}/\epsilon^2 \cdot \mathrm{EO})$. Our quantum
algorithm is, up to our knowledge, the first attempt to use quantum computing
for submodular optimization. The algorithm runs in time
$\widetilde{O}(n^{5/4}/\epsilon^{5/2} \cdot \log(1/\epsilon) \cdot
\mathrm{EO})$. The main ingredient of the quantum result is a new method for
sampling with high probability $T$ independent elements from any discrete
probability distribution of support size $n$ in time $O(\sqrt{Tn})$. Previous
quantum algorithms for this problem were of complexity $O(T\sqrt{n})$.
</p></div>
    </summary>
    <updated>2019-07-12T01:45:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05350</id>
    <link href="http://arxiv.org/abs/1907.05350" rel="alternate" type="text/html"/>
    <title>Competitive Analysis with a Sample and the Secretary Problem</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaplan:Haim.html">Haim Kaplan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Naori:David.html">David Naori</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raz:Danny.html">Danny Raz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05350">PDF</a><br/><b>Abstract: </b>We extend the standard online worst-case model to accommodate past experience
which is available to the online player in many practical scenarios. We do this
by revealing a random sample of the adversarial input to the online player
ahead of time. The online player competes with the expected optimal value on
the part of the input that arrives online. Our model bridges between existing
online stochastic models (e.g., items are drawn i.i.d. from a distribution) and
the online worst-case model. We also extend in a similar manner (by revealing a
sample) the online random-order model.
</p>
<p>We study the classical secretary problem in our new models. In the worst-case
model we present a simple online algorithm with optimal competitive-ratio for
any sample size. In the random-order model, we also give a simple online
algorithm with an almost tight competitive-ratio for small sample sizes.
Interestingly, we prove that for a large enough sample, no algorithm can be
simultaneously optimal both in the worst-cast and random-order models.
</p></div>
    </summary>
    <updated>2019-07-12T01:30:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05309</id>
    <link href="http://arxiv.org/abs/1907.05309" rel="alternate" type="text/html"/>
    <title>State-of-The-Art Sparse Direct Solvers</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bollh=ouml=fer:Matthias.html">Matthias Bollhöfer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schenk:Olaf.html">Olaf Schenk</a>, Radim Janalík, Steve Hamm, Kiran Gullapalli <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05309">PDF</a><br/><b>Abstract: </b>In this chapter we will give an insight into modern sparse elimination
methods. These are driven by a preprocessing phase based on combinatorial
algorithms which improve diagonal dominance, reduce fill-in, and improve
concurrency to allow for parallel treatment. Moreover, these methods detect
dense submatrices which can be handled by dense matrix kernels based on
multithreaded level-3 BLAS. We will demonstrate for problems arising from
circuit simulation, how the improvements in recent years have advanced direct
solution methods significantly.
</p></div>
    </summary>
    <updated>2019-07-12T01:33:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05296</id>
    <link href="http://arxiv.org/abs/1907.05296" rel="alternate" type="text/html"/>
    <title>Simplification of Polyline Bundles</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spoerhase:Joachim.html">Joachim Spoerhase</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Storandt:Sabine.html">Sabine Storandt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zink:Johannes.html">Johannes Zink</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05296">PDF</a><br/><b>Abstract: </b>We propose and study generalizations to the well-known problem of polyline
simplification. Instead of a single polyline, we are given a set of polylines
possibly sharing some line segments and bend points. The simplification of
those shared parts has to be consistent among the polylines. We consider two
optimization goals: either minimizing the number of line segments or minimizing
the number of bend points in the simplification. By reduction from
Minimum-Independent-Dominating-Set, we show that both of these optimization
problems are NP-hard to approximate within a factor $n^{1/3 - \varepsilon}$ for
any $\varepsilon &gt; 0$ where $n$ is the number of bend points in the polyline
bundle. Moreover, we outline that both problems remain NP-hard even if the
input is planar. On the positive side, we give a polynomial-size integer linear
program and show fixed-parameter tractability in the number of shared bend
points.
</p></div>
    </summary>
    <updated>2019-07-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05257</id>
    <link href="http://arxiv.org/abs/1907.05257" rel="alternate" type="text/html"/>
    <title>Stick Graphs with Length Constraints</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chaplick:Steven.html">Steven Chaplick</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kindermann:Philipp.html">Philipp Kindermann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/L=ouml=ffler:Andre.html">Andre Löffler</a>, Florian Thiele, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolff:Alexander.html">Alexander Wolff</a>, Alexander Zaft, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zink:Johannes.html">Johannes Zink</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05257">PDF</a><br/><b>Abstract: </b>Stick graphs are intersection graphs of horizontal and vertical line segments
that all touch a line of slope -1 and lie above this line. De Luca et al.
[GD'18] considered the recognition problem of stick graphs for the case that
the ordering of either one of the two sets (STICK_A) is given and for the case
that the ordering of both sets is given (STICK_AB). They showed how to solve
both cases efficiently. In this paper, we improve the running times of their
algorithms and consider new variants of STICK, where no ordering is given,
STICK_A, and STICK_AB where the lengths of the sticks are given as input. We
show that all new problem variants are NP-complete and give an efficient
solution for STICK_AB with fixed stick lengths if there are no isolated
vertices.
</p></div>
    </summary>
    <updated>2019-07-12T01:48:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05135</id>
    <link href="http://arxiv.org/abs/1907.05135" rel="alternate" type="text/html"/>
    <title>Perturbed Greedy on Oblivious Matching Problems</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Zhihao_Gavin.html">Zhihao Gavin Tang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Xiaowei.html">Xiaowei Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Yuhao.html">Yuhao Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05135">PDF</a><br/><b>Abstract: </b>We study the maximum matching problem in the oblivious setting, i.e. the edge
set of the graph is unknown to the algorithm. The existence of an edge is
revealed upon the probe of this pair of vertices. Further, if an edge exists
between two probed vertices, then the edge must be included in the matching
irrevocably. For unweighted graphs, the \textsf{Ranking} algorithm by Karp et
al.~(STOC 1990) achieves approximation ratios $0.696$ for bipartite graphs and
$0.526$ for general graphs. For vertex-weighted graphs, Chan et al. (TALG 2018)
proposed a $0.501$-approximate algorithm. In contrast, the edge-weighted
version only admits the trivial $0.5$-approximation by Greedy.
</p>
<p>In this paper, we propose the \textsf{Perturbed Greedy} algorithm for the
edge-weighted oblivious matching problem and prove that it achieves a $0.501$
approximation ratio. Besides, we show that the approximation ratio of our
algorithm on unweighted graphs is $0.639$ for bipartite graphs, and $0.531$ for
general graphs. The later improves the state-of-the-art result by Chan et al.
(TALG 2018). Furthermore, our algorithm can be regarded as a robust version of
the \textsf{Modified Randomized Greedy} (MRG) algorithm. By implication, our
$0.531$ approximation ratio serves as the first analysis of the MRG algorithm
beyond the $(1/2+\epsilon)$ regime.
</p></div>
    </summary>
    <updated>2019-07-12T01:26:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05121</id>
    <link href="http://arxiv.org/abs/1907.05121" rel="alternate" type="text/html"/>
    <title>Approximate Model Counting, Sparse XOR Constraints and Minimum Distance</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Boreale:Michele.html">Michele Boreale</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gorla:Daniele.html">Daniele Gorla</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05121">PDF</a><br/><b>Abstract: </b>The problem of counting the number of models of a given Boolean formula has
numerous applications, including computing the leakage of deterministic
programs in Quantitative Information Flow. Model counting is a hard,
#P-complete problem. For this reason, many approximate counters have been
developed in the last decade, offering formal guarantees of confidence and
accuracy. A popular approach is based on the idea of using random XOR
constraints to, roughly, successively halving the solution set until no model
is left: this is checked by invocations to a SAT solver. The effectiveness of
this procedure hinges on the ability of the SAT solver to deal with XOR
constraints, which in turn crucially depends on the length of such constraints.
We study to what extent one can employ sparse, hence short, constraints,
keeping guarantees of correctness. We show that the resulting bounds are
closely related to the geometry of the set of models, in particular to the
minimum Hamming distance between models. We evaluate our theoretical results on
a few concrete formulae. Based on our findings, we finally discuss possible
directions for improvements of the current state of the art in approximate
model counting.
</p></div>
    </summary>
    <updated>2019-07-12T01:26:23Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05094</id>
    <link href="http://arxiv.org/abs/1907.05094" rel="alternate" type="text/html"/>
    <title>Analysis of Ward's Method</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gro=szlig=wendt:Anna.html">Anna Großwendt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/R=ouml=glin:Heiko.html">Heiko Röglin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Melanie.html">Melanie Schmidt</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05094">PDF</a><br/><b>Abstract: </b>We study Ward's method for the hierarchical $k$-means problem. This popular
greedy heuristic is based on the \emph{complete linkage} paradigm: Starting
with all data points as singleton clusters, it successively merges two clusters
to form a clustering with one cluster less. The pair of clusters is chosen to
(locally) minimize the $k$-means cost of the clustering in the next step.
</p>
<p>Complete linkage algorithms are very popular for hierarchical clustering
problems, yet their theoretical properties have been studied relatively little.
For the Euclidean $k$-center problem, Ackermann et al. show that the
$k$-clustering in the hierarchy computed by complete linkage has a worst-case
approximation ratio of $\Theta(\log k)$. If the data lies in $\mathbb{R}^d$ for
constant dimension $d$, the guarantee improves to $\mathcal{O}(1)$, but the
$\mathcal{O}$-notation hides a linear dependence on $d$. Complete linkage for
$k$-median or $k$-means has not been analyzed so far.
</p>
<p>In this paper, we show that Ward's method computes a $2$-approximation with
respect to the $k$-means objective function if the optimal $k$-clustering is
well separated. If additionally the optimal clustering also satisfies a balance
condition, then Ward's method fully recovers the optimum solution. These
results hold in arbitrary dimension. We accompany our positive results with a
lower bound of $\Omega((3/2)^d)$ for data sets in $\mathbb{R}^d$ that holds if
no separation is guaranteed, and with lower bounds when the guaranteed
separation is not sufficiently strong. Finally, we show that Ward produces an
$\mathcal{O}(1)$-approximative clustering for one-dimensional data sets.
</p></div>
    </summary>
    <updated>2019-07-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05083</id>
    <link href="http://arxiv.org/abs/1907.05083" rel="alternate" type="text/html"/>
    <title>Cake Cutting on Graphs: A Discrete and Bounded Proportional Protocol</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bei:Xiaohui.html">Xiaohui Bei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Xiaoming.html">Xiaoming Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Hao.html">Hao Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Jialin.html">Jialin Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Zhijie.html">Zhijie Zhang</a>, Wei Zi <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05083">PDF</a><br/><b>Abstract: </b>The classical cake cutting problem studies how to find fair allocations of a
heterogeneous and divisible resource among multiple agents. Two of the most
commonly studied fairness concepts in cake cutting are proportionality and
envy-freeness. It is well known that a proportional allocation among $n$ agents
can be found efficiently via simple protocols [16]. For envy-freeness, in a
recent breakthrough, Aziz and Mackenzie [5] proposed a discrete and bounded
envy-free protocol for any number of players. However, the protocol suffers
from high multiple-exponential query complexity and it remains open to find
simpler and more efficient envy-free protocols.
</p>
<p>In this paper we consider a variation of the cake cutting problem by assuming
an underlying graph over the agents whose edges describe their acquaintance
relationships, and agents evaluate their shares relatively to those of their
neighbors. An allocation is called locally proportional if each agent thinks
she receives at least the average value over her neighbors. Local
proportionality generalizes proportionality and is in an interesting middle
ground between proportionality and envy-freeness: its existence is guaranteed
by that of an envy-free allocation, but no simple protocol is known to produce
such a locally proportional allocation for general graphs. Previous works
showed locally proportional protocols for special classes of graphs, and it is
listed in both [1] and [8] as an open question to design simple locally
proportional protocols for more general classes of graphs. In this paper we
completely resolved this open question by presenting a discrete and bounded
locally proportional protocol for any given graphs. Our protocol has a query
complexity of only single exponential, which is significantly smaller than the
six towers of $n$ query complexity of the envy-free protocol given in [5].
</p></div>
    </summary>
    <updated>2019-07-12T01:21:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.05000</id>
    <link href="http://arxiv.org/abs/1907.05000" rel="alternate" type="text/html"/>
    <title>ADDMC: Exact Weighted Model Counting with Algebraic Decision Diagrams</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dudek:Jeffrey_M=.html">Jeffrey M. Dudek</a>, Vu H. N. Phan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vardi:Moshe_Y=.html">Moshe Y. Vardi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.05000">PDF</a><br/><b>Abstract: </b>We compute exact literal-weighted model counts of CNF formulas. Our algorithm
employs dynamic programming, with Algebraic Decision Diagrams as the primary
data structure. This technique is implemented in ADDMC, a new model counter. We
empirically evaluate various heuristics that can be used with ADDMC. We also
compare ADDMC to state-of-the-art exact model counters (Cachet, c2d, d4,
miniC2D, and sharpSAT) on the two largest CNF model counting benchmark families
(BayesNet and Planning). ADDMC solves the most benchmarks in total within the
given timeout.
</p></div>
    </summary>
    <updated>2019-07-12T01:34:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04904</id>
    <link href="http://arxiv.org/abs/1907.04904" rel="alternate" type="text/html"/>
    <title>A Resource-Aware Approach to Collaborative Loop Closure Detection with Provable Performance Guarantees</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tian:Yulun.html">Yulun Tian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khosoussi:Kasra.html">Kasra Khosoussi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/How:Jonathan_P=.html">Jonathan P. How</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04904">PDF</a><br/><b>Abstract: </b>This paper presents resource-aware algorithms for distributed inter-robot
loop closure detection for applications such as collaborative simultaneous
localization and mapping (CSLAM) and distributed image retrieval. In real-world
scenarios, this process is resource-intensive as it involves exchanging many
observations and geometrically verifying a large number of potential matches.
This poses severe challenges for small-size and low-cost robots with various
operational and resource constraints that limit, e.g., energy consumption,
communication bandwidth, and computation capacity. This paper proposes a
framework in which robots first exchange compact queries to identify a set of
potential loop closures. We then seek to select a subset of potential
inter-robot loop closures for geometric verification that maximizes a monotone
submodular performance metric without exceeding budgets on computation (number
of geometric verifications) and communication (amount of exchanged data for
geometric verification). We demonstrate that this problem is in general
NP-hard, and present efficient approximation algorithms with provable
performance guarantees. The proposed framework is extensively evaluated on real
and synthetic datasets. A natural convex relaxation scheme is also presented to
certify the near-optimal performance of the proposed framework in practice.
</p></div>
    </summary>
    <updated>2019-07-12T01:27:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04889</id>
    <link href="http://arxiv.org/abs/1907.04889" rel="alternate" type="text/html"/>
    <title>Computing Minimal Persistent Cycles: Polynomial and Hard Cases</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dey:Tamal_K=.html">Tamal K. Dey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hou:Tao.html">Tao Hou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mandal:Sayan.html">Sayan Mandal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04889">PDF</a><br/><b>Abstract: </b>Persistent cycles, especially the minimal ones, are useful geometric features
functioning as augmentations for the intervals in the purely topological
persistence diagrams (also termed as barcodes). In our earlier work, we showed
that computing minimal 1-dimensional persistent cycles (persistent 1-cycles)
for finite intervals is NP-hard while the same for infinite intervals is
polynomially tractable. In this paper, we address this problem for general
dimensions with $Z_2$ coefficients. In addition to proving that it is NP-hard
to compute minimal persistent d-cycles (d&gt;1) for both types of intervals given
arbitrary simplicial complexes, we identify two interesting cases which are
polynomially tractable. These two cases assume the complex to be a certain
generalization of manifolds which we term as weak pseudomanifolds. For finite
intervals from the d-th persistence diagram of a weak (d+1)-pseudomanifold, we
utilize the fact that persistent cycles of such intervals are null-homologous
and reduce the problem to a minimal cut problem. Since the same problem for
infinite intervals is NP-hard, we further assume the weak (d+1)-pseudomanifold
to be embedded in $\mathbb{R}^{d+1}$ so that the complex has a natural dual
graph structure and the problem reduces to a minimal cut problem. Experiments
with both algorithms on scientific data indicate that the minimal persistent
cycles capture various significant features of the data.
</p></div>
    </summary>
    <updated>2019-07-12T01:47:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04733</id>
    <link href="http://arxiv.org/abs/1907.04733" rel="alternate" type="text/html"/>
    <title>Coresets for Clustering in Graphs of Bounded Treewidth</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Braverman:Vladimir.html">Vladimir Braverman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Lingxiao.html">Lingxiao Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Shaofeng_H==C=.html">Shaofeng H.-C. Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krauthgamer:Robert.html">Robert Krauthgamer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Xuan.html">Xuan Wu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04733">PDF</a><br/><b>Abstract: </b>We initiate the study of coresets for clustering in graph metrics, i.e., the
shortest-path metric of edge-weighted graphs. Such clustering problems (on
graph metrics) are essential to data analysis and used for example in road
networks and data visualization. Specifically, we consider $(k, z)$-Clustering,
where given a metric space $(V, d)$, the goal is to minimize, over all
$k$-point center sets $C$, the objective $\sum_{x \in V}{d^z(x, C)}$. This
problem is a well-known generalization of both k-Median ($z=1$) and k-Means
($z=2$). A coreset is a compact summary of the data that approximately
preserves the clustering objective for every possible center set. Coresets
offer significant efficiency improvements in terms of running time, storage,
and communication, including in streaming and distributed settings.
</p>
<p>Our main result is a near-linear time construction of a coreset of size
$O_{\epsilon, k, z}(\mathrm{tw}(G))$ for $(k, z)$-Clustering in a graph $G$
whose treewidth is $\mathrm{tw}(G)$. The construction is based on the framework
of Feldman and Langberg [STOC 2011], and our main technical contribution, as
required by this framework, is a uniform bound of $O(\mathrm{tw}(G))$ on the
shattering dimension under any point weights. Previously, the only construction
applicable to graph metrics, even for $z=1$, was a generic one with size
$O_{\epsilon, k}(\log n)$ where $n=|V|$ [Feldman and Langberg, STOC 2011].
</p>
<p>We complement our construction with an $\Omega_{\epsilon, k}(\mathrm{tw}(G))$
size lower bound, which matches our construction's linear dependence on
$\mathrm{tw}(G)$. This further provides the first proof that the $O(\log n)$
factor in the generic upper bound is indeed necessary, and also justifies
restricting the graph topology.
</p></div>
    </summary>
    <updated>2019-07-12T00:11:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04645</id>
    <link href="http://arxiv.org/abs/1907.04645" rel="alternate" type="text/html"/>
    <title>Smoothed Analysis of Order Types</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hoog:Ivor_van_der.html">Ivor van der Hoog</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Miltzow:Tillmann.html">Tillmann Miltzow</a>, Martijn van Schaik <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04645">PDF</a><br/><b>Abstract: </b>Consider an ordered point set $P = (p_1,\ldots,p_n)$, its order type (denoted
by $\chi_P$) is a map which assigns to every triple of points a value in
$\{+,-,0\}$ based on whether the points are collinear(0), oriented clockwise(-)
or counter-clockwise(+). An abstract order type is a map $\chi :
\left[\substack{n\\3}\right] \rightarrow \{+,-,0\}$ (where
$\left[\substack{n\\3}\right]$ is the collection of all triples of a set of $n$
elements) that satisfies the following condition: for every set of five
elements $S\subset [n]$ its induced order type $\chi_{|S}$ is realizable by a
point set. To be precise, a point set $P$ realizes an order type $\chi$,if
$\chi_P(p_i,p_j,p_k) = \chi(i,j,k)$, for all $i&lt;j&lt;k$. Planar point sets are
among the most basic and natural geometric objects of study in Discrete and
Computational Geometry. Properties of point sets are relevant in theory and
practice alike. It is known, that deciding if an abstract order type is
realizable is complete for the existential theory of the reals. Our results
show that order type realizability is much easier for realistic instances than
in the worst case. In particular, we can recognize instances in "expected
\NP-time". This is one of the first $\exists\mathbb{R}$-complete problems
analyzed under the lens of Smoothed Analysis.
</p></div>
    </summary>
    <updated>2019-07-11T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04630</id>
    <link href="http://arxiv.org/abs/1907.04630" rel="alternate" type="text/html"/>
    <title>Approximate Voronoi cells for lattices, revisited</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Laarhoven:Thijs.html">Thijs Laarhoven</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04630">PDF</a><br/><b>Abstract: </b>We revisit the approximate Voronoi cells approach for solving the closest
vector problem with preprocessing (CVPP) on high-dimensional lattices, and
settle the open problem of Doulgerakis-Laarhoven-De Weger [PQCrypto, 2019] of
determining exact asymptotics on the volume of these Voronoi cells under the
Gaussian heuristic. As a result, we obtain improved upper bounds on the time
complexity of the randomized iterative slicer when using less than $2^{0.076d +
o(d)}$ memory, and we show how to obtain time-memory trade-offs even when using
less than $2^{0.048d + o(d)}$ memory. We also settle the open problem of
obtaining a continuous trade-off between the size of the advice and the query
time complexity, as the time complexity with subexponential advice in our
approach scales as $d^{d/2 + o(d)}$, matching worst-case enumeration bounds,
and achieving the same asymptotic scaling as average-case enumeration
algorithms for the closest vector problem.
</p></div>
    </summary>
    <updated>2019-07-11T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04628</id>
    <link href="http://arxiv.org/abs/1907.04628" rel="alternate" type="text/html"/>
    <title>Polytopes, lattices, and spherical codes for the nearest neighbor problem</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Laarhoven:Thijs.html">Thijs Laarhoven</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04628">PDF</a><br/><b>Abstract: </b>We study locality-sensitive hash methods for the nearest neighbor problem for
the angular distance, focusing on the approach of first projecting down onto a
low-dimensional subspace, and then partitioning the projected vectors according
to Voronoi cells induced by a suitable spherical code. This approach
generalizes and interpolates between the fast but suboptimal hyperplane hashing
of Charikar [STOC'02] and the asymptotically optimal but practically often
slower hash families of Andoni-Indyk [FOCS'06], Andoni-Indyk-Nguyen-Razenshteyn
[SODA'14] and Andoni-Indyk-Laarhoven-Razenshteyn-Schmidt [NIPS'15]. We set up a
framework for analyzing the performance of any spherical code in this context,
and we provide results for various codes from the literature, such as those
related to regular polytopes and root lattices. Similar to hyperplane hashing,
and unlike cross-polytope hashing, our analysis of collision probabilities and
query exponents is exact and does not hide order terms which vanish only for
large $d$, facilitating an easy parameter selection.
</p>
<p>For the two-dimensional case, we derive closed-form expressions for arbitrary
spherical codes, and we show that the equilateral triangle is optimal,
achieving a better performance than the two-dimensional analogues of hyperplane
and cross-polytope hashing. In three and four dimensions, we numerically find
that the tetrahedron, $5$-cell, and $16$-cell achieve the best query exponents,
while in five or more dimensions orthoplices appear to outperform regular
simplices, as well as the root lattice families $A_k$ and $D_k$. We argue that
in higher dimensions, larger spherical codes will likely exist which will
outperform orthoplices in theory, and we argue why using the $D_k$ root
lattices will likely lead to better results in practice, due to a better
trade-off between the asymptotic query exponent and the concrete costs of
hashing.
</p></div>
    </summary>
    <updated>2019-07-11T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04565</id>
    <link href="http://arxiv.org/abs/1907.04565" rel="alternate" type="text/html"/>
    <title>Progressive Wasserstein Barycenters of Persistence Diagrams</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jules Vidal, Joseph Budin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tierny:Julien.html">Julien Tierny</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04565">PDF</a><br/><b>Abstract: </b>This paper presents an efficient algorithm for the progressive approximation
of Wasserstein barycenters of persistence diagrams, with applications to the
visual analysis of ensemble data. Given a set of scalar fields, our approach
enables the computation of a persistence diagram which is representative of the
set, and which visually conveys the number, data ranges and saliences of the
main features of interest found in the set. Such representative diagrams are
obtained by computing explicitly the discrete Wasserstein barycenter of the set
of persistence diagrams, a notoriously computationally intensive task. In
particular, we revisit efficient algorithms for Wasserstein distance
approximation [12,51] to extend previous work on barycenter estimation [94]. We
present a new fast algorithm, which progressively approximates the barycenter
by iteratively increasing the computation accuracy as well as the number of
persistent features in the output diagram. Such a progressivity drastically
improves convergence in practice and allows to design an interruptible
algorithm, capable of respecting computation time constraints. This enables the
approximation of Wasserstein barycenters within interactive times. We present
an application to ensemble clustering where we revisit the k-means algorithm to
exploit our barycenters and compute, within execution time constraints,
meaningful clusters of ensemble data along with their barycenter diagram.
Extensive experiments on synthetic and real-life data sets report that our
algorithm converges to barycenters that are qualitatively meaningful with
regard to the applications, and quantitatively comparable to previous
techniques, while offering an order of magnitude speedup when run until
convergence (without time constraint). Our algorithm can be trivially
parallelized to provide additional speedups in practice on standard
workstations. [...]
</p></div>
    </summary>
    <updated>2019-07-12T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-12T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04426</id>
    <link href="http://arxiv.org/abs/1907.04426" rel="alternate" type="text/html"/>
    <title>A near-linear time approximation scheme for geometric transportation with real supplies</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fox:Kyle.html">Kyle Fox</a>, Jiashuai Lu The University of Texas at Dallas) <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04426">PDF</a><br/><b>Abstract: </b>The geometric transportation problem takes as input a set of points $P$ in
$d$-dimensional Euclidean space and a supply function $\mu : P \to \mathbb{R}$.
The goal is to find a transportation map, a non-negative assignment $\tau : P
\times P \to \mathbb{R}_{\geq 0}$ to pairs of points so the total assignment
leaving each point is equal to its supply, i.e., $\sum_{r \in P} \tau(q, r) -
\sum_{p \in P} \tau(p, q) = \mu(q)$ for all points $q \in P$. The goal is to
minimize the weighted sum of Euclidean distances for the pairs, $\sum_{(p, q)
\in P \times P} \tau(p, q) \cdot ||q - p||_2$.
</p>
<p>We describe the first algorithm for this problem that returns, with high
probability, a $(1 + \epsilon)$-approximation to the optimal transportation map
in $O(n \text{poly}(1 / \epsilon) \text{polylog}{n})$ time. In contrast to the
previous best algorithms for this problem, our near-linear running time bound
is independent of the spread of $P$ and the magnitude of its real-valued
supplies.
</p></div>
    </summary>
    <updated>2019-07-12T00:16:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04420</id>
    <link href="http://arxiv.org/abs/1907.04420" rel="alternate" type="text/html"/>
    <title>Sublinear data structures for short Fr\'echet queries</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Driemel:Anne.html">Anne Driemel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Psarros:Ioannis.html">Ioannis Psarros</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Melanie.html">Melanie Schmidt</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04420">PDF</a><br/><b>Abstract: </b>We study metric data structures for curves in doubling spaces, such as
trajectories of moving objects in Euclidean $\mathbb{R}^d$, where the distance
between two curves is measured using the discrete Fr\'echet distance. We design
data structures in an \emph{asymmetric} setting where the input is a curve (or
a set of $n$ curves) each of complexity $m$ and the queries are with curves of
complexity $k\ll m$. We show that there exist approximate data structures that
are independent of the input size $N = d \cdot n \cdot m$ and we study how to
maintain them dynamically if the input is given in the stream.
</p>
<p>Concretely, we study two types of data structures: (i) distance oracles,
where the task is to store a compressed version of the input curve, which can
be used to answer queries for the distance of a query curve to the input curve,
and (ii) nearest-neighbor data structures, where the task is to preprocess a
set of input curves to answer queries for the input curve closest to the query
curve. In both cases we are interested in approximation. For curves embedded in
Euclidean $\mathbb{R}^d$ with constant $d$, our distance oracle uses space in
$\mathcal{O}((k \log(\epsilon^{-1}) \epsilon^{-d})^k)$ ($\epsilon$ is the
precision parameter). The oracle performs $(1+\epsilon)$-approximate queries in
time in $\mathcal{O}(k^2)$ and is deterministic. We show how to maintain this
distance oracle in the stream using polylogarithmic additional memory. In the
stream, we can dynamically answer distance queries to the portion of the stream
seen so far in $\mathcal{O}(k^4 \log^2 m)$ time. We apply our techniques to the
second problem, approximate near neighbor (ANN) data structures, and achieve an
exponential improvement in the dependency on the complexity of the input curves
compared to the state of the art.
</p></div>
    </summary>
    <updated>2019-07-12T00:15:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04413</id>
    <link href="http://arxiv.org/abs/1907.04413" rel="alternate" type="text/html"/>
    <title>On Approximating Partial Set Cover and Generalizations</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chekuri:Chandra.html">Chandra Chekuri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Quanrud:Kent.html">Kent Quanrud</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Zhao.html">Zhao Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04413">PDF</a><br/><b>Abstract: </b>Partial Set Cover (PSC) is a generalization of the well-studied Set Cover
problem (SC). In PSC the input consists of an integer $k$ and a set system
$(U,S)$ where $U$ is a finite set, and $S \subseteq 2^U$ is a collection of
subsets of $U$. The goal is to find a subcollection $S' \subseteq S$ of
smallest cardinality such that sets in $S'$ cover at least $k$ elements of $U$;
that is $|\cup_{A \in S'} A| \ge k$. SC is a special case of PSC when $k =
|U|$. In the weighted version each set $X \in S$ has a non-negative weight
$w(X)$ and the goal is to find a minimum weight subcollection to cover $k$
elements. Approximation algorithms for SC have been adapted to obtain
comparable algorithms for PSC in various interesting cases. In recent work
Inamdar and Varadarajan, motivated by geometric set systems, obtained a simple
and elegant approach to reduce PSC to SC via the natural LP relaxation. They
showed that if a deletion-closed family of SC admits a $\beta$-approximation
via the natural LP relaxation, then one can obtain a $2(\beta +
1)$-approximation for PSC on the same family. In a subsequent paper, they also
considered a generalization of PSC that has multiple partial covering
constraints which is partly inspired by and generalizes previous work of Bera
et al on the Vertex Cover problem. Our main goal in this paper is to
demonstrate some useful connections between the results in previous work and
submodularity. This allows us to simplify, and in some cases improve their
results. We improve the approximation for PSC to $(1-1/e)(\beta + 1)$. We
extend the previous work to the sparse setting.
</p></div>
    </summary>
    <updated>2019-07-12T00:13:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04383</id>
    <link href="http://arxiv.org/abs/1907.04383" rel="alternate" type="text/html"/>
    <title>Symmetric Polymorphisms and Efficient Decidability of Promise CSPs</title>
    <feedworld_mtime>1562889600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brakensiek:Joshua.html">Joshua Brakensiek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guruswami:Venkatesan.html">Venkatesan Guruswami</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04383">PDF</a><br/><b>Abstract: </b>In the field of constraint satisfaction problems (CSP), promise CSPs are an
exciting new direction of study. In a promise CSP, each constraint comes in two
forms: "strict" and "weak," and in the associated decision problem one must
distinguish between being able to satisfy all the strict constraints versus not
being able to satisfy all the weak constraints. The most commonly cited example
of a promise CSP is the approximate graph coloring problem--which has recently
benefited from multiple breakthroughs [BKO19, WZ19] due to a systematic study
of promise CSPs under the lens of "polymorphisms," operations that map tuples
in the strict form of each constraint to a tuple in its weak form.
</p>
<p>In this work, we present a simple algorithm which in polynomial time solves
the decision problem for all promise CSPs that admit infinitely many symmetric
polymorphisms, that is the coordinates are permutation invariant. This
generalizes previous work of the authors [BG19]. We also extend this algorithm
to a more general class of block-symmetric polymorphisms. As a corollary, this
single algorithm solves all polynomial-time tractable Boolean CSPs
simultaneously. These results give a new perspective on Schaefer's classic
theorem and shed further light on how symmetries of polymorphisms enable
algorithms.
</p></div>
    </summary>
    <updated>2019-07-11T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1705625191398821823</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1705625191398821823/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/degree-and-sensitivity.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1705625191398821823" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1705625191398821823" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/degree-and-sensitivity.html" rel="alternate" type="text/html"/>
    <title>Degree and Sensitivity</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Hao Huang's <a href="https://arxiv.org/abs/1907.00847">proof of the sensitivity conjecture</a> that I <a href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html">posted on last week</a> relied on a 1992 <a href="https://doi.org/10.1016/0097-3165(92)90060-8">result of Gotsman and Linial</a>. Let's talk about that result.<br/>
<br/>
Consider the set S={-1,1}<sup>n</sup>. The hypercube of dimension n is the graph with vertex set S and an edge between x = (x<sub>1</sub>,…,x<sub>n</sub>) and y = (y<sub>1</sub>,…,y<sub>n</sub>) in S if there is exactly one i such that x<sub>i</sub> ≠ y<sub>i</sub>. Every vertex has degree n.<br/>
<br/>
We say a vertex x is odd if x has an odd number of -1 coordinates, even otherwise. Every edge joins an odd and even vertex.<br/>
<br/>
Let f be a function mapping S to {-1,1}. The sensitivity of f on x is the number of i such that f(x<sub>1</sub>,…,x<sub>i</sub>,…,x<sub>n</sub>) ≠ f(x<sub>1</sub>,…,-x<sub>i</sub>,…,x<sub>n</sub>). The sensitivity of f is the maximum over all x in S of the sensitivity of f on x.<br/>
<br/>
Let g be the same function as f except that we flip the value on all odd vertices. Notice now that the sensitivity of f on x is the number of i such that g(x<sub>1</sub>,…,x<sub>i</sub>,…,x<sub>n</sub>) = g(x<sub>1</sub>,…,-x<sub>i</sub>,…,x<sub>n</sub>).<br/>
<br/>
Let G be the induced subgraph of vertices of x such that g(x)=-1 and H be induced subgraph on the set of x such that g(x)=1. The sensitivity of f is the maximum number of neighbors of any vertex in G or H.<br/>
<br/>
Consider f as a multilinear polynomial over the reals. The sensitivity conjecture states there is some α&gt;0 such that if f has degree n then f has sensitivity at least n<sup>α</sup>.<br/>
<br/>
Note g(x<sub>1</sub>,…,x<sub>n</sub>)=f(x<sub>1</sub>,…,x<sub>n</sub>)x<sub>1</sub>⋯x<sub>n</sub>. If f has a degree n term, the variables in that term cancel out on S (since x<sub>i</sub><sup>2</sup>=1) and the constant of the degree n term of f becomes the constant term of g. The constant term is just the expected value, so f has full degree iff g is unbalanced.<br/>
<br/>
GL Assumption: Suppose you have a partition of the hypercube into sets A and B with |A| ≠ |B|, and let G and H be the induced subgraphs of A and B. Then there is some constant α&gt;0 such that there is a node of A or B with at least n<sup>α</sup> neighbors.<br/>
<br/>
The above argument, due to Gotsman and Linial, shows that the GL assumption is equivalent to the sensitivity conjecture.<br/>
<br/>
Huang proved that given any subset A of the vertices of a hypercube with |A|&gt;2<sup>n</sup>/2 the induced subgraph has a node of degree at least n<sup>1/2</sup>. Since either A or B in the GL assumption has size greater than 2<sup>n</sup>/2, Huang's result gives the sensitivity conjecture.</div>
    </content>
    <updated>2019-07-11T17:54:00Z</updated>
    <published>2019-07-11T17:54:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-12T09:24:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04844</id>
    <link href="http://arxiv.org/abs/1907.04844" rel="alternate" type="text/html"/>
    <title>Vertex-Fault Tolerant Complete Matching in Bipartite graphs: the Biregular Case</title>
    <feedworld_mtime>1562803200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cichacz:Sylwia.html">Sylwia Cichacz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suchan:Karol.html">Karol Suchan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04844">PDF</a><br/><b>Abstract: </b>Given a family $\mathcal{H}$ of graphs and a positive integer $k$, a graph
$G$ is called vertex $k$-fault-tolerant with respect to $\mathcal{H}$, denoted
by $k$-FT$(\mathcal{H})$, if $G-S$ contains some $H\in\mathcal{H}$ as a
subgraph, for every $S\subset V(G)$ with $|S|\leq k$. Vertex-fault-tolerance
has been introduced by Hayes [A graph model for fault-tolerant computing
systems, IEEE Transactions on Computers, C-25 (1976), pp. 875-884.], and has
been studied in view of potential applications in the design of interconnection
networks operating correctly in the presence of faults. We define the
Fault-Tolerant Complete Matching (FTCM) Problem in bipartite graphs of order
$(n,m)$: to design a bipartite $G=(U,V;E)$, with $|U|=n$, $|V|=m$, $n&gt;m&gt;1$,
that has a FTCM, and the tuple $(\Delta_U, \Delta_V)$, where $\Delta_U$ and
$\Delta_V$ are the maximum degree in $U$ and $V$, respectively, is
lexicographically minimum. $G$ has a FTCM if deleting at most $n-m$ vertices
from $U$ creates $G'$ that has a complete matching, i.e., a matching of size
$m$. We show that if $m(n-m+1)/n$ is integer, solutions of the FTCM Problem can
be found among $(a,b)$-regular bipartite graphs of order $(n,m)$, with
$a=m(n-m+1)/n$, and $b=n-m+1$. If $a=m-1$ then all $(a,b)$-regular bipartite
graphs of order $(n,m)$ have a FTCM, and for $a&lt;m-1$, it is not the case. We
characterize the values of $n$, $m$, $a$, and $b$ that admit an $(a,b)$-regular
bipartite graph of order $(n,m)$, with $b=n-m+1$, and give a simple
construction that creates such a graph with a FTCM whenever possible. Our
techniques are based on Hall's marriage theorem, elementary number theory,
linear Diophantine equations, properties of integer functions and congruences,
and equations involving them.
</p></div>
    </summary>
    <updated>2019-07-11T23:49:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04826</id>
    <link href="http://arxiv.org/abs/1907.04826" rel="alternate" type="text/html"/>
    <title>Approximately counting and sampling small witnesses using a colourful decision oracle</title>
    <feedworld_mtime>1562803200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dell:Holger.html">Holger Dell</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lapinskas:John.html">John Lapinskas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meeks:Kitty.html">Kitty Meeks</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04826">PDF</a><br/><b>Abstract: </b>In this paper, we prove "black box" results for turning algorithms which
decide whether or not a witness exists into algorithms to approximately count
the number of witnesses, or to sample from the set of witnesses approximately
uniformly, with essentially the same running time. We do so by extending the
framework of Dell and Lapinskas (STOC 2018), which covers decision problems
that can be expressed as edge detection in bipartite graphs given limited
oracle access; our framework covers problems which can be expressed as edge
detection in arbitrary $k$-hypergraphs given limited oracle access. (Simulating
this oracle generally corresponds to invoking a decision algorithm.) This
includes many key problems in both the fine-grained setting (such as $k$-SUM,
$k$-OV and weighted $k$-Clique) and the parameterised setting (such as induced
subgraphs of size $k$ or weight-$k$ solutions to CSPs). From an algorithmic
standpoint, our results will make the development of new approximate counting
algorithms substantially easier; indeed, it already yields a new
state-of-the-art algorithm for approximately counting graph motifs, improving
on Jerrum and Meeks (JCSS 2015) unless the input graph is very dense and the
desired motif very small. Our $k$-hypergraph reduction framework generalises
and strengthens results in the graph oracle literature due to Beame et al.
(ITCS 2018) and Bhattacharya et al. (CoRR abs/1808.00691).
</p></div>
    </summary>
    <updated>2019-07-11T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04824</id>
    <link href="http://arxiv.org/abs/1907.04824" rel="alternate" type="text/html"/>
    <title>Scheduling With Inexact Job Sizes: The Merits of Shortest Processing Time First</title>
    <feedworld_mtime>1562803200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Matteo Dell'Amico <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04824">PDF</a><br/><b>Abstract: </b>It is well known that size-based scheduling policies, which take into account
job size (i.e., the time it takes to run them), can perform very desirably in
terms of both response time and fairness. Unfortunately, the requirement of
knowing a priori the exact job size is a major obstacle which is frequently
insurmountable in practice. Often, it is possible to get a coarse estimation of
job size, but unfortunately analytical results with inexact job sizes are
challenging to obtain, and simulation-based studies show that several
size-based algorithm are severely impacted by job estimation errors. For
example, Shortest Remaining Processing Time (SRPT), which yields optimal mean
sojourn time when job sizes are known exactly, can drastically underperform
when it is fed inexact job sizes.
</p>
<p>Some algorithms have been proposed to better handle size estimation errors,
but they are somewhat complex and this makes their analysis challenging. We
consider Shortest Processing Time (SPT), a simplification of SRPT that skips
the update of "remaining" job size and results in a preemptive algorithm that
simply schedules the job with the shortest estimated processing time. When job
size is inexact, SPT performs comparably to the best known algorithms in the
presence of errors, while being definitely simpler. In this work, SPT is
evaluated through simulation, showing near-optimal performance in many cases,
with the hope that its simplicity can open the way to analytical evaluation
even when inexact inputs are considered.
</p></div>
    </summary>
    <updated>2019-07-11T23:46:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04776</id>
    <link href="http://arxiv.org/abs/1907.04776" rel="alternate" type="text/html"/>
    <title>On the Complexity of Completing Binary Predicates</title>
    <feedworld_mtime>1562803200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Epstein:Samuel.html">Samuel Epstein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04776">PDF</a><br/><b>Abstract: </b>Given a binary predicate P, the length of the smallest program that computes
a complete extension of P is less than the size of the domain of P plus the
amount of information that P has with the halting sequence. This result is
derived from a theorem in this paper which says a prefix free set with large M
measure will have small monotone complexity, Km.
</p></div>
    </summary>
    <updated>2019-07-11T23:36:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04752</id>
    <link href="http://arxiv.org/abs/1907.04752" rel="alternate" type="text/html"/>
    <title>Sparse Regular Expression Matching</title>
    <feedworld_mtime>1562803200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bille:Philip.html">Philip Bille</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=oslash=rtz:Inge_Li.html">Inge Li Gørtz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04752">PDF</a><br/><b>Abstract: </b>We present the first algorithm for regular expression matching that can take
advantage of sparsity in the input instance. Our main result is a new algorithm
that solves regular expression matching in $O\left(\Delta \log \log
\frac{nm}{\Delta} + n + m\right)$ time, where $m$ is the number of positions in
the regular expression, $n$ is the length of the string, and $\Delta$ is the
\emph{density} of the instance, defined as the total number of active states in
a simulation of the position automaton. This measure is a lower bound on the
total number of active states in simulations of all classic polynomial sized
finite automata. Our bound improves the best known bounds for regular
expression matching by almost a linear factor in the density of the problem.
The key component in the result is a novel linear space representation of the
position automaton that supports state-set transition computation in
near-linear time in the size of the input and output state sets.
</p></div>
    </summary>
    <updated>2019-07-11T23:45:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04750</id>
    <link href="http://arxiv.org/abs/1907.04750" rel="alternate" type="text/html"/>
    <title>Efficient Gauss Elimination for Near-Quadratic Matrices with One Short Random Block per Row, with Applications</title>
    <feedworld_mtime>1562803200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Martin Dietzfelbinger Stefan Walzer <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04750">PDF</a><br/><b>Abstract: </b>In this paper we identify a new class of sparse near-quadratic random Boolean
matrices that have full row rank over $\mathbb{F}_2=\{0,1\}$ with high
probability and can be transformed into echelon form in almost linear time by a
simple version of Gauss elimination. The random matrix with dimensions
$n(1-\varepsilon) \times n$ is generated as follows: In each row, identify a
block of length $L=O((\log n)/\varepsilon)$ at a random position. The entries
outside the block are 0, the entries inside the block are given by fair coin
tosses. Sorting the rows according to the positions of the blocks transforms
the matrix into a kind of band matrix, on which, as it turns out, Gauss
elimination works very efficiently with high probability. For the proof, the
effects of Gauss elimination are interpreted as a ("coin-flipping") variant of
Robin Hood hashing, whose behaviour can be captured in terms of a simple Markov
model from queuing theory. Bounds for expected construction time and high
success probability follow from results in this area.
</p>
<p>By employing hashing, this matrix family leads to a new implementation of a
retrieval data structure, which represents an arbitrary function $f\colon S \to
\{0,1\}$ for some set $S$ of $m=(1-\varepsilon)n$ keys. It requires
$m/(1-\varepsilon)$ bits of space, construction takes $O(m/\varepsilon^2$)
expected time on a word RAM, while queries take $O(1/\varepsilon)$ time and
access only one contiguous segment of $O((\log m)/\varepsilon)$ bits in the
representation. The method is competitive with state-of-the-art methods. By
well-established methods the retrieval data structure leads to efficient
constructions of (static) perfect hash functions and (static) Bloom filters
with almost optimal space and very local storage access patterns for queries.
</p></div>
    </summary>
    <updated>2019-07-11T23:46:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04749</id>
    <link href="http://arxiv.org/abs/1907.04749" rel="alternate" type="text/html"/>
    <title>Dense Peelable Random Uniform Hypergraphs</title>
    <feedworld_mtime>1562803200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dietzfelbinger:Martin.html">Martin Dietzfelbinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Walzer:Stefan.html">Stefan Walzer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04749">PDF</a><br/><b>Abstract: </b>We describe a new family of $k$-uniform hypergraphs with independent random
edges. The hypergraphs have a high probability of being peelable, i.e. to admit
no sub-hypergraph of minimum degree $2$, even when the edge density (number of
edges over vertices) is close to $1$. In our construction, the vertex set is
partitioned into linearly arranged segments and each edge is incident to random
vertices of $k$ consecutive segments. Quite surprisingly, the linear geometry
allows our graphs to be peeled "from the outside in". The density thresholds
$f_k$ for peelability of our hypergraphs ($f_3 \approx 0.918$, $f_4 \approx
0.977$, $f_5 \approx 0.992$, ...) are well beyond the corresponding thresholds
($c_3 \approx 0.818$, $c_4 \approx 0.772$, $c_5 \approx 0.702$, ...) of
standard $k$-uniform random hypergraphs. To get a grip on $f_k$, we analyse an
idealised peeling process on the random weak limit of our hypergraph family.
The process can be described in terms of an operator on functions and $f_k$ can
be linked to thresholds relating to the operator. These thresholds are then
tractable with numerical methods.
</p>
<p>Random hypergraphs underlie the construction of various data structures based
on hashing. These data structures frequently rely on peelability of the
hypergraph or peelability allows for simple linear time algorithms. To
demonstrate the usefulness of our construction, we used our $3$-uniform
hypergraphs as a drop-in replacement for the standard $3$-uniform hypergraphs
in a retrieval data structure by Botelho et al. This reduces memory usage from
$1.23m$ bits to $1.12m$ bits ($m$ being the input size) with almost no change
in running time.
</p></div>
    </summary>
    <updated>2019-07-11T23:39:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04745</id>
    <link href="http://arxiv.org/abs/1907.04745" rel="alternate" type="text/html"/>
    <title>Constant-Time Dynamic $(\Delta+1)$-Coloring and Weight Approximation for Minimum Spanning Forest: Dynamic Algorithms Meet Property Testing</title>
    <feedworld_mtime>1562803200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Henzinger:Monika.html">Monika Henzinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Pan.html">Pan Peng</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04745">PDF</a><br/><b>Abstract: </b>With few exceptions (namely, algorithms for maximal matching, $2$-approximate
vertex cover, and certain constant-stretch spanners), all known fully dynamic
algorithms in general graphs require (amortized) $\Omega(\log n)$ update/query
time. Showing for the first time that techniques from property testing can lead
to constant-time fully dynamic graph algorithms we prove the following results:
</p>
<p>(1) We give a fully dynamic (Las-Vegas style) algorithm with constant
expected amortized time per update that maintains a proper $(\Delta+1)$-vertex
coloring of a graph with maximum degree at most $\Delta$. This improves upon
the previous $O(\log \Delta)$-time algorithm by Bhattacharya et al. (SODA
2018). We show that our result does not only have optimal running time, but is
also optimal in the sense that already deciding whether a $\Delta$-coloring
exists in a dynamically changing graph with maximum degree at most $\Delta$
takes $\Omega(\log n)$ time per operation.
</p>
<p>(2) We give two fully dynamic algorithms that maintain a
$(1+\varepsilon)$-approximation of the weight $M$ of the minimum spanning
forest of a graph $G$ with edges weights in $[1,W]$. Our deterministic
algorithm takes $O({W^2 \log W}/{\varepsilon^3})$ worst-case time, which is
constant if both $W$ and $\varepsilon$ are constant. This is somewhat
surprising as a lower bound by Patrascu and Demaine (SIAM J. Comput. 2006)
shows that it takes $\Omega(\log n)$ time per operation to maintain the exact
weight of the MSF that holds even for $W=1$. Our randomized (Monte-Carlo style)
algorithm works with high probability and runs in worst-case
$O(\frac{1}{\varepsilon^4}\log^2(\frac{1}{\varepsilon}))$ time if $W=
O({(m^*)^{1/3}}/{\log^3 n})$, where $m^*$ is the minimum number of edges in the
graph throughout all the updates. It works even against an adaptive adversary.
</p></div>
    </summary>
    <updated>2019-07-11T23:37:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04741</id>
    <link href="http://arxiv.org/abs/1907.04741" rel="alternate" type="text/html"/>
    <title>Matroid Bases with Cardinality Constraints on the Intersection</title>
    <feedworld_mtime>1562803200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lendl:Stefan.html">Stefan Lendl</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peis:Britta.html">Britta Peis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Timmermans:Veerle.html">Veerle Timmermans</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04741">PDF</a><br/><b>Abstract: </b>Given two matroids $\mathcal{M}_{1} = (E, \mathcal{B}_{1})$ and
$\mathcal{M}_{2} = (E, \mathcal{B}_{2})$ on a common ground set $E$ with base
sets $\mathcal{B}_{1}$ and $\mathcal{B}_{2}$, some integer $k \in \mathbb{N}$,
and two cost functions $c_{1}, c_{2} \colon E \rightarrow \mathbb{R}$, we
consider the optimization problem to find a basis $X \in \mathcal{B}_{1}$ and a
basis $Y \in \mathcal{B}_{2}$ minimizing cost $\sum_{e\in X} c_1(e)+\sum_{e\in
Y} c_2(e)$
</p>
<p>subject to either a lower bound constraint $|X \cap Y| \le k$, an upper bound
constraint $|X \cap Y| \ge k$, or an equality constraint $|X \cap Y| = k$ on
the size of the intersection of the two bases $X$ and $Y$. The problem with
lower bound constraint turns out to be a generalization of the Recoverable
Robust Matroid problem under interval uncertainty representation for which the
question for a strongly polynomial-time algorithm was left as an open question
by Hradovich et al.
</p>
<p>We show that the two problems with lower and upper bound constraints on the
size of the intersection can be reduced to weighted matroid intersection, and
thus be solved with a strongly polynomial-time primal-dual algorithm. The
question whether the problem with equality constraint can also be solved
efficiently turned out to be a lot harder. As our main result, we present a
strongly-polynomial, primal-dual algorithm for the problem with equality
constraint on the size of the intersection.
</p>
<p>Additionally, we discuss generalizations of the problems from matroids to
polymatroids, and from two to three or more matroids.
</p></div>
    </summary>
    <updated>2019-07-11T23:39:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04660</id>
    <link href="http://arxiv.org/abs/1907.04660" rel="alternate" type="text/html"/>
    <title>String Attractors and Combinatorics on Words</title>
    <feedworld_mtime>1562803200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mantaci:Sabrina.html">Sabrina Mantaci</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Restivo:Antonio.html">Antonio Restivo</a>, Giuseppe Romana, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rosone:Giovanna.html">Giovanna Rosone</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sciortino:Marinella.html">Marinella Sciortino</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04660">PDF</a><br/><b>Abstract: </b>The notion of \emph{string attractor} has recently been introduced in
[Prezza, 2017] and studied in [Kempa and Prezza, 2018] to provide a unifying
framework for known dictionary-based compressors. A string attractor for a word
$w=w[1]w[2]\cdots w[n]$ is a subset $\Gamma$ of the positions $\{1,\ldots,n\}$,
such that all distinct factors of $w$ have an occurrence crossing at least one
of the elements of $\Gamma$. While finding the smallest string attractor for a
word is a NP-complete problem, it has been proved in [Kempa and Prezza, 2018]
that dictionary compressors can be interpreted as algorithms approximating the
smallest string attractor for a given word.
</p>
<p>In this paper we explore the notion of string attractor from a combinatorial
point of view, by focusing on several families of finite words. The results
presented in the paper suggest that the notion of string attractor can be used
to define new tools to investigate combinatorial properties of the words.
</p></div>
    </summary>
    <updated>2019-07-11T23:40:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04640</id>
    <link href="http://arxiv.org/abs/1907.04640" rel="alternate" type="text/html"/>
    <title>Santha-Vazirani sources, deterministic condensers and very strong extractors</title>
    <feedworld_mtime>1562803200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gavinsky:Dmitry.html">Dmitry Gavinsky</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pudl=aacute=k:Pavel.html">Pavel Pudlák</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04640">PDF</a><br/><b>Abstract: </b>The notion of semi-random sources, also known as Santha-Vazirani (SV)
sources, stands for a sequence of n bits, where the dependence of the i'th bit
on the previous i-1 bits is limited for every $i\in[n]$. If the dependence of
the i'th bit on the remaining n-1 bits is limited, then this is a strong
SV-source. Even the strong SV-sources are known not to admit (universal)
deterministic extractors, but they have seeded extractors, as their min-entropy
is $\Omega(n)$. It is intuitively obvious that strong SV-sources are more than
just high-min-entropy sources, and this work explores the intuition.
Deterministic condensers are known not to exist for general high-min-entropy
sources, and we construct for any constants $\epsilon, \delta \in (0,1)$ a
deterministic condenser that maps n bits coming from a strong SV-source with
bias at most $\delta$ to $\Omega(n)$ bits of min-entropy rate at least
$1-\epsilon$. In conclusion we observe that deterministic condensers are
closely related to very strong extractors - a proposed strengthening of the
notion of strong (seeded) extractors: in particular, our constructions can be
viewed as very strong extractors for the family of strong Santha-Vazirani
distributions. The notion of very strong extractors requires that the output
remains unpredictable even to someone who knows not only the seed value (as in
the case of strong extractors), but also the extractor's outputs corresponding
to the same input value with each of the preceding seed values (say, under the
lexicographic ordering). Very strong extractors closely resemble the original
notion of SV-sources, except that the bits must satisfy the unpredictability
requirement only on average.
</p></div>
    </summary>
    <updated>2019-07-11T23:35:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04629</id>
    <link href="http://arxiv.org/abs/1907.04629" rel="alternate" type="text/html"/>
    <title>Evolutionary techniques in lattice sieving algorithms</title>
    <feedworld_mtime>1562803200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Laarhoven:Thijs.html">Thijs Laarhoven</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04629">PDF</a><br/><b>Abstract: </b>Lattice-based cryptography has recently emerged as a prominent candidate for
secure communication in the quantum age. Its security relies on the hardness of
certain lattice problems, and the inability of known lattice algorithms, such
as lattice sieving, to solve these problems efficiently. In this paper we
investigate the similarities between lattice sieving and evolutionary
algorithms, how various improvements to lattice sieving can be viewed as
applications of known techniques from evolutionary computation, and how other
evolutionary techniques can benefit lattice sieving in practice.
</p></div>
    </summary>
    <updated>2019-07-11T23:39:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04585</id>
    <link href="http://arxiv.org/abs/1907.04585" rel="alternate" type="text/html"/>
    <title>Quasi-polynomial time approximation schemes for the Maximum Weight Independent Set Problem in H-free graphs</title>
    <feedworld_mtime>1562803200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chudnovsky:Maria.html">Maria Chudnovsky</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pilipczuk:Marcin.html">Marcin Pilipczuk</a>, Michał Pilipczuk, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thomass=eacute=:St=eacute=phan.html">Stéphan Thomassé</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04585">PDF</a><br/><b>Abstract: </b>In the Maximum Independent Set problem we are asked to find a set of pairwise
nonadjacent vertices in a given graph with the maximum possible cardinality. In
general graphs, this classical problem is known to be NP-hard and hard to
approximate within a factor of $n^{1-\varepsilon}$ for any $\varepsilon &gt; 0$.
Due to this, investigating the complexity of \textsc{Maximum Independent Set}
in various graph classes in hope of finding better tractability results is an
active research direction.
</p>
<p>In $H$-free graphs, that is, graphs not containing a fixed graph $H$ as an
induced subgraph, the problem is known to remain NP-hard and APX-hard whenever
$H$ contains a cycle, a vertex of degree at least four, or two vertices of
degree at least three in one connected component. For the remaining cases,
where every component of $H$ is a path or a subdivided claw, the complexity of
Maximum Independent Set remains widely open, with only a handful of
polynomial-time solvability results for small graphs $H$ such as $P_5$, $P_6$,
the claw, or the fork.
</p>
<p>We prove that for every such "possibly tractable" graph $H$ there exists an
algorithm that, given an $H$-free graph $G$ and an accuracy parameter
$\varepsilon &gt; 0$, finds an independent set in $G$ of cardinality within a
factor of $(1-\varepsilon)$ of the optimum in time exponential in a polynomial
of $\log |V(G)|$ and $\varepsilon^{-1}$. That is, we show that for every graph
$H$ for which Maximum Independent Set is not known to be APX-hard in $H$-free
graphs, the problem admits a quasi-polynomial time approximation scheme in this
graph class. Our algorithm works also in the more general weighted setting,
where the input graph is supplied with a weight function on vertices and we are
maximizing the total weight of an independent set.
</p></div>
    </summary>
    <updated>2019-07-11T23:47:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04512</id>
    <link href="http://arxiv.org/abs/1907.04512" rel="alternate" type="text/html"/>
    <title>Computing the Maximum Degree of Minors in Skew Polynomial Matrices</title>
    <feedworld_mtime>1562803200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Oki:Taihei.html">Taihei Oki</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04512">PDF</a><br/><b>Abstract: </b>Skew polynomials, which have a noncommutative multiplication rule between
coefficients and an indeterminate, are the most general polynomial concept that
admits the degree function with desirable properties. This paper presents the
first algorithms to compute the maximum degree of the Dieudonn\'e determinant
of a $k \times k$ submatrix in a matrix $A$ whose entries are skew polynomials
over a skew field $F$. Our algorithms make use of the discrete Legendre
conjugacy between the sequences of the maximum degrees and the ranks of block
matrices over $F$ obtained from coefficient matrices of $A$. Three applications
of our algorithms are provided: (i) computing the dimension of the solution
spaces of linear differential and difference equations, (ii) determining the
Smith-McMillan form of transfer function matrices of linear time-varying
systems and (iii) solving the "weighted" version of noncommutative Edmonds'
problem with polynomial bit complexity. We also show that the deg-det
computation for matrices over sparse polynomials is at least as hard as solving
commutative Edmonds' problem.
</p></div>
    </summary>
    <updated>2019-07-11T23:50:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.04498</id>
    <link href="http://arxiv.org/abs/1907.04498" rel="alternate" type="text/html"/>
    <title>Speed Scaling with Tandem Servers</title>
    <feedworld_mtime>1562803200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vaze:Rahul.html">Rahul Vaze</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nair:Jayakrishnan.html">Jayakrishnan Nair</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.04498">PDF</a><br/><b>Abstract: </b>Speed scaling for a tandem server setting is considered, where there is a
series of servers, and each job has to be processed by each of the servers in
sequence. Servers have a variable speed, their power consumption being a convex
increasing function of the speed. We consider the worst case setting as well as
the stochastic setting. In the worst case setting, the jobs are assumed to be
of unit size with arbitrary (possibly adversarially determined) arrival
instants. For this problem, we devise an online speed scaling algorithm that is
constant competitive with respect to the optimal offline algorithm that has
non-causal information. The proposed algorithm, at all times, uses the same
speed on all active servers, such that the total power consumption equals the
number of outstanding jobs. In the stochastic setting, we consider a more
general tandem network, with a parallel bank of servers at each stage. In this
setting, we show that random routing with a simple gated static speed selection
is constant competitive. In both cases, the competitive ratio depends only on
the power functions, and is independent of the workload and the number of
servers.
</p></div>
    </summary>
    <updated>2019-07-11T23:47:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-11T01:30:00Z</updated>
    </source>
  </entry>
</feed>
