<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2022-02-21T13:39:02Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/026</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/026" rel="alternate" type="text/html"/>
    <title>TR22-026 |  Trading Time and Space in Catalytic Branching Programs | 

	Ian Mertz, 

	James  Cook</title>
    <summary>An $m$-catalytic branching program (Girard, Koucky, McKenzie 2015) is a set of $m$ distinct branching programs for $f$ which are permitted to share internal (i.e. non-source non-sink) nodes. While originally introduced as a non-uniform analogue to catalytic space, this also gives a natural notion of amortized non-uniform space complexity for $f$, namely the smallest value $|G|/m$ for an $m$-catalytic branching program $G$ for $f$ (Potechin 2017).

Potechin (2017) showed that every function $f$ has amortized size $O(n)$, witnessed by an $m$-catalytic branching program where $m = 2^{2^n-1}$. We recreate this result by defining a catalytic algorithm for evaluating polynomials using a large amount of space but $O(n)$ time. This allows us to balance this with previously known algorithms which are efficient with respect to space at the cost of time (Cook, Mertz 2020, 2021). We show that for any $\epsilon \geq 2n^{-1}$, every function $f$ has an $m$-catalytic branching program of size $O_\epsilon(mn)$, where $m = 2^{2^{\epsilon n}}$. We similarly recreate an improved result due to Robere and Zuiddam (2021), and show that for $d \leq n$ and $\epsilon \geq 2d^{-1}$, the same result holds for $m = 2^{n \choose \leq \epsilon d}$ as long as $f$ is a degree-$d$ polynomial over $\mathbb{F}_2$. We also show that for certain classes of functions, $m$ can be reduced to $2^{poly(n)}$ while still maintaining linear or quasi-linear amortized size.

In the other direction, we bound the necessary length, and by extension the amortized size, of any permutation branching program for an arbitrary function between $3n$ and $4n-4$.</summary>
    <updated>2022-02-20T12:27:11Z</updated>
    <published>2022-02-20T12:27:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-21T13:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/025</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/025" rel="alternate" type="text/html"/>
    <title>TR22-025 |  Efficient Low-Space Simulations From the Failure of the Weak Pigeonhole Principle | 

	Oliver Korten</title>
    <summary>A recurring challenge in the theory of pseudorandomness and circuit complexity is the explicit construction of ``incompressible strings,'' i.e. finite objects which lack a specific type of structure or simplicity. In most cases, there is an associated NP search problem which we call the ``compression problem,'' where we are given a candidate object and must either find a compressed/structured representation of it or determine that none exist. For a particular notion of compressibility, a natural question is whether an efficient algorithm for the compression problem would aide us in the construction of incompressible objects. Consider the following two instances of this question:

(1) Does an efficient algorithm for circuit minimization imply efficient constructions of hard truth tables?

(2) Does an efficient algorithm for factoring integers imply efficient constructions of large prime numbers?
 
In this work, we connect these kinds of questions to the long-standing challenge of proving space/time tradeoffs for Turing machines, and proving stronger separations between the RAM and 1-tape computation models. In particular, one of our main theorems shows that modest space/time tradeoffs for deterministic exponential time, or separations between basic Turing machine memory models, would imply a positive answer to both (1) and (2). 
These results apply to a more general class of explicit construction problems, where we have some efficient compression scheme that encodes $n$-bit strings using $&lt;n$ bits, and we aim to construct an $n$-bit string which cannot be recovered from its encoding.</summary>
    <updated>2022-02-20T12:24:52Z</updated>
    <published>2022-02-20T12:24:52Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-21T13:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2022/02/20/prague-summer-school-on-discrete-mathematics-2/</id>
    <link href="https://cstheory-events.org/2022/02/20/prague-summer-school-on-discrete-mathematics-2/" rel="alternate" type="text/html"/>
    <title>Prague Summer School on Discrete Mathematics</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 11-15, 2022 Prague, Czech Republic https://www.mff.cuni.cz/en/iuuk/events/prague-summer-school-on-discrete-mathematics Registration deadline: March 1, 2022 Prague Summer School on Discrete Mathematics 2022 will feature lecture series on statistical physics methods in combinatorics (Will Perkins) and the container method (Wojciech Samotij). The School is primarily intended for PhD students and postdocs, but students and researchers in other stages of … <a class="more-link" href="https://cstheory-events.org/2022/02/20/prague-summer-school-on-discrete-mathematics-2/">Continue reading <span class="screen-reader-text">Prague Summer School on Discrete Mathematics</span></a></div>
    </summary>
    <updated>2022-02-20T08:30:21Z</updated>
    <published>2022-02-20T08:30:21Z</published>
    <category term="school"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2022-02-21T13:38:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/024</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/024" rel="alternate" type="text/html"/>
    <title>TR22-024 |  Pseudorandomness of Expander Random Walks for Symmetric Functions and Permutation Branching Programs | 

	Louis Golowich, 

	Salil Vadhan</title>
    <summary>We study the pseudorandomness of random walks on expander graphs against tests computed by symmetric functions and permutation branching programs. These questions are motivated by applications of expander walks in the coding theory and derandomization literatures. We show that expander walks fool symmetric functions up to a $O(\lambda)$ error in total variation distance. This bound improves upon a line of prior work, which gave bounds that were weaker or applied only in more restricted cases. We extend our analysis to unify it with and strengthen the expander walk Chernoff bound. We then show that expander walks fool permutation branching programs up to a $O(\lambda)$ error in $\ell_2$-distance, and we prove that much tighter bounds hold for programs with a certain structure. We also prove lower bounds to show that our results are tight. To prove our results for symmetric functions, we analyze the Fourier coefficients of the relevant distributions using linear-algebraic techniques. Our analysis for permutation branching programs is likewise linear-algebraic in nature, but also makes use of the recently introduced singular-value approximation notion for matrices (Ahmadinejad et al. 2021).</summary>
    <updated>2022-02-20T08:20:04Z</updated>
    <published>2022-02-20T08:20:04Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-21T13:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08753</id>
    <link href="http://arxiv.org/abs/2202.08753" rel="alternate" type="text/html"/>
    <title>Strong spatial mixing for repulsive point processes</title>
    <feedworld_mtime>1645315200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Michelen:Marcus.html">Marcus Michelen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Perkins:Will.html">Will Perkins</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08753">PDF</a><br/><b>Abstract: </b>We prove that a Gibbs point process interacting via a finite-range, repulsive
potential $\phi$ exhibits a strong spatial mixing property for activities
$\lambda &lt; e/\Delta_{\phi}$, where $\Delta_{\phi}$ is the potential-weighted
connective constant of $\phi$, defined recently in [MP21]. Using this we derive
several analytic and algorithmic consequences when $\lambda$ satisfies this
bound: (1) We prove new identities for the infinite volume pressure and surface
pressure of such a process (and in the case of the surface pressure establish
its existence). (2) We prove that local block dynamics for sampling from the
model on a box of volume $N$ in $\mathbb R^d$ mixes in time $O(N \log N)$,
giving efficient randomized algorithms to approximate the partition function of
and approximately sample from these models. (3) We use the above identities and
algorithms to give efficient approximation algorithms for the pressure and
surface pressure.
</p></div>
    </summary>
    <updated>2022-02-20T22:41:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08737</id>
    <link href="http://arxiv.org/abs/2202.08737" rel="alternate" type="text/html"/>
    <title>Listing Maximal k-Plexes in Large Real-World Graphs</title>
    <feedworld_mtime>1645315200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Zhengren Wang, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Yi.html">Yi Zhou</a>, Mingyun Xiao, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khoussainov:Bakhadyr.html">Bakhadyr Khoussainov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08737">PDF</a><br/><b>Abstract: </b>Listing dense subgraphs in large graphs plays a key task in varieties of
network analysis applications like community detection. Clique, as the densest
model, has been widely investigated. However, in practice, communities rarely
form as cliques for various reasons, e.g., data noise. Therefore, $k$-plex, --
graph with each vertex adjacent to all but at most $k$ vertices, is introduced
as a relaxed version of clique. Often, to better simulate cohesive communities,
an emphasis is placed on connected $k$-plexes with small $k$. In this paper, we
continue the research line of listing all maximal $k$-plexes and maximal
$k$-plexes of prescribed size. Our first contribution is algorithm
\emph{ListPlex} that lists all maximal $k$-plexes in $O^*(\gamma^D)$ time for
each constant $k$, where $\gamma$ is a value related to $k$ but strictly
smaller than 2, and $D$ is the degeneracy of the graph that is far less than
the vertex number $n$ in real-word graphs. Compared to the trivial bound of
$2^n$, the improvement is significant, and our bound is better than all
previously known results. In practice, we further use several techniques to
accelerate listing $k$-plexes of a given size, such as structural-based prune
rules, cache-efficient data structures, and parallel techniques. All these
together result in a very practical algorithm. Empirical results show that our
approach outperforms the state-of-the-art solutions by up to orders of
magnitude.
</p></div>
    </summary>
    <updated>2022-02-20T22:49:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08704</id>
    <link href="http://arxiv.org/abs/2202.08704" rel="alternate" type="text/html"/>
    <title>A Bi-Criteria FPTAS for Scheduling with Memory Constraints on Graph with Bounded Tree-width</title>
    <feedworld_mtime>1645315200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Angel:Eric.html">Eric Angel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Morais:S=eacute=bastien.html">Sébastien Morais</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Regnault:Damien.html">Damien Regnault</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08704">PDF</a><br/><b>Abstract: </b>In this paper we study a scheduling problem arising from executing numerical
simulations on HPC architectures. With a constant number of parallel machines,
the objective is to minimize the makespan under memory constraints for the
machines. Those constraints come from a neighborhood graph G for the jobs.
Motivated by a previous result on graphs G with bounded path-width, our focus
is on the case when the neighborhood graph G has bounded tree-width. Our result
is a bi-criteria fully polynomial time approximation algorithm based on a
dynamic programming algorithm. It allows to find a solution within a factor of
1 + epsilon of the optimal makespan, where the memory capacity of the machines
may be exceeded by a factor at most 1 + epsilon. This result relies on the use
of a nice tree decomposition of G and its traversal in a specific way which may
be useful on its own. The case of unrelated machines is also tractable with
minor modifications.
</p></div>
    </summary>
    <updated>2022-02-20T22:43:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08688</id>
    <link href="http://arxiv.org/abs/2202.08688" rel="alternate" type="text/html"/>
    <title>Improved Optimal Testing Results from Global Hypercontractivity</title>
    <feedworld_mtime>1645315200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaufman:Tali.html">Tali Kaufman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Minzer:Dor.html">Dor Minzer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08688">PDF</a><br/><b>Abstract: </b>The problem of testing low-degree polynomials has received significant
attention over the years due to its importance in theoretical computer science,
and in particular in complexity theory. The problem is specified by three
parameters: field size $q$, degree $d$ and proximity parameter $\delta$, and
the goal is to design a tester making as few as possible queries to a given
function, which is able to distinguish between the case the given function has
degree at most $d$, and the case the given function is $\delta$-far from any
degree $d$ function.
</p>
<p>A tester is called optimal if it makes $O(q^d+1/\delta)$ queries (which are
known to be necessary). For the field of size $q$, the natural $t$-flat tester
was shown to be optimal first by Bhattacharyya et al. for $q=2$, and later by
Haramaty et al. for all prime powers $q$. The dependency on the field size,
however, is a tower-type function.
</p>
<p>We improve the results above, showing that the dependency on the field size
is polynomial. Our approach also applies in the more general setting of lifted
affine invariant codes, and is based on studying the structure of the
collection of erroneous subspaces. i.e. subspaces $A$ such that $f|_{A}$ has
degree greater than $d$. Towards this end, we observe that these sets are
poorly expanding in the affine version of the Grassmann graph and use that to
establish structural results on them via global hypercontractivity. We then use
this structure to perform local correction on $f$.
</p></div>
    </summary>
    <updated>2022-02-20T22:37:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08658</id>
    <link href="http://arxiv.org/abs/2202.08658" rel="alternate" type="text/html"/>
    <title>The merged-staircase property: a necessary and nearly sufficient condition for SGD learning of sparse functions on two-layer neural networks</title>
    <feedworld_mtime>1645315200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abbe:Emmanuel.html">Emmanuel Abbe</a>, Enric Boix-Adsera, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Misiakiewicz:Theodor.html">Theodor Misiakiewicz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08658">PDF</a><br/><b>Abstract: </b>It is currently known how to characterize functions that neural networks can
learn with SGD for two extremal parameterizations: neural networks in the
linear regime, and neural networks with no structural constraints. However, for
the main parametrization of interest (non-linear but regular networks) no tight
characterization has yet been achieved, despite significant developments.
</p>
<p>We take a step in this direction by considering depth-2 neural networks
trained by SGD in the mean-field regime. We consider functions on binary inputs
that depend on a latent low-dimensional subspace (i.e., small number of
coordinates). This regime is of interest since it is poorly understood how
neural networks routinely tackle high-dimensional datasets and adapt to latent
low-dimensional structure without suffering from the curse of dimensionality.
Accordingly, we study SGD-learnability with $O(d)$ sample complexity in a large
ambient dimension $d$.
</p>
<p>Our main results characterize a hierarchical property, the "merged-staircase
property", that is both necessary and nearly sufficient for learning in this
setting.
</p>
<p>We further show that non-linear training is necessary: for this class of
functions, linear methods on any feature map (e.g., the NTK) are not capable of
learning efficiently. The key tools are a new "dimension-free" dynamics
approximation result that applies to functions defined on a latent space of
low-dimension, a proof of global convergence based on polynomial identity
testing, and an improvement of lower bounds against linear methods for
non-almost orthogonal functions.
</p></div>
    </summary>
    <updated>2022-02-20T22:47:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08549</id>
    <link href="http://arxiv.org/abs/2202.08549" rel="alternate" type="text/html"/>
    <title>Oracle-Efficient Online Learning for Beyond Worst-Case Adversaries</title>
    <feedworld_mtime>1645315200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haghtalab:Nika.html">Nika Haghtalab</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Han:Yanjun.html">Yanjun Han</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shetty:Abhishek.html">Abhishek Shetty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Kunhe.html">Kunhe Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08549">PDF</a><br/><b>Abstract: </b>In this paper, we study oracle-efficient algorithms for beyond worst-case
analysis of online learning. We focus on two settings. First, the smoothed
analysis setting of [RST11, HRS12] where an adversary is constrained to
generating samples from distributions whose density is upper bounded by
$1/\sigma$ times the uniform density. Second, the setting of $K$-hint
transductive learning, where the learner is given access to $K$ hints per time
step that are guaranteed to include the true instance. We give the first known
oracle-efficient algorithms for both settings that depend only on the VC
dimension of the class and parameters $\sigma$ and $K$ that capture the power
of the adversary. In particular, we achieve oracle-efficient regret bounds of $
O ( \sqrt{T (d / \sigma )^{1/2} } ) $ and $ O ( \sqrt{T d K } )$ respectively
for these setting. For the smoothed analysis setting, our results give the
first oracle-efficient algorithm for online learning with smoothed adversaries
[HRS21]. This contrasts the computational separation between online learning
with worst-case adversaries and offline learning established by [HK16]. Our
algorithms also imply improved bounds for worst-case setting with small
domains. In particular, we give an oracle-efficient algorithm with regret of $O
( \sqrt{T(d \vert{\mathcal{X}}\vert ) ^{1/2} })$, which is a refinement of the
earlier $O ( \sqrt{T\vert{\mathcal{X} } \vert })$ bound by [DS16].
</p></div>
    </summary>
    <updated>2022-02-20T22:42:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08544</id>
    <link href="http://arxiv.org/abs/2202.08544" rel="alternate" type="text/html"/>
    <title>Efficient Classification of Local Problems in Regular Trees</title>
    <feedworld_mtime>1645315200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Balliu:Alkida.html">Alkida Balliu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brandt:Sebastian.html">Sebastian Brandt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chang:Yi=Jun.html">Yi-Jun Chang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Olivetti:Dennis.html">Dennis Olivetti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Studen=yacute=:Jan.html">Jan Studený</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suomela:Jukka.html">Jukka Suomela</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08544">PDF</a><br/><b>Abstract: </b>We give practical, efficient algorithms that automatically determine the
distributed round complexity of a given locally checkable graph problem, in two
settings. We present one algorithm for unrooted regular trees and another
algorithm for rooted regular trees. The algorithms take the description of a
locally checkable labeling problem as input, and the running time is polynomial
in the size of the problem description. The algorithms decide if the problem is
solvable in $O(\log n)$ rounds. If not, it is known that the complexity has to
be $\Theta(n^{1/k})$ for some $k = 1, 2, \dotsc$, and in this case the
algorithms also output the right value of the exponent $k$.
</p>
<p>In rooted trees in the $O(\log n)$ case we can then further determine the
exact complexity class by using algorithms from prior work; for unrooted trees
the more fine-grained classification in the $O(\log n)$ region remains an open
question.
</p></div>
    </summary>
    <updated>2022-02-20T22:39:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08489</id>
    <link href="http://arxiv.org/abs/2202.08489" rel="alternate" type="text/html"/>
    <title>A Faster Interior-Point Method for Sum-of-Squares Optimization</title>
    <feedworld_mtime>1645315200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Shunhua.html">Shunhua Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Natura:Bento.html">Bento Natura</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weinstein:Omri.html">Omri Weinstein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08489">PDF</a><br/><b>Abstract: </b>We present a faster interior-point method for optimizing sum-of-squares (SOS)
polynomials, which are a central tool in polynomial optimization and capture
convex programming in the Lasserre hierarchy. Let $p = \sum_i q^2_i$ be an
$n$-variate SOS polynomial of degree $2d$. Denoting by $L := \binom{n+d}{d}$
and $U := \binom{n+2d}{2d}$ the dimensions of the vector spaces in which
$q_i$'s and $p$ live respectively, our algorithm runs in time
$\tilde{O}(LU^{1.87})$. This is polynomially faster than state-of-art SOS and
semidefinite programming solvers, which achieve runtime
$\tilde{O}(L^{0.5}\min\{U^{2.37}, L^{4.24}\})$.
</p>
<p>The centerpiece of our algorithm is a dynamic data structure for maintaining
the inverse of the Hessian of the SOS barrier function under the polynomial
interpolant basis, which efficiently extends to multivariate SOS optimization,
and requires maintaining spectral approximations to low-rank perturbations of
elementwise (Hadamard) products. This is the main challenge and departure from
recent IPM breakthroughs using inverse-maintenance, where low-rank updates to
the slack matrix readily imply the same for the Hessian matrix.
</p></div>
    </summary>
    <updated>2022-02-20T22:48:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08482</id>
    <link href="http://arxiv.org/abs/2202.08482" rel="alternate" type="text/html"/>
    <title>Online Scheduling of Time-Critical Tasks to Minimize the Number of Calibrations</title>
    <feedworld_mtime>1645315200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Zuzhi.html">Zuzhi Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Jialin.html">Jialin Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08482">PDF</a><br/><b>Abstract: </b>We study the online scheduling problem where the machines need to be
calibrated before processing any jobs. To calibrate a machine, it will take
$\lambda$ time steps as the activation time, and then the machine will remain
calibrated status for $T$ time steps. The job can only be processed by the
machine that is in calibrated status. Given a set of jobs arriving online, each
of the jobs is characterized by a release time, a processing time, and a
deadline. We assume that there is an infinite number of machines for usage. The
objective is to minimize the total number of calibrations while feasibly
scheduling all jobs.
</p>
<p>For the case that all jobs have unit processing times, we propose an
$\mathcal{O}(\lambda)$-competitive algorithm, which is asymptotically optimal.
When $\lambda=0$, the problem is degraded to rent minimization, where our
algorithm achieves a competitive ratio of $3e+7(\approx 15.16)$ which improves
upon the previous results for such problems.
</p></div>
    </summary>
    <updated>2022-02-20T22:47:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08445</id>
    <link href="http://arxiv.org/abs/2202.08445" rel="alternate" type="text/html"/>
    <title>Extended MSO Model Checking via Small Vertex Integrity</title>
    <feedworld_mtime>1645315200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gima:Tatsuya.html">Tatsuya Gima</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Otachi:Yota.html">Yota Otachi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08445">PDF</a><br/><b>Abstract: </b>We study the model checking problem of an extended $\mathsf{MSO}$ with local
and global cardinality constraints, called
$\mathsf{MSO}^{\mathsf{GL}}_{\mathsf{Lin}}$, introduced recently by Knop,
Kouteck\'{y}, Masa\v{r}\'{\i}k, and Toufar [Log. Methods Comput. Sci., 15(4),
2019]. We show that the problem is fixed-parameter tractable parameterized by
vertex integrity, where vertex integrity is a graph parameter standing between
vertex cover number and treedepth. Our result thus fill a gap between the
fixed-parameter tractability parameterized by vertex cover number and the
W[1]-hardness parameterized by treedepth.
</p></div>
    </summary>
    <updated>2022-02-20T22:41:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08357</id>
    <link href="http://arxiv.org/abs/2202.08357" rel="alternate" type="text/html"/>
    <title>On the Complexity of Some Variations of Sorting by Transpositions</title>
    <feedworld_mtime>1645315200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alexandrino:Alexsandro_Oliveira.html">Alexsandro Oliveira Alexandrino</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Oliveira:Andre_Rodrigues.html">Andre Rodrigues Oliveira</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dias:Ulisses.html">Ulisses Dias</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dias:Zanoni.html">Zanoni Dias</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08357">PDF</a><br/><b>Abstract: </b>One of the main challenges in Computational Biology is to find the
evolutionary distance between two organisms. In the field of comparative
genomics, one way to estimate such distance is to find a minimum cost sequence
of rearrangements (large scale mutations) needed to transform one genome into
another, which is called the rearrangement distance. In the past decades, these
problems were studied considering many types of rearrangements (such as
reversals, transpositions, transreversals, and revrevs) and considering the
same weight for all rearrangements, or different weights depending on the types
of rearrangements. The complexity of the problems involving reversals,
transpositions, and both rearrangements is known, even though the hardness
proof for the problem combining reversals and transpositions was recently
given. In this paper, we enhance the knowledge for these problems by proving
that models involving transpositions alongside reversals, transreversals, and
revrevs are NP-hard, considering weights w1 for reversals and w2 for the other
rearrangements such that w2/w1 is less than or equal to 1.5. In addition, we
address a cost function related to the number of fragmentations caused by a
rearrangement, proving that the problem of finding a minimum cost sorting
sequence, considering the fragmentation cost function with some restrictions,
is NP-hard for transpositions and the combination of reversals and
transpositions.
</p></div>
    </summary>
    <updated>2022-02-20T22:38:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08351</id>
    <link href="http://arxiv.org/abs/2202.08351" rel="alternate" type="text/html"/>
    <title>Flat tori with large Laplacian eigenvalues in dimensions up to eight</title>
    <feedworld_mtime>1645315200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kao:Chiu=Yen.html">Chiu-Yen Kao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Osting:Braxton.html">Braxton Osting</a>, Jackson C. Turner <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08351">PDF</a><br/><b>Abstract: </b>We consider the optimization problem of maximizing the $k$-th Laplacian
eigenvalue, $\lambda_{k}$, over flat $d$-dimensional tori of fixed volume. For
$k=1$, this problem is equivalent to the densest lattice sphere packing
problem. For larger $k$, this is equivalent to the NP-hard problem of finding
the $d$-dimensional (dual) lattice with longest $k$-th shortest lattice vector.
As a result of extensive computations, for $d \leq 8$, we obtain a sequence of
flat tori, $T_{k,d}$, each of volume one, such that the $k$-th Laplacian
eigenvalue of $T_{k,d}$ is very large; for each (finite) $k$ the $k$-th
eigenvalue exceeds the value in (the $k\to \infty$ asymptotic) Weyl's law by a
factor between 1.54 and 2.01, depending on the dimension. Stationarity
conditions are derived and numerically verified for $T_{k,d}$ and we describe
the degeneration of the tori as $k \to \infty$.
</p></div>
    </summary>
    <updated>2022-02-20T22:58:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08349</id>
    <link href="http://arxiv.org/abs/2202.08349" rel="alternate" type="text/html"/>
    <title>Approximating Output Probabilities of Shallow Quantum Circuits which are Geometrically-local in any Fixed Dimension</title>
    <feedworld_mtime>1645315200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Suchetan Dontha, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tan:Shi_Jie_Samuel.html">Shi Jie Samuel Tan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Smith:Stephen.html">Stephen Smith</a>, Sangheon Choi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Coudron:Matthew.html">Matthew Coudron</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08349">PDF</a><br/><b>Abstract: </b>We present a classical algorithm that, for any $D$-dimensional
geometrically-local, quantum circuit $C$ of polylogarithmic-depth, and any bit
string $x \in {0,1}^n$, can compute the quantity $|&lt;x|C|0^{\otimes n}&gt;|^2$ to
within any inverse-polynomial additive error in quasi-polynomial time, for any
fixed dimension $D$. This is an extension of the result [CC21], which
originally proved this result for $D = 3$. To see why this is interesting, note
that, while the $D = 1$ case of this result follows from standard use of Matrix
Product States, known for decades, the $D = 2$ case required novel and
interesting techniques introduced in [BGM19]. Extending to the case $D = 3$ was
even more laborious and required further new techniques introduced in [CC21].
Our work here shows that, while handling each new dimension has historically
required a new insight, and fixed algorithmic primitive, based on known
techniques for $D \leq 3$, we can now handle any fixed dimension $D &gt; 3$.
</p>
<p>Our algorithm uses the Divide-and-Conquer framework of [CC21] to approximate
the desired quantity via several instantiations of the same problem type, each
involving $D$-dimensional circuits on about half the number of qubits as the
original. This division step is then applied recursively, until the width of
the recursively decomposed circuits in the $D^{th}$ dimension is so small that
they can effectively be regarded as $(D-1)$-dimensional problems by absorbing
the small width in the $D^{th}$ dimension into the qudit structure at the cost
of a moderate increase in runtime. The main technical challenge lies in
ensuring that the more involved portions of the recursive circuit decomposition
and error analysis from [CC21] still hold in higher dimensions, which requires
small modifications to the analysis in some places.
</p></div>
    </summary>
    <updated>2022-02-20T22:39:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08326</id>
    <link href="http://arxiv.org/abs/2202.08326" rel="alternate" type="text/html"/>
    <title>SAT Backdoors: Depth Beats Size</title>
    <feedworld_mtime>1645315200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dreier:Jan.html">Jan Dreier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ordyniak:Sebastian.html">Sebastian Ordyniak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Szeider:Stefan.html">Stefan Szeider</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08326">PDF</a><br/><b>Abstract: </b>For several decades, much effort has been put into identifying classes of CNF
formulas whose satisfiability can be decided in polynomial time. Classic
results are the linear-time tractability of Horn formulas (Aspvall, Plass, and
Tarjan, 1979) and Krom (i.e., 2CNF) formulas (Dowling and Gallier, 1984).
Backdoors, introduced by Williams Gomes and Selman (2003), gradually extend
such a tractable class to all formulas of bounded distance to the class.
Backdoor size provides a natural but rather crude distance measure between a
formula and a tractable class. Backdoor depth, introduced by M\"{a}hlmann,
Siebertz, and Vigny (2021), is a more refined distance measure, which admits
the utilization of different backdoor variables in parallel. Bounded backdoor
size implies bounded backdoor depth, but there are formulas of constant
backdoor depth and arbitrarily large backdoor size.
</p>
<p>We propose FPT approximation algorithms to compute backdoor depth into the
classes Horn and Krom. This leads to a linear-time algorithm for deciding the
satisfiability of formulas of bounded backdoor depth into these classes. We
base our FPT approximation algorithm on a sophisticated notion of obstructions,
extending M\"{a}hlmann et al.'s obstruction trees in various ways, including
the addition of separator obstructions. We develop the algorithm through a new
game-theoretic framework that simplifies the reasoning about backdoors.
</p>
<p>Finally, we show that bounded backdoor depth captures tractable classes of
CNF formulas not captured by any known method.
</p></div>
    </summary>
    <updated>2022-02-20T22:55:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.08296</id>
    <link href="http://arxiv.org/abs/2202.08296" rel="alternate" type="text/html"/>
    <title>Controlling Epidemic Spread using Probabilistic Diffusion Models on Networks</title>
    <feedworld_mtime>1645315200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Babay:Amy.html">Amy Babay</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dinitz:Michael.html">Michael Dinitz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Srinivasan:Aravind.html">Aravind Srinivasan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsepenekas:Leonidas.html">Leonidas Tsepenekas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vullikanti:Anil.html">Anil Vullikanti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.08296">PDF</a><br/><b>Abstract: </b>The spread of an epidemic is often modeled by an SIR random process on a
social network graph. The MinINF problem for optimal social distancing involves
minimizing the expected number of infections, when we are allowed to break at
most $B$ edges; similarly the MinINFNode problem involves removing at most $B$
vertices. These are fundamental problems in epidemiology and network science.
While a number of heuristics have been considered, the complexity of these
problems remains generally open. In this paper, we present two bicriteria
approximation algorithms for MinINF, which give the first non-trivial
approximations for this problem. The first is based on the cut sparsification
result of Karger \cite{karger:mathor99}, and works when the transmission
probabilities are not too small. The second is a Sample Average Approximation
(SAA) based algorithm, which we analyze for the Chung-Lu random graph model. We
also extend some of our results to tackle the MinINFNode problem.
</p></div>
    </summary>
    <updated>2022-02-20T22:43:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/023</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/023" rel="alternate" type="text/html"/>
    <title>TR22-023 |  Nisan--Wigderson generators in Proof Complexity: New lower bounds | 

	Erfan Khaniki</title>
    <summary>A map $g:\{0,1\}^n\to\{0,1\}^m$ ($m&gt;n$) is a hard proof complexity generator for a proof system $P$ iff for every string $b\in\{0,1\}^m\setminus Rng(g)$, formula $\tau_b(g)$ naturally expressing $b\not\in Rng(g)$ requires superpolynomial size $P$-proofs. One of the well-studied maps in the theory of proof complexity generators is Nisan--Wigderson generator. Razborov (Annals of Mathematics 2015) conjectured that if $A$ is a suitable matrix and $f$ is a $NP\cap CoNP$ function hard-on-average for $P/poly$, then $NW_{f, A}$ is a hard proof complexity generator for Extended Frege.
 In this paper, we prove a form of Razborov's conjecture for $AC^0$-Frege. We show that for any symmetric $NP\cap CoNP$ function $f$ that is exponentially hard for depth two $AC^0$ circuits, $NW_{f,A}$ is a hard proof complexity generator for $AC^0$-Frege in a natural setting. As direct applications of this theorem, we show that:

1. For any $f$ with the specified properties, $\tau_b(NW_{f,A})$ based on a random $b$ and a random matrix $A$ with probability $1-o(1)$ is a tautology and requires superpolynomial (or even exponential) $AC^0$-Frege proofs.

2. Certain formalizations of the principle $f_n\not\in(NP\cap CoNP)/poly$ requires superpolynomial $AC^0$-Frege proofs.
        
These applications relate to two questions that were asked by Krajícek (Cambridge University Press 2019).</summary>
    <updated>2022-02-19T11:45:55Z</updated>
    <published>2022-02-19T11:45:55Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-21T13:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/022</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/022" rel="alternate" type="text/html"/>
    <title>TR22-022 |  On Efficient Noncommutative Polynomial Factorization via Higman Linearization | 

	Vikraman Arvind, 

	Pushkar Joglekar</title>
    <summary>In this paper we study the problem of efficiently factorizing polynomials in the free noncommutative ring F  of polynomials in noncommuting variables x_1,x_2,…,x_n over the field F. We obtain the following result:

Given a noncommutative arithmetic formula of   size s computing a noncommutative polynomial f in F as input, where F=F_q is a finite field, we give a randomized algorithm that runs in time polynomial in s, n and log q that computes a factorization of the polynomial f as a product f=f_1f_2… f_r, where each f_i is an irreducible polynomial that is output as a noncommutative algebraic branching program. 

The algorithm works by first transforming f into a linear matrix L using Higman's linearization of polynomials. We then factorize the linear matrix L and recover the factorization of the polynomial f. We use basic elements from Cohn's theory of free ideals rings combined with Ronyai's randomized polynomial-time algorithm for computing invariant subspaces of a collection of matrices over finite fields.</summary>
    <updated>2022-02-19T05:28:13Z</updated>
    <published>2022-02-19T05:28:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-21T13:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/021</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/021" rel="alternate" type="text/html"/>
    <title>TR22-021 |  Improved Pseudorandom Generators for $\mathrm{AC}^0$ Circuits | 

	Xin Lyu</title>
    <summary>We give PRG for depth-$d$, size-$m$ $\mathrm{AC}^0$ circuits with seed length $O(\log^{d-1}(m)\log(m/\varepsilon)\log\log(m))$. Our PRG improves on previous work [TX13, ST19, Kel21] from various aspects. It has optimal dependence on $\frac{1}{\varepsilon}$ and is only one “$\log\log(m)$” away from the lower bound barrier. For the case of $d=2$, the seed length tightly matches the best-known PRG for CNFs [DETT10, Tal17].

There are two technical ingredients behind our new result; both of them might be of independent interest. First, we develop a “partitioning-based” approach to construct PRGs based on restriction lemmas for AC0. Previous works [TX13, ST19, Kel21] usually built PRGs on the Ajtai-Wigderson framework [AW89]. Compared with them, our new approach avoids the extra “$\log(n)$” factor that usually arises from the Ajtai-Wigderson framework, allowing us to get the almost-tight seed length. Our partitioning-based approach is quite general, and we believe it can help design PRGs for classes beyond constant-depth circuits.

Second, improving and extending [TX13, ST19, Kel21], we prove a full derandomization of the powerful multi-switching lemma [Hås14]. We show that one can use a short random seed to sample a restriction, such that a family of DNFs simultaneously simplifies under the restriction with high probability. This answers an open question in [Kel21]. Previous derandomizations were either partial (that is, they pseudorandomly choose variables to restrict, and then fix those variables to truly-random bits) or had sub-optimal seed length. In our application, having a fully-derandomized switching lemma is crucial, and the randomness-efficiency of our derandomization allows us to get an almost-tight seed length.</summary>
    <updated>2022-02-19T01:50:17Z</updated>
    <published>2022-02-19T01:50:17Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-21T13:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/18/postdoc-at-yale-university-apply-by-march-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/18/postdoc-at-yale-university-apply-by-march-15-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at Yale University (apply by March 15, 2022)</title>
    <summary>Applications are solicited for a postdoctoral position at Yale in Algorithms, Optimization, and Machine Learning. The position is expected to start in Fall 2022. Applicants should have an exceptional mathematical background and a proven track record. They should have their CV, research statement, and three recommendation letters emailed directly to Nisheeth Vishnoi Website: https://www.cs.yale.edu/homes/vishnoi/postdoc.html Email: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are solicited for a postdoctoral position at Yale in Algorithms, Optimization, and Machine Learning. The position is expected to start in Fall 2022. Applicants should have an exceptional mathematical background and a proven track record. They should have their CV, research statement, and three recommendation letters emailed directly to Nisheeth Vishnoi</p>
<p>Website: <a href="https://www.cs.yale.edu/homes/vishnoi/postdoc.html">https://www.cs.yale.edu/homes/vishnoi/postdoc.html</a><br/>
Email: nisheeth.vishnoi@gmail.com</p></div>
    </content>
    <updated>2022-02-18T19:04:31Z</updated>
    <published>2022-02-18T19:04:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-21T13:37:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3539</id>
    <link href="https://agtb.wordpress.com/2022/02/18/cfp-scw-special-issue-on-fair-public-decision-making/" rel="alternate" type="text/html"/>
    <title>CFP: SCW Special Issue on “Fair Public Decision Making”</title>
    <summary>Social Choice and Welfare will publish a special issue on “Fair Public Decision Making: Allocating budgets, seats, and probability” (submission deadline: May 1st, 2022) that will be concerned with apportionment, multi-winner elections, participatory budgeting, donor coordination, probabilistic social choice, sortition, multiple referenda, and related topics. See the Call for Papers. Guest editors: Haris Aziz, Felix […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Social Choice and Welfare</strong> will publish a special issue on “Fair Public Decision Making: Allocating budgets, seats, and probability” (<strong>submission deadline: May 1st, 2022</strong>) that will be concerned with <em>apportionment, multi-winner elections, participatory budgeting, donor coordination, probabilistic social choice, sortition, multiple referenda</em>, and related topics. See the <a href="https://www.springer.com/journal/355/updates/19966564">Call for Papers</a>.</p>



<p>Guest editors: Haris Aziz, Felix Brandt, Edith Elkind, Jérôme Lang</p>



<p/></div>
    </content>
    <updated>2022-02-18T14:39:28Z</updated>
    <published>2022-02-18T14:39:28Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>felixbrandt</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2022-02-21T13:37:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/020</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/020" rel="alternate" type="text/html"/>
    <title>TR22-020 |  Worst-Case to Average-Case Reductions via Additive Combinatorics | 

	Vahid Reza Asadi, 

	Alexander Golovnev, 

	Tom Gur, 

	Igor Shinkar</title>
    <summary>We present a new framework for designing worst-case to average-case reductions. For a large class of problems, it provides an explicit transformation of algorithms running in time $T$ that are only correct on a small (subconstant) fraction of their inputs into algorithms running in time $\widetilde{O}(T)$ that are correct on all inputs. 

Using our framework, we obtain such efficient worst-case to average-case reductions for fundamental problems in a variety of computational models; namely, algorithms for matrix multiplication, streaming algorithms for the online matrix-vector multiplication problem, and static data structures for all linear problems as well as for the multivariate polynomial evaluation problem.

Our techniques crucially rely on additive combinatorics. In particular, we show a local correction lemma that relies on a new probabilistic version of the quasi-polynomial Bogolyubov-Ruzsa lemma.</summary>
    <updated>2022-02-18T10:38:25Z</updated>
    <published>2022-02-18T10:38:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-21T13:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://francisbach.com/?p=6397</id>
    <link href="https://francisbach.com/matrix-monotony-and-convexity/" rel="alternate" type="text/html"/>
    <title>Playing with positive definite matrices – I: matrix monotony and convexity</title>
    <summary>In a series of a few blog posts, I will present classical and non-classical results on symmetric positive definite matrices. Beyond being mathematically exciting, they arise naturally a lot in machine learning and optimization, as Hessians of twice continuously differentiable convex functions and through kernel methods. In this post, I will focus on the benefits...</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="justify-text">In a series of a few blog posts, I will present classical and non-classical results on symmetric positive definite matrices. Beyond being mathematically exciting, they arise naturally a lot in machine learning and optimization, as Hessians of twice continuously differentiable convex functions and through kernel methods. In this post, I will focus on the benefits and perils of using the <a href="https://en.wikipedia.org/wiki/Loewner_order">Löwner order</a> between symmetric matrices as a tool for proving inequalities.</p>



<p class="justify-text">I will consider symmetric matrices \(A \in \mathbb{R}^{d \times d}\) of size \(d \times d\), denoting by \(\mathcal{S}_d\) the set all such matrices. There are many characterizations of symmetric positive semi-definite (PSD) matrices: (a) non-negative eigenvalues, (b) \(x^\top A x \geqslant 0\) for all \(x \in \mathbb{R}^d\), or (c) expression as a square as \(A = BB^\top\). Let’s denote this set by \(\mathcal{S}_d^+\).</p>



<p class="justify-text">A very useful tool in matrix analysis is the use of the Löwner order. It is defined as follows on \(\mathcal{S}_d\): $$ A \preccurlyeq B \Leftrightarrow B-A \in \mathcal{S}_d^+.$$ In other words, \(A\) is smaller than \(B\) if and only if \(B\, – A\) is positive semi-definite (PSD). The notation \(B \succcurlyeq A\) is defined as equivalent to \(A \preccurlyeq B\).</p>



<p class="justify-text">This defines a classical <a href="https://en.wikipedia.org/wiki/Order_theory">order relation</a> which is reflexive (\(A \preccurlyeq A\) for all \(A\)), antisymmetric (for all \(A, B \in \mathcal{S}_d\), \(A \preccurlyeq B\) and \(B \preccurlyeq A\) imply \(A=B\)), and transitive (\(A \preccurlyeq B\) and \(B \preccurlyeq C\) imply \(A \preccurlyeq C\)).</p>



<p class="justify-text">Using operations on the Löwner order can make proofs much simpler, but it can also lead to atrocious mistakes. The main reason ends up being the lack of commutativity of the matrix product, that is, <em>in general </em>\(AB \neq BA\).</p>



<p class="justify-text"><strong>Representing positive matrices through ellipsoids.</strong> Any strictly PSD matrix \(A\) defines an ellipsoid $$ \mathcal{E}_A = \big\{ x \in \mathbb{R}^d, \ x^\top A^{-1} x \leqslant 1 \big\}$$ centered at zero. The eigenvectors are the traditional principal axes of the ellipsoid and the eigenvalues the lengths of these axes. See an illustration below with \(d = 2\), and the two eigenvectors \(u_1\) and \(u_2\).</p>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-6580" height="151" src="https://francisbach.com/wp-content/uploads/2022/02/ellipsoid-1.png" width="246"/></figure></div>



<p class="justify-text">The key property here is that \(\mathcal{E}_A \subset \mathcal{E}_B\) if and only if \(A \preccurlyeq B\). This representation immediately highlights that the order is partial. See examples below.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-6581" height="280" src="https://francisbach.com/wp-content/uploads/2022/02/ellipsoids_notaligned-1024x571.png" width="503"/></figure></div>



<p class="justify-text">Moreover, if two matrices commute, then they are jointly diagonalizable, that is, the principal axes are aligned, and once expressed in the common eigenbasis, we obtain diagonal matrices, and we then have \({\rm Diag}(\lambda)  \preccurlyeq {\rm Diag}(\mu)\) if and only if for all \(i\), \(\lambda_i \leqslant \mu_i\).</p>



<p class="justify-text">Several good books are available and reading them is both enjoyable and fruitful [1, 4, 10]. Let’s now look at some properties of this Löwner order.</p>



<h2 id="fun-and-useful-facts-and-common-mistakes">Fun (and useful) facts and common mistakes</h2>



<p class="justify-text">Here I list classical properties that are constantly used in proofs using positive matrices. This is crucially used in the analysis of gradient methods for least-squares [<a href="http://proceedings.neurips.cc/paper/2013/file/7fe1f8abaad094e0b5cb1b01d712f708-Paper.pdf">6</a>, <a href="http://jmlr.org/papers/volume18/16-335/16-335.pdf">7</a>], as well as in analyzing linear dynamical systems, with control or not [<a href="http://web.stanford.edu/~boyd/lmibook/lmibook.pdf">8</a>].</p>



<p class="justify-text"><strong>Direct consequence of the definition.</strong> For any \(d \times n\) matrix \(X\), and \(A,B \in \mathcal{S}_d\) such that \( A \preccurlyeq B\), $$ X^\top A X \preccurlyeq X^\top B X, $$ with the simple proof \(y^\top X^\top A X y = ( X y)^\top A ( X y) \leqslant ( X y)^\top B ( X y)  =  y^\top X^\top B X y \) for all \(y \in \mathbb{R}^n\). </p>



<p class="justify-text">Another similar formulation is $$ A \preccurlyeq B \Rightarrow {\rm tr}(AM) \leqslant {\rm tr} (BM) \mbox{ for all } M \succcurlyeq 0.$$ However this <em>not</em> true if \(M\) is <em>not</em> PSD. In particular, if \(A \preccurlyeq B\) we do <em>not</em> have in general for all \(x, y \in \mathbb{R}^d\), \(x^\top A y \leqslant x^\top B y \), which is a common mistake.</p>



<p class="justify-text">Another consequence, with \(X = B^{\, -1/2}\) the inverse of the square root of \(B\) (assuming that \(B\) is invertible), is \(A \preccurlyeq B \Rightarrow B^{\, -1/2} A B^{\, -1/2} \preccurlyeq I\).</p>



<p class="justify-text"><strong>Schur complements.</strong> A very useful identity is, for any rectangular matrix \(C\): $$ CC^\top \preccurlyeq I \Leftrightarrow  C^\top C \preccurlyeq I.$$ This can be extended to (with matrices of proper sizes): $$ C B^{\, -1} C^\top \preccurlyeq A \Leftrightarrow  C^\top A^{-1} C \preccurlyeq B$$ for PSD invertible matrices \(A, B\), both properties being equivalent to $$ \bigg( \begin{array}{cc} A &amp; C \\ C^\top &amp; B \end{array} \bigg) \succcurlyeq 0.$$ This is the usual characterization of positive-definiteness of block matrices through <a href="https://en.wikipedia.org/wiki/Schur_complement">Schur complements</a>.</p>



<p class="justify-text"><strong>Trace inequalities.</strong> If \(A \succcurlyeq 0 \) and \(B \succcurlyeq 0 \), then we have $$ 0 \leqslant {\rm tr}(AB)  \leqslant {\rm tr(A)} \lambda_{\max}(B) \leqslant {\rm tr(A)} {\rm tr}(B).$$ Moreover, still if  \(A \succcurlyeq 0 \) and \(B \succcurlyeq 0 \), $$ {\rm tr} (AB) \geqslant 0 \mbox{ with equality if and only if } AB=0.$$ This is used a lot in <a href="https://en.wikipedia.org/wiki/Semidefinite_programming">semi-definite programming</a>, in particular for optimality conditions (see [<a href="http://stanford.edu/~boyd/papers/pdf/semidef_prog.pdf">9</a>] for details), and can be shown (for the non-trivial direction) by using an eigenvalue decomposition of \(A\) as \(A = \sum_{i=1}^d \lambda_i u_i u_i^\top\), writing \({\rm tr}(AB) = \sum_{i=1}^d \lambda_i u_i^\top B_i u_i\), which is a sum of non-negative terms and thus if \({\rm tr}(AB)=0\), all terms have to be equal to zero, leading exactly to the result (since \(u^\top B u =0\) is equivalent to \(Bu=0\) when \(B \succcurlyeq 0\)).</p>



<h2 id="matrix-functions">Matrix functions</h2>



<p class="justify-text">One particularly elegant and efficient way of using symmetric matrices is through matrix functions. Some are based on classical linear algebra such as the matrix inverse \(A^{\, -1}\), the matrix square root \(A^{1/2}\), or any polynomial or rational functions. Many others are defined as spectral functions. That is, given a function \(f:I \to \mathbb{R}\), defined on some interval \(I\) we can define for any symmetric matrix latex \(A \in \mathbb{S}_d\) with eigenvalue decomposition \(A = \sum_{i=1}^d \lambda_i u_i u_i^\top\), and all eigenvalues in \(I\): $$f(A) = \sum_{i=1}^d f(\lambda_i) u_i u_i^\top.$$</p>



<p class="justify-text">We get the usual definition of matrix powers \(A^p\), inverse \(A^{-1}\), but also logarithm \(\log A\) for PSD matrices, exponential \(\exp(A)\), etc. When the matrix is diagonal, then we apply the function on diagonal elements $$f({\rm Diag}(\lambda)) = {\rm Diag}(f(\lambda)).$$</p>



<p class="justify-text">For real numbers, a function \(f\) is non-decreasing if and only if for all \(\lambda,\mu\), $$ \lambda \leqslant \mu \Rightarrow f(\lambda) \leqslant f(\mu).$$ When \(f\) is non-decreasing, then for \(d=1\), we do have \(f(A)  \preccurlyeq  f(B)\) as soon as \(A \preccurlyeq B\). Moreover, when \(A\) and \(B\) commute, then can be <a href="https://kconrad.math.uconn.edu/blurbs/linmultialg/minpolyandappns.pdf">jointly diagonalized</a>, and then the property above is true for all non-decreasing functions. This is the same if we just want \({\rm tr} [ f(A) ] \leqslant {\rm tr}[f(B)]\).</p>



<p class="justify-text">When does it extend to \(d&gt;1\), beyond taking the trace, and for non-commuting matrices? Functions for which $$ \forall A, B \in \mathcal{S}_d, \  A \preccurlyeq B \Rightarrow  f(A) \preccurlyeq f(B)$$ for all dimensions \(d\) are called <em>matrix-monotone</em>. Let us start with a few positive examples with simple direct proofs.</p>



<p class="justify-text"><strong>Matrix inverse.</strong> If \( A \preccurlyeq B\) and \(A\)  is invertible, then, \(B\) is invertible, and \(B^{\, -1/2} A B^{\, -1/2} \preccurlyeq I\), which is equivalent to \((A^{1/2} B^{\, -1/2})^\top A^{1/2} B^{\, -1/2} \preccurlyeq I\) and thus \(A^{1/2} B^{\, -1} A^{1/2} = A^{1/2} B^{\, -1/2} (A^{1/2} B^{\, -1/2})^\top  \preccurlyeq I\), and then \(A^{\:\! -1} \succcurlyeq B^{\, -1} \). The function \(\lambda \mapsto -\lambda^{-1}\) is thus matrix-monotone.</p>



<p class="justify-text"><strong>Matrix square root.</strong> From the paragraph above, if \( A \preccurlyeq B\) and \(A\)  is invertible, then \(\|A^{1/2} B^{\, -1/2} \|_{\rm op} \leqslant 1\), thus all (potentially complex) eigenvalues of \(A^{1/2} B^{\, -1/2}\) have magnitude less than one, and thus this is the same for all eigenvalues of the <a href="https://en.wikipedia.org/wiki/Matrix_similarity">similar</a> matrix \(B^{\, -1/4} ( A^{1/2} B^{\, -1/2} ) B^{1/4}= B^{\, -1/4}   A^{1/2} B^{\, -1/4}\), which finally implies \(B^{\, -1/4}   A^{1/2} B^{\, -1/4} \preccurlyeq  I\), and thus \(A^{1/2} \preccurlyeq B^{1/2}\). The function \(\lambda \mapsto \lambda^{1/2}\) is thus matrix-monotone.</p>



<p class="justify-text"><strong>Matrix square.</strong> “Unfortunately” \(A \succcurlyeq B \succcurlyeq 0\) does not imply \(A^2 \succcurlyeq B^2\). This is a very common mistake! (I have made it at several occasions). </p>



<p class="justify-text">In fact, this is rarely true, indeed, if \(B = A + \Delta\), we have \(B^2 – A^2 = \Delta^2 + A \Delta + \Delta A,\) and as soon as the column space of \(\Delta\) does not contain the one of \(A\), the equality between squares is impossible. See an illustration below in two dimensions.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img alt="" class="wp-image-6602" height="294" src="https://francisbach.com/wp-content/uploads/2022/02/ellipsoid-1.gif" width="298"/>For  \(A = \frac{1}{5} \Big(\begin{array}{cc}\!  2 \! \!&amp;  \! \! 1 \! \\[-.25cm] \! 1\!\! &amp;\!\! 1 \!\end{array} \Big)\) and \(B = \frac{1}{5} \Big(\begin{array}{cc} \! 4 \!\!&amp; \!\! 1 \! \\[-.25cm] \! 1 \! \!&amp; \! \! 1 \! \end{array} \Big)\) which are such that \(0 \preccurlyeq A \preccurlyeq B\), represented by their ellipsoid, we represent \(A^p\) and \(B^p\) for various powers \(p \in [0,4]\). We have \(A^p \preccurlyeq B^p\) only for \(p \in [0,1]\).</figure></div>



<p class="justify-text">Luckily, as mentioned by my colleague <a href="https://www.di.ens.fr/~rudi/">Alessandro Rudi</a>, for any incorrect matrix inequality, there is a close by true inequality. Here, for example, we have that \(A \succcurlyeq  B \succcurlyeq 0\) does imply \({\rm tr}(A^2) \geqslant {\rm tr}(B^2)\) (as can be seen by from the positivity of the trace of products of PSD matrices). Moreover, there are the so-called <em>Furuta</em> <em>inequalities</em>, (see Corollary 1.18 in [4]): $$ A \succcurlyeq B \succcurlyeq 0 \Rightarrow A^2 \succcurlyeq ( AB^2A)^{1/2} \mbox{ and } (BA^2B)^{1/2} \succcurlyeq B^2, $$ which can prove useful.</p>



<p class="justify-text"><strong>Towards a characterization of matrix-monotone functions.</strong> We have seen that \(\lambda \mapsto \lambda^2\) is not matrix-monotone, while \(\lambda \mapsto \lambda^{1/2}\) and \(\lambda \mapsto -1/\lambda\) are. So what functions are matrix monotone? It turns out that there is a general answer, which is an amazing result from Löwner: he gives a precise characterization of matrix-monotone functions [<a href="http://gdz.sub.uni-goettingen.de/id/PPN266833020_0038?tify={">2</a>], with a whole book [3] about it with 11 different proofs!</p>



<h2 id="positivity-of-lowner-matrices">Positivity of Löwner matrices</h2>



<p class="justify-text">We start with a first characterization that will please the kernel enthusiasts. The question here is as follows. Given a differentiable function \(f: I \to \mathbb{R}\), and \(n\) real numbers \(\lambda_1,\dots,\lambda_n \in I\) the domain of \(f\), when is the \(n \times n\) matrix \(L\) with values $$L_{ij} = \frac{f(\lambda_i)-f(\lambda_j)}{\lambda_i – \lambda_j} \mbox{ for } i \neq j,$$ and \(L_{ii} = f'(\lambda_i)\), always positive semi-definite? These matrices are called Löwner matrices and it turns out that the differentiable functions \(f\) for which all Löwner matrices are PSD are exactly the matrix-monotone functions.</p>



<p class="justify-text">To see this, we simply need to compute the derivative at \(t=0\) of the matrix-valued function \(g: [0,1] \to \mathcal{S}_d\) defined as  $$g(t) =  f(A + t(B-A)).$$ Using a former <a href="https://francisbach.com/cauchy-residue-formula/">blog post</a>, we have with the eigenvalue decomposition \(A=\sum_{i=1}^d \! \lambda_i u_i u_i^\top\), $$g'(0) = \sum_{i,j=1}^d \frac{f(\lambda_i)-f(\lambda_j)}{\lambda_i – \lambda_j} u_i^\top (B-A)u_j,$$ with the convention that for \(i=j\), \(\frac{f(\lambda_i)-f(\lambda_j)}{\lambda_i – \lambda_j}  = f'(\lambda_i)\). Therefore, \(g'(0) = \sum_{i,j=1}^d L_{ij}  u_i^\top (B-A)u_j\).</p>



<p class="justify-text">Thus, if \(f\) is matrix-monotone, we have \(g'(0) \geqslant 0\), and by choosing \(A = {\rm Diag}(\lambda)\) diagonal and \(B\, – A = zz^\top\) rank-one, we get \(g'(0) = \sum_{i,j=1}^d L_{ij}  z_i z_j \geqslant 0\), which leads to the positivity of \(L\) since this is true for any vector \(z \in \mathbb{R}^n\).</p>



<p class="justify-text">In the other direction, if \(L \succcurlyeq 0\) all Löwner matrices are PSD, then as soon as \(B-A \succcurlyeq 0\), we can then get with a similar reasoning \(g'(t) \geqslant 0\) for \(t \in [0,1]\), and thus \(f(B) = g(1) \geqslant g(0) = f(A)\), which shows monotonicity.</p>



<p class="justify-text">Note that, like all generic results on positive-definiteness of matrices (like <a href="https://en.wikipedia.org/wiki/Bochner%27s_theorem">Bochner theorem</a>), this is an infinite source of “<a href="https://fr.wikipedia.org/wiki/Colle_(pr%C3%A9pa)">problèmes de colle</a>” (oral mathematical exams which are common in France).</p>



<h2 id="characterizing-all-matrix-monotone-functions">Characterizing all matrix-monotone functions</h2>



<p class="justify-text">There are many different characterizations of matrix monotonicity (see [3]). I will only mention a simple intuitive result for \(I = (0,+\infty)\), with a sketch of a particularly elegant proof coming from [<a href="http://arxiv.org/pdf/1112.0098.pdf">5</a>].</p>



<p class="justify-text"><strong>A family of non-negative monotone functions.</strong> As seen above, the function \(\lambda \mapsto -1/\lambda\) is matrix-monotone on \(\mathbb{R}_+^\ast\). So is \(\lambda \mapsto \frac{\lambda}{(1-t)\lambda+t}\) for any \(t \in [0,1]\). Moreover, for all \(t \in [0,1]\), these functions are non-negative on \(\mathbb{R}_+^\ast\) and the value at 1 is 1. Note that with \(t=1\), we recover \(\lambda \mapsto \lambda\), while for \(t=0\), we recover \(\lambda \mapsto 1\). </p>



<p class="justify-text">Since matrix-monotonicity is a property which is invariant by taking convex combinations of functions, all functions of the form $$ \lambda \mapsto \int_{0}^{1}\frac{\lambda}{(1-t)\lambda+t}d\mu(t)$$ for a probability measure \(\mu\) on \([ 0 , 1 ]\), are also matrix-monotone, non-negative and with value 1 at 1. It turns out we cover them all! The argument is based on showing that the functions \(\lambda \mapsto \frac{\lambda}{(1-t)\lambda+t}\) are the extreme points of the of functions defined above. See details in [<a href="http://arxiv.org/pdf/1112.0098.pdf">5</a>].</p>



<p class="justify-text">We can then recover all matrix-monotone functions on \( (0,+\infty)\) by adding a constant and letting the mass of \(\mu\) be different from one (and potentially infinite). By making the change of variable \(u = t / (1-t)\), we get the representation as $$f(\lambda) = \alpha + \beta (\lambda-1) + (\lambda-1) \int_0^\infty \!\!\frac{ 1  }{\lambda + u} d\nu(u)$$ for some positive measure \(\nu\) and \(\beta&gt;0\). For example, we have: $$ \log \lambda = (\lambda-1) \int_0^{+\infty} \!\!\frac{1}{\lambda +u} \frac{du}{1+u},$$ and for \(p \in (0,1]\), $$ \lambda^p = 1 + (\lambda-1) \frac{ \sin p \pi}{\pi} \int_0^{+\infty} \!\!\frac{1}{\lambda+u} u^{p-1} du,$$ showing the matrix-monotonicity of the logarithm and of certain powers. Note that the exponential function is <em>not</em> matrix-monotone, and that the only powers \(p \neq 0\) such that \(\lambda \mapsto \lambda^p\) or \(\lambda \mapsto -\lambda^p\) are matrix-monotone are \(p \in (0,1]\) and \(p \in [-1, 0)\).</p>



<h2 id="matrix-convex-functions">Matrix-convex functions</h2>



<p class="justify-text">Similarly to matrix-monotone functions, matrix-convex functions are functions for which $$ \forall A, B \in \mathcal{S}_d, \forall \lambda \in [0,1], \ f( \lambda A + (1-\lambda) B) \preccurlyeq \lambda f(A) + ( 1-\lambda) f(B).$$ Like for real-valued functions, there is an intimate link between monotonicity and convexity here. Indeed, one can show that \(f\) is matrix-convex on the interval \(I\) if and only if for all \(\mu \in I\), the function \(\lambda \mapsto \frac{f(\lambda)-f(\mu)}{\lambda-\mu}\) is matrix-monotone (this is one of these cases where a natural property extends to the matrix case). Using similar arguments than for matrix-monotone functions, all functions of the form $$f(\lambda) = \gamma + \alpha (\lambda-1) + \beta (\lambda-1)^2 + (\lambda-1)^2 \int_0^\infty \!\!\frac{ 1  }{\lambda + u} d\nu(u)$$ for some positive measure \(\nu\) on \([0,+\infty)\) with finite mass, and \(\beta&gt;0\) are matrix-convex on \((0,\infty)\). They also happen to be the only ones (see, e.g., [<a href="http://arxiv.org/pdf/math-ph/9808016">11</a>]). </p>



<p class="justify-text">The classical examples are then \(f(\lambda) = \, – \log \lambda\), \(f(\lambda) = \lambda \log \lambda\), \(f(\lambda) = \lambda^p\) for \(p \in [1,2]\) and \(p \in [-1,0)\).</p>



<p class="justify-text">Note that like for monotonicity, if we just want the <em>real-valued</em> function \(A \mapsto {\rm tr} [ f(A)]\) to be convex, this is equivalent to \(f\) being convex.</p>



<p class="justify-text"><strong>Beyond spectral functions. </strong>There are many nice matrix convex functions beyond spectral functions: for example (see [<a href="http://sciencedirect.com/science/article/pii/0024379579901794/pdf?md5=45d3cff8e7f727933ea9aef11cae997c&amp;pid=1-s2.0-0024379579901794-main.pdf">12</a>]) \(A \mapsto A^{-1} \) or \(A \mapsto A^2 \). Among ones that come up naturally: $$ (A,B) \mapsto A B^{\, -1} A$$ $$ (A,B) \mapsto\  – (A^{-1} + B^{\, -1})^{-1} $$ $$ (A,B) \mapsto\  – A^{1/2} ( A^{-1/2}  B A^{-1/2} )^{1/2} A^{1/2} .$$ Add your favorite one!</p>



<h2 id="conclusion">Conclusion</h2>



<p class="justify-text">Next months, we will see applications of matrix monotonicity and convexity, from sharp concentration inequalities for eigenvalues of random matrices [<a href="https://arxiv.org/pdf/1501.01571">13</a>] to a brand new mix of (quantum) information theory and kernels methods [<a href="https://arxiv.org/pdf/2202.08545.pdf">14</a>].<br/><br/><strong>Acknowledgements</strong>. I would like to thank Alessandro Rudi for fruitful discussions, and Loucas Pillaud-Vivien for proofreading this blog post and making good clarifying suggestions.</p>



<h2 id="references">References</h2>



<p class="justify-text">[1] Rajendra Bhatia. <em><a href="http://www.cmat.edu.uy/~lessa/tesis/Positive%20Definite%20Matrices.pdf">Positive Definite Matrices</a></em>. Princeton University Press, 2009.<br/>[2] Karl T. Löwner. <a href="https://gdz.sub.uni-goettingen.de/id/PPN266833020_0038?tify=%7B%22view%22:%22info%22,%22pages%22:%5B183%5D%7D">Über monotone Matrixfunktionen</a>. <em>Mathematische Zeitschrift</em>, 38:177-216, 1934.<br/>[3] Barry Simon.<em> <a href="https://www.ams.org/journals/bull/2020-57-04/S0273-0979-2019-01688-7/S0273-0979-2019-01688-7.pdf">Löwner’s Theorem on Monotone Matrix Functions</a></em>. Springer, 2019.<br/>[4] Xingzhi Zhan. <em>Matrix inequalities</em>. Springer Science &amp; Business Media, 2002.<br/>[5] Frank Hansen. <a href="https://arxiv.org/pdf/1112.0098.pdf">The fast track to Löwner’s theorem</a>. <em>Linear Algebra and its Applications</em> 438.11: 4557-4571, 2013.<br/>[6] Francis Bach and Eric Moulines. <a href="https://proceedings.neurips.cc/paper/2013/file/7fe1f8abaad094e0b5cb1b01d712f708-Paper.pdf">Non-strongly-convex smooth stochastic approximation with convergence rate \(O(1/n)\)</a>. <em>Advances in Neural Information Processing Systems</em> 26, 2013.<br/>[7] Aymeric Dieuleveut, Nicolas Flammarion, and Francis Bach. <a href="http://jmlr.org/papers/volume18/16-335/16-335.pdf">Harder, Better, Faster, Stronger Convergence Rates for Least-Squares Regression</a>. <em>Journal of Machine Learning Research</em>, 18(101):1−51, 2017.<br/>[8] Stephen Boyd, Laurent El Ghaoui, Eric Feron, and Venkataramanan Balakrishna.<em> <a href="https://web.stanford.edu/~boyd/lmibook/lmibook.pdf">Linear Matrix Inequalities in System and Control Theory</a></em>. SIAM, 1994.<br/>[9] Lieven Vandenberghe, Stephen Boyd. <a href="https://stanford.edu/~boyd/papers/pdf/semidef_prog.pdf">Semidefinite Programming</a>. <em>SIAM Review</em>, 38:49–95.<br/>[10] Rajendra Bhatia. <em>Matrix analysis</em>. Springer Science &amp; Business Media, 2013.<br/>[11] Andrew Lesniewski and Mary Beth Ruskai. <a href="https://arxiv.org/pdf/math-ph/9808016">Monotone Riemannian metrics and relative entropy on noncommutative probability spaces</a>. Journal of Mathematical Physics, 40(11):5702–5724, 1999.<br/>[12] Tsuyoshi Ando. <a href="https://www.sciencedirect.com/science/article/pii/0024379579901794/pdf?md5=45d3cff8e7f727933ea9aef11cae997c&amp;pid=1-s2.0-0024379579901794-main.pdf">Concavity of certain maps on positive definite matrices and applications to Hadamard products</a>. <em>Linear algebra and its applications</em>, 26: 203-241, 1979.<br/>[13] Joel A. Tropp. <a href="https://arxiv.org/pdf/1501.01571">An introduction to matrix concentration inequalities</a>. <em>Foundations and Trends in Machine Learning</em>, 8(1-2):1–230, 2015.<br/>[14] Francis Bach. <a href="https://arxiv.org/pdf/2202.08545.pdf">Information Theory with Kernel Methods</a>. Technical Report, arXiv-2202.08545, 2022.<br/></p></div>
    </content>
    <updated>2022-02-17T20:31:42Z</updated>
    <published>2022-02-17T20:31:42Z</published>
    <category term="Machine learning"/>
    <category term="Optimization"/>
    <category term="Tools"/>
    <author>
      <name>Francis Bach</name>
    </author>
    <source>
      <id>https://francisbach.com</id>
      <link href="https://francisbach.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://francisbach.com" rel="alternate" type="text/html"/>
      <subtitle>Francis Bach</subtitle>
      <title>Machine Learning Research Blog</title>
      <updated>2022-02-21T13:38:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/019</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/019" rel="alternate" type="text/html"/>
    <title>TR22-019 |  Simulation Methods in Communication Lower Bounds, Revisited | 

	Guangxu Yang, 

	Jiapeng Zhang</title>
    <summary>The notion of lifting theorems is a generic method to lift hardness of one-party functions to two-party lower bounds in communication model. It has many applications in different areas such as proof complexity, game theory, combinatorial optimization. Among many lifting results, a central idea is called Raz-McKenize simulation (FOCS 1997). This simulation provides a systematic way to convert a communication protocol into a corresponding decision tree. Though it is very convenient in many applications, there are still some challenges in this framework. A major problem is that Raz-McKenize simulation requires a very large gadget.

In this paper, we revise Raz-McKenzie simulation. We introduce a white-box simulation, proving lifting theorems for block sensitivity with constant-size gadgets. Concretely, we show there is a constant-size gadget $g$ such that for any Boolean function $f$, the corruption bound of $f\circ g^n$ is lower bounded by $\Omega(\mathrm{bs}(f))$. Combined with a result of Beame et al. (CCC 2005), this implies the randomized communication complexity of $f\circ g^n$ is lower bounded by $\Omega(\mathrm{bs}(f))$. Besides the result itself, we believe our simulation technique may have more applications in diverse areas. We also discuss why our simulation method has a potential to avoid the large-size gadget bottleneck in Raz-McKenzie simulation.</summary>
    <updated>2022-02-17T09:45:11Z</updated>
    <published>2022-02-17T09:45:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-21T13:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/018</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/018" rel="alternate" type="text/html"/>
    <title>TR22-018 |  Further Collapses in TFNP | 

	Mika Göös, 

	Alexandros Hollender, 

	Siddhartha Jain, 

	Gilbert Maystre, 

	William Pires, 

	Robert Robere, 

	Ran Tao</title>
    <summary>We show $\text{EOPL}=\text{PLS}\cap\text{PPAD}$. Here the class $\text{EOPL}$ consists of all total search problems that reduce to the End-of-Potential-Line problem, which was introduced in the works by Hubacek and Yogev (SICOMP 2020) and Fearnley et al. (JCSS 2020). In particular, our result yields a new simpler proof of the breakthrough collapse $\text{CLS}=\text{PLS}\cap\text{PPAD}$ by Fearnley et al. (STOC 2021). We also prove a companion result $\text{SOPL}=\text{PLS}\cap\text{PPADS}$, where $\text{SOPL}$ is the class associated with the Sink-of-Potential-Line problem.</summary>
    <updated>2022-02-15T22:05:13Z</updated>
    <published>2022-02-15T22:05:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-21T13:37:26Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/02/15/linkage</id>
    <link href="https://11011110.github.io/blog/2022/02/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Relevant points for nearest-neighbor classification (\(\mathbb{M}\)). The 48-minute extended remix of my SOSA talk, from the New York computational geometry seminar, somehow still going strong decades after I first started attending it in the late 1980s.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.youtube.com/watch?v=Vf1m2L2rhkQ">Relevant points for nearest-neighbor classification</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107727015706308147">\(\mathbb{M}\)</a>).</span> The 48-minute extended remix of my SOSA talk, from the New York computational geometry seminar, somehow still going strong decades after I first started attending it in the late 1980s.</p>
  </li>
  <li>
    <p>The journal I recently co-founded, <a href="https://www.cgt-journal.org/index.php/cgt"><em>Computing in Geometry and Topology</em></a>, has published its first paper! It’s “<a href="https://www.cgt-journal.org/index.php/cgt/article/view/4">On the pathwidth of hyperbolic 3-manifolds</a>” by Kristóf Huszár <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107729561681398073">\(\mathbb{M}\)</a>).</span> Hyperbolic 3-manifolds were known to have triangulations of treewidth linear in their hyperbolic volume — the paper improves this to pathwidth. Having small pathwidth, in turn, simplifies certain dynamic programming computations over tree decompositions of the triangulation.</p>
  </li>
  <li>
    <p><a href="https://conwaylife.com/book/"><em>Conway’s Game of Life: Mathematics and Construction</em></a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107738145296241309">\(\mathbb{M}\)</a>).</span> Free online book by Nathaniel Johnston and Dave Greene detailing the engineering behind some of the most complex patterns in Life including universal computers, large variable-speed spaceships and replicators, and metacells that can emulate any other 2d cellular automaton.</p>
  </li>
  <li>
    <p><a href="https://jaydaigle.net/blog/replication-crisis-math/">Why isn’t there a replication crisis in math</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107746496400902945">\(\mathbb{M}\)</a></span>, <a href="https://news.ycombinator.com/item?id=30181696">via</a>)? It’s not like there’s any shortage of papers with incorrect proofs in them; the bigger mystery is why, much of the time, the broken proofs turn out to be fixable.</p>
  </li>
  <li>
    <p><a href="https://doctorow.medium.com/a-bug-in-early-creative-commons-licenses-has-enabled-a-new-breed-of-superpredator-5f6360713299">A bug in the old version-2 Creative Commons licenses spawns a new breed of copyright troll</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107750081780995135">\(\mathbb{M}\)</a></span>, <a href="https://www.metafilter.com/194192/CC-will-have-them-quaking-in-their-boots">via</a>): seed the open web with CC2-licensed stock photography and the like, wait for unsuspecting people to use it without exactly following the proper format of attribution, sue. Cory Doctorow describes being threatened for using one of these images despite attributing it correctly. See also a <a href="https://doctorow.medium.com/an-open-letter-to-pixsy-ceo-kain-jones-who-keeps-sending-me-legal-threats-5dfc54558f2c">later followup from Doctorow</a>.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@christianp/107744005909936952">Christian Lawson-Perfect asks for names for the glyph you use to depict holes in tori</a>. Suggestions include donut hole, hologram, omphalos, and some made-up words. Incidentally, trying to re-create it as the image below ran into a bizarre Adobe Illustrator bug where saving an intersection of two circles in svg turned it into an ellipse; instead, I had to keep the top and bottom arcs as separate objects.</p>

    <p style="text-align: center;"><img alt="The hole in a torus" src="https://11011110.github.io/blog/assets/2022/omphalos.svg"/></p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/an-ancient-geometry-problem-falls-to-new-mathematical-techniques-20220208/">Squaring the circle, by cutting a square into fractal pieces and reassembling them into a circle</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107763584211385922">\(\mathbb{M}\)</a>).</span> The original paper, “<a href="https://arxiv.org/abs/2202.01412">Circle squaring with pieces of small boundary and low Borel complexity</a>” by András Máthé, Jonathan A. Noel, and Oleg Pikhurko, is very technical, but the main improvement on earlier work in the same line of research is that now the pieces all have positive measure and their boundaries have dimension less than two. The pretty animation at the start of the <em>Quanta</em> link is a little misleading, though: the number of pieces is huge, around \(10^{200}\).</p>
  </li>
  <li>
    <p>I made a project of illustrating an Erdős–Rényi–Gilbert random graph in which the <a href="https://en.wikipedia.org/wiki/Giant_component">giant component</a> (or at least, a large component) is clearly visible <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107766972074585140">\(\mathbb{M}\)</a>).</span> Used <a href="https://arxiv.org/abs/1209.0748">social gravity</a> to get the component centered and separated from everything else. Came out reasonably well, I think.</p>

    <p style="text-align: center;"><img alt="Random graph on 1000 vertices at the critical edge probability, showing a large component" src="https://11011110.github.io/blog/assets/2022/ERG1000.svg"/></p>
  </li>
  <li>
    <p><a href="https://ar5iv.org">Ar5iv, a project for automatically converting most arXiv preprints (the ones with LaTeX source) into html</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107772439338813071">\(\mathbb{M}\)</a></span>, <a href="https://www.metafilter.com/194267/LaTeX-to-HTML5-at-scale">via</a>). Too bad about the not-up-to-TeX-quality math formula formatting, though. They’re using mathml instead of MathJax, and it shows. For instance, when I view formulas like \(O\bigl(n^{4/3+\varepsilon}+k^{5/3}n^{2/3}\log^{O(1)}n\bigr)\) (from <a href="https://arxiv.org/abs/2110.06163">one of my recent papers</a>) in Firefox, the exponents get at least two inconsistent baselines, maybe four. Fortunately, CLP has a <a href="https://checkmyworking.com/misc/mathjax-bookmarklet/">MathJaxification bookmarklet</a> that can make things better…</p>
  </li>
  <li>
    <p>The lists of accepted papers are now up at the web sites for the <a href="https://www.inf.fu-berlin.de/inst/ag-ti/socg22/socg.html">2022 Symposium on Computational Geometry</a> and <a href="https://eurocg2022.unipg.it/accepted-papers.html">European Workshop on Computational Geometry</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107783558042391525">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://blog.plover.com/math/finding-factors.html">Factoring composite numbers into nearly equal factors</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@mjd/107747910032997935">\(\mathbb{M}\)</a>)</span> turns out to be complete for \(\mathsf{NP}\) under randomized reductions, or properly <span style="white-space: nowrap;">\(\mathsf{NP}\)-complete</span> if the gaps between prime numbers are small enough to allow a deterministic reduction from the subset sum problem to go through.</p>
  </li>
  <li>
    <p><a href="https://terrytao.wordpress.com/2022/02/08/perfectly-packing-a-square-by-squares-of-nearly-harmonic-sidelength/">Perfectly packing a square by squares of nearly harmonic sidelength</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107800881701660495">\(\mathbb{M}\)</a>).</span> Terry Tao attacks an old question of whether inverse-integer squares pack into a single square of area \(\zeta(2)=\pi^2/6\), showing that squares of sides <span style="white-space: nowrap;">1/integer\({}^{1+\varepsilon}\)</span> do pack. A key insight: the high perimeter of not-yet-packed squares is an obstacle, but can be controlled by grouping squares into rough grids before packing. (This is why the epsilon is needed: perimeter diverges without it.)</p>
  </li>
  <li>
    <p>What do you get when you combine an indigenous Australian painting aesthetic with vaguely-Kabbalistic astronomical charts and geometric diagrams <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107805270173949870">\(\mathbb{M}\)</a>)?</span> Answer: <a href="https://www.thisiscolossal.com/2020/03/shane-drinkwater-astronomical-maps/">the art</a> of <a href="https://www.thisiscolossal.com/2022/01/shane-drinkwater-paintings/">Shane Drinkwater</a>.</p>
  </li>
</ul></div>
    </content>
    <updated>2022-02-15T18:19:00Z</updated>
    <published>2022-02-15T18:19:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-02-16T06:13:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/017</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/017" rel="alternate" type="text/html"/>
    <title>TR22-017 |  Collision-Resistance from Multi-Collision-Resistance | 

	Prashant Nalini Vasudevan, 

	Ron D. Rothblum</title>
    <summary>Collision-resistant hash functions (CRH) are a fundamental and ubiquitous cryptographic primitive. Several recent works have studied a relaxation of CRH called t-way multi-collision-resistant hash functions (t-MCRH). These are families of functions for which it is computationally hard to find a t-way collision, even though such collisions are abundant (and even (t-1)-way collisions may be easy to find). The case of t=2 corresponds to standard CRH, but it is natural to study t-MCRH for larger values of t.

Multi-collision-resistance seems to be a qualitatively weaker property than standard collision-resistance. In particular, Komargodski et al. (Eurocrypt, 2018) showed that there does not exist a blackbox transformation of MCRH into CRH. Nevertheless, in this work we show a non-blackbox transformation of any moderately shrinking t-MCRH, for t in {3,4}, into an (infinitely often secure) CRH. This transformation is non-constructive - we can prove the existence of a CRH but cannot explicitly point out a construction.

Our result partially extends to larger values of t. In particular, we show that for suitable values of t&gt;t', we can transform a t-MCRH into a t'-MCRH, at the cost of reducing the shrinkage of the resulting hash function family and settling for infinitely often security. This result utilizes the list-decodability properties of Reed-Solomon codes.</summary>
    <updated>2022-02-15T15:00:33Z</updated>
    <published>2022-02-15T15:00:33Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-21T13:37:26Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8907273297572905957</id>
    <link href="http://blog.computationalcomplexity.org/feeds/8907273297572905957/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/belated-happy-80th-allan-borodin.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8907273297572905957" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8907273297572905957" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/belated-happy-80th-allan-borodin.html" rel="alternate" type="text/html"/>
    <title>Belated happy 80th, Allan Borodin!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i/></p><div class="separator" style="clear: both; text-align: center;"><div class="separator" style="clear: both; text-align: center;"><a href="https://www.fields.utoronto.ca/programs/scientific/00-01/borodin/image.jpg" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img border="0" height="320" src="https://www.fields.utoronto.ca/programs/scientific/00-01/borodin/image.jpg" width="213"/></a></div><i style="text-align: left;">Guest Post by Aravind Srinivasan</i><span style="text-align: left;"> </span></div><p/><p><a href="https://en.wikipedia.org/wiki/Allan_Borodin">Allan Borodin</a> turned 80 in 2021. This post is to belatedly wish him a very happy 80th, and to give a short personal perspective. </p><p>Three things come to mind when I think of Allan:</p><p/><ol style="text-align: left;"><li>His range of research topics: I was first exposed to his work (Borodin's Gap Theorem) in a complexity-theory class by Hartmanis in Spring 1990, and have since enjoyed reading---at varying levels of depth---his works on algebraic complexity, space complexity and tradeoffs, circuit complexity, lower bounds in general, routing, adversarial queuing, online algorithms, priority algorithms, and E-commerce (I am surely leaving out some areas). This is an amazingly broad sweep!</li><li>His enthusiasm in learning about and developing new models, as our field has evolved greatly over time.</li><li>The enthusiastic embrace he has given to researchers spanning generations. Indeed, I am one of many who have been inspired by various facets of his research and personality.</li></ol><p/><p>Photos from Allan’s 60th can be seen at <a href="http://www.cs.toronto.edu/~bor/birthday/index.htm">Amos Fiat’s page</a>.</p><p>Thank you for everything Allan, and wishing you continued robust health and enjoyment of your academic work! </p></div>
    </content>
    <updated>2022-02-14T13:32:00Z</updated>
    <published>2022-02-14T13:32:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-21T08:40:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/02/13/triangulation-thickens-grids</id>
    <link href="https://11011110.github.io/blog/2022/02/13/triangulation-thickens-grids.html" rel="alternate" type="text/html"/>
    <title>Triangulation thickens grids</title>
    <summary>If you zigzag back and forth through the columns (or rows) of an ordinary two-dimensional grid graph, following a pattern dignified with the fancy name “boustrophedon”, you get a one-dimensional ordering of the vertices that can be used as the basis of a nice planar arc diagram of this graph.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>If you zigzag back and forth through the columns (or rows) of an ordinary two-dimensional grid graph, following a pattern dignified with the fancy name “<a href="https://en.wikipedia.org/wiki/Boustrophedon">boustrophedon</a>”, you get a one-dimensional ordering of the vertices that can be used as the basis of a nice planar <a href="https://en.wikipedia.org/wiki/Arc_diagram">arc diagram</a> of this graph.</p>

<p style="text-align: center;"><img alt="Boustrophedon layout of a 2d grid" src="https://11011110.github.io/blog/assets/2022/boustrophedon.svg" width="80%"/></p>

<p>The same idea works in 3d. You can divide a 3d grid graph into 2d layers, zigzag within each layer, and then reverse the same zigzagging order in alternating layers, to get another nice one-dimensional ordering of the vertices. It doesn’t give a planar drawing (this graph is not planar), but it does allow it to be drawn without crossings on the four half-planes of a four-page <a href="https://en.wikipedia.org/wiki/Book_embedding">book embedding</a>. More generally, any \(d\)-dimensional grid graph can be drawn in the same way as a book embedding with \(2(d-1)\) pages.</p>

<p style="text-align: center;"><img alt="Double boustrophedon layout of a 3d grid" src="https://11011110.github.io/blog/assets/2022/double-boustrophedon.svg" width="80%"/></p>

<p>I’m a coauthor on a new preprint showing that this one-dimensional layout is very sensitive to the way you connect nearby vertices in the 3d grid. If you modify the grid just a little bit, triangulating it by adding a diagonal to each grid square, then the resulting graph no longer has a book embedding with a constant number of pages. Instead, for a triangulated \(n\times n\times n\) grid, \(\Theta(n^{1/3})\) pages are necessary (and sufficient). The preprint is “Three-dimensional graph products with unbounded stack-number”, with Robert Hickingbotham, Laura Merker, Sergey Norin, Michał T. Seweryn, and David R. Wood, <a href="https://arxiv.org/abs/2202.05327">arXiv:2202.05327</a>; the long coauthor list is because it comes from a collaboration that began at the Banff workshop on Graph Product Structure Theory last November.</p>

<p>There are many other related results packed into the same preprint, but rather than summarizing them all I’d rather take a step back and look at the big picture. The result that triangulated grids have high book thickness turns out to follow from a sequence of connections that is closely analogous to results about the high width of 2d grids, and I think the analogies between these connections are very interesting. For 2d grids:</p>

<ul>
  <li>
    <p>Two standard measures of one-dimensionality of graphs are <a href="https://en.wikipedia.org/wiki/Cutwidth">cutwidth</a> and <a href="https://en.wikipedia.org/wiki/Pathwidth">pathwidth</a>. Both can be defined in terms of continuous maps from the graph (considered as a one-dimensional topological space) to a line. A graph has cutwidth at most \(c\) if it has a map in which every point of the line belongs to the images of at most \(c\) edges, and pathwidth at most \(p\) if it has a map in which every point of the line belongs to the images of edges that have at most \(p\) distinct vertices as their left endpoints.</p>
  </li>
  <li>
    <p>For a graph of maximum degree \(d\), at most \(d\) edges can share a left endpoint, so if the graph has cutwidth \(c\) it has pathwidth at least \(c/d\).</p>
  </li>
  <li>
    <p>A complete graph with \(n\) vertices and \(\tbinom{n}{2}\) edges, mapped continuously to a line, always has a point covered by \(\Omega(n^2)\) edges, at the median vertex of the mapping.</p>
  </li>
  <li>
    <p>For a 2d grid graph, we can associate each vertex with a subgraph consisting of the union of the row and column of the grid containing that vertex.</p>

    <p style="text-align: center;"><img alt="Bramble associating each grid vertex with the union of its row and column" src="https://11011110.github.io/blog/assets/2022/grid-bramble.svg" width="50%"/></p>

    <p>This family of subgraphs is a <a href="https://en.wikipedia.org/wiki/Bramble_(graph_theory)">bramble</a>, meaning that all of the subgraphs are connected and touch each other. In this case, they all touch at shared vertices, but brambles also allow subgraphs to touch across edges. In the bramble for an \(n\times n\) grid graph, each graph vertex or edge belongs to \(O(n)\) subgraphs.</p>
  </li>
  <li>
    <p>We can map \(K_{n^2}\) continuously onto the grid, vertex-to-vertex, by mapping each edge of \(K_{n^2}\) onto a path through the two touching subgraphs for its endpoints. This map has low congestion: each grid vertex or edge is in the image of \(O(n)\) vertices or edges of \(K_{n^2}\).</p>
  </li>
  <li>
    <p>Any map of the grid to a line can be composed with the map from \(K_{n^2}\) to the grid, giving a map of \(K_{n^2}\) onto the line. Because of the low congestion of the map to the grid, a point of the line that is covered by \(\Omega(n^2)\) edges of the complete graph must also be covered by \(\Omega(n)\) edges of the grid. Since this is true for all maps to a line, the grid has pathwidth and cutwidth \(\Omega(n)\).</p>
  </li>
</ul>

<p>Now let’s do the same thing, stepped up a dimension!</p>

<ul>
  <li>
    <p>Instead of graphs, let’s consider 2-dimensional simplicial complexes, systems of points, edges, and triangles. And instead of mapping them to a one-dimensional line, let’s map them (topologically, not necessarily linearly) to a two-dimensional plane. We’ll say that the mapping has high thickness if some point is covered by many triangles (corresponding to cutwidth), or by many vertex-disjoint triangles (corresponding to pathwidth).</p>
  </li>
  <li>
    <p>For a graph of maximum  degree \(d\), at most \(\tbinom{d}{2}\) triangles can share a vertex, so a point covered by many triangles will be covered by many vertex-disjoint triangles. More importantly, this is where the book thickness comes in: an argument related to the <a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Szekeres_theorem">Erdős–Szekeres theorem</a> proves that, when a graph has a \(\theta\)-page book embedding, drawn with its vertices on a circle and its edges as chords of the circle, then at most \(\theta^3\) vertex-disjoint triangles in the graph can contain any point within the circle. So if every mapping into the plane produces a system of triangles of thickness \(t\), you also get book thickness \(\Omega(t^{1/3})\).</p>
  </li>
  <li>
    <p>A complete simplicial complex with \(n\) vertices, \(\tbinom{n}{2}\) edges, and \(\tbinom{n}{3}\) triangles, mapped to the plane, always leads to a point covered by \(\Omega(n^3)\) triangles, by a result of Gromov. (This is closely related to the earlier work of Regina Liu on <a href="https://en.wikipedia.org/wiki/Simplicial_depth">simplicial depth</a> but we want to allow any continuous mapping to the plane, whereas simplicial depth involves mappings that are linear on each edge and triangle.)</p>
  </li>
  <li>
    <p>For an \(n\times n\times n\) grid graph, with its squares triangulated to form a 2d complex \(C\), we can associate each vertex with a subcomplex of \(C\) consisting of the union of the 2d grid planes containing that vertex. This family of subcomplexes has connected pairwise unions and simply connected triplewise unions, analogous to the properties of a bramble for a graph.</p>
  </li>
  <li>
    <p>We can map the complete simplicial complex onto the grid, vertex-to-vertex, by mapping each edge onto a path through the union of two subgraphs and each triangle onto a triangulated surface within the union of three subgraphs. This map has low congestion: each grid vertex, edge, or triangle is in the image of \(O(n^2)\) vertices, edges, or triangles of the complete complex.</p>
  </li>
  <li>
    <p>Any map of the triangulated 3d grid onto the plane can be composed with the map from the complete 2-complex to the grid, giving a map of the complete complex onto the plane. Because of the low congestion of the map to the grid, a point of the plane that is covered by \(\Omega(n^3)\) triangles of the complete complex must also be covered by \(\Omega(n)\) triangles of the triangulated grid. Since this is true for all maps to a plane, the triangulated grid has book thickness \(\Omega(n^{1/3})\).</p>
  </li>
</ul>

<p>For details, generalizations to triangulated products of trees and non-grid tessellations of space, matching upper bounds on book thickness, and more, please see the preprint.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/107795266201400204">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2022-02-13T22:54:00Z</updated>
    <published>2022-02-13T22:54:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-02-16T06:13:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19647</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/" rel="alternate" type="text/html"/>
    <title>Inequalities on the Gridiron</title>
    <summary>Q: Why are Buffalo Bills unlike Dollar Bills? A: Dollar Bills are good for 4 quarters Reddit “outsmarting math” source Josh Allen is not appearing in today’s Super Bowl. He led the Buffalo Bills to not just one but two go-ahead touchdowns in the final 2:00 of the game at Kansas City three weeks ago, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Q: Why are Buffalo Bills unlike Dollar Bills? A: Dollar Bills are good for 4 quarters</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/joshallen/" rel="attachment wp-att-19649"><img alt="" class="alignright wp-image-19649" height="128" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/JoshAllen.jpg?resize=155%2C128&amp;ssl=1" width="155"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Reddit “outsmarting math” <a href="https://www.reddit.com/r/buffalobills/comments/km67tw/josh_allen_the_entirety_of_math_and_all_of/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Josh Allen is not appearing in today’s Super Bowl. He led the Buffalo Bills to not just one but two go-ahead touchdowns in the final 2:00 of the game at Kansas City three weeks ago, but the Bills lost both leads and KC won in overtime.</p>
<p>
Today we note an inequality that treats the real numbers like a football gridiron.</p>
<p>
The <a href="https://en.wikipedia.org/wiki/Hurry-up_offense#Two-minute_drill">two-minute drill</a> is the hallmark of quarterback heroism. KC’s Patrick Mahomes, however, demonstrated the <a href="https://dailystatuss.com/13-seconds-meme-13-seconds-chief-nfl-2022/">13-second drill</a> in two plays plus a tying field goal. That is, the Bills were good for 3 quarters plus 14:47. But Mahomes is not in the Super Bowl either. Two weeks ago, he lost the magic touch in both the closing minute of the fourth quarter and the beginning of overtime as KC squandered a big lead and lost to the Cincinnati Bengals. Whose quarterback, Joe Burrow, <i>is</i> playing in today’s Super Bowl, opposite Matthew Stafford of the Los Angeles Rams.</p>
<p>
The American football field is divided into 100 yards, but rarely subdivided beyond that. The announcers may refer to “a long two yards” or “a short 3,” but never 2.5 yards. It is not just the announcers. Official statistics are kept in units of whole yards, more often rounded up than down. A fourth-down quarterback plunge with 3 inches to go still counts as a 1-yard gain. Perhaps it is essential to the yard that it not be divided into dyadic or decimal units, the way the meter is. As the US celebrates an event still enjoyed by “one nation indivisible,” we note the indivisible.</p>
<p>
</p><p/><h2> Inequalities </h2><p/>
<p/><p>
Godfrey Hardy, John Littlewood, George Polya are famous for many things separately and together. All three lent their names to the timeless book <a href="https://mathematicalolympiads.files.wordpress.com/2012/08/inequalities-hardy-littlewood-polya.pdf">Inequalities</a>. It codifies the theory of real inequalities. </p>
<p/><p><br/>
<a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/inequalitiescover/" rel="attachment wp-att-19650"><img alt="" class="aligncenter wp-image-19650" height="250" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/InequalitiesCover.jpg?resize=171%2C250&amp;ssl=1" width="171"/></a></p>
<p/><p><br/>
<a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/hlp/" rel="attachment wp-att-19652"><img alt="" class="aligncenter wp-image-19652" height="105" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/HLP.png?resize=276%2C105&amp;ssl=1" width="276"/></a></p>
<p>
</p><p/><h2> An Inequality </h2><p/>
<p/><p>
We recently had reason to look at the following inequality: </p>
<blockquote><p><b> </b> <em> If <img alt="{a^2 - b^2 = c&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%5E2+-+b%5E2+%3D+c%3E0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then 	</em></p><em>
<p align="center"><img alt="\displaystyle  c \ge a+b. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%5Cge+a%2Bb.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</em><p><em/>
</p></blockquote>
<p>We noted that this fails in general: Let <img alt="{a=1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%3D1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{b=1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%3D1%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Then <img alt="{c=3/16}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%3D3%2F16%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and 	</p>
<p align="center"><img alt="\displaystyle  3/16 &lt; 1/2 + 1/4. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++3%2F16+%3C+1%2F2+%2B+1%2F4.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>This is not even close. But wait—the following lemma is true:</p>
<blockquote><p><b>Lemma 1</b> <em> If <img alt="{a^2 - b^2 = c&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%5E2+-+b%5E2+%3D+c%3E0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then 	</em></p><em>
<p align="center"><img alt="\displaystyle  c \ge a+b " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%5Cge+a%2Bb+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</em><p><em>provided <img alt="{a,b,c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> are integers. </em>
</p></blockquote>
<p/><p>
The proof is quite simple. We note that 	</p>
<p align="center"><img alt="\displaystyle  c = (a-b)(a+b). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%3D+%28a-b%29%28a%2Bb%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>But this shows that <img alt="{a+b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a non-zero divisor of <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. But then 	</p>
<p align="center"><img alt="\displaystyle  a+b \le c. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a%2Bb+%5Cle+c.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>This proves the inequality. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Is this interesting at all? We have an application of the above lemma, which we will discuss in the future. Are there other good examples of inequalities that are general and natural and only hold over the integers? Or is seeking them like trying to “outsmart math itself”?</p>
<p><br/></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/allenoutsmartsmath/" rel="attachment wp-att-19653"><img alt="" class="aligncenter wp-image-19653" height="177" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/AllenOutsmartsMath.jpg?resize=400%2C177&amp;ssl=1" width="400"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">SB Nation <a href="https://www.sbnation.com/nfl/2018/4/24/17271686/josh-allen-nfl-draft-2018-stats-analysis-comparisons">source</a></font>
</td>
</tr>
</tbody></table></font></font></div>
    </content>
    <updated>2022-02-13T21:57:51Z</updated>
    <published>2022-02-13T21:57:51Z</published>
    <category term="All Posts"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Results"/>
    <category term="American football"/>
    <category term="gridiron"/>
    <category term="inequalities"/>
    <category term="Josh Allen"/>
    <category term="Super Bowl"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-02-21T13:37:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6299</id>
    <link href="https://scottaaronson.blog/?p=6299" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6299#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6299" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Happy 70th birthday Dad!</title>
    <summary xml:lang="en-US">When, before covid, I used to travel the world giving quantum computing talks, every once in a while I’d meet an older person who asked whether I had any relation to a 1970s science writer by the name of Steve Aaronson. So, yeah, Steve Aaronson is my dad. He majored in English in Penn State, […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><figure class="wp-block-image size-large"><a href="https://149663533.v2.pressablecdn.com/wp-content/uploads/2022/02/dad70-scaled.jpg"><img alt="" class="wp-image-6302" height="768" src="https://149663533.v2.pressablecdn.com/wp-content/uploads/2022/02/dad70-1024x768.jpg" width="1024"/></a></figure>



<p>When, before covid, I used to travel the world giving quantum computing talks, every once in a while I’d meet an older person who asked whether I had any relation to a 1970s science writer by the name of Steve Aaronson.  So, yeah, Steve Aaronson is my dad.  He majored in English in Penn State, where he was lucky enough to study under the legendary <a href="https://en.wikipedia.org/wiki/William_Tenn">Phil Klass</a>, who wrote under the pen name William Tenn and who basically created the genre of science-fiction comedy, half a century before there were any such things as <em>Futurama</em>.  After graduating, my dad became a popular physics and cosmology writer, who interviewed greats like Steven Weinberg and John Archibald Wheeler and Arno Penzias (discoverer of the cosmic microwave background radiation).  He published not only in science magazines but in <em>Playboy</em> and <em>Penthouse</em>, which (as he explained to my mom) paid better than the science magazines.  When I was growing up, my dad had a <em>Playboy</em> on his office shelf, which I might take down if for example I wanted to show a friend a 2-page article, with an Aaronson byline, about the latest thinking on the preponderance of matter over antimatter in the visible universe.</p>



<p>Eventually, partly motivated by the need to make money to support … well, me, and then my brother, my dad left freelancing to become a corporate science writer at AT&amp;T Bell Labs.  There, my dad wrote speeches, delivered on the floor of Congress, about how breaking up AT&amp;T’s monopoly would devastate Bell Labs, a place that stood with ancient Alexandria and Cambridge University among the human species’ most irreplaceable engines of scientific creativity.  (Being a good writer, my dad didn’t put it in <em>quite</em> those words.)  Eventually, of course, AT&amp;T <em>was</em> broken up, and my dad’s dire warning about Bell Labs turned out to be 100% vindicated … although on the positive side, Americans got much cheaper long distance.</p>



<p>After a decade at Bell Labs, my dad was promoted to be a public relations executive at AT&amp;T itself, where when I was a teenager, he was centrally involved in the launch of the AT&amp;T spinoff <a href="https://en.wikipedia.org/wiki/Lucent">Lucent Technologies</a> (motto: “Bell Labs Innovations”), and then later the Lucent spinoff <a href="https://en.wikipedia.org/wiki/Avaya">Avaya</a>—developments that AT&amp;T’s original breakup had caused as downstream effects.</p>



<p>In the 1970s, somewhere between his magazine stage and his Bell Labs stage, my dad also worked for <a href="https://en.wikipedia.org/wiki/Eugene_Garfield">Eugene Garfield</a>, the pioneer of bibliometrics for scientific papers and founder of the <a href="https://en.wikipedia.org/wiki/Institute_for_Scientific_Information">Institute for Scientific Information</a>, or ISI.  (Sergey Brin and Larry Page would later cite Garfield’s work, on the statistics of the scientific-citation graph, as one of the precedents for the PageRank algorithm at the core of Google.)</p>



<p>My dad’s job at ISI was to supply Eugene Garfield with “raw material” for essays, which the latter would then write and publish in ISI’s journal <em>Current Contents</em> under the byline Eugene Garfield.  Once, though, my dad supplied some “raw material” for a planned essay about “Style in Scientific Writing”—and, well, I’ll let Garfield <a href="http://www.garfield.library.upenn.edu/essays/v3p004y1977-78.pdf">tell</a> the rest:</p>



<blockquote class="wp-block-quote"><p>This topic of style in scientific writing was first proposed as something I should undertake myself, with some research and drafting help from Steve.  I couldn’t, with a clear conscience, have put my name to the “draft” he submitted.  And, though I don’t disagree with much of it, I didn’t want to modify or edit it in order to justify claiming it as my own.  So here is Aaronson’s “draft,” as it was submitted for “review.”  You can say I got a week’s vacation.  After reading what he wrote it required little work to write this introduction.</p></blockquote>



<p>Interested yet?  You can <a href="http://www.garfield.library.upenn.edu/essays/v3p004y1977-78.pdf">read “Style in Scientific Writing” here</a>.  You can, if we’re being honest, tell that this piece was originally intended as “raw material”—but only because of the way it calls forth such a fierce armada of all of history’s awesomest quotations about what makes scientific writing good or bad, like Ben Franklin and William James and the whole gang, which would make it worth the read regardless.  I <em>love</em> eating raw dough, I confess, and I love my dad’s essay.  (My dad, ironically enough, likes everything he eats to be thoroughly cooked.)</p>



<p>When I read that essay, I hear my dad’s voice from my childhood.  “Omit needless words.”  There were countless revisions and pieces of advice on every single thing I wrote, but usually, “omit needless words” was the core of it.  And as terrible as you all know me to be on that count, imagine <em>how much worse</em> it would’ve been if not for my dad!  And I know that as soon as he reads this post, he’ll find needless words to omit.</p>



<p>But hopefully he won’t omit these:</p>



<p>Happy 70th birthday Pops, congrats on beating the cancer, and here’s to many more!</p></div>
    </content>
    <updated>2022-02-12T20:11:04Z</updated>
    <published>2022-02-12T20:11:04Z</published>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <category scheme="https://scottaaronson.blog" term="Self-Referential"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-02-14T19:44:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://nisheethvishnoi.wordpress.com/?p=147</id>
    <link href="https://nisheethvishnoi.wordpress.com/2022/02/11/focs-2021-talk-videos/" rel="alternate" type="text/html"/>
    <title>FOCS 2021 Talk Videos</title>
    <summary>After more than a year of planning, FOCS 2021 concluded yesterday. In case you missed all or part of the event, the talks for all of 117 papers and for the three workshops are now available on this youtube channel. The full versions of all papers (and videos) are also freely available here. Many thanks […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>After more than a year of planning, FOCS 2021 concluded yesterday. </p>



<p>In case you missed all or part of the event, the talks for all of 117 papers and for the three workshops are now available on <a href="https://www.youtube.com/channel/UClrteoQ-ULzlZZaWi6c6iKw/playlists">this youtube</a> channel.</p>



<p>The full versions of all papers (and videos) are also freely available <a href="https://focs2021.cs.colorado.edu/program/">here</a>.</p>



<p>Many thanks to more than 1000 people, including authors, program committee members, external reviewers, organizers, TCMF members, volunteers, and attendees for making this happen! </p>



<figure class="wp-block-video"/></div>
    </content>
    <updated>2022-02-11T14:30:16Z</updated>
    <published>2022-02-11T14:30:16Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>nisheethvishnoi</name>
    </author>
    <source>
      <id>https://nisheethvishnoi.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://nisheethvishnoi.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://nisheethvishnoi.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Algorithms, Nature, and Society</title>
      <updated>2022-02-21T13:38:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19636</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/02/10/national-academy-of-engineering-elects/" rel="alternate" type="text/html"/>
    <title>National Academy of Engineering Elects</title>
    <summary>The problem in this business isn’t to keep people from stealing your ideas; it’s making them steal your ideas!—Howard Aiken Composite crop of homepage photos Taher Elgamal and Anna Karlin are among 111 new US members of the National Academy of Engineering (NAE). That’s one-hundred-and-eleven, not seven in binary. Today we congratulate them and all […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>The problem in this business isn’t to keep people from stealing your ideas; it’s making them steal your ideas!—Howard Aiken</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/10/national-academy-of-engineering-elects/egak/" rel="attachment wp-att-19638"><img alt="" class="alignright size-full wp-image-19638" height="115" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/EGAK.png?resize=155%2C115&amp;ssl=1" width="155"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop of homepage photos</font></td>
</tr>
</tbody>
</table>
<p>
Taher Elgamal and Anna Karlin are among 111 <a href="https://www.nae.edu/270224/National-Academy-of-Engineering-Elects-111-Members-and-22-International-Members">new US members</a> of the National Academy of Engineering (NAE). That’s one-hundred-and-eleven, not seven in binary.</p>
<p>
Today we congratulate them and all the new members.<br/>
<span id="more-19636"/></p>
<p>
Elgamal and Karlin are the two closest to theory, by my reckoning. Elgamal developed the <a href="https://en.wikipedia.org/wiki/ElGamal_encryption">ElGamal</a> encryption scheme. Elgamal spelled his name with a capital G at the time of his famous 1985 <a href="https://caislab.kaist.ac.kr/lecture/2010/spring/cs548/basic/B02.pdf">paper</a> but it is lowercased on his own LinkedIn <a href="https://www.linkedin.com/in/taherelgamal/">page</a>, on Wikipedia, on his RSA conference <a href="https://www.rsaconference.com/experts/dr-taherelgamal">page</a>, and by the NAE. Wikipedia explains that he spells it more simply so that “it is less likely to be mangled in English.” Yet his invention keeps the capital G. Ken and I think a good reason for this is that it uses a large cyclic group <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The citation also hails his work on <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security#SSL_1.0,_2.0,_and_3.0">SSL</a> and other internet protocols.</p>
<p>
We featured Karlin’s nifty joint paper on the metric TSP problem recently <a href="https://rjlipton.wpcomstaging.com/2020/10/26/a-vast-and-tiny-breakthrough/">here</a>. She is also on the editorial board of the new TheoretiCS <a href="https://rjlipton.wpcomstaging.com/2021/12/01/the-new-journal/">journal</a>. I was glad to serve with her on an NSF committee to promote <a href="https://rjlipton.wpcomstaging.com/2011/07/12/time-chunks-and-theory-nuggets/">nuggets</a> of theory. She holds the Bill and Melinda Gates Chair at the Paul Allen School of Computer Science and Engineering at the University of Washington.</p>
<p>
The new members bring the total US membership in the NAE to 2,388. Joining them are 22 new international members. They include Natarajan Chandrasekaran of Tata Sons for advancing the Indian software industry and Hongjiang Zhang of The Carlyle Group in Beijing for multimedia computing. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2022/02/10/national-academy-of-engineering-elects/nae/" rel="attachment wp-att-19639"><img alt="" class="aligncenter wp-image-19639" height="120" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/nae.png?resize=120%2C120&amp;ssl=1" width="120"/></a></p>
<p>
</p><p/><h2> New Members in Computing </h2><p/>
<p/><p>
There are many other new members in areas of computing besides theory. Here are some of the new members that work in computer science—including the citations for Elgamal and Karlin. </p>
<ul>
<p/><li>
Bergeron, Kathleen, vice president, Hardware Engineering, Apple Inc., Los Gatos, Calif. <i>For contributions to and leadership in the invention and engineering product realization of innovative designs.</i><p/>
<p/></li><li>
Bovik, Alan C., Cockrell Family Regents Endowed Chair in Engineering and professor, Electrical and Computer Engineering, University of Texas, Austin. <i>For contributions to the development of tools for image and video quality assessment.</i><p/>
<p/></li><li>
Cohn, John Maxwell, IBM Fellow, MIT-IBM Watson AI Lab, Cambridge, Mass. <i>For improving design productivity of high-performance analog and mixed-signal circuits and for evangelizing STEM education.</i><p/>
<p/></li><li>
Croak, Marian R., vice president, Engineering, Google LLC, Fair Haven, N.J. <i>For technical and managerial leadership in the implementation of packet voice networking and for promotion of minority inclusion in engineering.</i><p/>
<p/></li><li>
Czerwinski, Mary, partner researcher and research manager, Microsoft Research, Redmond, Wash. <i>For the application of psychological principles to the design and understanding of human computer interaction.</i><p/>
<p/></li><li>
Elgamal, Taher, chief technology officer, Security, Salesforce, San Francisco. <i>For contributions to cryptography, e-commerce, and protocols for secure internet transactions.</i><p/>
<p/></li><li>
Fields, Craig I., chairman, Defense Science Board, U.S. Department of Defense, Washington, D.C. <i>For contributions to the development of systems and technology for national security and their transfer to commercial applications.</i><p/>
<p/></li><li>
Hammack, William S., William H. and Janet G. Lycan Professor, Chemical and Biomolecular Engineering, University of Illinois, Urbana-Champaign. <i>For innovations in multidisciplinary engineering education, outreach, and service to the profession through development and communication of internet-delivered content.</i><p/>
<p/></li><li>
Karlin, Anna, Bill and Melinda Gates Chair, Allen School of Computer Science &amp; Engineering, University of Washington, Seattle. <i>For contributions to the design and analysis of randomized algorithms and their impact on computer systems and the internet.</i><p/>
<p/></li><li>
Karniadakis, George Em, Charles Pitts Robinson and John Palmer Barstow Professor, Division of Applied Mathematics and School of Engineering, Brown University, Providence, R.I. <i>For computational tools, from high-accuracy algorithms to machine learning, and applications to complex flows, stochastic processes, and microfluidics.</i><p/>
<p/></li><li>
Levoy, Marc, Vmware Founders Professor (emeritus), Computer Science, Stanford University, Stanford, Calif. <i>For contributions to computer graphics and digital photography.</i><p/>
<p/></li><li>
Mauro, John C., professor, Department of Materials Science and Engineering, Pennsylvania State University, University Park. <i>For developing and applying data-driven models and machine learning that enable high-strength, damage-resistant glasses.</i><p/>
<p/></li><li>
Nadella, Satya, chairman and chief executive officer, Microsoft Corp., Redmond, Wash. <i>For advancing corporate computing infrastructure as a cloud service, and for international leadership on sociotechnical systems and practice.</i> <p/>
<p/></li><li>
Nahrstedt, Klara, Grainger Distinguished Chair, Grainger College of Engineering, University of Illinois, Urbana-Champaign. <i>For contributions to managing quality of service in distributed multimedia systems and networks.</i><p/>
<p/></li><li>
Reiman, Martin I., professor, Department of Industrial Engineering and Operations Research, Columbia University, Murray Hill, N.J. <i>For contributions to network theory and applications in large-scale stochastic systems.</i><p/>
<p/></li><li>
Sahinidis, Nikolaos V., Gary C. Butler Family Chair and Professor, H. Milton Stewart School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta. <i>For contributions to global optimization and the development of widely used software for optimization and machine learning.</i><p/>
<p/></li><li>
Sapiro, Guillermo, James B. Duke Distinguished Professor, Electrical and Computer Engineering, Duke University, Durham, N.C. <i>For contributions to the theory and practice of imaging.</i><p/>
<p/></li><li>
Veloso, Manuela M., head, Artificial Intelligence Research, JPMorgan Chase &amp; Co., New York City. <i>For contributions to machine learning and its applications in robotics and the financial services industry.</i><p/>
<p/></li><li>
Whitney, Telle, CEO, Telle Whitney Consulting LLC, Scotts Valley, Calif. <i>For contributions to structured silicon design and for increasing the participation of women in computing careers.</i><p/>
<p/></li><li>
Willcox, Karen E., director, Oden Institute for Computational Engineering and Sciences, University of Texas, Austin. <i>For contributions to computational engineering methods for the design and optimal control of high-dimensional systems with uncertainties.</i><p/>
</li></ul>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We count 8 women of the 20 above: Bergeron, Croak, Czerwinski, Karlin, Nahrstedt, Veloso, Whitney, and Willcox. That’s quite a lot better than other rations we’ve observed. How can awareness of this success be filtered through? We also note Anna’s <a href="https://medium.com/@karlin_41004/why-women-and-everyone-else-should-code-18e4a0a46a47">essay</a>, “Why Women (and Everyone Else) Should Code.”</p>
<p/></font></font></div>
    </content>
    <updated>2022-02-11T01:40:02Z</updated>
    <published>2022-02-11T01:40:02Z</published>
    <category term="All Posts"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Anna Karlin"/>
    <category term="National Academy of Engineering"/>
    <category term="new members"/>
    <category term="Taher Elgamal"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-02-21T13:37:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/02/10/hereditary-first-order</id>
    <link href="https://11011110.github.io/blog/2022/02/10/hereditary-first-order.html" rel="alternate" type="text/html"/>
    <title>Hereditary first order graph properties can be hard</title>
    <summary>Many natural classes of undirected graphs are hereditary, meaning that if you delete vertices from any graph in the class, the induced subgraph that you get always remains in this class. Every hereditary class of graphs can be defined by its forbidden induced subgraphs, the minimal graphs that do not belong to the class. When there are only finitely many of these forbidden subgraphs, it is possible to define the class by a formula in the first-order logic of graphs describing the graphs that do not have these subgraphs, and to test membership in the class in polynomial time by searching for a forbidden subgraph. Examples include:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Many natural classes of undirected graphs are <a href="https://en.wikipedia.org/wiki/Hereditary_property">hereditary</a>, meaning that if you delete vertices from any graph in the class, the induced subgraph that you get always remains in this class. Every hereditary class of graphs can be defined by its <a href="https://en.wikipedia.org/wiki/Forbidden_graph_characterization">forbidden induced subgraphs</a>, the minimal graphs that do not belong to the class. When there are only finitely many of these forbidden subgraphs, it is possible to define the class by a formula in the first-order <a href="https://en.wikipedia.org/wiki/Logic_of_graphs">logic of graphs</a> describing the graphs that do not have these subgraphs, and to test membership in the class in polynomial time by searching for a forbidden subgraph. Examples include:</p>

<ul>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Threshold_graph">threshold graphs</a>, whose forbidden subgraphs are a four-vertex path, four-vertex cycle, or four-vertex perfect matching.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Cograph">cographs</a>, whose single forbidden subgraph is a four-vertex path.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Triangle-free_graph">triangle-free graphs</a>, whose single forbidden subgraph is a <span style="white-space: nowrap;">triangle \(K_3\).</span></p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Claw-free_graph">claw-free graphs</a>, whose single forbidden subgraph is the four-vertex <span style="white-space: nowrap;">tree \(K_{1,3}\).</span></p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Line_graph">line graphs</a>, which have a forbidden subgraph characterization with nine forbidden subgraphs:</p>
  </li>
</ul>

<p style="text-align: center;"><img alt="The nine forbidden induced subgraphs of line graphs" src="https://11011110.github.io/blog/assets/2022/nonline.svg"/></p>

<p>However, there might be infinitely many forbidden subgraphs. In many such cases, it is still possible to recognize these graphs in polynomial time, often by a greedy algorithm that removes vertices one at a time based on some local structure. Additionally, in these cases, it is often possible to describe the property of being one of the forbidden subgraphs by a first-order formula, so that the graph class is the class of graphs none of whose subgraphs model that formula. For instance:</p>

<ul>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Degeneracy_(graph_theory)"><span style="white-space: nowrap;">\(d\)-degenerate</span> graphs</a> are graphs in which no non-empty induced subgraph has all vertices of degree greater <span style="white-space: nowrap;">than \(d\).</span> They can be recognized in polynomial time as the graphs reducible to empty by repeatedly removing low-degree vertices.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Distance-hereditary_graph">distance-hereditary graphs</a> are graphs in which every induced subgraph with two or more vertices has a degree-one vertex, or twins, two vertices with equal closed or open neighborhoods. They can be recognized in polynomial time by repeatedly removing degree-one vertices or merging twins.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Chordal_graph">chordal graphs</a> are graphs with no induced cycle of more than three vertices, or the graphs in which every non-empty induced subgraph has a simplicial vertex, a vertex whose neighbors are all adjacent. They can be recognized in polynomial time by repeatedly removing simplicial vertices.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Perfect_graph">perfect graphs</a> are graphs with no odd induced cycle of more than three vertices, or its complement. They can be recognized in polynomial time but the algorithm is complicated.</p>
  </li>
</ul>

<p>Obviously, not all hereditary classes are like that; one could, for instance, forbid induced cycles whose lengths belong to an undecidable set of integers, and get a hereditary class of graphs whose recognition problem is again undecidable. But this led me to wonder: is there a connection between the first-order recognizability of the forbidden subgraphs and the polynomial recognizability of the graph class itself? Could it be that every hereditary class defined by a first-order set of forbidden subgraphs is polynomially recognizable?</p>

<p>No!</p>

<p>The counterexample I found is the family of graphs whose forbidden subgraphs are the non-empty <a href="https://en.wikipedia.org/wiki/Perfect_graph">cubic (3-regular) graphs</a>. Let’s call these the cubic-free graphs. Being cubic is easily expressed in first-order logic, so the forbidden subgraphs for the cubic-free graphs are first-order recognizable. However, under standard assumptions, the cubic-free graphs themselves are not polynomially recognizable: their recognition problem is <span style="white-space: nowrap;">\(\mathsf{coNP}\)-complete.</span> Put another way, the problem <small>CUBIC INDUCED SUBGRAPH</small> asking whether a given graph has a non-empty cubic induced subgraph is <span style="white-space: nowrap;">\(\mathsf{NP}\)-complete.</span></p>

<p>I found lots of references in the literature to problems of finding non-empty cubic subgraphs (not required to be induced subgraphs; see Garey &amp; Johnson GT32), or to finding cubic induced subgraphs with some constraint on their size, but not to the <small>CUBIC INDUCED SUBGRAPH</small> problem itself. So instead, I found an <span style="white-space: nowrap;">\(\mathsf{NP}\)-completeness</span> reduction myself, from <a href="https://en.wikipedia.org/wiki/3-dimensional_matching"><small>3-DIMENSIONAL MATCHING</small></a>, in which the input is a 3-uniform hypergraph (meaning that each hyperedge touches three hypervertices) and one must find a subset of the hyperedges that touches every hypervertex exactly once. An example of my reduction is shown below, from which I think the general case should be more clear.</p>

<p style="text-align: center;"><img alt="NP-completeness reduction from 3-dimensional matching to cubic induced subgraph" src="https://11011110.github.io/blog/assets/2022/3dm23is.svg"/></p>

<p>The input hypergraph is shown with its hypervertices as large blue disks and its hyperedges as medium-sized yellow disks. Inside each of these disks is shown part of a graph, a gadget into which that piece of the hypergraph is translated to form a piece of a <small>CUBIC INDUCED SUBGRAPH</small> instance. The example hypergraph used in the image is 4-regular (every hypervertex touches four hyperedges) but that’s not essential. Once you start making choices of which vertices to include or exclude in an induced subgraph, you can make a chain of inferences from that choice:</p>
<ul>
  <li>If you have included a vertex that has only three non-excluded neighbors, you must include all three of them.</li>
  <li>If you have included a vertex that has three included neighbors, you must exclude all its other neighbors.</li>
  <li>If some vertex has fewer than three neighbors that are not excluded, you must exclude it.</li>
</ul>

<p>It follows from this sort of reasoning that the only non-empty cubic induced subgraphs are like the ones shown by the dark red vertices in these gadgets: a vertex for each of the the hyperedges in a matching (such as the matching of dark-yellow hyperedges), and a corresponding subset of the vertices in every hypervertex gadget. Because finding a cubic induced subgraph is <span style="white-space: nowrap;">\(\mathsf{NP}\)-complete,</span> its complementary problem, testing whether a graph is cubic-free, is <span style="white-space: nowrap;">\(\mathsf{coNP}\)-complete.</span></p>

<p>(<a href="https://mathstodon.xyz/@11011110/107776994325248199">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2022-02-10T17:40:00Z</updated>
    <published>2022-02-10T17:40:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-02-16T06:13:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/10/postdoc-in-computational-complexity-at-imperial-college-london-apply-by-april-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/10/postdoc-in-computational-complexity-at-imperial-college-london-apply-by-april-15-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc in computational complexity at Imperial College London (apply by April 15, 2022)</title>
    <summary>Applications are invited for a postdoctoral position at the Complexity Group, Imperial College London, led by prof. Iddo Tzameret and funded by the ERC. The position is for one year with up to two-year extension. The start date is flexible, and the salary is generous. This position is based at the South Kensington campus in […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a postdoctoral position at the Complexity Group, Imperial College London, led by prof. Iddo Tzameret and funded by the ERC. The position is for one year with up to two-year extension. The start date is flexible, and the salary is generous. This position is based at the South Kensington campus in the heart of London. Applications will be accepted until position filled.</p>
<p>Website: <a href="https://www.doc.ic.ac.uk/~itzamere/PhD_Postdoc_Post.html">https://www.doc.ic.ac.uk/~itzamere/PhD_Postdoc_Post.html</a><br/>
Email: iddo.tzameret@gmail.com</p></div>
    </content>
    <updated>2022-02-10T17:39:08Z</updated>
    <published>2022-02-10T17:39:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-21T13:37:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/10/tenure-track-assistant-professor-at-university-of-vienna-apply-by-march-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/10/tenure-track-assistant-professor-at-university-of-vienna-apply-by-march-15-2022/" rel="alternate" type="text/html"/>
    <title>Tenure-track assistant professor at University of Vienna (apply by March 15, 2022)</title>
    <summary>The faculty of Computer Science is looking for outstanding internationally recognized early career scientists with a research focus on scalable algorithmic approaches for AI. This competence is documented by publications in top venues in relevant areas, including, but not limited to, – machine learning, – AI, – algorithms, or – high performance computing research. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The faculty of Computer Science is looking for outstanding internationally recognized early career scientists with a research focus on scalable algorithmic approaches for AI.<br/>
This competence is documented by publications in top venues in relevant areas, including, but not limited to, – machine learning,<br/>
– AI,<br/>
– algorithms, or<br/>
– high performance computing research.</p>
<p>Website: <a href="https://univis.univie.ac.at/ausschreibungstellensuche/flow/bew_ausschreibung-flow?_flowExecutionKey=_c11E8D826-8A93-525D-7F25-64B17F6D4117_k70C7134F-AA27-C4B1-26FA-8A869B87BA6B&amp;tid=89875.28">https://univis.univie.ac.at/ausschreibungstellensuche/flow/bew_ausschreibung-flow?_flowExecutionKey=_c11E8D826-8A93-525D-7F25-64B17F6D4117_k70C7134F-AA27-C4B1-26FA-8A869B87BA6B&amp;tid=89875.28</a><br/>
Email: monika.henzinger@univie.ac.at</p></div>
    </content>
    <updated>2022-02-10T14:34:39Z</updated>
    <published>2022-02-10T14:34:39Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-21T13:37:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=22399</id>
    <link href="https://gilkalai.wordpress.com/2022/02/10/is-hqca-possible-a-conversation-with-michael-brooks/" rel="alternate" type="text/html"/>
    <title>Is HQCA Possible? A conversation with Michael Brooks</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Here is a short email interview from April 2021 with Michael Brooks from “New Scientist”. Dear Professor Kalai, I’m writing a short feature for New Scientist magazine on the theme “Will we ever have a useful quantum computer?”. I’m aware … <a href="https://gilkalai.wordpress.com/2022/02/10/is-hqca-possible-a-conversation-with-michael-brooks/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Here is a short email interview from April 2021 with Michael Brooks from “New Scientist”.</p>
<p><span class="im"><strong>Dear Professor Kalai,</strong> <b>I’m writing a short feature for New Scientist magazine on the theme “Will we ever have a useful quantum computer?”. I’m aware of your work on the problems with noise, and your position that error correction won’t be possible.</b></span></p>
<p>This is correct. My analysis asserts that quality error correction won’t be possible and that even the easier target of <span class="il">HQCA</span> (huge quantum computational advantage) won’t be possible. Here is a <a href="https://arxiv.org/abs/2008.05188">link</a> to my new paper that you may find useful. It refers to recent developments: the Google Sycamore experiment and <span class="il">HQCA</span> claims are discussed in Sections 6 and 7, and there is a new Section 9 regarding the very recent developments.</p>
<p><b>I was wondering whether anything you’ve seen – demonstrations or arguments – in the last few months have done anything to change your mind, or whether you are now more convinced than ever that we won’t ever see truly useful (beyond doing science) quantum computing?  </b></p>
<p>Well, I think that my theory is rather strong but not ironclad. As for the level of my conviction, it does not change often, but roughly speaking there were three stages to my research (and level of conviction):</p>
<p>1) 2005-2013.   What I did was (in hindsight) exploring consequences of the failure of quantum fault tolerance and, on the way, some mistakes in the logic of firmly believing that quantum computers could be built. But, as I often said at that time, I did not think my work then gave a reason for people to change their a priori beliefs.</p>
<p>2) 2013-2019.  Following my work with Guy Kindler I saw a clear scientific argument for why quantum computers will fail. (We first considered the special case of boson sampling and later I extended it in  greater generality.) Since that time, I regard my argument to be strong enough to change people a priori beliefs, and my level of conviction went up as well. But, as I said, it is not an ironclad argument.</p>
<p>3) 2019 – onward.  The experimental claims by Google and later by a group from Hefei, China would, if correct, refute my argument. So, naturally, this casts some doubts also in my mind. However, there are good technical reasons to doubt the fantastic claims by the Hefei group, and on that matter actually my 2014 paper with Kindler comes to play. The situation with the Google experiment is more delicate, but there are reasons to doubt their experimental claims as well.</p>
<p>As for a priori beliefs: In my view the situation is that it is hard to believe that quantum computers are not possible, but it is even harder to believe that quantum computers are possible <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/> . So much experimental and theoretical research is needed before humankind will crack this puzzle.</p>
<p><span class="im"><b>Also, I was wondering if the retraction of the main paper about creating Majorana fermions (<a href="https://www.nature.com/articles/d41586-021-00612-z" rel="noopener" target="_blank">https://www.nature.com/articles/d41586-021-00612-z</a>) kills topological computing’s hopes of getting us there?</b></span></p>
<p>No, the retraction of a single paper does not kill at all topological computing’s hopes. In fact, the researchers who found the mistake are hopeful that a successful experiment of that kind is possible and are also hopeful regarding further experimental steps towards topological quantum computing.</p>
<p>My general argument does extend to topological quantum computing and asserts that stable topological qubits are not possible.</p>
<p>Thanks for your interest and best wishes,  Gil Kalai</p>
<p><strong>Additional comments:</strong> The (very nice) <a href="https://www.scientiststudy.com/2021/09/why-it-might-be-impossible-to-build.html">article appeared in August 2021</a> and (accurately) refers to my position: “Gil Kalai, a mathematician at the Hebrew University of Jerusalem in Israel, argued that the basic noise level in a quantum computer will always be too high, no matter how many qubits are available. ‘My analysis says that correcting quality errors will not be possible.’ ” The article quotes also <a href="https://researchportal.helsinki.fi/en/persons/sabrina-maniscalco/publications/">Sabrina Maniscalco</a> from the University of Helsinki in Finland who said: “Finding a cure for the effect of environmental noise is not only, in my opinion, a technological problem, but more conceptual and fundamental. I would say that I am optimistic, rather than confident”.</p>
<p>My debate with Aram Harrow over GLL <a href="https://rjlipton.wpcomstaging.com/2012/01/30/perpetual-motion-of-the-21st-century/">started ten years ago</a>. A lot has happened in these ten years! (Here is a <a href="https://rjlipton.wpcomstaging.com/2012/01/30/perpetual-motion-of-the-21st-century/#comment-18029">comment</a> from the debate on my assessment of the situation at that time.)</p>
<p>The researchers who took on themselves the thankless task of putting the Microsoft Majorana claims under scrutiny and found the mistakes are <a href="https://www.physicsandastronomy.pitt.edu/people/sergey-frolov" rel="noopener" target="_blank">Sergey Frolov</a> and <a href="https://www.fqt.unsw.edu.au/staff/vincent-mourik-0" rel="noopener" target="_blank">Vincent Mourik</a>. (See also <a href="https://www.nature.com/articles/d41586-021-00954-8">Frolov’s commentary</a> in “Nature” and <a href="https://www.quantamagazine.org/major-quantum-computing-strategy-suffers-serious-setbacks-20210929/">this article</a> in “Quanta Magazine”.) They drew important conclusions for the need of sharing raw data and other experimental details for such experiments.</p>
<p>For more details:  on my view regarding quantum computers see <a href="https://gilkalai.wordpress.com/2020/12/29/the-argument-against-quantum-computers-a-very-short-introduction/" rel="bookmark">The Argument Against Quantum Computers – A Very Short Introduction</a> (December 2020); and on Google’s supremacy experiment see <a href="https://gilkalai.wordpress.com/2019/11/13/gils-collegial-quantum-supremacy-skepticism-faq/" rel="bookmark">Gil’s Collegial Quantum Supremacy Skepticism FAQ</a> (November 2019).</p></div>
    </content>
    <updated>2022-02-10T09:57:23Z</updated>
    <published>2022-02-10T09:57:23Z</published>
    <category term="Computer Science and Optimization"/>
    <category term="Quantum"/>
    <category term="Aram Harrow"/>
    <category term="Michael Brooks"/>
    <category term="Quantum computers"/>
    <category term="Sabrina Maniscalco"/>
    <category term="Sergey Frolov"/>
    <category term="Vincent Mourik"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2022-02-21T13:37:29Z</updated>
    </source>
  </entry>
</feed>
