<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2022-05-04T12:38:20Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19968</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/05/04/sedgewick-to-emeritus-status/" rel="alternate" type="text/html"/>
    <title>Sedgewick to Emeritus Status</title>
    <summary>Retire from your job, but never retire your mind. Bob Sedgewick is becoming an emeritus professor: When Faculty transfer to emeritus status and retain a professional connection with Princeton, they are expected to conduct their future research and University-related activities with the same ethical standards currently expected from all Princeton Faculty. Emeritus faculty members may […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<i>Retire from your job, but never retire your mind.</i></p>
<p>
Bob Sedgewick is becoming an <a href="https://dof.princeton.edu/book/export/html/5486">emeritus</a> professor: </p>
<p>
When Faculty transfer to emeritus status and retain a professional connection with Princeton, they are expected to conduct their future research and University-related activities with the same ethical standards currently expected from all Princeton Faculty. </p>
<p>
Emeritus faculty members may receive such University publications as the Princeton University Bulletin and the Princeton Alumni Weekly, as well as agendas and minutes of University Faculty Meetings. They may attend meetings of the University and departmental faculty upon invitation, but do not have votes at these meetings. Emeritus faculty members continue to receive University identification cards and to have use of the library, the athletic facilities and dining facilities on the same basis as active faculty members. </p>
<p>
A not so recent picture: <a href="https://rjlipton.wpcomstaging.com/rs/"><img alt="" class="aligncenter size-medium wp-image-19971" height="300" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/05/rs.jpg?resize=218%2C300&amp;ssl=1" width="218"/></a></p>
<p>
</p><p><b> Some History </b></p>
<p/><p>
Sedgewick got his PhD at Stanford and returned to Brown to start his academic career as an assistant professor in 1975. He was promoted to associate professor in 1980 and full professor in 1983. At Brown, he <a href="http://cs.brown.edu/events/25th-anniversary/hist_text.html">participated</a> in the <a href="https://news.brown.edu/articles/2014/05/cs35#:~:text=This year marks the 35th,Digital VAX-11/80.">founding</a> of the computer science department, in 1979. </p>
<p>
Later in 1985 he joined the faculty at Princeton as <a href="https://www.princeton.edu/news/2019/05/03/sedgewick-recognized-contribution-computer-science-education">founding</a> chair of the Department of Computer Science. Two founding positions—pretty neat. His first-year courses in computer science are among the most popular ever offered at Princeton. He also pioneered the practice of replacing large live lectures with on-demand online videos—pretty clever. </p>
<p>
Bob has worked at research institutions outside of Princeton during summers and leaves. Three come to mind: </p>
<ul>
<li> <a href="https://idaccr.org/about-us">IDA</a>, the Institute for Defense Analyses, gave him an opportunity to work with the CRAY-1 <a href="https://en.wikipedia.org/wiki/Cray-1">supercomputer</a>.
</li><li> <a href="https://www.parc.com">PARC</a>, Xerox Palo Alto Research Center, gave him an opportunity to see the personal computer come into existence.
</li><li> <a href="https://en.wikipedia.org/wiki/French_Institute_for_Research_in_Computer_Science_and_Automation">INRIA</a>, The Institut National de Recherche en Informatique et en Automatique, gave him a chance to work closely with Philippe Flajolet
</li></ul>
<p>
I joined him at IDA a few years later. I had to get a security clearance which is another whole story—see this <a href="https://rjlipton.wpcomstaging.com/2015/09/03/open-problems-that-might-be-easy/">post</a> for some fun thoughts.</p>
<p>
</p><p><b> Some More History </b></p>
<p/><p>
Bob and I wrote some papers together: Two were on <a href="https://en.wikipedia.org/wiki/Very_Large_Scale_Integration">VLSI</a>. The first on <a href="https://sedgewick.io/wp-content/themes/sedgewick/papers/1981Lower.pdf">lower</a> bounds on the size of chips that computed something and the second on a language <a href="https://sedgewick.io/wp-content/themes/sedgewick/papers/1982ALI.pdf">ALI</a> for designing VLSI circuits. </p>
<p>
Another paper was included also Jin-yi Cai and Andy Yao on <a href="https://ieeexplore.ieee.org/document/336546">Towards Uncheatable benchmarks</a>. Or see a follow-on <a href="https://link.springer.com/content/pdf/10.1007/978-0-387-35568-9_18.pdf">paper</a>. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/bs/"><img alt="" class="aligncenter size-medium wp-image-19972" height="300" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/05/bs.png?resize=225%2C300&amp;ssl=1" width="225"/></a></p>
<p>
</p><p><b> Open Problems </b></p>
<p/><p>
It was wonderful working <i>for</i> Bob when he was the chair of Computer Science and wonderful working <i>with</i> him on the above papers and more. </p>
<p>
Bob, have a wonderful time being retired. And happy emeritus status.</p>
<p/></div>
    </content>
    <updated>2022-05-04T10:54:47Z</updated>
    <published>2022-05-04T10:54:47Z</published>
    <category term="History"/>
    <category term="News"/>
    <category term="Oldies"/>
    <category term="People"/>
    <category term="Results"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-05-04T12:37:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6411</id>
    <link href="https://scottaaronson.blog/?p=6411" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6411#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6411" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Donate to protect women’s rights: a call to my fellow creepy, gross, misogynist nerdbros</title>
    <summary xml:lang="en-US">So, I’d been planning a fun post for today about the DALL-E image-generating AI model, and in particular, a brief new preprint about DALL-E’s capabilities by Ernest Davis, Gary Marcus, and myself. We wrote this preprint as a sort of “adversarial collaboration”: Ernie and Gary started out deeply skeptical of DALL-E, while I was impressed […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>So, I’d been planning a fun post for today about the <a href="https://en.wikipedia.org/wiki/DALL-E">DALL-E</a> image-generating AI model, and in particular, a brief new <a href="https://arxiv.org/abs/2204.13807">preprint</a> about DALL-E’s capabilities by <a href="https://cs.nyu.edu/~davise/">Ernest Davis</a>, <a href="https://en.wikipedia.org/wiki/Gary_Marcus">Gary Marcus</a>, and myself.  We wrote this preprint as a sort of “adversarial collaboration”: Ernie and Gary started out deeply skeptical of DALL-E, while I was impressed bordering on awestruck.  I was pleasantly surprised that we nevertheless managed to produce a text that we all agreed on.</p>



<p>Not for the first time, though, world events have derailed my plans.  The most important part of today’s post is this:</p>



<p><strong>For the next week, I, Scott Aaronson, will personally match all reader donations to <a href="https://fundtexaschoice.org/">Fund Texas Choice</a>—a group that helps women in Texas travel to out-of-state health clinics, for reasons that are neither your business nor mine—up to a total of $5,000.</strong></p>



<p>To show my seriousness, I’ve already $1,000.  Just let me know how much you’ve donated in the comments section!</p>



<p>The first reason for this donation drive is that, perhaps like many of you, I stayed up hours last night reading Alito’s <a href="https://www.documentcloud.org/documents/21835435-scotus-initial-draft">leaked decision</a> in a state of abject terror.  I saw how the logic of the decision, consistent and impeccable on its own terms, is one by which the Supreme Court’s five theocrats could now proceed to unravel the whole of modernity.  I saw how this court, unchecked by our broken democratic system, can now permanently enshrine the will of a radical minority, perhaps unless and until the United States is plunged into a second Civil War.</p>



<p>Anyway, that’s the first reason for the donation drive.  The second reason is to thank <em>Shtetl-Optimized</em>‘s commenters for their … err, consistently generous and thought-provoking contributions.  Let’s take, for example, <a href="https://scottaaronson.blog/?p=6405#comment-1938839">this</a> comment on last week’s admittedly <a href="https://scottaaronson.blog/?p=6405">rather silly post</a>, from an anonymous individual who calls herself “Feminist Bitch,” and who was enraged that it took me <em>a</em> <em>full day</em> to process one of the great political cataclysms of our lifetimes and publicly react to it:</p>



<blockquote class="wp-block-quote"><p>OF COURSE. Not a word about Roe v. Wade being overturned, but we get a pseudo-intellectual rationalist-tier rant about whatever’s bumping around Scott’s mind right now. Women’s most basic reproductive rights are being curtailed AS WE SPEAK and not a peep from Scott, eh? Even though in our state (Texas) there are already laws ON THE BOOKS that will criminalize abortion as soon as the alt-right fascists in our Supreme Court give the go-ahead. If you cared one lick about your female students and colleagues, Scott, you’d be posting about the Supreme Court and helping feminist causes, not posting your “memes.” But we all know Scott doesn’t give a shit about women. He’d rather stand up for creepy nerdbros and their right to harass women than women’s right to control their own fucking bodies. Typical Scott.</p></blockquote>



<p>If you want, you can <a href="https://scottaaronson.blog/?p=6405#comment-1938839">read</a> all of Feminist Bitch’s further thoughts about my failings, with my every attempt to explain and justify myself met with further contempt.  No doubt my well-meaning friends of both sexes would counsel me to ignore her.  Alas, from my <a href="https://www.theatlantic.com/politics/archive/2015/01/the-blog-comment-that-achieved-an-internet-miracle/384539/">infamous ordeal</a> of late 2014, I know that with her every word, Feminist Bitch speaks for thousands, and the knowledge eats at me day and night.</p>



<p>It’s often said that “the right looks for converts, while the left looks only for heretics.”  Has Feminist Bitch ever stopped to think about <em>how</em> our civilization reached its current terrifying predicament—how Trump won in 2016, how the Supreme Court got packed with extremists who represent a mere 25% of the country, how Putin and Erdogan and Orban and Bolsonaro and all the rest consolidated their power?  Does she think it happened because wokeists like herself reached out too much, made too many inroads among fellow citizens who share <em>some</em> but not <em>all</em> of their values?  Would Feminist Bitch say that, if the Democrats want to capitalize on the coming tsunami of outrage about the death of <em>Roe</em> and the shameless lies that enabled it, if they want to sweep to victory in the midterms and enshrine abortion rights into federal law … then their best strategy would be to double down on their condemnations of gross, creepy, smelly, white male nerdbros who all the girls, like, <em>totally hate</em>?</p>



<p>(until, thank God, some of them don’t)</p>



<p>I continue to think that the majority of my readers, of all races and sexes and backgrounds, are reasonable and sane.  I continue to think the majority of you recoil against hatred and dehumanization of <em>anyone</em>—whether that means women seeking abortions, gays, or (gasp!) even white male techbros.  In this sad twilight for the United States and for liberal democracy around the world, we the reasonable and sane, we the fans of the Enlightenment, we the <a href="https://scottaaronson.blog/?p=3922">Party of Psychological Complexity</a>, have decades of work cut out for us.  For now I’ll simply say: I don’t hear from you nearly enough in the comments.</p></div>
    </content>
    <updated>2022-05-04T05:38:14Z</updated>
    <published>2022-05-04T05:38:14Z</published>
    <category scheme="https://scottaaronson.blog" term="Obviously I'm Not Defending Aaronson"/>
    <category scheme="https://scottaaronson.blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-05-04T06:10:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/065</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/065" rel="alternate" type="text/html"/>
    <title>TR22-065 |  Streaming and Sketching Complexity of CSPs: A survey | 

	Madhu Sudan</title>
    <summary>In this survey we describe progress over the last decade or so in understanding the complexity of solving constraint satisfaction problems (CSPs) approximately in the streaming and sketching models of computation. After surveying some of the results we give some sketches of the proofs and in particular try to explain why there is a tight dichotomy result for sketching algorithms working in subpolynomial space regime.</summary>
    <updated>2022-05-03T19:56:03Z</updated>
    <published>2022-05-03T19:56:03Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-05-04T12:37:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/064</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/064" rel="alternate" type="text/html"/>
    <title>TR22-064 |  Improved Low-Depth Set-Multilinear Circuit Lower Bounds | 

	Deepanshu Kush, 

	Shubhangi Saraf</title>
    <summary>In this paper, we prove strengthened lower bounds for constant-depth set-multilinear formulas. More precisely, we show that over any field, there is an explicit polynomial $f$ in VNP defined over $n^2$ variables, and of degree $n$, such that any product-depth $\Delta$ set-multilinear formula computing $f$ has size at least $n^{\Omega \left( n^{1/\Delta}/\Delta\right)}$. The hard polynomial $f$ comes from the class of Nisan-Wigderson (NW) design-based polynomials. 

Our lower bounds improve upon the recent work of Limaye, Srinivasan and Tavenas (STOC 2022), where a lower bound of the form $(\log n)^{\Omega (\Delta n^{1/\Delta})}$ was shown for the size of product-depth $\Delta$ set-multilinear formulas computing the iterated matrix multiplication (IMM) polynomial of the same degree and over the same number of variables as $f$. Moreover, our lower bounds are novel for any $\Delta\geq 2$.

The precise quantitative expression in our lower bound is interesting also because the lower bounds we obtain are "sharp" in the sense that any asymptotic improvement would imply general set-multilinear circuit lower bounds via depth reduction results. 

In the setting of general set-multilinear formulas, a lower bound of the form $n^{\Omega(\log n)}$ was already obtained by Raz (J. ACM 2009) for the more general model of multilinear formulas. The techniques of LST (which extend the techniques of the same authors in (FOCS 2021)) give a different route to set-multilinear formula lower bounds, and allow them to obtain a lower bound of the form $(\log n)^{\Omega(\log n)}$ for the size of general set-multilinear formulas computing the IMM polynomial. Our proof techniques are another variation on those of LST, and enable us to show an improved lower bound (matching that of Raz) of the form $n^{\Omega(\log n)}$, albeit for the same polynomial $f$ in VNP (the NW polynomial). As observed by LST, if the same $n^{\Omega(\log n)}$ size lower bounds for unbounded-depth set-multilinear formulas could be obtained for the IMM polynomial, then using the self-reducibility of IMM and using hardness escalation results, this would imply super-polynomial lower bounds for general algebraic formulas.</summary>
    <updated>2022-05-03T19:37:30Z</updated>
    <published>2022-05-03T19:37:30Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-05-04T12:37:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/063</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/063" rel="alternate" type="text/html"/>
    <title>TR22-063 |  Fast Multivariate Multipoint Evaluation Over All Finite Fields | 

	Mrinal Kumar, 

	Sumanta Ghosh, 

	Zeyu Guo, 

	Chris Umans, 

	Vishwas Bhargava</title>
    <summary>Multivariate multipoint evaluation is the problem of evaluating a multivariate polynomial, given as a coefficient vector, simultaneously at multiple evaluation points. In this work, we show that there exists a deterministic algorithm for multivariate multipoint evaluation over any finite field $\mathbb{F}$ that outputs the evaluations of an $m$-variate polynomial of degree less than $d$ in each variable at $N$ points in time 
\[
(d^m+N)^{1+o(1)}\cdot poly(m,d,\log|\F|)
\]
for all $m\in\mathbb{N}$ and all sufficiently large $d\in \mathbb{N}$.

A previous work of Kedlaya and Umans (FOCS 2008, SICOMP 2011) achieved the same time complexity when the number of variables $m$ is at most $d^{o(1)}$ and had left the problem of removing this condition as an open problem. A recent work of Bhargava, Ghosh, Kumar and Mohapatra (STOC 2022) answered this question when the underlying field is not too large  and has characteristic less than $d^{o(1)}$. In this work, we remove this constraint on the number of variables over all finite fields, thereby answering the question of Kedlaya and Umans over all finite fields. 

Our algorithm relies on a non-trivial combination of ideas from three seemingly different previously known algorithms for multivariate multipoint evaluation, namely the algorithms of Kedlaya and Umans, that of  Bj\"orklund, Kaski and Williams (IPEC 2017, Algorithmica 2019), and that of Bhargava, Ghosh, Kumar and Mohapatra, together with a result of Bombieri and Vinogradov from analytic number theory about the distribution of primes in an arithmetic progression. 

We also present a second algorithm for multivariate multipoint evaluation that is completely elementary and in particular, avoids the use of the Bombieri--Vinogradov Theorem. However, it requires a mild assumption that the field size is bounded by an exponential-tower in $d$ of bounded height. More specifically, our second algorithm solves the multivariate multipoint evaluation problem over a finite field $\mathbb{F}$ in time 
\[
(d^m+N)^{1+o(1)}\cdot poly(m,d,\log |\mathbb{F}|)\]
for all $m\in \mathbb{N}$ and all sufficiently large $d\in \mathbb{N}$, provided that the size of the finite field $\mathbb{F}$ is at most $(\exp(\exp(\exp(\cdots (\exp(d)))))$, where the height of this tower of exponentials is fixed.</summary>
    <updated>2022-05-03T19:35:28Z</updated>
    <published>2022-05-03T19:35:28Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-05-04T12:37:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8321</id>
    <link href="https://windowsontheory.org/2022/05/03/philosophy-of-science-and-the-blockchain-a-book-review/" rel="alternate" type="text/html"/>
    <title>Philosophy of science and the blockchain: A book review</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This blog post is a book review of sorts for the following two books: To Explain the World: The Discovery of Modern Science by Steven Weinberg (2016) The Knowledge Machine: How Irrationality Created Modern Science by Michael Strevens (2020). Both books cover (in different proportions) the history and philosophy of science. By the end of … <a class="more-link" href="https://windowsontheory.org/2022/05/03/philosophy-of-science-and-the-blockchain-a-book-review/">Continue reading <span class="screen-reader-text">Philosophy of science and the blockchain: A book review</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This blog post is a book review of sorts for the following two books:</p>



<p><a href="https://www.amazon.com/Explain-World-Discovery-Modern-Science/dp/0062346660">To Explain the World: The Discovery of Modern Science</a> by Steven Weinberg (2016)</p>



<p><a href="https://www.amazon.com/Knowledge-Machine-Irrationality-Created-Science/dp/1631491377/">The Knowledge Machine: How Irrationality Created Modern Science</a> by Michael Strevens (2020).</p>



<p>Both books cover (in different proportions) the history and philosophy of science. By the end of this post, I will also discuss my thoughts. <em>Trigger warning:</em> I will end up comparing science to the blockchain and finding positive aspects of the dreaded “reviewer 2”.</p>



<p>Both books attempt to answer the question of <strong>“why and how did the scientific revolution happen?”</strong>. Strevens describes this conundrum as follows:</p>



<p><em>“[If you were a citizen of ancient Greece], you could enjoy just about every cultural invention that makes life worth living today. You could delight in the poetry of Homer and Sappho, visit the theater to relish Oedipus Rex and other masterpieces of ancient drama… You could live in cities regulated by law and a system of courts shaped by the architects and sculptors who built some of the seven wonders of the world and governed in accordance with political models that have lasted to this day: monarchy, oligarchy, sweet democracy.”</em></p>



<p>The point Strevens makes is that while obviously, a lot has changed in culture and society since 300 BC, the change has not been so drastic as to make life unrecognizably different. In contrast, science and technology have undergone drastic changes in the same period, with most changes occurring in the last few centuries. Weinberg quotes the historian Herbert Butterfield, who claimed that the scientific revolution <em>“outshines everything since the rise of Christianity and reduces the Renaissance and Reformation to the rank of mere episodes.”</em></p>



<p>If you are the type of person who prefers data to quotes from historians, there is no shortage of graphs demonstrating this point, including the following:</p>



<figure class="wp-block-image"><img alt="" src="https://lh3.googleusercontent.com/DMx0_KjPGixzzYdBleMYRX2Xx_sf0ubgbU04kyluA_vMugVbJhnRnI_I8lY7u8h2qYfHVxjnKltPKG8V94LrNYMGAeUPvV8I-h8JPFL00rC8FCReH0E-aavJsV7gnxpwXSRv43RH0tRF_ES8uA"/></figure>



<p>(The right graph is adapted from Terry Tao’s excellent <a href="https://terrytao.wordpress.com/2010/10/10/the-cosmic-distance-ladder-ver-4-1/">cosmic distance ladder</a> presentation; I was happy to hear Tao is planning to turn it into a <a href="https://terrytao.wordpress.com/2020/10/10/climbing-the-cosmic-distance-ladder-book-announcement/">popular science book</a>.)</p>



<p>One distinguishing property of science (compared to activities such as religion, philosophy, art, political thought, sports etc.) is that it simultaneously satisfies the following three properties:</p>



<ul><li><strong>Consensus:</strong> While scientists don’t agree about everything, they generally agree on much, and the scientific literature does seem to converge toward consensus in the long run. Perhaps most importantly, even when scientists disagree on interpreting facts, they agree on what these facts are and agree on the forum where these should be discussed. In contrast, there is much less consensus in other spheres of human activities. Often, there isn’t even a consensus on what forum to hold the debate or even if to hold it at all. As far as I know, there isn’t a <em>Science</em> or <em>Nature</em> journal of theology where clergypersons of all faiths debate with one another. Indeed, with the polarized media these days, there are fewer and fewer forums where Democrats and Republicans debate with one another.<br/></li><li><strong>Change:</strong> The consensus is not just frozen in time but instead evolves. Scientists today generally agree with one another, but their views have radically changed over time. While, as Strevens notes, in art and religion, millennia-old texts are still very much relevant, in Machine Learning, when I recommend my students “read the classics,” I mean papers written before 2018 <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/><br/></li><li><strong>Correlation with reality:</strong> Science does not merely change but also <em>progresses</em>, in the sense that with time we gain a better understanding of nature. While some radical subjectivists might dispute that external reality exists or that science gets to know more of it, most people who have ever flown in a plane, were administered a vaccine, or read a blog post over the Internet, will agree that science did advance. Science’s path may be a random walk, but that walk is biased towards progress.</li></ul>



<p>Science did not always possess the above properties, and the distinction between science and philosophy was much murkier in the past. Both Strevens and Weinberg trace the birth of modern science to the Scientific Revolution of the 16th and 17th centuries. Both books describe the history of science and attempt to answer what changed since ancient times and why.</p>



<p><strong>Strevens: Modern Science as a result of Newton and the “Iron Rule”:</strong></p>



<p>Strevens begins by explaining the philosophies of Karl Popper and Thomas Kuhn. I found this part very informative since I have never read a proper philosophy of science book.  (He also describes their fascinating personal histories.)</p>



<p>For Popper, progress in science happens via <em>refutations</em>. At a given point in time, there is a collection of hypotheses H₁,…,Hₖ that are currently consistent with known experiments. Then an experiment happens which refutes some of these, narrowing down the set of potentially feasible theories.</p>



<p>According to Strevens, Popper is an absolutist. Once a theory has been falsified, it’s dead, and all theories that have not been yet falsified will <em>“forever remain … conjectures”</em>. That is, Popper was not a Bayesian and did not assign any likelihood to theories based on how many true predictions they made. The only question was whether they still survive or have been refuted.</p>



<p>Popper is said to have been inspired by Einstein, who was willing to put his theory to the test and said, <em>“if the redshift of spectral lines due to the gravitational potential should not exist, then [my] general theory of relativity will be untenable.” </em> Indeed, a classical story of testing a theory via refutation is <a href="https://en.wikipedia.org/wiki/Eddington_experiment">Eddington’s expedition</a> to check Einstein’s predictions during the 1919 total solar eclipse. Specifically, due to the curvature of space, the effect of the sun’s gravity on the light shining from stars would be double the effect predicted by Newton’s theory. </p>



<p>A priori, the Eddington expedition seems like a textbook Popperian refutation: an experiment is set out to test conflicting predictions of two theories, after which only one of them will survive. However, as Strevens points out, the truth is murkier. The expedition took three measurements: one on the island of Principe, off the coast of West Africa, and two in Brazil. The weather in Principe was cloudy, and the resulting photos were blurry. In Brazil weather was good, but the measurements were taken using two different telescopes that gave conflicting results. Concretely, one of the Brazil telescopes’ measurements conformed with Einstein’s predictions, while the other conformed with the Newtonian theory. Eddington argued that the second Brazil telescope had a systematic error, and hence Einstein’s theory was confirmed. This was accepted by the Royal Society and made big headlines at the time. While Eddington probably <a href="https://www.nature.com/articles/d41586-019-01172-z">made the best conclusion given the data</a>, Strevens claims that he also had extra-scientific motivations to endorse Einstein’s theory: a desire to unite British and German science after WW-I. Einstein’s response to the experiment was also famously non-Popperian: When asked what he would have done if the investigation had the opposing results, he said, <em>“Then I would feel sorry for the dear Lord. The theory is correct anyway.”</em></p>



<p>Thomas Kuhn famously saw scientific progress as not so much a process of incremental refutation as periodic revolutions and paradigm shifts. A paradigm consists not just of mere factual predictions but also ways of thinking and determining truth. As such, paradigms are internally self-consistent, and one cannot “refute” them as much as step away from them, when they outlive their usefulness and cannot handle “anomalies”. Geo-centrism is a good example. While Strevens doesn’t say this, it is impossible to refute a geocentric point of the world (we can always say that the sun rotates around the earth but just does it in a very complex path). And of course, as Earth-based scientists, making it the center of the universe is a very natural prior assumption. Therefore, Helio-centrism did not arise from refuting geo-centrism but through switching to a different paradigm. </p>



<p>For Popper, scientific theories die in a duel with one another. For Kuhn, they die of old age. As scientists struggle ever more to get useful results out of their current paradigm (maybe fine-tuning it more and more to fit the data), they get the sinking feeling that it’s a dead end, and are ready to accept a new paradigm.  While some of Kuhn’s radical followers believed there is no such thing as scientific progress and all paradigms are equally valid, Strevens says that (at least later in life)  Kuhn did not agree with this view. Thus, for Kuhn, while switching paradigms is not as much a rational deliberation as a “leap of faith,” it typically results in improved understanding and predictive power. </p>



<p>If the Popperian scientist is a refutation machine, according to Kuhn, the vast majority of scientists are confirmation machines. They cannot see beyond the current paradigm, but rather because of their belief in it, they continue to push it forward, accumulating more and more data until its natural demise. Popper thought of scientists as always keeping an open mind and never believing in anything not proven. Kuhn thought that blind faith (and the pleasure of “puzzle-solving”) keeps scientists going in what 99% of the time is a slog to do more experiments and produce more data.</p>



<p>Strevens has his own view on the philosophy of science. In particular, he pinpoints the beginning of the Scientific Revolution to a single person – Isaac Newton. To Strevens, Newton’s theory was so different from what came before because it gives precise predictions without claiming to explain the deeper reasons. Newton gave the equation for gravity without explaining why objects can act on each other at a distance. In his postscript to the Principia, Newton said,</p>



<p> <em>“I have not as yet been able to deduce from phenomena the reasons for these properties of gravity, and I do not feign hypotheses. For whatever is not deduced from the phenomena … [has] no place in experimental philosophy. … It is enough that gravity really exists and acts according to the laws that we have set forth and is sufficient to explain all the motions of the heavenly bodies and of our sea.” </em></p>



<p>In other words, Strevens sees Newton as saying, “shut up and calculate,” and indeed believes that Newton would have had no trouble with quantum mechanics’ famous “measurement problem.”  </p>



<p>Strevens sees this as key to modern science: giving up on deeper explanation and focusing only on empirical predictions. He admits scientists take other considerations, including the beauty of theories, into account in their motivations. But he claims that the “rules of engagement” are that all scientific disputes should be settled based on empirical evidence alone and within the domain of the formal scientific literature. He calls this the “Iron Rule of Explanations.” Strevens also sees Newton as science personified, in the sense in which Newton was an archetype of the modern scientific professionalism, formalism, and compartmentalization of thought. While Newton was very interested in both alchemy and biblical studies, unlike prior philosophers, he completely separated those interests from his work on physics. In that, Strevens says, Newton anticipated the modern universities, with its focus on specialization. </p>



<p>“Breaking down silos” is a common slogan these days, but Strevens argues that specialization and compartmentalization were crucial to science’s success. He says that  <em>“whatever is lost through detachment and disregard for the grand view of life is more than recompensed by the narrow, tightly focused beam that searches out the diminutive but telling fact.”</em></p>



<p><strong>Weinberg: Science history through modern eyes</strong></p>



<p>Weinberg’s is a gem of a book. Weinberg does not merely describe the works of ancient scientists, but he redoes their calculations, explaining what they got right, what they got wrong, and whether or not they could have done better with the data available. The book contains 35 technical notes, including everything from reworking Aristarchus’ derivations of the sizes and distances of the sun and the moon, through Descartes’ derivation of the law of refraction, to Newton’s calculations showing that the moon’s motion can be explained by the same gravitational force we see here on earth.</p>



<p>Weinberg places the beginning of the scientific revolution with Copernicus. While the choice of starting point might seem immaterial, this betrays a nearly opposite philosophical stance to Strevens’. While Strevens sees the reduction of science’s goal to empirical predictions as key, Copernicus’ heliocentric theory was actually a <em>step back</em> in terms of predictive power. The theory fitted the data worse than the prior geocentric theory of Ptolemy. Ptolemy introduced <em>epicycles</em> to adjust Aristotle’s clean but wrong geocentric theory to fit the data better. Today we know that epicycles correspond to the Fourier decomposition, and hence with enough of them, one can fit any periodic function. So, Ptolemy’s theory was the quintessential “shut up and calculate” theory: a good fit with observed data, but ugly and with several “fine-tuned” aspects that didn’t have any explanations. This has troubled astronomers for ages. The following words of the 12th-century Muslim scholar Ibn Rushd about Ptolemy’s theory could have been written about quantum mechanics today: <em>“The astronomical science of our days surely offers nothing from which one can derive an existing reality. The model that has been developed in the time in which we live accords with the computations, not with existence.” </em>[A side note is that quantum mechanics is very different from Ptolemy’s theory in the sense that while it does not offer a satisfactory story about reality, it is not “fine-tuned” and has its own sense of beauty, even if seeing this beauty is an “acquired taste”.]</p>



<p>Thus Copernicus’ contribution was not to find a more predictive theory, but rather a more beautiful one. As Weinberg says, this theory <em>“provides a classic example of how a theory can be selected on aesthetic criteria, with no experimental evidence that factors it over other theories… [this is] a recurrent theme in the history of physical science: a simple and beautiful theory that agrees pretty well with observation is often closer to the truth than a complicated ugly theory that agrees better with observation.”</em> [This might be a point to make a side note: while Popper, Kuhn, and (to some extent) Strevens often consider experiments as having discrete or logical outcomes – either true or false – for Weinberg quantities are always continuous or approximate, and every experiment always has a measure of uncertainty.]</p>



<p>Not surprisingly, while Strevens calls Francis Bacon’s extreme-empiricist book “one of the most significant books ever written on scientific inquiry”, Weinberg says that Bacon is one of the individuals “whose importance in the scientific revolution is most overrated” and that “it is not clear to me that anyone’s scientific work was actually changed for the better by Bacon’s writing.”</p>



<p>That is, as far as Weinberg is concerned, the novel parts of Bacon’s writing– the extreme empiricism– are false, and the true parts— plain-old experimentalism— are not novel and were known to scientists before Bacon’s time.</p>



<p>However, both Strevens and Weinberg agree on the significance of Newton. Newton’s innovation was not showing that gravity induces a uniform acceleration on objects. As Weinberg describes, already in 1603 Galileo did experiments showing that an object in free fall undergoes uniform acceleration, and showed that the distance it undergoes under gravity is proportional to the square of the time. Newton’s crucial insight was that the same relation is enough to explain the motion of the moon around the earth. He then saw that the ratio between the gravitational acceleration on earth and the one applied on the moon corresponds to the square of the distance between the two objects, and so (through Kepler’s law and his own invention of calculus) used this relation to explain the motion of all planets around the sun. </p>



<p>This was an astounding achievement. Not because Newton dared use a calculation without understanding the underlying mechanism: that was already done thousands of years before by Ptolemy and many others. Rather the impressive feat was that Newton formulated a simple law that works equally well on falling apples here on earth as well as moving stars in space. By doing this, Newton gave us the reason to hope that there are simple mathematical laws that govern all objects in the universe, and truly initiated modern science.</p>



<p><strong>Concluding thoughts</strong></p>



<p>I enjoyed reading both books and highly recommend them.  Personally, I am more inclined toward Weinberg’s view than Strevens’. I think the history of science is fascinating and can teach us a lot about science even today. The philosophy of science, whether Bacon’s, Popper’s, Kuhn’s, or Strevens’, is nice to know but is of second-order importance. That said, I think Strevens does make an essential point that the scientific “rules of engagement” may well have been key to maintaining the balance between progress and consensus that made science so successful. In particular, he believes that much of science’s success can be explained by its emphasis on formal publications, with their insistence on a “sterile language” and spelling out all details of experiments or calculations, maintained through the peer review process and generations of “reviewers 2”. This might be something to keep in mind in our era, where social media, including blogs, Twitter, and company websites, sometimes replace formal venues as the main medium for conveying scientific results. </p>



<p>My own view is that truth in science is not settled as much by debates as by momentum.  Whether the scientific consensus is X is not determined by some committee of experts, but rather by scientists, and especially students, “voting with their feet”. It is not so much a result of a debate between two distinguished scientists, but a result of a new generation of students abandoning what they think of as dead ends. (This is also known as <a href="https://en.wikipedia.org/wiki/Planck%27s_principle">Planck’s Principle</a>, sometimes grimly expressed as “science progresses one funeral at a time”.) For example,  in Computer Science, scores of papers and Ph.D. dissertations would be rendered meaningless if P=NP. This is stronger proof that the consensus is P≠NP than any poll of Turing laureates. </p>



<p>In that sense, science reminds me of the <em>blockchain</em> of bitcoin and other cryptocurrencies. The blockchain is a history of transactions of the form “User A paid X amount to user B”. User B will only be able to use this amount if there is <em>consensus</em> on this history. The blockchain is decentralized, and so several “forks” of it can exist simultaneously, but if users work on a “dead-end fork” that will not end up as part of the consensus history then their work will be for nothing. This motivates users to ensure that they are on the “right side of history” and only work on extensions of the chains that they believe will be part of the future consensus. This also means that we have more assurance of the veracity of an entry in the blockchain the further back it is, since there has been more work done that is built on this entry.</p>



<p>Similarly, scientists can be said to mine natural and artificial reality for scientific credit (not credit in the crass CV-padding or citation-counting way, but in terms of impact on the long-term direction of the field). But they will not get any such credit if their assumptions are eventually invalidated. Hence scientists are incentivized to ensure that they are always on the “right side of history”. They don’t want to work on a “dead-end fork” that will never get “merged” into the future main scientific discourse. <strong>A corollary is that if the truth of a particular proposition P is irrelevant to the way people do science then science will never need to form a consensus on whether P  is true or false. </strong>For example, as long as the choice of interpretation of quantum mechanics remains irrelevant to actual papers, debates between the Many-Worlds, Bohm and other interpretations will continue to take place in “cheap talk” outside the formal literature (whether over beer, in blog comments, or the popular press) and science will not need to form a consensus on which interpretation is correct. In particular, I don’t think science will ever need to form a consensus on whether any view of the philosophy of science, including my own, is the true one.</p>



<p><strong>Acknowledgments:</strong> Thanks to Scott Aaronson for recommending Weinberg’s book to me and Ludwig Schmidt for recommending Strevens’ book. Thanks also to Scott, Ludwig, and Preetum Nakkiran for useful comments on an earlier draft of this post.</p></div>
    </content>
    <updated>2022-05-03T13:20:22Z</updated>
    <published>2022-05-03T13:20:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2022-05-04T12:37:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.00658</id>
    <link href="http://arxiv.org/abs/2205.00658" rel="alternate" type="text/html"/>
    <title>Sparse Fourier Transform over Lattices: A Unified Approach to Signal Reconstruction</title>
    <feedworld_mtime>1651536000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Zhao Song, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Baocheng.html">Baocheng Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weinstein:Omri.html">Omri Weinstein</a>, Ruizhe Zhang <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.00658">PDF</a><br/><b>Abstract: </b>We revisit the classical problem of band-limited signal reconstruction -- a
variant of the *Set Query* problem -- which asks to efficiently reconstruct (a
subset of) a $d$-dimensional Fourier-sparse signal ($\|\hat{x}(t)\|_0 \leq k$),
from minimum noisy samples of $x(t)$ in the time domain. We present a unified
framework for this problem, by developing a theory of sparse Fourier transforms
over *lattices*, which can be viewed as a "semi-continuous" version of SFT,
in-between discrete and continuous domains. Using this framework, we obtain the
following results:
</p>
<p>$\bullet$ *High-dimensional Fourier sparse recovery* We present a
sample-optimal discrete Fourier Set-Query algorithm with $O(k^{\omega+1})$
reconstruction time in one dimension, independent of the signal's length ($n$)
and $\ell_\infty$-norm ($R^* \approx \|\hat{x}\|_\infty$). This complements the
state-of-art algorithm of [Kap17], whose reconstruction time is $\tilde{O}(k
\log^2 n \log R^*)$, and is limited to low-dimensions. By contrast, our
algorithm works for arbitrary $d$ dimensions, mitigating the $\exp(d)$ blowup
in decoding time to merely linear in $d$.
</p>
<p>$\bullet$ *High-accuracy Fourier interpolation* We design a polynomial-time
$(1+ \sqrt{2} +\epsilon)$-approximation algorithm for continuous Fourier
interpolation. This bypasses a barrier of all previous algorithms [PS15,
CKPS16] which only achieve $&gt;100$ approximation for this problem. Our algorithm
relies on several new ideas of independent interest in signal estimation,
including high-sensitivity frequency estimation and new error analysis with
sharper noise control.
</p>
<p>$\bullet$ *Fourier-sparse interpolation with optimal output sparsity* We give
a $k$-Fourier-sparse interpolation algorithm with optimal output signal
sparsity, improving on the approximation ratio, sample complexity and runtime
of prior works [CKPS16, CP19].
</p></div>
    </summary>
    <updated>2022-05-03T22:48:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.00644</id>
    <link href="http://arxiv.org/abs/2205.00644" rel="alternate" type="text/html"/>
    <title>Eigenstripping, Spectral Decay, and Edge-Expansion on Posets</title>
    <feedworld_mtime>1651536000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gaitonde:Jason.html">Jason Gaitonde</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hopkins:Max.html">Max Hopkins</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaufman:Tali.html">Tali Kaufman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lovett:Shachar.html">Shachar Lovett</a>, Ruizhe Zhang <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.00644">PDF</a><br/><b>Abstract: </b>Fast mixing of random walks on hypergraphs has led to myriad breakthroughs in
theoretical computer science in the last five years. On the other hand, many
important applications (e.g. to locally testable codes, 2-2 games) rely on a
more general class of underlying structures called posets, and crucially take
advantage of non-simplicial structure. These works make it clear the global
expansion properties of posets depend strongly on their underlying architecture
(e.g. simplicial, cubical, linear algebraic), but the overall phenomenon
remains poorly understood. In this work, we quantify the advantage of different
poset architectures in both a spectral and combinatorial sense, highlighting
how regularity controls the spectral decay and edge-expansion of corresponding
random walks.
</p>
<p>We show that the spectra of walks on expanding posets (Dikstein, Dinur,
Filmus, Harsha APPROX-RANDOM 2018) concentrate in strips around a small number
of approximate eigenvalues controlled by the regularity of the underlying
poset. This gives a simple condition to identify poset architectures (e.g. the
Grassmann) that exhibit exponential decay of eigenvalues, versus architectures
like hypergraphs whose eigenvalues decay linearly -- a crucial distinction in
applications to hardness of approximation such as the recent proof of the 2-2
Games Conjecture (Khot, Minzer, Safra FOCS 2018). We show these results lead to
a tight characterization of edge-expansion on posets in the $\ell_2$-regime
(generalizing recent work of Bafna, Hopkins, Kaufman, and Lovett (SODA 2022)),
and pay special attention to the case of the Grassmann where we show our
results are tight for a natural set of sparsifications of the Grassmann graphs.
We note for clarity that our results do not recover the characterization of
expansion used in the proof of the 2-2 Games Conjecture which relies on
$\ell_\infty$ rather than $\ell_2$-structure.
</p></div>
    </summary>
    <updated>2022-05-03T22:43:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-05-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.00611</id>
    <link href="http://arxiv.org/abs/2205.00611" rel="alternate" type="text/html"/>
    <title>Improved Low-Depth Set-Multilinear Circuit Lower Bounds</title>
    <feedworld_mtime>1651536000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kush:Deepanshu.html">Deepanshu Kush</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saraf:Shubhangi.html">Shubhangi Saraf</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.00611">PDF</a><br/><b>Abstract: </b>We prove strengthened lower bounds for constant-depth set-multilinear
formulas. More precisely, we show that over any field, there is an explicit
polynomial $f$ in VNP defined over $n^2$ variables, and of degree $n$, such
that any product-depth $\Delta$ set-multilinear formula computing $f$ has size
at least $n^{\Omega \left( n^{1/\Delta}/\Delta\right)}$. The hard polynomial
$f$ comes from the class of Nisan-Wigderson (NW) design-based polynomials.
</p>
<p>Our lower bounds improve upon the recent work of Limaye, Srinivasan and
Tavenas (STOC 2022), where a lower bound of the form $(\log n)^{\Omega (\Delta
n^{1/\Delta})}$ was shown for the size of product-depth $\Delta$
set-multilinear formulas computing the iterated matrix multiplication (IMM)
polynomial of the same degree and over the same number of variables as $f$.
Moreover, our lower bounds are novel for any $\Delta\geq 2$.
</p>
<p>For general set-multilinear formulas, a lower bound of the form $
n^{\Omega(\log n)}$ was already obtained by Raz (J. ACM 2009) for the more
general model of multilinear formulas. The techniques of LST give a different
route to set-multilinear formula lower bounds, and allow them to obtain a lower
bound of the form $(\log n)^{\Omega(\log n)}$ for the size of general
set-multilinear formulas computing the IMM polynomial. Our proof techniques are
another variation on those of LST, and enable us to show an improved lower
bound (matching that of Raz) of the form $n^{\Omega(\log n)}$, albeit for the
same polynomial $f$ in VNP (the NW polynomial). As observed by LST, if the same
$n^{\Omega(\log n)}$ size lower bounds for unbounded-depth set-multilinear
formulas could be obtained for the IMM polynomial, then using the
self-reducibility of IMM and using hardness escalation results, this would
imply super-polynomial lower bounds for general algebraic formulas.
</p></div>
    </summary>
    <updated>2022-05-03T22:38:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-05-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.00539</id>
    <link href="http://arxiv.org/abs/2205.00539" rel="alternate" type="text/html"/>
    <title>Enumeration Classes Defined by Circuits</title>
    <feedworld_mtime>1651536000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Creignou:Nadia.html">Nadia Creignou</a>, Arnaud Durand, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vollmer:Heribert.html">Heribert Vollmer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.00539">PDF</a><br/><b>Abstract: </b>We refine the complexity landscape for enumeration problems by introducing
very low classes defined by using Boolean circuits as enumerators. We locate
well-known enumeration problems, e.g., from graph theory, Gray code
enumeration, and propositional satisfiability in our classes. In this way we
obtain a framework to distinguish between the complexity of different problems
known to be in $\mathbf{DelayP}$, for which a formal way of comparison was not
possible to this day.
</p></div>
    </summary>
    <updated>2022-05-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.00518</id>
    <link href="http://arxiv.org/abs/2205.00518" rel="alternate" type="text/html"/>
    <title>Scheduling for Multi-Phase Parallelizable Jobs</title>
    <feedworld_mtime>1651536000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vaze:Rahul.html">Rahul Vaze</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.00518">PDF</a><br/><b>Abstract: </b>With multiple identical unit speed servers, the online problem of scheduling
jobs that migrate between two phases, limitedly parallelizable or completely
sequential, and choosing their respective speeds to minimize the total flow
time is considered. In the limited parallelizable regime, allocating $k$
servers to a job, the speed extracted is $k^{1/\alpha}, \alpha&gt;1$, a
sub-linear, concave speedup function, while in the sequential phase, a job can
be processed by at most one server with a maximum speed of unity. A LCFS based
algorithm is proposed for scheduling jobs which always assigns equal speed to
the jobs that are in the same phase (limitedly parallelizable/sequential), and
is shown to have a constant (dependent only on $\alpha &gt; 1$) competitive ratio.
For the special case when all jobs are available beforehand, improved
competitive ratio is obtained.
</p></div>
    </summary>
    <updated>2022-05-03T22:49:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.00474</id>
    <link href="http://arxiv.org/abs/2205.00474" rel="alternate" type="text/html"/>
    <title>Voting in Two-Crossing Elections</title>
    <feedworld_mtime>1651536000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Constantinescu:Andrei.html">Andrei Constantinescu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wattenhofer:Roger.html">Roger Wattenhofer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.00474">PDF</a><br/><b>Abstract: </b>We introduce two-crossing elections as a generalization of single-crossing
elections, showing a number of new results. First, we show that two-crossing
elections can be recognized in polynomial time, by reduction to the
well-studied consecutive ones problem. We also conjecture that recognizing
$k$-crossing elections is NP-complete in general, providing evidence by
relating to a problem similar to consecutive ones proven to be hard in the
literature. Single-crossing elections exhibit a transitive majority relation,
from which many important results follow. On the other hand, we show that the
classical Debord-McGarvey theorem can still be proven two-crossing, implying
that any weighted majority tournament is inducible by a two-crossing election.
This shows that many voting rules are NP-hard under two-crossing elections,
including Kemeny and Slater. This is in contrast to the single-crossing case
and outlines an important complexity boundary between single- and two-crossing.
Subsequently, we show that for two-crossing elections the Young scores of all
candidates can be computed in polynomial time, by formulating a totally
unimodular linear program. Finally, we consider the Chamberlin-Courant rule
with arbitrary disutilities and show that a winning committee can be computed
in polynomial time, using an approach based on dynamic programming.
</p></div>
    </summary>
    <updated>2022-05-03T22:49:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.00442</id>
    <link href="http://arxiv.org/abs/2205.00442" rel="alternate" type="text/html"/>
    <title>On Binary Networked Public Goods Game with Altruism</title>
    <feedworld_mtime>1651536000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maiti:Arnab.html">Arnab Maiti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dey:Palash.html">Palash Dey</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.00442">PDF</a><br/><b>Abstract: </b>In the classical Binary Networked Public Goods (BNPG) game, a player can
either invest in a public project or decide not to invest. Based on the
decisions of all the players, each player receives a reward as per his/her
utility function. However, classical models of BNPG game do not consider
altruism, which players often exhibit and can significantly affect equilibrium
behavior. Yu et al. [24] extended the classical BNPG game to capture the
altruistic aspect of the players. We, in this paper, first study the problem of
deciding the existence of a Pure Strategy Nash Equilibrium (PSNE) in a BNPG
game with altruism. This problem is already known to be NP-complete. We
complement this hardness result by showing that the problem admits efficient
algorithms when the input network is either a tree or a complete graph. We
further study the Altruistic Network Modification problem, where the task is to
compute if a target strategy profile can be made a PSNE by adding or deleting a
few edges. This problem is also known to be NP-complete. We strengthen this
hardness result by exhibiting intractability results even for trees. A perhaps
surprising finding of our work is that the above problem remains NP-hard even
for bounded degree graphs when the altruism network is undirected, but becomes
polynomial-time solvable when the altruism network is directed. We also show
some results on computing an MSNE and some parameterized complexity results. In
summary, our results show that it is much easier to predict how the players in
a BNPG game will behave compared to how the players in a BNPG game can be made
to behave in a desirable way.
</p></div>
    </summary>
    <updated>2022-05-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.00441</id>
    <link href="http://arxiv.org/abs/2205.00441" rel="alternate" type="text/html"/>
    <title>Dynamic data structures for parameterized string problems</title>
    <feedworld_mtime>1651536000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jędrzej Olkowski, Michał Pilipczuk, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rychlicki:Mateusz.html">Mateusz Rychlicki</a>, Karol Węgrzycki, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zych=Pawlewicz:Anna.html">Anna Zych-Pawlewicz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.00441">PDF</a><br/><b>Abstract: </b>We revisit classic string problems considered in the area of parameterized
complexity, and study them through the lens of dynamic data structures. That
is, instead of asking for a static algorithm that solves the given instance
efficiently, our goal is to design a data structure that efficiently maintains
a solution, or reports a lack thereof, upon updates in the instance.
</p>
<p>We first consider the Closest String problem, for which we design randomized
dynamic data structures with amortized update times $d^{\mathcal{O}(d)}$ and
$|\Sigma|^{\mathcal{O}(d)}$, respectively, where $\Sigma$ is the alphabet and
$d$ is the assumed bound on the maximum distance. These are obtained by
combining known static approaches to Closest String with color-coding.
</p>
<p>Next, we note that from a result of Frandsen et al.~[J. ACM'97] one can
easily infer a meta-theorem that provides dynamic data structures for
parameterized string problems with worst-case update time of the form
$\mathcal{O}(\log \log n)$, where $k$ is the parameter in question and $n$ is
the length of the string. We showcase the utility of this meta-theorem by
giving such data structures for problems Disjoint Factors and Edit Distance. We
also give explicit data structures for these problems, with worst-case update
times $\mathcal{O}(k2^{k}\log \log n)$ and $\mathcal{O}(k^2\log \log n)$,
respectively. Finally, we discuss how a lower bound methodology introduced by
Amarilli et al.~[ICALP'21] can be used to show that obtaining update time
$\mathcal{O}(f(k))$ for Disjoint Factors and Edit Distance is unlikely already
for a constant value of the parameter $k$.
</p></div>
    </summary>
    <updated>2022-05-03T23:02:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.00371</id>
    <link href="http://arxiv.org/abs/2205.00371" rel="alternate" type="text/html"/>
    <title>The Johnson-Lindenstrauss Lemma for Clustering and Subspace Approximation: From Coresets to Dimension Reduction</title>
    <feedworld_mtime>1651536000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Charikar:Moses.html">Moses Charikar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Waingarten:Erik.html">Erik Waingarten</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.00371">PDF</a><br/><b>Abstract: </b>We study the effect of Johnson-Lindenstrauss transforms in various Euclidean
optimization problems. We ask, for a particular problem and an accuracy
parameter $\epsilon \in (0, 1)$, what is the smallest target dimension $t \in
\mathbb{N}$ such that a Johnson-Lindenstrauss transform $\Pi \colon
\mathbb{R}^d \to \mathbb{R}^t$ preserves the cost of the optimal solution up to
a $(1+\epsilon)$-factor.
</p>
<p>$\bullet$ For center-based $(k,z)$-clustering, we show $t = O( (\log k + z
\log(1/\epsilon)) / \epsilon^2)$ suffices, improving on $O(z^4
\log(k/\epsilon)/\epsilon^2)$ [MMR19].
</p>
<p>$\bullet$ For $(k,z)$-subspace approximation, we show $t = \tilde{O}(zk^2 /
\epsilon^3)$ suffices. The prior best bound, of $O(k/\epsilon^2)$, only applied
to the case $z = 2$ [CEMMP15].
</p>
<p>$\bullet$ For $(k,z)$-flat approximation, we show $t =
\tilde{O}(zk^2/\epsilon^3)$ suffices, improving on a bound of $\tilde{O}(zk^2
\log n/\epsilon^3)$ [KR15].
</p>
<p>$\bullet$ For $(k,z)$-line approximation, we show $t = O((k \log \log n + z +
\log(1/\epsilon)) / \epsilon^3)$ suffices. No prior results were known.
</p>
<p>All the above results follow from one general technique: we use algorithms
for constructing coresets as an analytical tool in randomized dimensionality
reduction.
</p></div>
    </summary>
    <updated>2022-05-03T23:00:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.00342</id>
    <link href="http://arxiv.org/abs/2205.00342" rel="alternate" type="text/html"/>
    <title>Fast Multivariate Multipoint Evaluation Over All Finite Fields</title>
    <feedworld_mtime>1651536000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhargava:Vishwas.html">Vishwas Bhargava</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghosh:Sumanta.html">Sumanta Ghosh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Zeyu.html">Zeyu Guo</a>, Mrinal Kumar, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Umans:Chris.html">Chris Umans</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.00342">PDF</a><br/><b>Abstract: </b>Multivariate multipoint evaluation is the problem of evaluating a
multivariate polynomial, given as a coefficient vector, simultaneously at
multiple evaluation points. In this work, we show that there exists a
deterministic algorithm for multivariate multipoint evaluation over any finite
field $\mathbb{F}$ that outputs the evaluations of an $m$-variate polynomial of
degree less than $d$ in each variable at $N$ points in time \[
(d^m+N)^{1+o(1)}\cdot\poly(m,d,\log|\mathbb{F}|) \] for all $m\in\N$ and all
sufficiently large $d\in\mathbb{N}$.
</p>
<p>A previous work of Kedlaya and Umans (FOCS 2008, SICOMP 2011) achieved the
same time complexity when the number of variables $m$ is at most $d^{o(1)}$ and
had left the problem of removing this condition as an open problem. A recent
work of Bhargava, Ghosh, Kumar and Mohapatra (STOC 2022) answered this question
when the underlying field is not \emph{too} large and has characteristic less
than $d^{o(1)}$. In this work, we remove this constraint on the number of
variables over all finite fields, thereby answering the question of Kedlaya and
Umans over all finite fields.
</p>
<p>Our algorithm relies on a non-trivial combination of ideas from three
seemingly different previously known algorithms for multivariate multipoint
evaluation, namely the algorithms of Kedlaya and Umans, that of Bj\"orklund,
Kaski and Williams (IPEC 2017, Algorithmica 2019), and that of Bhargava, Ghosh,
Kumar and Mohapatra, together with a result of Bombieri and Vinogradov from
analytic number theory about the distribution of primes in an arithmetic
progression.
</p>
<p>We also present a second algorithm for multivariate multipoint evaluation
that is completely elementary and in particular, avoids the use of the
Bombieri--Vinogradov Theorem. However, it requires a mild assumption that the
field size is bounded by an exponential-tower in $d$ of bounded
\textit{height}.
</p></div>
    </summary>
    <updated>2022-05-03T23:07:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.00277</id>
    <link href="http://arxiv.org/abs/2205.00277" rel="alternate" type="text/html"/>
    <title>Chromatic $k$-Nearest Neighbor Queries</title>
    <feedworld_mtime>1651536000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Horst:Thijs_van_der.html">Thijs van der Horst</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/L=ouml=ffler:Maarten.html">Maarten Löffler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Staals:Frank.html">Frank Staals</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.00277">PDF</a><br/><b>Abstract: </b>Let $P$ be a set of $n$ colored points. We develop efficient data structures
that store $P$ and can answer chromatic $k$-nearest neighbor ($k$-NN) queries.
Such a query consists of a query point $q$ and a number $k$, and asks for the
color that appears most frequently among the $k$ points in $P$ closest to $q$.
Answering such queries efficiently is the key to obtain fast $k$-NN
classifiers. Our main aim is to obtain query times that are independent of $k$
while using near-linear space.
</p>
<p>We show that this is possible using a combination of two data structures. The
first data structure allow us to compute a region containing exactly the
$k$-nearest neighbors of a query point $q$, and the second data structure can
then report the most frequent color in such a region. This leads to linear
space data structures with query times of $O(n^{1 / 2} \log n)$ for points in
$\mathbb{R}^1$, and with query times varying between $O(n^{2/3}\log^{2/3} n)$
and $O(n^{5/6} {\rm polylog} n)$, depending on the distance measure used, for
points in $\mathbb{R}^2$. Since these query times are still fairly large we
also consider approximations. If we are allowed to report a color that appears
at least $(1-\varepsilon)f^*$ times, where $f^*$ is the frequency of the most
frequent color, we obtain a query time of $O(\log n +
\log\log_{\frac{1}{1-\varepsilon}} n)$ in $\mathbb{R}^1$ and expected query
times ranging between $\tilde{O}(n^{1/2}\varepsilon^{-3/2})$ and
$\tilde{O}(n^{1/2}\varepsilon^{-5/2})$ in $\mathbb{R}^2$ using near-linear
space (ignoring polylogarithmic factors).
</p></div>
    </summary>
    <updated>2022-05-03T23:08:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-05-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.00162</id>
    <link href="http://arxiv.org/abs/2205.00162" rel="alternate" type="text/html"/>
    <title>A Faster Algorithm for Betweenness Centrality Based on Adjacency Matrices</title>
    <feedworld_mtime>1651536000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feng:Yelai.html">Yelai Feng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Huaixi.html">Huaixi Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Hongyi.html">Hongyi Lu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.00162">PDF</a><br/><b>Abstract: </b>Betweenness centrality is essential in complex network analysis; it
characterizes the importance of nodes and edges in networks. It is a crucial
problem that exactly computes the betweenness centrality in large networks
faster, which urgently needs to be solved. We propose a novel algorithm for
betweenness centrality based on the parallel computing of adjacency matrices,
which is faster than the existing algorithms for large networks. The time
complexity of the algorithm is only related to the number of nodes in the
network, not the number of edges. Experimental evidence shows that the
algorithm is effective and efficient. This novel algorithm is faster than
Brandes' algorithm on small and dense networks and offers excellent solutions
for betweenness centrality index computing on large-scale complex networks.
</p></div>
    </summary>
    <updated>2022-05-03T22:37:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-05-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.00140</id>
    <link href="http://arxiv.org/abs/2205.00140" rel="alternate" type="text/html"/>
    <title>Improved Approximation to First-Best Gains-from-Trade</title>
    <feedworld_mtime>1651536000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fei:Yumou.html">Yumou Fei</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.00140">PDF</a><br/><b>Abstract: </b>We study the two-agent single-item bilateral trade. Ideally, the trade should
happen whenever the buyer's value for the item exceeds the seller's cost.
However, the classical result of Myerson and Satterthwaite showed that no
mechanism can achieve this without violating one of the Bayesian incentive
compatibility, individual rationality and weakly balanced budget conditions.
This motivates the study of approximating the
trade-whenever-socially-beneficial mechanism, in terms of the expected
gains-from-trade. Recently, Deng, Mao, Sivan, and Wang showed that the
random-offerer mechanism achieves at least a 1/8.23 approximation. We improve
this lower bound to 1/3.15 in this paper. We also determine the exact
worst-case approximation ratio of the seller-pricing mechanism assuming the
distribution of the buyer's value satisfies the monotone hazard rate property.
</p></div>
    </summary>
    <updated>2022-05-03T23:02:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.00127</id>
    <link href="http://arxiv.org/abs/2205.00127" rel="alternate" type="text/html"/>
    <title>Baba is You is Undecidable</title>
    <feedworld_mtime>1651536000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Geller:Jonathan.html">Jonathan Geller</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.00127">PDF</a><br/><b>Abstract: </b>We establish the undecidability of 2019 puzzle game Baba is You through a
reduction from the Post correspondence problem. In particular, we consider a
restricted form of the Post correspondence problem introduced by Neary
(<a href="http://export.arxiv.org/abs/1312.6700">arXiv:1312.6700</a>) that is limited to five pairs of words. Baba is You is an
award winning tile-based game in which the player can reprogram the game's
mechanisms by pushing blocks that spell out the rules. We achieve
undecidability through a generalization of the size of the playfield in the
horizontal direction, adding a "hallway" to one side of the level. The
undecidability of Baba is You has been claimed several times online using
different source problems, including the simulation of Turing machines and
Conway's Game of Life, however, this contribution appears to be the first
formal proof of the result.
</p></div>
    </summary>
    <updated>2022-05-03T22:43:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-05-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.00117</id>
    <link href="http://arxiv.org/abs/2205.00117" rel="alternate" type="text/html"/>
    <title>A Scalable 5,6-Qubit Grover's Quantum Search Algorithm</title>
    <feedworld_mtime>1651536000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vemula:Dinesh_Reddy.html">Dinesh Reddy Vemula</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Konar:Debanjan.html">Debanjan Konar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Satheesan:Sudeep.html">Sudeep Satheesan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kalidasu:Sri_Mounica.html">Sri Mounica Kalidasu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cangi:Attila.html">Attila Cangi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.00117">PDF</a><br/><b>Abstract: </b>Recent studies have been spurred on by the promise of advanced quantum
computing technology, which has led to the development of quantum computer
simulations on classical hardware. Grover's quantum search algorithm is one of
the well-known applications of quantum computing, enabling quantum computers to
perform a database search (unsorted array) and quadratically outperform their
classical counterparts in terms of time. Given the restricted access to
database search for an oracle model (black-box), researchers have demonstrated
various implementations of Grover's circuit for two to four qubits on various
platforms. However, larger search spaces have not yet been explored. In this
paper, a scalable Quantum Grover Search algorithm is introduced and implemented
using 5-qubit and 6-qubit quantum circuits, along with a design pattern for
ease of building an Oracle for a higher order of qubits. For our
implementation, the probability of finding the correct entity is in the high
nineties. The accuracy of the proposed 5-qubit and 6-qubit circuits is
benchmarked against the state-of-the-art implementations for 3-qubit and
4-qubit. Furthermore, the reusability of the proposed quantum circuits using
subroutines is also illustrated by the opportunity for large-scale
implementation of quantum algorithms in the future.
</p></div>
    </summary>
    <updated>2022-05-03T22:48:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.00086</id>
    <link href="http://arxiv.org/abs/2205.00086" rel="alternate" type="text/html"/>
    <title>Enumerating Connected Dominating Sets</title>
    <feedworld_mtime>1651536000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Faisal Abu-Khzam, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fernau:Henning.html">Henning Fernau</a>, Benjamin Gras, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liedloff:Mathieu.html">Mathieu Liedloff</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mann:Kevin.html">Kevin Mann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.00086">PDF</a><br/><b>Abstract: </b>The question to enumerate all inclusion-minimal connected dominating sets in
a graph of order $n$ in time significantly less than $2^n$ is an open question
that was asked in many places. We answer this question affirmatively, by
providing an enumeration algorithm that runs in time $\mathcal{O}(1.9896^n)$,
using polynomial space only. The key to this result is the consideration of
this enumeration problem on 2-degenerate graphs, which is proven to be possible
in time $\mathcal{O}(1.9767^n)$. We also show new lower bound results by
constructing a family of graphs of order $n$ with $\Omega(1.4890^n)$ minimal
connected dominating sets, while previous examples achieved $\Omega(1.4422^n)$.
Our construction results in lower bounds for a few special graph classes.
</p>
<p>We also address essential questions concerning output-sensitive enumeration.
Namely, we give reasons why our algorithm cannot be turned into an enumeration
algorithm that guarantees polynomial delay without much efforts. More
precisely, we prove that it is NP-complete to decide, given a graph $G$ and a
vertex set $U$, if there exists a minimal connected dominating set $D$ with
$U\subseteq D$, even if $G$ is known to be 2-degenerate. Our reduction also
shows that even any subexponential delay is not easy to achieve for enumerating
minimal connected dominating sets. Another reduction shows that no
FPT-algorithms can be expected for this extension problem concerning minimal
connected dominating sets, parameterized by $|U|$. We also relate our
enumeration problem to the famous open Hitting Set Transversal problem, which
can be phrased in our context as the question to enumerate all minimal
dominating sets of a graph with polynomial delay by showing that a
polynomial-delay enumeration algorithm for minimal connected dominating sets
implies an affirmative algorithmic solution to the Hitting Set Transversal
problem.
</p></div>
    </summary>
    <updated>2022-05-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8314</id>
    <link href="https://windowsontheory.org/2022/05/02/brian-conrad-takes-down-the-cmf/" rel="alternate" type="text/html"/>
    <title>Brian Conrad takes down the CMF</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I’ve written before on the California Math Framework, but must admit that I have only read parts of this 900+ page document. Brian Conrad (Professor of Mathematics and Director of Undergraduate Studies at Stanford) has read the entire thing, and chased down many citations, reading the original papers. The results are not pretty. In a … <a class="more-link" href="https://windowsontheory.org/2022/05/02/brian-conrad-takes-down-the-cmf/">Continue reading <span class="screen-reader-text">Brian Conrad takes down the CMF</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’ve <a href="https://windowsontheory.org/category/k12-math/">written before</a> on the California Math Framework, but must admit that I have only read parts of this 900+ page document. <a href="http://math.stanford.edu/~conrad/">Brian Conrad</a> (Professor of Mathematics and Director of Undergraduate Studies at Stanford) has read the entire thing, and chased down many citations, reading the original papers. The results are not pretty. In a great many cases, the cited papers do not come close to justifying the claims that the CMF makes about them; sometimes they even come to the opposite conclusions. See the full analysis on this website: </p>



<p><strong><a href="https://sites.google.com/view/publiccommentsonthecmf/" rel="nofollow">https://sites.google.com/view/publiccommentsonthecmf/</a></strong></p>



<p><strong>Unrelated announcement:</strong> The Simons Institute for Theoretical Computer Science will have a <a href="https://simons.berkeley.edu/workshops/simons-institute-10th-anniversary-symposium">10th-anniversary symposium on May 25-27</a>. The program looks awesome! I plan to be there in person and hope to catch up with many friends and colleagues I haven’t seen for a long time.</p></div>
    </content>
    <updated>2022-05-02T19:37:50Z</updated>
    <published>2022-05-02T19:37:50Z</published>
    <category term="K12-math"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2022-05-04T12:37:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/062</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/062" rel="alternate" type="text/html"/>
    <title>TR22-062 |  Superredundancy: A tool for Boolean formula minimization complexity analysis | 

	Paolo Liberatore</title>
    <summary>A superredundant clause is a clause that is redundant in the resolution closure of a formula. The converse concept of superirredundancy ensures membership of the clause in all minimal CNF formulae that are equivalent to the given one. This allows for building formulae where some clauses are fixed when minimizing size. An example are proofs of complexity hardness of the problems of minimal formula size. Others are proofs of size when forgetting variables or revising a formula. Most clauses can be made superirredundant by splitting them over a new variable.</summary>
    <updated>2022-05-02T10:53:10Z</updated>
    <published>2022-05-02T10:53:10Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-05-04T12:37:17Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2247671755820931798</id>
    <link href="http://blog.computationalcomplexity.org/feeds/2247671755820931798/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/05/elon-musk-to-buy-complexityblog.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/2247671755820931798" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/2247671755820931798" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/05/elon-musk-to-buy-complexityblog.html" rel="alternate" type="text/html"/>
    <title>Elon Musk To Buy Complexityblog</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Elon Musk has offered to buy out Complexityblog. The money is too good to turn down. As part of the contract we can't say how much or in what cryptocurrency, but suffice to say it will be more than the royalties from our books. Or not.</p><p>Readers be aware of the following changes to the blog:</p><p>1) We can no longer send Donald's Trump comments into our spam folder.</p><p>2) All of our posts will be written by Tesla autopilot.</p><p>3) Complete free speech in the comments. Or not. Depends on Elon's mood that day</p><p>4) Purchases made through this blog can be in bitcoin or other cryptocurrencies. Or not. Depends on Elon's mood that day.</p><p>5) Switch the business model (Lance- we have a business model?) from advertisements to a subscription service. How much will people pay per year to access complexity blog? </p><p>6) Lance and I have been invited to fly to orbit on a SpaceX rocket so we can post from space. Or was it posting from the backseat of a Tesla? Depends on how you read the contract.</p><p>7)  April Fools day posts will henceforth be on May 1. </p></div>
    </content>
    <updated>2022-05-02T00:06:00Z</updated>
    <published>2022-05-02T00:06:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-05-03T23:50:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19958</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/04/30/math-monthly/" rel="alternate" type="text/html"/>
    <title>Math Monthly</title>
    <summary>Just because we can’t find a solution, it doesn’t mean there isn’t one—Andrew Wiles. Della Dumbaugh is a professor of mathematics at the University of Richmond. Her research is in the history of algebra and number theory. She says: When Mark Warner was governor of Virginia he asked, “what do historians of mathematics study?” That […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Just because we can’t find a solution, it doesn’t mean there isn’t one—Andrew Wiles.</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p>
Della Dumbaugh is a professor of mathematics at the University of Richmond. Her research is in the history of algebra and number theory. She says:</p>
<blockquote><p><b> </b> <em> When Mark Warner was governor of Virginia he asked, “what do historians of mathematics study?” That is a great question. We study mathematics, the people who create mathematics, the institutions that support mathematics, the false starts in particular areas of mathematics, the politics that influence the development of mathematics, and how the larger cultural context impinges on the development of mathematics. This discipline combines technical questions in mathematics with appropriate historical questions to yield a rich perspective on both mathematics and history. </em>
</p></blockquote>
<p/><p>
I must say that I wish I knew more about the history of math. When trying to add to the collection of theorems that are known to be true, it would definitely have helped to be more aware of their history. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/04/30/math-monthly/dd/" rel="attachment wp-att-19960"><img alt="" class="aligncenter size-full wp-image-19960" height="375" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/04/dd.jpg?resize=250%2C375&amp;ssl=1" width="250"/></a>
</p></td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><i>Hidden Figures</i> article <a href="https://theconversation.com/7-lessons-from-hidden-figures-nasa-mathematician-katherine-johnsons-life-and-career-132481">source</a></font>
</td>
</tr>
</tbody></table>
<p>
Dumbaugh was <a href="https://news.richmond.edu/releases/article/-/19943/ur-mathematics-professor-della-dumbaugh-named-editor-in-chief-of-american-mathematical-monthly.html">named</a> the editor-in-chief of <em>American Mathematical Monthly</em>, starting in January 2022. The <em>Monthly</em> has been published since 1894, and its editors mostly have served five-year terms. She is only the second woman to serve as editor, a figure that seems to be low, way low. Yet she is also the second consecutive female editor. Maybe that is the beginning of a streak.</p>
<p>
</p><p/><h2> Her View of the Monthly </h2><p/>
<p/><p>
Dumbaugh found the <em>Monthly</em> in a novel way: Here is a neat <a href="http://digitaleditions.walsworthprintgroup.com/publication/?i=704334&amp;article_id=4005794&amp;view=articleBrowser&amp;ver=html5">interview</a> with her that explains it. Check out the part on her relationship to the <em>Monthly</em>:</p>
<blockquote><p><b> </b> <em> I may be one of the few members of the mathematical community who did not meet the Monthly through the content on its pages. Instead, I met the journal through my PhD research on Leonard Dickson and his work in the theory of algebras. In particular, Dickson aimed to elevate the standard of American mathematics through quality journal publications and he served as an editor of the <em>Monthly</em> from 1903 to 1906. After I finished my dissertation, I turned my attention to a question about Dickson’s celebrated <b>History of the Theory of Numbers</b> and published that article in the <em>Monthly</em>. </em>
</p></blockquote>
<p>
</p><p/><h2> My View of the Monthly </h2><p/>
<p/><p>
I found the <em>Monthly</em> in a more common way: as a high school student. I loved it from the beginning, have read it for decades, yet have never submitted to it. I still recall using my hard earned money, money from odd jobs, to pay for my subscription to the <em>Monthly</em>.</p>
<p>
I enjoyed the articles, but especially liked two features. The problem <a href="https://www.mat.uniroma2.it/~tauraso/AMM/amm.html">session</a> each issue and the reviews of other articles and books. Since this was decades before the Internet seeing these articles helped me learn about directions and areas of mathematics. </p>
<p>
I still recall seeing the 1962 <a href="https://maa.tandfonline.com/toc/uamm20/70/7?nav=tocList">Putnam</a> exam in the <em>Monthly</em>. It was the first that I ever saw. I later took the exam as an undergraduate and did poorly. Oh well. </p>
<p>
More recently, I was struck by the <a href="https://scholarship.claremont.edu/cgi/viewcontent.cgi?article=1497&amp;context=jhm">article</a>, “Calculating Intersections: The Crossroads of Mathematics and Literature in the Lives of Mother and Daughter” by a mother and daughter: Della Dumbaugh and Hannah Fenster. Read it for interesting comments about the mom and daughter relationship:</p>
<blockquote><p><b> </b> <em> This article tells the stories of how we, Della (mom, mathematician) and Hannah (daughter, writing instructor and bookseller), arrived in our professional settings through the lens of mother and daughter. For us, the intersections of literature and mathematics inspired many of our pivotal moments. </em>
</p></blockquote>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Ken recently <a href="https://rjlipton.wpcomstaging.com/2018/06/08/hilberts-irreducibility-theorem/">had</a> an <a href="https://www.tandfonline.com/doi/abs/10.1080/00029890.2018.1448181">article</a> in the <em>Monthly</em> with Bill Gasarch and also Mark Villarino, who had <a href="https://www.tandfonline.com/doi/full/10.1080/00029890.2017.1416875">another</a> that same year. What I would think of as a good paper for the <em>Monthly</em> has a mixture of history, survey elements, and originality of approach to an entertaining problem, framed to be accessible to a high-school student. What topics might our readers suggest?</p>
<p/></font></font></div>
    </content>
    <updated>2022-05-01T01:29:49Z</updated>
    <published>2022-05-01T01:29:49Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Teaching"/>
    <category term="Della Dumbaugh"/>
    <category term="editor"/>
    <category term="history of mathematics"/>
    <category term="Math Monthly"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-05-04T12:37:21Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/04/30/linkage</id>
    <link href="https://11011110.github.io/blog/2022/04/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Talk videos from the Discrete &amp; Computational Geometry Day in Memory of Eli Goodman and Ricky Pollack (\(\mathbb{M}\)).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://youtube.com/playlist?list=PLl18CMjwy1yZmhwbMW6THPbu8vluKDrEz">Talk videos</a> from the <a href="https://math.nyu.edu/faculty/pollack/seminar/spring22/DCGDay22.html">Discrete &amp; Computational Geometry Day in Memory of Eli Goodman and Ricky Pollack</a> <span style="white-space: nowrap;">(<a href="https://mastodon.social/@sarielhp/108141757413063563">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://boingboing.net/2022/04/17/i-would-love-to-see-examples-of-what-florida-found-unacceptable-in-those-math-textbooks.html">Commenters baffled as Florida schools ban 54 mathematics textbooks for “prohibited topics”</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108148774015958780">\(\mathbb{M}\)</a>).</span> In Florida these days this seems likely to mean any hint of the existence of non-white non-cisgender people, but the quoted press release also mentions <a href="https://en.wikipedia.org/wiki/Social%E2%80%93emotional_learning">social-emotional learning</a>, helping students develop a positive self-image during their studies and making classrooms a safe space for learning, which for some reason the US right wing wants to prevent.</p>
  </li>
  <li>
    <p><a href="https://www.caltech.edu/about/news/american-institute-of-mathematics-moves-to-caltech">American Institute of Mathematics Moves to Caltech</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108154533641166847">\(\mathbb{M}\)</a>,</span> <a href="https://www.math.columbia.edu/~woit/wordpress/?p=12775">via</a>). It was formerly on the site of a Fry’s Electronics store in San Jose, California (its funding came from John Fry) but Fry’s is now defunct, hence the move much farther south. The via link also discusses MathSciNet’s choice of a supporter of Mochizuki to <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=4225476">review Mochizuki’s abc conjecture papers</a> and failure to mention that there is any controversy with the papers. <a href="https://zbmath.org/1465.14002">zbMATH did much better</a>.</p>
  </li>
  <li>
    <p>Who was the last holdout to publish a mathematics paper in Latin <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108160261381422211">\(\mathbb{M}\)</a>)?</span> It appears to be Vadim Schechtman, whose “<a href="https://doi.org/10.1007/0-8176-4478-4_18">Definitio nova algebroidis verticiani</a>” is from 2006.</p>
  </li>
  <li>
    <p>Two more Wikipedia good articles <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108168292013780341">\(\mathbb{M}\)</a>):</span></p>

    <ul>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/M%C3%B6bius_strip">Möbius strip</a>. This was difficult because the readership spans such a wide range: there’s a lot of popular-culture material but also some nontrivial mathematics, on topics like smooth embeddability of surfaces, uniform Riemannian geometries, and group models of Lie algebras.</p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Heilbronn_triangle_problem">Heilbronn triangle problem</a>: if \(n\) points are placed in a square, how small is the smallest triangle we can be guaranteed to find?</p>
      </li>
    </ul>
  </li>
  <li>
    <p><a href="https://www.timeshighereducation.com/opinion/open-access-closed-middle-income-countries">Gold-model open access shuts out researchers from middle-income countries like Brazil who can’t afford publication fees and can’t obtain fee waivers</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108174468963868095">\(\mathbb{M}\)</a>, </span> <a href="https://retractionwatch.com/2022/04/16/weekend-reads-white-academics-book-about-black-feminism-pulled-retraction-notices-as-a-genre-forget-the-scientific-paper/">via</a>). See also <a href="https://www.nature.com/articles/d41586-022-00864-3">original <em>Nature</em> article</a>.
Of course, diamond open access has no such issues…</p>
  </li>
  <li>
    <p>Lots of great geometric visualizations on <a href="https://twitter.com/theAlbertChern">Albert Chern’s twitter feed</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108180116083608611">\(\mathbb{M}\)</a>).</span> Here’s one: Most images of the <a href="https://en.wikipedia.org/wiki/Penrose_triangle">Penrose triangle</a>, an impossible object appearing to be made from three mutually perpendicular square beams, are drawn in an isometric perspective. But did you know that <a href="https://twitter.com/theAlbertChern/status/1392028293596028930">it can be drawn in three-point perspective</a>? (It’s also that way in Penrose’s original “<a href="https://www.iri.upc.edu/people/ros/StructuralTopology/ST17/st17-05-a2-ocr.pdf">cohomology of impossible figures</a>”.)</p>
  </li>
  <li>
    <p>This is your semi-regular reminder that to format LaTeX with automatic internally linked theorems and lemmas, sharing numbers, there is a required order <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108185458546061752">\(\mathbb{M}\)</a>):</span></p>

    <ol>
      <li>
        <p>load amsthm and hyperref</p>
      </li>
      <li>
        <p>load cleveref</p>
      </li>
      <li>
        <p>define theorems and lemmas</p>
      </li>
    </ol>

    <p>If you write LaTeX document classes that try to make things convenient by doing one of these steps out of order, you will frustrate your authors because there is no easy later fixup, and lead them to customize your class file. I’m looking at you, <a href="https://www.ryerson.ca/canadian-conference-computational-geometry-2022/submission/">cccg22.cls</a>.</p>
  </li>
  <li>
    <p><a href="https://minimalsurfaces.blog/2018/12/23/make-your-own-gyroid/">Make your own gyroid</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108191418595804372">\(\mathbb{M}\)</a>).</span> You just need to connect together lots of hexagrams and squares in the right pattern…unfortunately I don’t think any of the snap-together polygon shapes I have are hexagrams.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/elegant-six-page-proof-reveals-the-emergence-of-random-structure-20220425/"><em>Quanta</em> article on the Kahn–Kalai conjecture</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@btcprox/108196065209167912">\(\mathbb{M}\)</a>).</span> This is the principle that, for monotonic properties of random structures (like, say, Hamiltonicity of random graphs), the threshold density for the property to hold with probability \(\tfrac12\) and the threshold density for the expected number of witnesses to be \(\tfrac12\) are within a logarithmic factor of each other. See also <a href="https://arxiv.org/abs/2203.17207">preprint by Jinyoung Park and Huy Tuan Pham</a> with a proof of the conjecture.</p>
  </li>
  <li>
    <p><a href="https://sites.google.com/view/mathindatamatters/home">Data Science and the High School Math Curriculum</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108200062099969634">\(\mathbb{M}\)</a>),</span> an open letter by California academics (including me) asserting that high school algebra is essential for STEM, and data science (albeit valuable) cannot replace it. The context is a push to water down high school math, eliminate advanced tracks, and replace math by math appreciation, in the misguided hope that this will improve diversity and remove inequities. See also reactions at <a href="https://scottaaronson.blog/?p=6389">Scott Aaronson’s blog</a> and <a href="https://news.ycombinator.com/item?id=31170431">Hacker News</a>, and a <a href="https://windowsontheory.org/2022/04/27/a-personal-faq-on-the-math-education-controversies/">more detailed explainer of the context by Boaz Barak</a>.</p>
  </li>
  <li>
    <p>The news of Elon Musk’s impending buyout of Twitter and of his plans to release the trolls and propagandabots from their moderated chains led to a flood of new users on Mastodon. <a href="https://mathstodon.xyz/@11011110/108206072769622175">Here’s my welcome message and self-introduction</a>.</p>
  </li>
  <li>
    <p><a href="https://www.unesco.org/en/articles/girls-performance-mathematics-now-equal-boys-unesco-report">UNESCO reports that a mathematical advantage for boys over girls at very young ages disappears as they get older, and is even reversed in some countries</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@btcprox/108212750902862362">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="http://trademarkblog.kluweriplaw.com/2021/12/06/gomboc-3-the-final-decision/">Mathematics not trademarkable</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108219360525065087">\(\mathbb{M}\)</a>).</span> Somehow I missed this, but late last year the Supreme Court of Hungary ruled on a lawsuit asking to trademark the <a href="https://en.wikipedia.org/wiki/G%C3%B6mb%C3%B6c">Gömböc</a>, a 3D convex shape that, with only a single stable position, rights itself when placed on a flat surface. (Like a Weeble, but unweighted.) The answer was no: as “an answer given to a question of mathematics” with a shape “necessary for the Gömböc to self-right”, it could not be trademarked.</p>
  </li>
  <li>
    <p><a href="https://a3nm.net/blog/adversarial_tetris.html">Computer search proves that you can always complete at least one line in standard-size Tetris</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108222482587123946">\(\mathbb{M}\)</a>,</span> <a href="https://www.metafilter.com/195140/Beastly-AIs-known-to-let-the-piece-mmmdrop">via</a>). This is true even if the piece order is specifically chosen to make it difficult for you rather than randomly, and even if you are only allowed to rotate and drop pieces without slides or spins after they drop.</p>
  </li>
</ul></div>
    </content>
    <updated>2022-04-30T12:07:00Z</updated>
    <published>2022-04-30T12:07:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-04-30T20:00:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/061</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/061" rel="alternate" type="text/html"/>
    <title>TR22-061 |  On Approximability of Satisfiable $k$-CSPs: I | 

	Amey Bhangale, 

	Subhash Khot, 

	Dor Minzer</title>
    <summary>We consider the $P$-CSP problem for $3$-ary predicates $P$ on satisfiable instances. We show that under certain conditions on $P$ and a $(1,s)$ integrality gap instance of the $P$-CSP problem, it can be translated into a dictatorship vs. quasirandomness test with perfect completeness and soundness $s+\varepsilon$, for every constant $\varepsilon&gt;0$. Compared to Ragahvendra's result [STOC, 2008], we do not lose perfect completeness. This is particularly interesting as this test implies new hardness results on satisfiable constraint satisfaction problems, assuming the Rich 2-to-1 Games Conjecture by Braverman, Khot, and Minzer [ITCS, 2021]. Our result can be seen as the first step of a potentially long-term challenging program of characterizing optimal inapproximability of every satisfiable $k$-ary  CSP.
	
	At the heart of the reduction is our main analytical lemma for a class of $3$-ary predicates, which is a generalization of a lemma by  Mossel [Geometric and Functional Analysis, 2010]. The lemma and a further generalization of it that we propose as a hypothesis may be of independent interest.</summary>
    <updated>2022-04-30T10:35:38Z</updated>
    <published>2022-04-30T10:35:38Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-05-04T12:37:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=22570</id>
    <link href="https://gilkalai.wordpress.com/2022/04/29/joshua-hinman-proved-baranys-conjecture-on-face-numbers-of-polytopes-and-lei-xue-proved-a-lower-bound-conjecture-by-grunbaum/" rel="alternate" type="text/html"/>
    <title>Joshua Hinman proved Bárány’s conjecture on face numbers of polytopes, and Lei Xue proved a lower bound conjecture by Grünbaum.</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Joshua Hinman proved Bárány’s conjecture. One of my first posts on this blog was a 2008 post Five Open Problems Regarding Convex Polytopes, now 14 years later, I can tell you about the first problem on the list to get solved. … <a href="https://gilkalai.wordpress.com/2022/04/29/joshua-hinman-proved-baranys-conjecture-on-face-numbers-of-polytopes-and-lei-xue-proved-a-lower-bound-conjecture-by-grunbaum/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h3>Joshua Hinman proved Bárány’s conjecture.</h3>
<p>One of my first posts on this blog was a 2008 post <a href="https://gilkalai.wordpress.com/2008/05/07/five-open-problems-regarding-convex-polytopes/" rel="bookmark">Five Open Problems Regarding Convex Polytopes</a>, now 14 years later, I can tell you about the first problem on the list to get solved.</p>
<p>Imre Bárány posed in the late 1990s the following question:</p>
<p>For a <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>-dimensional polytope <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> and every <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>, <img alt="0 \le k \le d-1" class="latex" src="https://s0.wp.com/latex.php?latex=0+%5Cle+k+%5Cle+d-1&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>,  is it true that <img alt="f_k(P) \ge \min (f_0(P),f_{d-1}(P))" class="latex" src="https://s0.wp.com/latex.php?latex=f_k%28P%29+%5Cge+%5Cmin+%28f_0%28P%29%2Cf_%7Bd-1%7D%28P%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>?</p>
<p>Now, Joshua Hinman settled the problem! In his paper <a href="https://arxiv.org/abs/2204.02568">A Positive Answer to Bárány’s Question on Face Numbers of Polytopes</a> he actually proved even stronger linear relations. The abstract of Joshua’s paper starts with the very true assertion: “Despite a full characterization of the face vectors of simple and simplicial polytopes, the face numbers of general polytopes are poorly understood.” He moved on to describe his new inequalities:</p>
<pre><img alt="\frac{f_k(P)}{f_0(P)} \geq \frac{1}{2}\biggl[{\lceil \frac{d}{2} \rceil \choose k} + {\lfloor \frac{d}{2} \rfloor \choose k}\biggr], \qquad \frac{f_k(P)}{f_{d-1}(P)} \geq \frac{1}{2}\biggl[{\lceil \frac{d}{2} \rceil \choose d-k-1} + {\lfloor \frac{d}{2} \rfloor \choose d-k-1}\biggr]." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7Bf_k%28P%29%7D%7Bf_0%28P%29%7D+%5Cgeq+%5Cfrac%7B1%7D%7B2%7D%5Cbiggl%5B%7B%5Clceil+%5Cfrac%7Bd%7D%7B2%7D+%5Crceil+%5Cchoose+k%7D+%2B+%7B%5Clfloor+%5Cfrac%7Bd%7D%7B2%7D+%5Crfloor+%5Cchoose+k%7D%5Cbiggr%5D%2C+%5Cqquad+%5Cfrac%7Bf_k%28P%29%7D%7Bf_%7Bd-1%7D%28P%29%7D+%5Cgeq+%5Cfrac%7B1%7D%7B2%7D%5Cbiggl%5B%7B%5Clceil+%5Cfrac%7Bd%7D%7B2%7D+%5Crceil+%5Cchoose+d-k-1%7D+%2B+%7B%5Clfloor+%5Cfrac%7Bd%7D%7B2%7D+%5Crfloor+%5Cchoose+d-k-1%7D%5Cbiggr%5D.&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/></pre>
<h3>Lei Xue proved Grünbaum’s conjecture</h3>
<p>In her 2020 paper: <a href="https://arxiv.org/abs/2004.08429">A Proof of Grünbaum’s Lower Bound Conjecture for general polytopes</a>, <a href="http://sites.math.washington.edu/~lxue/">Lei Xue</a> proved a lower bound conjecture of Grünbaum: In 1967, Grünbaum conjectured that any <em><span class="MathJax" id="MathJax-Element-1-Frame"><span class="math" id="MathJax-Span-1"><span class="mrow" id="MathJax-Span-2"><span class="mi" id="MathJax-Span-3">d</span></span></span></span></em>-dimensional polytope with <em><span class="MathJax" id="MathJax-Element-2-Frame"><span class="math" id="MathJax-Span-4"><span class="mrow" id="MathJax-Span-5"><span class="mi" id="MathJax-Span-6">d</span><span class="mo" id="MathJax-Span-7">+</span><span class="mi" id="MathJax-Span-8">s</span><span class="mo" id="MathJax-Span-9">≤</span><span class="mn" id="MathJax-Span-10">2</span><span class="mi" id="MathJax-Span-11">d</span></span></span></span></em> vertices has at least</p>
<pre><img alt="\phi_k(d+s,d) = {d+1 \choose k+1 }+{d \choose k+1 }-{d+1-s \choose k+1 }" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi_k%28d%2Bs%2Cd%29+%3D+%7Bd%2B1+%5Cchoose+k%2B1+%7D%2B%7Bd+%5Cchoose+k%2B1+%7D-%7Bd%2B1-s+%5Cchoose+k%2B1+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/></pre>
<p><em><span class="MathJax" id="MathJax-Element-4-Frame"><span class="math" id="MathJax-Span-86"><span class="mrow" id="MathJax-Span-87"><span class="mi" id="MathJax-Span-88">k</span></span></span></span></em>-faces. Lei Xue proved this conjecture and also characterized the cases in which equality holds.</p>
<p><strong>Congratulations to Lei Xue and to Joshua Hinman.<br/></strong><strong><br/></strong></p>
<p/>
<p> </p>


<p/></div>
    </content>
    <updated>2022-04-29T07:11:24Z</updated>
    <published>2022-04-29T07:11:24Z</published>
    <category term="Combinatorics"/>
    <category term="Convex polytopes"/>
    <category term="Branko Grunbaum"/>
    <category term="Imre B&#xE1;r&#xE1;ny"/>
    <category term="Joshua Hinman"/>
    <category term="Lei Xue"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2022-05-04T12:37:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=619</id>
    <link href="https://tcsplus.wordpress.com/2022/04/28/tcs-talk-wednesday-may-4-vera-traub-eth-zurich/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, May 4 — Vera Traub, ETH Zürich</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, May 4th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Vera Traub from ETH Zürich will speak about “Approximation Algorithms for Connectivity Augmentation Problems” (abstract below). You can reserve a spot as an individual or a group to […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, May 4th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <a href="https://people.math.ethz.ch/~vtraub/"><strong>Vera Traub</strong></a> from ETH Zürich will speak about “<em>Approximation Algorithms for Connectivity Augmentation Problems</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: Augmentation problems are a fundamental class of network design problems. They ask about the cheapest way to increase the (edge-)connectivity of a graph by adding edges among a given set of options. One of the most elementary and intensely studied augmentation problems is the (Weighted) Tree Augmentation Problem. Here, a spanning tree has to be augmented into a 2-edge-connected graph.</p>
<p>Classic techniques for network design yield 2-approximation algorithms for a wide class of augmentation problems. For the Unweighted Tree Augmentation Problem, better-than-2 approximations are known for more than 20 years. However, only recently the first better-than-2 approximations have been found for the more general Unweighted Connectivity Augmentation Problem and Weighted Tree Augmentation Problem. In this talk we will discuss these recent advances.</p></blockquote></div>
    </content>
    <updated>2022-04-28T10:39:45Z</updated>
    <published>2022-04-28T10:39:45Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2022-05-04T12:37:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6405</id>
    <link href="https://scottaaronson.blog/?p=6405" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6405#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6405" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">My first-ever attempt to create a meme!</title>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><figure class="wp-block-image size-large"><img alt="" src="https://www.scottaaronson.com/4thinkers.jpg"/></figure></div>
    </content>
    <updated>2022-04-27T23:41:25Z</updated>
    <published>2022-04-27T23:41:25Z</published>
    <category scheme="https://scottaaronson.blog" term="Embarrassing Myself"/>
    <category scheme="https://scottaaronson.blog" term="Metaphysical Spouting"/>
    <category scheme="https://scottaaronson.blog" term="Procrastination"/>
    <category scheme="https://scottaaronson.blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-05-04T06:10:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/060</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/060" rel="alternate" type="text/html"/>
    <title>TR22-060 |  How much randomness is needed to convert MA protocols to AM protocols? | 

	Nikolay Vereshchagin</title>
    <summary>The Merlin-Arthur  class of languages MA is included into Arthur-Merlin  class AM, and into PP. For a  standard transformation of a given MA protocol with  Arthur's message (= random string) of length $a$ and Merlin's message of length $m$ to a PP machine, the latter needs  $O(ma)$ random bits. The same holds for simulating MA protocols by AM protocols: in the resulting AM protocol the length of Arthur's message (= random string) is $O(ma)$. And the same holds for simulating heuristic MA protocols by  heuristic  AM protocols as well. In the paper  [A. Knop, Circuit Lower Bounds for Average-Case MA, CSR 2015] it was conjectured that, in the transformation of heuristic MA protocols to heuristic AM protocols, $O(ma)$ can be replaced by a polynomial of $a$ only. A similar question can be asked for normal MA and AM protocols, and for the simulation of MA protocols by PP machines. In the present paper we show that, relative to an oracle,  both latter questions answer in the negative and Knop's conjecture is false. Moreover,  the same is true for simulation of MA protocols by AM protocols in which the  error probability is not bounded away from 1/2, the so called PP$\cdot$NP protocols. The latter protocols generalize both AM protocols and  PP machines.</summary>
    <updated>2022-04-27T16:52:27Z</updated>
    <published>2022-04-27T16:52:27Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-05-04T12:37:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8309</id>
    <link href="https://windowsontheory.org/2022/04/27/a-personal-faq-on-the-math-education-controversies/" rel="alternate" type="text/html"/>
    <title>A personal FAQ on the math education controversies</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I was a contact person for the open letter on K-12 math education, and am in strong support of the recent letter on the role of data science in math education (and would encourage readers that are faculty members in California to sign it). Since I tend to see the same questions and objections arise … <a class="more-link" href="https://windowsontheory.org/2022/04/27/a-personal-faq-on-the-math-education-controversies/">Continue reading <span class="screen-reader-text">A personal FAQ on the math education controversies</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I was a contact person for the <a href="https://windowsontheory.org/2021/12/03/an-alarming-trend-in-k-12-math-education/">open letter on K-12 math education</a>, and am in strong support of the <a href="https://scottaaronson.blog/?p=6389">recent letter on the role of data science in math education</a> (and would encourage readers that are faculty members in California to sign it). Since I tend to see the same questions and objections arise time and again, I thought it would be useful to write my responses to these. The following is my own opinions only, and does not reflect the views of any other contact person or signer of these letters. I also apologize in advance for the lack of links and references below. However, if you ask questions in the comments, I’d be happy to give more sources.</p>



<p><strong>Q: The status quo in US math education is terrible and doesn’t work for many children, especially students of color and low income students. Aren’t these letter writers just trying to protect a flawed system that worked well for them?</strong></p>



<p><strong>A: </strong>The US math education system is very complex, but I agree that it is largely failing a large chunk of our students. But that doesn’t mean that any change will necessarily be for the better. Just because a system is bad, doesn’t mean you can’t make it worse. We have a responsibility to “first do no harm” when we experiment on millions of children of our largest state, and the proposed changes are not based on any solid evidence, and in my opinion (and the opinion of many other experts) will make things worse. Indeed, there is no shortage of experiments in mathematics education that yielded no or even negative progress in terms of equity.</p>



<p>Also, not all change needs to be curricular change. The inequalities in the system were not created because of the math curriculum, and will not be fixed by it. Many top-performing countries use a fairly traditional math curriculum, some strongly influenced by the Soviet system.  The inequalities in the US arise from huge disparities in the resources at school, and a highly unequal society at large. I personally think that improving education is much more about support for students, resources, tutoring, teacher training, etc, than whether we teach logarithms using method X or method Y.</p>



<p><strong>Q:</strong> <strong>Shouldn’t CS and STEM faculty stay out of this debate, and leave it to the math education faculty that are the true subject matter experts?</strong></p>



<p><strong>A:</strong> The education system has many stakeholders, including students, parents, teachers, citizens, employers, and post-secondary educators, and they all should be heard. STEM careers and other quantitative fields are the fastest growing in opportunities and student interest in college. As such, one of the goals (though not the only one) of K-12 math education is to prepare students to have the option to major in STEM in college, if that is what they want to do. STEM faculty are the best equipped to <a href="https://mathematics.stanford.edu/news/submission-ca-math-framework-revision">say what is needed</a> for success in their field, and what they see is the impact of K-12 preparation. Math Ed and STEM faculty can and should be working together on the  K-12 curriculum. </p>



<p><strong>Q: But not all students will go to STEM in college. Shouldn’t the K-12 math education system also offer something for the students that are not interested in STEM?</strong></p>



<p><strong>A: </strong>I agree that not all students will go to STEM and that (for example) not all high-school students should be forced to take calculus. However, if we are offering an option that is designed for students that are not interested in STEM then we should be honest about it. At the moment high-school data science courses are marketed as a way to “have your cake and eat it too” – courses that are on one hand easier than algebra and calculus and on the other hand give just as good or maybe even better preparation for a career in tech or data science. This is misinformation, and the students most likely to fall for it are the ones with the least resources. In addition, the type of thinking developed by rigorous math courses can benefit students throughout their lives and careers, regardless of the path they take.</p>



<p><strong>Q: Isn’t equity more important than giving students opportunities to advance in math? Shouldn’t mathematical education policy be focused on the kids that are struggling the most and facing most challenges, in particular students of color?</strong></p>



<p><strong>A: </strong>I personally think equity and expanding access to mathematical education is absolutely crucial. This is why I was and am involved in initiatives including <a href="https://www.addiscoder.com/">AddisCoder</a>, <a href="https://jamcoders.org.jm/">JamCoders</a>, <a href="https://womenintheory.wordpress.com/">Women In Theory</a>, and <a href="https://boazbk.github.io/tcs-summerschool/">New Horizons in TCS</a>. But true equity is about actually educating students more, not about moving the goalposts and claiming success. This is doubly true in the context of the US education system. There will be many routes open to well-resourced students to bypass any limitations of the public system. These include private tutoring, courses such as Russian School of Math, Art of Problem Solving, or simply opting out of the public system altogether. Also, due to local control, wealthier districts are likely to opt out of any reforms that they perceive (correctly) as giving worse preparation for post-secondary success. </p>



<p>Hence changes such as the CMF will disproportionately harm low-income students and students of color, and make it less likely for them to succeed in STEM. Not coincidentally, many educators, researchers, and practitioners of color have signed both letters, while the CMF itself has no Black authors. There are efforts that actually do work to decrease educational gaps: these include Bob Moses’ <a href="https://www.nytimes.com/2001/01/07/education/algebra-project-bob-moses-empowers-students.html">Algebra Project</a>, Adrian Mims’ (contact person for one of the letters) <a href="https://thecalculusproject.org/">Calculus Project</a>,  <a href="https://www.theescalanteprogram.org/">Jaime Escalante</a>  (from “stand and deliver”) math program, and the <a href="https://www.aeaweb.org/articles?id=10.1257/app.3.3.158">Harlem Children’s Zone</a>. Notably, none of these projects involve lowering the bar. </p>



<p><strong>Q: Maybe the problem is with the STEM college curriculum as well? For example, why do students need calculus for a computer science degree when hardly any software engineer uses it? If colleges would make their curriculum more practically oriented then we wouldn’t need to teach high-school kids this hard math.</strong></p>



<p><strong>A:</strong> There is a narrow answer and a deeper answer to this question. The narrow answer is that the goal of K-12 education is to prepare students for success in the world as it exists now. If you want to fight these battles at the higher education level, then you should fight them and win them, and only later change the K-12 education to fit the new college curricula.</p>



<p>However, there is a deeper answer why university education has always been about more than just giving students the minimal vocational skills. We believe that our mission is not just to give students some tools that they’ll use in the first job out of school, but broader ways of thinking that will help them keep up with new developments throughout their careers. Computer Science is a great example of this. Fifteen years ago, most computer scientists didn’t need to know much about algebra, probability or calculus, but these days deep learning is fast expanding to every area of CS. The time between an academic paper to a real-world product is getting shorter and shorter, and one skill a computer scientist needs these days is the ability to read a complex technical text and not be afraid of learning new math. Foundational courses such as college calculus and linear algebra (which themselves build on high-school Algebra II and  pre-calculus) are crucial for this skill.</p>



<p><strong>Q: Aren’t you devaluing data science and saying it’s less important than Algebra or Calculus?</strong></p>



<p><strong>A: </strong>Absolutely not. I think literacy with data is an essential skill for any citizen in our modern society, and strongly support it being taught for every K-12 student. This does not mean that it can or should replace the basic math foundational skills. Data science can and be included in variety of courses, ranging from the computational and natural sciences to the social sciences and even humanities. (For example see the courses satisfying Harvard’s <a href="https://oue.fas.harvard.edu/quantitative-reasoning-data">quantitative reasoning with data requirement</a>.)</p>



<p>“Data science” is an evolving field and at the moment not very well defined, and as such there are data science courses of vastly different types. A high-school course or module in data proficiency can be extremely beneficial for students, but without prerequisites such as algebra, probability, and programming, there is a severe limit to the depth that it can go to. For students who will not go into STEM or data science, such a data literacy course would be highly recommended. Students who will take a deeper course later on are better served by foundational courses such as Algebra, Pre-calculus, and Calculus. </p>



<p>By the way, there is nothing about data science that makes it inherently easier than algebra or calculus. While (univariate) calculus is ultimately about functions you can draw on a paper and reason intuitively about their graphs, issues of correlations vs causation are highly subtle, and even experts could get it wrong. The skills and rigorous modes of thinking developed in courses such as Algebra II and beyond are required to develop a true understanding of data science. </p>



<p>There is another reason why a prerequisite-free data literacy course should not be considered as part of the math curriculum, which was eloquently put by <a href="https://blog.mathed.page/2019/10/14/freakonomics-radio-on-math-curriculum/">Henri Picciotto</a> (see also <a href="https://blog.mathed.page/2021/12/14/yet-more-on-the-california-framework-part-1/">this</a>): <em>“in math we should not teach black-box formulas and software packages that students cannot possibly understand thoroughly. We have been moving towards teaching math for understanding at all levels. There is no reason to use data analysis as an excuse to backtrack. Let science and social studies teachers use standard deviation, correlation coefficient, regression, confidence interval, and the like without understanding the underlying assumptions and the reasoning and calculations that lead to those. Math teachers should not. “</em></p>



<p><strong>Q: Isn’t the CMF an evidence-based proposal that is backed by a huge number of citations?</strong></p>



<p><strong>A:</strong> The short answer to this question is “No”. The medium answer is that the CMF contains many citations but often the research cited is <a href="https://notepad.michaelpershan.com/more-youcubed-research-that-is-difficult-to-explain/">sloppy</a>, or is cited incorrectly. (For example, they make plenty of <a href="https://docs.google.com/document/d/1WO4gCR0fCHtlN8uN5lRztAsdqEGuRgKE/edit#bookmark=id.d8y5jr2fqobx" rel="noreferrer noopener" target="_blank">unsupported</a> <a href="https://docs.google.com/document/d/1WO4gCR0fCHtlN8uN5lRztAsdqEGuRgKE/edit#bookmark=id.biqb9dlec448" rel="noreferrer noopener" target="_blank">claims</a> on neuroscience ,whereas essentially all neuroscientists agree that our understanding of the brain is nowhere near the level that it could be used to guide curriculum development.) The long answer is out of scope for this blog post, but here are some links to analyses done by other people. I will update this blog as more are put out (this is a 900 page document after all), but some people that wrote about this include <a href="https://notepad.michaelpershan.com/what-is-happening-in-california-with-math-right-now/">Michael Pershan</a> and <a href="https://twitter.com/BethKellySF/status/1516875836573454338?s=20&amp;t=ewWPTA0FYdJBpJNDzeTjDw">Beth Kelly</a> (see also <a href="https://twitter.com/BethKellySF/status/1518991575526699008?s=20&amp;t=ewWPTA0FYdJBpJNDzeTjDw">this</a>). Brian Conrad has been working on fuller analysis of the CMF, and I will update this post (as well as <a href="https://twitter.com/boazbaraktcs">tweet</a> about it) as parts of it become available.</p></div>
    </content>
    <updated>2022-04-27T15:37:13Z</updated>
    <published>2022-04-27T15:37:13Z</published>
    <category term="K12-math"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2022-05-04T12:37:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/059</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/059" rel="alternate" type="text/html"/>
    <title>TR22-059 |  Diameter versus Certificate Complexity of Boolean Functions | 

	Siddhesh Chaubal, 

	Anna Gal</title>
    <summary>In this paper, we introduce a measure of Boolean functions we call diameter, that captures the relationship between certificate complexity and several other measures of Boolean functions. Our measure can be viewed as a variation on alternating number, but while alternating number can be exponentially larger than certificate complexity, we show that diameter is always upper bounded by certificate complexity. We argue that estimating diameter may help to get improved bounds on certificate complexity in terms of sensitivity, and other measures.

Previous results due to Lin and Zhang  imply that $s(f) \ge \Omega(n^{1/3})$ for transitive functions with constant alternating number. We improve and extend this bound and prove that $s(f) \ge \sqrt{n}$ for transitive functions with constant alternating number, as well as for transitive functions with constant diameter. We also show that $bs(f) \ge \Omega(n^{3/7})$ for transitive functions under the weaker condition that the ``minimum'' diameter is constant.

Furthermore, we prove that the log-rank conjecture holds for functions of the form $f(x \oplus y)$ for functions $f$ with diameter bounded above by a polynomial of the logarithm of the Fourier sparsity of the function $f$.</summary>
    <updated>2022-04-27T03:46:54Z</updated>
    <published>2022-04-27T03:46:54Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-05-04T12:37:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6389</id>
    <link href="https://scottaaronson.blog/?p=6389" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6389#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6389" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">An update on the campaign to defend serious math education in California</title>
    <summary xml:lang="en-US">Update (April 27): Boaz Barak—Harvard CS professor, longtime friend-of-the-blog, and coauthor of my previous guest post on this topic—has just written an awesome FAQ, providing his personal answers to the most common questions about what I called our “campaign to defend serious math education.” It directly addresses several issues that have already come up in […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Update (April 27):</strong> Boaz Barak—Harvard CS professor, longtime friend-of-the-blog, and coauthor of my previous guest post on this topic—has just written an <a href="https://windowsontheory.org/2022/04/27/a-personal-faq-on-the-math-education-controversies/">awesome FAQ</a>, providing his personal answers to the most common questions about what I called our “campaign to defend serious math education.”  It directly addresses several issues that have already come up in the comments.  Check it out!</p>



<hr class="wp-block-separator"/>



<p>As you might remember, last December I hosted a <a href="https://scottaaronson.blog/?p=6146">guest post</a> about the “California Mathematics Framework” (CMF), which was set to cause radical changes to precollege math in California—e.g., eliminating 8th-grade algebra and making it nearly impossible to take AP Calculus.  I linked to an <a href="https://sites.google.com/view/k12mathmatters/home">open letter</a> setting out my and my colleagues’ concerns about the CMF.  That letter went on to receive more than 1700 signatures from STEM experts in industry and academia from around the US, including recipients of the Nobel Prize, Fields Medal, and Turing Award, as well as a lot of support from college-level instructors in California. </p>



<p>Following widespread pushback, a <a href="https://www.cde.ca.gov/ci/ma/cf/">new version of the CMF</a> appeared in mid-March.  I and others are gratified that the new version significantly softens the opposition to acceleration in high school math and to calculus as a central part of mathematics.  Nonetheless, we’re still concerned that the new version promotes a narrative about data science that’s a recipe for cutting kids off from any chance at earning a 4-year college degree in STEM fields (including, ironically, in data science itself).</p>



<p>To that end, some of my Californian colleagues have <a href="https://sites.google.com/view/mathindatamatters/home"><strong>issued a new statement today</strong></a> on behalf of academic staff at 4-year colleges in California, aimed at clearing away the fog on how mathematics is related to data science.  I strongly encourage my readers on the academic staff at 4-year colleges in California to sign this commonsense statement, which has already been signed by over 250 people (including, notably, at least 50 from Stanford, home of two CMF authors).</p>



<p>As a public service announcement, I’d also like to bring to wider awareness <a href="https://www.law.cornell.edu/regulations/california/5-CCR-Sec-18533">Section 18533 of the California Education Code</a>, for submitting written statements to the California State Board of Education (SBE) about errors, objections, and concerns in curricular frameworks such as the CMF.  </p>



<p>The SBE is scheduled to vote on the CMF in mid-July, and their remaining meeting before then is on May 18-19 according to <a href="https://www.cde.ca.gov/be/ag/st/index.asp">this site</a>, so it is really at the May meeting that concerns need to be aired.  Section 18533 requires submissions to be written (yes, snail mail) and postmarked at least 10 days before the SBE meeting.  So to make your voice heard by the SBE, please send your written concern by certified mail (for tracking, but <em>not</em> requiring signature for delivery), no later than Friday May 6, to State Board of Education, c/o Executive Secretary of the State Board of Education, 1430 N Street, Room 5111, Sacramento, CA 95814, complemented by an email submission to <a href="mailto:sbe@cde.ca.gov" rel="noreferrer noopener" target="_blank">sbe@cde.ca.gov</a> and <a href="mailto:mathframework@cde.ca.gov" rel="noreferrer noopener" target="_blank">mathframework@cde.ca.gov</a>.</p></div>
    </content>
    <updated>2022-04-26T17:02:02Z</updated>
    <published>2022-04-26T17:02:02Z</published>
    <category scheme="https://scottaaronson.blog" term="Announcements"/>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-05-04T06:10:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/058</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/058" rel="alternate" type="text/html"/>
    <title>TR22-058 |  Separations in Proof Complexity and TFNP | 

	Mika Göös, 

	Alexandros Hollender, 

	Siddhartha Jain, 

	Gilbert Maystre, 

	William Pires, 

	Robert Robere, 

	Ran Tao</title>
    <summary>It is well-known that Resolution proofs can be efficiently simulated by Sherali-Adams (SA) proofs. We show, however, that any such simulation needs to exploit huge coefficients: Resolution cannot be efficiently simulated by SA when the coefficients are written in unary. We also show that Reversible Resolution (a variant of MaxSAT Resolution) cannot be efficiently simulated by Nullstellensatz (NS).

These results can be interpreted in the language of total NP search problems. We show that PPADS, PPAD, SOPL are captured by unary-SA, unary-NS, and Reversible Resolution, respectively. Consequently, relative to an oracle, PLS $\not\subseteq$ PPADS and SOPL $\not\subseteq$ PPA.</summary>
    <updated>2022-04-26T15:47:44Z</updated>
    <published>2022-04-26T15:47:44Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-05-04T12:37:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/057</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/057" rel="alternate" type="text/html"/>
    <title>TR22-057 |  When Arthur has Neither Random Coins nor Time to Spare: Superfast Derandomization of Proof Systems | 

	Lijie Chen, 

	Roei Tell</title>
    <summary>What is the actual cost of derandomization? And can we get it for free? These questions were recently raised by Doron et. al (FOCS 2020) and have been attracting considerable interest. In this work we extend the study of these questions to the setting of *derandomizing interactive proofs systems*. 

First, we show conditional derandomization of $\mathcal{MA}$ and of $\mathcal{AM}$ with *optimal runtime overhead*, where optimality is under the  $\#NSETH$ assumption. Specifically, denote by $\mathcal{AM}\mathcal{TIME}^{[\rightleftharpoons c]}[T]$ a protocol with $c$ turns of interaction in which the verifier runs in polynomial time $T$. We prove that for every $\epsilon&gt;0$ there exists $\delta&gt;0$ such that:

1. $\mathcal{MATIME}[T]\subseteq \mathcal{NTIME}[T^{2+\epsilon}]$, and

2. $\mathcal{AM}\mathcal{TIME}^{[\rightleftharpoons c]}[T] \subseteq \mathcal{NTIME}[n\cdot T^{\lceil c/2 \rceil+\epsilon}]$,

where $(1)$ follows if there is a property $\Pi$ of Boolean functions that can be recognized from a $2^n$-length truth-table in $\mathcal{NTIME}[2^{(2+\epsilon/3)\cdot n}]$ such that functions with $\Pi$ are hard for $(\mathcal{N}\cap co\mathcal{N})\mathcal{TIME}[2^{(2-\delta)\cdot n}]/2^{(1-\delta)\cdot n}$; and $(2)$ follows if for every $k\ge1$ there is a $\Pi$ that can be recognized from a $2^n$-length truth-table in $\mathcal{NTIME}[2^{(k+\epsilon/3)\cdot n}]$ such that functions with $\Pi$ are hard for $\mathcal{MAMTIME}[2^{(1-\delta)\cdot k n}]/2^{(1-\delta)\cdot n}$.

To obtain faster derandomization, we introduce the notion of a *deterministic effective argument system*: This is a deterministic verifier $V$ such that correct claims $x\in L$ can be proved to $V$ (i.e., there is a proof $\pi$ such that $V(x,\pi)=1$), and for every probabilistic polynomial-time adversary $\tilde{P}$, the probability that $\tilde{P}$ finds an incorrect claim $x\notin L$ and a misleading proof $\pi$ such that $V(x,\pi)=1$ is negligible.

Under strong hardness assumptions, we prove that *any constant-round proof system can be compiled into a deterministic effective argument system, with essentially no time overhead*. As one corollary, under the foregoing hardness assumptions, for every $\epsilon&gt;0$ there is a deterministic verifier $V$ that gets as input an $n$-bit formula of size $2^{o(n)}$, runs in time $2^{\epsilon \cdot n}$, and satisfies the following: For every formula $\Phi$ there is a proof $\pi$ such that $V(\Phi,\pi)$ prints the number of satisfying assignments for $\Phi$; and for every adversary $\tilde{P}$ running in time $2^{O(n)}$, the probability that $\tilde{P}$ finds $\Phi$ and $\pi$ such that $V(\Phi,\pi)$ prints an incorrect count is $2^{-\omega(n)}$.</summary>
    <updated>2022-04-25T07:50:36Z</updated>
    <published>2022-04-25T07:50:36Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-05-04T12:37:17Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-889555349371097512</id>
    <link href="http://blog.computationalcomplexity.org/feeds/889555349371097512/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/04/the-roeder-problem-was-solved-before-i.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/889555349371097512" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/889555349371097512" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/04/the-roeder-problem-was-solved-before-i.html" rel="alternate" type="text/html"/>
    <title>The Roeder Problem was Solved Before I Posed it (how we missed it)</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>(This is a joint post with David and Tomas Harris.)</p><p><br/></p><p>In my an earlier post (see <a href="https://blog.computationalcomplexity.org/2022/04/the-roeder-seq-problems-was-solved.html">here</a>) I discussed the MATH behind a problem that I worked on, with David and Tomas Harris, that we later found out had already been solved. In this post we discuss HOW this happened. </p><p>Recall that Bill Gasarch read a column of Oliver Roeder (see <a href="https://fivethirtyeight.com/features/pick-a-number-any-number/">here</a>) on Nate Silvers' blog where he challenged his readers to the following:</p><p>Find the longest sequence using numbers from {1,...,100} such that every number is either a factor or multiple of the previous number. (A later column (see <a href="https://fivethirtyeight.com/features/is-this-bathroom-occupied/">here</a> ) revealed the answer to be 77 via a computer search, which we note is not a human-readable proof.)</p><p>Bill wrote a blog post (see <a href="https://blog.computationalcomplexity.org/2017/09/a-problem-i-thought-was-interesting-now.html">here</a>) and an open problems column (see <a href="https://www.cs.umd.edu/~gasarch/open/nate.pdf">here</a> ) asking about the general case of {1,...,n}. Before doing this Bill DID try to check the literature to see what was known, but he didn't check very hard since this was not going to be a published paper. Also, he vaguely thought that if it was a known problem then one of his readers would tell him.</p><p>QUESTION: Is it appropriate to blog on things that you have not done a search of the literature on?</p><p>ANSWER: Yes, but you should SAY SO in the blog post.</p><p>As measured by comments, the post did not generate much interest- 10 comments. 2 were me (Gasarch) responding to comments.</p><p>David (who has a PhD from UMCP under Aravind Srinivasan) asked Bill to find a HS project for his son Tomas. Bill gave Tomas the sequence problem (as he called it) to look at- perhaps write a program to find what happens for {1,...,n} for small n, perhaps find human-readable proofs of weaker bound, for small n or for n=100.</p><p>David got interested in the MATH behind the problem so the project became three projects: Tomas would look at the programing aspects and the human-readable aspects, David would look at the Math, and Bill would...  hmmm, not clear what Bill would do, but he did write up a great deal of it and cleaned up some of the proofs.</p><p>David showed</p><p>Omega( n/( (log n)^{1.68} )  LE  L(n)  LE  O( n/( (log n)^{0.79} ). </p><p>Tomas and Bill obtained a human-readable proof that L(100) LE 83. (Comments on my blog sketched a proof that L(100) LE 83, and someone else that L(100) LE 80). See my previous post (<a href="https://blog.computationalcomplexity.org/2022/04/the-roeder-seq-problems-was-solved.html">here</a>) for more on the known numbers for L. </p><p>At that point David did a brief literature search; however, he didn't know what to look for.</p><p>BILL still thought of this as a HS project so he didn't think much about a paper coming out of it, or if it was original. So he didn't do the due diligence of seeing what was already known.</p><p>David and Tomas were busy working on it, so they only did a few cursory checks of the literature.</p><div><div><br/></div><div>With the two results above,  we had a paper! David then looked much more carefully at the literature. He DID find some earlier papers -- he did a Google search for Roeder's puzzle, which mentioned another mathematician, who was quoted in a blog by another mathematician, who eventually mentioned Pomerance's old paper on the topic. Once he found a reference to an actual math paper it was easy to use Google Scholar to find forward/backward citations and find the current state of the art.</div><div><br/></div><div>His email had subject title</div><div><br/></div><div>                        SHUT IT ALL DOWN!!!</div><div><br/></div><div>Which made Bill think it involved a nuclear reactor undergoing The China Syndrome rather than just telling us that other people did had better and earlier results. </div><div><br/></div><div><p class="MsoNormal">In 1995 Gerald Tenenbaum showed, in a paper written in French,  that there exists a,b such that </p><p class="MsoNormal">                               n/(log n)^a LE L(n) LE n/(log n)^b (see <a href="http://www.numdam.org/item/ASENS_1995_4_28_2_115_0/">here</a>). </p><p class="MsoNormal">More recently, in 2021, Saias showed, in a paper written in French, that </p><p class="MsoNormal">                                      L(n) GE (0.3 - o(1)) n/log n (see <a href="https://arxiv.org/abs/2107.03855">here</a>). </p></div><div><br/></div><div>SO, why didn't Bill, David, Tomas find that it was already known until late in the process:</div><div><br/></div><div>1) They didn't know the right search term: <i>Divisor Graph</i></div><div><br/></div><div>2) The literature was in French so the right search term is <i>graphe divisoriel</i></div><div><br/></div><div>3) The transition from FUN HS PROJECT to SERIOUS MATH PAPER was somewhat abrupt and caught Bill by surprise.</div><div><br/></div><div>Was this a disappointment?</div><div><br/></div><div>1) We all learned some math from it, so that was nice.</div><div><br/></div><div>2) We were in a position to read and understand the paper since we knew all of the difficulties --- however, it was in French which I do not read. David reads some, Tomas does not read French.  I prefer to be scooped in English, but even then  I might not be able to read up on the problem since  math is... hard. When did math get so hard? see my blog on that <a href="https://blog.computationalcomplexity.org/2019/07/when-did-math-get-so-hard.html">here</a>. When did CS theory get so hard? See my blog on that <a href="https://blog.computationalcomplexity.org/2021/11/when-did-computer-science-theory-get-so.html">here</a>.)</div><div><br/></div><div>Could this happen again?</div><div><br/></div><div>1) Yes. Language barriers are hard to overcome. Though this is rare nowadays--- not much serious mathematics seems to be done outside English. French mathematicians seem to like to keep their language alive, although they probably know English as well. There may be a few other countries (China, perhaps), where English language skills are not advanced and researchers are cut off from the English literature.</div><div><br/></div><div>2) Yes. I've heard of cases where many people discovered the same theorem but were unaware of each others results since they were in different fields.</div><div><br/></div><div>3) Is it easier or harder to reprove a theorem now then it was X years ago?</div><div><br/></div></div><div>We have better search tools, but we also have more to search. </div><div><br/></div></div>
    </content>
    <updated>2022-04-25T01:19:00Z</updated>
    <published>2022-04-25T01:19:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-05-03T23:50:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6387</id>
    <link href="https://scottaaronson.blog/?p=6387" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6387#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6387" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">On form versus meaning</title>
    <summary xml:lang="en-US">There is a fundamental difference between form and meaning. Form is the physical structure of something, while meaning is the interpretation or concept that is attached to that form. For example, the form of a chair is its physical structure – four legs, a seat, and a back. The meaning of a chair is that […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>There is a fundamental difference between form and meaning. Form is the physical structure of something, while meaning is the interpretation or concept that is attached to that form. For example, the form of a chair is its physical structure – four legs, a seat, and a back. The meaning of a chair is that it is something you can sit on.</p>



<p>This distinction is important when considering whether or not an AI system can be trained to learn semantic meaning. AI systems are capable of learning and understanding the form of data, but they are not able to attach meaning to that data. In other words, AI systems can learn to identify patterns, but they cannot understand the concepts behind those patterns.</p>



<p>For example, an AI system might be able to learn that a certain type of data is typically associated with the concept of “chair.” However, the AI system would not be able to understand what a chair is or why it is used. In this way, we can see that an AI system trained on form can never learn semantic meaning.</p>



<p>–GPT3, when I gave it the prompt “Write an essay proving that an AI system trained on form can never learn semantic meaning” <img alt="&#x1F603;" height="16" src="https://static.xx.fbcdn.net/images/emoji.php/v9/taa/1.5/16/1f603.png" width="16"/></p></div>
    </content>
    <updated>2022-04-24T21:34:19Z</updated>
    <published>2022-04-24T21:34:19Z</published>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <category scheme="https://scottaaronson.blog" term="Procrastination"/>
    <category scheme="https://scottaaronson.blog" term="Rage Against Doofosity"/>
    <category scheme="https://scottaaronson.blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-05-04T06:10:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/056</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/056" rel="alternate" type="text/html"/>
    <title>TR22-056 |  Optimal Coding Theorems in Time-Bounded Kolmogorov Complexity | 

	Zhenjian Lu, 

	Igor Carboni Oliveira, 

	Marius Zimand</title>
    <summary>The classical coding theorem in Kolmogorov complexity states that if an $n$-bit string $x$ is sampled with probability $\delta$ by an algorithm with prefix-free domain then K$(x) \leq \log(1/\delta) + O(1)$. In a recent work, Lu and Oliveira [LO21] established an unconditional time-bounded version of this result, by showing that if $x$ can be efficiently sampled with probability $\delta$ then rKt$(x) = O(\log(1/\delta)) + O(\log n)$, where rKt denotes the randomized analogue of Levin's Kt complexity. Unfortunately, this result is often insufficient when transferring applications of the classical coding theorem to the time-bounded setting, as it  achieves a  $O(\log(1/\delta))$ bound instead of the information-theoretic optimal $\log(1/\delta)$.

Motivated by this discrepancy, we investigate optimal coding theorems in the time-bounded setting. Our main contributions can be summarised as follows.

Efficient coding theorem for rKt with a factor of $2$. Addressing a question from [LO21], we show that if $x$ can be efficiently sampled with probability at least $\delta$ then rKt$(x) \le (2 + o(1)) \cdot \log(1/\delta) + O\!\left(\log n\right)$. As in previous work, our coding theorem is efficient in the sense that it provides a polynomial-time probabilistic algorithm that, when given $x$, the code of the sampler, and $\delta$,  it outputs, with  probability $\ge 0.99$, a probabilistic representation of $x$ that certifies this rKt complexity bound.

Optimality under a cryptographic assumption. Under a hypothesis about the security of cryptographic pseudorandom generators, we show that no efficient coding theorem can achieve a bound of the form rKt$(x) \leq (2 - o(1)) \cdot \log(1/\delta) +$ poly$(\log n)$. Under a weaker assumption, we exhibit a gap between efficient coding theorems and existential coding theorems with near-optimal parameters.

Optimal coding theorem for pK$^t$ and unconditional Antunes-Fortnow. We consider pK$^t$ complexity [GKLO22], a variant of rKt where the randomness is public and the time bound is fixed. We observe the existence of an optimal coding theorem for pK$^t$, and employ this result to establish an unconditional version of a theorem of Antunes and Fortnow [AF09] which characterizes the worst-case running times of languages that are in average polynomial-time over all P-samplable distributions.</summary>
    <updated>2022-04-24T20:25:42Z</updated>
    <published>2022-04-24T20:25:42Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-05-04T12:37:17Z</updated>
    </source>
  </entry>
</feed>
