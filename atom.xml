<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-10-08T00:22:15Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01753</id>
    <link href="http://arxiv.org/abs/1910.01753" rel="alternate" type="text/html"/>
    <title>On Computing a Center Persistence Diagram</title>
    <feedworld_mtime>1570492800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Higashikawa:Yuya.html">Yuya Higashikawa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Katoh:Naoki.html">Naoki Katoh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Guohui.html">Guohui Lin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Miyano:Eiji.html">Eiji Miyano</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tamaki:Suguru.html">Suguru Tamaki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Teruyama:Junichi.html">Junichi Teruyama</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhu:Binhai.html">Binhai Zhu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01753">PDF</a><br/><b>Abstract: </b>Given a set of persistence diagrams ${\cal P}_1,...,{\cal P}_m$, for the data
reduction purpose, one way to summarize their topological features is to
compute the {\em center} ${\cal C}$ of them. Let $P_i$ be the set of feature
points in ${\cal P}_i$. Here we mainly focus on the two discrete versions when
points in ${\cal C}$ could be selected with or without replacement from
$P_i$'s. (We will briefly discuss the continuous case, i.e., points in ${\cal
C}$ are arbitrary, which turns out to be closely related to the 3-dimensional
geometric assignment problem). For technical reasons, we first focus on the
case when $|P_i|$'s are all the same (i.e., all have the same size $n$), and
the problem is to compute a center point set $C$ under the bottleneck matching
distance. We show, by a non-trivial reduction from the Planar 3D-Matching
problem, that this problem is NP-hard even when $m=3$. This implies that the
general center problem for persistence diagrams, when $P_i$'s possibly have
different sizes, is also NP-hard when $m\geq 3$. On the positive side, we show
that this problem is polynomially solvable when $m=2$ and admits a factor-2
approximation for $m\geq 3$. These positive results hold for any $L_p$ metric
when $P_i$'s are point sets of the same size, and also hold for the case when
$P_i$'s have different sizes in the $L_\infty$ metric (i.e., for the center
persistence diagram problem). This is the best possible in polynomial time
unless P = NP. All these results hold for both of the discrete versions.
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3430</id>
    <link href="https://agtb.wordpress.com/2019/10/07/videos-from-papafest/" rel="alternate" type="text/html"/>
    <title>Videos from PapaFest</title>
    <summary>Videos of all PapaFest talks and panels are here. Advertisements</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Videos of all PapaFest talks and panels are <a href="https://www.youtube.com/watch?v=OX2I00QVPDI&amp;list=PLPldBy2vuDR9gp98jsowJQFn6jtpZatU0">here</a>.</p></div>
    </content>
    <updated>2019-10-07T21:28:05Z</updated>
    <published>2019-10-07T21:28:05Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>timroughgarden</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-10-08T00:20:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1096889632414067693</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1096889632414067693/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/10/what-comes-first-theory-or-practice-its.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1096889632414067693" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1096889632414067693" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/10/what-comes-first-theory-or-practice-its.html" rel="alternate" type="text/html"/>
    <title>What comes first theory or practice? Its Complicated!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Having majored in pure math I had the impression that usually the theory comes first and then someone works out something to work in practice. While this is true sometimes it is often NOT true and this will not surprise any of my blog readers.  Even so, I want to tell you about some times it surprised me. This says more about my ignorance than about math or applications or whatnot.<br/>
<br/>
1) Quantum<br/>
<br/>
a) Factoring was proven to be in BQP way before actual quantum computers could do this in reasonable time (we're still waiting).<br/>
<br/>
b) Quantum Crypto- This really is out there. I do not know what came first, the theory or the practice. Or if they were in tandem.<br/>
<br/>
c) (this one is the inspiration for the post)  When I first heard the term <i>Quantum Supremacy</i> I thought it meant the desire for a THEOREM that problem A is in BQP but is provably not in P.  For example, if someone proved factoring is not in P (unlikely this will be proven, and hey- maybe  factoring is in P). Perhaps some contrived problem like those constructed by diagonalization (my spell checker thinks that's not a word. Having worked in computability theory, I think it is. Darn- my spellchecker thinks computability is not word.) Hence when I heard that Google had a paper proving Quantum Supremacy (I do not recall if I actually heard the word  <i>proven) </i>I assumed that there was some <i>theoretical </i>breakthrough. I was surprised and not in the slightest disappointed to find out it involved actual quantum computers.<br/>
<br/>
<b>Question</b>: When the term <i>Quantum Supremacy</i> was first coined, did they mean theoretical, or IRL, or both?<br/>
<br/>
2) Ramsey Theory<br/>
<br/>
a) For Ramsey's Theorem and Van Der waerden's theorem and Rado's theorem and others I could name, first a theorem showed a upper bound on a number, then later computers and perhaps some math got better bounds on that number.<br/>
<br/>
b) Consider the following statement:<br/>
<br/>
For all c there exists P such that for all c-colorings of {1,...,P} there exists x,y,z the same color such that x<sup>2</sup> +y<sup>2</sup> = z<sup>2</sup>.<br/>
<br/>
Ronald Graham conjectured the c=2 case and offered $100 in the 1980's. (I do not know if he had any comment on the general case.)  I assumed that it would be proven with ginormous bounds on the P(c) function, and then perhaps some reasonable bound would be found by clever programming and some math. (see <a href="https://en.wikipedia.org/wiki/Boolean_Pythagorean_triples_problem">here</a> for the Wikipedia Entry about the problem, which also has pointers to other material).<br/>
<br/>
Instead the c=2 case was proven with an exact bound, P(2)=7825, by a computer program, in 2016. The proof is 200 terabytes. So my prediction was incorrect.<br/>
<br/>
As for the result<br/>
<br/>
PRO: We know the result is true for c=2 and we even know the exact bound. Wow! and for Ramsey Theory its unusual to have exact bounds!<br/>
<br/>
CON: It would be good to have a human-readable proof. This is NOT an anti-technology statement. For one thing, a human-readable proof might help us get the result for c=3 and beyond.<br/>
<br/>
3) This item is a cheat in that I knew the empirical results first. However, I will tell you what I am sure I would have thought (and been wrong) had I not know them.<br/>
<br/>
Given k, does the equation<br/>
<br/>
<br/>
x<sup>3</sup> +y<sup>3</sup> +z<sup>3</sup> = k<br/>
<br/>
have a solution in Z? I would have thought that some hard number theory would determine<br/>
for which k it has a solution (with a proof that does not give the actual solutions)  and for then a computer programs would try to find the solutions. Instead (1) some values of k are ruled out by simple mod considerations, and (2) as for the rest, computers have found solutions for some of them. Lipton-Regan (<a href="https://rjlipton.wordpress.com/2019/09/30/writing-33-as-a-sum-of-cubes/">here</a>) and Gasarch (<a href="https://blog.computationalcomplexity.org/2019/04/x-3-y-3-z-3-33-has-solution-in-z-and.html">here</a>) have blogged about the k=33 case. Lipton-Regan also comment on the more recent k=42 case.<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-10-07T13:56:00Z</updated>
    <published>2019-10-07T13:56:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-10-07T19:40:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/10/07/culty-positions-at-the-rank-of-associate-and-assistant-professor-in-machine-learning-and-data-science-at-maersk-mc-kinney-moller-institute-faculty-of-engineering-university-of-southern-denmark-appl/</id>
    <link href="https://cstheory-jobs.org/2019/10/07/culty-positions-at-the-rank-of-associate-and-assistant-professor-in-machine-learning-and-data-science-at-maersk-mc-kinney-moller-institute-faculty-of-engineering-university-of-southern-denmark-appl/" rel="alternate" type="text/html"/>
    <title>culty Positions at the rank of Associate and Assistant Professor in machine learning and data science at Maersk Mc-Kinney Moller Institute, Faculty of Engineering, University of Southern Denmark (apply by November 3, 2019)</title>
    <summary>he Group of Machine Learning and Data Science (part of Embodied Systems for Robotics and Learning) at the Maersk Mc-Kinney Moller Institute, Faculty of Engineering, University of Southern Denmark, invites applications for Faculty positions at the rank of Associate (permanent) and Assistant (3-year period) Professor. Website: https://www.sdu.dk/en/service/ledige_stillinger/1063846 Email: esi@mmmi.sdu.dk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>he Group of Machine Learning and Data Science (part of Embodied Systems for Robotics and Learning) at the Maersk Mc-Kinney Moller Institute, Faculty of Engineering, University of Southern Denmark, invites applications for Faculty positions at the rank of Associate (permanent) and Assistant (3-year period) Professor.</p>
<p>Website: <a href="https://www.sdu.dk/en/service/ledige_stillinger/1063846">https://www.sdu.dk/en/service/ledige_stillinger/1063846</a><br/>
Email: esi@mmmi.sdu.dk</p></div>
    </content>
    <updated>2019-10-07T10:05:47Z</updated>
    <published>2019-10-07T10:05:47Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-10-08T00:21:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4361</id>
    <link href="https://www.scottaaronson.com/blog/?p=4361" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4361#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4361" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Book Review: ‘The AI Does Not Hate You’ by Tom Chivers</title>
    <summary xml:lang="en-US">A couple weeks ago I read The AI Does Not Hate You: Superintelligence, Rationality, and the Race to Save the World, the first-ever book-length examination of the modern rationalist community, by British journalist Tom Chivers. I was planning to review it here, before it got preempted by the news of quantum supremacy (and subsequent news […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>A couple weeks ago I read <a href="https://www.amazon.com/Rationalists-Artificial-Intelligence-Geeks-World/dp/1474608779/ref=tmm_hrd_swatch_0?_encoding=UTF8&amp;qid=&amp;sr=">The AI Does Not Hate You: Superintelligence, Rationality, and the Race to Save the World</a>, the first-ever book-length examination of the modern <a href="https://wiki.lesswrong.com/wiki/Rationalist_movement">rationalist community</a>, by British journalist <a href="https://twitter.com/TomChivers?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor">Tom Chivers</a>.  I was planning to review it here, before it got preempted by the news of <a href="https://www.scottaaronson.com/blog/?p=4317">quantum supremacy</a> (and subsequent news of <a href="https://www.scottaaronson.com/blog/?p=4342">classical non-supremacy</a>).  Now I can get back to rationalists.</p>



<p>Briefly, I think the book is a triumph.  It’s based around in-person conversations with many of the notable figures in and around the rationalist community, in its Bay Area epicenter and beyond (although apparently <a href="https://en.wikipedia.org/wiki/Eliezer_Yudkowsky">Eliezer Yudkowsky</a> only agreed to answer technical questions by Skype), together of course with the voluminous material available online.  There’s a good deal about the 1990s origins of the community that I hadn’t previously known.</p>



<p>The title is taken from Eliezer’s aphorism, “The AI does not hate you, nor does it love you, but you are made of atoms which it can use for something else.”  In other words: as soon as anyone succeeds in building a superhuman AI, if we don’t take extreme care that the AI’s values are “aligned” with human ones, the AI might be expected to obliterate humans almost instantly as a byproduct of pursuing whatever it <em>does</em> value, more-or-less as we humans did with woolly mammoths, moas, and now gorillas, rhinos, and thousands of other species.</p>



<p>Much of the book relates Chivers’s personal quest to figure out how seriously he should take this scenario.  Are the rationalists just an unusually nerdy doomsday cult?  Is there some non-negligible chance that they’re actually right about the AI thing?  If so, how much more time do we have—and is there even anything meaningful that can be done today?  Do the dramatic advances in machine learning over the past decade change the outlook?  Should Chivers be worried about his own two children?  How does this risk compare to the more “prosaic” civilizational risks, like climate change or nuclear war?  I suspect that Chivers’s exploration will be most interesting to readers who, like me, regard the answers to <em>none</em> of these questions as obvious.</p>



<p>While it sounds extremely basic, what makes <em>The AI Does Not Hate You</em> so valuable to my mind is that, as far as I know, it’s nearly the only examination of the rationalists ever written by an outsider that tries to assess the ideas on a scale from true to false, rather than from quirky to offensive.  Chivers’s own training in academic philosophy seems to have been crucial here.  He’s not put off by people who act weirdly around him, even needlessly cold or aloof, nor by utilitarian thought experiments involving death or torture or weighing the value of human lives.  He just cares, relentlessly, about the ideas—and about remaining a basically grounded and decent person while engaging them.  Most strikingly, Chivers clearly feels a need—anachronistic though it seems in 2019—actually to <em>understand</em> complicated arguments, be able to repeat them back correctly, before he attacks them.</p>



<p>Indeed, far from failing to understand the rationalists, it occurs to me that the central criticism of Chivers’s book is likely to be just the opposite: he understands the rationalists so well, extends them so much sympathy, and ends up endorsing so many aspects of their worldview, that he must simply <em>be</em> a closet rationalist himself, and therefore can’t write about them with any pretense of journalistic or anthropological detachment.  For my part, I’d say: it’s true that <em>The AI Does Not Hate You</em> is what you get if you treat rationalists as extremely smart (if unusual) people from whom you might learn something of consequence, rather than as monkeys in a zoo.  On the other hand, Chivers does perform the journalist’s task of constantly challenging the rationalists he meets, often with points that (if upheld) would be fatal to their worldview.  One of the rationalists’ best features—and this precisely matches my own experience—is that, far from clamming up or storming off when faced with such challenges (“lo! the visitor is not one of us!”), the rationalists positively relish them.</p>



<p>It occurred to me the other day that we’ll never know how the rationalists’ ideas would’ve developed, had they continued to do so in a cultural background like that of the late 20th century.  As Chivers points out, the rationalists today are effectively caught in the crossfire of a much larger cultural war—between, to their right, the recrudescent know-nothing authoritarians, and to their left, what one could variously describe as woke culture, call-out culture, or sneer culture.  On its face, it might seem laughable to conflate the rationalists with today’s resurgent fascists: many rationalists are driven by their utilitarianism to advocate open borders and massive aid to the Third World; the rationalist community is about as welcoming of alternative genders and sexualities as it’s humanly possible to be; and leading rationalists like Scott Alexander and Eliezer Yudkowsky strongly condemned Trump for the obvious reasons. </p>



<p>Chivers, however, explains how the problem started.  On rationalist Internet forums, many misogynists and white nationalists and so forth encountered nerds willing to <em>debate their ideas politely</em>, rather than immediately banning them as more mainstream venues would.  As a result, many of those forces of darkness (and they probably don’t mind being called that) predictably congregated on the rationalist forums, and their stench predictably wore off on the rationalists themselves.  Furthermore, this isn’t an easy-to-fix problem, because debating ideas on their merits, extending charity to ideological opponents, etc. is sort of the rationalists’ <em>entire shtick</em>, whereas denouncing and no-platforming anyone who can be connected to an ideological enemy (in the modern parlance, “punching Nazis”) is the entire shtick of those condemning the rationalists.</p>



<p>Compounding the problem is that, as anyone who’s ever hung out with STEM nerds might’ve guessed, the rationalist community tends to skew WASP, Asian, or Jewish, non-impoverished, and male.  Worse yet, while many rationalists live their lives in progressive enclaves and strongly support progressive values, they’ll also undergo extreme anguish if they feel forced to subordinate truth to those values.</p>



<p>Chivers writes that all of these issues “blew up in spectacular style at the end of 2014,” right here on this blog.  Oh, what the hell, I’ll just quote him:</p>



<blockquote class="wp-block-quote"><p>Scott Aaronson is, I think it’s fair to say, a member of the Rationalist community.  He’s a prominent theoretical computer scientist at the University of Texas at Austin, and writes a very interesting, maths-heavy blog called Shtetl-Optimised.</p><p>People in the comments under his blog were discussing feminism and sexual harassment.  And Aaronson, in a comment in which he described himself as a fan of Andrea Dworkin, described having been terrified of speaking to women as a teenager and young man.  This fear was, he said, partly that of being thought of as a sexual abuser or creep if any woman ever became aware that he sexually desired them, a fear that he picked up from sexual-harassment-prevention workshops at his university and from reading feminist literature.  This fear became so overwhelming, he said in the comment that came to be known as Comment #171, that he had ‘constant suicidal thoughts’ and at one point ‘actually begged a psychiatrist to prescribe drugs that would chemically castrate me (I had researched which ones), because a life of mathematical asceticism was the only future that I could imagine for myself.’  So when he read feminist articles talking about the ‘male privilege’ of nerds like him, he didn’t recognise the description, and so felt himself able to declare himself ‘only’ 97 per cent on board with the programme of feminism.</p><p>It struck me as a thoughtful and rather sweet remark, in the midst of a long and courteous discussion with a female commenter.  But it got picked up, weirdly, by some feminist bloggers, including one who described it as ‘a yalp of entitlement combined with an aggressive unwillingness to accept that women are human beings just like men’ and that Aaronson was complaining that ‘having to explain my suffering to women when they should already be there, mopping my brow and offering me beers and blow jobs, is so tiresome.’</p><p>Scott Alexander (<em>not</em> Scott Aaronson) then wrote a furious 10,000-word defence of his friend… (p. 214-215)</p></blockquote>



<p>And then Chivers goes on to explain Scott Alexander’s central thesis, in <a href="https://slatestarcodex.com/2015/01/01/untitled/">Untitled</a>, that privilege is not a one-dimensional axis, so that (to take one example) society can make many women in STEM miserable while <em>also</em> making shy male nerds miserable in different ways.</p>



<p>For nerds, perhaps an alternative title for Chivers’s book could be “The Normal People Do Not Hate You (Not All of Them, Anyway).”  It’s as though Chivers is demonstrating, through understated example, that taking delight in nerds’ suffering, wanting them to be miserable and alone, mocking their weird ideas, is not simply the default, well-adjusted human reaction, with any other reaction being ‘creepy’ and ‘problematic.’  Some might even go so far as to apply the latter adjectives to the sneerers’ attitude, the one that dresses up schoolyard bullying in a social-justice wig.</p>



<p>Reading Chivers’s book prompted me to reflect on my own relationship to the rationalist community.  For years, I interacted often with the community—I’ve known Robin Hanson since ~2004 and Eliezer Yudkowsky since ~2006, and our blogs bounced off each other—but I never considered myself a member.  I never ranked <a href="https://en.wikipedia.org/wiki/Instrumental_convergence#Paperclip_maximizer">paperclip-maximizing AIs</a> among humanity’s more urgent threats—indeed, I saw them as a distraction from an all-too-likely climate catastrophe that will leave its survivors lucky to have stone tools, let alone AIs.  I was also repelled by what I saw as the rationalists’ cultier aspects.  I even once toyed with the idea of changing the name of this blog to “More Wrong” or “Wallowing in Bias,” as a play on the rationalists’ <a href="https://www.lesswrong.com/">LessWrong</a> and <a href="http://www.overcomingbias.com/">OvercomingBias</a>.</p>



<p>But I’ve drawn much closer to the community over the last few years, because of a combination of factors:</p>



<ol><li>The comment-171 affair.  This was not the sort of thing that could provide any new information about the likelihood of a dangerous AI being built, but <em>was</em> (to put it mildly) the sort of thing that can tell you who your friends are.  I learned that empathy works a lot like intelligence, in that those who boast of it most loudly are often the ones who lack it.</li><li>The astounding progress in <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> and <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> and <a href="https://en.wikipedia.org/wiki/Generative_adversarial_network">GANs</a>, which caused me (like everyone else, perhaps) to update in the direction of human-level AI in our lifetimes being an actual live possibility.</li><li>The rise of <a href="https://slatestarcodex.com/">Scott Alexander</a>.  To the charge that the rationalists are a cult, there’s now the reply that Scott, with his constant equivocations and doubts, his deep dives into data, his clarity and self-deprecating humor, is perhaps the least culty cult leader in human history.  Likewise, to the charge that the rationalists are basement-dwelling kibitzers who accomplish nothing of note in the real world, there’s now the reply that Scott has attracted a huge mainstream following (Steven Pinker, Paul Graham, presidential candidate Andrew Yang…), purely by offering up what’s self-evidently some of the best writing of our time.</li><li>Research.  <a href="https://intelligence.org/">MIRI</a> (the Machine Intelligence Research Institute) and <a href="https://openai.com/">OpenAI</a> are now publishing some research papers that I find interesting—some with <a href="https://arxiv.org/abs/1606.06565">relatively approachable problems</a> that I could see myself trying to think about if quantum computing ever got boring.  This shift seems to have happened at roughly around the same time my former student, <a href="https://paulfchristiano.com/">Paul Christiano</a>, “defected” from quantum computing to AI-risk research. </li></ol>



<p>Anyway, if you’ve spent years steeped in the rationalist blogosphere, read Eliezer’s <a href="https://wiki.lesswrong.com/wiki/Sequences">“Sequences,”</a> and so on, <em>The AI Does Not Hate You</em> will probably have little that’s new, although it might still be interesting to revisit ideas and episodes that you know through a newcomer’s eyes.  For anyone else … well, reading the book would be a lot faster than spending all those years reading blogs!  I’ve heard of some rationalists now giving out copies of the book to their relatives, by way of explaining how they’ve chosen to spend their lives.</p>



<p>I <em>still</em> don’t know whether there’s a risk worth worrying about that a misaligned AI will threaten human civilization in my lifetime, or my children’s lifetimes, or even 500 years—or whether everyone will look back and laugh at how silly some people once were to think that (except, silly in which way?).  But I do feel fairly confident that <em>The AI Does Not Hate You</em> will make a positive difference—possibly for the world, but at any rate for a little well-meaning community of sneered-at nerds obsessed with the future and with following ideas wherever they lead.</p></div>
    </content>
    <updated>2019-10-07T02:09:05Z</updated>
    <published>2019-10-07T02:09:05Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-10-07T17:01:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.02063</id>
    <link href="http://arxiv.org/abs/1910.02063" rel="alternate" type="text/html"/>
    <title>Fully Dynamic $(\Delta+1)$-Coloring in Constant Update Time</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhattacharya:Sayan.html">Sayan Bhattacharya</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grandoni:Fabrizio.html">Fabrizio Grandoni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kulkarni:Janardhan.html">Janardhan Kulkarni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Quanquan_C=.html">Quanquan C. Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Solomon:Shay.html">Shay Solomon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.02063">PDF</a><br/><b>Abstract: </b>The problem of (vertex) $(\Delta+1)$-coloring a graph of maximum degree
$\Delta$ has been extremely well-studied over the years in various settings and
models. Surprisingly, for the dynamic setting, almost nothing was known until
recently. In SODA'18, Bhattacharya, Chakrabarty, Henzinger and Nanongkai
devised a randomized data structure for maintaining a $(\Delta+1)$-coloring
with $O(\log \Delta)$ expected amortized update time. In this paper, we present
a $(\Delta+1)$-coloring data structure that achieves a constant amortized
update time and show that this time bound holds not only in expectation but
also with high probability.
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.02057</id>
    <link href="http://arxiv.org/abs/1910.02057" rel="alternate" type="text/html"/>
    <title>C-Planarity Testing of Embedded Clustered Graphs with Bounded Dual Carving-Width</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lozzo:Giordano_Da.html">Giordano Da Lozzo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eppstein:David.html">David Eppstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goodrich:Michael_T=.html">Michael T. Goodrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Siddharth.html">Siddharth Gupta</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.02057">PDF</a><br/><b>Abstract: </b>For a clustered graph, i.e, a graph whose vertex set is recursively
partitioned into clusters, the C-Planarity Testing problem asks whether it is
possible to find a planar embedding of the graph and a representation of each
cluster as a region homeomorphic to a closed disk such that 1. the subgraph
induced by each cluster is drawn in the interior of the corresponding disk, 2.
each edge intersects any disk at most once, and 3. the nesting between clusters
is reflected by the representation, i.e., child clusters are properly contained
in their parent cluster. The computational complexity of this problem, whose
study has been central to the theory of graph visualization since its
introduction in 1995 [Qing-Wen Feng, Robert F. Cohen, and Peter Eades.
Planarity for clustered graphs. ESA'95], has only been recently settled
[Radoslav Fulek and Csaba D. T\'oth. Atomic Embeddability, Clustered Planarity,
and Thickenability. To appear at SODA'20]. Before such a breakthrough, the
complexity question was still unsolved even when the graph has a prescribed
planar embedding, i.e, for embedded clustered graphs.
</p>
<p>We show that the C-Planarity Testing problem admits a single-exponential
single-parameter FPT algorithm for embedded clustered graphs, when
parameterized by the carving-width of the dual graph of the input. This is the
first FPT algorithm for this long-standing open problem with respect to a
single notable graph-width parameter. Moreover, in the general case, the
polynomial dependency of our FPT algorithm is smaller than the one of the
algorithm by Fulek and T\'oth. To further strengthen the relevance of this
result, we show that the C-Planarity Testing problem retains its computational
complexity when parameterized by several other graph-width parameters, which
may potentially lead to faster algorithms.
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.02048</id>
    <link href="http://arxiv.org/abs/1910.02048" rel="alternate" type="text/html"/>
    <title>A Dichotomy for Homomorphism-Closed Queries on Probabilistic Graphs</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Amarilli:Antoine.html">Antoine Amarilli</a>, İsmail İlkan Ceylan <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.02048">PDF</a><br/><b>Abstract: </b>We study the problem of probabilistic query evaluation (PQE) over
probabilistic graphs, namely, tuple-independent probabilistic databases (TIDs)
on signatures of arity two. Our focus is the class of queries that is closed
under homomorphisms, or equivalently, the infinite unions of conjunctive
queries, denoted UCQ^\infty . Our main result states that all unbounded queries
in UCQ^\infty are #P-hard for PQE. As bounded queries in UCQ^\infty are already
classified by the dichotomy of Dalvi and Suciu [16], our results and theirs
imply a complete dichotomy on PQE for UCQ^\infty queries over arity-two
signatures. This dichotomy covers in particular all fragments in UCQ^\infty
such as negation-free (disjunctive) Datalog, regular path queries, and a large
class of ontology-mediated queries on arity-two signatures. Our result is shown
by reducing from counting the valuations of positive partitioned 2-DNF formulae
(#PP2DNF) for some queries, or from the source-to-target reliability problem in
an undirected graph (#U-ST-CON) for other queries, depending on properties of
minimal models.
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01957</id>
    <link href="http://arxiv.org/abs/1910.01957" rel="alternate" type="text/html"/>
    <title>A Polyhedral Homotopy Algorithm For Real Zeros</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Erg=uuml=r:Alperen_A=.html">Alperen A. Ergür</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolff:Timo_de.html">Timo de Wolff</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01957">PDF</a><br/><b>Abstract: </b>We design a homotopy continuation algorithm for finding real zeros of sparse
polynomial systems. Our algorithm builds on a well-known geometric deformation
process, namely Viro's patchworking method. The algorithm operates entirely
over the real numbers and tracks the optimal number of solution paths. In
exchange, the algorithm is not universally applicable: It works for polynomial
system with coefficients satisfying certain concavity conditions. More
precisely, it requires the given polynomial system to be located in the
unbounded components of the complement of the underlying $A$-discriminant
amoeba. A preliminary implementation of an example from the literature suggests
practical performance of the algorithm. We plan to work towards a vigorous
implementation including a larger scale of examples and a software paper.
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01935</id>
    <link href="http://arxiv.org/abs/1910.01935" rel="alternate" type="text/html"/>
    <title>Synchronization under Dynamic Constraints</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolf:Petra.html">Petra Wolf</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01935">PDF</a><br/><b>Abstract: </b>Imagine an assembly line where a box with a lid and liquid in it enters in
some unknown orientation. The box should leave the line with the open lid
facing upwards with the liquid still in it. To save costs there are no complex
sensors or image recognition software available on the assembly line, so a
reset sequence needs to be computed. But how can the dependencies of the
deforming impact of a transformation of the box, such as 'do not tilt the box
over when the lid is open' or 'open the lid again each time it gets closed' be
modeled? We present three attempts to model constraints of these kinds on the
order in which the states of an automaton are transitioned by a synchronizing
word. The first two concepts relate the last visits of states and form
constraints on which states still need to be reached, whereas the third concept
concerns the first visits of states and forms constraints on which states might
still be reached. We examine the computational complexity of different variants
of the problem, whether an automaton can be synchronized with a word that
respects the constraints defined in the respective concept, and obtain nearly a
full classification. While most of the problems are PSPACE-complete we also
observe NP-complete variants and variants solvable in polynomial time. We will
also observe a drop of the complexity if we track the orders of states on
several paths simultaneously instead of tracking the set of active states.
Further, we give upper bounds on the length of a synchronizing word depending
on the size of the input relation and show that the Cerny conjecture holds for
partial weakly acyclic automata.
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01934</id>
    <link href="http://arxiv.org/abs/1910.01934" rel="alternate" type="text/html"/>
    <title>FPT Inapproximability of Directed Cut and Connectivity Problems</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chitnis:Rajesh.html">Rajesh Chitnis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldmann:Andreas_Emil.html">Andreas Emil Feldmann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01934">PDF</a><br/><b>Abstract: </b>(see paper for full abstract)
</p>
<p>Cut problems and connectivity problems on digraphs are two well-studied
classes of problems from the viewpoint of parameterized complexity. After a
series of papers over the last decade, we now have (almost) tight bounds for
the running time of several standard variants of these problems parameterized
by two parameters: the number $k$ of terminals and the size $p$ of the
solution. When there is evidence of FPT intractability, then the next natural
alternative is to consider FPT approximations. In this paper, we show two types
of results for several directed cut and connectivity problems, building on
existing results from the literature: first is to circumvent the hardness
results for these problems by designing FPT approximation algorithms, or
alternatively strengthen the existing hardness results by creating
"gap-instances" under stronger hypotheses such as the (Gap-)Exponential Time
Hypothesis (ETH).
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01788</id>
    <link href="http://arxiv.org/abs/1910.01788" rel="alternate" type="text/html"/>
    <title>Efficient Symmetric Norm Regression via Linear Sketching</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Song:Zhao.html">Zhao Song</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Ruosong.html">Ruosong Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Lin_F=.html">Lin F. Yang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhong:Peilin.html">Peilin Zhong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Hongyang.html">Hongyang Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01788">PDF</a><br/><b>Abstract: </b>We provide efficient algorithms for overconstrained linear regression
problems with size $n \times d$ when the loss function is a symmetric norm (a
norm invariant under sign-flips and coordinate-permutations). An important
class of symmetric norms are Orlicz norms, where for a function $G$ and a
vector $y \in \mathbb{R}^n$, the corresponding Orlicz norm $\|y\|_G$ is defined
as the unique value $\alpha$ such that $\sum_{i=1}^n G(|y_i|/\alpha) = 1$. When
the loss function is an Orlicz norm, our algorithm produces a $(1 +
\varepsilon)$-approximate solution for an arbitrarily small constant
$\varepsilon &gt; 0$ in input-sparsity time, improving over the previously
best-known algorithm which produces a $d \cdot \mathrm{polylog} n$-approximate
solution. When the loss function is a general symmetric norm, our algorithm
produces a $\sqrt{d} \cdot \mathrm{polylog} n \cdot
\mathrm{mmc}(\ell)$-approximate solution in input-sparsity time, where
$\mathrm{mmc}(\ell)$ is a quantity related to the symmetric norm under
consideration. To the best of our knowledge, this is the first input-sparsity
time algorithm with provable guarantees for the general class of symmetric norm
regression problem. Our results shed light on resolving the universal sketching
problem for linear regression, and the techniques might be of independent
interest to numerical linear algebra problems more broadly.
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01783</id>
    <link href="http://arxiv.org/abs/1910.01783" rel="alternate" type="text/html"/>
    <title>Width Parameterizations for Knot-free Vertex Deletion on Digraphs</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bessy:St=eacute=phane.html">Stéphane Bessy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bougeret:Marin.html">Marin Bougeret</a>, Alan D. A. Carneiro, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Protti:F=aacute=bio.html">Fábio Protti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Souza:U=eacute=verton_S=.html">Uéverton S. Souza</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01783">PDF</a><br/><b>Abstract: </b>A knot in a directed graph $G$ is a strongly connected subgraph $Q$ of $G$
with at least two vertices, such that no vertex in $V(Q)$ is an in-neighbor of
a vertex in $V(G)\setminus V(Q)$. Knots are important graph structures, because
they characterize the existence of deadlocks in a classical distributed
computation model, the so-called OR-model. Deadlock detection is correlated
with the recognition of knot-free graphs as well as deadlock resolution is
closely related to the {\sc Knot-Free Vertex Deletion (KFVD)} problem, which
consists of determining whether an input graph $G$ has a subset $S \subseteq
V(G)$ of size at most $k$ such that $G[V\setminus S]$ contains no knot. In this
paper we focus on graph width measure parameterizations for {\sc KFVD}. First,
we show that: (i) {\sc KFVD} parameterized by the size of the solution $k$ is
W[1]-hard even when $p$, the length of a longest directed path of the input
graph, as well as $\kappa$, its Kenny-width, are bounded by constants, and we
remark that {\sc KFVD} is para-NP-hard even considering many directed width
measures as parameters, but in FPT when parameterized by clique-width; (ii)
{\sc KFVD} can be solved in time $2^{O(tw)}\times n$, but assuming ETH it
cannot be solved in $2^{o(tw)}\times n^{O(1)}$, where $tw$ is the treewidth of
the underlying undirected graph. Finally, since the size of a minimum directed
feedback vertex set ($dfv$) is an upper bound for the size of a minimum
knot-free vertex deletion set, we investigate parameterization by $dfv$ and we
show that (iii) {\sc KFVD} can be solved in FPT-time parameterized by either
$dfv+\kappa$ or $dfv+p$; and it admits a Turing kernel by the distance to a DAG
having an Hamiltonian path.
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1910.01749</id>
    <link href="http://arxiv.org/abs/1910.01749" rel="alternate" type="text/html"/>
    <title>Finding monotone patterns in sublinear time</title>
    <feedworld_mtime>1570406400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ben=Eliezer:Omri.html">Omri Ben-Eliezer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Canonne:Cl=eacute=ment_L=.html">Clément L. Canonne</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Letzter:Shoham.html">Shoham Letzter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Waingarten:Erik.html">Erik Waingarten</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1910.01749">PDF</a><br/><b>Abstract: </b>We study the problem of finding monotone subsequences in an array from the
viewpoint of sublinear algorithms. For fixed $k \in \mathbb{N}$ and
$\varepsilon &gt; 0$, we show that the non-adaptive query complexity of finding a
length-$k$ monotone subsequence of $f \colon [n] \to \mathbb{R}$, assuming that
$f$ is $\varepsilon$-far from free of such subsequences, is $\Theta((\log
n)^{\lfloor \log_2 k \rfloor})$. Prior to our work, the best algorithm for this
problem, due to Newman, Rabinovich, Rajendraprasad, and Sohler (2017), made
$(\log n)^{O(k^2)}$ non-adaptive queries; and the only lower bound known, of
$\Omega(\log n)$ queries for the case $k = 2$, followed from that on testing
monotonicity due to Erg\"un, Kannan, Kumar, Rubinfeld, and Viswanathan (2000)
and Fischer (2004).
</p></div>
    </summary>
    <updated>2019-10-07T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-10-07T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/138</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/138" rel="alternate" type="text/html"/>
    <title>TR19-138 |  On the Probabilistic Degrees of Symmetric Boolean functions | 

	Srikanth Srinivasan, 

	Utkarsh Tripathi, 

	S Venkitesh</title>
    <summary>The probabilistic degree of a Boolean function $f:\{0,1\}^n\rightarrow \{0,1\}$ is defined to be the smallest $d$ such that there is a random polynomial $\mathbf{P}$ of degree at most $d$ that agrees with $f$ at each point with high probability. Introduced by Razborov (1987), upper and lower bounds on probabilistic degrees of Boolean functions --- specifically symmetric Boolean functions --- have been used to prove explicit lower bounds, design pseudorandom generators, and devise algorithms for combinatorial problems. 
		
In this paper, we characterize the probabilistic degrees of all symmetric Boolean functions up to polylogarithmic factors over all fields of fixed characteristic (positive or zero).</summary>
    <updated>2019-10-06T15:42:51Z</updated>
    <published>2019-10-06T15:42:51Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-10-08T00:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/137</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/137" rel="alternate" type="text/html"/>
    <title>TR19-137 |  Decision list compression by mild random restrictions | 

	Shachar Lovett, 

	Kewen Wu, 

	Jiapeng Zhang</title>
    <summary>A decision list is an ordered list of rules. Each rule is specified by a term, which is a conjunction of literals, and a value. Given an input, the output of a decision list is the value corresponding to the first rule whole term is satisfied by the input. Decision lists generalize both CNFs and DNFs, and have been studied both in complexity theory and in learning theory.

The size of a decision list is the number of rules, and its width is the maximal number of variables in a term. We prove that decision lists of small width can always be approximated by decision lists of small size, where we obtain sharp bounds (up to constants). This in particular resolves a conjecture of Gopalan, Meka and Reingold (Computational Complexity, 2013) on DNF sparsification.

An ingredient in our proof is a new random restriction lemma, which allows to analyze how DNFs (and more generally, decision lists) simplify if a small fraction of the variables are fixed. This is in contrast to the more commonly used switching lemma, which requires most of the variables to be fixed.</summary>
    <updated>2019-10-06T11:20:34Z</updated>
    <published>2019-10-06T11:20:34Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-10-08T00:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/136</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/136" rel="alternate" type="text/html"/>
    <title>TR19-136 |  Quantum Query-to-Communication Simulation Needs a Logarithmic Overhead | 

	Sourav Chakraborty, 

	Arkadev Chattopadhyay, 

	Nikhil Mande, 

	Manaswi Paraashar</title>
    <summary>Buhrman, Cleve and Wigderson (STOC'98) observed that for every Boolean function $f : \{-1, 1\}^n \to \{-1, 1\}$ and $\bullet : \{-1, 1\}^2 \to \{-1, 1\}$ the two-party bounded-error quantum communication complexity of $(f \circ \bullet)$ is $O(Q(f) \log n)$, where $Q(f)$ is the bounded-error quantum query complexity of $f$. Note that the bounded-error randomized communication complexity of $(f \circ \bullet)$ is bounded by $O(R(f))$, where $R(f)$ denotes the bounded-error randomized query complexity of $f$. Thus, the BCW simulation has an extra $O(\log n)$ factor appearing that is absent in classical simulation. A natural question is if this factor can be avoided. H{\o}yer and de Wolf (STACS'02) showed that for the Set-Disjointness function, this can be reduced to $c^{\log^* n}$ for some constant $c$, and subsequently Aaronson and Ambainis (FOCS'03) showed that this factor can be made a constant. That is, the quantum communication complexity of the Set-Disjointness function (which is $NOR_n \circ \wedge$) is $O(Q(NOR_n))$.

Perhaps somewhat surprisingly, we show that when $ \bullet = \oplus$, then the extra $\log n$ factor in the BCW simulation is unavoidable. In other words, we exhibit a total function $F : \{-1, 1\}^n \to \{-1, 1\}$ such that $Q^{cc}(F \circ \oplus) = \Theta(Q(F) \log n)$.

To the best of our knowledge, it was not even known prior to this work whether there existed a total function $F$ and 2-bit function $\bullet$, such that $Q^{cc}(F \circ \bullet) = \omega(Q(F))$.</summary>
    <updated>2019-10-06T09:03:52Z</updated>
    <published>2019-10-06T09:03:52Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-10-08T00:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/10/05/future-faculty-fellow-postdoc-at-university-of-illinois-urbana-champaign-apply-by-february-1-2020/</id>
    <link href="https://cstheory-jobs.org/2019/10/05/future-faculty-fellow-postdoc-at-university-of-illinois-urbana-champaign-apply-by-february-1-2020/" rel="alternate" type="text/html"/>
    <title>Future Faculty Fellow/Postdoc at University of Illinois, Urbana-Champaign (apply by February 1, 2020)</title>
    <summary>The Department of Computer Science (CS) at the University of Illinois at Urbana-Champaign invites applications for the “Future Faculty” program. The Future Faculty Program is a selective program offering two-year postdoctoral positions whose goal is to mentor and prepare outstanding candidates for an academic career in research and teaching. Contact a theory faculty member if […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science (CS) at the University of Illinois at Urbana-Champaign invites applications for the “Future Faculty” program. The Future Faculty Program is a selective program offering two-year postdoctoral positions whose goal is to mentor and prepare outstanding candidates for an academic career in research and teaching. Contact a theory faculty member if interested.</p>
<p>Website: <a href="https://cs.illinois.edu/about-us/staff-positions#futurefaculty">https://cs.illinois.edu/about-us/staff-positions#futurefaculty</a><br/>
Email: chekuri@illinois.edu</p></div>
    </content>
    <updated>2019-10-05T21:36:12Z</updated>
    <published>2019-10-05T21:36:12Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-10-08T00:21:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/10/05/multiple-faculty-positions-at-university-of-illinois-urbana-champaign-apply-by-december-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/10/05/multiple-faculty-positions-at-university-of-illinois-urbana-champaign-apply-by-december-1-2019/" rel="alternate" type="text/html"/>
    <title>Multiple Faculty Positions at University of Illinois, Urbana-Champaign (apply by December 1, 2019)</title>
    <summary>The Department of Computer Science has multiple tenure track at all levels. Quantum Computing and Theory are among the priority areas. Website: https://cs.illinois.edu/about-us/faculty-positions Email: HR@cs.illinois.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science has multiple tenure track at all levels. Quantum Computing and Theory are among the priority areas.</p>
<p>Website: <a href="https://cs.illinois.edu/about-us/faculty-positions">https://cs.illinois.edu/about-us/faculty-positions</a><br/>
Email: HR@cs.illinois.edu</p></div>
    </content>
    <updated>2019-10-05T21:23:38Z</updated>
    <published>2019-10-05T21:23:38Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-10-08T00:21:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3427</id>
    <link href="https://agtb.wordpress.com/2019/10/05/blind-folks-and-the-evolving-elephant-by-vijay-vazirani/" rel="alternate" type="text/html"/>
    <title>Blind Folks and the Evolving Elephant – by Vijay Vazirani</title>
    <summary>One of my favorite parables ever since childhood was that of the four blind men and the elephant, with each man announcing the local image evoked in his mind’s eye on touching a different part of the elephant. This parable has provided an interesting metaphor even for serious scientific matters, a well-known one being wave-particle […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>One of my favorite parables ever since childhood was that of the four blind men and the elephant, with each man announcing the local image evoked in his mind’s eye on touching a different part of the elephant. This parable has provided an interesting metaphor even for serious scientific matters, a well-known one being wave-particle duality in physics.</p>
<p>But when it comes to matching markets, the parable has taken an unusual twist, with the proverbial elephant undergoing a metamorphosis of its own! The “blind men’’ in this case are entire disciplines which can lay claim to the field of matching markets. Of course, the obvious one is economics – the founders of this field, namely Gale and Shapley, were mathematical economists and <a href="https://www.nobelprize.org/prizes/economic-sciences/2012/summary/">the 2012 Nobel Prize in Economics</a> was awarded to Alvin Roth and Lloyd Shapley for work on these markets.</p>
<p>A key enabler was researchers in systems and networking. Their scientific revolutions of the Internet and mobile computing put matching markets on an exciting, new journey and their systems run these centralized markets on powerful computers.</p>
<p>The discipline of algorithm design has had an umbilical connection to matching markets: At the birth of this field lies the highly sophisticated <a href="https://www.tandfonline.com/doi/abs/10.4169/amer.math.monthly.120.05.386?journalCode=uamm20">Gale-Shapley</a> stable matching algorithm (1962), whose pivotal game-theoretic property of incentive compatibility follows as a free gift from polynomial time solvability — it was established <a href="http://pareto.uab.es/jmasso/pdf/DubinsFreedmanAMM1981.pdf">two decades</a> after the discovery of the algorithm! Yet most researchers, including those in theoretical computer science, are not aware that algorithm design is also a legitimate claimant to this field. Indeed, the very “engine’’ that runs almost each one of these markets is a <a href="https://simons.berkeley.edu/rmklectures2019-fall-1">sophisticated algorithm</a> chosen from the “gold mine’’ of matching theory! Besides stable matching, this includes maximum matching and online matching and their numerous variants.</p>
<p>Looking back at the huge expansion of matching markets over the last decade-and-a-half, one can see that all three disciplines were faced with numerous challenges: understanding the incentive structure of a new market; finding ways of dealing with terra-bytes of data, and choosing and delivering within milli-seconds the “right’’ ads to show with a user query; and designing an algorithm for the latest variant of online matching. And they all delivered!</p>
<p>The rich and diverse set of research talks given at the recent <a href="https://agtb.wordpress.com/2019/10/02/matching-markets-simons-driven-by-theory-driving-the-economy/">Simons program</a> on matching markets is proof enough that the elephant is still evolving!</p></div>
    </content>
    <updated>2019-10-05T20:08:09Z</updated>
    <published>2019-10-05T20:08:09Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>michalfeldman</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-10-08T00:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://adamsheffer.wordpress.com/?p=5454</id>
    <link href="https://adamsheffer.wordpress.com/2019/10/05/new-horizons-in-geometry-and-micha-sharir/" rel="alternate" type="text/html"/>
    <title>New Horizons in Geometry and Micha Sharir</title>
    <summary>Always wanted to visit Israel? Like discrete or computational geometry, and Micha Sharir? Considering what to do with this year’s travel funds? Join us in Tel Aviv! https://geometrynyc.wixsite.com/sharir (Open on a computer – does not support mobile yet.) If you can, please help us spread the word. Partial list of speakers: Pankaj Agarwal (Duke) Noga […]</summary>
    <updated>2019-10-05T15:55:19Z</updated>
    <published>2019-10-05T15:55:19Z</published>
    <category term="Math events"/>
    <author>
      <name>Adam Sheffer</name>
    </author>
    <source>
      <id>https://adamsheffer.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://adamsheffer.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://adamsheffer.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://adamsheffer.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://adamsheffer.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Discrete geometry and other typos</subtitle>
      <title>Some Plane Truths</title>
      <updated>2019-10-08T00:21:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/10/05/faculty-at-universidad-catolica-de-chile-apply-by-november-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/10/05/faculty-at-universidad-catolica-de-chile-apply-by-november-1-2019/" rel="alternate" type="text/html"/>
    <title>Faculty at Universidad Católica de Chile (apply by November 1, 2019)</title>
    <summary>OPEN POSITION AT THE INSTITUTE FOR MATHEMATICAL AND COMPUTATIONAL ENGINEERING (IMC) ,PONTIFICIA UNIVERSIDAD CATÓLICA DE CHILE We are offering a full-time position at the assistant or associate level. We invite highly qualified candidates in all areas of applied mathematics, including data science and machine learning. Website: http://imc.uc.cl/index.php/noticias/135-open-position-at-the-institute-for-mathematical-and-computational-engineering Email: pbarcelo@ing.puc.cl</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>OPEN POSITION AT THE<br/>
INSTITUTE FOR MATHEMATICAL AND COMPUTATIONAL<br/>
ENGINEERING (IMC) ,PONTIFICIA UNIVERSIDAD CATÓLICA DE CHILE</p>
<p>We are offering a full-time position at the assistant or associate level. We invite highly qualified candidates in all areas of applied mathematics, including data science and machine learning.</p>
<p>Website: <a href="http://imc.uc.cl/index.php/noticias/135-open-position-at-the-institute-for-mathematical-and-computational-engineering">http://imc.uc.cl/index.php/noticias/135-open-position-at-the-institute-for-mathematical-and-computational-engineering</a><br/>
Email: pbarcelo@ing.puc.cl</p></div>
    </content>
    <updated>2019-10-05T12:04:39Z</updated>
    <published>2019-10-05T12:04:39Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-10-08T00:21:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://grigory.github.io/blog/how-i-spent-last-summer</id>
    <link href="http://grigory.github.io/blog/how-i-spent-last-summer/" rel="alternate" type="text/html"/>
    <title xml:lang="en">How I Spent Last Summer FAQ</title>
    <content type="xhtml" xml:lang="en"><div xmlns="http://www.w3.org/1999/xhtml"><!--
<div align="center"><img alt="CAML" src="http://grigory.github.io/blog/pics/summer.png" width="400"></div>
-->

<p>I get a lot of questions about how I spent last summer. Normally I just take off to the Bay Area the day my last Spring class is over and fly back the day before my Fall class begins.
However, last summer I decided I’ve been in the US long enough to learn everything it has to offer and it was time to explore life across the pond and spend three months at the Alan Turing Institute in London. Then I had two interns coming over to Bloomington so I spent my first ever summer month here. 
Since it is that time of year, a quick reminder to <a href="https://cs.indiana.edu/apply/graduate-application.html">apply by Dec 15</a> if you are interested in doing a Ph.D. and stay tuned for the internship call announcement (probably similar deadline).</p>

<h1 id="summer-interns-in-bloomington">Summer Interns in Bloomington</h1>

<p>IU has started a <a href="https://sice.indiana.edu/research/student-research/fellowship.html">Global Talent Attraction Program (GTAP)</a> – fantastic program for international summer interns. The program gives you a $4000 stipend and you spend 2 months here at IU. There were a lot of strong applicants so it took me a while to interview all candidates. In the end, the two interns I got were <a href="https://codeforces.com/profile/Chameleon2460">Jakub Boguta</a> (U. Warsaw, ACM ICPC gold this year, must be tough to be in the lead for 4 hours and not win) and <a href="https://codeforces.com/profile/josdas">Stanislav Naumov</a> (SPb ITMO, ACM ICPC finalist, who spent summer at Google and just arrived on campus). Also, <a href="https://www.eleves.ens.fr/home/farthaud/">Farid Arthaud</a> joined us from ENS Paris, Ulm with a short recommendation of being “probably the best third-year CS student in France”. If you think you are the best in your country, have U.S. citizenship and don’t need to get paid, shoot me an email ;) Despite it being hot and humid here in Bloomington during the summer, we had a great time.</p>

<div align="center"><img alt="interns" src="http://grigory.github.io/blog/pics/interns.jpg" width="400"/></div>
<p><br/></p>

<p>We decided to dive into deep learning for image classification and figured out how to get more mileage out of standard pretrained neural nets by using them to produce hierarchical clusterings (with guarantees). If this sounds fun, you can apply for GTAP next year (picture by Farid).</p>

<div align="center"><img alt="hc" src="http://grigory.github.io/blog/pics/hc.png" width="400"/></div>

<h1 id="london-and-the-alan-turing-institute">London and the Alan Turing Institute</h1>

<p>Overall, this was a great experience as it quickly became clear that my neural net is overfit to the US lifestyle. I think of UK as throwing in some perturbations to your visual and verbal input (some may seem adversarial, but mostly just random) which, as we know, is good for robustness, generalization and what not.</p>

<ul>
  <li><b>Q</b>: Is grass greener there? <b>A</b>: Yes, of course. Especially, if you live next to the Regent’s Park.</li>
  <li><b>Q</b>: Is it your cup of tea? <b>A</b>: No, I still only function on Redbull, but the afternoon teas are a great experience. Proximity to cutting-edge tech, CS research and startups still matters most to me. However, if you are into math or finance, your mileage will almost certainly vary. Also, London seems perfect for a short-term visit/sabbatical, especially if you want to take a break from the tech hype, write a book, explore Europe, etc.</li>
  <li><b>Q</b>: What’s up with the <a href="https://www.turing.ac.uk/">Alan Turing Institute</a> and DeepMind? <b>A</b>: These two are probably the most happening places in the UK right now in academia and industry respectively. They are within a 5-minute walk from each other in King’s Cross. I was staying right across the road and it was perfect except for no AC. ATI serves as a meeting hub for researchers from all of the top UK schools (Cambridge, Oxford, Warwick, UCL, Edinburgh, etc.).
ATI is based inside the British library, which was the largest public building constructed in the UK in the 20th century. ATI has its own space inside the library which is equipped similarly to Google/FB offices. Except no free food, only drinks – would you want to have free British food anyway?</li>
</ul>

<div align="center"><img alt="ati" src="http://grigory.github.io/blog/pics/ati.jpg" width="400"/></div>
<p><br/></p>
<div align="center"><img alt="bl" src="http://grigory.github.io/blog/pics/bl.jpg" width="400"/></div>

<ul>
  <li><b>Q</b>: Is Shoreditch the most hip neighborhood? <b>A</b>: I think so, best Sci-Fi graffiti ever.</li>
</ul>

<div align="center"><img alt="murals" src="http://grigory.github.io/blog/pics/mural.jpg" width="400"/></div>

<ul>
  <li><b>Q</b>: Did you meet the King? <b>A</b>: Yes, in Heathrow I ran into a 250-pound dude from Atlanta who made it quite clear that’s him by wearing one of these (except in a larger font and in dirty red color).</li>
</ul>

<div align="center"><img alt="king" src="http://grigory.github.io/blog/pics/king.jpg" width="400"/></div>

<ul>
  <li><b>Q</b>: <a href="https://www.youtube.com/watch?v=ViHsfeXNgjY">Is Paris still Paris?</a> <b>A</b>: I think so (my third time). K and I took a 2-hour train down there directly from King’s Cross (St. Pancras station, another reason to stay in King’s Cross). We’ve enjoyed our time greatly, especially in Versailles and ENS Paris, Ulm. The Salvador Dali Museum in Montmartre was another highlight of this trip.</li>
</ul>

<div align="center"><img alt="versailles" src="http://grigory.github.io/blog/pics/versailles.jpg" width="400"/></div>

<ul>
  <li><b>Q</b>: Brexit, Boris Johnson? <b>A</b>: Locals made fun of me for having never heard of Boris Johnson. <a href="https://www.youtube.com/watch?v=dXyO_MC9g3k">Is there much to know anyway</a>?</li>
</ul>


  <p><a href="http://grigory.github.io/blog/how-i-spent-last-summer/">How I Spent Last Summer FAQ</a> was originally published by Grigory Yaroslavtsev at <a href="http://grigory.github.io/blog">The Big Data Theory</a> on October 05, 2019.</p></div>
    </content>
    <updated>2019-10-05T00:00:00Z</updated>
    <published>2019-10-05T00:00:00Z</published>
    <author>
      <name>Grigory Yaroslavtsev</name>
      <email>grigory@grigory.us</email>
      <uri>http://grigory.github.io/blog</uri>
    </author>
    <source>
      <id>http://grigory.github.io/blog/</id>
      <author>
        <name>Grigory Yaroslavtsev</name>
        <email>grigory@grigory.us</email>
        <uri>http://grigory.github.io/blog/</uri>
      </author>
      <link href="http://grigory.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="http://grigory.github.io/blog" rel="alternate" type="text/html"/>
      <title xml:lang="en">The Big Data Theory</title>
      <updated>2019-10-05T20:27:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/135</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/135" rel="alternate" type="text/html"/>
    <title>TR19-135 |  Doubly-Efficient Pseudo-Deterministic Proofs | 

	Dhiraj Holden, 

	Shafi Goldwasser, 

	Michel Goemans</title>
    <summary>In [20] Goldwasser, Grossman and Holden  introduced pseudo-deterministic interactive proofs for search problems where a powerful prover can convince a probabilistic polynomial time verifier that a solution to a search problem is canonical.  They studied  search problems for which polynomial time algorithms are not known and for which many solutions are possible. They showed that whereas there exists a constant round pseudo deterministic proof for graph isomorphism where the canonical solution is the lexicographically smallest isomorphism, the existence of pseudo-deterministic interactive proofs for NP-hard problems would imply the collapse of the polynomial time hierarchy.

In this paper, we turn our attention to studying  doubly-efficient pseudo-deterministic proofs for polynomial time search problems:  pseudo-deterministic proofs with the extra requirement that the prover runtime is polynomial  and the verifier runtime to verify that a solution is canonical is significantly lower  than the complexity of finding any solution, canonical or otherwise. Naturally this question is particularly interesting for search problems for which a lower bound on its worst case complexity  is known or has been widely conjectured. 

We show doubly-efficient pseudo-deterministic algorithms for a host of natural problems whose complexity has long been conjectured. In particular:

We show a doubly efficient pseudo-deterministic proof for linear programming where the canonical solution which the prover will provide is  the lexicographically greatest optimal solution for the LP. To this end, we show how through perturbing the linear program and strong duality this solution can be both  computed efficiently by the prover, and verified by the verifier.  
The time of the verifier is $O(d^2 )$ for a linear program with integer data and at most $d$ variables and constraints, whereas the time to solve such linear program is $\tilde{O}(d^{\omega} )$ by randomized algorithms [11] for $\omega$  the exponent for fast matrix multiplication .


We show a doubly efficient pseudo-deterministic proof for 3-SUM and problems reducible to 3-SUM where the prover is a $O(n^2)$ time algorithm and the verifier takes time $\tilde{O}(n^{1.5})$. 


We show a doubly-efficient pseudo-deterministic proof for the hitting set problem} where the verifier runs in time $\tilde{O}(m)$ and the prover runs in time $\tilde{O}(m^2)$ where $ m = \sum_{S \in \mathcal{S}} |S| + \sum_{T \in \mathcal{T}} |T|$ for inputs  collections of sets $\mathcal{S}, \mathcal{T}$.

We show a doubly-efficient pseudo-deterministic proof for the Zero Weight Triangle problem where the verifier runs in time $\tilde{O}(n^{2 + \omega/3})$ and the prover runs in randomized time $\tilde{O}(n^3)$. The Zero Weight Triangle problem is equivalent to the All-Pairs Shortest Path problem, a well-studied problem that is the foundation of many hardness results in graph algorithms [39,38], under sub-cubic reductions.</summary>
    <updated>2019-10-04T15:50:06Z</updated>
    <published>2019-10-04T15:50:06Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-10-08T00:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/134</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/134" rel="alternate" type="text/html"/>
    <title>TR19-134 |  Finding monotone patterns in sublinear time | 

	Omri Ben-Eliezer, 

	Clement Canonne, 

	Shoham Letzter, 

	Erik Waingarten</title>
    <summary>We study the problem of finding monotone subsequences in an array from the viewpoint of sublinear algorithms. For fixed $k \in \mathbb{N}$ and $\varepsilon &gt; 0$, we show that the non-adaptive query complexity of finding a length-$k$ monotone subsequence of $f \colon [n] \to \mathbb{R}$, assuming that $f$ is $\varepsilon$-far from free of such subsequences, is $\Theta((\log n)^{\lfloor \log_2 k \rfloor})$. Prior to our work, the best algorithm for this problem, due to Newman, Rabinovich, Rajendraprasad, and Sohler (2017), made $(\log n)^{O(k^2)}$ non-adaptive queries; and the only lower bound known, of $\Omega(\log n)$ queries for the case $k = 2$, followed from that on testing monotonicity due to Erg\"un, Kannan, Kumar, Rubinfeld, and Viswanathan (2000) and Fischer (2004).</summary>
    <updated>2019-10-04T15:42:39Z</updated>
    <published>2019-10-04T15:42:39Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-10-08T00:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/10/04/postdoc-at-university-of-warwick-uk-apply-by-december-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/10/04/postdoc-at-university-of-warwick-uk-apply-by-december-1-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Warwick, UK (apply by December 1, 2019)</title>
    <summary>We invite applications for a postdoc position hosted by Tom Gur at the University of Warwick, United Kingdom, in the fields of sublinear-time algorithms, coding theory, interactive and probabilistically checkable proofs, and complexity theory. Please contact Tom Gur directly with your CV. The start date is flexible. Website: https://www.dcs.warwick.ac.uk/~tomgur/ Email: tom.gur@warwick.ac.uk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We invite applications for a postdoc position hosted by Tom Gur at the University of Warwick, United Kingdom, in the fields of sublinear-time algorithms, coding theory, interactive and probabilistically checkable proofs, and complexity theory.</p>
<p>Please contact Tom Gur directly with your CV. The start date is flexible.</p>
<p>Website: <a href="https://www.dcs.warwick.ac.uk/~tomgur/">https://www.dcs.warwick.ac.uk/~tomgur/</a><br/>
Email: tom.gur@warwick.ac.uk</p></div>
    </content>
    <updated>2019-10-04T13:10:04Z</updated>
    <published>2019-10-04T13:10:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-10-08T00:21:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3425</id>
    <link href="https://agtb.wordpress.com/2019/10/04/highlights-beyond-ec-call-for-nominations/" rel="alternate" type="text/html"/>
    <title>Highlights Beyond EC – Call for Nominations</title>
    <summary>The 21st ACM Conference on Economics and Computation (EC’20) will host a special plenary session highlighting some of the best work in economics and computation that appears in conferences and journals other than EC, or mature working papers. The intention of this session is to expose EC attendees to related work just beyond the boundary of their […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The <a href="http://ec20.sigecom.org/">21st ACM Conference on Economics and Computation</a> (EC’20) will host a special <strong>plenary session</strong> highlighting some of the best work in economics and computation that appears in conferences and journals other than EC, or mature working papers. The intention of this session is to expose EC attendees to related work just beyond the boundary of their current awareness. We seek nominations for papers in Economics and Computation that have made breakthrough advances, opened up new horizons for research, made interesting connections between different scientific areas, or had significant impact on practice. Examples of relevant conferences and journals include STOC/FOCS/SODA/ITCS, AAAI/IJCAI/AAMAS, NIPS/ICML/COLT, WWW/KDD, AER/Econometrica/JPE/QJE/RESTUD/TE/AEJ Micro/JET/GEB, and Math of OR/Management Science/Operations Research.</p>
<p><strong>Who can nominate? </strong>This call is open to everyone (self-nominations are also allowed), but we particularly encourage members of PCs or editorial boards in various venues to submit nominations.</p>
<p><strong>Deadline:</strong> December 23, 2019.</p>
<p><strong>Nomination format:</strong> Nominations should be emailed to <a href="mailto:HighlightsBeyondEC@gmail.com">HighlightsBeyondEC2020@gmail.com</a>, and should include:</p>
<ul>
<li>Paper title and author names.</li>
<li>Publication venue or online working version. Preference will be given to papers that have appeared in a related conference or journal within the past two years, or have a working version circulated within the past two years.</li>
<li>A short (2-3 paragraph) justification letter, explaining the significance of the paper.</li>
<li>Names of 1-3 experts on the area of the paper.</li>
</ul>
<p><strong>Committee members:</strong></p>
<ul>
<li><strong>Michal Feldman </strong>(Tel Aviv University)</li>
<li><strong>Hervé Moulin</strong> (University of Glasgow)</li>
<li><strong>Michael Wellman </strong>(University of Michigan)</li>
<li><strong>Adam Wierman </strong>(California Institute of Technology)</li>
</ul></div>
    </content>
    <updated>2019-10-04T06:05:58Z</updated>
    <published>2019-10-04T06:05:58Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>michalfeldman</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-10-08T00:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1192</id>
    <link href="https://ptreview.sublinear.info/?p=1192" rel="alternate" type="text/html"/>
    <title>News for Sept 2019</title>
    <summary>Five Six papers this month: results on testing separations, linearity testing in \(\mathbb{R}^n\), testing for regular languages, graph property testing, topological property testing, and Boolean rank. Hard properties with (very) short PCPPs and their applications, by Omri Ben-Eliezer, Eldar Fischer, Amit Levi, and Ron D. Rothblum (arXiv). Probably, the most significant takeaway from this work is a (largest […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><s>Five</s> Six papers this month: results on testing separations, linearity testing in \(\mathbb{R}^n\), testing for regular languages, graph property testing, topological property testing, and Boolean rank. </p>



<p><strong>Hard properties with (very) short PCPPs and their applications</strong>, by Omri Ben-Eliezer, Eldar Fischer, Amit Levi, and Ron D. Rothblum (<a href="https://eccc.weizmann.ac.il/report/2019/088/">arXiv</a>). Probably, the most significant takeaway from this work is a (largest possible) separation between standard and tolerant property testing. PCPPs (Probabilistically Checkable Proofs of Proximity) are the “NP” variant of property testing, where the tester is aided by a proof string. Consider property \(\mathcal{P}\). If \(x \in \mathcal{P}\), there must be a proof string that makes the tester accept (with probability 1). If \(x\) is far from \(\mathcal{P}\) (in the usual property testing sense), for any proof string, the tester must reject with sufficiently high probability. PCPPs have played a role in the classical constructions of PCPs, but have also found uses in getting a better understanding of property testing itself. And this paper shows how PCPP constructions can be used to get property testing separations. The main result in this paper is a property \(\mathcal{P}\) that (basically) requires \(\Omega(n)\) queries to “property test”, but has a PCPP system where the proof length is \(\widetilde{O}(n)\). (\(n\) is the input length.) The main construction uses collections of random linear codes. Significantly, these constructions show a strong separation between standard vs tolerant property testing, and standard vs erasure-resilient property testing. (The latter is a recent variant by <a href="https://epubs.siam.org/doi/abs/10.1137/16M1075661?journalCode=smjcat">Dixit et al</a>, where certain parts of the input are hidden from the tester.) There is a property that is testable in a constant number of queries, but requires \(\widetilde{\Omega}(n)\) queries to test tolerantly (for any non-trivial choice of parameters). An analogous result holds for erasure-resilient testing.</p>



<p><strong>Distribution-Free Testing of Linear Functions on R^n</strong>, by Noah Fleming and Yuichi Yoshida (<a href="https://arxiv.org/abs/1909.03391">arXiv</a>). Linearity testing is arguably <em>the</em> canonical problem in property testing, yet there is still much to be learned about it. This paper considers functions \(f: \mathbb{R}^n \to \mathbb{R}\), and the <em>distribution-free setting</em>. (In this setting, distance is measured according is an unknown distribution \(\mathcal{D}\) over the input, and the tester can access samples from this distribution. For \(\mathbb{R}^n\), the “standard” distribution would the \(n\)-dimensional Gaussian.) The main result is that linearity testing can be done in the distribution-free setting with \(\widetilde{O}(1/\varepsilon)\) queries, assuming that the distribution is continuous. The primary technical tool, an interesting result in its own right, is that additivity \((f(x+y) = f(x) + f(y))\) can be tested in \(\widetilde{O}(1/\varepsilon)\) queries. The significance of the testing result is cemented by an \(\Omega(n)\) lower bound for sample-based testers.</p>



<p><strong>Sliding window property testing for regular languages</strong> by Moses Ganardi, Danny Hucke, Markus Lohrey, Tatiana Starikovskaya (<a href="https://arxiv.org/abs/1909.10261">arXiv</a>). Fix a regular language \(\mathcal{R}\). Consider the streaming model, and the basic question of recognizing whether the string (being streamed) is in \(\mathcal{R}\). Simple, you will say! Run the DFA recognizing \(\mathcal{R}\) in constant space. Now, suppose there is a sliding window length of \(n\). The aim is to determine if the past \(n\) symbols (the “active window”) form a string in \(\mathcal{R}\). Suprisingly (at least to me), there is a full characterization of the space required for randomized algorithms, and (depending on \(\mathcal{R}\)), it is either \(\Theta(1)\), \(\Theta(\log\log n)\), \(\Theta(\log n)\), or \(\Theta(n)\).  In the interest of beating these lower bounds, suppose we wish to property test on the active window. It turns out the answer is quite nuanced. There are deterministic \(O(\log n)\)-space testers and randomized two-sided \(O(1/\varepsilon)\)-space testers for all regular languages. For randomized one-sided testers, there are multiple possibilities for the optimal space complexity, and there is a full characterization of these regular languages.</p>



<p><strong>A characterization of graph properties testable for general planar graphs with one-sided error (It’s all about forbidden subgraphs)</strong> by Artur Czumaj and Christian Sohler (<a href="https://arxiv.org/pdf/1909.10647.pdf">arXiv</a>). Property testing of sparse graphs has been receiving more attention, but most results focus on the bounded degree setting. Unfortunately, many of these results break quite dramatically on sparse graphs with unbounded degrees. This paper focuses on property testing, within the class of unbounded degree planar graphs. (Meaning, the input is always assumed to be planar.) The results achieve a significant goal: as the title suggests, there is a complete characterization of properties that are constant-query testable with one-sided error. The easier part is in showing that all such properties can be reduced to testing \(H\)-freeness. The harder (remarkable) result is \(H\)-freeness can be tested in general planar queries with constant queries. (This is non-trivial even for triangle-freeness.) And, as is easy to conjecture but hard to prove, these results carry over for all minor-closed families.  As a small indication of the challenge, most testers for bounded-degree graphs work by doing constant depth BFSes. When high degree vertices are present, this method fails, and we really need new ideas to deal with such graphs.</p>



<p><strong>Near Coverings and Cosystolic Expansion – an example of topological property testing</strong> by Irit Dinur and Roy Meshulam (<a href="https://eccc.weizmann.ac.il/report/2019/126/">ECCC</a>). In most algebraic settings, property testing results can be seen as local to global theorems. When do local constraints on a large object imply a global condition? This paper gives a topological instantiation of this phenomenon. We need to define the <em>cover</em> of a simplicial complex \(X\). For concreteness, think of a 2D simplicial complex \(X\), which is a hypergraph with hyperedges of size at most 3, where subsets of hyperedges are also present. A 2-cover is a simplicial complex \(X’\) with the following property. It has two copies of each vertex of \(X\). Each hyperedge of \(X\) must have two “corresponding” disjoint copies in \(X’\). Let the copies of vertex \(v\) be \(v_0, v_1\). Then, for every hyperedge (say) \((u,v,w)\) of \(X\), there must be two disjoint hyperedges in \(X’\) involving copies of the corresponding vertices. One can consider the property testing twist: if the neighborhoods of “most” vertices \(v\) in \(X\) satisfy these condition (with respect to the neighborhoods of the copies of \(v\) in \(X’\)), then is \(X’\) close to being a cover of \(X\)? Indeed, this paper proves that such a “property testing condition” holds iff \(X\) is a high-dimensional expander.</p>



<p><strong>Property testing of the Boolean and binary rank</strong> by Michal Parnas, Dana Ron, and Adi Shraibman (<a href="https://arxiv.org/abs/1908.11632">arXiv</a>). The Boolean rank of a matrix \(M\) is a fundamental quantity that appears in many lower bound constructions. (Recall that an \(n \times m\) Boolean matrix \(M\) has a rank \(r\) if \(M\) can be expressed as \(X \cdot Y\), where \(X \in \mathbb{F}_2^{n \times d}\) and \(Y \in \mathbb{F}_2^{d \times m}\).) In the real-valued setting, results show that one can property test rank in \(poly(d/\varepsilon)\) queries. This paper proves an analogous result for the Boolean rank. There is a surprise element here: over reals, the rank can be computed in polynomial time, and many of the geometric intuitions can be brought over to the property testing problem. On the other hand, the Boolean rank is NP-hard to compute exactly, yet we can still get a tester with \(poly(d)\) query complexity. The paper also gives results for <em>binary rank</em>. For the binary rank, we require the component matrices \(X, Y\) to be Boolean, but algebraic operations are over the reals. In the case, the tester has query complexity \(2^{2d}\) (with varying dependencies on \(\varepsilon\) for adaptive/non-adaptive testers). The intriguing open problem is whether \(poly(d)\)-query testers exist for binary rank.</p>



<p> </p></div>
    </content>
    <updated>2019-10-04T05:54:43Z</updated>
    <published>2019-10-04T05:54:43Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Seshadhri</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2019-10-08T00:08:35Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3615744836127152440</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3615744836127152440/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/10/quantum-supremacy-guest-post-by-abhinav.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3615744836127152440" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3615744836127152440" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/10/quantum-supremacy-guest-post-by-abhinav.html" rel="alternate" type="text/html"/>
    <title>Quantum Supremacy: A Guest Post by Abhinav Deshpande</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I am delighted to introduce you to Abhinav Deshpande, who is a graduate student at the University of Maryland, studying Quantum Computing. This will be a guest post on the rumors of the recent Google breakthrough on Quantum Supremacy. For other blog posts on this exciting rumor, see <a href="https://www.scottaaronson.com/blog/?p=4317">Scott Aaronson's post</a>, <a href="https://www.scottaaronson.com/blog/?p=4342">Scott Aaronson's second post on it</a>, <a href="https://www.quantamagazine.org/john-preskill-explains-quantum-supremacy-20191002/">John Preskill's quanta article</a>, <a href="https://blog.computationalcomplexity.org/2019/09/quantum-supremacy.html">Fortnow's post</a>,<br/>
and there may be others.<br/>
<br/>
Guest post by Abhinav:<br/>
<br/>
I (Abhinav) thank Bill Fefferman for help with this post, and Bill Gasarch for inviting me to do a guest post.<br/>
<br/>
<br/>
<b>The quest towards quantum computational supremacy</b><br/>
<br/>
September saw some huge news in the area of quantum computing, with rumours that the Google AI Lab has achieved a milestone known as 'quantum computational supremacy', also termed 'quantum supremacy' or 'quantum advantage' by some authors. Today, we examine what this term means, the most promising approach towards achieving this milestone, and the best complexity-theoretic evidence we have so far against classical simulability of quantum mechanics. We will not be commenting on details of the purported paper since there is no official announcement or claim from the authors so far.<br/>
<br/>
<b>What it means</b><br/>
<br/>
First off, the field of quantum computational supremacy arose from trying to formally understand the differences in the power of classical and quantum computers. A complexity theorist would view this goal as trying to give evidence to separate the complexity classes BPP and BQP. However, it turns out that one can gain more traction from considering the sampling analogues of these classes, SampBPP and SampBQP.  These are classes of distributions that can be efficiently sampled on classical and quantum computers, respectively. Given a quantum circuit U on n qubits, one may define an associated probability distribution over 2^n outcomes as follows: apply U to the fiducial initial state |000...0&gt; and measure the resulting state in the computational basis. This produces a distribution D_U.<br/>
<br/>
A suitable way to define the task of simulating the quantum circuit is as follows<b style="font-style: italic;">:</b><br/>
<br/>
Input: Description of a quantum circuit U acting on n qubits.<br/>
<br/>
Output: A sample from the probability distribution D_U obtained by measuring U|000...0&gt; in the computational basis.<br/>
<br/>
One of the early works in this field was that of <a href="https://arxiv.org/abs/quant-ph/0205133">Terhal and DiVincenzo</a>, which first considered the complexity of sampling from a distribution (weak simulation) as opposed to that of calculating the exact probability of a certain outcome (strong simulation). Weak simulation is arguably the more natural notion of simulating a quantum system, since in general, we cannot feasibly compute the probability of a certain outcome even if we can simulate the quantum circuit. Subsequent works by <a href="https://arxiv.org/abs/1011.3245">Aaronson and Arkhipov</a>, and by <a href="https://arxiv.org/abs/1005.1407">Bremner, Jozsa, and Shepherd</a> established that if there is a classically efficient weak simulator for different classes of quantum circuits, the polynomial hierarchy collapses to the third level.<br/>
<br/>
<br/>
So far, we have only considered the question of exactly sampling from the distribution D_U. However, any realistic experiment is necessarily noisy, and a more natural problem is to sample from a distribution that is not exactly D_U but from any distribution D_O that is ε-close in a suitable distance measure, say the variation distance.<br/>
<br/>
The aforementioned work by Aaronson and Arkhipov was the first to consider this problem, and they made progress towards showing that a special class of quantum circuits (linear optical circuits) is classically hard to approximately simulate in the sense above. The task of sampling from the output of linear optical circuits is known as boson sampling. At the   time, it was the best available way to show that quantum computers  may solve some problems that are far beyond the reach of classical computers.<br/>
<br/>
Even granting that the PH doesn't collapse, one still needs to make an additional conjecture to establish that boson sampling is not classically simulable.  The conjecture is that additively approximating the output probabilities of a random linear optical quantum circuit is #P-hard.  The reason this may be true is that output probabilities of random linear optical quantum circuits are Permanents of a Gaussian random matrix, and the Permanent is as hard to compute on a random matrix as it is on a worst-case matrix. Therefore, the only missing link is to go from average-case hardness of exact computation to average-case hardness of an additive estimation. In addition, if we make a second conjecture known as the "anti-concentration" conjecture, we can show that this additive estimation is non-trivial: it suffices to give us a good multiplicative estimation with high probability.<br/>
<br/>
So that's what quantum computational supremacy is about: we have a computational task that is efficiently solvable with quantum computers, but which would collapse the polynomial hierarchy if done by a classical computer (assuming certain other conjectures are true). One may substitute "collapse of the polynomial hierarchy" with stronger conjectures and incur a corresponding tradeoff in the likelihood of the conjecture being true.<br/>
<br/>
<b>Random circuit sampling</b><br/>
<br/>
In 2016,<a href="https://arxiv.org/abs/1608.00263"> Boixo et al</a>. proposed to replace the class of quantum circuits for which some hardness results were known (commuting circuits and boson sampling) by random circuits of sufficient depth on a 2D grid of qubits having nearest-neighbour interactions. Concretely, the proposed experiment would be to apply random unitaries from a specified set on n qubits arranged on a 2D grid for sufficient depth, and then sample from the resulting distribution. The two-qubit unitaries in the set are restricted to act between nearest neighbours, respecting the geometric This task is called random circuit sampling (RCS).<br/>
<br/>
At the time, the level of evidence for the hardness of this scheme was not yet the same as the linear optical scheme. However, given the theoretical and experimental interest in the idea of demonstrating a quantum speedup over classical computers, subsequent works by<a href="https://arxiv.org/abs/1803.04402"> Bouland, Fefferman, Nirkhe and Vazirani</a>, and <a href="https://arxiv.org/abs/1809.06957">Harrow and Mehraban</a> bridged this gap (the relevant work by <a href="https://arxiv.org/abs/1612.05903">Aaronson and Chen</a> will be discussed in the following section). Harrow and Mehraban proved anticoncentration for random circuits. In particular, they showed that a 2-dimensional grid of n qubits achieve anticoncentration in depth O(\sqrt{n}), improving upon earlier results with higher depth due to <a href="https://arxiv.org/abs/1208.0692">Brandao, Harrow and Horodeck</a>i. Bouland et al. proved the same supporting evidence for RCS as that for boson sampling, namely a worst-to-average-case reduction for exactly computing most output probabilities, even without the permanent structure possessed by linear optical quantum circuits.<br/>
<br/>
<b>Verification</b><br/>
<br/>
So far, we have not discussed the elephant in the room: of verifying that the output distribution supported on 2^n outcomes. It turns out that there are concrete lower bounds such as those due to Valiant and Valiant, showing that verifying whether an empirical distribution is close to a target distribution is impossible if one has few samples.<br/>
<br/>
Boixo et al. proposed a way of certifying the fidelity of the purported simulation. Their key observation was to note that if their experimental system is well modelled by a noise model called global depolarising noise, estimating the output fidelity is possible with relatively few outcomes. Under global depolarising noise with fidelity f, the noisy distribution takes the form D_N = f D_U + (1-f) I, where I is the uniform distribution over the 2^n outcomes. Together with another empirical observation about the statistics of output probabilities of the ideal distribution D_U, they argued that computing the following cross-entropy score would serve as a good estimator of the fidelity:<br/>
<br/>
f ~ H(I, D_U) - H(D_exp, D_U), where H(D_A,D_B) is the cross-entropy between the two distributions: H(D_A, D_B) = -\sum_i p_A log (p_B).<br/>
<br/>
The proposal here was to experimentally collect several samples from D_exp, classically compute using brute-force the probabilities of these outcomes in the distribution D_U, and estimate the cross-entropy using this information. If the test outputs a high score for a computation on sufficiently many qubits and depth, the claim is that quantum supremacy has been achieved.<br/>
<br/>
Aaronson and Chen gave alternative form of evidence for the hardness of scoring well on a test that aims to certify quantum supremacy similar to the manner above. This sidesteps the issue of whether a test similar to the one above does indeed certify the fidelity. The specific problem considered was "Heavy Output Generation" (HOG), the problem of outputting strings that have higher than median probability in the output distribution. Aaronson and Chen linked the hardness of HOG to a closely related problem called "QUATH", and conjectured that QUATH is hard for classical computers.<br/>
<br/>
<b>Open questions</b><br/>
<br/>
Assuming the Google team has performed the impressive feat of both running the experiment outlined before and classically computing the probabilities of the relevant outcomes to see a high score on their cross-entropy test, I discuss the remaining positions a skeptic might take regarding the claim about quantum supremacy.<br/>
<br/>
"The current evidence of classical hardness of random circuit sampling is not sufficient to conclude that the task is hard". Assuming that the skeptic believes that the polynomial hierarchy does not collapse, a remaining possibility is that there is no worst-to-average-case reduction for the problem of *approximating* most output probabilities, which kills the proof technique of Aaronson and Arkhipov to show hardness of approximate sampling.<br/>
<br/>
"The cross-entropy proposal does not certify the fidelity." Boixo et al. gave numerical evidence and other arguments for this statement, based on the observation that the noise is of the global depolarising form. A skeptic may argue that the assumption of global depolarising noise is a strong one.<br/>
<br/>
"The QUATH problem is not classically hard." In order to give evidence for the hardness of QUATH, Aaronson and Chen examined the best existing algorithms for this problem and also gave a new algorithm that nevertheless do not solve QUATH with the required parameters.<br/>
<br/>
It would be great if the community could work towards strengthening the evidence we already have for this task to be hard, either phrased as a sampling experiment or together with the verification test.<br/>
<br/>
Finally, I think this is an exciting time for quantum computing and to witness this landmark event. It may not be the first probe of an experiment that is "hard" to classically simulate, since there are many quantum experiments that are beyond the reach of current classical simulations, but the inherent programmability and control present in the experimental system is what enables the tools of complexity theory to be applied to the problem. A thought that fascinates me is the idea that we may be exploring quantum mechanics in a regime never probed this carefully before, the "high complexity regime" of quantum mechanics. One imagines there are important lessons in physics here.<br/>
<br/></div>
    </content>
    <updated>2019-10-03T19:41:00Z</updated>
    <published>2019-10-03T19:41:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-10-07T19:40:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=18199</id>
    <link href="https://gilkalai.wordpress.com/2019/10/03/noisy-quantum-circuits-how-do-we-know-that-we-have-robust-experimental-outcomes-at-all-and-do-we-care/" rel="alternate" type="text/html"/>
    <title>Noisy quantum circuits: how do we know that we have robust experimental outcomes at all? (And do we care?)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In a recent post we discussed Google’s claim of achieving “quantum supremacy” and my reasons to think that these claims will not stand. (See also this comment for necessary requirements from a quantum supremacy experiment.) This debate gives a good … <a href="https://gilkalai.wordpress.com/2019/10/03/noisy-quantum-circuits-how-do-we-know-that-we-have-robust-experimental-outcomes-at-all-and-do-we-care/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In <a href="https://gilkalai.wordpress.com/2019/09/23/quantum-computers-amazing-progress-google-ibm-and-extraordinary-but-probably-false-supremacy-claims-google/">a recent post we discussed Google’s claim of achieving “quantum supremacy” and my reasons to think that these claims will not stand.</a> (See also <a href="https://gilkalai.wordpress.com/2019/09/23/quantum-computers-amazing-progress-google-ibm-and-extraordinary-but-probably-false-supremacy-claims-google/#comment-61043">this comment</a> for necessary requirements from a quantum supremacy experiment.) This debate gives a good opportunity to discuss some conceptual issues regarding sampling, probability distributions, statistics, and computational complexity. This time we will discuss <span style="color: #ff0000;">chaotic behavior vs. robust experimental outcomes.</span></p>
<p>On unrelated matter, I just heard Shachar Lovett’s very beautiful TCS+ lecture on the sunflower conjecture (<a href="https://gilkalai.wordpress.com/2019/08/23/amazing-ryan-alweiss-shachar-lovett-kewen-wu-jiapeng-zhang-made-dramatic-progress-on-the-sunflower-conjecture/">see this post</a> on the Alweiss, Lovett, Wu, and Zhang’s breakthrough). You can see the lecture and many others on the <a href="https://www.youtube.com/user/TCSplusSeminars/videos">TCS+ you tube channel</a>.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/10/cern-slide-30c.png"><img alt="" class="alignnone size-full wp-image-18240" height="449" src="https://gilkalai.files.wordpress.com/2019/10/cern-slide-30c.png?w=640&amp;h=449" width="640"/></a></p>
<p style="text-align: center;"><span style="color: #ff0000;"><span style="color: #993366;">Slide 30 from my August, ’19 CERN lecture: predictions of near-term experiments. (Here is the</span> <a href="https://gilkalai.files.wordpress.com/2019/09/cern.pptx">full powerpoint presentation</a><span style="color: #993366;">.) In this post we mainly</span> <strong>discuss</strong> <strong>point b) about chaotic behavior. </strong><span style="color: #800080;">See also <a href="https://arxiv.org/abs/1908.02499">my paper: The argument against quantum computers</a>.</span></span></p>
<p>Consider an experiment aimed for establishing quantum supremacy: your quantum computer produced a sample <img alt="x_i" class="latex" src="https://s0.wp.com/latex.php?latex=x_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_i"/> which is a 0-1 string of length <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> from a certain distribution <img alt="D_i" class="latex" src="https://s0.wp.com/latex.php?latex=D_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_i"/>. The research assumption is that <img alt="D_i" class="latex" src="https://s0.wp.com/latex.php?latex=D_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_i"/>  is close enough to a fixed distribution <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D"/> (<img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D"/> accounts for the computing process and the noise) which is very hard to be demonstrated on a classical computer. By looking at a large number of samples you can perform a statistical test on the samples to verify that they were (approximately) sampled from <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D"/>, or at least that they were sampled from a probability distribution that is very hard to be computed on a classical computer!</p>
<p>But, is it possible that all the distributions <img alt="D_i" class="latex" src="https://s0.wp.com/latex.php?latex=D_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_i"/>‘s are very different? Namely that each sample is taken from a completely different distribution? More formally, is it possible  that under a correct modeling of the device for two different samples <img alt="x_i" class="latex" src="https://s0.wp.com/latex.php?latex=x_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_i"/> and <img alt="x_j" class="latex" src="https://s0.wp.com/latex.php?latex=x_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_j"/>, <img alt="D_i" class="latex" src="https://s0.wp.com/latex.php?latex=D_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_i"/> has a very small correlation with <img alt="D_j" class="latex" src="https://s0.wp.com/latex.php?latex=D_j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_j"/>? In this case we say that the experiment outcomes are <strong>not robust</strong> and that the situation is <strong>chaotic</strong>.</p>
<p>Here are a couple of questions that I propose to think about:</p>
<ul>
<li>How do we test robustness?</li>
<li>Do the supremacy experiments require that the experiment is robust?</li>
<li>If, after many samples, you reach a probability distribution that require exponential time on a classical computer should you worry about the question whether the experiment is robust?</li>
<li><span style="color: #0000ff;">Do the 10,000,000 samples for the Google 53-qubit experiment represent a robust sampling experiment?</span></li>
</ul>
<p> </p></div>
    </content>
    <updated>2019-10-03T19:23:25Z</updated>
    <published>2019-10-03T19:23:25Z</published>
    <category term="Computer Science and Optimization"/>
    <category term="Quantum"/>
    <category term="chaos"/>
    <category term="chaos and computation"/>
    <category term="quantum supremacy"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-10-08T00:20:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/10/03/faculty-position-at-university-of-minnesota-twin-cities-apply-by-november-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/10/03/faculty-position-at-university-of-minnesota-twin-cities-apply-by-november-1-2019/" rel="alternate" type="text/html"/>
    <title>Faculty position at University of Minnesota-Twin Cities (apply by November 1, 2019)</title>
    <summary>The Department of Computer Science &amp; Engineering at the University of Minnesota-Twin Cities is hiring to fill multiple tenure-track positions at the assistant professor level, although higher levels of appointments may be considered when commensurate with experience and accomplishments. One of the areas of interest is theoretical computer science. Website: https://www.cs.umn.edu/news/cse-now-hiring-new-faculty Email: csciadmin@umn.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science &amp; Engineering at the University of Minnesota-Twin Cities is hiring to fill multiple tenure-track positions at the assistant professor level, although higher levels of appointments may be considered when commensurate with experience and accomplishments. One of the areas of interest is theoretical computer science.</p>
<p>Website: <a href="https://www.cs.umn.edu/news/cse-now-hiring-new-faculty">https://www.cs.umn.edu/news/cse-now-hiring-new-faculty</a><br/>
Email: csciadmin@umn.edu</p></div>
    </content>
    <updated>2019-10-03T18:02:59Z</updated>
    <published>2019-10-03T18:02:59Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-10-08T00:21:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/10/03/faculty-at-virginia-tech-apply-by-december-31-2019/</id>
    <link href="https://cstheory-jobs.org/2019/10/03/faculty-at-virginia-tech-apply-by-december-31-2019/" rel="alternate" type="text/html"/>
    <title>Faculty at Virginia Tech (apply by December 31, 2019)</title>
    <summary>http://careers.pageuppeople.com/968/cw/en-us/job/510994 Website: http://www.cs.vt.edu/ Email: facdev@cs.vt.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="http://careers.pageuppeople.com/968/cw/en-us/job/510994">http://careers.pageuppeople.com/968/cw/en-us/job/510994</a></p>
<p>Website: <a href="http://www.cs.vt.edu/">http://www.cs.vt.edu/</a><br/>
Email: facdev@cs.vt.edu</p></div>
    </content>
    <updated>2019-10-03T14:24:41Z</updated>
    <published>2019-10-03T14:24:41Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-10-08T00:21:09Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2019/10/03/NTK/</id>
    <link href="http://offconvex.github.io/2019/10/03/NTK/" rel="alternate" type="text/html"/>
    <title>Ultra-Wide Deep Nets and Neural Tangent Kernel (NTK)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>(Crossposted <a href="https://blog.ml.cmu.edu/2019/10/03/ultra-wide-deep-nets-and-the-neural-tangent-kernel-ntk/">at CMU ML</a>.)</p>

<p>Traditional wisdom in machine learning holds that there is a careful trade-off between training error and generalization gap. There is a “sweet spot” for the model complexity such that the model (i) is big enough to achieve reasonably good training error, and (ii) is small enough so that the generalization gap - the difference between test error and training error - can be controlled. A smaller model would give a larger training error, while making the model bigger would result in a larger generalization gap, both leading to larger test errors. This is described by the classical U-shaped curve for the test error when the model complexity varies (see Figure 1(a)).</p>

<p>However, it is common nowadays to use highly complex over-parameterized models like deep neural networks. These models are usually trained to achieve near zero error on the training data, and yet they still have remarkable performance on test data. <a href="https://arxiv.org/abs/1812.11118">Belkin et al. (2018)</a> characterized this phenomenon by a “double descent” curve which extends the classical U-shaped curve. It was observed that, as one increases the model complexity past the point where it can perfectly fits the training data (i.e., <em>interpolation</em> regime is reached), test error continues to drop! Interestingly, the best test error is often achieved by the largest model, which goes against the classical intuition about the “sweet spot.” The following figure from <a href="https://arxiv.org/abs/1812.11118">Belkin et al. (2018)</a> illustrates this phenomenon.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/belkinfig.jpg" style="width: 700px;"/>
<br/>
<b>Figure 1.</b> Effect of increased model complexity on generalization: traditional belief vs actual practice. 
</div>
<p><br/></p>

<p>Consequently one suspects that the training algorithms used in deep learning - (stochastic) gradient descent and its variants - somehow implicitly constrain the complexity of trained networks (i.e., “true number” of parameters), thus leading to a small generalization gap.</p>

<p>Since larger models often give better performance in practice, one may naturally wonder:</p>

<blockquote>
  <p>How does an infinitely wide net perform?</p>
</blockquote>

<p>The answer to this question corresponds to the right end of Figure 1(b). This blog post is about a model that has attracted a lot of attention in the past year:  deep learning in the regime where the width - namely, the number of channels in convolutional filters, or the number of neurons in fully-connected internal layers - goes to infinity. At first glance this approach may seem hopeless for both practitioners and theorists: all the computing power in the world is insufficient to train an infinite network, and theorists already have their hands full trying to figure out finite ones. But in math/physics there is a tradition of deriving insights into questions by studying them in the infinite limit, and indeed here too the infinite limit becomes easier for theory.</p>

<p>Experts may recall the connection between infinitely wide neural networks and kernel methods from 25 years ago by <a href="https://www.cs.toronto.edu/~radford/pin.abstract.html">Neal (1994)</a> as well as the recent extensions by <a href="https://openreview.net/forum?id=B1EA-M-0Z">Lee et al. (2018)</a> and <a href="https://arxiv.org/abs/1804.11271">Matthews et al. (2018)</a>. These kernels correspond to infinitely wide deep networks whose all parameters are chosen randomly, and <em>only the top (classification) layer is trained</em> by gradient descent. Specifically, if $f(\theta,x)$ denotes the output of the network on input $x$ where $\theta$ denotes the parameters in the network, and $\mathcal{W}$ is an initialization distribution over $\theta$ (usually Gaussian with proper scaling), then the corresponding kernel is

where $x,x’$ are two inputs.</p>

<p>What about the more usual scenario when <em>all layers are trained</em>? Recently, <a href="https://arxiv.org/pdf/1806.07572.pdf">Jacot et al. (2018)</a> first observed that this is also related to a kernel named <em>neural tangent kernel (NTK)</em>, which has the form
</p>

<p>The key difference between the NTK and previously proposed kernels is that the NTK is defined through the inner product between the gradients of the network outputs with respect to the network parameters. This gradient arises from the use of the gradient descent algorithm. Roughly speaking, the following conclusion can be made for a sufficiently wide deep neural network trained by gradient descent:</p>

<blockquote>
  <p>A properly randomly initialized <strong>sufficiently wide</strong> deep neural network <strong>trained by gradient descent</strong> with infinitesimal step size (a.k.a. gradient flow) is <strong>equivalent to a kernel regression predictor</strong> with a <strong>deterministic</strong> kernel called <em>neural tangent kernel (NTK)</em>.</p>
</blockquote>

<p>This was more or less established in the original paper of <a href="https://arxiv.org/pdf/1806.07572.pdf">Jacot et al. (2018)</a>, but they required the width of every layer to go to infinity in a sequential order. In <a href="https://arxiv.org/abs/1904.11955">our recent paper</a> with Sanjeev Arora, Zhiyuan Li, Ruslan Salakhutdinov and Ruosong Wang, we improve this result to the non-asymptotic setting where the width of every layer only needs to be greater than a certain finite threshold.</p>

<p>In the rest of this post we will first explain how NTK arises and the idea behind the proof of the equivalence between wide neural networks and NTKs. Then we will present experimental results showing how well infinitely wide neural networks perform in practice.</p>

<h2 id="how-does-neural-tangent-kernel-arise">How Does Neural Tangent Kernel Arise?</h2>

<p>Now we describe how training an ultra-wide fully-connected neural network leads to kernel regression with respect to the NTK. A more detailed treatment is given in <a href="https://arxiv.org/abs/1904.11955">our paper</a>. We first specify our setup. We consider the standard supervised learning setting, in which we are given $n$ training data points ${(x_i,y_i)}_{i=1}^n \subset \mathbb{R}^{d}\times\mathbb{R}$ drawn from some underlying distribution and wish to find a function that given the input $x$ predicts the label $y$ well on the data distribution. We consider a fully-connected neural network defined by $f(\theta, x)$, where $\theta$ is the collection of all the parameters in the network and $x$ is the input. For simplicity we only consider neural network with a single output, i.e., $f(\theta, x) \in \mathbb{R}$, but the generalization to multiple outputs is straightforward.</p>

<p>We consider training the neural network by minimizing the quadratic loss over training data:

Gradient descent with infinitesimally small learning rate (a.k.a. gradient flow) is applied on this loss function $\ell(\theta)$:                                                                               
where $\theta(t)$ denotes the parameters at time $t$.</p>

<p>Let us define some useful notation. Denote $u_i = f(\theta, x_i)$, which is the network’s output on $x_i$. We let $u=(u_1, \ldots, u_n)^\top \in \mathbb{R}^n$ be the collection of the network outputs on all training inputs. We use the time index $t$ for all variables that depend on time, e.g. $u_i(t), u(t)$, etc. With this notation the training objective can be conveniently written as $\ell(\theta) = \frac12 |u-y|_2^2$.</p>

<p>Using simple differentiation, one can obtain the dynamics of $u(t)$ as follows: (see <a href="https://arxiv.org/abs/1904.11955">our paper</a> for a proof)​

where $H(t)$ is an $n\times n$ positive semidefinite matrix whose $(i, j)$-th entry is $\left\langle \frac{\partial f(\theta(t), x_i)}{\partial\theta}, \frac{\partial f(\theta(t), x_j)}{\partial\theta} \right\rangle$.</p>

<p>Note that $H(t)$ is the <em>kernel matrix</em> of the following (time-varying) kernel $ker_t(\cdot,\cdot)$ evaluated on the training data:

In this kernel an input $x$ is mapped to a feature vector $\phi_t(x) = \frac{\partial f(\theta(t), x)}{\partial\theta}$ defined through the gradient of the network output with respect to the parameters at time $t$.</p>

<p>###The Large Width Limit</p>

<p>Up to this point we haven’t used the property that the neural network is very wide. The formula for the evolution of $u(t)$ is valid in general. In the large width limit, it turns out that the time-varying kernel $ker_t(\cdot,\cdot)$ is (with high probability) always close to a <em>deterministic</em> fixed kernel $ker_{\mathsf{NTK}}(\cdot,\cdot)$, which is the <strong>neural tangent kernel (NTK)</strong>. This property is proved in two steps, both requiring the large width assumption:</p>

<ol>
  <li>
    <p><strong>Step 1: Convergence to the NTK at random initialization.</strong> Suppose that the network parameters at initialization ($t=0$), $\theta(0)$, are i.i.d. Gaussian. Then under proper scaling, for any pair of inputs $x, x’$, it can be shown that the random variable $ker_0(x,x’)$, which depends on the random initialization $\theta(0)$, converges in probability to the deterministic value $ker_{\mathsf{NTK}}(x,x’)$, in the large width limit.</p>

    <p>(Technically speaking, there is a subtlety about how to define the large width limit. <a href="https://arxiv.org/pdf/1806.07572.pdf">Jacot et al. (2018)</a> gave a proof for the sequential limit where the width of every layer goes to infinity one by one. Later <a href="https://arxiv.org/abs/1902.04760">Yang (2019)</a> considered a setting where all widths go to infinity at the same rate. <a href="https://arxiv.org/abs/1904.11955">Our paper</a> improves them to the non-asymptotic setting, where we only require all layer widths to be larger than a finite threshold, which is the weakest notion of limit.)</p>
  </li>
  <li>
    <p><strong>Step 2: Stability of the kernel during training.</strong> Furthermore, the kernel <em>barely changes</em> during training, i.e., $ker_t(x,x’) \approx ker_0(x,x’)$ for all $t$. The reason behind this is that the weights do not move much during training, namely $\frac{|\theta(t) - \theta(0)|}{|\theta(0)|} \to 0$ as width $\to\infty$. Intuitively, when the network is sufficiently wide, each individual weight only needs to move a tiny amount in order to have a non-negligible change in the network output. This turns out to be true when the network is trained by gradient descent.</p>
  </li>
</ol>

<p>Combining the above two steps, we conclude that for any two inputs $x, x’$, with high probability we have

As we have seen, the dynamics of gradient descent is closely related to the time-varying kernel $ker_t(\cdot,\cdot)$. Now that we know that $ker_t(\cdot,\cdot)$ is essentially the same as the NTK, with a few more steps, we can eventually establish the equivalence between trained neural network and NTK: the final learned neural network at time $t=\infty$, denoted by $f_{\mathsf{NN}}(x) = f(\theta(\infty), x)$, is equivalent to the <em>kernel regression</em> solution with respect to the NTK. Namely, for any input $x$ we have

where $ker_{\mathsf{NTK}}(x, X) = (ker_{\mathsf{NTK}}(x, x_1), \ldots, ker_{\mathsf{NTK}}(x, x_n))^\top \in \mathbb{R}^n$, and $ker_{\mathsf{NTK}}(X, X) $ is an $n\times n$ matrix whose $(i, j)$-th entry is $ker_{\mathsf{NTK}}(x_i, x_j)$.</p>

<p>(In order to not have a bias term in the kernel regression solution we also assume that the network output at initialization is small: $f(\theta(0), x)\approx0$; this can be ensured by e.g. scaling down the initialization magnitude by a large constant, or replicating a network with opposite signs on the top layer at initialization.)</p>

<h2 id="how-well-do-infinitely-wide-neural-networks-perform-in-practice">How Well Do Infinitely Wide Neural Networks Perform in Practice?</h2>

<p>Having established this equivalence, we can now address the question of how well infinitely wide neural networks perform in practice — we can just evaluate the kernel regression predictors using the NTKs! We test NTKs on a standard image classification dataset, CIFAR-10. Note that for image datasets, one needs to use convolutional neural networks (CNNs) to achieve good performance. Therefore, we derive an extension of NTK, <em>convolutional neural tangent kernels (CNTKs)</em> and test their performance on CIFAR-10. In the table below, we report the classification accuracies of different CNNs and CNTKs:</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/cntk_acc.jpeg" style="width: 700px;"/>
<br/>
</div>

<p>Here CNN-Vs are vanilla practically-wide CNNs (without pooling), and CNTK-Vs are their NTK counterparts. We also test CNNs with global average pooling (GAP), denotes above as CNN-GAPs, and their NTK counterparts, CNTK-GAPs. For all experiments, we turn off batch normalization, data augmentation, etc., and only use SGD to train CNNs (for CNTKs, we use the closed-form formula of kernel regression).</p>

<p>We find that CNTKs are actually very power kernels. The best kernel we find, 11-layer CNTK with GAP, achieves 77.43% classification accuracy on CIFAR-10. This results in a significant new benchmark for performance of a pure kernel-based method on CIFAR-10, being 10% higher than methods reported by <a href="https://openreview.net/forum?id=B1g30j0qF7">Novak et al. (2019)</a>. The CNTKs also perform similarly to their CNN counterparts. This means that ultra-wide CNNs can achieve reasonable test performance on CIFAR-10.</p>

<p>It is also interesting to see that the global average pooling operation can significantly increase the classification accuracy for both CNNs and CNTKs. From this observation, we suspect that many techniques that improve the performance of neural networks are in some sense universal, i.e., these techniques might benefit kernel methods as well.</p>

<h2 id="concluding-thoughts">Concluding Thoughts</h2>

<p>Understanding the surprisingly good performance of over-parameterized deep neural networks is definitely a challenging theoretical question. Now, at least we have a better understanding of a class of ultra-wide neural networks: they are captured by neural tangent kernels! A hurdle that remains is that the classic generalization theory for kernels is still incapable of giving realistic bounds for generalization. But at least we now know that better understanding of kernels can lead to better understanding of deep nets.</p>

<p>Another fruitful direction is to “translate” different architectures/tricks of neural networks to kernels and to check their practical performance. We have found that global average pooling can significantly boost the performance of kernels, so we hope other tricks like batch normalization, dropout, max-pooling, etc. can also benefit kernels. Similarly, one can try to translate other architectures like recurrent neural networks, graph neural networks, and transformers, to kernels as well.</p>

<p>Our study also shows that there is a performance gap between infinitely wide networks and finite ones. How to explain this gap is an important theoretical question.</p></div>
    </summary>
    <updated>2019-10-03T10:00:00Z</updated>
    <published>2019-10-03T10:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2019-10-08T00:08:05Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-4476874159248982333</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/4476874159248982333/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=4476874159248982333" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/4476874159248982333" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/4476874159248982333" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2019/10/harvard-admissions-lawsuit-decision-out.html" rel="alternate" type="text/html"/>
    <title>Harvard Admissions Lawsuit Decision Out</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">As someone who reads a significant number of court documents and decisions (I still do expert witness work), I can recommend for your reading pleasure the <a href="https://admissionscase.harvard.edu/files/adm-case/files/2019-10-30_dkt_672_findings_of_fact_and_conclusions_of_law.pdf">very recent decision on the Harvard admissions case</a>.  For those who want a sense of how Harvard admissions works, you will get a good summary of the information that came out during the trial.  For those who want to see a well-written court decision, in my opinion, this is a good example.  (Whether you agree with the decision or not, you should find the decision well written;  it lays out the issues and challenges in determining the decision clearly, and similarly explains the reasons for the ultimate conclusion clearly.)  And for those who care about the actual underlying issues of discrimination and affirmative action, I think the document provides a lot of food for thought, with a depth beyond what you'll see in the  news coverage. </div>
    </content>
    <updated>2019-10-03T05:06:00Z</updated>
    <published>2019-10-03T05:06:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2019-10-03T05:06:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4342</id>
    <link href="https://www.scottaaronson.com/blog/?p=4342" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4342#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4342" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">From quantum supremacy to classical fallacy</title>
    <summary xml:lang="en-US">Maybe I should hope that people never learn to distinguish for themselves which claimed breakthroughs in building new forms of computation are obviously serious, and which ones are obviously silly. For as long as they don’t, this blog will always serve at least one purpose. People will cite it, tweet it, invoke its “authority,” even […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Maybe I should hope that people <em>never</em> learn to distinguish for themselves which claimed breakthroughs in building new forms of computation are obviously serious, and which ones are obviously silly.  For as long as they don’t, this blog will always serve at least one purpose.  People will cite it, tweet it, invoke its “authority,” even while from my point of view, I’m offering nothing more intellectually special than my toddler does when he calls out “moo-moo cow! baa-baa sheep!” as we pass them on the road.</p>



<p>But that’s too pessimistic.  Sure, most readers <em>must</em> more-or-less already know what I’ll say about each thing: that <a href="https://www.scottaaronson.com/blog/?p=4317">Google’s quantum supremacy claim</a> is serious, that <a href="https://www.scottaaronson.com/blog/?p=2212">memcomputing to solve NP-complete problems</a> is not, etc.  Even so, I’ve heard from many readers that this blog was at least helpful for double-checking their initial impressions, and for making <a href="https://www.scottaaronson.com/blog/?p=2410">common knowledge</a> what before had merely been known to many.  I’m fine for it to continue serving those roles.</p>



<p>Last week, even as I dealt with fallout from Google’s quantum supremacy leak, I also got several people asking me to comment on a <em>Nature</em> paper entitled <a href="https://www-nature-com.ezproxy.lib.utexas.edu/articles/s41586-019-1557-9">Integer factorization using stochastic magnetic tunnel junctions</a> (warning: paywalled).  See also <a href="https://www.purdue.edu/newsroom/releases/2019/Q3/poor-mans-qubit-can-solve-quantum-problems-without-going-quantum.html">here</a> for a university press release.</p>



<p>The authors report building a new kind of computer based on asynchronously updated “p-bits” (probabilistic bits).  A p-bit is “a robust, classical entity fluctuating in time between 0 and 1, which interacts with other p-bits … using principles inspired by neural networks.”  They build a device with 8 p-bits, and use it to factor integers up to 945.  They present this as another “unconventional computation scheme” alongside quantum computing, and as a “potentially scalable hardware approach to the difficult problems of optimization and sampling.”</p>



<p>A <a href="https://www.nature.com/articles/d41586-019-02742-x">commentary accompanying the </a><em><a href="https://www.nature.com/articles/d41586-019-02742-x">Nature</a></em><a href="https://www.nature.com/articles/d41586-019-02742-x"> paper</a> goes much further still—claiming that the new factoring approach, “if improved, could threaten data encryption,” and that resources should now be diverted from quantum computing to this promising new idea, one with the advantages of requiring no refrigeration or maintenance of delicate entangled states.  (It should’ve added: and how big a number has Shor’s algorithm factored anyway, 21?  Compared to 945, that’s peanuts!)</p>



<p>Since I couldn’t figure out a gentler way to say this, here goes: it’s <strong>astounding</strong> that this paper and commentary made it into <em>Nature</em> in the form that they did.  Juxtaposing Google’s sampling achievement with p-bits, as several of my Facebook friends did last week, is juxtaposing the Wright brothers with some guy bouncing around on a pogo stick.</p>



<p>If you were looking forward to watching me dismantle the p-bit claims, I’m afraid you might be disappointed: the task is over almost the moment it begins.  <strong>“p-bit” devices can’t scalably outperform classical computers, for the simple reason that they <font color="red">are</font> classical computers.</strong>  A little unusual in their architecture, but still well-covered by the classical <a href="https://www.scottaaronson.com/talks/bernays2.ppt">Extended Church-Turing Thesis</a>.  Just like with the <a href="https://en.wikipedia.org/wiki/Adiabatic_quantum_computation">quantum adiabatic algorithm</a>, an energy penalty is applied to coax the p-bits into running a local optimization algorithm: that is, making random local moves that preferentially decrease the number of violated constraints.  Except here, because the whole evolution is classical, there doesn’t seem to be even the <em>pretense</em> that anything is happening that a laptop with a random-number generator couldn’t straightforwardly simulate.  In terms of <a href="https://www.nytimes.com/2019/10/02/opinion/impeachment-trump-nixon.html">this editorial</a>, if adiabatic quantum computing is Richard Nixon—hiding its lack of observed speedups behind subtle arguments about tunneling and spectral gaps—then p-bit computing is Trump.</p>



<p>Even so, I wouldn’t be writing this post if you opened the paper and it immediately said, in effect, “look, <em>we know</em>.  You’re thinking that this is just yet another stochastic local optimization method, which could clearly be simulated efficiently on a conventional computer, thereby putting it into a different conceptual universe from quantum computing.  You’re thinking that factoring an n-bit integer will self-evidently take exp(n) time by this method, as compared to exp(n<sup>1/3</sup>) for the <a href="https://en.wikipedia.org/wiki/General_number_field_sieve">Number Field Sieve</a>, and that no crypto is in even remote danger from this.  But here’s why you should still be interested in our p-bit model: because of other advantages X, Y, and Z.”  Alas, in vain one searches the whole paper, <em>and</em> the lengthy supplementary material, <em>and</em> the commentary, for any acknowledgment of the pachyderm in the pagoda.  Not an asymptotic runtime scaling in sight.  Quantum computing is there, but stripped of the theoretical framework that gives it its purpose.</p>



<p>That silence, in the pages of <em>Nature</em>—<em>that’s</em> the part that convinced me that, while on the negative side this blog seems to have accomplished nothing for the world in 14 years of existence, on the positive side it will likely have a role for decades to come.</p>



<p><strong>Update:</strong> See a <a href="https://www.scottaaronson.com/blog/?p=4342#comment-1820670">response in the comments</a>, which I appreciated, from Kerem Cansari (one of the authors of the paper), and <a href="https://www.scottaaronson.com/blog/?p=4342#comment-1820674">my response to the response</a>.</p>



<p><strong>(Partly) Unrelated Announcement #1:</strong> My new postdoc, <a href="https://andrearocchetto.github.io/">Andrea Rocchetto</a>, had the neat idea of compiling a <a href="https://quantumfactsheet.github.io/">Quantum Computing Fact Sheet</a>: a quick “Cliffs Notes” for journalists, policymakers, and others looking to get the basics right.  The fact sheet might grow in the future, but in the meantime, check it out!  Or at a more popular level, try the <a href="https://quantumatlas.umd.edu/">Quantum Atlas</a> made by folks at the University of Maryland.</p>



<p><strong>Unrelated Announcement #2:</strong> Daniel Wichs asked me to give a shout-out to a new <a href="https://itcrypto.github.io/">Conference on Information-Theoretic Cryptography</a>, to be held June 17-19 in Boston.</p>



<p><strong>Third Announcement:</strong> Several friends asked me to share that <a href="https://peterwittek.com/">Prof. Peter Wittek</a>, quantum computing researcher at the University of Toronto, has <a href="https://www.theglobeandmail.com/canada/article-renowned-ai-expert-university-of-toronto-prof-missing-after-avalanche/?fbclid=IwAR0FTnzQxRL79-oo43xjKaNEA7Oe1rA8A2yVjvhrgodxG1wJzhfhJZt9oJw">gone missing</a> in the Himalayas.  Needless to say we hope for his safe return.</p></div>
    </content>
    <updated>2019-10-03T03:59:37Z</updated>
    <published>2019-10-03T03:59:37Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Speaking Truth to Parallelism"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-10-07T17:01:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1288</id>
    <link href="https://thmatters.wordpress.com/2019/10/02/a-solicitation-for-tcs-job-market-profiles/" rel="alternate" type="text/html"/>
    <title>A solicitation for TCS job market profiles</title>
    <summary>CATCS is piloting an effort this year to collect and disseminate profiles of junior theory researchers who are going on the job market during the 2019-20 academic year, complementing the job postings collected under the Jobs tab. The SIGecom community has run a similar effort very successfully for a number of years and we are […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>CATCS is piloting an effort this year to collect and disseminate profiles of junior theory researchers who are going on the job market during the 2019-20 academic year, complementing the job postings collected under the <a href="https://cstheory-jobs.org/">Jobs tab</a>. The SIGecom community has run a similar effort very successfully for a number of years and we are following their lead. The goals are two-fold:</p>
<div/>
<ul>
<li>Provide a platform to job-seekers to advertise their credentials.</li>
<li>Provide an interface for institutions/individuals with open positions to find prospective candidates.</li>
</ul>
<p>Candidates looking for theory jobs can fill out <a href="https://forms.gle/gMDaChCqQocKSXT79" rel="noopener" target="_blank">this form</a>. The form asks for basic personal information, thesis title, graduation date (past or future), research/teaching interests, bibliographic information for three publications, and allows you to add links to publications and a brief CV.</p>
<div/>
<p>The responses will be reviewed and, if approved, edited and posted on Theory Matters starting in Nov’19. There is no deadline, but for responses received after Nov 1 please allow two weeks for review before your profile appears on the website. Responses received by Dec 15 will have summaries published in the following issue of SIGACT News.</p></div>
    </content>
    <updated>2019-10-02T21:09:02Z</updated>
    <published>2019-10-02T21:09:02Z</published>
    <category term="for PhD students"/>
    <category term="postdocs"/>
    <category term="Uncategorized"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2019-10-08T00:21:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/133</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/133" rel="alternate" type="text/html"/>
    <title>TR19-133 |  More on $AC^0[\oplus]$ and Variants of the Majority Function | 

	Utkarsh Tripathi, 

	Nutan Limaye, 

	Srikanth Srinivasan</title>
    <summary>In this paper we prove two results about $AC^0[\oplus]$ circuits. 

We show that for $d(N) = o(\sqrt{\log N/\log \log N})$ and $N \leq s(N) \leq 2^{dN^{1/d^2}}$ there is an explicit family of functions $\{f_N:\{0,1\}^N\rightarrow \{0,1\}\}$ such that 
$f_N$ has uniform $AC^0$ formulas of depth $d$ and size at most $s$; 
$f_N$ does not have $AC^0[\oplus]$ formulas of depth $d$ and size $s^{\varepsilon}$, where $\varepsilon$ is a fixed absolute constant. 

This gives a quantitative improvement on the recent result of Limaye, Srinivasan, Sreenivasaiah, Tripathi, and Venkitesh, (STOC, 2019), which proved a similar Fixed-Depth Size-Hierarchy theorem but for $d \ll \log \log N$ and $s \ll \exp(N^{1/2^{\Omega(d)}})$. 

As in the previous result, we use the Coin Problem to prove our hierarchy theorem. Our main technical result is the construction of uniform size-optimal formulas for solving the coin problem with improved sample complexity $(1/\delta)^{d+4}$ (down from $(1/\delta)^{2^{O(d)}}$ in the previous result).

In our second result, we show that randomness buys depth in the $AC^0[\oplus]$ setting. Formally, we show that for any fixed constant $d\geq 2$, there is a family of Boolean functions that has polynomial-sized randomized uniform $AC^0$ circuits of depth $d$ but no polynomial-sized (deterministic) $AC^0[\oplus]$ circuits of depth $d$.

Previously Viola (Computational Complexity, 2014) showed that an increase in depth (by at least $2$) is essential to avoid superpolynomial blow-up while derandomizing randomized $AC^0$ circuits. We show that an increase in depth (by at least $1$) is essential even for $AC^0[\oplus]$. 

As in Viola's result, the separating examples are promise variants of the Majority function on $N$ inputs that accept inputs of weight at least $N/2 + N/(\log N)^{d-1}$ and reject inputs of weight at most $N/2 - N/(\log N)^{d-1}$.</summary>
    <updated>2019-10-02T11:00:43Z</updated>
    <published>2019-10-02T11:00:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-10-08T00:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/10/02/quics-fellows-at-joint-center-for-quantum-information-and-computer-science-apply-by-october-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/10/02/quics-fellows-at-joint-center-for-quantum-information-and-computer-science-apply-by-october-15-2019/" rel="alternate" type="text/html"/>
    <title>QuICS Fellows at Joint Center for Quantum Information and Computer Science (apply by October 15, 2019)</title>
    <summary>The Joint Center for Quantum Information and Computer Science (QuICS) is currently seeking outstanding quantum information researchers to join the Center faculty as QuICS Fellows. QuICS is a research partnership between the University of Maryland and the National Institute of Standards and Technology, with faculty from both institutions. Website: http://quics.umd.edu/join-quics/new-faculty Email: quics-coordinator@umiacs.umd.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Joint Center for Quantum Information and Computer Science (QuICS) is currently seeking outstanding quantum information researchers to join the Center faculty as QuICS Fellows. QuICS is a research partnership between the University of Maryland and the National Institute of Standards and Technology, with faculty from both institutions.</p>
<p>Website: <a href="http://quics.umd.edu/join-quics/new-faculty">http://quics.umd.edu/join-quics/new-faculty</a><br/>
Email: quics-coordinator@umiacs.umd.edu</p></div>
    </content>
    <updated>2019-10-02T03:13:13Z</updated>
    <published>2019-10-02T03:13:13Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-10-08T00:21:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3422</id>
    <link href="https://agtb.wordpress.com/2019/10/02/matching-markets-simons-driven-by-theory-driving-the-economy/" rel="alternate" type="text/html"/>
    <title>Matching Markets @ Simons:  Driven by Theory, Driving the Economy</title>
    <summary>[Guest post by Sid Banerjee.] Divergent Evolution: The formation of new species when populations experience different selective pressures. While the canonical example is Darwin’s finches, it could apply as well to matching theorists! A notable feature of the first and second workshops at the Simons Institute program on Matching Markets was how researchers in Economics, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>[Guest post by Sid Banerjee.]</em></p>



<blockquote class="wp-block-quote"><p><em>Divergent Evolution: The formation of new species when populations experience different selective pressures.</em></p></blockquote>



<p>While the canonical example is Darwin’s finches, it could apply as well to matching theorists! A notable feature of the <a href="https://simons.berkeley.edu/workshops/market2019-1" rel="noreferrer noopener" target="_blank">first</a> and <a href="https://simons.berkeley.edu/workshops/market2019-2" rel="noreferrer noopener" target="_blank">second</a> workshops at the <a href="https://simons.berkeley.edu/programs/market2019" rel="noreferrer noopener" target="_blank">Simons Institute program on Matching Markets</a> was how researchers in Economics, Operations Research and TCS all share common antecedents (Fulkerson, Gale, Scarf, Shapley, Walras — to name but a few giants invoked regularly), and yet have taken the theory in  diverse directions. The workshops helped create a healthy dialogue between the communities, as everyone tries to understand each other’s objectives and techniques. </p>



<p>A more notable aspect of matching theory in recent years has been its  impact on the design of real-world marketplaces. Over the two workshops,  a mix of speakers from academia and industry covered a host of markets,  including <a href="https://simons.berkeley.edu/talks/tba-121" rel="noreferrer noopener" target="_blank">payment routing</a>, <a href="https://simons.berkeley.edu/talks/tba-127" rel="noreferrer noopener" target="_blank">online advertising</a>, <a href="https://simons.berkeley.edu/talks/tba-124" rel="noreferrer noopener" target="_blank">kidney exchange</a>, <a href="https://simons.berkeley.edu/talks/tba-128" rel="noreferrer noopener" target="_blank">real-estate</a>, <a href="https://simons.berkeley.edu/talks/tba-131" rel="noreferrer noopener" target="_blank">public housing</a>, <a href="https://simons.berkeley.edu/talks/ridesharing-panel" rel="noreferrer noopener" target="_blank">ride-sharing</a>, <a href="https://simons.berkeley.edu/talks/driving-efficiencies-freight-industry" rel="noreferrer noopener" target="_blank">long-haul trucking</a>, <a href="https://simons.berkeley.edu/talks/ratings-design-and-barriers-entry" rel="noreferrer noopener" target="_blank">restaurant reviews</a>, <a href="https://simons.berkeley.edu/talks/tba-129" rel="noreferrer noopener" target="_blank">school choice</a>, <a href="https://simons.berkeley.edu/talks/unreasonable-effectiveness-artificial-currencies" rel="noreferrer noopener" target="_blank">food-banks</a> and many many others. A common theme that emerged was that online marketplaces, with the support of good algorithm and mechanism designers, are slowly taking over the economy.</p>



<p>And talking of giants of matching theory, another event held in parallel with the program was a <a href="https://simons.berkeley.edu/events/richard-m-karp-distinguished-lecture-inaugural-lecture" rel="noreferrer noopener" target="_blank">celebration</a> of the achievements and contributions of Dick Karp, with Vijay Vazirani giving the <a href="https://simons.berkeley.edu/rmklectures2019-fall-1" rel="noreferrer noopener" target="_blank">inaugural lecture</a> of the Simons Institute Richard M. Karp Distinguished Lecture Series. Vijay’s talk touched on both the above themes, with a sweeping overview of three great threads in matching theory (stable matching, market equilibria, and online matching). He highlighted the critical role of algorithmic thinking in their development, and concluded with a tantalizing 40-year-old open problem connected to finding a polynomial-time algorithm for the Hylland-Zeckhauser market equilibrium. It is an excellent starting point for those interested in the program, or matching markets in general!</p></div>
    </content>
    <updated>2019-10-02T00:45:32Z</updated>
    <published>2019-10-02T00:45:32Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>robertkleinberg</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2019-10-08T00:20:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-8966138510075761711</id>
    <link href="http://processalgebra.blogspot.com/feeds/8966138510075761711/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=8966138510075761711" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/8966138510075761711" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/8966138510075761711" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2019/10/phd-position-at-tue-on-product-line.html" rel="alternate" type="text/html"/>
    <title>PhD position at TU/e on product line engineering in multidisciplinary cyber-physical systems</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The Model Driven Software Engineering section at Eindhoven University of Technology (TU/e) is searching for a candidate for a fully-funded PhD position on product line engineering in the multidisciplinary context of cyber-physical systems to collaborate with the high-tech company ASML in the context of the EU ECSEL project Arrowhead Tools.<br/><br/>See <a href="https://eapls.org/items/3327/">here</a> for the details of the position.<br/><br/>TU/e is a dynamic, research-intensive university in the heart of Europe, and in the Brainport region, a leading European technology region, and a centre for innovation and hi-tech industry. TU/e is consistently ranked within the top-100 positions in several world rankings for its research and quality of education.</div>
    </content>
    <updated>2019-10-01T10:06:00Z</updated>
    <published>2019-10-01T10:06:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2019-10-03T10:52:22Z</updated>
    </source>
  </entry>
</feed>
