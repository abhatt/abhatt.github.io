<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-05-14T22:33:52Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=435</id>
    <link href="https://tcsplus.wordpress.com/2020/05/14/tcs-talk-wednesday-may-20-mark-bun-boston-university/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, May 20 — Mark Bun, Boston University</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, May 20th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Mark Bun from Boston University will speak about “An Equivalence between Private Classification and Online Predictability” (abstract below). You can reserve a spot as an individual or a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, May 20th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Mark Bun</strong> from Boston University will speak about “<em>An Equivalence between Private Classification and Online Predictability</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our website</a> on the day of the talk, so people who did not sign up will still be able to watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: We prove that every concept class with finite Littlestone dimension can be learned by an (approximate) differentially-private algorithm. The converse direction was shown in recent work of Alon, Livni, Malliaris, and Moran, STOC ’19. Together these two results show that a class of functions is privately learnable if and only if it is learnable in the mistake-bound model of online learning. To establish our result, we introduce “global stability,” a new notion of algorithmic stability for learning algorithms that we show can always be satisfied when learning classes of finite Littlestone dimension.</p></blockquote>
<p> </p></div>
    </content>
    <updated>2020-05-14T18:04:41Z</updated>
    <published>2020-05-14T18:04:41Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-05-14T22:33:09Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-05-14-streamlet/</id>
    <link href="https://decentralizedthoughts.github.io/2020-05-14-streamlet/" rel="alternate" type="text/html"/>
    <title>Streamlet: A Simple Textbook Blockchain Protocol</title>
    <summary>Guest post by Benjamin Chan and Elaine Shi In this post, we describe an extraordinarily simple blockchain protocol called Streamlet. Consensus is a complex problem and has been studied since the 1980s. More recently, blockchain research has spawned many new works aiming for performance and ease-of-implementation. However, simple, understandable protocols...</summary>
    <updated>2020-05-14T17:48:00Z</updated>
    <published>2020-05-14T17:48:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-05-14T22:33:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1688</id>
    <link href="https://theorydish.blog/2020/05/14/pride-and-prejudice-from-research-to-practice/" rel="alternate" type="text/html"/>
    <title>Pride and Prejudice: From Research to Practice</title>
    <summary>Despite (or because of) being a devoted theoretician, I truly enjoy every occasion when theory influences practice. I therefore felt quite a bit of satisfaction when our rather recent work, in the context of algorithmic fairness (with Úrsula Hébert-Johnson, Michael P. Kim and Guy N. Rothblum), found an application for predicting COVID-19 complications. Researchers in Israel, in collaboration with Israel’s biggest health-care provider, adapted a refined model for predicting flu complications to a model for predicting COVID-19 complications.  At the time, only very limited data from China were available (marginal statistics).  This is where our work came in (following several past empiric studies of the method):  the team applied our algorithm to improve the accuracy of predictions across various subpopulations (as part of an immense research and engineering effort). Now that there is (unfortunately) more data, it seems that the predictor exhibited surprisingly good performance (surprising, due to the poor training data).  See a manuscript here, an interview here and a more technical talk here (starting at minute 36 roughly). The predictor was applied with the appropriate cautiousness to inform and advise patients. But this is also an example of the gravity of decisions by researchers and software developers. Taking [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Despite (or because of) being a devoted theoretician, I truly enjoy every occasion when theory influences practice. I therefore felt quite a bit of satisfaction when our <a href="https://arxiv.org/abs/1711.08513">rather recent work</a>, in the context of algorithmic fairness (with Úrsula Hébert-Johnson, Michael P. Kim and Guy N. Rothblum), found an application for predicting COVID-19 complications. Researchers in Israel, in collaboration with Israel’s biggest health-care provider, adapted a refined model for predicting flu complications to a model for predicting COVID-19 complications.  At the time, only very limited data from China were available (marginal statistics).  This is where our work came in (following several past empiric studies of the method):  the team applied our algorithm to improve the accuracy of predictions across various subpopulations (as part of an immense research and engineering effort). Now that there is (unfortunately) more data, it seems that the predictor exhibited surprisingly good performance (surprising, due to the poor training data).  See a <a href="https://www.medrxiv.org/content/10.1101/2020.04.23.20076976v1">manuscript</a> here, an interview <a href="https://www.youtube.com/watch?v=r_alyuZULYI">here</a> and a more technical talk <a href="https://www.youtube.com/watch?v=weaRmSVA3yM">here</a> (starting at minute 36 roughly). The predictor was applied with the appropriate cautiousness to inform and advise patients.</p>
<p>But this is also an example of the gravity of decisions by researchers and software developers. Taking it to extreme, imagine a predictor that is used to determine which patients are denied treatment in an overwhelmed hospital. The booming research area of algorithmic fairness sees a very short turnover from research ideas (in many areas) to deployment. In an ideal world, it would have been much better to first have a couple of decades to develop the computational foundations of algorithmic fairness, before the practical need arose. But in the real world, the huge scale of algorithmic decision making creates immense demand for solutions. Industry, as well as policy and law makers are unlikely to wait decades or even years, nor is it clear that they should. From my perspective, this reality underscores the urgency for <em>principled</em> and <em>deliberate</em> research – rather than <em>hasty</em> research – continuously developing the foundations of algorithmic fairness and offering answers to real-world challenges.</p></div>
    </content>
    <updated>2020-05-14T17:32:17Z</updated>
    <published>2020-05-14T17:32:17Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-05-14T22:33:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1307</id>
    <link href="https://thmatters.wordpress.com/2020/05/14/cra-and-ccc-announce-computing-innovation-fellows-2020/" rel="alternate" type="text/html"/>
    <title>CRA and CCC announce Computing Innovation Fellows 2020</title>
    <summary>The Computing Research Association (CRA) and Computing Community Consortium (CCC) have announced a new CI Fellows program that will offer 2 year postdoctoral opportunities in computing starting Fall’20. The deadline for application is yet to be announced but will be around mid-June 2020, with decisions being made around mid-July 2020 for positions beginning this fall […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Computing Research Association (CRA) and Computing Community Consortium (CCC) have announced a new CI Fellows program that will offer 2 year postdoctoral opportunities in computing starting Fall’20.</p>
<p>The deadline for application is yet to be announced but will be around <strong>mid-June 2020</strong>, with decisions being made around mid-July 2020 for positions beginning this fall or winter. We will update this post once a deadline is announced. In the meantime, further details can be found at <a href="https://cifellows2020.org/" rel="nofollow">https://cifellows2020.org/</a>.</p></div>
    </content>
    <updated>2020-05-14T16:39:50Z</updated>
    <published>2020-05-14T16:39:50Z</published>
    <category term="Deadlines"/>
    <category term="for PhD students"/>
    <category term="Funding opportunity"/>
    <category term="postdocs"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2020-05-14T22:32:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1304</id>
    <link href="https://thmatters.wordpress.com/2020/05/14/call-for-nominations-for-talg-new-editor-in-chief/" rel="alternate" type="text/html"/>
    <title>Call for Nominations for TALG new Editor-in-Chief</title>
    <summary>Prof. David Shmoys is chairing the committee to identify a new Editor-in-Chief for ACM Trans. on Algorithms.  The deadline for nominations is Jun 8th. Please see details below. ACM TALG (webpage: http://talg.acm.org/) publishes original research of the highest quality dealing with algorithms. It is a peer-reviewed journal, appearing quarterly. Specific areas of computation covered by the journal are […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Prof. <span class="il">David</span> <span class="il">Shmoys</span> is chairing the committee to identify a new Editor-in-Chief for ACM Trans. on Algorithms.  The deadline for nominations is <strong>Jun 8th</strong>. Please see details below.</p>
<p>ACM TALG (webpage: <a href="http://talg.acm.org/" rel="nofollow">http://talg.acm.org/</a>) publishes original research of the highest quality dealing with algorithms. It is a peer-reviewed journal, appearing quarterly. Specific areas of computation covered by the journal are listed at <a href="http://talg.acm.org/Aims.html" rel="nofollow">http://talg.acm.org/Aims.html</a>.</p>
<p>We are looking for a well-established person with a strong record of research achievements and service, and with a vision for the future of the field. The term of appointment is three years, to begin late summer 2020, with the possibility of renewal for a second term. The editor-in-chief is responsible for faithfully executing the editorial charter of the journal yet should be proactive in adapting the journal and its charter to changes in the field. A description of the duties of the EiC and evaluation criteria can be found at <a href="http://www.acm.org/publications/policies/evaluation" rel="nofollow">http://www.acm.org/publications/policies/evaluation</a>.</p>
<p>The Search Committee members are:<br/>
David Eppstein – University of California, Irvine<br/>
Anna Karlin – University of Washington<br/>
Chris Hankin – Imperial College London – ACM Publications Board Liaison<br/>
Dana Randall – Georgia Institute of Technology<br/>
David Shmoys – Cornell University – Committee Chair.</p>
<p>All nominees, including self-nominees, should send a CV and a Vision Statement for TALG (at least one page), with subject header “EiC nomination” to the committee chair – david.shmoys@cornell.edu .</p>
<p>The deadline for nominations is Monday, June 8, 2020 at 11:59 p.m. (EST).</p></div>
    </content>
    <updated>2020-05-14T16:34:59Z</updated>
    <published>2020-05-14T16:34:59Z</published>
    <category term="Deadlines"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2020-05-14T22:32:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/05/14/6-year-postdoc-at-tu-wien-vienna-austria-apply-by-may-28-2020/</id>
    <link href="https://cstheory-jobs.org/2020/05/14/6-year-postdoc-at-tu-wien-vienna-austria-apply-by-may-28-2020/" rel="alternate" type="text/html"/>
    <title>6-year postdoc at TU Wien, Vienna, Austria (apply by May 28, 2020)</title>
    <summary>A 6-Year Postdoc Position in Algorithms is available at TU Wien, Vienna, Austria. Research experience in one of the following areas is of advantage: parameterized complexity, algorithmic applications of graph decompositions, SAT and CSP. Website: https://www.ac.tuwien.ac.at/jobs/#junprof Email: sz@ac.tuwien.ac.at</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A 6-Year Postdoc Position in Algorithms is available at TU Wien, Vienna, Austria. Research experience in one of the following areas is of advantage: parameterized complexity, algorithmic applications of graph decompositions, SAT and CSP.</p>
<p>Website: <a href="https://www.ac.tuwien.ac.at/jobs/#junprof">https://www.ac.tuwien.ac.at/jobs/#junprof</a><br/>
Email: sz@ac.tuwien.ac.at</p></div>
    </content>
    <updated>2020-05-14T10:16:15Z</updated>
    <published>2020-05-14T10:16:15Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-05-14T22:32:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/05/14/postdoc-at-university-of-haifa-israel-apply-by-december-30-2020/</id>
    <link href="https://cstheory-jobs.org/2020/05/14/postdoc-at-university-of-haifa-israel-apply-by-december-30-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Haifa (Israel) (apply by December 30, 2020)</title>
    <summary>We invite applications for a postdoc position, hosted by Or Meir, at the university of Haifa in Israel. We are especially looking for candidates who are interested in working on communication complexity and circuit complexity, but we will also consider candidates who are interested in other areas of complexity theory and algorithms. For details, please […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We invite applications for a postdoc position, hosted by Or Meir, at the university of Haifa in Israel. We are especially looking for candidates who are interested in working on communication complexity and circuit complexity, but we will also consider candidates who are interested in other areas of complexity theory and algorithms. For details, please e-mail Or Meir directly.</p>
<p>Website: <a href="https://docs.google.com/viewer?a=v&amp;pid=sites&amp;srcid=ZGVmYXVsdGRvbWFpbnxub2dhcm9uemV3aTF8Z3g6Nzc2ZjU5ZjIwY2QwNzJhMg&amp;urp=gmail_link">https://docs.google.com/viewer?a=v&amp;pid=sites&amp;srcid=ZGVmYXVsdGRvbWFpbnxub2dhcm9uemV3aTF8Z3g6Nzc2ZjU5ZjIwY2QwNzJhMg&amp;urp=gmail_link</a><br/>
Email: ormeir@cs.haifa.ac.il</p></div>
    </content>
    <updated>2020-05-14T09:57:34Z</updated>
    <published>2020-05-14T09:57:34Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-05-14T22:32:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.06441</id>
    <link href="http://arxiv.org/abs/2005.06441" rel="alternate" type="text/html"/>
    <title>Testing Positive Semi-Definiteness via Random Submatrices</title>
    <feedworld_mtime>1589414400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bakshi:Ainesh.html">Ainesh Bakshi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chepurko:Nadiia.html">Nadiia Chepurko</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jayaram:Rajesh.html">Rajesh Jayaram</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06441">PDF</a><br/><b>Abstract: </b>We study the problem of testing whether a matrix $A \in \mathbb{R}^{n \times
n}$ with bounded entries ($\|A\|_\infty \leq 1$) is positive semi-definite
(PSD), or $\epsilon$-far in $\ell_2^2$-distance from the PSD cone, i.e. $\min_{
B \succeq 0} \| A - B\|_F^2 = \sum_{i : \lambda_i(A) &lt; 0} \lambda_i^2(A) &gt;
\epsilon n^2$. Our main algorithmic contribution is a non-adaptive tester which
distinguishes between these cases using only $\tilde{O}(1/\epsilon^4)$ queries
to the entries of $A$. For the related "$\ell_\infty$-gap problem", where $A$
is either PSD or has an eigenvalue satisfying $\lambda_i(A) &lt; - \epsilon n$,
our algorithm only requires $\tilde{O}(1/\epsilon^2)$ queries, which is optimal
up to $\log(1/\epsilon)$ factors. Our testers randomly sample a collection of
principle sub-matrices and check whether these sub-matrices are PSD.
Consequentially, our algorithms achieve one-sided error: whenever they output
that $A$ is not PSD, they return a certificate that $A$ has negative
eigenvalues.
</p>
<p>We complement our upper bound for PSD testing with $\ell_2^2$-gap by giving a
$\tilde{\Omega}(1/\epsilon^2)$ lower bound for any non-adaptive algorithm. Our
lower bound construction is general, and can be used to derive lower bounds for
a number of spectral testing problems. As an example of the applicability of
our construction, we obtain a new $\tilde{\Omega}(1/\epsilon^4)$ sampling lower
bound for testing the Schatten-$1$ norm with a $\epsilon^{1.5}$ gap, extending
a result of Balcan, Li, Woodruff, and Zhang [SODA'19]. In addition, our hard
instance results in new sampling lower bounds for estimating the Ky-Fan Norm,
and the cost of rank-$k$ approximations, i.e. $\|A - A_k\|_F^2 = \sum_{i &gt; k}
\sigma_i^2(A)$.
</p></div>
    </summary>
    <updated>2020-05-14T22:27:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.06344</id>
    <link href="http://arxiv.org/abs/2005.06344" rel="alternate" type="text/html"/>
    <title>A remark on approximating permanents of positive definite matrices</title>
    <feedworld_mtime>1589414400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Alexander Barvinok <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06344">PDF</a><br/><b>Abstract: </b>Let $A$ be an $n \times n$ positive definite Hermitian matrix with all
eigenvalues between 1 and 2. We represent the permanent of $A$ as the integral
of some explicit log-concave function on ${\Bbb R}^{2n}$. Consequently, there
is a fully polynomial randomized approximation scheme (FPRAS) for the permanent
of $A$.
</p></div>
    </summary>
    <updated>2020-05-14T22:26:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.06329</id>
    <link href="http://arxiv.org/abs/2005.06329" rel="alternate" type="text/html"/>
    <title>k-Approximate Quasiperiodicity under Hamming and Edit Distance</title>
    <feedworld_mtime>1589414400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Aleksander Kędzierski, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Radoszewski:Jakub.html">Jakub Radoszewski</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06329">PDF</a><br/><b>Abstract: </b>Quasiperiodicity in strings was introduced almost 30 years ago as an
extension of string periodicity. The basic notions of quasiperiodicity are
cover and seed. A cover of a text $T$ is a string whose occurrences in $T$
cover all positions of $T$. A seed of text $T$ is a cover of a superstring of
$T$. In various applications exact quasiperiodicity is still not sufficient due
to the presence of errors. We consider approximate notions of quasiperiodicity,
for which we allow approximate occurrences in $T$ with a small Hamming,
Levenshtein or weighted edit distance.
</p>
<p>In previous work Sip et al. (2002) and Christodoulakis et al. (2005) showed
that computing approximate covers and seeds, respectively, under weighted edit
distance is NP-hard. They, therefore, considered restricted approximate covers
and seeds which need to be factors of the original string $T$ and presented
polynomial-time algorithms for computing them. Further algorithms, considering
approximate occurrences with Hamming distance bounded by $k$, were given in
several contributions by Guth et al. They also studied relaxed approximate
quasiperiods that do not need to cover all positions of $T$.
</p>
<p>In case of large data the exponents in polynomial time complexity play a
crucial role. We present more efficient algorithms for computing restricted
approximate covers and seeds. In particular, we improve upon the complexities
of many of the aforementioned algorithms, also for relaxed quasiperiods. Our
solutions are especially efficient if the number (or total cost) of allowed
errors is bounded. We also show NP-hardness of computing non-restricted
approximate covers and seeds under Hamming distance.
</p>
<p>Approximate covers were studied in three recent contributions at CPM over the
last three years. However, these works consider a different definition of an
approximate cover of $T$.
</p></div>
    </summary>
    <updated>2020-05-14T22:25:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.06311</id>
    <link href="http://arxiv.org/abs/2005.06311" rel="alternate" type="text/html"/>
    <title>Fully Online Matching II: Beating Ranking and Water-filling</title>
    <feedworld_mtime>1589414400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Zhiyi.html">Zhiyi Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Zhihao_Gavin.html">Zhihao Gavin Tang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Xiaowei.html">Xiaowei Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Yuhao.html">Yuhao Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06311">PDF</a><br/><b>Abstract: </b>Karp, Vazirani, and Vazirani (STOC 1990) initiated the study of online
bipartite matching, which has held a central role in online algorithms ever
since. Of particular importance are the Ranking algorithm for integral matching
and the Water-filling algorithm for fractional matching. Most algorithms in the
literature can be viewed as adaptations of these two in the corresponding
models. Recently, Huang et al.~(STOC 2018, SODA 2019) introduced a more general
model called \emph{fully online matching}, which considers general graphs and
allows all vertices to arrive online. They also generalized Ranking and
Water-filling to fully online matching and gave some tight analysis: Ranking is
$\Omega \approx 0.567$-competitive on bipartite graphs where the
$\Omega$-constant satisfies $\Omega e^\Omega = 1$, and Water-filling is
$2-\sqrt{2} \approx 0.585$-competitive on general graphs.
</p>
<p>We propose fully online matching algorithms strictly better than Ranking and
Water-filling. For integral matching on bipartite graphs, we build on the
online primal dual analysis of Ranking and Water-filling to design a
$0.569$-competitive hybrid algorithm called Balanced Ranking. To our knowledge,
it is the first integral algorithm in the online matching literature that
successfully integrates ideas from Water-filling. For fractional matching on
general graphs, we give a $0.592$-competitive algorithm called Eager
Water-filling, which may match a vertex on its arrival. By contrast, the
original Water-filling algorithm always matches vertices at their deadlines.
Our result for fractional matching further shows a separation between fully
online matching and the general vertex arrival model by Wang and Wong (ICALP
2015), due to an upper bound of $0.5914$ in the latter model by Buchbinder,
Segev, and Tkach (ESA 2017).
</p></div>
    </summary>
    <updated>2020-05-14T22:27:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.06225</id>
    <link href="http://arxiv.org/abs/2005.06225" rel="alternate" type="text/html"/>
    <title>An improved solution approach for the Budget constrained Fuel Treatment Scheduling problem</title>
    <feedworld_mtime>1589414400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Croce:Federico_Della.html">Federico Della Croce</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghirardi:Marco.html">Marco Ghirardi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scatamacchia:Rosario.html">Rosario Scatamacchia</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06225">PDF</a><br/><b>Abstract: </b>This paper considers the budget constrained fuel treatment scheduling (BFTS)
problem where, in the context of wildfire mitigation, the goal is to inhibit
the potential of fire spread in a landscape by proper fuel treatment
activities. Given a time horizon represented by consecutive unit periods, the
landscape is divided into cells and represented as a grid graph where each cell
has a fuel age that increases over time and becomes old if no treatment is
applied in the meantime: this induces a potential high fire risk whenever two
contiguous cells are old. Cells fuel ages can be reset to zero under
appropriate fuel treatments but there is a limited budget for treatment in each
period. The problem calls for finding a suitable selection of cells to be
treated so as to minimize the presence of old contiguous cells over the whole
time horizon. We prove that problem BFTS is strongly NP-complete on paths and
thus on grid graphs and show that no polynomial time approximation algorithm
exists unless P = NP. We provide an enhanced integer linear programming
formulation of the problem with respect to the relevant literature that shows
up to be efficiently solved by an ILP solver on reasonably large size
instances. Finally, we consider a harder periodic variant of the problem with
the aim of finding a cyclic treatment plan with cycles of length T and propose
a matheuristic approach capable of efficiently tackling those instances where
an ILP solver applied to the ILP formulation runs into difficulties.
</p></div>
    </summary>
    <updated>2020-05-14T22:26:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.06156</id>
    <link href="http://arxiv.org/abs/2005.06156" rel="alternate" type="text/html"/>
    <title>A robust multi-dimensional sparse Fourier transform in the continuous setting</title>
    <feedworld_mtime>1589414400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jin:Yaonan.html">Yaonan Jin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Daogao.html">Daogao Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Song:Zhao.html">Zhao Song</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06156">PDF</a><br/><b>Abstract: </b>Sparse Fourier transform (Sparse FT) is the problem of learning an unknown
signal, whose frequency spectrum is dominated by a small amount of $k$
individual frequencies, through fast algorithms that use as few samples as
possible in the time domain. The last two decades have seen an extensive study
on such problems, either in the one-/multi-dimensional discrete setting
[Hassanieh, Indyk, Katabi, and Price STOC'12; Kapralov STOC'16] or in the
one-dimensional continuous setting [Price and Song FOCS'15]. Despite this rich
literature, the most general multi-dimensional continuous case remains
mysterious.
</p>
<p>This paper initiates the study on the Sparse FT problem in the
multi-dimensional continuous setting. Our main result is a randomized
non-adaptive algorithm that uses sublinear samples and runs in sublinear time.
In particular, the sample duration bound required by our algorithm gives a
non-trivial improvement over [Price and Song FOCS'15], which studies the same
problem in the one-dimensional continuous setting.
</p>
<p>The dimensionality in the continuous setting, different from both the
discrete cases and the one-dimensional continuous case, turns out to incur many
new challenges. To overcome these issues, we develop a number of new techniques
for constructing the filter functions, designing the permutation-then-hashing
schemes, sampling the Fourier measurements, and locating the frequencies. We
believe these techniques can find their applications in the future studies on
the Sparse FT problem.
</p></div>
    </summary>
    <updated>2020-05-14T22:23:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.06100</id>
    <link href="http://arxiv.org/abs/2005.06100" rel="alternate" type="text/html"/>
    <title>Structure and Algorithm for Path of Solutions to a Class of Fused Lasso Problems</title>
    <feedworld_mtime>1589414400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Cheng.html">Cheng Lu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06100">PDF</a><br/><b>Abstract: </b>We study a class of fused lasso problems where the estimated parameters in a
sequence are regressed toward their respective observed values (fidelity loss),
with $\ell_1$ norm penalty (regularization loss) on the differences between
successive parameters, which promotes local constancy. In many applications,
there is a coefficient, often denoted as $\lambda$, on the regularization term,
which adjusts the relative importance between the two losses.
</p>
<p>In this paper, we characterize how the optimal solution evolves with the
increment of $\lambda$. We show that, if all fidelity loss functions are convex
piecewise linear, the optimal value for \emph{each} variable changes at most
$O(nq)$ times for a problem of $n$ variables and total $q$ breakpoints. On the
other hand, we present an algorithm that solves the path of solutions of
\emph{all} variables in $\tilde{O}(nq)$ time for all $\lambda \geq 0$.
Interestingly, we find that the path of solutions for each variable can be
divided into up to $n$ locally convex-like segments. For problems of arbitrary
convex loss functions, for a given solution accuracy, one can transform the
loss functions into convex piecewise linear functions and apply the above
results, giving pseudo-polynomial bounds as $q$ becomes a pseudo-polynomial
quantity.
</p>
<p>To our knowledge, this is the first work to solve the path of solutions for
fused lasso of non-quadratic fidelity loss functions.
</p></div>
    </summary>
    <updated>2020-05-14T22:26:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.06046</id>
    <link href="http://arxiv.org/abs/2005.06046" rel="alternate" type="text/html"/>
    <title>Red-Blue Point Separation for Points on a Circle</title>
    <feedworld_mtime>1589414400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Misra:Neeldhara.html">Neeldhara Misra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mittal:Harshil.html">Harshil Mittal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sethia:Aditi.html">Aditi Sethia</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.06046">PDF</a><br/><b>Abstract: </b>Given a set R of red points and a set B of blue points in the plane, the
Red-Blue point separation problem asks if there are at most k lines that
separate R from B, that is, each cell induced by the lines of the solution is
either empty or monochromatic (containing points of only one color). A common
variant of the problem is when the lines are required to be axis-parallel. The
problem is known to be NP-complete for both scenarios, and W[1]-hard
parameterized by k in the former setting and FPT in the latter. We demonstrate
a polynomial-time algorithm for the special case when the points lie on a
circle. Further, we also demonstrate the W-hardness of a related problem in the
axis-parallel setting, where the question is if there are p horizontal and q
vertical lines that separate R from B. The hardness here is shown in the
parameter p.
</p></div>
    </summary>
    <updated>2020-05-14T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2005.05490</id>
    <link href="http://arxiv.org/abs/2005.05490" rel="alternate" type="text/html"/>
    <title>Monotone Boolean Functions, Feasibility/Infeasibility, LP-type problems and MaxCon</title>
    <feedworld_mtime>1589414400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suter:David.html">David Suter</a>, Ruwan Tennakoon, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Erchuan.html">Erchuan Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chin:Tat=Jun.html">Tat-Jun Chin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bab=Hadiashar:Alireza.html">Alireza Bab-Hadiashar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2005.05490">PDF</a><br/><b>Abstract: </b>This paper outlines connections between Monotone Boolean Functions, LP-Type
problems and the Maximum Consensus Problem. The latter refers to a particular
type of robust fitting characterisation, popular in Computer Vision (MaxCon).
Indeed, this is our main motivation but we believe the results of the study of
these connections are more widely applicable to LP-type problems (at least
'thresholded versions', as we describe), and perhaps even more widely. We
illustrate, with examples from Computer Vision, how the resulting perspectives
suggest new algorithms. Indeed, we focus, in the experimental part, on how the
Influence (a property of Boolean Functions that takes on a special form if the
function is Monotone) can guide a search for the MaxCon solution.
</p></div>
    </summary>
    <updated>2020-05-14T22:28:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/05/13/lecturer-at-university-of-illinois-chicago-apply-by-may-20-2020/</id>
    <link href="https://cstheory-jobs.org/2020/05/13/lecturer-at-university-of-illinois-chicago-apply-by-may-20-2020/" rel="alternate" type="text/html"/>
    <title>Lecturer at University of Illinois Chicago (apply by May 20, 2020)</title>
    <summary>The Department of Mathematics, Statistics, and Computer Science at UIC is accepting applications for Lecturer positions beginning in Fall 2020 to teach computer science and statistics courses. Please see the full ad at the link for more details. Website: https://jobs.uic.edu/job-board/job-details?jobID=131035&amp;job=lecturer-mathematics-statistics-and-computer-science Email: willp@uic.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Mathematics, Statistics, and Computer Science at UIC is accepting applications for Lecturer positions beginning in Fall 2020 to teach computer science and statistics courses. Please see the full ad at the link for more details.</p>
<p>Website: <a href="https://jobs.uic.edu/job-board/job-details?jobID=131035&amp;job=lecturer-mathematics-statistics-and-computer-science">https://jobs.uic.edu/job-board/job-details?jobID=131035&amp;job=lecturer-mathematics-statistics-and-computer-science</a><br/>
Email: willp@uic.edu</p></div>
    </content>
    <updated>2020-05-13T23:22:28Z</updated>
    <published>2020-05-13T23:22:28Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-05-14T22:32:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7728</id>
    <link href="https://windowsontheory.org/2020/05/13/resources-for-the-upcoming-job-market-crunch/" rel="alternate" type="text/html"/>
    <title>Resources for the upcoming job market crunch</title>
    <summary>Aside from its devastating death toll, the COVID-19 pandemic has had severe economic implications. The impact on universities is particularly substantial, including disruptions to our physical campuses and student residences, as well as to the sources of income for private and public universities such as endowments and state budgets. All this means that the academic […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Aside from its devastating death toll, the COVID-19 pandemic has had severe economic implications. The impact on universities is particularly substantial, including disruptions to our physical campuses and student residences, as well as to the sources of income for private and public universities such as endowments and state budgets.</p>



<p>All this means that the academic job market is likely going to be tough in the near future, and computer  science will not be immune. During the last recession, the CCC started a <a href="https://cra.org/ccc/leadership-development/cifellows/">computing innovation fellows</a> program which was very successful, and I hope that something similar will occur this time as well. But it won’t be enough.</p>



<p>If you are aware of any postdoc positions (or better yet, can create one) please do make sure to post it on the <a href="https://cstheory-jobs.org/">CS theory job board</a>. If you know of any teaching position that could potentially be applicable for theorists, please post it there too.  This crisis can also be an opportunity to get fantastic people for such positions. If you have any ideas on how we as the theoretical CS community can support graduating students  and postdocs, please do share these in the comments or on <a href="https://twitter.com/boazbaraktcs">Twitter</a>.</p>



<p>If anything, this crisis has taught us that the world needs more science, not less. Moreover, computer science has been and will continue to be a crucial component in fighting this epidemic, including not just modeling but also tracing applications using crypto, load balancing that ensures the Internet doesn’t crush, and more. I am thus hopeful that within a couple of years, the academic job market for theoretical computer scientists will recover. However we should try to do all we can to help our junior colleagues get through this period.</p></div>
    </content>
    <updated>2020-05-13T16:22:27Z</updated>
    <published>2020-05-13T16:22:27Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-05-14T22:32:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/05/13/postdoc-at-university-of-salzburg-apply-by-june-14-2020/</id>
    <link href="https://cstheory-jobs.org/2020/05/13/postdoc-at-university-of-salzburg-apply-by-june-14-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Salzburg (apply by June 14, 2020)</title>
    <summary>A postdoc position is available in the project “Distributed Algorithms for Fundamental Graph Problems” led by Sebastian Forster at the University of Salzburg, Austria. Research experience in efficient graph algorithms is required, but not specifically in the distributed setting. The position is for one year with the possibility of extension by another year. Website: https://www.cs.sbg.ac.at/~forster/openings.html […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A postdoc position is available in the project “Distributed Algorithms for Fundamental Graph Problems” led by Sebastian Forster at the University of Salzburg, Austria. Research experience in efficient graph algorithms is required, but not specifically in the distributed setting. The position is for one year with the possibility of extension by another year.</p>
<p>Website: <a href="https://www.cs.sbg.ac.at/~forster/openings.html">https://www.cs.sbg.ac.at/~forster/openings.html</a><br/>
Email: sebastian.forster@sbg.ac.at</p></div>
    </content>
    <updated>2020-05-13T14:54:41Z</updated>
    <published>2020-05-13T14:54:41Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-05-14T22:32:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blog.simons.berkeley.edu/?p=260</id>
    <link href="https://blog.simons.berkeley.edu/2020/05/lattice-blog-reduction-part-ii-slide-reduction/" rel="alternate" type="text/html"/>
    <title>Lattice Blog Reduction – Part II: Slide Reduction</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This is the second entry in a series of posts about lattice block reduction. See here for the first part. In this post I will assume you have read the first one, so if you haven’t, continue at your own … <a href="https://blog.simons.berkeley.edu/2020/05/lattice-blog-reduction-part-ii-slide-reduction/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This is the second entry in a series of posts about lattice block reduction. See <a class="uri" href="https://blog.simons.berkeley.edu/2020/04/lattice-blog-reduction-part-i-bkz/">here</a> for the first part. In this post I will assume you have read the first one, so if you haven’t, continue at your own risk. (I suggest reading at least the first part for context, notations and disclaimers.)</p>
<p>Last time we focused on BKZ which applies SVP reduction to successive projected subblocks. In this post we consider slide reduction, which allows for a much cleaner and nicer analysis. But before we can do that, we need a little more background.</p>
<h4 id="a-new-tool-dual-svp-reduction">A New Tool: Dual SVP Reduction</h4>
<p>As you hopefully know, duality is a very useful concept in lattice theory (and in mathematics more generally). It allows to pair up lattices, which are related in a well defined way. Similarly, we can pair up the different bases of two dual lattices to obtain dual bases. I’ll skip the definition of these two concepts since we will not need them. It is sufficient to know that we can compute the dual basis from the primal basis efficiently. One very cool feature of dual bases is that the last vector in the dual basis has a length that is inverse to the length of the last GSO vector of the primal basis. In math: if <span class="math inline">\({\mathbf{B}}\)</span> and <span class="math inline">\({\mathbf{D}}\)</span> are dual bases, then <span class="math inline">\(\| {\mathbf{b}}_n^* \| = \| {\mathbf{d}}_n \|^{-1}\)</span>. (If you want to see why this is true at least for full rank lattices, use the fact that in this case <span class="math inline">\({\mathbf{D}} = {\mathbf{B}}^{-T}\)</span>, and the QR-factorization.) It follows that if <span class="math inline">\({\mathbf{d}}_n\)</span> happens to be the shortest vector in the dual lattice, then <span class="math inline">\({\mathbf{b}}_n^*\)</span> is as long as possible, since the existence of any basis <span class="math inline">\(\bar{{\mathbf{B}}}\)</span> where <span class="math inline">\(\|\bar{{\mathbf{b}}}_n^*\| &gt; \|{\mathbf{b}}_n^*\|\)</span> would imply that there exists a dual basis <span class="math inline">\(\bar {{\mathbf{D}}}\)</span> such that <span class="math inline">\(\| \bar{{\mathbf{d}}}_n\| &lt; \| {\mathbf{d}}_n\| \)</span>. By analogy to SVP reduction, we call a basis, where <span class="math inline">\(\| {\mathbf{b}}^*_n \|\)</span> is maximized, dual SVP reduced (DSVP reduced). This gives us a new tool to control the size of the GSO vectors: we can apply an SVP algorithm to the dual basis of a projected subblock <span class="math inline">\({\mathbf{B}}_{[i,j]}\)</span>. This will yield a shortest vector in the dual of this projected sublattice. Then we can compute a dual basis, which contains this shortest vector in the last position and finally compute a new primal basis for this projected subblock, which now locally maximizes <span class="math inline">\(\|{\mathbf{b}}_j^* \|\)</span>. As we did for primal SVP reduction in the last post, we will assume access to an algorithm that, given a basis <span class="math inline">\({\mathbf{B}}\)</span> and indices <span class="math inline">\(i,j\)</span>, will return a basis such that <span class="math inline">\({\mathbf{B}}_{[i,j]}\)</span> is DSVP reduced and the rest of the basis is unchanged. We will call such an algorithm a DSVP oracle. It may sound like this should be somewhat less efficient than SVP reduction, since we have to switch between the dual and the primal bases (which, when done explicitly, requires matrix inversion), but this is not actually the case. In fact, one can implement a DSVP reduction entirely without having to explicitly compute (any part of) the dual basis as shown in [GN08,MW16].</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img alt="" class="wp-image-262" src="https://blog.simons.berkeley.edu/wp-content/uploads/2020/05/dsvp.png"/>Effect of a call to the DSVP oracle. GSO log norms of the input in black, of the output in blue. Note that the sum of the GSO log norms is a constant, so increasing the length of the last vector, decreases the (average of the) remaining vectors.</figure></div>



<p>I hope this figure provides some intuition that such an oracle can be useful. Now let us quantify how much this DSVP oracle helps us. Recall that in the primal SVP reduction we used Minkowski’s theorem to bound the length of the first vector. Since we are now applying the SVP algorithm to the dual, it should come as no surprise that we will use Minkowski’s theorem on the dual lattice, which tells us that <span class="math display">\[\lambda_1(\widehat{\Lambda}) \leq \sqrt{\gamma_n} \det(\widehat{\Lambda})^{1/n} = \sqrt{\gamma_n} \det(\Lambda)^{-1/n}\]</span> where <span class="math inline">\(\widehat{\Lambda}\)</span> is the dual lattice, i.e. the lattice generated by the dual basis. Furthermore, by exploiting above fact that for basis <span class="math inline">\({\mathbf{B}}\)</span> and its dual <span class="math inline">\({\mathbf{D}}\)</span> we have <span class="math inline">\(\| {\mathbf{b}}_n^* \| = \|{\mathbf{d}}_n \|^{-1}\)</span>, this shows that if <span class="math inline">\({\mathbf{B}}\)</span> is DSVP reduced, i.e. <span class="math inline">\({\mathbf{d}}_n\)</span> is a shortest vector in the dual lattice, then <span class="math display">\[\| {\mathbf{b}}_n^* \| = \|{\mathbf{d}}_n \|^{-1} = \lambda_1(\widehat{\Lambda})^{-1} \geq \frac{\det(\Lambda)^{1/n}}{\sqrt{\gamma_n}}.\]</span> So after we’ve applied the DSVP oracle to a projected block <span class="math inline">\({\mathbf{B}}_{[i-k+1,i]}\)</span>, we have <span class="math display">\[\|{\mathbf{b}}^*_i \| \geq  \frac{\left(\prod_{j = i-k+1}^{i} \|{\mathbf{b}}_j^* \| \right)^{1/k}}{\sqrt{\gamma_{k}}}.\]</span></p>
<h1 id="sec:slide">Slide Reduction</h1>
<p>Now we have all the tools we need to describe slide reduction [GN08]. One of the major hurdles to apply an LLL-style running time analysis to BKZ seems to be that the projected subblocks considered in that algorithm are maximally overlapping. So slide reduction takes a different route: it applies primal and dual SVP reduction to minimally overlapping subblocks, which allows to still prove nice bounds on the output quality (in fact, even better than BKZ), but also on the running time via a generalization of the LLL analysis. More specifically, let <span class="math inline">\({\mathbf{B}}\)</span> be the given lattice basis of an <span class="math inline">\(n\)</span>-dimensional lattice and <span class="math inline">\(k\)</span> be the blocksize. We require that <span class="math inline">\(k\)</span> divides <span class="math inline">\(n\)</span>. (We’ll come back to that restriction later.) Instead of applying our given SVP oracle to successive projected subblocks, we apply it to <em>disjoint</em> projected subblocks, i.e. to the blocks <span class="math inline">\({\mathbf{B}}_{[1,k]}\)</span>, <span class="math inline">\({\mathbf{B}}_{[k+1,2k]}\)</span>, etc. So we locally minimize the GSO vectors <span class="math inline">\({\mathbf{b}}^*_{ik + 1}\)</span> for <span class="math inline">\(i \in \{0,\cdots,n/k – 1\}\)</span>. (Technically, we iterate this step with a subsequent LLL reduction until there is no more change, which is important for the runtime analysis, but let’s ignore this for now). So now we have a basis where these disjoint projected subblocks are SVP-reduced. In the next step we shift the blocks by 1 and apply our DSVP oracle to them. (Note that the last block now extends beyond the basis, so we ignore this block.) This has the effect of locally maximizing the vectors <span class="math inline">\({\mathbf{b}}^*_{ik + 1}\)</span> for <span class="math inline">\(i \in \{1,\cdots,n/k – 1\}\)</span>. This might seem counter-intuitive at first, but note that the optimization context for <span class="math inline">\({\mathbf{b}}^*_{ik + 1}\)</span> changes between the SVP reduction and the DSVP reduction: <span class="math inline">\({\mathbf{b}}^*_{ik + 1}\)</span> is first minimized with respect to the block <span class="math inline">\({\mathbf{B}}_{[ik+1,(i+1)k]}\)</span> and then maximized with respect to the block <span class="math inline">\({\mathbf{B}}_{[(i-1)k+1,ik+1]}\)</span>. So one can view this as using the block <span class="math inline">\({\mathbf{B}}_{[ik+2, (i+1)k]}\)</span> as a pivot to lower the ratio between the lengths of the GSO vectors <span class="math inline">\({\mathbf{b}}^*_{ik+1}\)</span> and <span class="math inline">\({\mathbf{b}}^*_{(i+1)k+1}\)</span>. This view is reminiscent of the proof of Mordell’s inequality <span class="math inline">\(\gamma_n^{\frac{1}{n-1}} \leq \gamma_{n-1}^{\frac{1}{n-2}}\)</span>, which explains the title of the paper [GN08]. The idea of slide reduction is to simply iterate these two steps until there is no more change.</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img alt="" class="wp-image-265" src="https://blog.simons.berkeley.edu/wp-content/uploads/2020/05/slide-1024x910.png"/>Slide reduction in one picture: apply the SVP oracle to the disjoint projected blocks in parallel, then shift the blocks by 1 and apply the DSVP oracle. Repeat.</figure></div>



<p>Let’s dive into the analysis.</p>
<h4 id="the-good">The Good</h4>
<p>When the algorithm terminates, we are guaranteed that the following conditions hold simultaneously:</p>
<ol>
<li><p>The blocks <span class="math inline">\({\mathbf{B}}_{[ik+1, (i+1)k]}\)</span> are SVP reduced for all <span class="math inline">\(i \in \{0,\cdots,n/k – 1\}\)</span> (the <em>primal conditions</em>), which implies <span class="math display">\[\|{\mathbf{b}}^*_{ik+1} \|^{k-1} \leq \gamma_k^{k/2} \prod_{j=ik+2}^{(i+1)k} \|{\mathbf{b}}^*_j \|\]</span> (Note that we raised Minowski’s bound to the <span class="math inline">\(k\)</span>-th power and canceled one the <span class="math inline">\(\|{\mathbf{b}}^*_{ik+1} \|\)</span> on both sides.)</p></li>
<li><p>The blocks <span class="math inline">\({\mathbf{B}}_{[ik+2, (i+1)k+1]}\)</span> are DSVP reduced for all <span class="math inline">\(i \in \{0,\cdots,n/k – 2\}\)</span> (the <em>dual conditions</em>), which implies <span class="math display">\[\gamma_{k}^{k/2} \|{\mathbf{b}}^*_{(i+1)k+1} \|^{k-1} \geq \prod_{j = ik+2}^{(i+1)k} \|{\mathbf{b}}_j^* \|\]</span></p></li>
</ol>
<p>(Technically, there is a constant slack factor <span class="math inline">\(&gt;1\)</span> involved, which can be set arbitrarly close to 1, but is important for running time. We’ll sweep under the rug for simplicity.)</p>
<p>Just by staring at the two inequalities, you will notice that they can easily be combined to yield: <span class="math display">\[\|{\mathbf{b}}^*_{ik+1} \| \leq \gamma_k^{\frac{k}{k-1}} \|{\mathbf{b}}^*_{(i+1)k+1} \|\]</span> for all <span class="math inline">\(i \in \{0,\dots,n/k-2\}\)</span> and in particular <span class="math display">\[\|{\mathbf{b}}^*_{1} \| \leq \gamma_k^{\frac{k}{k-1} (\frac{n}{k}-1)} \|{\mathbf{b}}^*_{n-k+1} \|
= \gamma_k^{\frac{n-k}{k-1}} \|{\mathbf{b}}^*_{n-k+1} \|\]</span> By a similar trick as last time we can assume that <span class="math inline">\(\lambda_1({\mathbf{B}}) \geq \|{\mathbf{b}}^*_{n-k+1} \|\)</span>, because the last block is SVP-reduced, which shows that slide reduction achieves an approximation factor <span class="math display">\[\|{\mathbf{b}}^*_{1} \| \leq \gamma_k^{\frac{n-k}{k-1}} \lambda_1({\mathbf{B}}).\]</span> Done! Yes, it is really that simple. With (very) little more work one can similarly show a bound on the Hermite factor <span class="math display">\[\|{\mathbf{b}}^*_{1} \| \leq \gamma_k^{\frac{n-1}{2(k-1)}} \det({\mathbf{B}})^{\frac1n}.\]</span> Simply reuse the bounds on the ratios of <span class="math inline">\(\| {\mathbf{b}}^*_1 \|\)</span> and <span class="math inline">\(\| {\mathbf{b}}^*_{ik+1} \|\)</span> in combination with Minkowski’s bound for each block. (You guessed it: Homework!) Note that both of them are better than what we were able to obtain for BKZ in our last blog post. And in contrast to BKZ one can easily bound the number of calls to the SVP oracle by a polynomial in <span class="math inline">\(n, k\)</span> and the bit size of the original basis. The analysis is similar to the one of LLL with a modified potential function: we let <span class="math inline">\(P({\mathbf{B}}) = \prod_{i=0}^{n/k-2} \det({\mathbf{B}}_{[1,ik]})^2\)</span>. If the basis <span class="math inline">\({\mathbf{B}}\)</span> consists of integer coefficients only, this potential is also integral. Furthermore, one can show that if an iteration of slide reduction modifies the basis, it will decrease this potential by at least a constant factor (by using the slack factor we brushed over). This shows that while the basis is modified, the potential decreases exponentially, which results in a polynomial number of calls to the (D)SVP oracle.</p>
<h4 id="the-bad">The Bad</h4>
<p>We just sketched a complete and elegant analysis of the entire algorithm and it checks all the boxes: best known approximation factor, best known Hermite factor, a polynomial number of calls to its (D)SVP oracle. So what could possibly be bad about it? Remember that we required that the blocksize <span class="math inline">\(k\)</span> divides the dimension <span class="math inline">\(n\)</span>. It seems like it should be easy to get rid of this restriction, for example one could artificially increase the dimension of the lattice to assure that the blocksize divides it. Unfortunately, this and similar approaches will degrade the bound on the output quality – there will be a rounding-up operator in the exponent [LW13]. For small <span class="math inline">\(k\)</span> this might not be too much of an issue, but as <span class="math inline">\(k\)</span> grows, this results in a significant performance hit. Luckily, a recent work [ALNS19] shows that one can avoid this degradation by combining slide reduction with yet another block reduction algorithm: SDBKZ, which will be the topic of the next post.</p>
<h4 id="the-ugly">The Ugly</h4>
<p>Slide reduction is beautiful and there is little one can find ugly about it in theory. Unfortunately, experimental studies so far concluded that this algorithm is significantly inferior to BKZ, which (at least to me) is puzzling. This is often attributed to the fact that BKZ uses maximally overlapping blocks, which seems to allow it to obtain stronger reduction notions (even though we cannot prove it). So, one could wonder if there is an algorithm that uses maximally overlapping blocks (and is thus hopefully competetive in practice), but allows for a clean analysis. It turns out that the topic of the next post (SDBKZ) is such an algorithm.</p>
<ul>
<li><p>Gama, Nguyen. Finding short lattice vectors within Mordell’s inequality. STOC 2008</p></li>
<li><p>Li, Wei. Slide reduction, successive minima and several applications. Bulletin of the Australian Mathematical Society 2013</p></li>
<li><p>Micciancio, Walter. Practical, predictable lattice basis reduction. EUROCRYPT 2016</p></li>
<li><p>Aggarwal, Li, Nguyen, Stephens-Davidowitz. Slide Reduction, Revisited—Filling the Gaps in SVP Approximation. <a class="uri" href="https://arxiv.org/abs/1908.03724">https://arxiv.org/abs/1908.03724</a></p></li>
</ul></div>
    </content>
    <updated>2020-05-12T10:45:24Z</updated>
    <published>2020-05-12T10:45:24Z</published>
    <category term="General"/>
    <category term="Lattice Block Reduction"/>
    <author>
      <name>Michael Walter</name>
    </author>
    <source>
      <id>https://blog.simons.berkeley.edu</id>
      <link href="https://blog.simons.berkeley.edu/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blog.simons.berkeley.edu" rel="alternate" type="text/html"/>
      <subtitle>What's New at the Simons Institute for the Theory of Computing.</subtitle>
      <title>Calvin Café: The Simons Institute Blog</title>
      <updated>2020-05-14T22:33:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/05/12/ideal-workshop-on-estimation-of-network-processes-and-information-diffusion/</id>
    <link href="https://cstheory-events.org/2020/05/12/ideal-workshop-on-estimation-of-network-processes-and-information-diffusion/" rel="alternate" type="text/html"/>
    <title>IDEAL Workshop on Estimation of Network Processes and Information Diffusion</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">May 14, 2020 Virtual https://www.ideal.northwestern.edu/events/estimation-of-network-processes-and-information-diffusion/?fbclid=IwAR3HRiqCz8zTQfHt46hF-VF9PHE2F1v4uvQ6V_ggxmzKqFvromZXhVOOygY Many important dynamic processes are determined by an underlying network structure. Examples include the spread of epidemics, the dynamics of public opinions, the diffusion of information about social programs, and biological processes such as neural spike trains. Data about these processes is becoming increasingly available which has lead to a … <a class="more-link" href="https://cstheory-events.org/2020/05/12/ideal-workshop-on-estimation-of-network-processes-and-information-diffusion/">Continue reading <span class="screen-reader-text">IDEAL Workshop on Estimation of Network Processes and Information Diffusion</span></a></div>
    </summary>
    <updated>2020-05-12T03:47:26Z</updated>
    <published>2020-05-12T03:47:26Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-05-14T22:33:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17029</id>
    <link href="https://rjlipton.wordpress.com/2020/05/11/consistency-and-pnp/" rel="alternate" type="text/html"/>
    <title>Consistency and P=NP</title>
    <summary>Can we at least show that is consistent? [ From personal page ] Jan Krajicek is an expert on linking computational complexity and mathematical logic. He has authored four books on this area including the often cited text Bounded Arithmetic and Complexity Theory. Moreover, he has studied the consistency of various of theories and whether […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Can we at least show that <img alt="{P\neq NP}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%5Cneq+NP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P\neq NP}"/> is consistent?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/05/11/consistency-and-pnp/unknown-140/" rel="attachment wp-att-17032"><img alt="" class="alignright size-full wp-image-17032" src="https://rjlipton.files.wordpress.com/2020/05/unknown.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ From personal page ]</font></td>
</tr>
</tbody>
</table>
<p>
Jan Krajicek is an expert on linking computational complexity and mathematical logic. He has authored four books on this area including the often cited <a href="https://www.cambridge.org/core/books/bounded-arithmetic-propositional-logic-and-complexity-theory/899C8FF084B3EB2430EDEBC27921D635">text</a> <em>Bounded Arithmetic and Complexity Theory</em>. Moreover, he has studied the consistency of various of theories and whether they can prove <img alt="{\mathsf{P \neq NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P \neq NP}}"/> and related questions. </p>
<p>
Today I thought we would discuss consistency proofs in general.</p>
<p>
Lately I have been thinking about <img alt="{\mathsf{P=NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P=NP}}"/> and logic, with emphasis on consistency results. Thanks to Kurt Gödel’s famous Second Incompleteness Theorem we know that consistency theorems are difficult to prove. In particular he showed that</p>
<blockquote><p><b>Theorem 1 (Informally)</b> <em> Any sufficiently powerful consistent theory cannot prove that it is consistent. </em>
</p></blockquote>
<p/><p>
In order to prove that some theory <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> is consistent we need a stronger theory say <img alt="{T^{*}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%5E%7B%2A%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T^{*}}"/>. But to prove this theory is itself consistent we need an even stronger theory <img alt="{T^{**}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%5E%7B%2A%2A%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T^{**}}"/> and so on. As they <a href="https://en.wikipedia.org/wiki/Turtles_all_the_way_down">say</a>:</p>
<blockquote><p><b> </b> <em> Its turtles all the way down. </em>
</p></blockquote>
<p/><p>
It is not clear who first said this, but an 1854 <a href="https://books.google.com/books?id=SGtYAAAAMAAJ&amp;pg=PA48#v=onepage&amp;q&amp;f=false">transcript</a> of debates between a mainline and maverick minister records the former (Joseph Berg) saying of the latter (Joseph Barker):</p>
<blockquote><p><b> </b> <em> My opponent’s reasoning reminds me of the heathen, who, being asked on what the world stood, replied, “On a tortoise.” But on what does the tortoise stand? “On another tortoise.” With Mr. Barker, too, there are tortoises all the way down. </em>
</p></blockquote>
<p/><p>
Recall a logical theory is consistent provided it never proves <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and <img alt="{\neg A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneg+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neg A}"/> where as usual <img alt="{\neg A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneg+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neg A}"/> means “not” <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>. Thus a theory is consistent provided it will never prove both <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and <img alt="{\neg A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneg+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neg A}"/>. This means that once a statement is proved we are done. There will be no surprise in the future. </p>
<p>
Bluntly: I would hate if my paper showing that <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> is true, was followed by your paper showing that <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> is also false. Besides pride I would hate this because, then any statement is true. This would certainly reduce any interest in my theorem proving <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> and also in your theorem proving <img alt="{\neg X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneg+X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neg X}"/>. This is “ex contradictione quodlibet”.</p>
<p>
The rule 	</p>
<p align="center"><img alt="\displaystyle  X \text{ and } \neg X \implies \text{``Pigs can fly''} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X+%5Ctext%7B+and+%7D+%5Cneg+X+%5Cimplies+%5Ctext%7B%60%60Pigs+can+fly%27%27%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  X \text{ and } \neg X \implies \text{``Pigs can fly''} "/></p>
<p>must be true. Right. Or must it? In a moment, but first some examples of consistency issues.</p>
<p>
</p><p/><h2> Failure of Consistency </h2><p/>
<p/><p>
Since David Hilbert explicitly, and before implicitly, there has been interest in showing that our math theories are consistent. It may seem strange that consistency could ever be an issue, but read on.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>A theory that was thought to be inconsistent:</i><br/>
The creation of non-Euclidean geometries asked could these geometries be consistent? The answer is yes. It is possible to show that they are as consistent as Euclidean geometries. This done by building models of their new geometry by using Eucildean geometries in clever ways.</p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/05/11/consistency-and-pnp/models2/" rel="attachment wp-att-17033"><img alt="" class="aligncenter size-medium wp-image-17033" height="282" src="https://rjlipton.files.wordpress.com/2020/05/models2.jpg?w=300&amp;h=282" width="300"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"/>
</td>
</tr>
</tbody></table>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>A theory that was thought to be consistent:</i> <br/>
The famous Russell paradox destroyed early formulations of set theory. Bertrand Russell noted that the formulations allowed defining the following as a set: 	</p>
<p align="center"><img alt="\displaystyle  S = \{ x \mid x \not\in x \}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S+%3D+%5C%7B+x+%5Cmid+x+%5Cnot%5Cin+x+%5C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  S = \{ x \mid x \not\in x \}. "/></p>
<p>But this is a problem, since it creates logical statements that are equivalent to their negations: 	</p>
<p align="center"><img alt="\displaystyle  x \in S \iff x \not\in S. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%5Cin+S+%5Ciff+x+%5Cnot%5Cin+S.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x \in S \iff x \not\in S. "/></p>
<p>Fixing this led to the creation of modern set theory <a href="https://plato.stanford.edu/entries/set-theory/#AxiZFC">ZF</a>. It is named Zermelo-Fraenkel set theory, after Ernst Zermelo and Abraham Fraenkel.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <i>A theory that was thought to be—still unclear:</i> <br/>
Willard Quine’s theory “New Foundations” (<a href="https://en.wikipedia.org/wiki/New_Foundations">NF</a>) of set theory remains a problem. There are some possible relative proofs that show that it is as consistent as normal set theory. See this for the <a href="https://arxiv.org/abs/1503.01406">claim</a> by Randall Holmes that NF is as consistent as ZF—see <a href="https://math.boisestate.edu/~holmes/nfproof/sorted_at_last_maybe.pdf">this</a>.</p>
<p>
</p><p/><h2> Length-based Immunity </h2><p/>
<p/><p>
The sentences used by Krajicek and his co-authors Jan Bydzovsky and Igor Oliveira in a recent <a href="https://arxiv.org/abs/1905.12935">paper</a> deal with forms of <em>length-based immunity</em>. The complexity-theoretic definition is this:</p>
<blockquote><p><b>Definition 2</b> <em><a name="lbimmune"/> A language <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B}"/> is <b>length-based immune</b> (LBI) to <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/> if for every polynomial-time program <img alt="{P_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_i%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{P_i}"/>, there are only finitely many <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> such that <img alt="{P_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_i%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{P_i}"/> is correct on strings of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>. That is, </em></p><em>
<p align="center"><img alt="\displaystyle  (\forall P_i)(\exists \ell)(\forall n &gt; \ell)(\exists x \in \Sigma^n): P_i(x) \neq B(x). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28%5Cforall+P_i%29%28%5Cexists+%5Cell%29%28%5Cforall+n+%3E+%5Cell%29%28%5Cexists+x+%5Cin+%5CSigma%5En%29%3A+P_i%28x%29+%5Cneq+B%28x%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  (\forall P_i)(\exists \ell)(\forall n &gt; \ell)(\exists x \in \Sigma^n): P_i(x) \neq B(x). "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
This property is akin to <em>immunity</em>: not having an infinite easy subset. The known <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/>-complete sets are <em>not</em> immune: for instance there are many easy cases of SAT. Under the <a href="https://en.wikipedia.org/wiki/Berman-Hartmanis_conjecture">Isomorphism Conjecture</a>, no <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/>-complete set is immune. Whether SAT can be length-based immune might depend on details of how formulas are encoded, but under a “natural” encoding one might expect length-based immunity to hold.</p>
<p>
Of course, if <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> has a length-based immune set then <img alt="{\mathsf{P \neq NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P \neq NP}}"/>. Say a theory <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> is “adequate” if it is consistent and proves basic facts about complexity classes such as that one. Then for an adequate theory <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>:</p>
<blockquote><p><b> </b> <em> Suppose we prove it is consistent with <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T}"/> that <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> has an LBI set. Then <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T}"/> cannot prove that <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> does not have an LBI set. Since <img alt="{\mathsf{P = NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{P = NP}}"/> imples that <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> does not have an LBI set, this yields the simple and notable conclusion that <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T}"/> cannot prove <img alt="{\mathsf{P = NP}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D.%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{P = NP}.}"/> That is, <img alt="{\mathsf{P \neq NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+NP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{P \neq NP}}"/> is consistent with <img alt="{T.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT.%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T.}"/></em>
</p></blockquote>
<p/><p>
Krajicek, as we said before, has tried to prove that complexity statements like <img alt="{\mathsf{P \neq NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P \neq NP}}"/> are consistent. The trouble is that such questions are difficult. So he and others have worked on showing that these questions are at least consistent with theories <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> of arithmetic. It seems too hard to handle Peano arithmetic yet, so they work with theories <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> that are weaker than Peano arithmetic—but still adequate. For these theories, Krajicek and company have results for some variations of Definition~<a href="https://rjlipton.wordpress.com/feed/#lbimmune">2</a>, albeit ones that seem not to have a direct relation to <img alt="{\mathsf{P = NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P = NP}}"/>. The two main ways to vary the Definition~<a href="https://rjlipton.wordpress.com/feed/#lbimmune">2</a> are:</p>
<ul>
<li>
Change the class <img alt="{\mathcal{C}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{C}}"/> that has—or may not have—a length-based immune set to something else, for instance <img alt="{\mathcal{C} = \mathsf{P^{NP}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BC%7D+%3D+%5Cmathsf%7BP%5E%7BNP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{C} = \mathsf{P^{NP}}}"/>. <p/>
</li><li>
Change the class <img alt="{\mathcal{Q}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BQ%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{Q}}"/> of programs the sets are immune to from polynomial-time programs to something else.
</li></ul>
<p>
</p><p/><h2> Fixed Polynomial Size Circuits </h2><p/>
<p/><p>
They fix a constant exponent <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> and take <img alt="{\mathcal{Q}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BQ%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{Q}}"/> to be families of <em>circuits</em> <img alt="{C_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_n}"/> of fixed polynomial size <img alt="{n^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^k}"/>. The circuits can be non-uniform, and indeed the unprovable statements are defined by a process that is not constructive. </p>
<p>
Circuits of linear or other fixed polynomial size are a fascinating and important topic in themselves. We have <a href="https://rjlipton.wordpress.com/2010/03/31/a-problem-with-proving-problems-are-hard/">posted</a> about Ravi Kannan’s famous theorem that for every fixed <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>, the second level of the polynomial hierarchy has languages without <img alt="{n^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^k}"/>-sized circuits. The upper bound has since been pushed lower but not all the way to <img alt="{\mathsf{P^{NP}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%5E%7BNP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P^{NP}}}"/>. It is of course believed that <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> has languages without <img alt="{n^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^k}"/>-sized circuits, since SAT is believed to require super-polynomial size. But the question of whether <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> has sets that lack such circuits—let alone being immune—is currently not known to have implications about <img alt="{\mathsf{P = NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P = NP}}"/>. </p>
<p>
Note that the easy instances of SAT that we alluded to above are easy for linear-size circuits. Moreover, whether <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/> itself has—or doesn’t have—sets that are length-based immune to <img alt="{n^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^k}"/>-size circuits is a statement that can be plausibly argued either way. Krajicek and Oliveira had earlier <a href="https://arxiv.org/abs/1605.00263">proved</a> that a particular theory called PV—which we will discuss next—cannot prove for any <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> that every language in <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/> has <img alt="{n^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^k}"/>-sized circuits. This unprovable statement, without the LBI condition, strikes us as less plausible—hence less surprising that a weaker theory like PV cannot prove it. What they prove now is:</p>
<blockquote><p><b>Theorem 3</b> <em><a name="thm1a"/> For any fixed <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k}"/>, PV cannot prove that every language in <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/> allows circuits of size <img alt="{n^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n^k}"/> to get the right answers on infinitely many input lengths. That is, it is consistent with PV that <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/> has sets that are LBI to <img alt="{n^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n^k}"/>-size circuits.</em></p><em>
</em><p><em>
Moreover, for some particular theories called <img alt="{S^1_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%5E1_2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S^1_2}"/> and <img alt="{T^1_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%5E1_2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T^1_2}"/> that extend PV, it is consistent that <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/>, respectively <img alt="{\mathsf{p^{NP}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bp%5E%7BNP%7D%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\mathsf{p^{NP}}}"/> has sets that are LBI to <img alt="{n^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n^k}"/>-sized circuits. </em>
</p></blockquote>
<p/><p>
We will talk a little more about these theories.</p>
<p>
</p><p/><h2> PV and Related Theories </h2><p/>
<p/><p>
What are the candidate theories for <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>? One is PV, a theory created by Steve Cook. For every polynomial-time program <img alt="{P_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_i}"/>, PV has a symbol <img alt="{\varphi_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvarphi_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\varphi_i}"/> for the function that <img alt="{P_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_i}"/> computes. Then add all the equations that these functions satisfy and you have PV. For example, 	</p>
<p align="center"><img alt="\displaystyle  2^{x+1} = 2 \times 2^{x}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++2%5E%7Bx%2B1%7D+%3D+2+%5Ctimes+2%5E%7Bx%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  2^{x+1} = 2 \times 2^{x}, "/></p>
<p>for the exponential function <img alt="{x \rightarrow 2^{x}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Crightarrow+2%5E%7Bx%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x \rightarrow 2^{x}}"/>. </p>
<p>
PV can formalize and prove properties of program-building constructs like composition and bounded for-loops that preserve running in polynomial time. It can formalize the concept of polynomial-size Boolean circuits and establish basic facts about them. It can prove deep results like the PCP theorem and more. </p>
<p>
Thus showing that your favorite statement is at least consistent with PV would be neat. It is critical that PV only allows equations as axioms. Thus PV does not axiomatize the statement 	</p>
<p align="center"><img alt="\displaystyle  \forall x \exists y&gt;x \ 2^{y}-1 \text{ is a prime} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+x+%5Cexists+y%3Ex+%5C+2%5E%7By%7D-1+%5Ctext%7B+is+a+prime%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \forall x \exists y&gt;x \ 2^{y}-1 \text{ is a prime} "/></p>
<p>even if it is true. The more-formal statement of their theorem for PV is:</p>
<blockquote><p><b>Theorem 4</b> <em><a name="thm1b"/> For every <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k}"/>, there is a formula <img alt="{\varphi(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvarphi%28x%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\varphi(x)}"/> in the language of PV such that the statement </em></p><em>
<p align="center"><img alt="\displaystyle  \Upsilon_{\varphi} = (\forall \ell)(\exists n &gt; \ell)(\exists C_n \text{ of size } \leq n^k)(\forall x\in \Sigma^n): \varphi(x) = C_n(x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5CUpsilon_%7B%5Cvarphi%7D+%3D+%28%5Cforall+%5Cell%29%28%5Cexists+n+%3E+%5Cell%29%28%5Cexists+C_n+%5Ctext%7B+of+size+%7D+%5Cleq+n%5Ek%29%28%5Cforall+x%5Cin+%5CSigma%5En%29%3A+%5Cvarphi%28x%29+%3D+C_n%28x%29+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  \Upsilon_{\varphi} = (\forall \ell)(\exists n &gt; \ell)(\exists C_n \text{ of size } \leq n^k)(\forall x\in \Sigma^n): \varphi(x) = C_n(x) "/></p>
</em><p><em>is not provable in PV, and such that the function <img alt="{\varphi(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvarphi%28x%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\varphi(x)}"/> is polynomial-time computable. </em>
</p></blockquote>
<p/><p>
The theorem is not diminished if we restrict attention to yes/no formulas and circuit outputs. Thus it is not provable that every language in <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/> has infinitely many input lengths at which it is easy for <img alt="{n^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^k}"/>-sized circuits. Put another way, it is consistent with PV to assert (for any <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>) that <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/> has a language that lacks size-<img alt="{n^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^k}"/> circuits <img alt="{C_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_n}"/> in the strong sense of <em>every</em> <img alt="{C_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_n}"/> making an error on some string of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, beyond a finite number of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. This is stronger than saying the language lacks <img alt="{n^k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^k}"/>-size circuits, which makes the consistency more notable.</p>
<p>
Where PV lacks power is with the unrestricted induction enjoyed by Peano Arithmetic. The other theories <img alt="{S_2^1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS_2%5E1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S_2^1}"/> and <img alt="{T_2^1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_2%5E1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_2^1}"/>, which were named and studied by Sam Buss in the 1980s, add more induction—by limiting the kind of formulas on which it is allowed.</p>
<p>
Here is where we point to the papers for details. The devil in those details is that the exceptional formulas <img alt="{\varphi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvarphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\varphi}"/> are not expressly constructed. For one, the proofs of their theorems use a disjunction about whether the polynomial hierarchy collapses at a certain level. Note that something similar is already at work in our <a href="https://rjlipton.wordpress.com/2010/03/31/a-problem-with-proving-problems-are-hard/">post</a> on Kannan’s theorem. </p>
<p>
Second, their proofs exploit a quirk of PV and the other theories that they have symbols for all polynomial-time programs without having commensurate command of the semantics of what these programs represent. The induction and axioms available to <img alt="{S_2^1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS_2%5E1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S_2^1}"/> and <img alt="{T_2^1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_2%5E1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_2^1}"/> bridge some but not all of these gaps. </p>
<p>
Third and most particular, their theorem uses a self-referential strategy. It starts building <img alt="{\varphi'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvarphi%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\varphi'}"/> but branches according to whether the theory <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> can prove <img alt="{\Upsilon_{\varphi'}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CUpsilon_%7B%5Cvarphi%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Upsilon_{\varphi'}}"/>. If not it keeps going, if yes it does something else. Thus the proof does not tell what <img alt="{\varphi(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cvarphi%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\varphi(x)}"/> is, nor identify a particular language in <img alt="{\mathcal{C}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{C}}"/> for which the LBI property is consistent.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Another way of saying “Statement <img alt="{\Upsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CUpsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Upsilon}"/> is consistent with <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>” is that one can build a <em>model</em> of <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> in which <img alt="{\Upsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CUpsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Upsilon}"/> is true. What do those models look like? Do they relate to the notion of <em>oracles</em> <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> relative to which certain statements—such as <img alt="{\mathsf{NP}^A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}^A}"/> having languages that are (length-based-) immune to <img alt="{\mathsf{P}^A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}^A}"/>—are true?</p>
<p>
[William–&gt;Willard Quine]</p></font></font></div>
    </content>
    <updated>2020-05-11T12:51:06Z</updated>
    <published>2020-05-11T12:51:06Z</published>
    <category term="Ideas"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="consistent"/>
    <category term="models"/>
    <category term="Peano"/>
    <category term="SAT"/>
    <category term="Theory"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-05-14T22:32:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3481</id>
    <link href="https://agtb.wordpress.com/2020/05/11/special-issue-of-jaamas-on-fair-division/" rel="alternate" type="text/html"/>
    <title>Special Issue of JAAMAS on Fair Division</title>
    <summary>Dear all, We are happy to announce that the Journal of Autonomous Agents and Multiagent Systems will host a special issue on Fair Division. We welcome full versions of papers on fair division that have appeared in recent editions of AAMAS, IJCAI, AAAI, ECAI, ACM EC, WINE, SAGT, and other relevant conferences, as well as […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Dear all,</p>
<p>We are happy to announce that the Journal of Autonomous Agents and Multiagent Systems will host a special issue on Fair Division. We welcome full versions of papers on fair division that have appeared in recent editions of AAMAS, IJCAI, AAAI, ECAI, ACM EC, WINE, SAGT, and other relevant conferences, as well as papers that have not been published in conference proceedings.</p>
<p><a href="https://www.springer.com/journal/10458/updates/17851836">Call for Papers</a></p>
<p>Please note that there will be a rolling review process: submissions accepted before the completion of the issue will be available on the journal website shortly after acceptance. Deadline: March 1, 2021.</p>
<p>Guest Editors<br/>
Edith Elkind<br/>
Nicolas Maudet<br/>
Warut Suksompong</p></div>
    </content>
    <updated>2020-05-11T11:05:41Z</updated>
    <published>2020-05-11T11:05:41Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>felixbrandt</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2020-05-14T22:32:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19844</id>
    <link href="https://gilkalai.wordpress.com/2020/05/11/to-cheer-you-up-in-difficult-times-4-wit-presents-i-will-survive/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 4: Women In Theory present — I will survive</title>
    <summary>An amazing video The original 1978 version is also quite good.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>An amazing video</p>
<p/>
<p><span id="more-19844"/></p>
<p>The original 1978 version is also quite good.<br/>
</p></div>
    </content>
    <updated>2020-05-10T21:53:30Z</updated>
    <published>2020-05-10T21:53:30Z</published>
    <category term="Academics"/>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Convexity"/>
    <category term="Games"/>
    <category term="Philosophy"/>
    <category term="Poetry"/>
    <category term="What is Mathematics"/>
    <category term="Women in science"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-05-14T22:32:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1693</id>
    <link href="https://theorydish.blog/2020/05/10/weve-got-wit-and-they-got-talent/" rel="alternate" type="text/html"/>
    <title>We’ve got WIT and they got Talent</title>
    <summary>The wonderful Women in Theory is, like so many other events this year, virtual in 2020 (physical meeting postponed to 2021). And it is happening today! The virtual meeting lets our WIT show that their talents go beyond science. Highly recommended clip! I’ve been watching on loop 🙂</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The wonderful <a href="https://theorydish.blog/2020/01/09/women-in-theory-2018-call-for-application-2/">Women in Theory</a> is, like so many other events this year, virtual in 2020 (physical meeting <a href="https://womenintheory.wordpress.com/">postponed to 2021)</a>. And it is happening today! The virtual meeting lets our WIT show that their talents go beyond science. <a href="https://www.youtube.com/watch?v=4Wl-3kadvgw">Highly recommended clip</a>! I’ve been watching on loop <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/></p></div>
    </content>
    <updated>2020-05-10T17:41:07Z</updated>
    <published>2020-05-10T17:41:07Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-05-14T22:33:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/05/10/visiting-professor-at-university-of-tyumen-school-of-advanced-studies-apply-by-june-30-2020/</id>
    <link href="https://cstheory-jobs.org/2020/05/10/visiting-professor-at-university-of-tyumen-school-of-advanced-studies-apply-by-june-30-2020/" rel="alternate" type="text/html"/>
    <title>Visiting Professor at University of Tyumen, School of Advanced Studies (apply by June 30, 2020)</title>
    <summary>Visiting Professors of Computer Science, 2-10 months appointments during 2020-2021 academic year. No knowledge of Russian is required. Please send a CV, two letters of reference (to be sent separately), and a cover letter describing your professional background, including the description of courses you have taught or would like to teach, to job.sas@utmn.ru. Website: https://sas.utmn.ru/en/ […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Visiting Professors of Computer Science, 2-10 months appointments during 2020-2021 academic year. No knowledge of Russian is required.</p>
<p>Please send a CV, two letters of reference (to be sent separately), and a cover letter describing your professional background, including the description of courses you have taught or would like to teach, to job.sas@utmn.ru.</p>
<p>Website: <a href="https://sas.utmn.ru/en/">https://sas.utmn.ru/en/</a><br/>
Email: d.kontowski@utmn.ru</p></div>
    </content>
    <updated>2020-05-10T06:35:29Z</updated>
    <published>2020-05-10T06:35:29Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-05-14T22:32:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=430</id>
    <link href="https://tcsplus.wordpress.com/2020/05/08/430/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, May 13 — Sahil Singla, Princeton University and IAS</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, May 13th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Sahil Singla from Princeton University and IAS will speak about “Online Vector Balancing and Geometric Discrepancy” (abstract below). You can reserve a spot as an individual or a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, May 13th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Sahil Singla</strong> from Princeton University and IAS will speak about “<em>Online Vector Balancing and Geometric Discrepancy</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our website</a> on the day of the talk, so people who did not sign up will still be able to watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: We consider an online vector balancing question where <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=fff&amp;fg=444444&amp;s=0" title="T"/> vectors, chosen from an arbitrary distribution over <img alt="[-1,1]^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D%5En&amp;bg=fff&amp;fg=444444&amp;s=0" title="[-1,1]^n"/>, arrive one-by-one and must be immediately given a <img alt="\{+1,-1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%2B1%2C-1%5C%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="\{+1,-1\}"/> sign. The goal is to keep the discrepancy—the <img alt="\ell_{\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_%7B%5Cinfty%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="\ell_{\infty}"/>-norm of any signed prefix-sum—as small as possible. A concrete example of this question is the online interval discrepancy problem where <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=fff&amp;fg=444444&amp;s=0" title="T"/> points are sampled one-by-one uniformly in the unit interval <img alt="[0,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=fff&amp;fg=444444&amp;s=0" title="[0,1]"/>, and the goal is to immediately color them <img alt="\{+1,-1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%2B1%2C-1%5C%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="\{+1,-1\}"/> such that every sub-interval remains always nearly balanced. As random coloring incurs <img alt="\Omega(T^{1/2})" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%28T%5E%7B1%2F2%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\Omega(T^{1/2})"/> discrepancy, while the worst-case offline bounds are <img alt="\Theta(\sqrt{n \log (T/n)})" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta%28%5Csqrt%7Bn+%5Clog+%28T%2Fn%29%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\Theta(\sqrt{n \log (T/n)})"/> for vector balancing and 1 for interval balancing, a natural question is whether one can (nearly) match the offline bounds in the online setting for these problems. One must utilize the stochasticity as in the worst-case scenario it is known that discrepancy is <img alt="\Omega(T^{1/2})" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%28T%5E%7B1%2F2%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\Omega(T^{1/2})"/> for any online algorithm.</p>
<p>In this work, we introduce a new framework that allows us to handle online vector balancing even when the input distribution has dependencies across coordinates. In particular, this lets us obtain a <img alt="\textrm{poly}(n, \log T)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7Bpoly%7D%28n%2C+%5Clog+T%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{poly}(n, \log T)"/> bound for online vector balancing under arbitrary input distributions, and a <img alt="\textrm{poly}\log (T)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7Bpoly%7D%5Clog+%28T%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{poly}\log (T)"/> bound for online interval discrepancy. Our framework is powerful enough to capture other well-studied geometric discrepancy problems; e.g., we obtain a <img alt="\textrm{poly}(\log^d (T))" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7Bpoly%7D%28%5Clog%5Ed+%28T%29%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\textrm{poly}(\log^d (T))"/> bound for the online <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=fff&amp;fg=444444&amp;s=0" title="d"/>-dimensional Tusnády’s problem. All our bounds are tight up to polynomial factors.</p>
<p>A key new technical ingredient in our work is an anti-concentration inequality for sums of pairwise uncorrelated random variables, which might also be of independent interest.</p>
<p>Based on joint works with Nikhil Bansal, Haotian Jiang, Janardhan Kulkarni, and Makrand Sinha. Part of this work appears in STOC 2020 and is available at <a href="https://arxiv.org/abs/1912.03350" rel="nofollow">https://arxiv.org/abs/1912.03350</a></p></blockquote>
<p> </p></div>
    </content>
    <updated>2020-05-09T01:20:02Z</updated>
    <published>2020-05-09T01:20:02Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-05-14T22:33:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/05/08/14-phd-positions-in-stochastics-and-algorithmics-cofund-at-networks-apply-by-may-31-2020/</id>
    <link href="https://cstheory-jobs.org/2020/05/08/14-phd-positions-in-stochastics-and-algorithmics-cofund-at-networks-apply-by-may-31-2020/" rel="alternate" type="text/html"/>
    <title>14 PhD Positions in Stochastics and Algorithmics (COFUND) at NETWORKS (apply by May 31, 2020)</title>
    <summary>The research project NETWORKS is looking for 14 international PhD students in mathematics and computer science. Are you interested in the stochastics and algorithmics behind network problems? And would you like to be part of this project with its many activities? Then we invite you to apply for one of these positions. Website: https://www.thenetworkcenter.nl/Open-Positions/openposition/29/14-PhD-Positions-in-Stochastics-and-Algorithmics-COFUND- Email: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The research project NETWORKS is looking for 14 international PhD students in mathematics and computer science. Are you interested in the stochastics and algorithmics behind network problems? And would you like to be part of this project with its many activities? Then we invite you to apply for one of these positions.</p>
<p>Website: <a href="https://www.thenetworkcenter.nl/Open-Positions/openposition/29/14-PhD-Positions-in-Stochastics-and-Algorithmics-COFUND-">https://www.thenetworkcenter.nl/Open-Positions/openposition/29/14-PhD-Positions-in-Stochastics-and-Algorithmics-COFUND-</a><br/>
Email: info@thenetworkcenter.nl</p></div>
    </content>
    <updated>2020-05-08T13:12:32Z</updated>
    <published>2020-05-08T13:12:32Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-05-14T22:32:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19821</id>
    <link href="https://gilkalai.wordpress.com/2020/05/08/to-cheer-you-up-in-difficult-times-3-a-guest-post-by-noam-lifshitz-on-the-new-hypercontractivity-inequality-of-peter-keevash-noam-lifshitz-eoin-long-and-dor-minzer/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 3: A guest post by Noam Lifshitz on the new hypercontractivity inequality of Peter Keevash, Noam Lifshitz, Eoin Long and Dor Minzer</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This is a guest post kindly contributed by Noam Lifshitz. My short introduction: There is nothing like a new hypercontractivity inequality to cheer you up in difficult times and this post describes an amazing new hypercontractivity inequality.  The post describes … <a href="https://gilkalai.wordpress.com/2020/05/08/to-cheer-you-up-in-difficult-times-3-a-guest-post-by-noam-lifshitz-on-the-new-hypercontractivity-inequality-of-peter-keevash-noam-lifshitz-eoin-long-and-dor-minzer/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>This is a guest post kindly contributed by Noam Lifshitz</em>.</p>
<p>My short introduction: There is nothing like a new hypercontractivity inequality to cheer you up in difficult times and this post describes an amazing new hypercontractivity inequality.  The post describes a recent hypercontractive inequality by Peter Keevash, Noam Lifshitz, Eoin Long and Dor Minzer (KLLM) from their paper: <a href="https://arxiv.org/abs/1906.05568">Hypercontractivity for global functions and sharp thresholds</a>. (We reported on this development in <a href="https://gilkalai.wordpress.com/2018/10/30/exciting-beginning-of-the-year-activities-and-seminars/">this post</a>. By now, there are quite a few important applications.) And for Talagrand’s generic chaining inequality, see this <a href="https://lucatrevisan.wordpress.com/2020/05/03/talagrands-generic-chaining/">beautiful blog post</a> by Luca Trevisan.</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/04/barrysimon.jpg"><img alt="" class="alignnone size-full wp-image-19825" src="https://gilkalai.files.wordpress.com/2020/04/barrysimon.jpg?w=640"/></a></p>
<p><span style="color: #ff0000;">Barry Simon coined the term “hypercontractivity” in the 70s.  (We asked about it here and Nick Read was the first to answer.) A few months ago Barry told us about the early history of hypercontractivity inequalities, and, in particular, the very entertaining story on William Beckner’s Ph. D. qualifying exam.</span></p>
<p>And now to Noam Lifshitz’s guest post.</p>
<h2>Hypercontractivity on product spaces</h2>
<p>Analysis of Boolean functions (ABS) is a very rich subject. There are many works whose concern is generalising some of the results on analysis of Boolean functions to other (product) settings, such as functions on the multicube <img alt="{\left[m\right]^{n},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5Bm%5Cright%5D%5E%7Bn%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left[m\right]^{n},}"/> where <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> is very large. However, in some of these cases the fundemental tools of AOBF seem to be false for functions on the multicube <img alt="{f\colon\left[m\right]^{n}\rightarrow\mathbb{R}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cleft%5Bm%5Cright%5D%5E%7Bn%7D%5Crightarrow%5Cmathbb%7BR%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\left[m\right]^{n}\rightarrow\mathbb{R}.}"/> However, in the recent work of Keevash, Long, Minzer, and I. We introduce the notion of global functions. These are functions that do not strongly depend on a small set of coordinates. We then show that most of the rich classical theory of AOBF can in fact be generalised to these global functions. Using our machinery we were able to strengthen an isoperimetric stability result of Bourgain, and to make progress on some Erdos-Ko-Rado type open problem.</p>
<p>We now discuss some background on the Fourier analysis on functions on the multicube <img alt="{f\colon\left\{ 1,\ldots,m\right\} ^{n}\rightarrow\mathbb{R}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%5E%7Bn%7D%5Crightarrow%5Cmathbb%7BR%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\left\{ 1,\ldots,m\right\} ^{n}\rightarrow\mathbb{R}.}"/></p>
<h3>Derivatives and Laplacians</h3>
<p>There are two fundemental types of operators on Boolean functions <img alt="{f\colon\left\{ 0,1\right\} ^{n}\rightarrow\mathbb{R}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cleft%5C%7B+0%2C1%5Cright%5C%7D+%5E%7Bn%7D%5Crightarrow%5Cmathbb%7BR%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\left\{ 0,1\right\} ^{n}\rightarrow\mathbb{R}.}"/> The first ones are the discrete derivatives, defined by <img alt="{D_{i}[f]=\frac{f_{i\rightarrow1}-f_{i\rightarrow0}}{2},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD_%7Bi%7D%5Bf%5D%3D%5Cfrac%7Bf_%7Bi%5Crightarrow1%7D-f_%7Bi%5Crightarrow0%7D%7D%7B2%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D_{i}[f]=\frac{f_{i\rightarrow1}-f_{i\rightarrow0}}{2},}"/> where <img alt="{f_{i\rightarrow x}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7Bi%5Crightarrow+x%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{i\rightarrow x}}"/> denotes the we plug in the value <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> for the <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>th coordinate. The other closely related ones are the laplacians defined by <img alt="{L_{i}f\left(x\right):=f\left(x\right)-\mathbb{E}f\left(\mathbf{y}\right),}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bi%7Df%5Cleft%28x%5Cright%29%3A%3Df%5Cleft%28x%5Cright%29-%5Cmathbb%7BE%7Df%5Cleft%28%5Cmathbf%7By%7D%5Cright%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{i}f\left(x\right):=f\left(x\right)-\mathbb{E}f\left(\mathbf{y}\right),}"/> where <img alt="{\mathbf{y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7By%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{y}}"/> is obtained from <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> by resampling its <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>th coordinate.</p>
<p>The laplacians and the derivatives are closely related. In fact, when we plug in <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> in the <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>th coordinate, we obtain <img alt="{L_{i}[f]_{i\rightarrow1}=D_{i}[f]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bi%7D%5Bf%5D_%7Bi%5Crightarrow1%7D%3DD_%7Bi%7D%5Bf%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{i}[f]_{i\rightarrow1}=D_{i}[f]}"/>, and when we plug in <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> in it, we obtain <img alt="{L_{i}[f]_{i\rightarrow0}=-D_{i}[f].}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bi%7D%5Bf%5D_%7Bi%5Crightarrow0%7D%3D-D_%7Bi%7D%5Bf%5D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{i}[f]_{i\rightarrow0}=-D_{i}[f].}"/></p>
<p>The 2-norm of the <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>th derivative is called the <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>th influence of <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> as it measures the impact of the <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>th coordinate on the value of <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/>. It’s usually denoted by <img alt="{\mathrm{Inf}_{i}[f]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BInf%7D_%7Bi%7D%5Bf%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{Inf}_{i}[f]}"/>.</p>
<h3>Generalisation to functions on the multicube</h3>
<p>For functions on the multicube we don’t have a very good notion of a discrete derivative, but it turns out that it will be enough to talk about the laplacians and their restrictions. The Laplacians are again defined via <img alt="{L_{i}f\left(x\right):=f\left(x\right)-\mathbb{E}f\left(\mathbf{y}\right),}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7Bi%7Df%5Cleft%28x%5Cright%29%3A%3Df%5Cleft%28x%5Cright%29-%5Cmathbb%7BE%7Df%5Cleft%28%5Cmathbf%7By%7D%5Cright%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{i}f\left(x\right):=f\left(x\right)-\mathbb{E}f\left(\mathbf{y}\right),}"/> where <img alt="{\mathbf{y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7By%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{y}}"/> is obtained from <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> by resampling its <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>th coordinate. It turns out that in the continuous cube it’s not enough to talk about Laplacians of coordinate, and we will also have to concern ourselves with Laplacians of sets. We define the generalised Laplacians of a set <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> by composing the laplacians corresponding to each coordinate in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> <img alt="{L_{\left\{ i_{1},i_{2},\ldots,i_{r}\right\} }\left[f\right]:=L_{i_{1}}\circ\cdots\circ L_{i_{r}}\left[f\right].}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_%7B%5Cleft%5C%7B+i_%7B1%7D%2Ci_%7B2%7D%2C%5Cldots%2Ci_%7Br%7D%5Cright%5C%7D+%7D%5Cleft%5Bf%5Cright%5D%3A%3DL_%7Bi_%7B1%7D%7D%5Ccirc%5Ccdots%5Ccirc+L_%7Bi_%7Br%7D%7D%5Cleft%5Bf%5Cright%5D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_{\left\{ i_{1},i_{2},\ldots,i_{r}\right\} }\left[f\right]:=L_{i_{1}}\circ\cdots\circ L_{i_{r}}\left[f\right].}"/></p>
<p>We now need to convince ourselves that these laplacians have something to do with the impact of <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> on the outcome of <img alt="{f.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f.}"/> In fact, the following notions are equivalent</p>
<ol>
<li>For each <img alt="{x,y\in\left[m\right]^{S}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%5Cin%5Cleft%5Bm%5Cright%5D%5E%7BS%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y\in\left[m\right]^{S}}"/>we have <img alt="{\|f_{S\rightarrow x}-f_{S\rightarrow y}\|_{2}&lt;\delta_{1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7Cf_%7BS%5Crightarrow+x%7D-f_%7BS%5Crightarrow+y%7D%5C%7C_%7B2%7D%3C%5Cdelta_%7B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|f_{S\rightarrow x}-f_{S\rightarrow y}\|_{2}&lt;\delta_{1}}"/></li>
<li>For each <img alt="{x\in\left[m\right]^{S}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin%5Cleft%5Bm%5Cright%5D%5E%7BS%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x\in\left[m\right]^{S}}"/> we have <img alt="{\|L_{S}[f]_{S\rightarrow x}\|_{2}&lt;\delta_{2},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7CL_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5C%7C_%7B2%7D%3C%5Cdelta_%7B2%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|L_{S}[f]_{S\rightarrow x}\|_{2}&lt;\delta_{2},}"/></li>
</ol>
<p>in the sense that if (1) holds then (2) holds with <img alt="{\delta_{2}=C^{\left|S\right|}\delta_{1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta_%7B2%7D%3DC%5E%7B%5Cleft%7CS%5Cright%7C%7D%5Cdelta_%7B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta_{2}=C^{\left|S\right|}\delta_{1}}"/> and conversely if (2) holds, then (1) holds with <img alt="{\delta_{1}=C^{\left|S\right|}\delta_{2}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta_%7B1%7D%3DC%5E%7B%5Cleft%7CS%5Cright%7C%7D%5Cdelta_%7B2%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\delta_{1}=C^{\left|S\right|}\delta_{2}.}"/></p>
<p>The main theme of our work is that one can understand <strong>global</strong> function on the continuous cube, and these are functions that satisfy the above equivalent notions for all small sets <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>.</p>
<h3>Noise operator, hypercontractivity, and small set expansion</h3>
<p>For <img alt="{\rho\in\left(0,1\right),}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%5Cin%5Cleft%280%2C1%5Cright%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho\in\left(0,1\right),}"/> the noise operator is given by <img alt="{\mathrm{T}_{\rho}\left[f\right]\left(x\right)=\mathbb{E}f\left(\mathbf{y}\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D%5Cleft%5Bf%5Cright%5D%5Cleft%28x%5Cright%29%3D%5Cmathbb%7BE%7Df%5Cleft%28%5Cmathbf%7By%7D%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{T}_{\rho}\left[f\right]\left(x\right)=\mathbb{E}f\left(\mathbf{y}\right)}"/> when <img alt="{\mathbf{y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7By%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{y}}"/> is obtained from <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> by independently setting each coordinate <img alt="{\mathbf{y}_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7By%7D_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{y}_{i}}"/> to be <img alt="{\mathbf{x}_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7Bx%7D_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{x}_{i}}"/> with probability <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/> and resampling it with uniformly out of <img alt="{\left\{ -1,1\right\} }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{ -1,1\right\} }"/> otherwise. The process which given <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> outputs <img alt="{\mathbf{y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7By%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{y}}"/> is called the <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/>-noisy process, and we write <img alt="{\mathbf{y}\sim N_{\rho}\left(x\right).}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7By%7D%5Csim+N_%7B%5Crho%7D%5Cleft%28x%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{y}\sim N_{\rho}\left(x\right).}"/></p>
<p>The Bonami hypercontractivity theorem, which was then generalised by Gross and Beckner states that the noise operator <img alt="{T_{\frac{1}{\sqrt{3}}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_%7B%5Cfrac%7B1%7D%7B%5Csqrt%7B3%7D%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_{\frac{1}{\sqrt{3}}}}"/> is a contraction from <img alt="{L^{2}\left(\left\{ 0,1\right\} ^{n}\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%5E%7B2%7D%5Cleft%28%5Cleft%5C%7B+0%2C1%5Cright%5C%7D+%5E%7Bn%7D%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L^{2}\left(\left\{ 0,1\right\} ^{n}\right)}"/> to <img alt="{L^{4}\left(\left\{ 0,1\right\} ^{n}\right),}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL%5E%7B4%7D%5Cleft%28%5Cleft%5C%7B+0%2C1%5Cright%5C%7D+%5E%7Bn%7D%5Cright%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L^{4}\left(\left\{ 0,1\right\} ^{n}\right),}"/> i.e.</p>
<blockquote><p><img alt="\displaystyle \|\mathrm{T}_{\frac{1}{\sqrt{3}}}f\|_{4}\le\|f\|_{2} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Cfrac%7B1%7D%7B%5Csqrt%7B3%7D%7D%7Df%5C%7C_%7B4%7D%5Cle%5C%7Cf%5C%7C_%7B2%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|\mathrm{T}_{\frac{1}{\sqrt{3}}}f\|_{4}\le\|f\|_{2} "/><br/>
for any function <img alt="{f.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f.}"/></p></blockquote>
<p>One consequence of the hypercontractivity theorem is the small set expansion theorem of KKL. It concerns fixed <img alt="{\rho\in\left(0,1\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%5Cin%5Cleft%280%2C1%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho\in\left(0,1\right)}"/> and a sequence of sets <img alt="{A_{n}\subseteq\{0,1\}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%5Csubseteq%5C%7B0%2C1%5C%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}\subseteq\{0,1\}^{n}}"/> with <img alt="{\left|A_{n}\right|=o\left(2^{n}\right).}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%7CA_%7Bn%7D%5Cright%7C%3Do%5Cleft%282%5E%7Bn%7D%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left|A_{n}\right|=o\left(2^{n}\right).}"/> The small set expansion theorem states that if we choose <img alt="{\mathbf{x}\sim A_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7Bx%7D%5Csim+A_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{x}\sim A_{n}}"/> uniformly and a noisy <img alt="{\mathbf{y}\sim N_{\rho}\left(\mathbf{x}\right),}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7By%7D%5Csim+N_%7B%5Crho%7D%5Cleft%28%5Cmathbf%7Bx%7D%5Cright%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{y}\sim N_{\rho}\left(\mathbf{x}\right),}"/> then <img alt="{\mathbf{y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7By%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbf{y}}"/> will reside outside of <img alt="{A_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}}"/> almost surely.</p>
<h3>The Generalisation to the multicube:</h3>
<p>The small set expansion theorem and the hypercontractivity theorem both fail for function on the multicube that are of a very local nature. For instance, let <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> be the set of all <img alt="{x\in\left\{ 1,\ldots,m\right\} ^{n},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%5E%7Bn%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x\in\left\{ 1,\ldots,m\right\} ^{n},}"/> such that <img alt="{x_{1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{1}}"/> is <img alt="{m.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m.}"/> Then <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> is of size <img alt="{m^{n-1},}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%5E%7Bn-1%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m^{n-1},}"/> which is <img alt="{o\left(m^{n}\right)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bo%5Cleft%28m%5E%7Bn%7D%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{o\left(m^{n}\right)}"/> if we allow <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> to be a growing function of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. However, the <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho}"/>-noisy process from the set stays within the set with probability <img alt="{\rho.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\rho.}"/> For a similar reason the hypercontractivity theorem fails as is for functions on <img alt="{\left\{ 1,\ldots,m\right\} ^{n}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%5E%7Bn%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\left\{ 1,\ldots,m\right\} ^{n}.}"/> However we were able to generalise the hypercontractivity theorem by taking the globalness of <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> into consideration.</p>
<p>Our main hypercontractive inequality is the following</p>
<p><strong>Theorem 1.</strong></p>
<blockquote><p><img alt="\displaystyle \|\mathrm{T}_{\frac{1}{100}}f\|_{4}^{4}\le\sum_{S\subseteq\left[n\right]}\mathbb{E}_{\mathbf{x}\sim\left\{ 1,\ldots,m\right\} ^{m}}\left(\|L_{S}\left[f\right]_{S\rightarrow\mathbf{x}}\|_{2}^{4}\right). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Cfrac%7B1%7D%7B100%7D%7Df%5C%7C_%7B4%7D%5E%7B4%7D%5Cle%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%5Cmathbb%7BE%7D_%7B%5Cmathbf%7Bx%7D%5Csim%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%5E%7Bm%7D%7D%5Cleft%28%5C%7CL_%7BS%7D%5Cleft%5Bf%5Cright%5D_%7BS%5Crightarrow%5Cmathbf%7Bx%7D%7D%5C%7C_%7B2%7D%5E%7B4%7D%5Cright%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \|\mathrm{T}_{\frac{1}{100}}f\|_{4}^{4}\le\sum_{S\subseteq\left[n\right]}\mathbb{E}_{\mathbf{x}\sim\left\{ 1,\ldots,m\right\} ^{m}}\left(\|L_{S}\left[f\right]_{S\rightarrow\mathbf{x}}\|_{2}^{4}\right). "/></p></blockquote>
<p>The terms <img alt="{\|L_{S}\left[f\right]_{S\rightarrow x}\|_{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7CL_%7BS%7D%5Cleft%5Bf%5Cright%5D_%7BS%5Crightarrow+x%7D%5C%7C_%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|L_{S}\left[f\right]_{S\rightarrow x}\|_{2}}"/> appearing on the right hand side are small whenever <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> has a small dependency on <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> and it turns out that you have the following corrolary of it, which looks a bit more similar to the hypercontractive intequality.</p>
<p> </p>
<p><strong>Corollary 2.</strong></p>
<p>Let <img alt="{f\colon\left\{ 1,\ldots,m\right\} ^{n}\rightarrow\mathbb{R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%5E%7Bn%7D%5Crightarrow%5Cmathbb%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\left\{ 1,\ldots,m\right\} ^{n}\rightarrow\mathbb{R}}"/>, and uppose that <img alt="{\|L_{S}[f]_{S\rightarrow x}\|_{2}\le4^{\left|S\right|}\|f\|_{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7CL_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5C%7C_%7B2%7D%5Cle4%5E%7B%5Cleft%7CS%5Cright%7C%7D%5C%7Cf%5C%7C_%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|L_{S}[f]_{S\rightarrow x}\|_{2}\le4^{\left|S\right|}\|f\|_{2}}"/> for all sets <img alt="{S.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S.}"/></p>
<p>Then <img alt="{\mathrm{\|\mathrm{T}_{\frac{1}{1000}}f\|_{4}\le\|f\|_{2}.}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7B%5C%7C%5Cmathrm%7BT%7D_%7B%5Cfrac%7B1%7D%7B1000%7D%7Df%5C%7C_%7B4%7D%5Cle%5C%7Cf%5C%7C_%7B2%7D.%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathrm{\|\mathrm{T}_{\frac{1}{1000}}f\|_{4}\le\|f\|_{2}.}}"/></p>
<p>Finally, one might ask wonder why this globalness notion appears only when we look at large values of <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> and not when <img alt="{m=2.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%3D2.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m=2.}"/> I think the corollary is a good explanation for that as <img alt="{\|f\|_{2}^{2}\ge\left(\frac{1}{2}\right)^{\left|S\right|}\|f_{S\rightarrow x}\|_{2}^{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7Cf%5C%7C_%7B2%7D%5E%7B2%7D%5Cge%5Cleft%28%5Cfrac%7B1%7D%7B2%7D%5Cright%29%5E%7B%5Cleft%7CS%5Cright%7C%7D%5C%7Cf_%7BS%5Crightarrow+x%7D%5C%7C_%7B2%7D%5E%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\|f\|_{2}^{2}\ge\left(\frac{1}{2}\right)^{\left|S\right|}\|f_{S\rightarrow x}\|_{2}^{2}}"/> holds trivially for any Boolean function <img alt="{f\colon\left\{ 0,1\right\} ^{n}\rightarrow\mathbb{R}.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cleft%5C%7B+0%2C1%5Cright%5C%7D+%5E%7Bn%7D%5Crightarrow%5Cmathbb%7BR%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f\colon\left\{ 0,1\right\} ^{n}\rightarrow\mathbb{R}.}"/></p></div>
    </content>
    <updated>2020-05-07T21:01:42Z</updated>
    <published>2020-05-07T21:01:42Z</published>
    <category term="Analysis"/>
    <category term="Combinatorics"/>
    <category term="Computer Science and Optimization"/>
    <category term="Guest post"/>
    <category term="Poetry"/>
    <category term="Probability"/>
    <category term="Barry Simon"/>
    <category term="Dor Minzer"/>
    <category term="Eoin Long"/>
    <category term="Noam Lifshitz"/>
    <category term="Peter Keevash"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-05-14T22:32:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/075</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/075" rel="alternate" type="text/html"/>
    <title>TR20-075 |  Rigid Matrices From Rectangular PCPs | 

	Amey Bhangale, 

	Prahladh Harsha, 

	Orr Paradise, 

	Avishay Tal</title>
    <summary>We introduce a variant of PCPs, that we refer to as *rectangular* PCPs, wherein proofs are thought of as square matrices, and the random coins used by the verifier can be partitioned into two disjoint sets, one determining the *row* of each query and the other determining the *column*.

We construct PCPs that are *efficient*, *short*, *smooth* and (almost-)*rectangular*. As a key application, we show that proofs for hard languages in NTIME$(2^n)$, when viewed as matrices, are rigid infinitely often. This strengthens and considerably simplifies a recent result of Alman and Chen [FOCS, 2019] constructing explicit rigid matrices in FNP. Namely, we prove the following theorem:
- There is a constant $\delta \in (0,1)$ such that there is an FNP-machine that, for infinitely many $N$, on input $1^N$ outputs $N \times N$ matrices with entries in $\mathbb{F}_2$ that are $\delta N^2$-far (in Hamming distance) from matrices of rank at most $2^{\log  N/\Omega(\log \log N)}$.

Our construction of rectangular PCPs starts with an analysis of how randomness yields queries in the Reed--Muller-based outer PCP of Ben-Sasson, Goldreich, Harsha, Sudan and Vadhan [SICOMP, 2006; CCC, 2005]. We then show how to preserve rectangularity under PCP composition and a smoothness-inducing transformation. This warrants refined and stronger notions of rectangularity, which we prove for the outer PCP and its transforms.</summary>
    <updated>2020-05-06T19:28:27Z</updated>
    <published>2020-05-06T19:28:27Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-14T22:31:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/074</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/074" rel="alternate" type="text/html"/>
    <title>TR20-074 |  Depth-First Search in Directed Graphs, Revisited | 

	Eric Allender, 

	Archit Chauhan, 

	Samir Datta</title>
    <summary>We present an algorithm for constructing a depth-first search tree in planar digraphs; the algorithm can be implemented in the complexity class UL, which is contained in nondeterministic logspace NL, which in turn lies in NC^2. Prior to this (for more than a quarter-century), the fastest uniform deterministic parallel algorithm for this problem was O(log^10 n) (corresponding to the complexity class AC^10, which is contained in NC^11).

We also consider the problem of computing depth-first search trees in other classes of graphs, and obtain additional new upper bounds.</summary>
    <updated>2020-05-06T18:15:38Z</updated>
    <published>2020-05-06T18:15:38Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-14T22:31:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/073</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/073" rel="alternate" type="text/html"/>
    <title>TR20-073 |  Lower Bounds on OBDD Proofs with Several Orders | 

	Dmitry Itsykson, 

	Sam Buss, 

	Dmitry Sokolov, 

	Alexander Knop, 

	Artur Riazanov</title>
    <summary>This paper is motivated by seeking lower bounds on OBDD($\land$, weakening, reordering) refutations, namely OBDD refutations that allow weakening and arbitrary reorderings. We first work with 1-NBP($\land$) refutations based on read-once nondeterministic branching programs. These generalize OBDD($\land$, reordering) refutations. There are polynomial size 1-NBP($\land$) refutations of the pigeonhole principle, hence 1-NBP($\land$) is strictly stronger than OBDD($\land$, reordering). There are also formulas that have polynomial size tree-like resolution refutations but require exponential size 1-NBP($\land$) refutations. As a corollary, OBDD($\land$, reordering) does not simulate tree-like resolution, answering a previously open question.

The system 1-NBP($\land$, $\exists$) uses projection inferences instead of weakening. 1-NBP($\land$, $\exists_k$) is the system restricted to projection on at most $k$ distinct variables. We construct explicit constant degree graphs $G_n$ on $n$ vertices and an $\epsilon &gt; 0$, such that 1-NBP($\land$, $\exists_{\epsilon n}$) refutations of the Tseitin formula for $G_n$ require exponential size.

Second, we study the proof system OBDD($\land$, weakening, reordering$_\ell$) which allows $\ell$ different variable orders in a refutation. We prove an exponential lower bound on the complexity of tree-like OBDD($\land$, weakening, reordering$_\ell$) refutations for $\ell = \epsilon \log n$, where $n$ is the number of variables and $\epsilon &gt; 0$ is a constant. The lower bound is based on multiparty communication complexity.</summary>
    <updated>2020-05-05T18:13:59Z</updated>
    <published>2020-05-05T18:13:59Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-14T22:31:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=48</id>
    <link href="https://dstheory.wordpress.com/2020/05/05/friday-may-15-amin-karbasi-from-yale-university/" rel="alternate" type="text/html"/>
    <title>Friday, May 15 — Amin Karbasi from Yale University</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The fourth Foundations of Data Science virtual talk will take place on Friday, May 15th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  Amin Karbasi from Yale University will speak about “User-Friendly Submodular Maximization”. Abstract: Submodular functions model the intuitive notion of diminishing returns. Due to their far-reaching applications, they<a class="more-link" href="https://dstheory.wordpress.com/2020/05/05/friday-may-15-amin-karbasi-from-yale-university/">Continue reading <span class="screen-reader-text">"Friday, May 15 — Amin Karbasi from Yale University"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The fourth Foundations of Data Science virtual talk will take place on Friday, May 15th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  <strong>Amin Karbasi </strong>from Yale University will speak about “<em>User-Friendly Submodular Maximization</em>”.</p>



<p class="has-text-align-left"><strong>Abstract</strong>: Submodular functions model the intuitive notion of diminishing returns. Due to their far-reaching applications, they have been rediscovered in many fields such as information theory, operations research, statistical physics, economics, and machine learning. They also enjoy computational tractability as they can be minimized exactly or maximized approximately.</p>



<p>The goal of this talk is simple. We see how a little bit of randomness, a little bit of greediness, and the right combination can lead to pretty good methods for offline, streaming, and distributed solutions. I do not assume any background on submodularity and try to explain all the required details during the talk.</p>



<p><a href="https://sites.google.com/view/dstheory" rel="noreferrer noopener" target="_blank">Please register here to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>
    </content>
    <updated>2020-05-05T01:30:02Z</updated>
    <published>2020-05-05T01:30:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2020-05-14T22:33:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/072</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/072" rel="alternate" type="text/html"/>
    <title>TR20-072 |  Locally testable codes via high-dimensional expanders | 

	Irit Dinur, 

	Prahladh Harsha, 

	Yotam Dikstein, 

	Noga Ron-Zewi</title>
    <summary>Locally testable codes (LTC) are error-correcting codes that have a local tester which can distinguish valid codewords from words that are far from all codewords, by probing a given word only at a very small (sublinear, typically constant) number of locations. Such codes form the combinatorial backbone of PCPs. A major open problem is whether there exist LTCs with positive rate, constant relative distance and testable with a constant number of queries. 

In this paper, we present a new approach towards constructing such LTCs using the machinery of high-dimensional expanders. 
To this end, we consider the Tanner representation of a code, which is specified by a graph and a base code. Informally, our result states that if this graph is part of an {\em agreement expander} then the local testability of the code follows from the local testability of the base code. Agreement expanders allow one to stitch together many mostly-consistent local functions into a single global function. High-dimensional expanders are known to yield agreement expanders with constant degree. 

This work unifies and generalizes the known results on testability of the Hadamard, Reed-Muller and lifted codes, all of which are proved via a single round of local self-correction: the corrected value at a vertex v depends on the values of all vertices that share a constraint with v. In the above codes this set includes all of the vertices. In contrast, in our setting the degree of a vertex might be a constant, so we cannot hope for one-round self-correction. We overcome this technical hurdle by performing iterative self correction with logarithmically many rounds and tightly controlling the error in each iteration using properties of the agreement expander.

Given this result, the missing ingredient towards constructing a constant-query LTC with positive rate and constant relative distance is an instantiation of a base code and a constant-degree agreement expander that interact well with each other.</summary>
    <updated>2020-05-05T00:09:11Z</updated>
    <published>2020-05-05T00:09:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-14T22:31:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/05/04/postdoc-position-at-university-of-alberta-apply-by-december-31-2020/</id>
    <link href="https://cstheory-jobs.org/2020/05/04/postdoc-position-at-university-of-alberta-apply-by-december-31-2020/" rel="alternate" type="text/html"/>
    <title>postdoc position at University of Alberta (apply by December 31, 2020)</title>
    <summary>The Theory Group in the Dept. of Computing Science at U. of Alberta invites applications for TWO postdoc positions. The successful applicants are expected to work closely with Zachary Friggstad and Mohammad Salavatipour in the areas of: approx algorithms, hardness of approximation, combinatorial optimization. For details see https://webdocs.cs.ualberta.ca/~mreza/pdf-ad7.pdf Email: mrs@ualberta.ca Website: http://www.cs.ualberta.ca Email: mrs@ualberta.ca</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Theory Group in the Dept. of Computing Science at U. of Alberta invites applications for TWO postdoc positions. The successful applicants are expected to work closely with Zachary Friggstad and Mohammad Salavatipour in the areas of: approx algorithms, hardness of approximation, combinatorial optimization. For details see <a href="https://webdocs.cs.ualberta.ca/~mreza/pdf-ad7.pdf">https://webdocs.cs.ualberta.ca/~mreza/pdf-ad7.pdf</a><br/>
Email: mrs@ualberta.ca</p>
<p>Website: <a href="http://www.cs.ualberta.ca">http://www.cs.ualberta.ca</a><br/>
Email: mrs@ualberta.ca</p></div>
    </content>
    <updated>2020-05-04T18:43:57Z</updated>
    <published>2020-05-04T18:43:57Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-05-14T22:32:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/071</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/071" rel="alternate" type="text/html"/>
    <title>TR20-071 |  A Tight Lower Bound on Adaptively Secure Full-Information Coin Flip | 

	Iftach Haitner, 

	Yonatan Karidi-Heller</title>
    <summary>In a distributed coin-flipping protocol, Blum [ACM Transactions on Computer Systems '83],
the parties try to output a common (close to) uniform bit, even when some adversarially chosen parties try to bias the common output. In an adaptively secure full-information coin flip, Ben-Or and Linial [FOCS '85], the parties communicate over a broadcast channel and a computationally unbounded adversary can choose which parties to corrupt during the protocol execution. Ben-Or and Linial proved that the $n$-party majority protocol is resilient to $o(\sqrt{n})$ corruptions (ignoring log factors), and conjectured this is a tight upper bound for any $n$-party protocol (of any round complexity). Their conjecture was proved to be correct for single-turn (each party sends a single message) single-bit (a message is one bit) protocols, Lichtenstein, Linial, and Saks [Combinatorica '89], symmetric protocols Goldwasser, Kalai, and Park [ICALP '15], and recently for (arbitrary message length) single-turn protocols Tauman Kalai, Komargodski, and Raz [DISC '18]. Yet, the question for many-turn (even single-bit) protocols was left completely open.

In this work we close the above gap, proving that no $n$-party protocol (of any round complexity) is resilient to $O(\sqrt{n})$ (adaptive) corruptions.</summary>
    <updated>2020-05-04T14:14:22Z</updated>
    <published>2020-05-04T14:14:22Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-14T22:31:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/070</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/070" rel="alternate" type="text/html"/>
    <title>TR20-070 |  On the list recoverability of randomly punctured codes | 

	Ben Lund, 

	Aditya Potukuchi</title>
    <summary>We show that a random puncturing of a code with good distance is list recoverable beyond the Johnson bound.
In particular, this implies that there are Reed-Solomon codes that are list recoverable beyond the Johnson bound.
It was previously known that there are Reed-Solomon codes that do not have this property. 
As an immediate corollary to our main theorem, we obtain better degree bounds on unbalanced expanders that come from Reed-Solomon codes.</summary>
    <updated>2020-05-04T09:06:23Z</updated>
    <published>2020-05-04T09:06:23Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-14T22:31:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1297</id>
    <link href="https://ptreview.sublinear.info/?p=1297" rel="alternate" type="text/html"/>
    <title>News for April 2020</title>
    <summary>April is now behind us, and we hope you and your families are all staying safe and healthy. We saw six seven property papers appear online last month, so at least there is some reading ahead of us! A mixture of privacy, quantum, high-dimensional distributions, and juntas (juntæ?). A lot of distribution testing, overall. Connecting […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>April is now behind us, and we hope you and your families are all staying safe and healthy. We saw <s>six</s> seven property papers appear online last month, so at least there is some reading ahead of us! A mixture of privacy, quantum, high-dimensional distributions, and juntas (juntæ?). A lot of distribution testing, overall.</p>



<p><strong>Connecting Robust Shuffle Privacy and Pan-Privacy</strong>, by Victor Balcer, Albert Cheu, Matthew Joseph, and Jieming Mao (<a href="https://arxiv.org/abs/2004.09481">arXiv</a>). This paper considers a recent notion of differential privacy called<em> shuffle privacy</em>, where users have sensitive data, a central untrusted server wants to do something with that data (for instance, say… testing its distribution), and a trusted middle-man/entity shuffles the users’ messages u.a.r. to bring in a bit more anonymity. As it turns out, testing uniformity (or identity) of distributions in the shuffle privacy model is (i) much harder than without privacy constraints; (ii) much harder than with ‘usual’ (weaker) differential privacy (iii) much easier than with local privacy; (iv) related to the sample complexity under another privacy notion, <em>pan-privacy</em>. It’s a brand exciting new world out there!</p>



<p><em>(Note: for the reader interested in keeping track of identity/uniformity testing of probability distributions under various privacy models, I wrote a very short summary of the current results <a href="https://github.com/ccanonne/probabilitydistributiontoolbox/blob/master/private-goodness-of-fit.pdf">here</a>.)</em></p>



<p><strong>Entanglement is Necessary for Optimal Quantum Property Testing, </strong>by Sebastien Bubeck, Sitan Chen, and Jerry Li (<a href="https://arxiv.org/abs/2004.07869">arXiv</a>). The analogue of uniformity testing, in the quantum world, is testing whether a quantum state is equal (or far from) the maximally mixed state. It’s known that this task  has “quantum sample complexity” (number of measurements) \(\Theta(d/\varepsilon^2)\) (i.e., square root dependence on  the dimension of the state, \(d^2\)). But this requires <em>entangled</em> measurements, which may be tricky to get (or, in my case, understand): what happens if the measurements can be adaptive, but not entangled? In this work, the authors show that, under this weaker access model \(\Omega(d^{4/3}/\varepsilon^2)\) measurements are necessary: adaptivity alone won’t cut it. It may still help though: without either entanglement <em>nor</em> adaptivity, the authors also show a \(\Omega(d^{3/2}/\varepsilon^2)\) measurements lower bound.</p>



<p><strong>Testing Data Binnings</strong>, by Clément Canonne and Karl Wimmer (<a href="https://eccc.weizmann.ac.il/report/2020/062/">ECCC</a>). More identity testing! Not private and not quantum for this one, but… not <em>quite</em> identity testing either. To paraphrase the abstract: this paper introduces (and gives near matching bounds for)  the related question of <em>identity up to binning</em>, where the reference distribution \(q\) is over \(k \ll n\) elements: the question is then whether there exists a suitable binning of the domain \([n]\) into \(k\) intervals such that, <em>once binned</em>, \(p\) is equal to \(q\).” </p>



<p><strong>Hardness of Identity Testing for Restricted Boltzmann Machines and Potts models</strong>, by Antonio Blanca, Zongchen Chen, Daniel Štefankovič, and Eric Vigoda (<a href="https://arxiv.org/abs/2004.10805">arXiv</a>). Back to identity testing of distributions, but for high-dimensional structured ones this one. Specifically, this paper focuses on the undirected graphical models known as <em>restricted Boltzmann machines, </em>and provides efficient algorithms for identity testing and conditional hardness lower bounds depending on the type of correlations allowed in the graphical models.</p>



<p><strong>Robust testing of low-dimensional functions</strong>, by Anindya De, Elchanan Mossel, and Joe Neeman (<a href="https://arxiv.org/abs/2004.11642">arXiv</a>). Junta testing is a classical, central problem in property testing, with motivations and applications in machine learning and complexity. The related (and equally well-motivated) question of junta testing of functions on \(\mathbb{R}^d\) (instead of the Boolean hypercube) was recently studied by the same authors; and the related (and, again, equally well-motivated) question of <em>tolerant</em> junta testing on the Boolean hypercube was also recently studied (among other works) by the same authors. Well, this paper does it all, and tackles the challenging (and, for a change, equally well-motivated!) question of <em>tolerant</em> testing of juntas  on \(\mathbb{R}^d\).</p>



<p><strong>Differentially Private Assouad, Fano, and Le Cam</strong>, by Jayadev Acharya, Ziteng Sun, and Huanyu Zhang (<a href="https://arxiv.org/abs/2004.06830">arXiv</a>). Back to probability distributions and privacy. This paper provides differentially private analogues of the classical eponymous statistical inference results (Assouad’s lemma, Fano’s inequality, and Le Cam’s method). In particular, it gives ready-to-use, blackbox tools to prove testing and learning lower bounds for distributions in the differentially private setting, and shows how to use them to easily derive, and rederive, several lower bounds.</p>



<p><strong>Edit: </strong>We missed one!</p>



<p><strong>Learning and Testing Junta Distributions with Subcube Conditioning</strong>, by Xi Chen, Rajesh Jayaram, Amit Levi, Erik Waingarten (<a href="https://arxiv.org/abs/2004.12496">arXiv</a>). This paper focuses on the <em>subcube conditioning</em> model of (high-dimensional) distribution testing, where the algorithm can fix some variables to values of its choosing and get samples conditioned on those variables. Extending and refining techniques from <a href="https://ptreview.sublinear.info/?p=1227">a previous work by a (sub+super)set of the authors</a>, the paper shows how to optimally learn and test <a href="http://proceedings.mlr.press/v49/aliakbarpour16.html">junta distributions</a> in this framework—with exponential savings with respect to the usual i.i.d. sampling model.</p></div>
    </content>
    <updated>2020-05-04T01:52:43Z</updated>
    <published>2020-05-04T01:52:43Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Clement Canonne</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2020-05-14T22:33:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blog.simons.berkeley.edu/?p=164</id>
    <link href="https://blog.simons.berkeley.edu/2020/05/fine-grained-hardness-of-lattice-problems-open-questions/" rel="alternate" type="text/html"/>
    <title>Fine-grained hardness of lattice problems: Open questions</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">1 Introduction 1.1 Lattices and lattice-based cryptography Lattices are classically-studied geometric objects that in the past few decades have found a multitude of applications in computer science. The most important application area is lattice-based cryptography, the design of cryptosystems whose … <a href="https://blog.simons.berkeley.edu/2020/05/fine-grained-hardness-of-lattice-problems-open-questions/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h1>1 Introduction</h1>
<h2>1.1 Lattices and lattice-based cryptography</h2>
<p>Lattices are classically-studied geometric objects that in the past few decades have found a multitude of applications in computer science. The most important application area is <em>lattice-based cryptography</em>, the design of cryptosystems whose security is based on the apparent intractability of computational problems on lattices, even for quantum computers. Indeed, lattice-based cryptography has revolutionized the field because of its apparent quantum resistance and its other attractive security, functionality, and efficiency properties.</p>
<p>Intuitively, a lattice is a regular ordering of points in some (typically high-dimensional) space. More precisely, a <em>lattice</em> \( {{\cal{L}}}\) of rank \( {n}\) is the set of all integer linear combinations of some linearly independent vectors \( {\mathbf{b}_1, \ldots, \mathbf{b}_n}\), which are called a <em>basis</em> of \( {{\cal{L}}}\). We will be primarily interested in analyzing the running times of lattice algorithms as functions of the lattice’s rank \( {n}\).</p>
<h2>1.2. Computational lattice problems</h2>
<p>The two most important computational problems on lattices are the Shortest Vector Problem (SVP) and the Closest Vector Problem (CVP). SVP asks, given a basis of a lattice \( {{\cal{L}}}\) as input, to find a shortest non-zero vector in \( {{\cal{L}}}\). CVP, which can be viewed as an inhomogeneous version of SVP, asks, given a basis of a lattice \( {{\cal{L}}}\) and a target point \( {\mathbf{t}}\) as input, to find a closest vector in \( {{\cal{L}}}\) to \( {\mathbf{t}}\).</p>
<p>Algorithms for solving SVP form the core of the best known attacks on lattice-based cryptography both in theory and in practice. Accordingly, it is critical to understand the precise complexity of SVP as well as possible. The best provably correct algorithms for both SVP and CVP run in \( {2^{n + o(n)}}\)-time [<a href="https://arxiv.org/abs/1412.7994">ADRS15</a>, <a href="https://arxiv.org/abs/1504.01995">ADS15</a>, <a href="https://arxiv.org/abs/1709.01535">AS18a</a>]. The best heuristic algorithms for SVP run in \( {2^{cn + o(n)}}\)-time for \( {c = 0.292}\) classically [<a href="https://eprint.iacr.org/2015/1128">BDGL16</a>] and \( {c = 0.265}\) using quantum speedups [<a href="http://www.thijs.com/docs/phd-final.pdf">Laa15</a>] (see also [<a href="https://eprint.iacr.org/2019/1016">KMPR19</a>]), and most real-world lattice-based cryptosystems assume that these algorithms are close to optimal. Indeed, many of these cryptosystems assume what Bos et al. [<a href="https://eprint.iacr.org/2016/659">B+16</a>] call a “paranoid” worst-case estimate of \( {c = 0.2075}\) (based on the kissing number and assuming that sieving algorithms are optimal) as the fastest hypothetical running time for SVP algorithms when choosing parameters. (See also Albrecht et al. [<a href="https://estimate-all-the-lwe-ntru-schemes.github.io/paper.pdf">A+18</a>], which surveys the security assumptions made in a wide range of lattice-based cryptosystems.) Accordingly, the difference in being able to solve SVP in \( {2^{0.2075n}}\) versus \( {2^{n/20}}\) versus \( {2^{\sqrt{n}}}\) time may mean the difference between lattice-based cryptosystems being secure, insecure with current parameters, or effectively broken in practice.</p>
<p>There is a rank-preserving reduction from SVP to CVP [<a href="https://cseweb.ucsd.edu/~daniele/papers/GMSS.pdf">GMSS99</a>], so any algorithm for CVP immediately gives an essentially equally fast algorithm for SVP. In other words, CVP is at least as hard as SVP (and probably a bit harder). Indeed, historically, almost all lower bounds for SVP are proven via reduction from CVP (and nearly all algorithmic progress on CVP uses ideas originally developed for SVP).</p>
<h2>1.3. Fine-grained hardness</h2>
<p>The field of fine-grained complexity works to give strong, quantitative lower bounds on computational problems assuming standard complexity-theoretic assumptions. Proving such a (conditional) lower bound for an \( {{\mathsf{NP}}}\)-hard problem generally works by (1) assuming a stronger hardness assumption than \( {{\mathsf{P}} \neq {\mathsf{NP}}}\) about the complexity of \( {k}\)-SAT (such as ETH or SETH, defined below), and (2) giving a highly efficient reduction from \( {k}\)-SAT to the problem. The most important hardness assumptions for giving lower bounds on \( {{\mathsf{NP}}}\)-hard problems are the Exponential Time Hypothesis (ETH) and the Strong Exponential Time Hypothesis (SETH) of Impagliazzo and Paturi [<a href="https://cseweb.ucsd.edu/~paturi/myPapers/pubs/ImpagliazzoPaturi_2001_jcss.pdf">IP01</a>]. ETH asserts that there is no \( {2^{o(n)}}\)-time algorithm for \( {3}\)-SAT, and SETH asserts that for every \( {\epsilon &gt; 0}\) there exists \( {k \in {\mathbb Z}^+}\) such that there is no \( {2^{(1 – \epsilon)n}}\)-time algorithm for \( {k}\)-SAT, where \( {n}\) denotes the number of variables in the SAT instance.</p>
<p>Here by “highly efficient” reductions we mean linear ones, i.e., reductions that map a \( {3}\)-SAT or \( {k}\)-SAT formula on \( {n}\) variables to an SVP or CVP instance of rank \( {C n + o(n)}\) for some absolute constant \( {C &gt; 0}\). Indeed, by giving a reduction from \( {3}\)-SAT (respectively, \( {k}\)-SAT for any \( {k \in {\mathbb Z}^+}\)) instances on \( {n}\) variables to SVP or CVP instances of rank \( {C n + o(n)}\), we can conclude that there is no \( {2^{o(n)}}\)-time (resp., \( {2^{(1-\epsilon)n/C}}\)-time for any \( {\epsilon &gt; 0}\)) algorithm for the corresponding problem assuming ETH (resp., SETH). Note that the smaller the value of \( {C}\) for which one can show such a reduction, the stronger the conclusion. In particular, a reduction mapping \( {k}\)-SAT instances on \( {n}\) variables to SVP or CVP instances of rank \( {n + o(n)}\) would imply an essentially tight lower bound on the corresponding problem assuming SETH — as mentioned above, the best provably correct algorithms for both SVP and CVP run in time \( {2^{n + o(n)}}\).</p>
<h2>1.4. Fine-grained hardness of CVP (and SVP)</h2>
<p>It is relatively easy to show that CVP is “ETH-hard,” i.e., to show that a \( {2^{o(n)}}\)-time algorithm for CVP would imply a \( {2^{o(n)}}\)-time algorithm for \( {3}\)-SAT instances with \( {n}\) variables. This would falsify ETH. (It’s a nice exercise to show that the Subset Sum problem on a set of size \( {n}\) reduces to CVP on a lattice of rank \( {n}\), which implies the result.)</p>
<p>With some work, Divesh Aggarwal and Noah extended this to SVP [<a href="https://arxiv.org/abs/1712.00942">AS18b</a>]. In particular, we showed a reduction from CVP to SVP that only increases the rank of the lattice by some constant multiplicative factor. (Formally, the reduction only works with certain minor constraints on the CVP instance. The reduction originally relied on a geometric conjecture, which was open for decades. But, Serge Vlăduţ proved the conjecture [<a href="https://arxiv.org/abs/1802.00886">Vlă19</a>] shortly after we published!)</p>
<p>So, unless ETH is false, there is no \( {2^{o(n)}}\)-time algorithm for CVP or SVP. But, for cryptographic applications, even, say, a \( {2^{n/20}}\)-time algorithm would be completely devastating. If such an algorithm were found, cryptographic schemes that we currently think are secure against absurdly powerful attackers straight out of science fiction (say, one with a computer the size of the sun running until the heat death of the universe) would turn out to be easily broken (e.g., in seconds on our laptops).</p>
<p>In [<a href="https://arxiv.org/abs/1704.03928">BGS17</a>, <a href="https://arxiv.org/abs/1911.02440">ABGS20</a>], we <em>almost</em> showed that CVP is “SETH-hard,” i.e., that a \( {2^{(1-\epsilon)n}}\)-time algorithm for CVP would imply such an algorithm for \( {k}\)-SAT for <em>any</em> constant \( {k}\). This would falsify SETH. So, we <em>almost</em> showed that the [<a href="https://arxiv.org/abs/1504.01995">ADS15</a>] algorithm is optimal. The “almost” is because our proof works with \( {\ell_p}\) norms, that is, we show hardness for the version of CVP in which the distance from the target to a lattice vector is defined in terms of the \( {\ell_p}\) norm,</p>
<p align="center">\( \displaystyle \|\mathbf{x}\|_p := (|x_1|^p + \cdots + |x_d|^p)^{1/p} \; . \)</p>
<p>We call the corresponding problem \( {{\mathrm{CVP}}_p}\). In fact, our proof works for all \( {\ell_p}\) norms <em>except</em> when \( {p}\) is an even integer. (To see why this might happen, notice \( {\|\mathbf{x}\|_p^p}\) is a polynomial in the \( {x_i}\) if and only if \( {p}\) is an even integer. In fact, there’s some sense in which “\( {\ell_2}\) is the easiest norm,” because for any \( {p}\), there is a linear map \( {A \in {\mathbb R}^{d \times m}}\) such that \( {m}\) is not too large and \( {\|\mathbf{x}\|_2 \approx \|A \mathbf{x}\|_p}\).) Of course, we are most interested in the case \( {p= 2}\) (the only case for which the [<a href="https://arxiv.org/abs/1504.01995">ADS15</a>] algorithm works), which is an even integer! Indeed, for all \( {p \neq 2}\), the fastest known algorithm for CVP is still Ravi Kannan’s \( {n^{O(n)}}\)-time algorithm from 1987 [<a href="https://kilthub.cmu.edu/articles/Minkowski_s_convex_body_theorem_and_integer_programming/6607328/files/12097865.pdf">Kan87</a>]. (For SVP and for constant-factor approximate CVP, \(2^{O(n)}\)-time algorithms are known [<a href="https://arxiv.org/abs/1011.5666">DPV11</a>].)</p>
<p>In fact, we showed that for \( {p = 2}\), no “natural” reduction can rule out a \( {2^{3n/4}}\)-time algorithm for CVP under SETH. A “natural” reduction is one with a fixed bijection between witnesses. In particular, any “natural” reduction from \( {3}\)-SAT to CVP must reduce to a lattice with rank at least roughly \( {4n/3}\). So, new ideas will be needed to prove stronger hardness of CVP in the \( {\ell_2}\) norm.</p>
<h1>2. Open problems</h1>
<p>We now discuss some of the problems that we left open in [<a href="https://arxiv.org/abs/1704.03928">BGS17</a>, <a href="https://arxiv.org/abs/1911.02440">ABGS20</a>]. For simplicity, we ask for specific results (e.g., “prove that problem \( {A}\) is \( {T}\)-hard under hypothesis \( {B}\)“), but of course any similar results would be very interesting (e.g., “\( {A}\) is \( {T’}\)-hard under hypothesis \( {B’}\)“).</p>
<h2>2.1. Hardness in the \(\ell_2\) norm</h2>
<p>The most obvious question that we left open is, of course, to prove similar \( {2^n}\)-time hardness results for \( {{\mathrm{CVP}}_2}\) (and more generally for \( {{\mathrm{CVP}}_p}\) for even integers \( {p}\)).</p>
<blockquote>
<p><b>Open problem 1.</b> Show that there is no \( {2^{0.99 n}}\)-time algorithm for \( {{\mathrm{CVP}}_2}\) assuming SETH.</p>
</blockquote>
<p>Remember that we showed that any proof of such a strong result would have to use an “unnatural” reduction. So, a fundamentally different approach is needed. One potentially promising direction would be to find a Cook reduction, as our limitations only apply to Karp reductions.</p>
<p>Alternatively, one might try for a different result that gets around this “natural” reduction limitations. E.g., even the following much weaker result would be very interesting.</p>
<blockquote>
<p><b>Open problem 2.</b> Show an efficient reduction from \( {3}\)-SAT on \( {n}\) variables to \( {{\mathrm{CVP}}_2}\) on a lattice of rank \( {\approx 10n}\).</p>
</blockquote>
<p>Such a reduction to \( {{\mathrm{CVP}}_2}\) on a lattice of rank \( {Cn}\) for some large constant \( {C}\) is known by applying the Sparsification Lemma [<a href="https://cseweb.ucsd.edu/~russell/ipz.pdf">IPZ01</a>] to \( {3}\)-SAT, but showing such a reduction for any reasonably small \( {C}\) or even any explicit \( {C}\) using a different proof technique would be interesting.</p>
<p>Also, our limitations only apply to reductions that map satisfying assignments to <em>exact</em> closest vectors. So, one might try to get around our limitation by working directly with approximate versions of \( {3}\)-SAT and \( {{\mathrm{CVP}}_2}\). (In [<a href="https://arxiv.org/abs/1911.02440">ABGS20</a>], we show such reductions from Gap-\( {k}\)-SAT to constant-factor approximate \( {{\mathrm{CVP}}_p}\) for all \( {p \notin 2{\mathbb Z}}\) as well as all \( {k \leq p}\). We also show reductions from Gap-\( {k}\)-Parity that achieve relatively large approximation factors.)</p>
<blockquote>
<p><b>Open problem 3.</b> Show an efficient reduction from Gap-\( {3}\)-SAT on \( {n}\) variables to approximate \( {{\mathrm{CVP}}_2}\) on a lattice of rank \( {n}\).</p>
</blockquote>
<h2>2.2. Hardness in \(\ell_p\) norms</h2>
<p>Intuitively, one reason that we are able to prove such strong results for \( {\ell_p}\) norms for \( {p \neq 2}\) is because we can use lattices with large ambient dimension \( {d}\) but low rank \( {n}\). In other words, while our reductions produce lattices \( {{\cal{L}}}\) that live in some \( {n}\)-dimensional subspace of \( {\ell_p}\)-space, the ambient space itself has large dimension \( {d}\) relative to \( {n}\). Of course, any subspace of the \( {\ell_2}\) norm is an \( {\ell_2}\) subspace (i.e., every slice of a ball is a lower-dimensional ball), so in the \( {\ell_2}\) norm, one can assume without loss of generality that \( {d = n}\). In particular, if we were able to prove \( {2^n}\)-hardness for the \( {\ell_2}\) norm, then we would actually prove \( {2^d}\)-hardness for free. However, a potentially easier problem would be to improve the \( {2^n}\)-hardness of \( {{\mathrm{CVP}}_p}\) shown in [<a href="https://arxiv.org/abs/1704.03928">BGS17</a>, <a href="https://arxiv.org/abs/1911.02440">ABGS20</a>]  to \( {2^d}\)-hardness for some \( p \neq 2 \).</p>
<blockquote>
<p><b>Open problem 4.</b> Show that there is no \( {2^{0.99 d}}\)-time algorithm for \( {{\mathrm{CVP}}_p}\) (for some \( {p}\)) assuming SETH.</p>
</blockquote>
<p>More generally, it would be very interesting to settle the fine-grained complexity of \( {{\mathrm{CVP}}_p}\) for some \( {p \neq 2}\) (either in terms of rank \( {n} \) or dimension \( {d} \)). This could take the form either of showing improved algorithms (currently the fastest algorithms for \( {{\mathrm{CVP}}_p}\) for general \( {p}\) run in \( {n^{O(n)}}\)-time [<a href="https://kilthub.cmu.edu/articles/Minkowski_s_convex_body_theorem_and_integer_programming/6607328/files/12097865.pdf">Kan87</a>], and \( {2^{O(n)}}\)-time for a constant approximation factor [<a href="https://arxiv.org/abs/1011.5666">DPV11</a>]), or showing super-\( {2^n}\) hardness, or both.</p>
<blockquote>
<p><b>Open problem 5.</b> Show matching upper bounds and lower bounds (under SETH) for \( {{\mathrm{CVP}}_p}\) for some \( {p}\) (possibly with a constant approximation factor).</p>
</blockquote>
<p>The case where \( {p = \infty}\) is especially interesting. Indeed, because the kissing number in the \( {\ell_\infty}\) norm is \( {3^n-1}\), one might guess that the fastest algorithms for \( {{\mathrm{CVP}}_\infty}\) and \( {{\mathrm{SVP}}_\infty}\) actually run in time \( {3^{n + o(n)}}\) or perhaps \( {3^{d + o(d)}}\). (See [<a href="https://arxiv.org/pdf/1801.02358">AM18</a>], which essentially achieves this.) We therefore ask whether stronger lower bounds can be proven in this special case.</p>
<blockquote>
<p><b>Open problem 6.</b> Show that \( {{\mathrm{CVP}}_\infty}\) cannot be solved in time \( {3^{0.99n}}\) (under SETH).</p>
</blockquote>
<h2>2.3. Hardness closer to crypto</h2>
<p>The most relevant problem to cryptography is approximate \( {{\mathrm{SVP}}_2}\) with an approximation factor that is polynomial in the rank \( {n}\). Our fastest algorithms to solve this problem work via a reduction to exact (or near exact) \( {{\mathrm{SVP}}_2}\) with some lower rank \( {n’ = \Theta(n)}\), so that even for these polynomial approximation factors, our fastest algorithms run in time \( {2^{\Omega(n)}}\) (where the hidden constant depends on the polynomial; see <a href="https://blog.simons.berkeley.edu/2020/04/lattice-blog-reduction-part-i-bkz/">Michael’s post</a> for more on this topic). And, hardness results for exact SVP rule out attacks on cryptography that use such reductions. We currently only know how to rule out \( {2^{o(n)}}\)-time algorithms for \( {{\mathrm{SVP}}_2}\) (under the Gap-ETH assumption). We ask whether we can do better. (In [<a href="https://arxiv.org/abs/1712.00942">AS18b</a>], we proved the stronger result below for \( {\ell_p}\) norms for large enough \( {p \notin 2{\mathbb Z}}\).)</p>
<blockquote>
<p><b>Open problem 7.</b> Prove that there is no \( {2^{n/10}}\)-time algorithm for \( {{\mathrm{SVP}}_2}\) (under SETH).</p>
</blockquote>
<p>Of course, we would ideally like to directly rule out faster algorithms for approximate \( {{\mathrm{SVP}}_2}\) with the approximation factors that are most directly relevant to cryptography. There are serious complexity-theoretic barriers to overcome to get all the way there (e.g., \( {{\mathrm{CVP}}_p}\) and \( {{\mathrm{SVP}}_p}\) are known to be in \( {{\mathsf{NP}}} \cap {{\mathsf{coNP}}}\) for large enough polynomial approximation factors. But, we can still hope to get as close as possible, by proving stronger hardness results for approximate \( {{\mathrm{CVP}}_p}\) and approximate \( {{\mathrm{SVP}}_p}\). Indeed, a beautiful sequence of works showed hardness for approximation factors up to \( {n^{c/\log \log n}}\) (so “nearly polynomial) [<a href="http://www.wisdom.weizmann.ac.il/~dinuri/mypapers/cvpjournal.pdf">DKRS03</a>, <a href="https://arxiv.org/abs/1806.04087">HR12</a>], but these results are not fine grained.</p>
<p>The best <em>fine-grained</em> hardness of approximation results known rule out algorithms for small constant-factor approximations for \( {{\mathrm{CVP}}_p}\) with \( {p \notin 2{\mathbb Z}}\) in time \( {2^{0.99n}}\) for \( {{\mathrm{CVP}}_p}\) and \( {{\mathrm{SVP}}_p}\) for any \( {p}\) in time \( {2^{o(n)}}\). We ask whether we can do better.</p>
<blockquote>
<p><b>Open problem 8.</b> Prove that there is no \( {2^{0.99 n}}\)-time algorithm for \( {2}\)-approximate \( {{\mathrm{CVP}}_p}\) (under some form of Gap-SETH, see below).</p>
</blockquote>
<blockquote>
<p><b>Open problem 9.</b> Prove that there is no \( {2^{o(n)}}\)-time algorithm for \( {\gamma}\)-approximate \( {{\mathrm{CVP}}_p}\) for superconstant \( {\gamma = \omega(1)}\) (under Gap-ETH).</p>
</blockquote>
<h2>2.4. Gap-SETH?</h2>
<p>One issue that arose in our attempts to prove fine-grained hardness of approximation results is that we don’t even know the “right” complexity-theoretic assumption about approximate CSPs to use as a starting point. For fine-grained hardness of exact problems, ETH and SETH are very well established hypotheses, and they are in some sense “the weakest possible” assumptions of their form. E.g., it is easy to see that \( {k}\)-SAT is \( {2^{Cn}}\) hard if any \( {k}\)-CSP is. But, for hardness of approximation, the situation is less clear.</p>
<p>The analogue of ETH in the regime of hardness of approximation is the beautiful Gap-ETH assumption, which was defined independently by Irit Dinur [<a href="https://eccc.weizmann.ac.il/report/2016/128/">Din16</a>] and Pasin Manurangsi and Prasad Raghavendra [<a href="https://arxiv.org/pdf/1607.02986.pdf">MR17</a>]. This assumption says that there exists some constant approximation factor \( {\delta \neq 1}\) such that \( {\delta}\)-Gap-\( {3}\)-SAT cannot be solved in time \( {2^{o(n)}}\). (Formally, both Dinur and Manurangsi and Raghavendra say that there is no \( {2^{o(n)}}\)-time algorithm that distinguishes a satisfiable formula from a formula for which no assignment satisfies more than a \( {(1-\epsilon)}\) fraction of the clauses, but we ignore this requirement of perfect completeness here.) It is easy to see that this hypothesis is equivalent to a similar hypothesis about any \( {3}\)-CSP (or, indeed, any \( {k}\)-CSP for any constant\( {k}\)).</p>
<p>However, to prove hardness of approximation with the finest of grains, we need some “gap” analogue of SETH, i.e., we would like to assume that for large enough \( {k}\), some Gap-\( {k}\)-CSP is hard to approximate up to some constant factor \( {\delta \neq 1}\) in better than \( {2^{0.99n}}\)-time. (Formally, we should add an additional variable \( {\epsilon &gt; 0}\) and have such a hypothesis for every running time \( {2^{(1-\epsilon)n}}\), but we set \( {\epsilon = 0.01}\) here to keep things relatively simple.)</p>
<p>An issue arises here concerning the dependence of the approximation factor \( {\delta}\) on the arity \( {k}\). In particular, recall that \( {k}\)-SAT can be trivially approximated up to a factor of \( {1-2^{-k}}\) (since a random assignment satisfies a \( {1-2^{-k}}\) fraction of the clauses in expectation). So, if we define Gap-SETH in terms of Gap-\( {k}\)-SAT, then we must choose \( {\delta = \delta(k) \geq 1-2^{-k}}\) that converges to one as \(k\) increases. Manurangsi proposed such a version of Gap-SETH in his thesis [<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-49.html">Man19</a>, Conjecture 12.1], specifically that for every large enough constant \( {k}\) there exists a constant \( {\delta = \delta(k) \neq 1}\) such that Gap-\( {k}\)-SAT cannot be approximated up to a factor of \( {\delta}\) in time \( {2^{0.99n}}\). (Again, we are leaving out an additional variable, \( {\epsilon}\).)</p>
<p>If we rely on this version of Gap-SETH, then our current techniques seem to get stuck at proving hardness of approximation for, say, \( {\gamma}\)-approximate \( {{\mathrm{CVP}}_p}\) for some non-explicit constant \( {\gamma_p &gt; 1}\) (and, if one works out the numbers, one can see immediately that \( {\gamma_p}\) must be really quite close to one). However, other Gap-\(k\)-CSPs are known to be (\(\mathsf{NP}\)-)hard to approximate up to much better approximation factors. E.g., for any \( {k}\), Gap-\(k\)-Parity is \( {{\mathsf{NP}}}\)-hard to approximate up to any constant approximation factor \( {1/2 &lt; \delta \leq 1}\) [<a href="http://kiosk.nada.kth.se/theory/projects/publications/optimaljh.pdf">Hås01</a>], and Gap-\( {k}\)-AND is \( {{\mathsf{NP}}}\)-hard to approximate for any constant approximation factor \( {\Omega(k/2^k) \leq \delta \leq 1}\) [<a href="https://eccc.weizmann.ac.il/report/2012/110/">Cha16</a>]. Indeed, Gap-\( {k}\)-AND is a quite natural problem to consider in this context since there is a fine-grained, approximation-factor preserving reduction from any Gap-\( {k}\)-CSP to Gap-\( {k}\)-AND. This generality motivates understanding the precise complexity of Gap-\( {k}\)-AND.</p>
<blockquote>
<p><b>Open problem 10.</b> What is the fine-grained complexity of the \( {\delta}\)-Gap-\( {k}\)-AND problem in terms of \( {n}\), \( {k}\), and \( {\delta}\)? In particular, if</p>
<p align="center">\( \displaystyle C_{k,\delta} := \inf \{ C &gt; 0 \ : \ \text{there is a $2^{C_{k,\delta}}$-time algorithm for algorithm for $\delta$-Gap-$k$-AND}\}\)</p>
<p>then what is the behavior of \( {C_{k,\delta}}\) as \( {k \rightarrow \infty}\) (for various functions \( {\delta = \delta(k)}\) of \( {k}\))?</p>
</blockquote>
<p>In particular, if one were to hypothesize sufficiently strong hardness of \( {\delta}\)-Gap-\( {k}\)-AND — i.e., to define an appropriate variant of Gap-SETH based on Gap-\( {k}\)-AND — then one might be able to use this hypothesis to prove very strong fine-grained hardness of approximation results. There is a fine-grained (but non-approximation preserving) reduction from Gap-\( {k}\)-AND to Gap-\( {k}\)-SAT, and so Manurangsi’s Gap-SETH is equivalent to the conjecture that there exists some non-explicit \( {\delta(k)}\) such that \( {\lim_{k \rightarrow \infty} C_{k,\delta} = 1}\).</p>


<ul><li>[<a href="https://arxiv.org/abs/1911.02440">ABGS20</a>] Aggarwal, Bennett, Golovnev, Stephens-Davidowitz. Fine-grained hardness of CVP(P)— Everything that we can prove (and nothing else)</li><li>[<a href="https://estimate-all-the-lwe-ntru-schemes.github.io/paper.pdf">A+18</a>] Albrecht, Curtis, Deo, Davidson, Player, Postlethwaite, Virdia, Wunderer. Estimate all the {LWE, NTRU} schemes! <em>SCN</em>, 2019.</li><li>[<a href="https://arxiv.org/abs/1412.7994">ADRS15</a>] Aggarwal, Dadush, Regev, Stephens-Davidowitz. Solving the Shortest Vector Problem in \(2^n\) time via discrete Gaussian sampling. <em>STOC</em>, 2015.</li><li>[<a href="https://arxiv.org/abs/1504.01995">ADS15</a>]  Aggarwal, Dadush, Stephens-Davidowitz. Solving the Closest Vector Problem in \(2^n\) time–The discrete Gaussian strikes again! <em>FOCS</em>, 2015.</li><li>[<a href="https://arxiv.org/pdf/1801.02358">AM18</a>] Aggarwal, Mukhopadhyay. Faster algorithms for SVP and CVP in the \(\ell_\infty\) norm. <em>ISAAC</em>, 2018.</li><li>[<a href="https://arxiv.org/abs/1709.01535">AS18a</a>] Aggarwal, Stephens-Davidowitz. Just take the average! An embarrassingly simple \(2^n\)-time algorithm for SVP (and CVP). <em>SOSA</em>, 2018.</li><li>[<a href="https://arxiv.org/abs/1712.00942">AS18b</a>] Aggarwal, Stephens-Davidowitz. (Gap/S)ETH hardness of SVP. <em>STOC</em>, 2018.</li><li>[<a href="https://eprint.iacr.org/2016/659">B+16</a>] Bos, Costello, Ducas, Mironov, Naehrig, Nikolaenko, Raghunathan, Stebila. Frodo: Take off the ring! Practical, Quantum-Secure Key Exchange from LWE. <em>CCS,</em> 2016.</li><li>[<a href="https://eprint.iacr.org/2015/1128">BDGL16</a>] Becker, Ducas, Gama, Laarhoven. New directions in nearest neighbor searching with applications to lattice sieving. <em>SODA</em>, 2016.</li><li>[<a href="https://arxiv.org/abs/1704.03928">BGS17</a>] Bennett, Golovnev, Stephens-Davidowitz. On the quantitative hardness of CVP. <em>FOCS</em>, 2017.</li><li>[<a href="https://eccc.weizmann.ac.il/report/2012/110/">Cha16</a>] Chan. Approximation resistance from pairwise-independent subgroups. <em>J. ACM</em>, 2016.</li><li>[<a href="https://eccc.weizmann.ac.il/report/2016/128/">Din16</a>] Dinur. Mildly exponential reduction from gap 3SAT to polynomial-gap label-cover.</li><li>[<a href="http://www.wisdom.weizmann.ac.il/~dinuri/mypapers/cvpjournal.pdf">DKRS03</a>] Dinur, Kindler, Raz, Safra. Approximating CVP to within almost-polynomial factors is NP-hard. <em>Combinatorica</em>, 2003.</li><li>[<a href="https://arxiv.org/abs/1011.5666">DPV11</a>] Dadush, Peikert, Vempala. Enumerative lattice algorithms in any norm via \(M\)-ellipsoid coverings. <em>FOCS</em>, 2011.</li><li>[<a href="https://cseweb.ucsd.edu/~daniele/papers/GMSS.pdf">GMSS99</a>] Goldreich, Micciancio, Safra, Seifert. Approximating shortest lattice vectors is not harder than approximating closest lattice vectors. <em>IPL</em>, 1999.</li><li>[<a href="http://kiosk.nada.kth.se/theory/projects/publications/optimaljh.pdf">Hås01</a>] Håstad. Some optimal inapproximability results. <em>J. ACM</em>, 2001.</li><li>[<a href="https://arxiv.org/abs/1806.04087">HR12</a>] Haviv, Regev. Tensor-based hardness of the Shortest Vector Problem to within almost polynomial factors. <em>TOC</em>, 2012.</li><li>[<a href="https://cseweb.ucsd.edu/~paturi/myPapers/pubs/ImpagliazzoPaturi_2001_jcss.pdf">IP01</a>] Impagliazzo, Paturi. On the complexity of \(k\)-SAT. <em>JCSS</em>, 2001.</li><li>[<a href="https://cseweb.ucsd.edu/~russell/ipz.pdf">IPZ01</a>] Impagliazzo, Paturi, Zane. Which problems have strongly exponential complexity? <em>JCSS</em>, 2001.</li><li>[<a href="http://www.thijs.com/docs/phd-final.pdf">Laa15</a>] Laarhoven. Search problems in cryptography. Ph.D thesis, 2015.</li><li>[<a href="https://kilthub.cmu.edu/articles/Minkowski_s_convex_body_theorem_and_integer_programming/6607328/files/12097865.pdf">Kan87</a>] Kannan. Minkowski’s convex body theorem and Integer Programming. <em>MOR</em>, 1987.</li><li>[<a href="https://eprint.iacr.org/2019/1016">KMPR19</a>] Kirshanova, Mårtensson, Postlethwaite, Roy Moulik. Quantum algorithms for the approximate \(k\)-list problem and their application to lattice sieving. <em>Asiacrypt</em>, 2019.</li><li>[<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-49.html">Man19</a>] Manurangsi. Approximation and Hardness: Beyond P and NP.</li><li>[<a href="https://arxiv.org/pdf/1607.02986.pdf">MR17</a>] Manurangsi, Raghavendra. A Birthday Repetition Theorem and Complexity of Approximating Dense CSPs. <em>ICALP</em>, 17.</li><li>[<a href="https://arxiv.org/abs/1802.00886">Vlă19</a>] Vlăduţ. Lattices with exponentially large kissing numbers. <em>Moscow J. of Combinatorics and Number Theory</em>, 2019<em>.</em></li></ul></div>
    </content>
    <updated>2020-05-04T01:07:28Z</updated>
    <published>2020-05-04T01:07:28Z</published>
    <category term="General"/>
    <author>
      <name>Huck Bennett</name>
    </author>
    <source>
      <id>https://blog.simons.berkeley.edu</id>
      <link href="https://blog.simons.berkeley.edu/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blog.simons.berkeley.edu" rel="alternate" type="text/html"/>
      <subtitle>What's New at the Simons Institute for the Theory of Computing.</subtitle>
      <title>Calvin Café: The Simons Institute Blog</title>
      <updated>2020-05-14T22:33:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/069</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/069" rel="alternate" type="text/html"/>
    <title>TR20-069 |  Optimal Error Pseudodistributions for Read-Once Branching Programs | 

	Eshan Chattopadhyay, 

	Jyun-Jie Liao</title>
    <summary>In a seminal work, Nisan (Combinatorica'92) constructed a pseudorandom generator for length $n$ and width $w$ read-once branching programs  with seed length $O(\log n\cdot \log(nw)+\log n\cdot\log(1/\varepsilon))$ and  error $\varepsilon$. It remains a central question  to reduce the seed length to $O(\log (nw/\varepsilon))$, which would prove that $\mathbf{BPL}=\mathbf{L}$. However, there has been no improvement on Nisan's construction for the case $n=w$, which is most relevant to space-bounded derandomization.




Recently, in a beautiful work, Braverman, Cohen and Garg (STOC'18) introduced the notion of a \emph{pseudorandom pseudo-distribution} (PRPD) and gave an explicit construction of a PRPD with seed length $\tilde{O}(\log n\cdot \log(nw)+\log(1/\varepsilon))$. A PRPD is a relaxation of a pseudorandom generator, which suffices for derandomizing $\mathbf{BPL}$ and also implies a hitting set. Unfortunately, their construction is quite involved and complicated. Hoza and Zuckerman (FOCS'18) later constructed a much simpler hitting set generator with seed length $O(\log n\cdot \log(nw)+\log(1/\varepsilon))$, but their techniques are restricted to hitting sets.

In this work, we construct a PRPD with seed length 
$$O(\log n\cdot \log (nw)\cdot \log\log(nw)+\log(1/\varepsilon)).$$
This improves upon the construction in \cite{BCG18} by a $O(\log\log(1/\varepsilon))$ factor, and is optimal in the small error regime. In addition, we believe our construction and analysis to be   simpler than the work of Braverman, Cohen and Garg.</summary>
    <updated>2020-05-03T22:01:57Z</updated>
    <published>2020-05-03T22:01:57Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-05-14T22:31:54Z</updated>
    </source>
  </entry>
</feed>
