<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-09-30T15:39:08Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8844632344201187395</id>
    <link href="http://blog.computationalcomplexity.org/feeds/8844632344201187395/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/09/being-chair.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8844632344201187395" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8844632344201187395" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/09/being-chair.html" rel="alternate" type="text/html"/>
    <title>Being the Chair</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>If you have Netflix and interested in the academic world, I recommend <a href="https://www.netflix.com/title/81206259">The Chair</a>, a six-episode dramatic series starring Sandra Oh as a new English department chair at a "lower tier ivy league university". The series takes many artistic liberties and compresses much in a short time period but gets much about academics right such as the tension between faculty and the administration with the chair caught in the middle, the need to create majors that attract students, faculty past their prime teaching the same courses in the same way for decades, faculty who get themselves in a hole and keep digging, alumni donors controlling academic decisions, pressure to build a diverse faculty, faculty feeling under appreciated and getting outside offers, and a wonderful exposition of how the field has changed over the past thirty years given to someone who had dropped out before finishing their PhD to take on a different career.</p><p>When I served as department chair at Georgia Tech, I dealt with most if not all of these issues above, though not at the same time. I had some challenges that today's English department doesn't face: how to handle enrollments that more than doubled while barely able to hire more faculty than were departing, not that I would trade in a second for the existential crisis that English departments are going through. </p><p>When I left Georgia Tech after seven years, I had outlasted every other current chair in the Colleges of Computing, Science and Engineering. Not sure what this says about me or about Georgia Tech.</p><p>Being chair is the most challenging job in academia. The faculty technically report to you but you aren't their boss in any traditional sense--they came to academia because of the freedom to work on what they want and they won't give it up. It's virtually impossible to fire anyone with tenure. The joke goes that a chair needs two umbrellas, one to block stuff coming from the administration going to the faculty and the other to block the stuff from the faculty from going to the administration. Since I left it has gotten much uglier in the University System of Georgia which has no mask or vaccine mandates and glad I'm not the chair to deal with that.</p><p>This all sounds like I'm discouraging of becoming a department chair and it certainly isn't a job for anyone but it can be a very rewarding job. You can help shape the future of the department by the faculty you hire and the vision you set and create an environment that helps your faculty and students succeed. </p></div>
    </content>
    <updated>2021-09-30T14:29:00Z</updated>
    <published>2021-09-30T14:29:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-09-30T14:30:21Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2021-09-30-distributed-consensus-made-simple-for-real-this-time/</id>
    <link href="https://decentralizedthoughts.github.io/2021-09-30-distributed-consensus-made-simple-for-real-this-time/" rel="alternate" type="text/html"/>
    <title>Distributed consensus made simple (for real this time!)</title>
    <summary>Multi-Paxos is the de facto solution for deciding a log of commands to execute on a replicated state machine, yet it’s famously difficult to understand, motivating the switch to ‘simpler’ consensus protocols such as Raft. The conventional wisdom is that the best way to use Paxos (aka Synod, or single-shot...</summary>
    <updated>2021-09-30T07:39:00Z</updated>
    <published>2021-09-30T07:39:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2021-09-30T15:21:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19166</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/09/30/baby-steps/" rel="alternate" type="text/html"/>
    <title>Baby Steps</title>
    <summary>You don’t have to see the whole staircase, just take the first step—Martin Luther King, Jr. Still from her IHES lecture Maryna Viazovska was the first person to prove an exact bound on sphere packing in a dimension higher than 3. She achieved this for dimension 8 in 2016 by making an improvement of 0.00001 […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>You don’t have to see the whole staircase, just take the first step—Martin Luther King, Jr.</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/09/30/baby-steps/viazovska/" rel="attachment wp-att-19168"><img alt="" class="alignright wp-image-19168" height="150" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/Viazovska.jpg?resize=195%2C150&amp;ssl=1" width="195"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Still from her IHES <a href="https://www.youtube.com/watch?v=xALXm2XHDWc">lecture</a></font></td>
</tr>
</tbody>
</table>
<p>
Maryna Viazovska was the first person to prove an exact bound on sphere packing in a dimension higher than 3. She <a href="https://arxiv.org/pdf/1603.04246.pdf">achieved</a> this for dimension 8 in 2016 by making an improvement of <b>0.00001</b> over one previous <a href="https://annals.math.princeton.edu/wp-content/uploads/annals-v157-n2-p09.pdf">paper</a> by Henry Cohn and Noam Elkies. This also led to the <a href="https://arxiv.org/pdf/1603.06518.pdf">solution</a> in dimension 24, joint with Cohn and Abhinav Kumar, Stephen Miller, and Danylo Radchenko.</p>
<p>
Today we talk about partial progress—baby steps—and its relation to solving conjectures.</p>
<p>
This post is a continuation of our recent <a href="https://rjlipton.wpcomstaging.com/2021/08/10/p-vs-np-proof-claims/">thoughts</a> about how those who claim to have solved a major problem almost always claim to have solved the whole thing in one large leap. We’ve thought about declaring a rule that any claim on a major open problem, at least about complexity lower bounds, must first be a <em>partial result</em>. We will give concrete suggestions in that direction at the end. But on reflection, we’ll curb the dogmatics a little.</p>
<p>
In her 2016 <em>Quanta</em> <a href="https://www.quantamagazine.org/sphere-packing-solved-in-higher-dimensions-20160330">article</a> on Viazovska’s breakthrough, Erica Klarreich quotes Peter Sarnak:</p>
<blockquote><p><b> </b> <em> “It’s stunningly simple, as all great things are. You just start reading the paper and you know this is correct.” </em>
</p></blockquote>
<p>
We hasten to add that the paper’s correctness is evident amid the context that others had established over the previous two decades, going back at least to Thomas Hales’s voluminous proof of Johannes Kepler’s conjecture for dimension 3. To quote Klarreich:</p>
<blockquote><p><b> </b> <em> Researchers have known for more than a decade what the missing ingredient in the proof [of optimality for dimensions 8 and 24] should be—an “auxiliary” function that can calculate the largest allowable sphere density—but they couldn’t find the right function. … [F]inding the right modular form allowed Viazovska to prove [the case of 8] in a mere 23 pages. </em>
</p></blockquote>
<p>
Thus Viazovska brought in a new tool to the problem, <em>modular forms</em>, which had already proved their merit in resolving the Fermat conjecture. But she still needed to choose the right modular form among many candidates. Klarreich quotes her as saying it is difficult even just to explain how she knew which one to use. This brings us back to the challenge of explaining—or debunking—the flash of insight that claimers claim to have. At least in this case, per Sarnak’s quote, the proof was in the pudding.</p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/09/30/baby-steps/cohnexcerpt/" rel="attachment wp-att-19169"><img alt="" class="aligncenter size-full wp-image-19169" height="174" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/CohnExcerpt.jpg?resize=460%2C174&amp;ssl=1" width="460"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">From Cohn’s 2017 <i>AMS Notices</i> <a href="https://www.ams.org/publications/journals/notices/201702/rnoti-p102.pdf">article</a></font>
</td>
</tr>
</tbody></table>
<p>
To complete the mixing of our original message, the examples we chose happen to involve improvements by tiny amounts. We’ve even understated Viazovska’s above: reckoned against a later <a href="https://annals.math.princeton.edu/2009/170-3/p01">paper</a> by Cohn and Elkies, her improvement was </p>
<p align="center"><img alt="\displaystyle  0.000000000000000000000000000001. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++0.000000000000000000000000000001.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>
The recent <a href="https://rjlipton.wpcomstaging.com/2020/10/26/a-vast-and-tiny-breakthrough/">post</a> where we discussed the phrase “the proof is in the pudding” involves a number with six more <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>s than that. These are <b>not</b> what we mean by “baby steps.” But let us tell our next story, which also involves Cohn.</p>
<p>
</p><p/><h2> Steps Toward Matrix Multiplication </h2><p/>
<p/><p>
We have <a href="https://rjlipton.wpcomstaging.com/2011/11/29/a-breakthrough-on-matrix-product/">covered</a> <a href="https://rjlipton.wpcomstaging.com/2011/12/03/the-meaning-of-omega/">other</a> <a href="https://rjlipton.wpcomstaging.com/2012/02/01/a-brief-history-of-matrix-product/">work</a> on the exponent <img alt="{\omega}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of matrix product. This means the infimum of all <img alt="{e}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that any two <img alt="{n \times n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> matrices can be multiplied in <img alt="{O(n^e)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5Ee%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> unit operations. In 1990, Don Coppersmith and Shmuel Winograd <a href="https://www.sciencedirect.com/science/article/pii/S0747717108800132">brought</a> <img alt="{\omega}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> down below <img alt="{2.375477}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2.375477%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The current best bound <img alt="{\omega &lt; 2.37286}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Comega+%3C+2.37286%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is from a SODA 2021 <a href="https://arxiv.org/abs/2010.05846">paper</a> by Josh Alman and Virginia Williams; its abstract highlights the improvement by <img alt="{0.00001}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0.00001%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> from the previous best.</p>
<p>
In 2005, however, Cohn wrote a <a href="https://arxiv.org/pdf/math/0511460.pdf">paper</a> with Robert Kleinberg, Balazs Szegedy, and Christopher Umans on ideas for taking <img alt="{\omega}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> all the way down to <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in one jump. This diverges from both the reading of “baby step” as “tiny improvement” and our idea meaning limited-but-definite partial progress. Their strategy for the full jump has come in and out of clouds since then. But their paper has motivated the subsequent partial progress in several ways. We have <a href="https://rjlipton.wpcomstaging.com/2010/03/27/fast-matrix-products-and-other-amazing-results/">mentioned</a> this paper <a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/">several</a> <a href="https://rjlipton.wpcomstaging.com/2012/06/22/cricket-400-and-complexity-theory/">times</a>, notably <a href="https://rjlipton.wpcomstaging.com/2018/08/30/limits-on-matrix-multiplication/">here</a>. </p>
<p>
The objective need not be <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> versus <img alt="{2.372...}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2.372...%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, however. There is a notable milepost just above <img alt="{2.30}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2.30%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. It comes from a STOC 2015 <a href="https://arxiv.org/abs/1411.5414">paper</a> by Andris Ambainis, Yuval Flimus, and François Le Gall. It shows that a wide class of techniques of the kind used since 1990 cannot achieve better than <img alt="{\omega &lt; 2.3078}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Comega+%3C+2.3078%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. </p>
<p>
Other recent <a href="https://drops.dagstuhl.de/opus/volltexte/2018/8360/pdf/LIPIcs-ITCS-2018-25.pdf">work</a> by Alman and Williams shows both a dimension along which the road down to <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> may still be open but other limits in other directions. Even their new <img alt="{0.00001}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0.00001%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> improvement has new ideas that may be exploited more generally. This is a feature of partial progress that contrasts with what we said <a href="https://rjlipton.wpcomstaging.com/2021/08/10/p-vs-np-proof-claims/">recently</a> about not learning much from whole-jump attempts: partial progress always shows a higher learning curve.</p>
<p>
</p><p/><h2> Some Partial Progress Objectives </h2><p/>
<p/><p>
Cohn also has a page of informal <a href="http://math.mit.edu/~cohn/Thoughts/">thoughts</a> on how to perform research, including <a href="https://math.mit.edu/~cohn/Thoughts/advice.html">advice</a> for those who claim to have solved some open problem. We want to add this advice:</p>
<blockquote><p><b> </b> <em> Make sure ahead of time that your advance really covers the intermediate ground it jumps through. Even better, walk back your claim a little so that it proves something only a step or so beyond previous knowledge. </em>
</p></blockquote>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/09/30/baby-steps/steps/" rel="attachment wp-att-19171"><img alt="" class="aligncenter size-full wp-image-19171" height="186" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/steps.png?resize=270%2C186&amp;ssl=1" width="270"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><a href="https://www.kimaverycoaching.com/baby-steps/">source</a> (not <a href="https://www.warehouse3b.top/ProductDetail.aspx?iid=151594314&amp;pr=30.99">this</a>)</font>
</td>
</tr>
</tbody></table>
<p>
Here are a few examples of such things to prove in complexity theory:</p>
<p/><p/>
<ul>
<li>
<img alt="{\mathsf{P \neq NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>: The claim is that SAT requires exponential time. <p/>
</li><li>
<b>A Baby Step</b>: Prove SAT cannot be done in linear time. Or that it cannot be done in <img alt="{n^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> time.
</li></ul>
<p><br/></p>
<ul>
<li>
<b>Circuit Lower Bounds</b>: The claim is that some concrete problem in <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> requires super-polynomial size general circuits. <p/>
</li><li>
<b>A Baby Step</b>: Prove that some concrete problem cannot be done in a linear size boolean circuit–or one of size <img alt="{6n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B6n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.
</li></ul>
<p><br/></p>
<ul>
<li>
<b>Factoring</b>: The claim is that factoring a general number <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> requires super-polynomial time in the bit-length of <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. <p/>
</li><li>
<b>A Baby Step</b>: Prove that factoring cannot be done in linear time. Or not in quadratic time. See <a href="https://math.mit.edu/~cohn/Thoughts/factoring.html">this</a>.
</li></ul>
<p><br/></p>
<ul>
<li>
<b>Graph Isomorphism</b>: The claim is that there is polynomial-time algorithm to tell whether two graphs are isomorphic. <p/>
</li><li>
<b>A Baby Step</b>: Prove the case where the graphs have degree a fixed constant.
</li></ul>
<p>
This is an example of a baby step that is already done. Note: it was not an easy step. It is a famous result of Eugene Luks—see his 1982 <a href="https://www.sciencedirect.com/science/article/pii/0022000082900095">paper</a>. </p>
<p/><p><br/>
We could go deeper into known computational complexity issues to find more. The idea applies to problems from mathematics in general. Here is one:</p>
<p/><p/>
<ul>
<li>
<b>Riemann Hypothesis”</b> The <a href="https://en.wikipedia.org/wiki/Riemann_hypothesis">claim</a> is of course that 	<p/>
<p align="center"><img alt="\displaystyle  \sum_{n=1}^{\infty} \frac{1}{n^s} = 0 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bn%3D1%7D%5E%7B%5Cinfty%7D+%5Cfrac%7B1%7D%7Bn%5Es%7D+%3D+0+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>only happens for negative even integers and for <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with real part <img alt="{1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The latter are the zeroes on the half line. </p>
</li><li>
<b>A Baby Step</b>: Prove that it is impossible for just two zeroes to be off the half line. Or that only a finite number can be off the half line.
</li></ul>
<p/><p><br/>
We invite readers to add more favorite math examples in comments, or others from complexity theory.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What are some additional first steps? </p>
<p>
Have we also—unintendedly but effectively—made a case for the value of tiny improvements? At least when they are conceptual improvements?</p>
<p>
Here is the answer to the puzzle in the previous <a href="https://rjlipton.wpcomstaging.com/2021/09/26/a-possible-ramsey-insight-into-p-versus-np/">post</a>: Barbara wins. She forces the sum of every row to be <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Alan makes an entry <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, she then makes an entry in the same row <img alt="{-x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. This works since 1986 is even. This makes the matrix singular, since the matrix times the all <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> vector is <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p/><p><br/>
[inserted “in dimension 8” at top, other tweaks]</p></font></font></div>
    </content>
    <updated>2021-09-30T06:22:07Z</updated>
    <published>2021-09-30T06:22:07Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Open Problems"/>
    <category term="P=NP"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="claimed proofs"/>
    <category term="Henry Cohn"/>
    <category term="incremental improvements"/>
    <category term="Maryna Viazovska"/>
    <category term="matrix multiplication"/>
    <category term="partial progress"/>
    <category term="sphere packings"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-09-30T15:37:45Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/09/29/postdoc-at-cwi-apply-by-october-31-2021/</id>
    <link href="https://cstheory-jobs.org/2021/09/29/postdoc-at-cwi-apply-by-october-31-2021/" rel="alternate" type="text/html"/>
    <title>Postdoc at CWI (apply by October 31, 2021)</title>
    <summary>A 2-year postdoctoral position is available at CWI in the area of discrete and continuous optimization under the supervision of Daniel Dadush. Candidates with interests in theoretical aspects of integer programming &amp; linear programming, as well as discrepancy theory should apply. No teaching requirement. The starting date is flexible. Website: https://www.cwi.nl/jobs/vacancies/894611 Email: dadush@cwi.nl</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A 2-year postdoctoral position is available at CWI in the area of discrete and continuous optimization under the supervision of Daniel Dadush. Candidates with interests in theoretical aspects of integer programming &amp; linear programming, as well as discrepancy theory should apply. No teaching requirement. The starting date is flexible.</p>
<p>Website: <a href="https://www.cwi.nl/jobs/vacancies/894611">https://www.cwi.nl/jobs/vacancies/894611</a><br/>
Email: dadush@cwi.nl</p></div>
    </content>
    <updated>2021-09-29T16:59:57Z</updated>
    <published>2021-09-29T16:59:57Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-09-30T15:37:47Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2021-09-29-the-round-complexity-of-reliable-broadcast/</id>
    <link href="https://decentralizedthoughts.github.io/2021-09-29-the-round-complexity-of-reliable-broadcast/" rel="alternate" type="text/html"/>
    <title>The round complexity of Reliable Broadcast</title>
    <summary>Reliable Broadcast is an important building block of many Asynchronous protocols. There is a broadcaster that has some input value, $v$, and a non-faulty party that terminates needs to output a value. Reliable Broadcast is defined via two properties: Validity: If the broadcaster is non-faulty then eventually all non-faulty parties...</summary>
    <updated>2021-09-29T10:05:00Z</updated>
    <published>2021-09-29T10:05:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2021-09-30T15:21:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.13871</id>
    <link href="http://arxiv.org/abs/2109.13871" rel="alternate" type="text/html"/>
    <title>Expectation-based Minimalist Grammars</title>
    <feedworld_mtime>1632873600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chesi:Cristiano.html">Cristiano Chesi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.13871">PDF</a><br/><b>Abstract: </b>Expectation-based Minimalist Grammars (e-MGs) are simplified versions of the
(Conflated) Minimalist Grammars, (C)MGs, formalized by Stabler (Stabler, 2011,
2013, 1997) and Phase-based Minimalist Grammars, PMGs (Chesi, 2005, 2007;
Stabler, 2011). The crucial simplification consists of driving structure
building only by relying on lexically encoded categorial top-down expectations.
The commitment on a top-down derivation (as in e-MGs and PMGs, as opposed to
(C)MGs, Chomsky, 1995; Stabler, 2011) allows us to define a core derivation
that should be the same in both parsing and generation (Momma &amp; Phillips,
2018).
</p></div>
    </summary>
    <updated>2021-09-29T22:37:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.13686</id>
    <link href="http://arxiv.org/abs/2109.13686" rel="alternate" type="text/html"/>
    <title>Preemptive Two-stage Goal-Programming Formulation of a Strict Version of the Unbounded Knapsack Problem with Bounded Weights</title>
    <feedworld_mtime>1632873600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Beyer:Michael.html">Michael Beyer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mills:Steven.html">Steven Mills</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.13686">PDF</a><br/><b>Abstract: </b>The unbounded knapsack problem with bounded weights is a variant of the
well-studied variant of the traditional binary knapsack problem; key changes
being the relaxation of the binary constraint and allowing the unit weights of
each item to fall within a range. In this paper, we formulate a variant of this
problem, which we call the strict unbounded knapsack problem with bounded
weights, by replacing the inequality constraint on the total weight with an
equality. We show that this problem can be decomposed into a two-stage,
pre-emptive goal programming problem, with the first stage being a
2-dimensional knapsack problem and the second being either a linear feasibility
program (per canonical formulation) or simply a linearly-constrained program in
the general case. This reformulation is shown to be equivalent to the original
formulation but allows the use of well-studied, efficient algorithms for
multidimensional knapsack problems. In addition, it separates the modeling
effort around what to put in the knapsack from considerations around what unit
weight one should assign to each item type, providing substantially more
flexibility to the modeler without adding complexity to the choice of knapsack
configuration. Finally, we show that for the feasibility version of the second
stage, one can immediately get a feasible solution to the first stage solution.
</p></div>
    </summary>
    <updated>2021-09-29T22:38:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.13460</id>
    <link href="http://arxiv.org/abs/2109.13460" rel="alternate" type="text/html"/>
    <title>Self-Improving Voronoi Construction for a Hidden Mixture of Product Distributions</title>
    <feedworld_mtime>1632873600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheng:Siu=Wing.html">Siu-Wing Cheng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wong:Man_Ting.html">Man Ting Wong</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.13460">PDF</a><br/><b>Abstract: </b>We propose a self-improving algorithm for computing Voronoi diagrams under a
given convex distance function with constant description complexity. The $n$
input points are drawn from a hidden mixture of product distributions; we are
only given an upper bound $m = o(\sqrt{n})$ on the number of distributions in
the mixture, and the property that for each distribution, an input instance is
drawn from it with a probability of $\Omega(1/n)$. For any $\varepsilon \in
(0,1)$, after spending $O\bigl(mn\log^{O(1)} (mn) + m^{\varepsilon}
n^{1+\varepsilon}\log(mn)\bigr)$ time in a training phase, our algorithm
achieves an $O\bigl(\frac{1}{\varepsilon}n\log m +
\frac{1}{\varepsilon}n2^{O(\log^* n)} + \frac{1}{\varepsilon}H\bigr)$ expected
running time with probability at least $1 - O(1/n)$, where $H$ is the entropy
of the distribution of the Voronoi diagram output. The expectation is taken
over the input distribution and the randomized decisions of the algorithm. For
the Euclidean metric, the expected running time improves to
$O\bigl(\frac{1}{\varepsilon}n\log m + \frac{1}{\varepsilon}H\bigr)$.
</p></div>
    </summary>
    <updated>2021-09-29T22:39:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.13457</id>
    <link href="http://arxiv.org/abs/2109.13457" rel="alternate" type="text/html"/>
    <title>On the Geometry of Stable Steiner Tree Instances</title>
    <feedworld_mtime>1632873600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Freitag:James.html">James Freitag</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mohammadi:Neshat.html">Neshat Mohammadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Potukuchi:Aditya.html">Aditya Potukuchi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Reyzin:Lev.html">Lev Reyzin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.13457">PDF</a><br/><b>Abstract: </b>In this note we consider the Steiner tree problem under Bilu-Linial
stability. We give strong geometric structural properties that need to be
satisfied by stable instances. We then make use of, and strengthen, these
geometric properties to show that $1.562$-stable instances of Euclidean Steiner
trees are polynomial-time solvable. We also provide a connection between
certain approximation algorithms and Bilu-Linial stability for Steiner trees.
</p></div>
    </summary>
    <updated>2021-09-29T22:38:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.13346</id>
    <link href="http://arxiv.org/abs/2109.13346" rel="alternate" type="text/html"/>
    <title>Computational phase transition in Quantum Approximate Optimization Algorithm -- the difference between hard and easy</title>
    <feedworld_mtime>1632873600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Bingzhi.html">Bingzhi Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhuang:Quntao.html">Quntao Zhuang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.13346">PDF</a><br/><b>Abstract: </b>Quantum Approximate Optimization algorithm (QAOA) is one of the candidates to
achieve a near-term quantum advantage. As QAOA seems only capable of solving
optimization problems, there is a folklore that QAOA cannot see the difference
between easy problems such as 2-SAT and hard problems such as 3-SAT -- although
2-SAT is in the polynomial-time (P) class, its optimization version is also
nondeterministic polynomial-time (NP)-hard. In this paper, we show that the
folklore is not true. We find a computational phase transition in QAOA when
solving a variant of 3-SAT -- the amplitude of gradient and the success
probability achieve their minimum at the well-known SAT-UNSAT phase transition.
On the contrary, for 2-SAT, such a phenomena is absent at SAT-UNSAT phase
transition and the success probability is unity for a reasonable circuit depth.
In solving the NP-hard optimization versions of SAT, we identify quantum
advantages over a classical approximate algorithm at quite a shallow depth of
p=4 for the problem size of $n=10$.
</p></div>
    </summary>
    <updated>2021-09-29T22:37:23Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.13341</id>
    <link href="http://arxiv.org/abs/2109.13341" rel="alternate" type="text/html"/>
    <title>0-Gaps on 3D Digital Curves</title>
    <feedworld_mtime>1632873600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nordo:Giorgio.html">Giorgio Nordo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maimone:Angelo.html">Angelo Maimone</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.13341">PDF</a><br/><b>Abstract: </b>In Digital Geometry, gaps are some basic portion of a digital object that a
discrete ray can cross without intersecting any voxel of the object itself.
Such a notion is quite important in combinatorial image analysis and it is
strictly connected with some applications in fields as CAD and Computer
graphics. In this paper we prove that the number of $0$-gaps of a $3$D digital
curve can be expressed as a linear combination of the number of its $i$-cells
(with $i = 0, \ldots, 3$).
</p></div>
    </summary>
    <updated>2021-09-29T22:40:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.13335</id>
    <link href="http://arxiv.org/abs/2109.13335" rel="alternate" type="text/html"/>
    <title>Improved algorithms for Boolean matrix multiplication via opportunistic matrix multiplication</title>
    <feedworld_mtime>1632873600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harris:David_G=.html">David G. Harris</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.13335">PDF</a><br/><b>Abstract: </b>Karppa &amp; Kaski (2019) proposed a novel type of "broken" or "opportunistic"
multiplication algorithm, based on a variant of Strassen's alkgorithm, and used
this to develop new algorithms for Boolean matrix multiplication, among other
tasks. For instance, their algorithm can compute Boolean matrix multiplication
in $O(n^{\log_2(6 + 6/7)} \log n) = O(n^{2.778})$ time. While faster matrix
multiplication algorithms exist asymptotically, in practice most such
algorithms are infeasible for practical problems. Their opportunistic algorithm
is a slight variant of Strassen's algorithm, so hopefully it should yield
practical as well as asymptotic improvements to it.
</p>
<p>In this note, we describe a more efficient way to use the broken matrix
multiplication algorithm to solve Boolean matrix multiplication. In brief,
instead of running multiple iterations of the broken algorithm on the original
input matrix, we form a new larger matrix by sampling and run a single
iteration of the broken algorithm on it. The resulting algorithm has runtime
$O( n^{\frac{3 \log 6}{\log 7}} (\log n)^{\frac{ \log 6}{\log 7}}) \leq
O(n^{2.763})$. We also describe an extension to witnessing Boolean matrix
multiplication, as well as extensions to non-square matrices.
</p>
<p>The new algorithm is simple and has reasonable constants. We hope it may lead
to improved practical algorithms
</p></div>
    </summary>
    <updated>2021-09-29T22:38:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2109.13302</id>
    <link href="http://arxiv.org/abs/2109.13302" rel="alternate" type="text/html"/>
    <title>Clustering with Neighborhoods</title>
    <feedworld_mtime>1632873600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Hongyao.html">Hongyao Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klimenko:Georgiy.html">Georgiy Klimenko</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raichel:Benjamin.html">Benjamin Raichel</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2109.13302">PDF</a><br/><b>Abstract: </b>In the standard planar $k$-center clustering problem, one is given a set $P$
of $n$ points in the plane, and the goal is to select $k$ center points, so as
to minimize the maximum distance over points in $P$ to their nearest center.
Here we initiate the systematic study of the clustering with neighborhoods
problem, which generalizes the $k$-center problem to allow the covered objects
to be a set of general disjoint convex objects $\mathscr{C}$ rather than just a
point set $P$. For this problem we first show that there is a PTAS for
approximating the number of centers. Specifically, if $r_{opt}$ is the optimal
radius for $k$ centers, then in $n^{O(1/\varepsilon^2)}$ time we can produce a
set of $(1+\varepsilon)k$ centers with radius $\leq r_{opt}$. If instead one
considers the standard goal of approximating the optimal clustering radius,
while keeping $k$ as a hard constraint, we show that the radius cannot be
approximated within any factor in polynomial time unless $\mathsf{P=NP}$, even
when $\mathscr{C}$ is a set of line segments. When $\mathscr{C}$ is a set of
unit disks we show the problem is hard to approximate within a factor of
$\frac{\sqrt{13}-\sqrt{3}}{2-\sqrt{3}}\approx 6.99$. This hardness result
complements our main result, where we show that when the objects are disks, of
possibly differing radii, there is a $(5+2\sqrt{3})\approx 8.46$ approximation
algorithm. Additionally, for unit disks we give an $O(n\log
k)+(k/\varepsilon)^{O(k)}$ time $(1+\varepsilon)$-approximation to the optimal
radius, that is, an FPTAS for constant $k$ whose running time depends only
linearly on $n$. Finally, we show that the one dimensional version of the
problem, even when intersections are allowed, can be solved exactly in $O(n\log
n)$ time.
</p></div>
    </summary>
    <updated>2021-09-29T22:40:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-09-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/141</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/141" rel="alternate" type="text/html"/>
    <title>TR21-141 |  On the (im)possibility of branch-and-bound search-to-decision reductions for approximate optimization | 

	Alexander Golovnev, 

	Siyao Guo, 

	Spencer Peters, 

	Noah Stephens-Davidowitz</title>
    <summary>We study a natural and quite general model of branch-and-bound algorithms. In this model, an algorithm attempts to minimize (or maximize) a function $f : D \to \mathbb{R}_{\geq 0}$ by making oracle queries to a heuristic $h_f$ satisfying 
\[
    \min_{x \in S} f(x) \leq h_f(S) \leq \gamma \cdot \min_{x \in S} f(x)
\]
for some $\gamma \geq 1$ and any subset $S$ in some allowed class of subsets $\mathcal{S}$ of the domain $D$. We show tight upper and lower bounds on the number of queries $q$ needed to find even a $\gamma'$-approximate minimizer for quite large $\gamma'$ in a number of interesting settings, as follows.

- For arbitrary functions $f : \{0,1\}^n \to \mathbb{R}_{\geq 0}$, where $\mathcal{S}$ contains all subsets of the domain, we show that no branch-and-bound algorithm can achieve $\gamma' \approx\gamma^{n/\log q}$, while a simple greedy algorithm achieves essentially $\gamma^{n/\log q}$.

- For a large class of MAX-CSPs, where $\mathcal{S} := \{ S_w\}$ contains each set of assignments to the variables induced by a partial assignment $w$, we show that no branch-and-bound algorithm can do significantly better than essentially a random guess, even for  $\gamma \approx 1+\sqrt{\log(q)/n}$.

- For the Traveling Salesperson Problem (TSP), where $\mathcal{S} := \{S_p\}$ contains each set of tours extending a path $p$, we show that no branch-and-bound algorithm can achieve $\gamma' \approx (\gamma-1) n/\log q$. We also prove a nearly matching upper bound in our model. 

Behind these results is a "useless oracle lemma," which allows us to argue that under certain conditions the heuristic $h_f$ is "useless," and which might be of independent interest.

We also note two alternative interpretations of our model and results. If we interpret the heuristic $h_f$ as an oracle for an approximate decision problem, then our results unconditionally rule out a large and natural class of approximate search-to-decision reductions (which we think of as "branch-and-bound" search-to-decision reductions). We therefore show an oracle model in which approximate search and decision are strongly separated. (In particular, our lower bound for TSP can be viewed as a negative answer to a question posed by Bellare and Goldwasser (SIAM J. Comput. 1994), though only in an oracle model.) By instead interpreting $h_f$ as a data structure, we see that our results unconditionally rule out black-box search-to-decision reductions for data structures.</summary>
    <updated>2021-09-28T20:45:30Z</updated>
    <published>2021-09-28T20:45:30Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-09-30T15:37:34Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2021/09/28/summarization/</id>
    <link href="http://benjamin-recht.github.io/2021/09/28/summarization/" rel="alternate" type="text/html"/>
    <title>Statistics as algorithmic summarization</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Though a multifaceted and complex discipline, Statistics’ greatest contribution is a rigorous framework for summarization. Statistics gives us reasonable procedures to estimate properties of a general population by examining only a few individuals from the population. In this regard, statistics is algorithmic: it provides randomized algorithms for extrapolation. In this blog, I’ll review some elementary stats (with as little mathematical formalism as possible), and try to crystalize why this algorithmic view is illuminating. In future blogs, I’ll build upon this algorithm perspective in applying it to more interesting examples in experiment design and prediction.</p>

<p>For a simple starter example, we know that every person on Earth has a height, defined as the distance from the bottom of their feet to the top of their head when standing upright. Suppose we would like to know the mean of the height of all living people. This would require us tracking down every living individual, getting out a tape measure, and measuring the distance from the bottom of their feet to the top of their head. To avoid such exhaustive counting we could instead devise an efficient algorithm to estimate this quantity. What if we selected a subset at random, and used this subset to estimate the mean? That is, we could collect a random sample of individuals from the population and measure the average height of all of the individuals in the sample.</p>

<p>The average height measured on this random sample is a random quantity. Thus it must have a mean and variance like we associate with other random quantities. If we were to sample each individual uniformly at random from all living humans, the expected mean height of the sample would be precisely the average height in the general population. Moreover, the variance of the average height of the sample will shrink proportionally to the number of sampled individuals. The more individuals you measure, the closer the average height on the sample will be to the average over the population.</p>

<p>Statistics provides powerful formulas that let us precisely quantify how close the sample average will be to the population average. For instance, we know a person’s height is a positive number and that there are no people who are taller than nine feet. With these two facts, a simple application of a formula called <a href="https://en.wikipedia.org/wiki/Hoeffding%27s_inequality"><em>Hoeffding’s inequality</em></a> tells us that if we sample the heights of thirty thousand individuals, our sample average will be within an inch of the true average height with probability at least 83%. This assertion is true no matter how large the population of individuals. The required sample size is dictated only by the variability of height, not by the number of total individuals.</p>

<p>You could replace “height” in this example with almost any attribute that you are able to measure well. For quantities with reasonable variability, a uniform sample from a general population will give a high quality estimate of the average value. Statistics provides a powerful framework to reason about population-level properties by examining properties of small subsets.</p>

<p>In this example, statistics provided an algorithm for estimation. We began with a quantity whose average value we would like to estimate. We specified how much this quantity can vary in the population under study. Using formulas from statistics, we computed the number of individuals we needed to examine in order to have an estimate of appropriate quality. We then can proceed to do our best to extract a random sample of individuals of this size from the population, measure these individuals, and report the mean of the sample. This is a full procedure for estimating the mean value of the general population.</p>

<p>This algorithmic description of statistical summarization probably seems uncontroversial, but it differs from how statistics is often taught or conceptualized. As I’ve discussed in previous blogs, the statistical model is oftentimes given highest precedence. In this model-based framing of statistics, the world is governed by probabilistic rules. With enough effort, these rules can be specified by a generative statistical model, and we assume that measurement is equivalent to sampling from this generative model. The generative model will have properties like a mean, and the law-of-large numbers will tell us that if we sample enough times from the model, we can accurately estimate the mean and other properties.</p>

<p>This distinction between modeling the sampling and modeling the population may appear to be splitting hairs. In some sense, the two viewpoints only differ conceptually as the algorithms for estimating the mean height in a population will be identical. However, our interpretation of these two views is different: in the algorithmic view, one can use statistics to understand the physical world no matter how the general population arose. As our height example highlights, only the most minimal modeling assumptions are needed to make use of statistical methods. In the modeling view, we shoehorn ourselves into modeling all processes with probability distributions. Not only is this unnecessary, but validating probabilistic models is also quite difficult. As I described in my last two blog posts, proposed statistical models are never validated in the vast majority of scientific studies.</p>

<p>The algorithmic view of statistics moreover illuminates the aspects of randomness that we have under our control. For example, there are whole branches of computer science dedicated to deterministically generating numbers that look random for all intents and purposes. Random number generation is something we can control. We can focus on understanding how our measurements fail to be ideal, rather than focusing on how the natural world doesn’t obey our models. This empowers the statistical practitioner to tune their procedures to be more robust against the limitations of what that can measure.</p>

<p>I want to once more emphasize that the algorithmic perspective I’ve presented here is not novel at all. Thinking about the combinatorics of random permutations and how they could be used to design randomized experiments is nearly one hundred years old, and, for example, prevalent in the works of <a href="https://www.jstor.org/stable/2342192">Jerzy Neyman</a> and the eccentric eugenicist <a href="https://en.wikipedia.org/wiki/The_Design_of_Experiments">Ronald Fisher</a> by the 1930s. Fisher’s rambling discursion on the woman who can tell if milk was added to a cup before tea describes a randomization procedure that does not model the appearance of tea in cups, the composition of tea cups, nor the psychic abilities of the tea expert. It purely counts permutations and uses exact statistics to provide a way to evaluate validity of a claim. I’ll review in more detail how to use these effectively <em>model-free</em> ideas for experimentation in the next post.</p>

<p>There are obviously issues with the algorithmic view. Statistical sampling methods work best when the variability of the quantity of interest is low. In such a case, small experiments quickly reveal insights about the population. When variances are large or effectively unbounded, the number of samples required for high precision estimates might be impractical and our estimators and algorithms need to be rethought. There are many phenomena that obey “power law” scaling, and such quantities are harder to work with in this rudimentary experimental framework. The uniform sampling algorithm we have described will have unbounded variance, and hence the average on the sample will no longer be an accurate measure of the average of the population. More sophisticated means must be deployed to estimate means of quantities with such high variation.</p>

<p>Another drawback of statistical sampling is the requirement that samples be sampled uniformly. Uniform sampling is an idealization and is often hard to implement in practice. For example, what does it mean to collect an i.i.d. sampling of registered voters in a poll? Some voters may not respond to your phone calls. Even more problematic is when you cannot define the population well in advance, as would be the case of the vague notion of “likely” voters. More sophisticated statistical analyses can provide guarantees on non-uniform sampling strategies, but care must be taken to ensure that the statistical bounds we compute reflect the reality of the implementation of the data collection. Understanding our sampling capabilities is crucial to understanding the validity of our estimates.</p>

<p>With these caveats in mind, our algorithmic framing of statistics gives us a focused way to think about experiment design and prediction methods. In the next blogs, I’ll explore these both in depth.</p></div>
    </summary>
    <updated>2021-09-28T00:00:00Z</updated>
    <published>2021-09-28T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2021-09-29T22:42:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/09/27/postdoc-at-university-of-washington-and-georgia-tech-apply-by-december-10-2021/</id>
    <link href="https://cstheory-jobs.org/2021/09/27/postdoc-at-university-of-washington-and-georgia-tech-apply-by-december-10-2021/" rel="alternate" type="text/html"/>
    <title>postdoc at University of Washington and Georgia Tech (apply by December 10, 2021)</title>
    <summary>Yin Tat Lee and Santosh Vempala are looking for a postdoc interested in the broad topics of high-dimensional optimization and sampling. The position is for up to 3 years, and the candidate can split their time between University of Washington and Georgia Tech. No teaching requirement. Start date is flexible. Website: https://yintat.com/ Email: yintat@uw.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Yin Tat Lee and Santosh Vempala are looking for a postdoc interested in the broad topics of high-dimensional optimization and sampling. The position is for up to 3 years, and the candidate can split their time between University of Washington and Georgia Tech. No teaching requirement. Start date is flexible.</p>
<p>Website: <a href="https://yintat.com/">https://yintat.com/</a><br/>
Email: yintat@uw.edu</p></div>
    </content>
    <updated>2021-09-27T07:31:24Z</updated>
    <published>2021-09-27T07:31:24Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-09-30T15:37:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/140</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/140" rel="alternate" type="text/html"/>
    <title>TR21-140 |  Tight Computational Indistinguishability Bound of Product Distributions | 

	Nathan Geier</title>
    <summary>Assume that $X_0,X_1$ (respectively $Y_0,Y_1$) are $d_X$ (respectively $d_Y$) indistinguishable for circuits of a given size. It is well known that the product distributions $X_0Y_0,\,X_1Y_1$ are $d_X+d_Y$ indistinguishable for slightly smaller circuits. However, in probability theory where unbounded adversaries are considered through statistical distance, it is folklore knowledge that in fact $X_0Y_0$ and $X_1Y_1$ are $d_X+d_Y-d_X\cdot d_Y$ indistinguishable, and also that this bound is tight.

We formulate and prove the computational analog of this tight bound. Our proof is entirely different from the proof in the statistical case, which is non-constructive. As a corollary, we show that if $X$ and $Y$ are $d$ indistinguishable, then $k$ independent copies of $X$ and $k$ independent copies of $Y$ are almost $1-(1-d)^k$ indistinguishable for smaller circuits, as against $d\cdot k$ using the looser bound. Our bounds are useful in settings where only weak (i.e. non-negligible) indistinguishability is guaranteed. We demonstrate this in the context of cryptography, showing that our bounds yield simple analysis for amplification of weak oblivious transfer protocols.</summary>
    <updated>2021-09-27T06:01:50Z</updated>
    <published>2021-09-27T06:01:50Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-09-30T15:37:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/09/27/tenure-track-faculty-at-portland-state-university-apply-by-november-1-2021/</id>
    <link href="https://cstheory-jobs.org/2021/09/27/tenure-track-faculty-at-portland-state-university-apply-by-november-1-2021/" rel="alternate" type="text/html"/>
    <title>Tenure-track faculty  at Portland State University (apply by November 1, 2021)</title>
    <summary>The Department of Computer Science at Portland State University invites applications for two Assistant Professor positions. Theory, including algorithms and quantum computing, is a focus area. One position is part of a cluster hire in Computational Science for a Sustainable Future, and theory candidates working on related topics, such as big data algorithms &amp; theoretical […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at Portland State University invites applications for two Assistant Professor positions. Theory, including algorithms and quantum computing, is a focus area. One position is part of a cluster hire in Computational Science for a Sustainable Future, and theory candidates working on related topics, such as big data algorithms &amp; theoretical ML are welcome to apply.</p>
<p>Website: <a href="https://jobs.hrc.pdx.edu/postings/35879">https://jobs.hrc.pdx.edu/postings/35879</a><br/>
Email: cssearch@pdx.edu</p></div>
    </content>
    <updated>2021-09-27T03:59:23Z</updated>
    <published>2021-09-27T03:59:23Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-09-30T15:37:47Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4828719808701026500</id>
    <link href="http://blog.computationalcomplexity.org/feeds/4828719808701026500/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/09/my-academic-lineage-and-more.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/4828719808701026500" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/4828719808701026500" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/09/my-academic-lineage-and-more.html" rel="alternate" type="text/html"/>
    <title>My academic lineage and more interesting facts that come out of it</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> I got my PhD from Harvard in 1985 with advisor Harry Lewis</p><p>Harry Lewis got his PhD from Harvard in 1974 with advisor Burton Dreben (Dreben was in the Philosophy department and did logic). Burton Dreben never got a PhD (more on that later). So I thought my lineage stopped there. A while back I was in an email conversation with Harry and for some odd reason Galileo came up.</p><p>He then emailed me the following:</p><p>----------------</p><p>Did you know you were descended from Galileo, via Newton? See below. The data is from the Math Genealogy project (see <a href="https://www.genealogy.math.ndsu.nodak.edu/">here</a>). As you know  Dreben had no PhD, but it would certainly be fair to call Quine his advisor anyway. And, in fact, the Math Geneology project lists Quine as Dreben's advisor. By starting with Dreben and clicking backwards I found the following:</p><p>In the list below everyone was advised (in some form) by the person below them.</p><p>William Gasarch, Harvard 1985</p><p>Harry Lewis, Harvard 1974</p><p>Burton Dreben, Harvard 1955</p><p>WVO Quine, Harvard 1932</p><p>AN Whitehead, Cambridge 1884</p><p>Edward John Routh, Cambridge 1857</p><p>William Hopkins, Cambridge 1830</p><p>Adam Sedgwick, Cambridge 1811</p><p>Thomas Jones, Cambridge 1782</p><p>Thomas Postlethwaite, Cambridge 1756</p><p>Stephen Whisson, Cambridge 1742</p><p>Walter Taylor, Cambridge 1723</p><p>Robert Smith, Cambridge 1715</p><p>Roger Coles, Cambridge 1706</p><p>Isaac Newton, Cambridge 1668</p><p>Isaac Barrow, Cambridge 1652</p><p>Vincenzo Viviani, Pisa 1642</p><p>Galileo Galilei, Pisa 1585</p><p>--------------------------------------</p><p>A few observations</p><p>1) Dreben was a philosophy professor at Harvard without a PhD. How? He was a Junior Fellow, which is for brilliant people, some of which were made professors without  the burden of going  through the PhD-getting ritual.  Andrew Gleason was a professor of Math at Harvard without a PhD-- also a junior fellow (he solved Hilbert's 5th problem, which surely helped). Tom Cheatham was a CS professor at Harvard who did not have a PhD but  was <i>not</i> a junior fellow. I do not know how he did that. Things are more formal now, and more people have PhD's, so I suspect it is much rarer to be a professor without a PhD.  Harvard still has the Junior Fellows Program, but even they have PhDs now. If someone solved P vs NP as an ugrad, I suspect they would be hired as a professor even though they do not have a PhD. That's one way for a theorist to get out of taking graduate systems courses. </p><p>2) Note that Galileo and Vincenzo were in Pisa but then a long line of people from Cambridge. In those days schools hired their own. Is this good or bad? They know what they are getting, but you could have an old-boys-network blocking fresh new talent, and you may get stuck in your ways. Nowadays, at least in America, it is uncommon to stay at the same school as you got your PhD.</p><p>3) The shift from Pisa to Cambridge might be part of a more general phenomena--- the intellectual center for science shifting from Italy to England. What caused this? Amir Alexander, in his book <i>Infinitesimals: How a dangerous mathematical idea shaped the modern world </i>(see my review <a href="https://www.cs.umd.edu/~gasarch/bookrev/FRED/inf.pdf">here</a> ) speculates that the Catholic Church's rejection of Infinitesimals was the cause.  I suspect that letting non-scientists interfere with science was the cause (a lesson for us all).</p><p>4) Lance did a blog on his lineage <a href="https://blog.computationalcomplexity.org/2005/06/eulerian-tour.html">here</a>. He has Gauss and Euler as ancestors. </p><p>5) To honor the myths about  my two most famous academic ancestors, Galileo and Newton,  I am going to travel to Italy and have Darling drop two apples of different weights off the leaning tower of Pisa and see if they hit my head at the same time.</p><div><br/></div></div>
    </content>
    <updated>2021-09-27T03:13:00Z</updated>
    <published>2021-09-27T03:13:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-09-30T14:30:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19144</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/09/26/a-possible-ramsey-insight-into-p-versus-np/" rel="alternate" type="text/html"/>
    <title>A Possible Ramsey Insight into P Versus NP?</title>
    <summary>In mathematics the art of proposing a question must be held of higher value than solving it—Georg Cantor Cropped from his page David Zuckerman has a beautiful result on the approximate hardness of the clique problem. His paper, “Linear Degree Extractors and the Inapproximability of Max Clique and Chromatic Number,” has has received almost 1,000 […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>In mathematics the art of proposing a question must be held of higher value than solving it—Georg Cantor</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/09/26/a-possible-ramsey-insight-into-p-versus-np/dz/" rel="attachment wp-att-19146"><img alt="" class="alignright size-full wp-image-19146" height="161" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/dz.png?resize=171%2C161&amp;ssl=1" width="171"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from his <a href="https://www.cs.utexas.edu/people/faculty-researchers/david-zuckerman">page</a></font></td>
</tr>
</tbody>
</table>
<p>
David Zuckerman has a beautiful result on the approximate hardness of the clique problem. His <a href="https://www.theoryofcomputing.org/articles/v003a006/v003a006.pdf">paper</a>, “Linear Degree Extractors and the Inapproximability of Max Clique and Chromatic Number,” has has received almost 1,000 citations since it was first published in 2007. Wow.</p>
<p>
Today we discuss a possible relevance of this result for P versus NP.</p>
<p>
Recall a clique is a subset of nodes of an undirected graph, such that every two nodes in the subset are connected by an edge. Wikipedia’s <a href="https://en.wikipedia.org/wiki/Clique_%28graph_theory%29">illustration</a> below does not have large cliques—only two cliques of <img alt="{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> nodes shaded blue to go with a bunch of triangles shaded lighter.</p>
<p/><p><br/>
<a href="https://rjlipton.wpcomstaging.com/2021/09/26/a-possible-ramsey-insight-into-p-versus-np/clique/" rel="attachment wp-att-19147"><img alt="" class="aligncenter wp-image-19147" height="160" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/clique.png?resize=200%2C160&amp;ssl=1" width="200"/></a></p>
<p/><p><br/>
Is there a relatively small change we could make to the graph to give it a much larger clique? At top right, we could add two edges to extend the blur <img alt="{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-clique to a <img alt="{5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-clique—a pentagram inside a pentagon. At bottom left we could add <img alt="{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> edges to make the four triangles blossom into a <img alt="{6}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-clique.</p>
<p>
Computing the size of the largest clique in a graph—or just telling whether it has a clique of a given size <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>—is a famous NP-complete problem. Counting the number of cliques of the largest size is evidently a harder problem still. Yet you might think it easier to tell a graph with only small cliques apart from a graph that has large ones. This is where David’s result comes in.</p>
<p>
In passing, we note David’s place among the <a href="https://www.maa.org/sites/default/files/pdf/Putnam/Competition_Archive/List%20of%20Previous%20Putnam%20Winners.pdf">winners</a> of the 1986 William Lowell Putnam Mathematical Competition. Also on the list was Bjorn Poonen, whom we have also <a href="https://rjlipton.wpcomstaging.com/2010/08/07/hilberts-tenth-over-the-rationals/">highlighted</a> <a href="https://rjlipton.wpcomstaging.com/2014/11/19/two-versus-three/">multiple</a> times <a href="https://rjlipton.wpcomstaging.com/2020/01/25/the-halting-no-go-theorem/">including</a> <a href="https://rjlipton.wpcomstaging.com/2021/03/13/hilberts-tenth-again/">recently</a>. Here is the 1986 <a href="https://kskedlaya.org/putnam-archive/1986.pdf">exam</a>; Ken and I confess we did much worse when we took the Putnam in earlier years.</p>
<p>
</p><p/><h2> David’s Result </h2><p/>
<p/><p>
Polynomial growth refers to a function that is bounded by <img alt="{n^c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5Ec%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for some constant <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. <b>Quasi-polynomial</b> growth means one bounded by <img alt="{n^{\log^c n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B%5Clog%5Ec+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for some <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Let <img alt="{\mathsf{\widetilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> those sets accepted by a deterministic algorithm that runs in quasi-polynomial time and let <img alt="{\mathsf{N\widetilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BN%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be those sets accepted by a nondeterministic algorithm that runs in quasi-polynomial time</p>
<p>
Let <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> be an <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-vertex graph. We have two properties of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for a fixed <img alt="{\epsilon&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>:</p>
<blockquote><p><b> </b> <em> </em></p><em>
<ul>
<li>
<b>Clumpy</b>: <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> has a clique of size at least <img alt="{\epsilon n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+n%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>. <p/>
</li><li>
<b>Limpid</b>: <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> has no clique of size <img alt="{n^{\epsilon}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B%5Cepsilon%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>.
</li></ul>
</em><p><em/>
</p></blockquote>
<p/><p>
The following is a main result in David’s paper:</p>
<blockquote><p><b>Theorem 1</b> <em> The problem of distinguishing clumpy graphs from limpid graphs is not in <img alt="{\widetilde{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> provided <img alt="{\mathsf{\widetilde{P} \neq N\widetilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5Cwidetilde%7BP%7D+%5Cneq+N%5Cwidetilde%7BP%7D%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>. </em>
</p></blockquote>
<p/><p>
It is fundamentally a de-randomization result. Our idea is to scale it down in a way that may bring <img alt="{\mathsf{\widetilde{P} \neq N\widetilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5Cwidetilde%7BP%7D+%5Cneq+N%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> into contact with mathematical theorems that govern effects of the scaling. The theorems may be adjacent to conjectures that can suggest new approaches. The idea may require bringing back randomization, however.</p>
<p>
</p><p/><h2> The Question </h2><p/>
<p/><p>
Our quest to build on David’s theorem leads us to interpose a classic idea. In work with Paul Erdős, Tibor Radó wrote <img alt="{G\rightarrow(H)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%5Crightarrow%28H%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to mean that every <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-coloring of the edges of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> has a monochromatic subgraph <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The classic two-color Ramsey theorem states that for all <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> there is a <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that <img alt="{G\rightarrow(K_r)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%5Crightarrow%28K_r%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Erdős and George Szekeres further showed <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> can have fewer than <img alt="{2^{2r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B2r%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> nodes. </p>
<blockquote><p><b>Definition 2</b> <em> Say an <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>-node graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> is <b><img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>-Radó</b> if every edge 2-coloring of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> leaves a clique of <img alt="{\frac{1}{2}\log n - c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D%5Clog+n+-+c%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> vertices. </em>
</p></blockquote>
<p/><p>
In Radó’s notation, this is if <img alt="{G \rightarrow (K_{\frac{1}{2}\log_2 n - c})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG+%5Crightarrow+%28K_%7B%5Cfrac%7B1%7D%7B2%7D%5Clog_2+n+-+c%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The first point is that all clumpy graphs are <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-Radó for large enough <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Taking <img alt="{c \geq 2\log_2(\frac{1}{\epsilon})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc+%5Cgeq+2%5Clog_2%28%5Cfrac%7B1%7D%7B%5Cepsilon%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> puts the <img alt="{\epsilon n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-sized clique above the Erdős-Szekeres bound for the Ramsey property to hold. </p>
<p>
Thus the key question becomes:</p>
<blockquote><p><b> </b> <em><a name="limpid"/> Suppose that <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a limpid graph. Can <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> also be <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>-Radó? </em>
</p></blockquote>
<p/><p>
Suppose the answer is <b>no</b>. Then every limpid graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> has an edge 2-coloring that does not leave a clique of size <img alt="{k = \frac{1}{2}\log n - c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+%5Cfrac%7B1%7D%7B2%7D%5Clog+n+-+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. We can verify this in quasi-polynomial time by trying all <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-subsets of the vertices. </p>
<p>
This sets up a situation where both “limpid” and “clumpy” have an <img alt="{\mathsf{N\widetilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BN%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> witness. More to the point, we obtain the modified problem of distinguishing “clumpy” from “not <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-Radó” (for appropriately chosen <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>). This would then likewise be <img alt="{\mathsf{N\widetilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BN%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-hard by David’s result. Then, we would have an <img alt="{\mathsf{N\widetilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BN%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-hard <b>promise problem</b> with promise set <img alt="{\mathsf{clumpy \cup}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bclumpy+%5Ccup%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> not-<i>c</i>-Radó belonging to <img alt="{\mathsf{N\widetilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BN%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. This would be a plausible unlikelihood along the lines of what the <a href="https://link.springer.com/article/10.1007/s00037-015-0107-6">ESY</a> <a href="https://www.sciencedirect.com/science/article/pii/S001999588480056X">conjecture</a>, which we covered <a href="https://rjlipton.wpcomstaging.com/2012/07/14/it-dont-come-easy/">here</a>, rules out. 	 We can obtain a clearer unlikelihood if we relax the new definition.</p>
<blockquote><p><b>Definition 3</b> <em><a name="almost"/> An <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>-node graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> is <b>almost <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>-Radó</b> if all but a negligible fraction of edge 2-colorings leave a monochrome clique on <img alt="{\frac{1}{2}\log_2 n - c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D%5Clog_2+n+-+c%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> vertices. </em>
</p></blockquote>
<p/><p>
Here “negligible” means a function asymptotically less than <img alt="{1/q(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2Fq%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for any quasi-polynomial function <img alt="{q(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. With some informality, we can prove:</p>
<blockquote><p><b>Proposition 4</b> <em> Suppose no limpid graphs are almost <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>-Radó. Then <img alt="{\mathsf{N\widetilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BN%5Cwidetilde%7BP%7D%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> is contained in randomized <img alt="{\widetilde{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Formally, the negation is worded so that there is a quasi-polynomial function <img alt="{q(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such that for every limpid graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>—with the concrete value of <img alt="{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and corresponding <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>—there are a <img alt="{\frac{1}{q(n)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7Bq%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> fraction of 2-edge-colorings of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that do not have a monochromatic clique of size <img alt="{\frac{1}{2}\log_2 n - c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D%5Clog_2+n+-+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Now define an algorithm <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that given any graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> guesses order-<img alt="{q(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> such colorings at random.</p>
<ul>
<li>
If <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> finds a coloring that does not have a monochromatic clique of size <img alt="{\frac{1}{2}\log_2 n - c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D%5Clog_2+n+-+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> rejects. <p/>
</li><li>
Else, <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> accepts.
</li></ul>
<p>
Whenever <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is clumpy, <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> will always accept. If <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is limpid, then with high probability, <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> will find a coloring witnessing that <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is not clumpy, and <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> will reject <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Thus, <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> distinguishes limpid from clumpy in randomized quasi-polynomial time. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>
</p><p/><h2> The Quest For Limpid Radó Graphs </h2><p/>
<p/><p>
If, like most, you believe <img alt="{\mathsf{\widetilde{P} \neq N\widetilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5Cwidetilde%7BP%7D+%5Cneq+N%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, or further in the “ESY”-type strengthening of <img alt="{\mathsf{\widetilde{NP} \neq \text{co-}N\widetilde{P}}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5Cwidetilde%7BNP%7D+%5Cneq+%5Ctext%7Bco-%7DN%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then the answer must be that limpid (almost-)<img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-Radó graphs exist. The question of <em>finding</em> them, however, has a long trail that leads back into complexity theory.</p>
<p>
To begin, let’s decouple the clique size from the number <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of nodes by considering graphs with a clique of size <img alt="{6}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to be “lumpy,” and use the original form of the Radó property: every 2-edge coloring has a monochrome triangle. It is surprisingly hard to find a <img alt="{K_6}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK_6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-free graph with the property. Brute-force attempts for <img alt="{7}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B7%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-node and <img alt="{8}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-node graphs that are maximal for having no <img alt="{K_6}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK_6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> fail:</p>
<p/><p><br/>
<a href="https://rjlipton.wpcomstaging.com/?attachment_id=19149" rel="attachment wp-att-19149"><img alt="" class="aligncenter wp-image-19149" height="146" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/NonRadoGraphs.png?resize=550%2C146&amp;ssl=1" width="550"/></a></p>
<p/><p><br/>
The smallest <img alt="{K_6}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK_6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-free graph with the Radó triangle property that we know how to build has <img alt="{n=14}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D14%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> nodes and comes from a proof that the Radó triangle property is <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-complete. The proof is in a 1985 <a href="https://bd.booksc.org/book/5907065/04eeae">paper</a> by Moon-Jung Chung, W. Michael Evangelist, and Ivan Hal Sudborough. The graph at left, which looks like a bat, is such that any 2-edge coloring without a monochrome triangle must give the two edges marked <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> the same color—whichever color is used for two edges of the middle triangle. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/09/26/a-possible-ramsey-insight-into-p-versus-np/ces1985graphs/" rel="attachment wp-att-19151"><img alt="" class="aligncenter wp-image-19151" height="236" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/CES1985graphs.jpg?resize=550%2C236&amp;ssl=1" width="550"/></a></p>
<p>
Joining a bat and an upside-down bat creates the graph at right, in which the edges marked <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{\bar{x}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7Bx%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> must have opposite colors. This creates a truth-assignment gadget for each pair of literals <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{\bar{x}_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7Bx%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in a 3CNF formula <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> given as instance of the <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-complete Not-All-Equal 3SAT <a href="https://en.wikipedia.org/wiki/Not-all-equal_3-satisfiability">problem</a>. Using one triangle per clause of <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, connecting more bats between <img alt="{x_i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> or <img alt="{\bar{x}_j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7Bx%7D_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> appearing in the clause to the corresponding edges in the truth gadgets creates a <img alt="{K_6}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK_6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-free graph <img alt="{G_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> that has the Radó property if and only if <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> has an assignment making 1 or 2 literals true in each clause. </p>
<p>
Then every negative instance <img alt="{\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> induces a <img alt="{K_6}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK_6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-free Radó graph <img alt="{G_\phi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. We can get one more simply, however, by adding a third “bat” to the graph at right above that connects <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{\bar{x}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7Bx%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The resulting <img alt="{14}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B14%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-node graph has no 2-edge coloring without making a monochrome triangle.</p>
<p>
To be truly “limpid,” however, the graph should exclude smaller cliques. The following problem of Erdős and Radó was open for some time:</p>
<blockquote><p><b> </b> <em> Does there exist a <img alt="{K_4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK_4%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>-free graph with the Radó triangle property? </em>
</p></blockquote>
<p/><p>
This was <a href="https://www.jstor.org/stable/2099355">solved</a> in 1970 by Jon Folkman and then improved in 1987 by a probabilistic argument of Joel Spencer, in a <a href="https://core.ac.uk/download/pdf/82159088.pdf">paper</a> titled, “Three Hundred Million Points Suffice.” That’s right: for the minimum Radó criterion he showed there is a limpid graph with <img alt="{N &lt; \mathbf{300,000,000}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%3C+%5Cmathbf%7B300%2C000%2C000%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> nodes. This 2007 <a href="https://www.cs.rit.edu/~spr/PUBL/paper53.pdf">paper</a> by the Ramsey-theory experts Stanisław Radziszowski and Xu Xiaodong proves that the minimum possible <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is <img alt="{19}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B19%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and gives evidence that <img alt="{N \leq 127}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%5Cleq+127%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is plausible. let <img alt="{N_{3,3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN_%7B3%2C3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> stand for the least possible such <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>
However one such graph exists, it must give rise to a “bat”-type construction and forthwith a reduction showing the <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-completeness of the <img alt="{K_4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK_4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-free Radó property. Thus the Ramsey-type existence question is entangled with complexity theory. How this relationship <em>scales</em> up for <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-Radó and clumpy versus limpid graphs is the point we are driving at.</p>
<p>
</p><p/><h2> Ramsey Scaling And Complexity </h2><p/>
<p/><p>
There are two main levers by which we are scaling:</p>
<ul>
<li>
Up from the constant <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of the Radó triangle property to <img alt="{\rho = \frac{1}{2}\log_2(n) - c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho+%3D+%5Cfrac%7B1%7D%7B2%7D%5Clog_2%28n%29+-+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-Radó. <p/>
</li><li>
Up to <img alt="{k=n^\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3Dn%5E%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as the allowed clique size in a <em>limpid</em> graph.
</li></ul>
<p>
The latter corresponds to the <img alt="{\epsilon n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> size for <em>clumpy</em> that we are distinguishing, but there is some freedom in <img alt="{\epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. If we imagine <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as fixed—temporarily ignoring the dependence on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>—we can ask, what is the minimum size <img alt="{N = N_{\rho,k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+N_%7B%5Crho%2Ck%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of a <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-limpid graph that is <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-Radó? </p>
<p>
To avoid a complexity collapse, we must bet on at worst a single-exponential dependence on <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, polynomial in <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Can we possibly show this directly? Note that <img alt="{\rho = 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho+%3D+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, <img alt="{k = 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> already raised the specter of <img alt="{N_{3,3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN_%7B3%2C3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the hundred millions. Not only do we not see a way to scale up Spencer’s proof, he remarked in the intro that his proof is “extremely case specific” and does not scale even to 3-edge colorings. The “almost” feature of Definition <a href="https://rjlipton.wpcomstaging.com/feed/#almost">3</a> adds a further complication.</p>
<p>
It may be that the guiderails for ascending to higher <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{\rho}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (scaling with the number <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of nodes) are already present among the details of the graph constructions in David’s proof and the proofs of the theorems his paper builds on. We have not had time to delve. There must be <em>some</em> connection; the question is whether complexity considerations take the lead or follow only in train of the sides that can be mathematically disproved.  Other connections of Ramsey theory are in this nice 2004 <a href="https://www.combinatorics.org/ojs/index.php/eljc/article/view/DS13/pdf">survey</a> by Vera Rosta.</p>
<p>
Here is one more indication of why we think the interaction between complexity and Ramsey theory can be nontrivial. Putting <img alt="{R = 2^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR+%3D+2%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, the upper bound noted above for the diagonal-<img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> Ramsey number has rough order <img alt="{R^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The best known lower bound has rough order <img alt="{R^{1/2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%5E%7B1%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Can we show an impact of the growth of <img alt="{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> on complexity theory, in advance of resolving this gap which has been open for over fifty years?</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
The key issue is, what about the above question? Assuming the usual belief that quasi-polynomial time and nondeterministic quasi-polynomial time are distinct we must be able to show a fact about <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-colorings of clumpy and limpid graphs. If this is hard to prove, then we have an interesting impasse. Even worse, if this is false, then our beliefs collapse. </p>
<p/><p><br/>
The feature that surprises us about the 1986 Putnam <a href="https://kskedlaya.org/putnam-archive/1986.pdf">exam</a> is that it does <em>not</em> have a question that involves the number <b>1,986</b>. Ken and I both remember such features. Here is a problem they could have used; we will give the answer later:</p>
<blockquote><p><b> </b> <em> Alan and Barbara play a game in which they take turns filling entries of an initially empty 1986 x 1986 array. Alan plays first. At each turn, a player chooses a real number and places it in a vacant entry. The game ends when all the entries are filled. Alan wins if the determinant of the resulting matrix is nonzero; Barbara wins if it is zero. Which player has a winning strategy? </em>
</p></blockquote>
<p>The answer is at the end of the next <a href="https://rjlipton.wpcomstaging.com/2021/09/30/baby-steps/">post</a>.</p>
<p/><p><br/>
[removed reference to Putnam ranking, “batch”-&gt;”bats” in the proof from 1985, added answer link for puzzle at end]</p></font></font></div>
    </content>
    <updated>2021-09-26T20:18:22Z</updated>
    <published>2021-09-26T20:18:22Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="Open Problems"/>
    <category term="P=NP"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="approximation"/>
    <category term="clique"/>
    <category term="complexity"/>
    <category term="David Zuckerman"/>
    <category term="ESY conjecture"/>
    <category term="graphs"/>
    <category term="Joel Spencer"/>
    <category term="Paul Erdos"/>
    <category term="Ramsey theory"/>
    <category term="Tibor Rado"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-09-30T15:37:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5854</id>
    <link href="https://www.scottaaronson.com/blog/?p=5854" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5854#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5854" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">“Is China Ahead in the Quantum Computing Race?”</title>
    <summary xml:lang="en-US">Please enjoy an hourlong panel discussion of that question on YouTube, featuring yours truly, my former MIT colleague Will Oliver, and political scientist and China scholar Elsa Kania. If you’re worried that the title sounds too sensationalistic, I hope my fellow panelists and I will pleasantly surprise you with our relative sobriety! Thanks so much […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Please enjoy an <a href="https://www.youtube.com/watch?v=KzFEeQ49HHI">hourlong panel discussion of that question on YouTube</a>, featuring yours truly, my former MIT colleague Will Oliver, and political scientist and China scholar Elsa Kania.  If you’re worried that the title sounds too sensationalistic, I hope my fellow panelists and I will pleasantly surprise you with our relative sobriety!  Thanks so much to <a href="https://qcware.com/">QC Ware</a> for arranging the panel (full disclosure: I’m QC Ware’s scientific adviser).</p></div>
    </content>
    <updated>2021-09-26T16:48:06Z</updated>
    <published>2021-09-26T16:48:06Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="http://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-09-26T16:48:06Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/09/25/multilayer-tiles</id>
    <link href="https://11011110.github.io/blog/2021/09/25/multilayer-tiles.html" rel="alternate" type="text/html"/>
    <title>Multilayer tiles</title>
    <summary>You’re probably familiar with the fact that you can draw a convex octagon with corners in an integer grid, fitting into a \(3\times 3\) square. It’s not regular, because its side lengths alternate between \(1\) and \(\sqrt 2\), but it has the same angles as a regular octagon and looks close enough to it for some purposes.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>You’re probably familiar with the fact that you can draw a convex octagon with corners in an integer grid, fitting into a \(3\times 3\) square. It’s not regular, because its side lengths alternate between \(1\) and \(\sqrt 2\), but it has the same angles as a regular octagon and looks close enough to it for some purposes.</p>

<p style="text-align: center;"><img alt="3x3 integer octagon and its 7-ply tiling of the plane" src="https://11011110.github.io/blog/assets/2021/7way-octagon.svg"/></p>

<p>It also has another interesting property: if you place copies of it at every point of the integer grid, then each edge of each copy is also the edge of another copy. Therefore, if you let \(p\) be any point that avoids the edges of the octagons, count the number of octagons that cover any point of the plane, and then slide \(p\) around to another edge-avoiding point, the number of covering octagons always stays unchanged. Whenever \(p\) slides off from one octagon, it slides onto another one. Because the area of the integer octagon is seven units, and you’re placing one octagon for every unit square of the grid, the average covering depth is seven. And since the covering depth stays the same everywhere, it’s seven everywhere. You can think of this collection of octagons as forming a <span style="white-space: nowrap;">\(7\)-ply</span> tiling of the plane, despite the fact that convex octagons cannot tile the plane in the usual \(1\)-ply sense of tiling.</p>

<p>More generally, define a \(k\)-ply tiling to be a covering of the plane by congruent copies of some prototile (allowing rotations, even though these are not necessary for the octagon) such that, except at a subset of the plane of measure zero (the boundaries of the prototiles), every point is covered by exactly \(k\) copies, and define the “ply” of a prototile to be the minimum \(k\) such that it has a \(k\)-ply tiling. The integer octagon has <span style="white-space: nowrap;">ply \(7\):</span> once one octagon is placed anywhere in the plane, the rest of the tiling is forced to follow in the same way around it, in order to avoid creating seams where an octagon edge is not matched by another octagon and the ply changes. The same construction, using centrally symmetric octagons with integer vertices and longer sides, produces for any \(k\ge9\) a convex tile of <span style="white-space: nowrap;">ply \(k\).</span></p>

<p>This is the subject of my new short paper (or maybe extended abstract) “Multifold tiles of polyominoes and convex lattice polygons”, with many coauthors from the 2017 Bellairs Winter Workshop on Computational Geometry: Kota Chida, Erik Demaine, Martin Demaine, Adam Hesterberg, Takashi Horiyama, John Iacono, Hiro Ito, Stefan Langerman, Ryuhei Uehara, and Yushi Uno. You can find it in the <a href="http://www.math.science.cmu.ac.th/tjcdcggg/Book-abstract.pdf">book of abstracts of the 23rd Thailand–Japan Conference on Discrete and Computational Geometry, Graphs, and Games (TJCDCG<sup>3</sup> 2020+1)</a>, which was organized online by Chiang Mai University earlier this month.</p>

<p>As well as the family of octagon \(k\)-ply tilers described above, we found that cutting the bottom row of squares off a \(3\times 3\) octagon produces a \(5\)-ply hexagon tiler, this time requiring \(180^\circ\)-degree rotations for its tiling, and that stretching this hexagon can produce an <span style="white-space: nowrap;">\(8\)-ply</span> convex tiler. We also found polyomino <span style="white-space: nowrap;">\(k\)-ply</span> tilers for <span style="white-space: nowrap;">all \(k\ge 2\),</span> and three heptominoes (the smallest possible polyominoes) that can each form <span style="white-space: nowrap;">\(k\)-ply</span> tilings for all \(k\ge 2\) but not for <span style="white-space: nowrap;">\(k=1\).</span> I imagine the details will become available in a more complete paper at some point but for now the abstract just announces these results and gives pictures of these heptominoes. We still don’t know whether there can exist convex polygons whose ply is one of <span style="white-space: nowrap;">\(\{2,3,4,6\}\).</span></p>

<p>The TJCDCG<sup>3</sup> abstract book has many other intriguing results in discrete geometry, graph theory, and combinatorial game theory, so do check it out if you’re interested. Tiling-related highlights include a variation on Wang tiling adding connectivity constraints and inspired by a dungeon-making mini-game in <em>The Legend of Zelda: Link’s Awakening</em> (“Tiling the Plane Connectively with Wang Tiles”, Chao Yang), signal processing using high-dimensional substitution tilings (“Generating Frames via Discretized Substitution Tilings”, Luis S. Silvestre Jr. and Job A. Nable), a partial classification of edge-to-edge monohedral tilings of the sphere (“Tiling of the Sphere by Congruent Polygons”, Yohji Akama, Hoi Ping Luk, Erxiao Wang, and Min Yan), and tilings that can be used to make arrays of joined-up origami cranes (“Renzuru Tilings with Asymmetric Quadrilaterals”, Takashi Yoshino).</p>

<p>(<a href="https://mathstodon.xyz/@11011110/106995035140693185">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2021-09-25T00:00:00Z</updated>
    <published>2021-09-25T00:00:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-09-26T00:06:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5850</id>
    <link href="https://www.scottaaronson.com/blog/?p=5850" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5850#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5850" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Was Scientific American Sokal’d?</title>
    <summary xml:lang="en-US">Here’s yesterday’s clickbait offering from Scientific American, the once-legendary home of Martin Gardner’s Mathematical Games column: Why the Term ‘JEDI’ Is Problematic for Describing Programs That Promote Justice, Equity, Diversity and Inclusion The sad thing is, I see few signs that this essay was meant as a Sokal-style parody, although in many ways it’s written […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Here’s yesterday’s clickbait offering from <em>Scientific American</em>, the once-legendary home of Martin Gardner’s Mathematical Games column:</p>



<p><a href="https://www.scientificamerican.com/article/why-the-term-jedi-is-problematic-for-describing-programs-that-promote-justice-equity-diversity-and-inclusion/">Why the Term ‘JEDI’ Is Problematic for Describing Programs That Promote Justice, Equity, Diversity and Inclusion</a></p>



<p>The sad thing is, I see few signs that this essay was meant as a Sokal-style parody, although in many ways it’s written as one.  The essay actually develops a 100% cogent, reasoned argument: namely, that the ideology of the <em>Star Wars</em> films doesn’t easily fit with the new ideology of militant egalitarianism at the expense of all other human values, including irony, humor, joy, and the nurturing of unusual talents. The authors are merely oblivious to the conclusion that most people would draw from their argument: namely, so much the worse for the militant egalitarianism then!</p>



<p>I predict that this proposal—to send the acronym “JEDI” the way of “mankind,” “blacklist,” and, err, “quantum supremacy”—will meet with opposition even from the wokeists themselves, a huge fraction of whom (in my experience) have soft spots for the <em>Star Wars</em> franchise.  Recall for example that in 2014, Laurie Penny used <em>Star Wars</em> metaphors in her <a href="https://www.newstatesman.com/uncategorized/2014/12/on-nerd-entitlement-rebel-alliance-empire">interesting response</a> to my comment-171, telling male nerds like me that we need to learn to accept that “[we’re] not the Rebel Alliance, [we’re] actually part of the Empire and have been all along.”  Admittedly, I’ve never <em>felt like</em> part of an Empire, although I’ll confess to some labored breathing lately when ascending flights of stairs.</p>



<p>As for me, I spent much of my life opposed in principle to <em>Star Wars</em>—I hated how the most successful “science fiction” franchise of all time became that way <em>precisely</em> by ditching any pretense of science and fully embracing mystical woo—but sure, when the chips are down, I’m crazy and radical enough to take the side of Luke Skywalker, even if a team of woke theorists is earnestly, unironically explaining to me that lightsabers are phallocentric and that Vader ranks higher on the intersectional oppression axis because of his breathing problem.</p>



<p>Meantime, of course, the US continues to <a href="https://l.facebook.com/l.php?u=https%3A%2F%2Fwww.washingtonpost.com%2Fopinions%2F2021%2F09%2F23%2Frobert-kagan-constitutional-crisis">careen toward its worst Constitutional crisis since the Civil War</a>, as Trump prepares to run again in 2024, and as this time around, the Republicans are systematically purging state governments of their last Brad Raffenspergers, of anyone who might stand in the way of them simply setting aside the vote totals and declaring Trump the winner regardless of the actual outcome.  It’s good to know that my fellow progressives have their eyes on the ball—so that when that happens, at least universities will no longer be using offensive acronyms like “JEDI”!</p></div>
    </content>
    <updated>2021-09-24T19:41:19Z</updated>
    <published>2021-09-24T19:41:19Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Obviously I'm Not Defending Aaronson"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="http://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-09-26T16:48:06Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/09/24/which-integer-sequences</id>
    <link href="https://11011110.github.io/blog/2021/09/24/which-integer-sequences.html" rel="alternate" type="text/html"/>
    <title>Which integer sequences form denominators of Egyptian fractions?</title>
    <summary>I have a new paper out: “Egyptian Fractions with Denominators from Sequences Closed Under Doubling”, in the Journal of Integer Sequences. (There should also be an arXiv version soon but despite my long association with arXiv they made me get an endorser before I could upload to the number theory category, slowing down my submission there.)</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I have a new paper out: “<a href="https://cs.uwaterloo.ca/journals/JIS/VOL24/Eppstein/eppstein2.html">Egyptian Fractions with Denominators from Sequences Closed Under Doubling</a>”, in the <em>Journal of Integer Sequences</em>. (There should also be an arXiv version soon but despite my long association with arXiv they made me get an endorser before I could upload to the number theory category, slowing down my submission there.)</p>

<p>Anyway, it’s basically a journal version of an old blog post here, “<a href="https://11011110.github.io/blog/2016/11/20/egyptian-fractions-with.html">Egyptian fractions with practical denominators</a>”. That post concerned the <a href="https://en.wikipedia.org/wiki/Practical_number">practical numbers</a>, positive integers \(n\) such that all other positive integers up to \(n\) can be represented as sums of distinct divisors of \(n\). This definition gives the practical numbers a natural connection to <a href="https://en.wikipedia.org/wiki/Egyptian_fraction">Egyptian fractions</a>, representations of rational numbers as sums of distinct unit fractions: if you represent a number \(k&lt;n\) by a sum of distinct divisors of \(n\), and then divide everything by \(n\), you get an Egyptian fraction for \(k/n\). Zhi-Wei Sun asked whether the practical numbers and Egyptian fractions were connected in a different way, with every positive integer having an Egyptian fraction representation in which all denominators are practical, and my blog post provides a positive answer to Sun’s question.</p>

<p>The new paper simplifies the presentation of the solution, compared to the blog post, by providing direct formulas for the representation rather than an iterative computational method for finding it. But beyond that, it also shows that the same method (based on dividing by a large power of two and dealing separately with the quotient and remainder) works for many other integer sequences beyond the practical numbers. All it needs from an integer sequence is two simple properties:</p>

<ul>
  <li>
    <p>The sequence should include a multiple of every integer. In order to represent \(k/p\) as an Egyptian fraction, when \(p\) is prime, the denominators must include at least one multiple of \(p\), so the requirement of including multiples is pretty natural in this context.</p>
  </li>
  <li>
    <p>For every number \(n\) that belongs to the sequence, \(2n\) should also belong to the sequence. This is the “closed under doubling” of the new article’s title, and is closely connected to the method used by the article involving division by powers of two.</p>
  </li>
</ul>

<p>Whenever a sequence \(S\) of positive integers has both properties, we can find Egyptian fractions for all positive rationals up to \(\sum_{x\in S}1/x\), the natural limiting value for such representations. When \(\sum_{x\in S}1/x\) diverges, we get all positive rationals. As well as the practical numbers, this works for some other nice sequences including the <a href="https://en.wikipedia.org/wiki/Odious_number">odious</a> and <a href="https://en.wikipedia.org/wiki/Evil_number">evil</a> numbers, the <a href="https://oeis.org/A001013">orders of isomorphism groups of trees</a>, and the <a href="https://oeis.org/A003714">fibbinary numbers</a>, numbers whose binary representation avoids consecutive ones. Because they’re based on binary representations, the doubling property of odious, evil, and fibbinary numbers follows from their definitions; the existence of multiples of other integers in these sequences is less obvious but was more or less already known. Isomorphism groups of trees have orders that are the products of factorials, from which (because 2 is a factorial and \(n!\) is a multiple of \(n\)) both properties follow immediately.</p>

<p>Although these two properties are sufficient for a sequence to form Egyptian fractions for rationals up to its natural limit, they are not necessary. Ron Graham’s PhD dissertation was on the same topic, and showed that the sequence of squares greater than one has the same property. (The sequence of all squares, including one, is a little more complicated: its sums of distinct reciprocals can represent all rationals in the intervals \([0,\pi^2/6-1)\) and \([1,\pi^2/6)\) but can’t cover the gap between these two intervals.) Characterizing which sequences do or do not form representations of this type more generally seems like an interesting question, but one that I don’t have much idea how to attack at this point.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/106989108978976649">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2021-09-24T15:47:00Z</updated>
    <published>2021-09-24T15:47:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-09-26T00:06:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/139</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/139" rel="alternate" type="text/html"/>
    <title>TR21-139 |  Punctured Large Distance Codes, and Many Reed-Solomon Codes, Achieve List-Decoding Capacity | 

	Venkatesan Guruswami, 

	Jonathan Mosheiff</title>
    <summary>We prove the existence of Reed-Solomon codes of any desired rate $R \in (0,1)$ that are combinatorially list-decodable up to a radius approaching  $1-R$, which is the information-theoretic limit. This is established by starting with the full-length $[q,k]_q$ Reed-Solomon code over a field $\mathbb{F}_q$ that is polynomially larger than the desired dimension $k$, and "puncturing" it by including $k/R$ randomly chosen codeword positions. 
		
Our puncturing result is more general and applies to any code with large minimum distance: we show that a random rate $R$ puncturing of an $\mathbb{F}_q$-linear "mother" code whose relative distance is close enough to $1-1/q$ is list-decodable up to a radius approaching the $q$-ary list-decoding capacity bound $h_q^{-1}(1-R)$. In fact, for large $q$, or under a stronger assumption of low-bias of the mother-code, we prove that the threshold rate for list-decodability with a specific list-size (and more generally, any "local" property) of the random puncturing approaches that of fully random linear codes. Thus, all current (and future) list-decodability bounds shown for random linear codes extend automatically to random puncturings of any low-bias (or large alphabet) code. This can be viewed as a general derandomization result applicable to random linear codes. 
		
To obtain our conclusion about Reed-Solomon codes, we establish some hashing properties of field trace maps that allow us to reduce the list-decodability of RS codes to its associated trace (dual-BCH) code, and then apply our puncturing theorem to the latter. Our approach implies, essentially for free, optimal rate list-recoverability of punctured RS codes as well.</summary>
    <updated>2021-09-24T02:44:57Z</updated>
    <published>2021-09-24T02:44:57Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-09-30T15:37:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=570</id>
    <link href="https://tcsplus.wordpress.com/2021/09/23/tcs-talk-wednesday-september-29-audra-mcmillan-apple/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, September 29 — Audra McMillan, Apple</title>
    <summary>The next TCS+ talk (and first of the semester!) will take place this coming Wednesday, September 29th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC: check your time zone!). We’re excited to have Audra McMillan from Apple speak about “Hiding among the clones: a simple and nearly optimal […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk (and first of the semester!) will take place this coming Wednesday, September 29th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC: check your time zone!). We’re excited to have <a href="https://audramarymcmillan.wixsite.com/mysite"><strong>Audra McMillan</strong> </a>from Apple speak about “<em>Hiding among the clones: a simple and nearly optimal analysis of privacy amplification by shuffling</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards, so people who did not sign up will still be able to watch the talk)</p>
<p>As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: Differential privacy (DP) is a model of privacy-preserving machine learning that has garnered significant interest in recent years due to its rigorous privacy guarantees. An algorithm differentially private if the output is stable under small changes in the input database. While DP has been adopted in a variety of applications, most applications of DP in industry actually satisfy a stronger notion called local differential privacy. In local differential privacy data subjects perturb their data before it reaches the data analyst. While this requires less trust, it comes a substantial cost to accuracy. Recent work of Erlingsson, Feldman, Mironov, Raghunathan, Talwar, and Thakurta [EFMRTT19] demonstrated that random shuffling amplifies differential privacy guarantees of locally randomized data. Such amplification implies substantially stronger privacy guarantees for systems in which data is contributed anonymously [BEMMRLRKTS17] and has led to significant interest in the shuffle model of privacy [CSUZZ19, EFMRTT19]. In this talk, we will discuss a new result on privacy amplification by shuffling, which achieves the asymptotically optimal dependence in the local privacy parameter. Our result is based on a new proof strategy which is simpler than previous approaches, and extends to a lightly weaker notion known as approximate differential privacy with nearly the same guarantees.</p>
<p>Based on joint work with Vitaly Feldman and Kunal Talwar (<a href="https://arxiv.org/abs/2012.12803">https://arxiv.org/abs/2012.12803</a>).</p></blockquote></div>
    </content>
    <updated>2021-09-23T21:57:43Z</updated>
    <published>2021-09-23T21:57:43Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2021-09-30T15:38:35Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2703071019388552512</id>
    <link href="http://blog.computationalcomplexity.org/feeds/2703071019388552512/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/09/why-conferences.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/2703071019388552512" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/2703071019388552512" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/09/why-conferences.html" rel="alternate" type="text/html"/>
    <title>Why Conferences?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>An <a href="https://arxiv.org/abs/2109.06438">undergrad thesis</a> from North Carolina State University tries to tackle the question as to why computer science has used conferences as its main and most prestigious publication venues. The author Elijah Bouma-Sims gives a synopsis with some interesting follow up conversation in this <a href="https://twitter.com/ElijahBoumaSims/status/1439041100111548419">Twitter thread</a>.</p><p>The upshot is that the conference culture grew organically early in computing and just took hold as the field grew. My personal non-scientific theory is that technology not available to earlier fields, namely jet airplanes, allowed CS to have national and international meetings that researchers could regularly attend. Before that conferences in more established fields like math were held either locally (<a href="http://www.ams.org/meetings/sectional/sectional.html">AMS sectional meetings</a>) or less often (<a href="https://www.mathunion.org/icm/icm-2022">ICM</a> held every four years), traditions that continue to this day.</p><p>Covid has temporarily suspended fully on-site conferences, and new technologies allow us to have virtual meetings. It's still not clear what will be the new normal for conferences. I hope we get to the model where we have more virtual meetings and rarer in-person meetings that people make more of an effort to attend. Conferences focused on networking instead of publications.</p><p>The culture of conference publications has been slowly changing. Many subfields in CS, though not no much theory, have moved to a hybrid model where papers are submitted to a journal and those accepted are invited to be presented at a conference.</p><p>Conferences used to be the first place you would hear about new results but that's no longer the case. Papers posted on <a href="https://arxiv.org/">arXiv</a> get noticed and Google Scholar doesn't distinguished citations to an arXiv paper differently from any other publication venue. </p><p>Now you don't even need a presentation or a paper, just a promise of one. How many of you are excited about linear-size locally testable codes based on a <a href="https://simons.berkeley.edu/events/breakthroughs-locally-testable-codes-constant-rate-distance-and-locality">talk announcement</a> alone?</p></div>
    </content>
    <updated>2021-09-23T12:54:00Z</updated>
    <published>2021-09-23T12:54:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-09-30T14:30:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8202</id>
    <link href="https://windowsontheory.org/2021/09/23/nominate-papers-to-sigact-research-highlights/" rel="alternate" type="text/html"/>
    <title>Nominate papers to SIGACT Research highlights</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">TL;DR: Know of a great recent paper that should be highlighted to the theory community and beyond? Email a nomination to sigact.highlights.nominations@outlook.com by Friday, Oct 22, 2021. The goal of the SIGACT Research Highlights Committee is to help promotetop computer science theory research via identifying results that are ofhigh quality and broad appeal to the … <a class="more-link" href="https://windowsontheory.org/2021/09/23/nominate-papers-to-sigact-research-highlights/">Continue reading <span class="screen-reader-text">Nominate papers to SIGACT Research highlights</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>TL;DR:</strong> Know of a great recent paper that should be highlighted to the theory community and beyond? Email a nomination to <a href="mailto:sigact.highlights.nominations@outlook.com" rel="noreferrer noopener" target="_blank">sigact.highlights.nominations@outlook.com</a> by <strong>Friday, Oct 22, 2021</strong>.</p>



<p>The goal of the<a href="https://www.sigact.org/articles/news.html"> SIGACT Research Highlights Committee </a>is to help promote<br/>top computer science theory research via identifying results that are of<br/>high quality and broad appeal to the general computer science audience.<br/>These results would then be recommended for consideration for the <a href="http://cacm.acm.org/">CACM</a> <em>Research Highlights</em> section as well as other general-audience computer science research outlets.</p>



<p><strong>Nomination and Selection Process:</strong></p>



<p>The committee solicits two types of nominations:</p>



<p>1) <strong>Conference nominations.</strong> Each year, the committee will ask the PC<br/>chairs of theoretical computer science conferences to send a selection<br/>of up to three top papers from these conferences (selected based on both<br/>their technical merit and breadth of interest to non-theory audience)<br/>and forwarding them to the committee for considerations.</p>



<p>2) <strong>Community nominations. </strong>The committee will accept nominations from the members of the community. Each such nomination should summarize the contribution of the nominated paper and also argue why this paper is<br/>suitable for broader outreach. The nomination should be no more than a<br/>page in length and can be submitted at any time by emailing it to<br/><a href="mailto:sigact.highlights.nominations@outlook.com" rel="noreferrer noopener" target="_blank">sigact.highlights.nominations@outlook.com</a>. Self-nominations are<br/>discouraged.</p>



<p>The nomination deadline is <strong>Friday, Oct 22, 2021 </strong>.</p>



<p><strong>Committee:</strong></p>



<p>The SIGACT Research Highlights Committee currently comprises the<br/>following members:</p>



<p>Irit Dinur, Weizmann Institute of Science<br/>Yuval Ishai, Technion<br/>Jelani Nelson, UC Berkeley (chair)<br/>Ronald de Wolf, CWI Amsterdam</p></div>
    </content>
    <updated>2021-09-23T12:41:35Z</updated>
    <published>2021-09-23T12:41:35Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-09-30T15:38:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/138</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/138" rel="alternate" type="text/html"/>
    <title>TR21-138 |  Iterated Lower Bound Formulas: A Diagonalization-Based Approach to Proof Complexity | 

	Rahul Santhanam, 

	Iddo  Tzameret</title>
    <summary>We propose a diagonalization-based approach to several important questions in proof complexity. We illustrate this approach in the context of the algebraic proof system IPS and in the context of propositional proof systems more generally.

We give an explicit sequence of CNF formulas $\{\phi_n\}$ such that VNP$\neq$VP iff there are no polynomial-size IPS proofs for the formulas $\phi_n$. This provides the first natural equivalence between proof complexity lower bounds and standard algebraic complexity lower bounds. Our proof of this fact uses the implication from IPS lower bounds to algebraic complexity lower bounds due to Grochow and Pitassi together with a diagonalization argument: the formulas $\phi_n$ themselves assert the non-existence of short IPS proofs for formulas encoding VNP$\neq$VP at a different input length. Our result also has meta-mathematical implications: it gives evidence for the difficulty of proving strong lower bounds for IPS within IPS.

More generally, for any strong enough propositional proof system $R$ we propose a new explicit hard candidate, the iterated $R$-lower bound formulas, which inductively asserts the non-existence of short $R$ proofs for formulas encoding this same statement at a different input length. We show that these formulas are unconditionally hard for Resolution following recent results of Atserias and Muller and of Garlik. We further give evidence in favour of this hypothesis for other proof systems.</summary>
    <updated>2021-09-22T23:41:52Z</updated>
    <published>2021-09-22T23:41:52Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-09-30T15:37:34Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2021/09/21/models-are-wrong/</id>
    <link href="http://benjamin-recht.github.io/2021/09/21/models-are-wrong/" rel="alternate" type="text/html"/>
    <title>All statistical models are wrong. Are any useful?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Though I singled out a mask study <a href="https://www.argmin.net/2021/09/13/effect-size/">in the last post</a>, I’ve had a growing discomfort with statistical modeling and significance more generally. Statistical models explicitly describe the probability of outcomes of experiments in terms of specific variables of individuals from a population. Such statistical models bring with them a host of assumptions and powers. But when are they appropriate for deducing significance of the outcomes of experiments? Here, I’ll argue that they are almost never appropriate in most settings, and, moreover, they can result in confidence intervals that rarely contain the correct parameters.</p>

<p>Note that in order to sample from some population, we need not assume that the population is <em>itself</em> random. An experimenter can choose to sample one individual from a larger pool at random even when the pool is a deterministic collection. Similarly, the experimenter can randomly assign each member of the pool to a group for experimentation even when the pool is deterministic. We need not build a statistical model of our population in order to study it experimentally.</p>

<p>But the convention in much scientific practice entangles the randomness used in survey and experiment design with the randomness of the natural world. The dominant convention in experimental sciences is to assert the existence of a probability distribution from which all observations in an experiment are samples. That is, most analyses begin with the assumption that the population is itself a stochastic entity whose statistical properties can be accurately modeled. Such probabilistic modeling is immediately problematic. We are forced to confront the notion of probability itself. What does the probability of an event mean? Is a Bayesian or Frequentist viewpoint more correct? What does it mean to sample a natural process?</p>

<p>My perspective on the pitfalls of probabilistic modeling has been heavily influenced by the writings of David Freedman. Freedman advocates for a pragmatic approach to statistical modeling. “<a href="https://www.stat.berkeley.edu/~stark/Preprints/611.pdf">Probability is just a property of a mathematical model intended to describe some features of the natural world. For the model to be useful, it must be shown to be in good correspondence with the system it describes.</a>” This is the less pithy, but more prescriptive version of Box’s famous and tiresome aphorism “All models are wrong, but some are useful.”</p>

<p>Model building and validation requires deep domain knowledge for a task at hand. One of my favorite models is Ohm’s law, which states that the current that flows across a conductive material is proportional to the voltage drop across the resistor. Due to thermal noise, the actual model is</p>

\[\small{
  \text{current} = \text{material constant} \times \text{voltage} + \text{noise}}\]

<p>And the noise is Gaussian white noise. This model has been extensively tested and is a foundation of all circuit design. Remarkably, this simple formula describes complex electronic behavior. Physics is full of amazing examples of statistical models that accurately predict the outcome of experiments to a dozen significant figures.</p>

<p>But in biology, medicine, social science, and economics, our models are much less accurate and less grounded in natural laws. Most of the time, models are selected because they are convenient, not because they are plausible, well motivated from phenomenological principles, or even empirically validated. Freedman built a cottage industry around pointing out how poorly motivated many of the common statistical models are.</p>

<p>A particular example called out by Freedman is the <a href="https://www.jstor.org/stable/27645896">ubiquitous logistic regression model</a>. Freedman observed that in a variety of randomized control trials, experimenters would “correct” the estimates of their randomized controlled trials by “controlling for fixed effects” with logistic regression. Controlling for fixed effects is pernicious jargon that means “set up a regression problem with all of the variables that one thinks make their effect size look too small, and then solve the regression as an attempt to remove the influence of these variables.” It is most common in observational studies, but many insist it is appropriate in the context of randomized controlled trials as well. This convention of correction persists in the present, and I highlighted similar corrections in my last post. Freedman argues that such corrections are misguided, especially in the context of randomized trials.</p>

<p>To understand the motivation for using logistic in the first place, I need to tell you what an odds ratio is. Experiments are often interested in estimating an odds ratio of particular outcomes. The odds of an outcome is the number of individuals with a positive outcome divided by the number of individuals with a negative outcome. If the odds of winning a lottery are one million to one, that means that for every person that wins, one million people lose.</p>

<p>In the context of randomized experiments, let’s suppose that when given a treatment, M out of N individuals will have a favorable outcome, and without treatment only Q out of N will have a positive outcome Then the odds ratio is simply the ratio of the odds of the outcome with and without treatment</p>

\[\small{
\frac{M}{N-M} \cdot \frac{N-Q}{Q}\,.}\]

<p>When the odds ratio is large, we deem a treatment to be highly effective.</p>

<p>Logistic regression posits that individuals have a vector of features $Z$ that influence the odds of the effectiveness of treatment. Specifically, if $Y$ is the indicator of the desired outcome and $X$ is indicator of treatment, the logistic regression model asserts the log of the odds the outcome is a linear function of the treatment and the selected features. Since the model assumes the population is random, we can write the fraction of individuals with a positive outcome as probability. With this identification, the assumption of logistic regression is</p>

\[\small{
\log  \frac{p(Y=1 | X,Z ) }{ 1-p(Y=1 | X,Z) } = \beta X + \gamma^\top Z + \alpha \,.}\]

<p>This model is convenient if we are interested in odds ratios. In the logistic model, no matter what the covariate $Z$, the odds ratio is</p>

\[\small{
\frac{p(Y=1 | X=1,Z ) } {1-p(Y=1| X=1,Z) }  \cdot \frac{1-p(Y=1 | X=0, Z)}{p(Y=1 | X=0, Z)} = e^\beta\,.}\]

<p>Hence, if we can estimate beta, we can estimate the odds ratio. And if we can estimate the variance of beta, we can compute confidence intervals over our odds ratio estimates.</p>

<p>But all of this assumes that the model is correct! If the logistic model is not correct, then our confidence intervals are meaningless. Or at least, they are not confidence intervals around any true notion of odds ratios.</p>

<p>It’s almost always reasonable to be suspicious of this logistic model. It is first asserting that the odds ratio is a constant for a fixed covariate $Z$. That is, all subjects experience the same proportional effect of treatment. Even less realistically, the model asserts that the outcome is positive for an individual $i$ with treatment value $X_i$ and covariate value $Z_i$ if</p>

\[\small{
  U_i  \leq \alpha + \beta X_i + \gamma^\top Z_i\,,}\]

<p>where $U_i$ is a random variable sampled from the logistic distribution. The model assumes the $U_i$ are independent of the treatment and the covariates, the $U_i$ are independent across all of the individuals, and the $U_i$ have a common logistic distribution. The only thing that differs between treatment and control is the value of the threshold on the left hand side. These are a lot of assumptions, and they are seldom verified or tested in papers where logistic regression is applied.</p>

<p>The question remains: does this matter? Do these modeling assumptions actually affect our inferences about effect size? Freedman provides an elegant argument demonstrating that logistic regression always overestimates the true odds ratio, and sometimes can do so quite poorly. He also shows that simply computing a plugin estimator of the odds ratio with no covariate adjustment at all is consistent in randomized controlled trials. That is, there is no need to adjust for covariates in randomized controlled trials if you want an accurate estimate of the odds ratio. Furthermore, covariate adjustments can lead to significant overestimation of the treatment’s effect size.</p>

<p>Rather than going through Freedman’s theoretical argument, it’s a bit more evocative to give an example. The following is gleaned from a helpful discussion with Joel Middleton. Suppose you sample 10000 children from a larger population where each child in the population has an equal chance of liking and disliking vegetables. We propose a treatment of bribing kids with a cookie to eat their veggies, and randomly assign this treatment to half of the subjects. Left untreated, veggie haters have a 20% probability of finishing their veggies, but veggie lovers have an 80% probability of eating their greens. When bribed with a cookie, veggie haters and veggie lovers have 25% and 85% of eating their vegetables, respectively.</p>

<p>An average child in the study has a probability of 50% of eating their veggies if in control and 55% if in treatment. The log odds ratio is thus</p>

\[\small{
  \log \frac{.55}{1−.55}−\log\frac{.5}{1−.5} \approx 0.2\,.}\]

<p>Now, when you instead run logistic regression, the coefficient of the treatment variable is larger than 0.2. Indeed, <a href="https://nbviewer.jupyter.org/url/argmin.net/code/logistic_logodds_example.ipynb">when I try this in python</a>, running 1000 synthetic experiments, I find that the median point estimate is 0.32, which is, as promised, larger than the true log odds. Even more worrisome is the 95% confidence interval contains 0.2 only 38% of the time. Clearly, the confidence intervals are not accurate when the model is wrong.</p>

<p>When the true effect size is large, this discrepancy between the logistic regression estimate and the true log odds might not be that big a deal: your error bars are wrong, but the effect size is estimated in the correct direction. But the results of such logistic regression analyzes are regularly quoted as estimates of odds ratios (For example, look at any  observational study of vaccine effectiveness). The precision of these estimates is unfortunately lacking and misleading.</p>

<p>Even if the model <em>was</em> true, the same argument shows that the coefficient of the treatment variable overestimates the log-odds. This is demonstrated in the <a href="https://nbviewer.jupyter.org/url/argmin.net/code/logistic_logodds_example.ipynb">second example in the python notebook</a>. Even when the model is true, the coefficient of the treatment variable is an overestimate of the true log odds. If the model was true, one could at least say they had constructed a reasonable estimate of the change in odds for an individual under treatment. But if the model is wrong, there’s nothing we can say at all other than we have overestimated the effect size and our error bars might not contain the true odds with any certainty.</p>

<p>So what is the remedy here? The thing is, we already know the answer: if we randomized the assignment, we can estimate log odds by counting the number of positive outcomes under treatment and control, and then just plugging these values into the odds ratio. If you do this, you find an estimate whose median is precisely equal to the true log odds. No covariate adjustment is required.</p>

<p>This is merely one example showing why it is critical to decouple the randomness used to probe a system from the randomness inherent in its system itself. Statistical models are not necessary for statistical inference, but randomness itself is amazingly… let’s say… <em>useful</em> for understanding natural phenomena. I will spend the next few blogs reminding myself and you faithful blog readers that proper experiments, machine learning predictions, and statistical summarizations can all be designed without statistical models of populations. Perhaps the mathematical formalizations of randomized algorithms can suggest paths to reform conventional experimental formalism.</p></div>
    </summary>
    <updated>2021-09-21T00:00:00Z</updated>
    <published>2021-09-21T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2021-09-29T22:42:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2021-09-20-optimal-communication-complexity-of-authenticated-byzantine-agreement/</id>
    <link href="https://decentralizedthoughts.github.io/2021-09-20-optimal-communication-complexity-of-authenticated-byzantine-agreement/" rel="alternate" type="text/html"/>
    <title>Optimal Communication Complexity of Authenticated Byzantine Agreement</title>
    <summary>Communication complexity of Byzantine Agreement (BA) has been studied for decades. Dolev and Reischuk showed that quadratic communication is necessary for BA with perfect security, i.e., without error. Berman, Garay, and Perry showed that this lower bound is tight for the unauthenticated setting (without signatures) with $f &lt; n/3$. However,...</summary>
    <updated>2021-09-20T19:28:00Z</updated>
    <published>2021-09-20T19:28:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2021-09-30T15:21:57Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2021-09-20-information-theoretic-hotstuff-it-hs-part-one/</id>
    <link href="https://decentralizedthoughts.github.io/2021-09-20-information-theoretic-hotstuff-it-hs-part-one/" rel="alternate" type="text/html"/>
    <title>Information Theoretic HotStuff (IT-HS): Part One</title>
    <summary>This post is the first of two on Information Theoretic HotStuff (IT-HS). Information Theoretic HotStuff is a Byzantine Consensus protocol in the partially synchronous model. It replaces all of HotStuff’s cryptographic signatures with simple information theoretic message passing techniques over authenticated channels. Information theoretic protocols are often easy to reason...</summary>
    <updated>2021-09-20T12:07:00Z</updated>
    <published>2021-09-20T12:07:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2021-09-30T15:21:56Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8953224762580714055</id>
    <link href="http://blog.computationalcomplexity.org/feeds/8953224762580714055/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/09/the-new-jeopardy-champion-is-a-cs-grad.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8953224762580714055" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8953224762580714055" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2021/09/the-new-jeopardy-champion-is-a-cs-grad.html" rel="alternate" type="text/html"/>
    <title>The New Jeopardy Champion is a `A CS grad student from a school in New Haven'</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> As of Sept 17, Matt Amodio has won 23 straight games in a row on Jeopardy and won over $800,000 in regular play. The following website is not quite up to date, but its close: <a href="https://www.jeopardy.com/contestant-zone/hall-of-fame">here</a>. Of course, that website will change. </p><p>1) They refer to him as <i>A CS grad student from a school in New Haven</i>. My first thought was <i>probably</i> <i>Yale, but whatever it is, they should just say it. </i>I looked it up and it is Yale. So why aren't they just saying <i>A CS grad student from Yale?  </i>If someone works for <i>an airline company</i> they do not tell you which airline- prob to avoid giving that airline free publicity. But I would think a school is different. And I remember (perhaps incorrectly) that they DO say what school someone teaches at or is a student at. </p><p>(ADDED LATER: a colleague of mine who was on Jeop (he lost his only game) tells me that YES, you re NOT ALLOWED to say the company you work for. He was from <i>Riverdale Park, MD </i>which might make some people think there is a <i>Univ of MD at Riverdale Park</i> . He also told me that when he was on the show the following happened:  <i>On One of the shows of the game before I  played, Alex was curious which LA area restaurant somebody worked at (to see if he had eaten there--- he hadn't), and sure enough, they edited the name of the restaurant out.)</i></p><p>2) Longest streak: Ken Jennings: 74. Also most money in reg play: roughly 2.5 Mill</p><p>    2nd longest: James Holzhauer: 32. Also  2nd most money in reg play: roughly 2.4 Mill</p><p>    3rd longest: Matt Amodio: 23. Also  3rd most money in reg play: roughly 0.8 Mill</p><p>3) I do not think Matt will move into second place on any of these categories. He bets big on the daily doubles and it has paid off but either (a) he will miss and it will lead to a loss, or (b) he will just not get the daily double and be against a very good opponent. Item (b) happened to James H- and the person who beat him did have a good enough win streak to be in the Tournament of Champions. I wonder if they try to stop a long streak by picking really good opponents. I also wonder if they can even tell who will be a really good opponent. </p><p>4) Matt has played in front of (or will- counting tomorrow) six hosts: Robin Roberts, LeVar Burton, David Faber, Joe Buck, Mike Richards, and Mayim Bialik. Six is a record which I suspect won't be broken, except possibly by Matt himself if he also plays in front of Ken Jennings (the rest of 2021 will be Mayim B and Ken J as hosts, see <a href="https://www.npr.org/2021/09/16/1037930905/mayim-bialik-ken-jennings-host-jeopardy">here</a>.</p><p>5) Matt works in AI. When he gets his PhD and is on the job market will his Jeopardy success help him, hurt him, or neither?  </p><p>6) James H and Matt A are both very good at calculating how much to bet. I think Ken J is not quite as good but still good. Generally the players on Jeop are not that good at that aspect. I had the chance to ask some a champions (not any of those three) why that was and she said that most people get into because of the trivia-aspect, not the betting aspect. I wonder if just as players now study lots of facts to prep, they will also learn how to bet better. </p><p>7) Ken J as host is a bit odd in that, if he says (as Alex T did sometimes) <i>That category looks hard </i>I won't believe him. I also have this suspicion that when a contestant gets something wrong Ken might be thinking <i>what a moron; </i>however, (a) by all accounts Ken is a nice guy, and (b)  I might be projecting. </p></div>
    </content>
    <updated>2021-09-20T00:35:00Z</updated>
    <published>2021-09-20T00:35:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-09-30T14:30:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/09/19/faculty-at-ben-gurion-university-apply-by-february-1-2022/</id>
    <link href="https://cstheory-jobs.org/2021/09/19/faculty-at-ben-gurion-university-apply-by-february-1-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at Ben-Gurion University (apply by February 1, 2022)</title>
    <summary>I (Dean Doron) invite applicants for a postdoctoral position at Ben-Gurion University’s Computer Science department. Candidates with a strong background in TCS whose research interests include pseudorandomness, complexity, coding theory, or related combinatorial constructions, are welcome to apply. Start date is flexible. To apply, please email me your CV and 2-3 representative papers. Website: https://www.cs.bgu.ac.il/~deand […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I (Dean Doron) invite applicants for a postdoctoral position at Ben-Gurion University’s Computer Science department.<br/>
Candidates with a strong background in TCS whose research interests include pseudorandomness, complexity, coding theory, or related combinatorial constructions, are welcome to apply.<br/>
Start date is flexible. To apply, please email me your CV and 2-3 representative papers.</p>
<p>Website: <a href="https://www.cs.bgu.ac.il/~deand">https://www.cs.bgu.ac.il/~deand</a><br/>
Email: deand@bgu.ac.il</p></div>
    </content>
    <updated>2021-09-19T09:53:31Z</updated>
    <published>2021-09-19T09:53:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-09-30T15:37:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19128</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/09/17/happy-unbirthday-ken/" rel="alternate" type="text/html"/>
    <title>Happy UnBirthday Ken</title>
    <summary>Mad Hatter: Now, statistics prove, prove that you’ve one birthday. March Hare: Imagine, just one birthday every year. Mad Hatter: Ah, but there are three hundred and sixty four unbirthdays! March Hare: Precisely why we’re gathered here to cheer. Ken Regan just had his birthday the other day. Today is another unbirthday. Please join me […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>Mad Hatter: Now, statistics prove, prove that you’ve one birthday.<br/>
March Hare: Imagine, just one birthday every year.<br/>
Mad Hatter: Ah, but there are three hundred and sixty four unbirthdays!<br/>
March Hare: Precisely why we’re gathered here to cheer.</em></p>
<p>
Ken Regan just had his birthday the other day. Today is another <a href="https://en.wikipedia.org/wiki/Unbirthday">unbirthday</a>. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/09/17/happy-unbirthday-ken/kr/" rel="attachment wp-att-19131"><img alt="" class="aligncenter size-medium wp-image-19131" height="300" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/kr.jpg?resize=205%2C300&amp;ssl=1" width="205"/></a></p>
<p>
Please join me in wishing Ken many more happy birthdays as well as many many more unbirthdays.</p>
<p>
 <span id="more-19128"/></p>
<p><b> Ken is a Mathematician </b></p>
<p/><p>
Ken is of course a co-author of this blog. We try to cover computer science and mathematics, but we are open to other areas. Ken started his career in Mathematics; he obtained a PhD in math from Oxford University in 1986. It was under Dominic Welsh and was tilted: <i>On the separation of complexity classes</i>. Welsh’s family tree is <a href="https://users.monash.edu.au/~davidwo/files/Welsh-FamilyTree.pdf">here</a>. </p>
<p>
</p><p><b> Ken is a Programmer </b></p>
<p/><p>
Ken is of course famous for being one of the world’s top chess cheating detectors. Recall to cheat at chess is to use a computer program to make your moves in a game against a human opponent. This is strictly illegal. </p>
<p>
Ken was featured on the cover in <a href="https://cse.buffalo.edu/~regan/personal/JuneCLarticleKWR.pdf">chess review</a>. His work gets critic review <a href="https://kar.kent.ac.uk/44719/">here</a> by David Barnes and Julio Hernandez-Castro in the 2015 article <i>On the limits of engine analysis for cheating detection in chess</i> in the journal Computers and Security.</p>
<p>
</p><p><b> Ken is Unique </b></p>
<p/><p>
Ken is special in many ways. He is smart, he is a wonderful partner, and he is a great friend. I would claim that he is one of the few people that have the following three properties:</p>
<ol>
<li> He is an international master in chess of rating <img alt="{2372}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2372%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>;
</li><li> He is a strong researcher in complexity theory;
</li><li> He is a terrific programmer.
</li></ol>
<p>
The last I would claim is pretty remarkable. There are many strong chess players, there are many of us working in complexity theory. But few have written as much production quality code as Ken has. For his work on chess cheating he has had to write thousands of lines of code. This code must run fast, and be correct. The latter, correctness, is really important. This since his work on detecting cheating has led players to be suspended from chess for years. It also has helped protect players who did not cheat, even though many thought they had. </p>
<p>
</p><p><b> Open Problems </b></p>
<p/><p>
Again I wish him a wonderful unbirthday day.</p>
<p/></div>
    </content>
    <updated>2021-09-17T13:45:15Z</updated>
    <published>2021-09-17T13:45:15Z</published>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-09-30T15:37:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-5589824032420181390</id>
    <link href="http://processalgebra.blogspot.com/feeds/5589824032420181390/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=5589824032420181390" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/5589824032420181390" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/5589824032420181390" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2021/09/phd-scholarship-in-data-science-for.html" rel="alternate" type="text/html"/>
    <title>PhD scholarship in Data Science for sustainability at Reykjavik University</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p style="text-align: center;"><b>Department of Computer Science, Reykjavik University </b></p><p style="text-align: center;"><b>PhD scholarship in Data Science for sustainability by predicting food consumption to reduce food waste </b></p><p>The Department of Computer Science at Reykjavík University is looking for a PhD student to build, apply and evaluate a global model that predicts future food consumption by geographic area. The goal of the project is twofold:      Reduce food waste in restaurants and grocery stores by using global machine learning algorithms.     Understand food consumption trends in restaurants and grocery stores by analyzing the global model’s input data and their results.  The ideal candidate should possess data science expertise, be passionate about sustainability and enthusiastic about research.  The project is a collaboration with <a href="https://greenbytes.is" target="_blank">GreenBytes</a> and will be carried out in Reykjavik, Iceland. </p><p>See <a href="https://jobs.50skills.com/ru/en/10068">https://jobs.50skills.com/ru/en/10068</a> for full details and for information on how to apply.</p></div>
    </content>
    <updated>2021-09-16T12:23:00Z</updated>
    <published>2021-09-16T12:23:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2021-09-29T20:29:01Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/09/16/faculty-equivalent-of-tenure-track-at-university-of-sydney-apply-by-november-30-2021/</id>
    <link href="https://cstheory-jobs.org/2021/09/16/faculty-equivalent-of-tenure-track-at-university-of-sydney-apply-by-november-30-2021/" rel="alternate" type="text/html"/>
    <title>Faculty (equivalent of tenure-track) at University of Sydney (apply by November 30, 2021)</title>
    <summary>The School of Computer Science at the University of Sydney (Australia) is seeking applications for several academic positions at all levels. Successful applicants will have an excellent research record and be able to teach in a range of courses. Website: https://usyd.wd3.myworkdayjobs.com/en-US/USYD_EXTERNAL_CAREER_SITE/job/Camperdown-Campus/Multiple-Continuing-Academic-Positions–School-of-Computer-Science_0085639 Email: hr.recruitmentcampaign@sydney.edu.au</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The School of Computer Science at the University of Sydney (Australia) is seeking applications for several academic positions at all levels. Successful applicants will have an excellent research record and be able to teach in a range of courses.</p>
<p>Website: <a href="https://usyd.wd3.myworkdayjobs.com/en-US/USYD_EXTERNAL_CAREER_SITE/job/Camperdown-Campus/Multiple-Continuing-Academic-Positions--School-of-Computer-Science_0085639">https://usyd.wd3.myworkdayjobs.com/en-US/USYD_EXTERNAL_CAREER_SITE/job/Camperdown-Campus/Multiple-Continuing-Academic-Positions–School-of-Computer-Science_0085639</a><br/>
Email: hr.recruitmentcampaign@sydney.edu.au</p></div>
    </content>
    <updated>2021-09-16T04:01:14Z</updated>
    <published>2021-09-16T04:01:14Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-09-30T15:37:47Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5843</id>
    <link href="https://www.scottaaronson.com/blog/?p=5843" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5843#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5843" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">My ACM TechTalk on quantum supremadvantage</title>
    <summary xml:lang="en-US">This Erev Yom Kippur, I wish to repent for not putting enough quantum computing content on this blog. Of course, repentance is meaningless unless accompanied by genuine reform. That being the case, please enjoy the YouTube video of my ACM TechTalk from last week about quantum supremacy—although, as you’ll see if you watch the thing, […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>This Erev Yom Kippur, I wish to repent for not putting enough quantum computing content on this blog.  Of course, repentance is meaningless unless accompanied by genuine reform.  That being the case, please enjoy the <a href="https://www.youtube.com/watch?v=QnLmGfNKCLU">YouTube video of my ACM TechTalk from last week about quantum supremacy</a>—although, as you’ll see if you watch the thing, I oscillate between quantum supremacy and other terms like “quantum advantage” and even “quantum supremadvantage.”  This represents the first time ever that I got pushback about a talk before I’d delivered it for political reasons—the social-justice people, it turns out, are <em>actually serious</em> about wanting to <a href="https://www.scottaaronson.com/blog/?p=4450">ban the term “quantum supremacy”</a>—but my desire to point out all the difficulties with their proposal competed with my desire not to let that issue overshadow my talk.</p>



<p>And there’s plenty to talk about!  While regular <em>Shtetl-Optimized</em> readers will have already heard (or read) most of what I say, I make some new comments, including about the <a href="https://arxiv.org/abs/2109.03494">new paper from last week</a>, the night before my talk (!), by the USTC group in China, where they report a quantum supremacy experiment based on random circuit sampling with a superconducting chip, this time with a record-setting 60 qubits and 24 layers of gates.  On the other hand, I also stress how increasing the circuit fidelity has become a <em>much</em> more urgent issue than further increasing the number of qubits (or in the case of BosonSampling, the number of photons), if our goal is for these experiments to remain a couple steps ahead of classical spoofing algorithms.</p>



<p>Anyway, I hope you enjoy my lovingly handcrafted visuals.  Over the course of this pandemic, I’ve become a full convert to writing out my talks with a stylus pen rather than PowerPointing them—not only is it faster for me, not only does it allow for continuous scrolling rather than arbitrary divisions into slides, but it enforces simplicity and concision in ways they <em>should</em> be enforced.</p>



<p>While there was only time for me to field a few questions at the end of the talk, I later supplied <a href="https://on.acm.org/t/quantum-computational-supremacy/2106/2?u=acm-learning">written answers to 52 questions (!!) that I hadn’t gotten to</a>.  If <em>you</em> have a question, please check to see if it’s already there, and otherwise ask away in the comments!</p>



<p>Thanks so much to Yan Timanovsky for inviting and organizing this talk, and to whurley for hosting it.</p></div>
    </content>
    <updated>2021-09-15T23:12:40Z</updated>
    <published>2021-09-15T23:12:40Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="http://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-09-26T16:48:06Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/09/15/linkage</id>
    <link href="https://11011110.github.io/blog/2021/09/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Does anyone but me find it odd that car tire sizes are measured in millimeters for width, inches for inner radius, and a dimensionless number expressed as a percentage for (difference between inner and outer radius)/width (\(\mathbb{M}\))? Imagine the fun if we tried to do solid geometry this way.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p>Does anyone but me find it odd that <a href="https://en.wikipedia.org/wiki/Tire_code">car tire sizes</a> are measured in millimeters for width, inches for inner radius, and a dimensionless number expressed as a percentage for (difference between inner and outer radius)/width <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/106864082094813780">\(\mathbb{M}\)</a>)?</span> Imagine the fun if we tried to do solid geometry this way.</p>
  </li>
  <li>
    <p><a href="https://aas.org/press/aas-journals-open-access">American Astronomical Society switches to open source for all its journals</a> (<a href="https://mathstodon.xyz/@11011110/106871073920675993">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=28379917">via</a>). The fine print is a <a href="https://journals.aas.org/oa/#charge_comparison">hefty &gt;$1000-paper publication charge</a>
with only a vague hope of waivers for some journals and not even that for one of them. Publication is not without cost, but comparing this with the <a href="https://www.dagstuhl.de/en/publications/lipics/processing-charge/">actual-cost 
€60/paper charges of LIPIcs</a> suggests that there’s a lot of profit/overhead built into the AAS fees.</p>
  </li>
  <li>
    <p>You may have heard that <a href="https://www.math3ma.com/blog/fibonacci-sequence">Fibonacci numbers form a meet-semilattice under divisibility, and that the map from \(n\) to \(F_n\) is a meet-semilattice homomorphism</a> (<a href="https://mathstodon.xyz/@11011110/106880573772645015">\(\mathbb{M}\)</a>). But did you know they’re actually a lattice, almost the same as the positive integer divisibility lattice (an infinite-dimensional grid with a dimension per prime), but missing one element at the index \(2\) (because \(F_2=F_1=1\))? Unfortunately, because of the missing grid element, \(F\) is not a lattice homomorphism.</p>

    <p style="text-align: center;"><img alt="Divisibility lattice of Fibonacci numbers" src="https://11011110.github.io/blog/assets/2021/Fibonacci-divisibility.svg"/></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2109.00022">Point sets with no four collinear and no large visible island</a> (<a href="https://mathstodon.xyz/@11011110/106883568827068806">\(\mathbb{M}\)</a>). If you project a 
\(3\times 3\times \cdots\times 3\) grid linearly into the plane, for a generic projection, then there are no four points in a row. But if you choose the projection carefully, you can get another property: every convex subset of the plane that hits more than a constant number of points includes at least one three-point line. New preprint by UCSD undergrad Sophie Leuchtner and Andrew Suk.</p>
  </li>
  <li>
    <p><a href="https://britishorigami.info/lister/egypt.php">Possibly the earliest known example of folding</a> (<a href="https://mathstodon.xyz/@11011110/106889063469591427">\(\mathbb{M}\)</a>): an Egyptian map from over 3000 years ago. The link unfortunately lacks pictures but they can be found on <a href="https://en.wikipedia.org/wiki/Turin_Papyrus_Map">the Wikipedia article on the same map</a>, which however suggests an alternative hypothesis than folding for its markings.</p>
  </li>
  <li>
    <p><a href="https://retractionwatch.com/2021/09/07/authors-object-after-springer-nature-journal-cedes-to-publisher-frontiers-demand-for-retraction/">Springer journal <em>Scientometrics</em> retracts a journal paper on predatory publishing after predatory publisher Frontiers objects to its use of a list of predatory publishers that lists Frontiers as a predatory publisher</a> (<a href="https://mathstodon.xyz/@11011110/106891442309422502">\(\mathbb{M}\)</a>). A followup comment connects the dots: “Notably, Springer owns a stake in Frontiers, although they rarely mention this publicly”. Editors of the Springer journal call the retraction misconduct and consider resigning from its board in protest.</p>
  </li>
  <li>
    <p><a href="https://www.getrevue.co/profile/shift-happens/issues/moire-no-more-688319">Removing halftoning artifacts from images by FFT+masking</a> (<a href="https://mathstodon.xyz/@11011110/106900166239796915">\(\mathbb{M}\)</a>, <a href="https://www.metafilter.com/192541/pure-old-fashioned-math-and-science">via</a>). A nice illustration of how the right piece of mathematics can seem like “some sort of witchcraft that should not be possible”. The original uses a piece of software I haven’t used called <a href="https://imagej.net/software/fiji/">Fiji</a>, but there’s also <a href="http://ft.rognemedia.no/">the “Pattern Suppressor” Photoshop plugin for similar manipulations</a>.</p>
  </li>
  <li>
    <p><a href="https://www.wired.com/story/one-womans-mission-to-rewrite-nazi-history-wikipedia/">Ksenia Coffman’s work stomping out Nazi-glorification on Wikipedia</a> (<a href="https://mathstodon.xyz/@11011110/106905799003035925">\(\mathbb{M}\)</a>, <a href="https://www.metafilter.com/192594/One-Womans-Mission-to-Rewrite-Nazi-History-on-Wikipedia">see also</a>).</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/new-math-book-rescues-landmark-topology-proof-20210909/">Quanta has a new article</a> (<a href="https://mathstodon.xyz/@11011110/106911678317985799">\(\mathbb{M}\)</a>, <a href="https://mathoverflow.net/questions/87674/independent-evidence-for-the-classification-of-topological-4-manifolds">see also</a>) on the book <em>The Disc Embedding Theorem</em> by Behrens, Kalmar, Kim, Powell, and Ray, attempting to clarify Freedman’s early-1980s 4-manifold classification, which many found insufficiently rigorous. But it’s not the only book on this; there’s also Calegari’s <a href="https://math.uchicago.edu/~dannyc/books/4dpoincare/4dpoincare.html"><em>The 4-Dimensional Poincaré Conjecture</em></a>, and Freedman’s <em>Topology of 4-manifolds</em> (with Frank Quinn, 1990). Third time’s the charm?</p>
  </li>
  <li>
    <p><a href="https://thereader.mitpress.mit.edu/perils-of-publication-and-citation-bias/">Citation bias</a> (<a href="https://mathstodon.xyz/@11011110/106917424161901510">\(\mathbb{M}\)</a>): how the tendency to cite certain types of results over others (e.g. positive more than negative) and academic games of telephone can herd the research community towards a distorted view of what the scientific record has actually established.</p>
  </li>
  <li>
    <p>The annual Graph Drawing symposium really loves hybrid formats (<a href="https://mathstodon.xyz/@11011110/106921800901735764">\(\mathbb{M}\)</a>). <a href="https://algo.inf.uni-tuebingen.de/gd2021/">This year’s symposium</a> will be held  this Wednesday through Friday as a hybrid of a small in-person meeting in Tübingen and online for those like me still not traveling. And, as in past years, the proceedings is a hybrid of a Springer LNCS volume (not yet out) and <a href="https://arxiv.org/abs/2109.04863">an arXiv copy, newly up at arXiv:2109.04863</a>. If anything the arXiv version is better: more timely, with appendices and color both allowed.</p>
  </li>
  <li>
    <p><a href="https://www.bridgetownrb.com/future/rip-jekyll/">Death of the Jekyll static site generator proclaimed</a> (<a href="https://mathstodon.xyz/@11011110/106928704495143550">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=28514029">via</a>), because of some open source politics I don’t understand. Meanwhile for those of us using it as a static site generator and github-pages blog springboard, Jekyll still largely just works as it always has without much need for development. Indeed, a big reason for the lack of momentum for going from Jekyll 3 to 4 is that it was an unnecessary incompatible update that would have broken too much stuff.</p>
  </li>
  <li>
    <p><a href="https://www.thomasclausen.net/en/but-this-is-a-weird-bibliography/">Why would someone plagiarize the bibliography of their journal paper</a> (<a href="https://mathstodon.xyz/@11011110/106934028229929325">\(\mathbb{M}\)</a>), by copying someone else’s bibliography on a totally unrelated topic, in an inconsistent format to the references in the main text of the paper (no doubt copied from somewhere else)? Thomas Clausen looks more deeply than necessary at the garbage pile that is predatory publishing, triggered by an odd citation alert.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Existential_theory_of_the_reals">\(\exists\mathbb{R}\), the problem of testing the existence of solutions to polynomial real equations</a> is only a little harder than \(\mathsf{NP}\), but \(\exists\mathbb{Z}\) is undecidable (Matiyasevich). Today I learned from <a href="https://arxiv.org/abs/2107.11663">Marcus Schaefer’s GD talk</a> that <a href="https://en.wikipedia.org/wiki/RAC_drawing">right-angle-crossing graph drawing</a> is \(\exists\mathbb{R}\)-complete but that requiring in addition that the vertices have integer coordinates makes it \(\exists\mathbb{Q}\)-complete (<a href="https://mathstodon.xyz/@11011110/106936348796765483">\(\mathbb{M}\)</a>). That means we don’t know whether it’s decidable!</p>
  </li>
</ul></div>
    </content>
    <updated>2021-09-15T14:57:00Z</updated>
    <published>2021-09-15T14:57:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-09-26T00:06:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5837</id>
    <link href="https://www.scottaaronson.com/blog/?p=5837" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5837#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5837" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Open Problems Related to Quantum Query Complexity</title>
    <summary xml:lang="en-US">Way back in 2005, I posed Ten Semi-Grand Challenges for Quantum Computing Theory, on at least half of which I’d say there’s been dramatic progress in the 16 years since (most of the challenges were open-ended, so that it’s unclear when to count them as “solved”). I posed more open quantum complexity problems in 2010, […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Way back in 2005, I posed <a href="https://www.scottaaronson.com/writings/qchallenge.html">Ten Semi-Grand Challenges for Quantum Computing Theory</a>, on at least half of which I’d say there’s been dramatic progress in the 16 years since (most of the challenges were open-ended, so that it’s unclear when to count them as “solved”).  I posed <a href="https://www.scottaaronson.com/blog/?p=471">more open quantum complexity problems</a> in 2010, and some <a href="https://www.scottaaronson.com/blog/?p=663">classical complexity problems</a> in 2011.  In the latter cases, I’d say there’s been dramatic progress on about a third of the problems.  I won’t go through the problems one by one, but feel free to ask in the comments about any that interest you.</p>



<p>Shall I push my luck as a problem-poser?  Shall or shall not, I have.</p>



<p>My impetus, this time around, was a kind invitation by Travis Humble, the editor-in-chief of the new <em><a href="https://dl.acm.org/journal/tqc">ACM Transactions on Quantum Computing</a></em>, to contribute a perspective piece to that journal on the occasion of my <a href="https://www.scottaaronson.com/blog/?p=5448">ACM Prize</a>.  I agreed—but only on the condition that, rather than ponderously pontificate about the direction of the field, I could simply discuss a bunch of open problems that I wanted to see solved.  The result is below.  It’s coming soon to an arXiv near you, but <em>Shtetl-Optimized</em> readers get it first.</p>



<blockquote class="wp-block-quote"><p><strong><a href="https://www.scottaaronson.com/papers/open.pdf">Open Problems Related to Quantum Query Complexity</a></strong>  (11 pages, PDF)</p><p>by Scott Aaronson</p><p><em>Abstract:</em> I offer a case that quantum query complexity still has loads of enticing and fundamental open problems—from relativized QMA versus QCMA and BQP versus IP, to time/space tradeoffs for collision and element distinctness, to polynomial degree versus quantum query complexity for partial functions, to the Unitary Synthesis Problem and more.</p></blockquote>



<p>Some of the problems on my new hit-list are ones that I and others have flogged for years or even decades, but others, as far as I know, appear here for the first time.  If your favorite quantum query complexity open problem, or a problem I’ve discussed in the past, is missing, that doesn’t mean that it’s been solved or is no longer interesting—it might mean I simply ran out of time or energy before I got to it.</p>



<p>Enjoy!  And tell me what I missed or got wrong or has a trivial solution that I overlooked.</p></div>
    </content>
    <updated>2021-09-15T04:09:31Z</updated>
    <published>2021-09-15T04:09:31Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="http://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-09-26T16:48:06Z</updated>
    </source>
  </entry>
</feed>
