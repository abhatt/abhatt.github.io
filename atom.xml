<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2022-02-15T08:39:06Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/016</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/016" rel="alternate" type="text/html"/>
    <title>TR22-016 |  Super-cubic lower bound for generalized Karchmer-Wigderson games | 

	Alexander Smal, 

	Artur Ignatiev, 

	Ivan Mihajlin</title>
    <summary>In this paper, we prove a super-cubic lower bound on the size of a communication protocol for generalized Karchmer-Wigderson game for some explicit function $f: \{0,1\}^n\to \{0,1\}^{\log n}$. Lower bounds for original Karchmer-Wigderson games correspond to De Morgan formula lower bounds, thus the best known size lower bound is cubic. The generalized Karchmer-Wigderson games are very similar to the original ones, so we hope that our approach can provide an insight for proving better lower bounds on the original Karchmer-Wigderson games, and hence for proving new lower bounds on De Morgan formula size.

To achieve super-cubic lower bound we adapt several techniques used in formula complexity to communication protocols, prove communication complexity lower bound for a composition of several functions with a multiplexer relation, and use a technique from [TR20-117] to extract the "hardest" function from it. As a result, in this setting we are able to show that there is a relatively small set of functions such that at least one of them does not have a small protocol. The resulting lower bound of $\Omega(n^{3.156})$ is significantly better than the bound obtained from the counting argument.</summary>
    <updated>2022-02-15T02:50:42Z</updated>
    <published>2022-02-15T02:50:42Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-15T08:37:20Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8907273297572905957</id>
    <link href="http://blog.computationalcomplexity.org/feeds/8907273297572905957/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/belated-happy-80th-allan-borodin.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8907273297572905957" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8907273297572905957" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/belated-happy-80th-allan-borodin.html" rel="alternate" type="text/html"/>
    <title>Belated happy 80th, Allan Borodin!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i/></p><div class="separator" style="clear: both; text-align: center;"><div class="separator" style="clear: both; text-align: center;"><a href="https://www.fields.utoronto.ca/programs/scientific/00-01/borodin/image.jpg" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img border="0" height="320" src="https://www.fields.utoronto.ca/programs/scientific/00-01/borodin/image.jpg" width="213"/></a></div><i style="text-align: left;">Guest Post by Aravind Srinivasan</i><span style="text-align: left;"> </span></div><p/><p><a href="https://en.wikipedia.org/wiki/Allan_Borodin">Allan Borodin</a> turned 80 in 2021. This post is to belatedly wish him a very happy 80th, and to give a short personal perspective. </p><p>Three things come to mind when I think of Allan:</p><p/><ol style="text-align: left;"><li>His range of research topics: I was first exposed to his work (Borodin's Gap Theorem) in a complexity-theory class by Hartmanis in Spring 1990, and have since enjoyed reading---at varying levels of depth---his works on algebraic complexity, space complexity and tradeoffs, circuit complexity, lower bounds in general, routing, adversarial queuing, online algorithms, priority algorithms, and E-commerce (I am surely leaving out some areas). This is an amazingly broad sweep!</li><li>His enthusiasm in learning about and developing new models, as our field has evolved greatly over time.</li><li>The enthusiastic embrace he has given to researchers spanning generations. Indeed, I am one of many who have been inspired by various facets of his research and personality.</li></ol><p/><p>Photos from Allan’s 60th can be seen at <a href="http://www.cs.toronto.edu/~bor/birthday/index.htm">Amos Fiat’s page</a>.</p><p>Thank you for everything Allan, and wishing you continued robust health and enjoyment of your academic work! </p></div>
    </content>
    <updated>2022-02-14T13:32:00Z</updated>
    <published>2022-02-14T13:32:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-14T13:32:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.05776</id>
    <link href="http://arxiv.org/abs/2202.05776" rel="alternate" type="text/html"/>
    <title>Privately Estimating Graph Parameters in Sublinear time</title>
    <feedworld_mtime>1644796800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blocki:Jeremiah.html">Jeremiah Blocki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grigorescu:Elena.html">Elena Grigorescu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mukherjee:Tamalika.html">Tamalika Mukherjee</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.05776">PDF</a><br/><b>Abstract: </b>We initiate a systematic study of algorithms that are both differentially
private and run in sublinear time for several problems in which the goal is to
estimate natural graph parameters. Our main result is a differentially-private
$(1+\rho)$-approximation algorithm for the problem of computing the average
degree of a graph, for every $\rho&gt;0$. The running time of the algorithm is
roughly the same as its non-private version proposed by Goldreich and Ron
(Sublinear Algorithms, 2005). We also obtain the first differentially-private
sublinear-time approximation algorithms for the maximum matching size and the
minimum vertex cover size of a graph.
</p>
<p>An overarching technique we employ is the notion of coupled global
sensitivity of randomized algorithms. Related variants of this notion of
sensitivity have been used in the literature in ad-hoc ways. Here we formalize
the notion and develop it as a unifying framework for privacy analysis of
randomized approximation algorithms.
</p></div>
    </summary>
    <updated>2022-02-14T22:46:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.05710</id>
    <link href="http://arxiv.org/abs/2202.05710" rel="alternate" type="text/html"/>
    <title>Collaborative Dispersion by Silent Robots</title>
    <feedworld_mtime>1644796800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gorain:Barun.html">Barun Gorain</a>, Partha Sarathi Mandal, Kaushik Mondal, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pandit:Supantha.html">Supantha Pandit</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.05710">PDF</a><br/><b>Abstract: </b>In the dispersion problem, a set of $k$ co-located mobile robots must
relocate themselves in distinct nodes of an unknown network. The network is
modeled as an anonymous graph $G=(V,E)$, where the nodes of the graph are not
labeled. The edges incident to a node $v$ with degree $d$ are labeled with port
numbers in the range $0,1, \cdots, d-1$ at $v$. The robots have unique ids in
the range $[0,L]$, where $L \ge k$, and are initially placed at a source node
$s$. Each robot knows only its own id but does not know the ids of the other
robots or the values of $L,k$. The task of dispersion was traditionally
achieved with the assumption of two types of communication abilities: (a) when
some robots are at the same node, they can communicate by exchanging messages
between them (b) any two robots in the network can exchange messages between
them.
</p>
<p>In this paper, we ask whether this ability of communication among co-located
robots is necessary to achieve dispersion. We show that even if the ability of
communication is not available, the task of dispersion by a set of mobile
robots can be achieved in a much weaker model where a robot at a node $v$ has
the access of following very restricted information at the beginning of any
round: (1) am I alone at $v$? (2) the number of robots at $v$ increased or
decreased compare to the previous round?
</p>
<p>We propose a deterministic algorithm that achieves dispersion on any given
graph $G=(V,E)$ in time $O\left( k\log L+k^2 \log \Delta\right)$, where
$\Delta$ is the maximum degree of a node in $G$. Each robot uses $O(\log L+
\log \Delta)$ additional memory. We also prove that the task of dispersion
cannot be achieved by a set of mobile robots with $o(\log L + \log \Delta)$
additional memory.
</p></div>
    </summary>
    <updated>2022-02-14T22:41:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.05693</id>
    <link href="http://arxiv.org/abs/2202.05693" rel="alternate" type="text/html"/>
    <title>Black-box Identity Testing of Noncommutative Rational Formulas of Inversion Height Two in Deterministic Quasipolynomial-time</title>
    <feedworld_mtime>1644796800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>V. Arvind, Abhranil Chatterjee, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mukhopadhyay:Partha.html">Partha Mukhopadhyay</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.05693">PDF</a><br/><b>Abstract: </b>Hrube\v{s} and Wigderson (2015) initiated the complexity-theoretic study of
noncommutative formulas with inverse gates. They introduced the Rational
Identity Testing (RIT) problem which is to decide whether a noncommutative
rational formula computes zero in the free skew field. In the white-box
setting, deterministic polynomial-time algorithms are known for this problem
following the works of Garg, Gurvits, Oliveira, and Wigderson (2016) and
Ivanyos, Qiao, and Subrahmanyam (2018).
</p>
<p>A central open problem in this area is to design efficient deterministic
black-box identity testing algorithm for rational formulas. In this paper, we
solve this problem for the first nested inverse case. More precisely, we obtain
a deterministic quasipolynomial-time black-box RIT algorithm for noncommutative
rational formulas of inversion height two via a hitting set construction.
Several new technical ideas are involved in the hitting set construction,
including key concepts from matrix coefficient realization theory
(Vol\v{c}i\v{c}, 2018) and properties of cyclic division algebra (Lam, 2001).
En route to the proof, an important step is to embed the hitting set of Forbes
and Shpilka for noncommutative formulas (2013) inside a cyclic division algebra
of small index.
</p></div>
    </summary>
    <updated>2022-02-14T22:37:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.05691</id>
    <link href="http://arxiv.org/abs/2202.05691" rel="alternate" type="text/html"/>
    <title>A Tight $(\frac{3}{2}+\epsilon)$-Approximation for Unsplittable Capacitated Vehicle Routing on Trees</title>
    <feedworld_mtime>1644796800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mathieu:Claire.html">Claire Mathieu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Hang.html">Hang Zhou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.05691">PDF</a><br/><b>Abstract: </b>We give a polynomial time $(3/2+\epsilon)$-approximation algorithm for the
unsplittable capacitated vehicle routing problem (CVRP) on trees. Our
approximation ratio is tight, given that it is NP-hard to approximate this
problem to better than a $3/2$ factor.
</p></div>
    </summary>
    <updated>2022-02-14T22:42:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.05651</id>
    <link href="http://arxiv.org/abs/2202.05651" rel="alternate" type="text/html"/>
    <title>Notes on switching lemmas</title>
    <feedworld_mtime>1644796800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thapen:Neil.html">Neil Thapen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.05651">PDF</a><br/><b>Abstract: </b>We prove three switching lemmas, for random restrictions for which variables
are set independently; for random restrictions where variables are set in
blocks (both due to Hastad [Hastad 86]); and for a distribution appropriate for
the bijective pigeonhole principle [Beame et al. 94, Krajicek et al. 95]. The
proofs are based on Beame's version [Beame 94] of Razborov's proof of the
switching lemma in [Razborov 93], except using families of weighted
restrictions rather than families of restrictions which are all the same size.
This follows a suggestion of Beame in [Beame 94]. The result is something
between Hastad's and Razborov's methods of proof. We use probabilistic
arguments rather than counting ones, in a similar way to Hastad, but rather
than doing induction on the terms in our formula with an inductive hypothesis
involving conditional probability, as Hastad does, we explicitly build one
function to bound the probabilities for the whole formula.
</p></div>
    </summary>
    <updated>2022-02-14T22:41:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.05562</id>
    <link href="http://arxiv.org/abs/2202.05562" rel="alternate" type="text/html"/>
    <title>Perfect Matchings and Quantum Physics: Progress on Krenn's Conjecture</title>
    <feedworld_mtime>1644796800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chandran:L=_Sunil.html">L. Sunil Chandran</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gajjala:Rishikesh.html">Rishikesh Gajjala</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.05562">PDF</a><br/><b>Abstract: </b>In 2017, Krenn reported that certain problems related to the perfect
matchings and colourings of graphs emerge out of studying the constructability
of general quantum states using modern photonic technologies. He realized that
if we can prove that the \emph{weighted matching index} of a graph, a parameter
defined in terms of perfect matchings and colourings of the graph is at most 2,
that could lead to exciting insights on the potential of resources of quantum
inference. Motivated by this, he conjectured that the {weighted matching index}
of any graph is at most 2. The first result on this conjecture was by Bogdanov,
who proved that the \emph{(unweighted) matching index} of graphs
(non-isomorphic to $K_4$) is at most 2, thus classifying graphs non-isomorphic
to $K_4$ into Type 0, Type 1 and Type 2. By definition, the weighted matching
index of Type 0 graphs is 0. We give a structural characterization for Type 2
graphs, using which we settle Krenn's conjecture for Type 2 graphs. Using this
characterization, we provide a simple $O(|V||E|)$ time algorithm to find the
unweighted matching index of any graph. In view of our work, Krenn's conjecture
remains to be proved only for Type 1 graphs. We give upper bounds for the
weighted matching index in terms of connectivity parameters for such graphs.
Using these bounds, for a slightly simplified version, we settle Krenn's
conjecture for the class of graphs with vertex connectivity at most 2 and the
class of graphs with maximum degree at most 4.
</p>
<p>Krenn has been publicizing his conjecture in various ways since 2017. He has
even declared a reward for a resolution of his conjecture. We hope that this
article will popularize the problem among computer scientists.
</p></div>
    </summary>
    <updated>2022-02-14T22:43:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.05554</id>
    <link href="http://arxiv.org/abs/2202.05554" rel="alternate" type="text/html"/>
    <title>Improved bounds for randomly colouring simple hypergraphs</title>
    <feedworld_mtime>1644796800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feng:Weiming.html">Weiming Feng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Heng.html">Heng Guo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Jiaheng.html">Jiaheng Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.05554">PDF</a><br/><b>Abstract: </b>We study the problem of sampling almost uniform proper $q$-colourings in
$k$-uniform simple hypergraphs with maximum degree $\Delta$. For any $\delta &gt;
0$, if $k \geq\frac{20(1+\delta)}{\delta}$ and $q \geq
100\Delta^{\frac{2+\delta}{k-4/\delta-4}}$, the running time of our algorithm
is $\tilde{O}(\mathrm{poly}(\Delta k)\cdot n^{1.01})$, where $n$ is the number
of vertices. Our result requires fewer colours than previous results for
general hypergraphs (Jain, Pham, and Voung, 2021; He, Sun, and Wu, 2021), and
does not require $\Omega(\log n)$ colours unlike the work of Frieze and Anastos
(2017).
</p></div>
    </summary>
    <updated>2022-02-14T22:44:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.05546</id>
    <link href="http://arxiv.org/abs/2202.05546" rel="alternate" type="text/html"/>
    <title>Insertion Time of Random Walk Cuckoo Hashing below the Peeling Threshold</title>
    <feedworld_mtime>1644796800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Walzer:Stefan.html">Stefan Walzer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.05546">PDF</a><br/><b>Abstract: </b>When it comes to hash tables, the only truly respectable insertion time is
$O(1)$, possibly qualified as expected and/or amortised. While insertions into
cuckoo hash tables indeed seem to take $O(1)$ expected time in practice, only
polylogarithmic guarantees are proven in all but the simplest of practically
relevant cases. Given the widespread use of cuckoo hashing to implement compact
dictionaries and Bloom filter alternatives, closing this gap is an important
open problem for theoreticians.
</p>
<p>In this paper, we show that random walk insertions into cuckoo hash tables
take $O(1)$ expected amortised time when any number $k \geq 3$ of hash
functions is used and the load factor is below the corresponding peeling
threshold (e.g. $\approx 0.81$ for $k = 3$). To our knowledge, this is the
first meaningful guarantee for constant time insertion for cuckoo hashing that
works for $k \in \{3,\dots,9\}$.
</p>
<p>In addition to being useful in its own right, we hope that our key-centred
analysis method can be a stepping stone on the path to the true end goal:
$O(1)$ time insertions for all load factors below the load threshold (e.g.
$\approx 0.91$ for $k = 3$).
</p></div>
    </summary>
    <updated>2022-02-14T22:45:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.05444</id>
    <link href="http://arxiv.org/abs/2202.05444" rel="alternate" type="text/html"/>
    <title>Computational-Statistical Gaps in Reinforcement Learning</title>
    <feedworld_mtime>1644796800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kane:Daniel.html">Daniel Kane</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Sihan.html">Sihan Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lovett:Shachar.html">Shachar Lovett</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahajan:Gaurav.html">Gaurav Mahajan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.05444">PDF</a><br/><b>Abstract: </b>Reinforcement learning with function approximation has recently achieved
tremendous results in applications with large state spaces. This empirical
success has motivated a growing body of theoretical work proposing necessary
and sufficient conditions under which efficient reinforcement learning is
possible. From this line of work, a remarkably simple minimal sufficient
condition has emerged for sample efficient reinforcement learning: MDPs with
optimal value function $V^*$ and $Q^*$ linear in some known low-dimensional
features. In this setting, recent works have designed sample efficient
algorithms which require a number of samples polynomial in the feature
dimension and independent of the size of state space. They however leave
finding computationally efficient algorithms as future work and this is
considered a major open problem in the community.
</p>
<p>In this work, we make progress on this open problem by presenting the first
computational lower bound for RL with linear function approximation: unless
NP=RP, no randomized polynomial time algorithm exists for deterministic
transition MDPs with a constant number of actions and linear optimal value
functions. To prove this, we show a reduction from Unique-Sat, where we convert
a CNF formula into an MDP with deterministic transitions, constant number of
actions and low dimensional linear optimal value functions. This result also
exhibits the first computational-statistical gap in reinforcement learning with
linear function approximation, as the underlying statistical problem is
information-theoretically solvable with a polynomial number of queries, but no
computationally efficient algorithm exists unless NP=RP. Finally, we also prove
a quasi-polynomial time lower bound under the Randomized Exponential Time
Hypothesis.
</p></div>
    </summary>
    <updated>2022-02-14T22:38:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/02/13/triangulation-thickens-grids</id>
    <link href="https://11011110.github.io/blog/2022/02/13/triangulation-thickens-grids.html" rel="alternate" type="text/html"/>
    <title>Triangulation thickens grids</title>
    <summary>If you zigzag back and forth through the columns (or rows) of an ordinary two-dimensional grid graph, following a pattern dignified with the fancy name “boustrophedon”, you get a one-dimensional ordering of the vertices that can be used as the basis of a nice planar arc diagram of this graph.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>If you zigzag back and forth through the columns (or rows) of an ordinary two-dimensional grid graph, following a pattern dignified with the fancy name “<a href="https://en.wikipedia.org/wiki/Boustrophedon">boustrophedon</a>”, you get a one-dimensional ordering of the vertices that can be used as the basis of a nice planar <a href="https://en.wikipedia.org/wiki/Arc_diagram">arc diagram</a> of this graph.</p>

<p style="text-align: center;"><img alt="Boustrophedon layout of a 2d grid" src="https://11011110.github.io/blog/assets/2022/boustrophedon.svg" width="80%"/></p>

<p>The same idea works in 3d. You can divide a 3d grid graph into 2d layers, zigzag within each layer, and then reverse the same zigzagging order in alternating layers, to get another nice one-dimensional ordering of the vertices. It doesn’t give a planar drawing (this graph is not planar), but it does allow it to be drawn without crossings on the four half-planes of a four-page <a href="https://en.wikipedia.org/wiki/Book_embedding">book embedding</a>. More generally, any \(d\)-dimensional grid graph can be drawn in the same way as a book embedding with \(2(d-1)\) pages.</p>

<p style="text-align: center;"><img alt="Double boustrophedon layout of a 3d grid" src="https://11011110.github.io/blog/assets/2022/double-boustrophedon.svg" width="80%"/></p>

<p>I’m a coauthor on a new preprint showing that this one-dimensional layout is very sensitive to the way you connect nearby vertices in the 3d grid. If you modify the grid just a little bit, triangulating it by adding a diagonal to each grid square, then the resulting graph no longer has a book embedding with a constant number of pages. Instead, for a triangulated \(n\times n\times n\) grid, \(\Theta(n^{1/3})\) pages are necessary (and sufficient). The preprint is “Three-dimensional graph products with unbounded stack-number”, with Robert Hickingbotham, Laura Merker, Sergey Norin, Michał T. Seweryn, and David R. Wood, <a href="https://arxiv.org/abs/2202.05327">arXiv:2202.05327</a>; the long coauthor list is because it comes from a collaboration that began at the Banff workshop on Graph Product Structure Theory last November.</p>

<p>There are many other related results packed into the same preprint, but rather than summarizing them all I’d rather take a step back and look at the big picture. The result that triangulated grids have high book thickness turns out to follow from a sequence of connections that is closely analogous to results about the high width of 2d grids, and I think the analogies between these connections are very interesting. For 2d grids:</p>

<ul>
  <li>
    <p>Two standard measures of one-dimensionality of graphs are <a href="https://en.wikipedia.org/wiki/Cutwidth">cutwidth</a> and <a href="https://en.wikipedia.org/wiki/Pathwidth">pathwidth</a>. Both can be defined in terms of continuous maps from the graph (considered as a one-dimensional topological space) to a line. A graph has cutwidth at most \(c\) if it has a map in which every point of the line belongs to the images of at most \(c\) edges, and pathwidth at most \(p\) if it has a map in which every point of the line belongs to the images of edges that have at most \(p\) distinct vertices as their left endpoints.</p>
  </li>
  <li>
    <p>For a graph of maximum degree \(d\), at most \(d\) edges can share a left endpoint, so if the graph has cutwidth \(c\) it has pathwidth at least \(c/d\).</p>
  </li>
  <li>
    <p>A complete graph with \(n\) vertices and \(\tbinom{n}{2}\) edges, mapped continuously to a line, always has a point covered by \(\Omega(n^2)\) edges, at the median vertex of the mapping.</p>
  </li>
  <li>
    <p>For a 2d grid graph, we can associate each vertex with a subgraph consisting of the union of the row and column of the grid containing that vertex.</p>

    <p style="text-align: center;"><img alt="Bramble associating each grid vertex with the union of its row and column" src="https://11011110.github.io/blog/assets/2022/grid-bramble.svg" width="50%"/></p>

    <p>This family of subgraphs is a <a href="https://en.wikipedia.org/wiki/Bramble_(graph_theory)">bramble</a>, meaning that all of the subgraphs are connected and touch each other. In this case, they all touch at shared vertices, but brambles also allow subgraphs to touch across edges. In the bramble for an \(n\times n\) grid graph, each graph vertex or edge belongs to \(O(n)\) subgraphs.</p>
  </li>
  <li>
    <p>We can map \(K_{n^2}\) continuously onto the grid, vertex-to-vertex, by mapping each edge of \(K_{n^2}\) onto a path through the two touching subgraphs for its endpoints. This map has low congestion: each grid vertex or edge is in the image of \(O(n)\) vertices or edges of \(K_{n^2}\).</p>
  </li>
  <li>
    <p>Any map of the grid to a line can be composed with the map from \(K_{n^2}\) to the grid, giving a map of \(K_{n^2}\) onto the line. Because of the low congestion of the map to the grid, a point of the line that is covered by \(\Omega(n^2)\) edges of the complete graph must also be covered by \(\Omega(n)\) edges of the grid. Since this is true for all maps to a line, the grid has pathwidth and cutwidth \(\Omega(n)\).</p>
  </li>
</ul>

<p>Now let’s do the same thing, stepped up a dimension!</p>

<ul>
  <li>
    <p>Instead of graphs, let’s consider 2-dimensional simplicial complexes, systems of points, edges, and triangles. And instead of mapping them to a one-dimensional line, let’s map them (topologically, not necessarily linearly) to a two-dimensional plane. We’ll say that the mapping has high thickness if some point is covered by many triangles (corresponding to cutwidth), or by many vertex-disjoint triangles (corresponding to pathwidth).</p>
  </li>
  <li>
    <p>For a graph of maximum  degree \(d\), at most \(\tbinom{d}{2}\) triangles can share a vertex, so a point covered by many triangles will be covered by many vertex-disjoint triangles. More importantly, this is where the book thickness comes in: an argument related to the <a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Szekeres_theorem">Erdős–Szekeres theorem</a> proves that, when a graph has a \(\theta\)-page book embedding, drawn with its vertices on a circle and its edges as chords of the circle, then at most \(\theta^3\) vertex-disjoint triangles in the graph can contain any point within the circle. So if every mapping into the plane produces a system of triangles of thickness \(t\), you also get book thickness \(\Omega(t^{1/3})\).</p>
  </li>
  <li>
    <p>A complete simplicial complex with \(n\) vertices, \(\tbinom{n}{2}\) edges, and \(\tbinom{n}{3}\) triangles, mapped to the plane, always leads to a point covered by \(\Omega(n^3)\) triangles, by a result of Gromov. (This is closely related to the earlier work of Regina Liu on <a href="https://en.wikipedia.org/wiki/Simplicial_depth">simplicial depth</a> but we want to allow any continuous mapping to the plane, whereas simplicial depth involves mappings that are linear on each edge and triangle.)</p>
  </li>
  <li>
    <p>For an \(n\times n\times n\) grid graph, with its squares triangulated to form a 2d complex \(C\), we can associate each vertex with a subcomplex of \(C\) consisting of the union of the 2d grid planes containing that vertex. This family of subcomplexes has connected pairwise unions and simply connected triplewise unions, analogous to the properties of a bramble for a graph.</p>
  </li>
  <li>
    <p>We can map the complete simplicial complex onto the grid, vertex-to-vertex, by mapping each edge onto a path through the union of two subgraphs and each triangle onto a triangulated surface within the union of three subgraphs. This map has low congestion: each grid vertex, edge, or triangle is in the image of \(O(n^2)\) vertices, edges, or triangles of the complete complex.</p>
  </li>
  <li>
    <p>Any map of the triangulated 3d grid onto the plane can be composed with the map from the complete 2-complex to the grid, giving a map of the complete complex onto the plane. Because of the low congestion of the map to the grid, a point of the plane that is covered by \(\Omega(n^3)\) triangles of the complete complex must also be covered by \(\Omega(n)\) triangles of the triangulated grid. Since this is true for all maps to a plane, the triangulated grid has book thickness \(\Omega(n^{1/3})\).</p>
  </li>
</ul>

<p>For details, generalizations to triangulated products of trees and non-grid tessellations of space, matching upper bounds on book thickness, and more, please see the preprint.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/107795266201400204">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2022-02-13T22:54:00Z</updated>
    <published>2022-02-13T22:54:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-02-14T07:54:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19647</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/" rel="alternate" type="text/html"/>
    <title>Inequalities on the Gridiron</title>
    <summary>Q: Why are Buffalo Bills unlike Dollar Bills? A: Dollar Bills are good for 4 quarters Reddit “outsmarting math” source Josh Allen is not appearing in today’s Super Bowl. He led the Buffalo Bills to not just one but two go-ahead touchdowns in the final 2:00 of the game at Kansas City three weeks ago, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Q: Why are Buffalo Bills unlike Dollar Bills? A: Dollar Bills are good for 4 quarters</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/joshallen/" rel="attachment wp-att-19649"><img alt="" class="alignright wp-image-19649" height="128" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/JoshAllen.jpg?resize=155%2C128&amp;ssl=1" width="155"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Reddit “outsmarting math” <a href="https://www.reddit.com/r/buffalobills/comments/km67tw/josh_allen_the_entirety_of_math_and_all_of/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Josh Allen is not appearing in today’s Super Bowl. He led the Buffalo Bills to not just one but two go-ahead touchdowns in the final 2:00 of the game at Kansas City three weeks ago, but the Bills lost both leads and KC won in overtime.</p>
<p>
Today we note an inequality that treats the real numbers like a football gridiron.</p>
<p>
The <a href="https://en.wikipedia.org/wiki/Hurry-up_offense#Two-minute_drill">two-minute drill</a> is the hallmark of quarterback heroism. KC’s Patrick Mahomes, however, demonstrated the <a href="https://dailystatuss.com/13-seconds-meme-13-seconds-chief-nfl-2022/">13-second drill</a> in two plays plus a tying field goal. That is, the Bills were good for 3 quarters plus 14:47. But Mahomes is not in the Super Bowl either. Two weeks ago, he lost the magic touch in both the closing minute of the fourth quarter and the beginning of overtime as KC squandered a big lead and lost to the Cincinnati Bengals. Whose quarterback, Joe Burrow, <i>is</i> playing in today’s Super Bowl, opposite Matthew Stafford of the Los Angeles Rams.</p>
<p>
The American football field is divided into 100 yards, but rarely subdivided beyond that. The announcers may refer to “a long two yards” or “a short 3,” but never 2.5 yards. It is not just the announcers. Official statistics are kept in units of whole yards, more often rounded up than down. A fourth-down quarterback plunge with 3 inches to go still counts as a 1-yard gain. Perhaps it is essential to the yard that it not be divided into dyadic or decimal units, the way the meter is. As the US celebrates an event still enjoyed by “one nation indivisible,” we note the indivisible.</p>
<p>
</p><p/><h2> Inequalities </h2><p/>
<p/><p>
Godfrey Hardy, John Littlewood, George Polya are famous for many things separately and together. All three lent their names to the timeless book <a href="https://mathematicalolympiads.files.wordpress.com/2012/08/inequalities-hardy-littlewood-polya.pdf">Inequalities</a>. It codifies the theory of real inequalities. </p>
<p/><p><br/>
<a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/inequalitiescover/" rel="attachment wp-att-19650"><img alt="" class="aligncenter wp-image-19650" height="250" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/InequalitiesCover.jpg?resize=171%2C250&amp;ssl=1" width="171"/></a></p>
<p/><p><br/>
<a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/hlp/" rel="attachment wp-att-19652"><img alt="" class="aligncenter wp-image-19652" height="105" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/HLP.png?resize=276%2C105&amp;ssl=1" width="276"/></a></p>
<p>
</p><p/><h2> An Inequality </h2><p/>
<p/><p>
We recently had reason to look at the following inequality: </p>
<blockquote><p><b> </b> <em> If <img alt="{a^2 - b^2 = c&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%5E2+-+b%5E2+%3D+c%3E0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then 	</em></p><em>
<p align="center"><img alt="\displaystyle  c \ge a+b. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%5Cge+a%2Bb.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</em><p><em/>
</p></blockquote>
<p>We noted that this fails in general: Let <img alt="{a=1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%3D1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{b=1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%3D1%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Then <img alt="{c=3/16}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%3D3%2F16%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and 	</p>
<p align="center"><img alt="\displaystyle  3/16 &lt; 1/2 + 1/4. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++3%2F16+%3C+1%2F2+%2B+1%2F4.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>This is not even close. But wait—the following lemma is true:</p>
<blockquote><p><b>Lemma 1</b> <em> If <img alt="{a^2 - b^2 = c&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%5E2+-+b%5E2+%3D+c%3E0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then 	</em></p><em>
<p align="center"><img alt="\displaystyle  c \ge a+b " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%5Cge+a%2Bb+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</em><p><em>provided <img alt="{a,b,c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> are integers. </em>
</p></blockquote>
<p/><p>
The proof is quite simple. We note that 	</p>
<p align="center"><img alt="\displaystyle  c = (a-b)(a+b). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%3D+%28a-b%29%28a%2Bb%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>But this shows that <img alt="{a+b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%2Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is a non-zero divisor of <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. But then 	</p>
<p align="center"><img alt="\displaystyle  a+b \le c. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a%2Bb+%5Cle+c.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>This proves the inequality. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Is this interesting at all? We have an application of the above lemma, which we will discuss in the future. Are there other good examples of inequalities that are general and natural and only hold over the integers? Or is seeking them like trying to “outsmart math itself”?</p>
<p><br/></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/allenoutsmartsmath/" rel="attachment wp-att-19653"><img alt="" class="aligncenter wp-image-19653" height="177" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/AllenOutsmartsMath.jpg?resize=400%2C177&amp;ssl=1" width="400"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">SB Nation <a href="https://www.sbnation.com/nfl/2018/4/24/17271686/josh-allen-nfl-draft-2018-stats-analysis-comparisons">source</a></font>
</td>
</tr>
</tbody></table></font></font></div>
    </content>
    <updated>2022-02-13T21:57:51Z</updated>
    <published>2022-02-13T21:57:51Z</published>
    <category term="All Posts"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Results"/>
    <category term="American football"/>
    <category term="gridiron"/>
    <category term="inequalities"/>
    <category term="Josh Allen"/>
    <category term="Super Bowl"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-02-15T08:37:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6299</id>
    <link href="https://scottaaronson.blog/?p=6299" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6299#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6299" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Happy 70th birthday Dad!</title>
    <summary xml:lang="en-US">When, before covid, I used to travel the world giving quantum computing talks, every once in a while I’d meet an older person who asked whether I had any relation to a 1970s science writer by the name of Steve Aaronson. So, yeah, Steve Aaronson is my dad. He majored in English in Penn State, […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><figure class="wp-block-image size-large"><a href="https://149663533.v2.pressablecdn.com/wp-content/uploads/2022/02/dad70-scaled.jpg"><img alt="" class="wp-image-6302" height="768" src="https://149663533.v2.pressablecdn.com/wp-content/uploads/2022/02/dad70-1024x768.jpg" width="1024"/></a></figure>



<p>When, before covid, I used to travel the world giving quantum computing talks, every once in a while I’d meet an older person who asked whether I had any relation to a 1970s science writer by the name of Steve Aaronson.  So, yeah, Steve Aaronson is my dad.  He majored in English in Penn State, where he was lucky enough to study under the legendary <a href="https://en.wikipedia.org/wiki/William_Tenn">Phil Klass</a>, who wrote under the pen name William Tenn and who basically created the genre of science-fiction comedy, half a century before there were any such things as <em>Futurama</em>.  After graduating, my dad became a popular physics and cosmology writer, who interviewed greats like Steven Weinberg and John Archibald Wheeler and Arno Penzias (discoverer of the cosmic microwave background radiation).  He published not only in science magazines but in <em>Playboy</em> and <em>Penthouse</em>, which (as he explained to my mom) paid better than the science magazines.  When I was growing up, my dad had a <em>Playboy</em> on his office shelf, which I might take down if for example I wanted to show a friend a 2-page article, with an Aaronson byline, about the latest thinking on the preponderance of matter over antimatter in the visible universe.</p>



<p>Eventually, partly motivated by the need to make money to support … well, me, and then my brother, my dad left freelancing to become a corporate science writer at AT&amp;T Bell Labs.  There, my dad wrote speeches, delivered on the floor of Congress, about how breaking up AT&amp;T’s monopoly would devastate Bell Labs, a place that stood with ancient Alexandria and Cambridge University among the human species’ most irreplaceable engines of scientific creativity.  (Being a good writer, my dad didn’t put it in <em>quite</em> those words.)  Eventually, of course, AT&amp;T <em>was</em> broken up, and my dad’s dire warning about Bell Labs turned out to be 100% vindicated … although on the positive side, Americans got much cheaper long distance.</p>



<p>After a decade at Bell Labs, my dad was promoted to be a public relations executive at AT&amp;T itself, where when I was a teenager, he was centrally involved in the launch of the AT&amp;T spinoff <a href="https://en.wikipedia.org/wiki/Lucent">Lucent Technologies</a> (motto: “Bell Labs Innovations”), and then later the Lucent spinoff <a href="https://en.wikipedia.org/wiki/Avaya">Avaya</a>—developments that AT&amp;T’s original breakup had caused as downstream effects.</p>



<p>In the 1970s, somewhere between his magazine stage and his Bell Labs stage, my dad also worked for <a href="https://en.wikipedia.org/wiki/Eugene_Garfield">Eugene Garfield</a>, the pioneer of bibliometrics for scientific papers and founder of the <a href="https://en.wikipedia.org/wiki/Institute_for_Scientific_Information">Institute for Scientific Information</a>, or ISI.  (Sergey Brin and Larry Page would later cite Garfield’s work, on the statistics of the scientific-citation graph, as one of the precedents for the PageRank algorithm at the core of Google.)</p>



<p>My dad’s job at ISI was to supply Eugene Garfield with “raw material” for essays, which the latter would then write and publish in ISI’s journal <em>Current Contents</em> under the byline Eugene Garfield.  Once, though, my dad supplied some “raw material” for a planned essay about “Style in Scientific Writing”—and, well, I’ll let Garfield <a href="http://www.garfield.library.upenn.edu/essays/v3p004y1977-78.pdf">tell</a> the rest:</p>



<blockquote class="wp-block-quote"><p>This topic of style in scientific writing was first proposed as something I should undertake myself, with some research and drafting help from Steve.  I couldn’t, with a clear conscience, have put my name to the “draft” he submitted.  And, though I don’t disagree with much of it, I didn’t want to modify or edit it in order to justify claiming it as my own.  So here is Aaronson’s “draft,” as it was submitted for “review.”  You can say I got a week’s vacation.  After reading what he wrote it required little work to write this introduction.</p></blockquote>



<p>Interested yet?  You can <a href="http://www.garfield.library.upenn.edu/essays/v3p004y1977-78.pdf">read “Style in Scientific Writing” here</a>.  You can, if we’re being honest, tell that this piece was originally intended as “raw material”—but only because of the way it calls forth such a fierce armada of all of history’s awesomest quotations about what makes scientific writing good or bad, like Ben Franklin and William James and the whole gang, which would make it worth the read regardless.  I <em>love</em> eating raw dough, I confess, and I love my dad’s essay.  (My dad, ironically enough, likes everything he eats to be thoroughly cooked.)</p>



<p>When I read that essay, I hear my dad’s voice from my childhood.  “Omit needless words.”  There were countless revisions and pieces of advice on every single thing I wrote, but usually, “omit needless words” was the core of it.  And as terrible as you all know me to be on that count, imagine <em>how much worse</em> it would’ve been if not for my dad!  And I know that as soon as he reads this post, he’ll find needless words to omit.</p>



<p>But hopefully he won’t omit these:</p>



<p>Happy 70th birthday Pops, congrats on beating the cancer, and here’s to many more!</p></div>
    </content>
    <updated>2022-02-12T20:11:04Z</updated>
    <published>2022-02-12T20:11:04Z</published>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <category scheme="https://scottaaronson.blog" term="Self-Referential"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-02-14T19:44:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/015</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/015" rel="alternate" type="text/html"/>
    <title>TR22-015 |  Lower Bounds for Unambiguous Automata via Communication Complexity | 

	Mika Göös, 

	Stefan Kiefer, 

	Weiqiang Yuan</title>
    <summary>We use results from communication complexity, both new and old ones, to prove lower bounds for unambiguous finite automata (UFAs). We show three results.

$\textbf{Complement:}$ There is a language $L$ recognised by an $n$-state UFA such that the complement language $\overline{L}$ requires NFAs with $n^{\tilde{\Omega}(\log n)}$ states. This improves on a lower bound by Raskin.

$\textbf{Union:}$ There are languages $L_1$, $L_2$ recognised by $n$-state UFAs such that the union $L_1\cup L_2$ requires UFAs with $n^{\tilde{\Omega}(\log n)}$ states.

$\textbf{Separation:}$ There is a language $L$ such that both $L$ and $\overline{L}$ are recognised by $n$-state NFAs but such that $L$ requires UFAs with $n^{\Omega(\log n)}$ states. This refutes a conjecture by Colcombet.</summary>
    <updated>2022-02-12T16:29:35Z</updated>
    <published>2022-02-12T16:29:35Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-15T08:37:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://nisheethvishnoi.wordpress.com/?p=147</id>
    <link href="https://nisheethvishnoi.wordpress.com/2022/02/11/focs-2021-talk-videos/" rel="alternate" type="text/html"/>
    <title>FOCS 2021 Talk Videos</title>
    <summary>After more than a year of planning, FOCS 2021 concluded yesterday. In case you missed all or part of the event, the talks for all of 117 papers and for the three workshops are now available on this youtube channel. The full versions of all papers (and videos) are also freely available here. Many thanks […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>After more than a year of planning, FOCS 2021 concluded yesterday. </p>



<p>In case you missed all or part of the event, the talks for all of 117 papers and for the three workshops are now available on <a href="https://www.youtube.com/channel/UClrteoQ-ULzlZZaWi6c6iKw/playlists">this youtube</a> channel.</p>



<p>The full versions of all papers (and videos) are also freely available <a href="https://focs2021.cs.colorado.edu/program/">here</a>.</p>



<p>Many thanks to more than 1000 people, including authors, program committee members, external reviewers, organizers, TCMF members, volunteers, and attendees for making this happen! </p>



<figure class="wp-block-video"/></div>
    </content>
    <updated>2022-02-11T14:30:16Z</updated>
    <published>2022-02-11T14:30:16Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>nisheethvishnoi</name>
    </author>
    <source>
      <id>https://nisheethvishnoi.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://nisheethvishnoi.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://nisheethvishnoi.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Algorithms, Nature, and Society</title>
      <updated>2022-02-15T08:38:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19636</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/02/10/national-academy-of-engineering-elects/" rel="alternate" type="text/html"/>
    <title>National Academy of Engineering Elects</title>
    <summary>The problem in this business isn’t to keep people from stealing your ideas; it’s making them steal your ideas!—Howard Aiken Composite crop of homepage photos Taher Elgamal and Anna Karlin are among 111 new US members of the National Academy of Engineering (NAE). That’s one-hundred-and-eleven, not seven in binary. Today we congratulate them and all […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>The problem in this business isn’t to keep people from stealing your ideas; it’s making them steal your ideas!—Howard Aiken</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/10/national-academy-of-engineering-elects/egak/" rel="attachment wp-att-19638"><img alt="" class="alignright size-full wp-image-19638" height="115" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/EGAK.png?resize=155%2C115&amp;ssl=1" width="155"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop of homepage photos</font></td>
</tr>
</tbody>
</table>
<p>
Taher Elgamal and Anna Karlin are among 111 <a href="https://www.nae.edu/270224/National-Academy-of-Engineering-Elects-111-Members-and-22-International-Members">new US members</a> of the National Academy of Engineering (NAE). That’s one-hundred-and-eleven, not seven in binary.</p>
<p>
Today we congratulate them and all the new members.<br/>
<span id="more-19636"/></p>
<p>
Elgamal and Karlin are the two closest to theory, by my reckoning. Elgamal developed the <a href="https://en.wikipedia.org/wiki/ElGamal_encryption">ElGamal</a> encryption scheme. Elgamal spelled his name with a capital G at the time of his famous 1985 <a href="https://caislab.kaist.ac.kr/lecture/2010/spring/cs548/basic/B02.pdf">paper</a> but it is lowercased on his own LinkedIn <a href="https://www.linkedin.com/in/taherelgamal/">page</a>, on Wikipedia, on his RSA conference <a href="https://www.rsaconference.com/experts/dr-taherelgamal">page</a>, and by the NAE. Wikipedia explains that he spells it more simply so that “it is less likely to be mangled in English.” Yet his invention keeps the capital G. Ken and I think a good reason for this is that it uses a large cyclic group <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The citation also hails his work on <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security#SSL_1.0,_2.0,_and_3.0">SSL</a> and other internet protocols.</p>
<p>
We featured Karlin’s nifty joint paper on the metric TSP problem recently <a href="https://rjlipton.wpcomstaging.com/2020/10/26/a-vast-and-tiny-breakthrough/">here</a>. She is also on the editorial board of the new TheoretiCS <a href="https://rjlipton.wpcomstaging.com/2021/12/01/the-new-journal/">journal</a>. I was glad to serve with her on an NSF committee to promote <a href="https://rjlipton.wpcomstaging.com/2011/07/12/time-chunks-and-theory-nuggets/">nuggets</a> of theory. She holds the Bill and Melinda Gates Chair at the Paul Allen School of Computer Science and Engineering at the University of Washington.</p>
<p>
The new members bring the total US membership in the NAE to 2,388. Joining them are 22 new international members. They include Natarajan Chandrasekaran of Tata Sons for advancing the Indian software industry and Hongjiang Zhang of The Carlyle Group in Beijing for multimedia computing. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2022/02/10/national-academy-of-engineering-elects/nae/" rel="attachment wp-att-19639"><img alt="" class="aligncenter wp-image-19639" height="120" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/nae.png?resize=120%2C120&amp;ssl=1" width="120"/></a></p>
<p>
</p><p/><h2> New Members in Computing </h2><p/>
<p/><p>
There are many other new members in areas of computing besides theory. Here are some of the new members that work in computer science—including the citations for Elgamal and Karlin. </p>
<ul>
<p/><li>
Bergeron, Kathleen, vice president, Hardware Engineering, Apple Inc., Los Gatos, Calif. <i>For contributions to and leadership in the invention and engineering product realization of innovative designs.</i><p/>
<p/></li><li>
Bovik, Alan C., Cockrell Family Regents Endowed Chair in Engineering and professor, Electrical and Computer Engineering, University of Texas, Austin. <i>For contributions to the development of tools for image and video quality assessment.</i><p/>
<p/></li><li>
Cohn, John Maxwell, IBM Fellow, MIT-IBM Watson AI Lab, Cambridge, Mass. <i>For improving design productivity of high-performance analog and mixed-signal circuits and for evangelizing STEM education.</i><p/>
<p/></li><li>
Croak, Marian R., vice president, Engineering, Google LLC, Fair Haven, N.J. <i>For technical and managerial leadership in the implementation of packet voice networking and for promotion of minority inclusion in engineering.</i><p/>
<p/></li><li>
Czerwinski, Mary, partner researcher and research manager, Microsoft Research, Redmond, Wash. <i>For the application of psychological principles to the design and understanding of human computer interaction.</i><p/>
<p/></li><li>
Elgamal, Taher, chief technology officer, Security, Salesforce, San Francisco. <i>For contributions to cryptography, e-commerce, and protocols for secure internet transactions.</i><p/>
<p/></li><li>
Fields, Craig I., chairman, Defense Science Board, U.S. Department of Defense, Washington, D.C. <i>For contributions to the development of systems and technology for national security and their transfer to commercial applications.</i><p/>
<p/></li><li>
Hammack, William S., William H. and Janet G. Lycan Professor, Chemical and Biomolecular Engineering, University of Illinois, Urbana-Champaign. <i>For innovations in multidisciplinary engineering education, outreach, and service to the profession through development and communication of internet-delivered content.</i><p/>
<p/></li><li>
Karlin, Anna, Bill and Melinda Gates Chair, Allen School of Computer Science &amp; Engineering, University of Washington, Seattle. <i>For contributions to the design and analysis of randomized algorithms and their impact on computer systems and the internet.</i><p/>
<p/></li><li>
Karniadakis, George Em, Charles Pitts Robinson and John Palmer Barstow Professor, Division of Applied Mathematics and School of Engineering, Brown University, Providence, R.I. <i>For computational tools, from high-accuracy algorithms to machine learning, and applications to complex flows, stochastic processes, and microfluidics.</i><p/>
<p/></li><li>
Levoy, Marc, Vmware Founders Professor (emeritus), Computer Science, Stanford University, Stanford, Calif. <i>For contributions to computer graphics and digital photography.</i><p/>
<p/></li><li>
Mauro, John C., professor, Department of Materials Science and Engineering, Pennsylvania State University, University Park. <i>For developing and applying data-driven models and machine learning that enable high-strength, damage-resistant glasses.</i><p/>
<p/></li><li>
Nadella, Satya, chairman and chief executive officer, Microsoft Corp., Redmond, Wash. <i>For advancing corporate computing infrastructure as a cloud service, and for international leadership on sociotechnical systems and practice.</i> <p/>
<p/></li><li>
Nahrstedt, Klara, Grainger Distinguished Chair, Grainger College of Engineering, University of Illinois, Urbana-Champaign. <i>For contributions to managing quality of service in distributed multimedia systems and networks.</i><p/>
<p/></li><li>
Reiman, Martin I., professor, Department of Industrial Engineering and Operations Research, Columbia University, Murray Hill, N.J. <i>For contributions to network theory and applications in large-scale stochastic systems.</i><p/>
<p/></li><li>
Sahinidis, Nikolaos V., Gary C. Butler Family Chair and Professor, H. Milton Stewart School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta. <i>For contributions to global optimization and the development of widely used software for optimization and machine learning.</i><p/>
<p/></li><li>
Sapiro, Guillermo, James B. Duke Distinguished Professor, Electrical and Computer Engineering, Duke University, Durham, N.C. <i>For contributions to the theory and practice of imaging.</i><p/>
<p/></li><li>
Veloso, Manuela M., head, Artificial Intelligence Research, JPMorgan Chase &amp; Co., New York City. <i>For contributions to machine learning and its applications in robotics and the financial services industry.</i><p/>
<p/></li><li>
Whitney, Telle, CEO, Telle Whitney Consulting LLC, Scotts Valley, Calif. <i>For contributions to structured silicon design and for increasing the participation of women in computing careers.</i><p/>
<p/></li><li>
Willcox, Karen E., director, Oden Institute for Computational Engineering and Sciences, University of Texas, Austin. <i>For contributions to computational engineering methods for the design and optimal control of high-dimensional systems with uncertainties.</i><p/>
</li></ul>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We count 8 women of the 20 above: Bergeron, Croak, Czerwinski, Karlin, Nahrstedt, Veloso, Whitney, and Willcox. That’s quite a lot better than other rations we’ve observed. How can awareness of this success be filtered through? We also note Anna’s <a href="https://medium.com/@karlin_41004/why-women-and-everyone-else-should-code-18e4a0a46a47">essay</a>, “Why Women (and Everyone Else) Should Code.”</p>
<p/></font></font></div>
    </content>
    <updated>2022-02-11T01:40:02Z</updated>
    <published>2022-02-11T01:40:02Z</published>
    <category term="All Posts"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Anna Karlin"/>
    <category term="National Academy of Engineering"/>
    <category term="new members"/>
    <category term="Taher Elgamal"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-02-15T08:37:30Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/02/10/hereditary-first-order</id>
    <link href="https://11011110.github.io/blog/2022/02/10/hereditary-first-order.html" rel="alternate" type="text/html"/>
    <title>Hereditary first order graph properties can be hard</title>
    <summary>Many natural classes of undirected graphs are hereditary, meaning that if you delete vertices from any graph in the class, the induced subgraph that you get always remains in this class. Every hereditary class of graphs can be defined by its forbidden induced subgraphs, the minimal graphs that do not belong to the class. When there are only finitely many of these forbidden subgraphs, it is possible to define the class by a formula in the first-order logic of graphs describing the graphs that do not have these subgraphs, and to test membership in the class in polynomial time by searching for a forbidden subgraph. Examples include:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Many natural classes of undirected graphs are <a href="https://en.wikipedia.org/wiki/Hereditary_property">hereditary</a>, meaning that if you delete vertices from any graph in the class, the induced subgraph that you get always remains in this class. Every hereditary class of graphs can be defined by its <a href="https://en.wikipedia.org/wiki/Forbidden_graph_characterization">forbidden induced subgraphs</a>, the minimal graphs that do not belong to the class. When there are only finitely many of these forbidden subgraphs, it is possible to define the class by a formula in the first-order <a href="https://en.wikipedia.org/wiki/Logic_of_graphs">logic of graphs</a> describing the graphs that do not have these subgraphs, and to test membership in the class in polynomial time by searching for a forbidden subgraph. Examples include:</p>

<ul>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Threshold_graph">threshold graphs</a>, whose forbidden subgraphs are a four-vertex path, four-vertex cycle, or four-vertex perfect matching.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Cograph">cographs</a>, whose single forbidden subgraph is a four-vertex path.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Triangle-free_graph">triangle-free graphs</a>, whose single forbidden subgraph is a <span style="white-space: nowrap;">triangle \(K_3\).</span></p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Claw-free_graph">claw-free graphs</a>, whose single forbidden subgraph is the four-vertex <span style="white-space: nowrap;">tree \(K_{1,3}\).</span></p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Line_graph">line graphs</a>, which have a forbidden subgraph characterization with nine forbidden subgraphs:</p>
  </li>
</ul>

<p style="text-align: center;"><img alt="The nine forbidden induced subgraphs of line graphs" src="https://11011110.github.io/blog/assets/2022/nonline.svg"/></p>

<p>However, there might be infinitely many forbidden subgraphs. In many such cases, it is still possible to recognize these graphs in polynomial time, often by a greedy algorithm that removes vertices one at a time based on some local structure. Additionally, in these cases, it is often possible to describe the property of being one of the forbidden subgraphs by a first-order formula, so that the graph class is the class of graphs none of whose subgraphs model that formula. For instance:</p>

<ul>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Degeneracy_(graph_theory)"><span style="white-space: nowrap;">\(d\)-degenerate</span> graphs</a> are graphs in which no non-empty induced subgraph has all vertices of degree greater <span style="white-space: nowrap;">than \(d\).</span> They can be recognized in polynomial time as the graphs reducible to empty by repeatedly removing low-degree vertices.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Distance-hereditary_graph">distance-hereditary graphs</a> are graphs in which every induced subgraph with two or more vertices has a degree-one vertex, or twins, two vertices with equal closed or open neighborhoods. They can be recognized in polynomial time by repeatedly removing degree-one vertices or merging twins.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Chordal_graph">chordal graphs</a> are graphs with no induced cycle of more than three vertices, or the graphs in which every non-empty induced subgraph has a simplicial vertex, a vertex whose neighbors are all adjacent. They can be recognized in polynomial time by repeatedly removing simplicial vertices.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Perfect_graph">perfect graphs</a> are graphs with no odd induced cycle of more than three vertices, or its complement. They can be recognized in polynomial time but the algorithm is complicated.</p>
  </li>
</ul>

<p>Obviously, not all hereditary classes are like that; one could, for instance, forbid induced cycles whose lengths belong to an undecidable set of integers, and get a hereditary class of graphs whose recognition problem is again undecidable. But this led me to wonder: is there a connection between the first-order recognizability of the forbidden subgraphs and the polynomial recognizability of the graph class itself? Could it be that every hereditary class defined by a first-order set of forbidden subgraphs is polynomially recognizable?</p>

<p>No!</p>

<p>The counterexample I found is the family of graphs whose forbidden subgraphs are the non-empty <a href="https://en.wikipedia.org/wiki/Perfect_graph">cubic (3-regular) graphs</a>. Let’s call these the cubic-free graphs. Being cubic is easily expressed in first-order logic, so the forbidden subgraphs for the cubic-free graphs are first-order recognizable. However, under standard assumptions, the cubic-free graphs themselves are not polynomially recognizable: their recognition problem is <span style="white-space: nowrap;">\(\mathsf{coNP}\)-complete.</span> Put another way, the problem <small>CUBIC INDUCED SUBGRAPH</small> asking whether a given graph has a non-empty cubic induced subgraph is <span style="white-space: nowrap;">\(\mathsf{NP}\)-complete.</span></p>

<p>I found lots of references in the literature to problems of finding non-empty cubic subgraphs (not required to be induced subgraphs; see Garey &amp; Johnson GT32), or to finding cubic induced subgraphs with some constraint on their size, but not to the <small>CUBIC INDUCED SUBGRAPH</small> problem itself. So instead, I found an <span style="white-space: nowrap;">\(\mathsf{NP}\)-completeness</span> reduction myself, from <a href="https://en.wikipedia.org/wiki/3-dimensional_matching"><small>3-DIMENSIONAL MATCHING</small></a>, in which the input is a 3-uniform hypergraph (meaning that each hyperedge touches three hypervertices) and one must find a subset of the hyperedges that touches every hypervertex exactly once. An example of my reduction is shown below, from which I think the general case should be more clear.</p>

<p style="text-align: center;"><img alt="NP-completeness reduction from 3-dimensional matching to cubic induced subgraph" src="https://11011110.github.io/blog/assets/2022/3dm23is.svg"/></p>

<p>The input hypergraph is shown with its hypervertices as large blue disks and its hyperedges as medium-sized yellow disks. Inside each of these disks is shown part of a graph, a gadget into which that piece of the hypergraph is translated to form a piece of a <small>CUBIC INDUCED SUBGRAPH</small> instance. The example hypergraph used in the image is 4-regular (every hypervertex touches four hyperedges) but that’s not essential. Once you start making choices of which vertices to include or exclude in an induced subgraph, you can make a chain of inferences from that choice:</p>
<ul>
  <li>If you have included a vertex that has only three non-excluded neighbors, you must include all three of them.</li>
  <li>If you have included a vertex that has three included neighbors, you must exclude all its other neighbors.</li>
  <li>If some vertex has fewer than three neighbors that are not excluded, you must exclude it.</li>
</ul>

<p>It follows from this sort of reasoning that the only non-empty cubic induced subgraphs are like the ones shown by the dark red vertices in these gadgets: a vertex for each of the the hyperedges in a matching (such as the matching of dark-yellow hyperedges), and a corresponding subset of the vertices in every hypervertex gadget. Because finding a cubic induced subgraph is <span style="white-space: nowrap;">\(\mathsf{NP}\)-complete,</span> its complementary problem, testing whether a graph is cubic-free, is <span style="white-space: nowrap;">\(\mathsf{coNP}\)-complete.</span></p>

<p>(<a href="https://mathstodon.xyz/@11011110/107776994325248199">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2022-02-10T17:40:00Z</updated>
    <published>2022-02-10T17:40:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-02-14T07:54:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/10/postdoc-in-computational-complexity-at-imperial-college-london-apply-by-april-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/10/postdoc-in-computational-complexity-at-imperial-college-london-apply-by-april-15-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc in computational complexity at Imperial College London (apply by April 15, 2022)</title>
    <summary>Applications are invited for a postdoctoral position at the Complexity Group, Imperial College London, led by prof. Iddo Tzameret and funded by the ERC. The position is for one year with up to two-year extension. The start date is flexible, and the salary is generous. This position is based at the South Kensington campus in […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a postdoctoral position at the Complexity Group, Imperial College London, led by prof. Iddo Tzameret and funded by the ERC. The position is for one year with up to two-year extension. The start date is flexible, and the salary is generous. This position is based at the South Kensington campus in the heart of London. Applications will be accepted until position filled.</p>
<p>Website: <a href="https://www.doc.ic.ac.uk/~itzamere/PhD_Postdoc_Post.html">https://www.doc.ic.ac.uk/~itzamere/PhD_Postdoc_Post.html</a><br/>
Email: iddo.tzameret@gmail.com</p></div>
    </content>
    <updated>2022-02-10T17:39:08Z</updated>
    <published>2022-02-10T17:39:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-15T08:37:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/10/tenure-track-assistant-professor-at-university-of-vienna-apply-by-march-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/10/tenure-track-assistant-professor-at-university-of-vienna-apply-by-march-15-2022/" rel="alternate" type="text/html"/>
    <title>Tenure-track assistant professor at University of Vienna (apply by March 15, 2022)</title>
    <summary>The faculty of Computer Science is looking for outstanding internationally recognized early career scientists with a research focus on scalable algorithmic approaches for AI. This competence is documented by publications in top venues in relevant areas, including, but not limited to, – machine learning, – AI, – algorithms, or – high performance computing research. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The faculty of Computer Science is looking for outstanding internationally recognized early career scientists with a research focus on scalable algorithmic approaches for AI.<br/>
This competence is documented by publications in top venues in relevant areas, including, but not limited to, – machine learning,<br/>
– AI,<br/>
– algorithms, or<br/>
– high performance computing research.</p>
<p>Website: <a href="https://univis.univie.ac.at/ausschreibungstellensuche/flow/bew_ausschreibung-flow?_flowExecutionKey=_c11E8D826-8A93-525D-7F25-64B17F6D4117_k70C7134F-AA27-C4B1-26FA-8A869B87BA6B&amp;tid=89875.28">https://univis.univie.ac.at/ausschreibungstellensuche/flow/bew_ausschreibung-flow?_flowExecutionKey=_c11E8D826-8A93-525D-7F25-64B17F6D4117_k70C7134F-AA27-C4B1-26FA-8A869B87BA6B&amp;tid=89875.28</a><br/>
Email: monika.henzinger@univie.ac.at</p></div>
    </content>
    <updated>2022-02-10T14:34:39Z</updated>
    <published>2022-02-10T14:34:39Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-15T08:37:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=22399</id>
    <link href="https://gilkalai.wordpress.com/2022/02/10/is-hqca-possible-a-conversation-with-michael-brooks/" rel="alternate" type="text/html"/>
    <title>Is HQCA Possible? A conversation with Michael Brooks</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Here is a short email interview from April 2021 with Michael Brooks from “New Scientist”. Dear Professor Kalai, I’m writing a short feature for New Scientist magazine on the theme “Will we ever have a useful quantum computer?”. I’m aware … <a href="https://gilkalai.wordpress.com/2022/02/10/is-hqca-possible-a-conversation-with-michael-brooks/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Here is a short email interview from April 2021 with Michael Brooks from “New Scientist”.</p>
<p><span class="im"><strong>Dear Professor Kalai,</strong> <b>I’m writing a short feature for New Scientist magazine on the theme “Will we ever have a useful quantum computer?”. I’m aware of your work on the problems with noise, and your position that error correction won’t be possible.</b></span></p>
<p>This is correct. My analysis asserts that quality error correction won’t be possible and that even the easier target of <span class="il">HQCA</span> (huge quantum computational advantage) won’t be possible. Here is a <a href="https://arxiv.org/abs/2008.05188">link</a> to my new paper that you may find useful. It refers to recent developments: the Google Sycamore experiment and <span class="il">HQCA</span> claims are discussed in Sections 6 and 7, and there is a new Section 9 regarding the very recent developments.</p>
<p><b>I was wondering whether anything you’ve seen – demonstrations or arguments – in the last few months have done anything to change your mind, or whether you are now more convinced than ever that we won’t ever see truly useful (beyond doing science) quantum computing?  </b></p>
<p>Well, I think that my theory is rather strong but not ironclad. As for the level of my conviction, it does not change often, but roughly speaking there were three stages to my research (and level of conviction):</p>
<p>1) 2005-2013.   What I did was (in hindsight) exploring consequences of the failure of quantum fault tolerance and, on the way, some mistakes in the logic of firmly believing that quantum computers could be built. But, as I often said at that time, I did not think my work then gave a reason for people to change their a priori beliefs.</p>
<p>2) 2013-2019.  Following my work with Guy Kindler I saw a clear scientific argument for why quantum computers will fail. (We first considered the special case of boson sampling and later I extended it in  greater generality.) Since that time, I regard my argument to be strong enough to change people a priori beliefs, and my level of conviction went up as well. But, as I said, it is not an ironclad argument.</p>
<p>3) 2019 – onward.  The experimental claims by Google and later by a group from Hefei, China would, if correct, refute my argument. So, naturally, this casts some doubts also in my mind. However, there are good technical reasons to doubt the fantastic claims by the Hefei group, and on that matter actually my 2014 paper with Kindler comes to play. The situation with the Google experiment is more delicate, but there are reasons to doubt their experimental claims as well.</p>
<p>As for a priori beliefs: In my view the situation is that it is hard to believe that quantum computers are not possible, but it is even harder to believe that quantum computers are possible <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/> . So much experimental and theoretical research is needed before humankind will crack this puzzle.</p>
<p><span class="im"><b>Also, I was wondering if the retraction of the main paper about creating Majorana fermions (<a href="https://www.nature.com/articles/d41586-021-00612-z" rel="noopener" target="_blank">https://www.nature.com/articles/d41586-021-00612-z</a>) kills topological computing’s hopes of getting us there?</b></span></p>
<p>No, the retraction of a single paper does not kill at all topological computing’s hopes. In fact, the researchers who found the mistake are hopeful that a successful experiment of that kind is possible and are also hopeful regarding further experimental steps towards topological quantum computing.</p>
<p>My general argument does extend to topological quantum computing and asserts that stable topological qubits are not possible.</p>
<p>Thanks for your interest and best wishes,  Gil Kalai</p>
<p><strong>Additional comments:</strong> The (very nice) <a href="https://www.scientiststudy.com/2021/09/why-it-might-be-impossible-to-build.html">article appeared in August 2021</a> and (accurately) refers to my position: “Gil Kalai, a mathematician at the Hebrew University of Jerusalem in Israel, argued that the basic noise level in a quantum computer will always be too high, no matter how many qubits are available. ‘My analysis says that correcting quality errors will not be possible.’ ” The article quotes also <a href="https://researchportal.helsinki.fi/en/persons/sabrina-maniscalco/publications/">Sabrina Maniscalco</a> from the University of Helsinki in Finland who said: “Finding a cure for the effect of environmental noise is not only, in my opinion, a technological problem, but more conceptual and fundamental. I would say that I am optimistic, rather than confident”.</p>
<p>My debate with Aram Harrow over GLL <a href="https://rjlipton.wpcomstaging.com/2012/01/30/perpetual-motion-of-the-21st-century/">started ten years ago</a>. A lot has happened in these ten years! (Here is a <a href="https://rjlipton.wpcomstaging.com/2012/01/30/perpetual-motion-of-the-21st-century/#comment-18029">comment</a> from the debate on my assessment of the situation at that time.)</p>
<p>The researchers who took on themselves the thankless task of putting the Microsoft Majorana claims under scrutiny and found the mistakes are <a href="https://www.physicsandastronomy.pitt.edu/people/sergey-frolov" rel="noopener" target="_blank">Sergey Frolov</a> and <a href="https://www.fqt.unsw.edu.au/staff/vincent-mourik-0" rel="noopener" target="_blank">Vincent Mourik</a>. (See also <a href="https://www.nature.com/articles/d41586-021-00954-8">Frolov’s commentary</a> in “Nature” and <a href="https://www.quantamagazine.org/major-quantum-computing-strategy-suffers-serious-setbacks-20210929/">this article</a> in “Quanta Magazine”.) They drew important conclusions for the need of sharing raw data and other experimental details for such experiments.</p>
<p>For more details:  on my view regarding quantum computers see <a href="https://gilkalai.wordpress.com/2020/12/29/the-argument-against-quantum-computers-a-very-short-introduction/" rel="bookmark">The Argument Against Quantum Computers – A Very Short Introduction</a> (December 2020); and on Google’s supremacy experiment see <a href="https://gilkalai.wordpress.com/2019/11/13/gils-collegial-quantum-supremacy-skepticism-faq/" rel="bookmark">Gil’s Collegial Quantum Supremacy Skepticism FAQ</a> (November 2019).</p></div>
    </content>
    <updated>2022-02-10T09:57:23Z</updated>
    <published>2022-02-10T09:57:23Z</published>
    <category term="Computer Science and Optimization"/>
    <category term="Quantum"/>
    <category term="Aram Harrow"/>
    <category term="Michael Brooks"/>
    <category term="Quantum computers"/>
    <category term="Sabrina Maniscalco"/>
    <category term="Sergey Frolov"/>
    <category term="Vincent Mourik"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2022-02-15T08:37:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/10/postdoc-positions-in-algorithms-complexity-at-university-of-california-san-diego-apply-by-march-31-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/10/postdoc-positions-in-algorithms-complexity-at-university-of-california-san-diego-apply-by-march-31-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc Positions in Algorithms &amp; Complexity at University of California San Diego (apply by March 31, 2022)</title>
    <summary>Multiple postdoc positions available at UCSD Theory group to work on graph algorithms, randomized and approximation algorithms, fine-grained complexity, and additive combinatorics. Apply directly to barnas@ucsd.edu. Must include your resume, and contact information of three reference writers. Website: https://cstheory.ucsd.edu/home.html Email: barnas@ucsd.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Multiple postdoc positions available at UCSD Theory group to work on graph algorithms, randomized and approximation algorithms, fine-grained complexity, and additive combinatorics. Apply directly to barnas@ucsd.edu. Must include your resume, and contact information of three reference writers.</p>
<p>Website: <a href="https://cstheory.ucsd.edu/home.html">https://cstheory.ucsd.edu/home.html</a><br/>
Email: barnas@ucsd.edu</p></div>
    </content>
    <updated>2022-02-10T08:02:51Z</updated>
    <published>2022-02-10T08:02:51Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-15T08:37:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=595</id>
    <link href="https://tcsplus.wordpress.com/2022/02/09/tcs-talk-wednesday-february-23-merav-parter-weizmann-institute-of-science/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, February 23 — Merav Parter, Weizmann Institute of Science</title>
    <summary>The first TCS+ talk of 2022 will take place on Wednesday, February 23rd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Merav Parter from Weizmann Institute of Science will speak about “New Diameter Reducing Shortcuts: Breaking the Barrier” (abstract below). You can reserve a spot as an individual […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The first TCS+ talk of 2022 will take place on Wednesday, February 23rd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <a href="https://www.weizmann.ac.il/math/parter/home"><strong>Merav Parter</strong></a> from Weizmann Institute of Science will speak about “<em>New Diameter Reducing Shortcuts: Breaking the <img alt="O(\sqrt{n})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7Bn%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> Barrier</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: For an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-vertex digraph <img alt="G=(V,E)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3D%28V%2CE%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>, a <em>shortcut set</em> is a (small) subset of edges <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> taken from the transitive closure of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> that, when added to <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> guarantees that the diameter of <img alt="G \cup H" class="latex" src="https://s0.wp.com/latex.php?latex=G+%5Ccup+H&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> is small. Shortcut sets, introduced by Thorup in 1993, have a wide range of applications in algorithm design, especially in the context of parallel, distributed and dynamic computation on directed graphs. A folklore result in this context shows that every <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-vertex digraph admits a shortcut set of linear size (i.e., of <img alt="O(n)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> edges) that reduces the diameter to <img alt="\widetilde{O}(\sqrt{n})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BO%7D%28%5Csqrt%7Bn%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>. Despite extensive research over the years, the question of whether one can reduce the diameter to <img alt="o(\sqrt{n})" class="latex" src="https://s0.wp.com/latex.php?latex=o%28%5Csqrt%7Bn%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> with <img alt="\widetilde{O}(n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BO%7D%28n%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> shortcut edges has been left open.</p>
<p>In this talk, I will present the first improved diameter-sparsity tradeoff for this problem, breaking the <img alt="\sqrt{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bn%7D&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> diameter barrier. Specifically, we show an <img alt="O(n^{\omega})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28n%5E%7B%5Comega%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-time randomized algorithm for computing a linear shortcut set that reduces the diameter of the digraph to <img alt="\widetilde{O}(n^{1/3})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BO%7D%28n%5E%7B1%2F3%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>. We also extend our algorithms to provide improved <img alt="(\beta,\epsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cbeta%2C%5Cepsilon%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/> hopsets for <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>-vertex weighted directed graphs.</p>
<p>Joint work with Shimon Kogan.</p></blockquote></div>
    </content>
    <updated>2022-02-10T04:08:49Z</updated>
    <published>2022-02-10T04:08:49Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2022-02-15T08:38:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://ptreview.sublinear.info/?p=1622</id>
    <link href="https://ptreview.sublinear.info/2022/02/news-for-january-2021-2/" rel="alternate" type="text/html"/>
    <title>News for January 2022</title>
    <summary>A slow month to start 2022, as far as property testing (and myself) are concerned — “only” 3 papers, and a delay of several days in posting this. Let’s jump in with quantum testing! Testing matrix product states, by Mehdi Soleimanifar and John Wright (arXiv). Suppose you are given a state \(|\psi\rangle\) of \(n\) qubits, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A slow month to start 2022, as far as property testing (and myself) are concerned — “only” 3 papers, and a delay of several days in posting this. Let’s jump in with quantum testing!</p>



<p><strong>Testing matrix product states</strong>, by Mehdi Soleimanifar and John Wright (<a href="https://arxiv.org/abs/2201.01824">arXiv</a>). Suppose you are given a state \(|\psi\rangle\) of \(n\) qubits, and want to know “how entangled” this whole thing is: for instance, is \(|\psi\rangle\) a product state (no entanglement between the \(n\) qudits)? More generally, the “amount of entanglement” allowed is captured by an integer \(r\), the<em> bond dimension</em>, where product state corresponds to \(r=1\), and larger \(r\) allows for more entanglement. This paper then considers the following property testing question: how many copies of \(|\psi\rangle\) are needed to test whether it has bond dimension at most \(r\), or is \(\varepsilon\)-far from every such state (in trace distance)? While the case \(r=1\) had been previously considered, this paper considers the general case; and, in particular, shows a qualitative gap between \(r=1\) (for which a constant number of copies, \(O(1/\varepsilon^2)\), suffice) and \(r\geq 2\) (for which they show the number of states is \(\Omega(\sqrt{n}/\varepsilon^2)\), and \(O(n r^2/\varepsilon^2)\)).</p>



<p><strong>Constant-time one-shot testing of large-scale graph states</strong>, by Hayata Yamasaki and Sathyawageeswar Subramanian (<a href="https://arxiv.org/abs/2201.11127">arXiv</a>). In this paper, the authors consider the task of testing if the physical error rate of a given system is below a given threshold — namely, the threshold below which fault-tolerant measurement-based quantum computation (MBQC) becomes feasible. Casting this into the framework of property testing, the paper shows that measuring very few (a constant number!) of the input state is enough to test whether the error rate is low.</p>



<p>And, to conclude, a paper which escaped us in December, on private distribution testing:</p>



<p><strong>Pure Differential Privacy from Secure Intermediaries</strong>, by Albert Cheu and Chao Yan (<a href="https://arxiv.org/abs/2112.10032">arXiv</a>). Throwback to <a href="https://ptreview.sublinear.info/2020/05/news-for-april-2020/">April 2020</a> and <a href="https://ptreview.sublinear.info/2021/09/news-for-august-2021/">August 2021</a>, which covered results on distribution testing (uniformity testing!) under the <em>shuffle model</em> of differential privacy. Namely, there was an upper bound of $$ O( k^{2/3}/(\alpha^{4/3}\varepsilon^{2/3})\log^{1/3}(1/\delta) + k^{1/2}/(\alpha\varepsilon) \log^{1/2}(1/\delta) + k^{1/2}/\alpha^2)$$ samples for testing uniformity of distributions over \([k]\), to distance \(\alpha\), under \((\varepsilon,\delta)\)<em>–</em>shuffle privacy (so, <em>approximate</em> privacy: \(\delta&gt;0\)). A partial lower bound existed for <em>pure</em> differential privacy, i.e., when \(\delta=0\): however, no upper bound was known for pure shuffle privacy.<br/>Until now: this new paper shows that pure DP basically comes at no cost, by providing an \((\varepsilon,0)\)-shuffle private testing algorithm with sample complexity $$ O( k^{2/3}/(\alpha^{4/3}\varepsilon^{2/3}) + k^{1/2}/(\alpha\varepsilon) + k^{1/2}/\alpha^2)$$ The paper actually does a lot more, focusing on a different problem, private summation; and the testing upper bound is a corollary of the new methods they develop in the process.</p></div>
    </content>
    <updated>2022-02-09T07:05:07Z</updated>
    <published>2022-02-09T07:05:07Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Clement Canonne</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2022-02-14T22:49:17Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-72814287285807577</id>
    <link href="http://blog.computationalcomplexity.org/feeds/72814287285807577/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/a-book-break.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/72814287285807577" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/72814287285807577" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/a-book-break.html" rel="alternate" type="text/html"/>
    <title>A Book Break</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I got the writing bug back while working on my <a href="https://cacm.acm.org/magazines/2022/1/257448-fifty-years-of-p-vs-np-and-the-possibility-of-the-impossible/fulltext">recent CACM article</a> and I'd like to try my hand at another book. Not sure the exact topic but something related to the changing nature of computing and its implications. </p><p>I'll cut down my blogging for a while. I'll still post or tweet when I have something I want to say. Bill will continue to post regularly and keep this blog active.</p><p>Bill asked me if I have time to write this book as dean but he already knew the answer. Writing keeps me sane in a world that seems less and less so.</p></div>
    </content>
    <updated>2022-02-08T23:00:00Z</updated>
    <published>2022-02-08T23:00:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-14T13:32:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/08/postdoc-in-quantum-algorithms-at-university-of-latvia-at-centre-for-quantum-computer-science-university-of-latvia-apply-by-march-1-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/08/postdoc-in-quantum-algorithms-at-university-of-latvia-at-centre-for-quantum-computer-science-university-of-latvia-apply-by-march-1-2022/" rel="alternate" type="text/html"/>
    <title>postdoc in quantum algorithms at University of Latvia at Centre for Quantum Computer Science, University of Latvia (apply by March 1, 2022)</title>
    <summary>Applications are invited for a postdoctoral position at the Centre for Quantum Computer Science (CQCS), University of Latvia, lead by prof. Andris Ambainis. We are looking for candidates who would be interested in quantum algorithms (with background in either quantum information or classical TCS.) The appointment would be for 2 years, starting between September 1, […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a postdoctoral position at the Centre for Quantum Computer Science (CQCS), University of Latvia, lead by prof. Andris Ambainis. We are looking for candidates who would be interested in quantum algorithms (with background in either quantum information or classical TCS.) The appointment would be for 2 years, starting between September 1, 2022 and January 1, 2023.</p>
<p>Website: <a href="https://quantum.lu.lv/join-us/">https://quantum.lu.lv/join-us/</a><br/>
Email: ambainis@lu.lv</p></div>
    </content>
    <updated>2022-02-08T18:16:56Z</updated>
    <published>2022-02-08T18:16:56Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-15T08:37:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/014</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/014" rel="alternate" type="text/html"/>
    <title>TR22-014 |  Tighter MA/1 Circuit Lower Bounds From Verifier Efficient PCPs for PSPACE | 

	Joshua Cook, 

	Dana Moshkovitz</title>
    <summary>We prove for some constant $a &gt; 1$, for all $k \leq a$,
$$\mathbf{MATIME}[n^{k + o(1)}] / 1 \not \subset \mathbf{SIZE}[O(n^{k})],$$
for some specific $o(1)$ function. This improves on the Santhanam lower bound, which says there exists constant $c$ such that for all $k &gt; 1$:
$$\mathbf{MATIME}[n^{c k}] / 1 \not \subset \mathbf{SIZE}[O(n^{k})].$$
There is inherently no upper bound on $c$ in Santhanam's proof. Using ideas from Murray and Williams, all $k &gt; 1$:
$$\mathbf{MATIME}[n^{10 k^2}] / 1 \not \subset \mathbf{SIZE}[O(n^{k})].$$
    
Our proof uses a new, very efficient $\mathbf{PCP}$ for $\mathbf{PSPACE}$. We construct a $\mathbf{PCP}$ with unbounded proof length for $\mathbf{SPACE}[O(n)]$ that has a $\tilde{O}(n)$ time verifier, $\tilde{O}(n)$ space prover, $O(\log(n))$ queries, and polynomial alphabet size. Prior to this work, $\mathbf{PCP}$s for $\mathbf{SPACE}[O(n)]$ either used $\Omega(n)$ queries or had verifiers that run in $\Omega(n^2)$ time.</summary>
    <updated>2022-02-08T14:57:45Z</updated>
    <published>2022-02-08T14:57:45Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-15T08:37:20Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6817129401606575319</id>
    <link href="http://blog.computationalcomplexity.org/feeds/6817129401606575319/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/pspace-is-contained-in-zero-knowledge.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6817129401606575319" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6817129401606575319" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/pspace-is-contained-in-zero-knowledge.html" rel="alternate" type="text/html"/>
    <title>PSPACE is contained in Zero Knowledge!! How come nobody seems to care?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>(This post was inspired by Lance's post on Zero Knowledge, <a href="https://blog.computationalcomplexity.org/2022/02/the-beginnings-of-zero-knowledge.html">here</a>, which was inspired by a video he has in the post which was inspired by... (I think this ordering is well founded.))</p><p> ZK= Zero Knowledge.</p><p>When it was shown that NP \subseteq ZK this was a big deal. This was by Goldreich-Micali-Wigderson  (see <a href="https://dl.acm.org/doi/10.1145/116825.116852">her</a>e (FOCS-1986, JACM-1991). In the JACM paper they have the following passage:</p><div><blockquote>Our result that all languages in NP have zero-knowledge proof systems, has been extended to IP, assuming the same assumptions. (The result was first proved by Impagliazzo and Yung, but since their paper [53] contains only a claim of the result, the interested reader is directed to [11] where a (different proof) appears.) In other words, whatever can be efficiently proven can be efficiently proven in a zero-knowledge manner. This may be viewed as the best result possible, since only languages having interactive proof systems can have zero-knowledge interactive proof systems.<br/><br/>11. BEN-OR, M., GOLDREICH, O., GOLDWASSER, S., HASTAD, J., KILLIAN, J., MICALI, S,,  AND ROGAWAY, P. Everything provable is provable in zero-knowledge. In Proceedings of Advances in Cryptology— Crypto88. Lecture Notes in Computer Science, vol. 403. Springer-Verlag, New York, 1990, pp. 37-56.<br/><br/>53.IMPAGLIAZZO. R., AND YUNG, M. Direct minimum-knowledge computations. In C. Pomerance, ed., Proceedings of Advances in Cryptology— Crypto87. Lecture Notes in Computer Science, vol. 293. Springer-Verlag, New York, 1987, pp. 40-51.</blockquote>Later the papers of Lund-Fortnow-Karloff-Nisan and Shamir showed IP=PSPACE. Hence<br/><br/><div style="text-align: center;">PSPACE \subseteq ZK</div><p>When I realized this I thought OH, that's interesting! I then looked around the web and could not find any mention of it. I asked Lance and some people in crypto and yeah, they all knew it was true, but nobody seemed to care.</p><p>Why the apathy? Speculation:</p><p>1) ZK is a notion people actually want to use in real crypto (and there has been some progress on that lately). The prover for ZK in PSPACE has to be way to powerful to be practical. I don't really like this explanation since we are talking about theorists. Even in crypto, which has more of a connection to the real works then, say, Ramsey Theory, there are still plenty of non-useful results. </p><p>2) IP=PSPACE was the big news and  had interesting proof with nice ideas. Nothing crypto-ish about it. So the corollary that PSPACE \subseteq ZK is an afterthought. </p><p>3) SAT in ZK was big news. IP in ZK is nice, but uses mostly the same ideas.</p><p>4) I am WRONG- it is a celebrated result and I somehow missed the celebration.</p><p>5) The proof that ZK is in PSPACE USES two interesting results, but adds NOTHING to the mix. In short, the proof is to easy.</p><p>Any other ideas?</p></div></div>
    </content>
    <updated>2022-02-06T20:19:00Z</updated>
    <published>2022-02-06T20:19:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-14T13:32:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6288</id>
    <link href="https://scottaaronson.blog/?p=6288" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6288#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6288" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">AlphaCode as a dog speaking mediocre English</title>
    <summary xml:lang="en-US">Tonight, I took the time actually to read DeepMind’s AlphaCode paper, and to work through the example contest problems provided, and understand how I would’ve solved those problems, and how AlphaCode solved them. It is absolutely astounding. Consider, for example, the “n singers” challenge (pages 59-60). To solve this well, you first need to parse […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Tonight, I took the time actually to read DeepMind’s <a href="https://storage.googleapis.com/deepmind-media/AlphaCode/competition_level_code_generation_with_alphacode.pdf">AlphaCode paper</a>, and to work through the example contest problems provided, and understand how I would’ve solved those problems, and how AlphaCode solved them.</p>



<p>It is absolutely astounding.</p>



<p>Consider, for example, the “n singers” challenge (pages 59-60). To solve this well, you first need to parse a somewhat convoluted English description, discarding the irrelevant fluff about singers, in order to figure out that you’re being asked to find a positive integer solution (if it exists) to a linear system whose matrix looks like<br/>1 2 3 4<br/>4 1 2 3<br/>3 4 1 2<br/>2 3 4 1.<br/>Next you need to find a trick for solving such a system without Gaussian elimination or the like (I’ll leave that as an exercise…). Finally, you need to generate code that implements that trick, correctly handling the wraparound at the edges of the matrix, and breaking and returning “NO” for any of multiple possible reasons why a positive integer solution won’t exist.   Oh, and also correctly parse the input.</p>



<p>Yes, I realize that AlphaCode generates a million candidate programs for each challenge, then discards the vast majority by checking that they don’t work on the example data provided, then <em>still</em> has to use clever tricks to choose from among the thousands of candidates remaining. I realize that it was trained on tens of thousands of contest problems and millions of solutions to those problems. I realize that it “only” solves about a third of the contest problems, making it similar to a mediocre human programmer on these problems. I realize that it works only in the artificial domain of programming contests, where a complete English problem specification and example inputs and outputs are always provided.</p>



<p>Forget all that. Judged against where AI was 20-25 years ago, when I was a student, a dog is now holding meaningful conversations in English. And people are complaining that the dog isn’t a very eloquent orator, that it often makes grammatical errors and has to start again, that it took heroic effort to train it, and that it’s unclear how much the dog really understands.</p>



<p>It’s not obvious how you go from solving programming contest problems to conquering the human race or whatever, but I feel pretty confident that we’ve now entered a world where “programming” will look different.</p>



<p><strong>Update:</strong> A colleague of mine points out that one million, the number of candidate programs that AlphaCode needs to generate, could be seen as roughly exponential in the number of lines of the generated programs.  If so, this suggests a perspective according to which DeepMind has created almost the exact equivalent, in AI code generation, of a non-fault-tolerant quantum computer that’s nevertheless competitive on some task (as in the quantum supremacy experiments). I.e., it clearly does something highly nontrivial, but the “signal” is still decreasing exponentially with the number of instructions, necessitating an exponential number of repetitions to extract the signal and imposing a limit on the size of the programs you can scale to.</p></div>
    </content>
    <updated>2022-02-06T09:12:13Z</updated>
    <published>2022-02-06T09:12:13Z</published>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <category scheme="https://scottaaronson.blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-02-14T19:44:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/013</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/013" rel="alternate" type="text/html"/>
    <title>TR22-013 |  On properties that are non-trivial to test | 

	Nader Bshouty, 

	Oded Goldreich</title>
    <summary>In this note we show that all sets that are neither finite nor too dense are non-trivial to test in the sense that, for every $\epsilon&gt;0$, distinguishing between strings in the set and strings that are $\epsilon$-far from the set requires $\Omega(1/\epsilon)$ queries. 
Specifically, we show that if, for infinitely many $n$'s, the set contains at least one $n$-bit long string and at most $2^{n-\Omega(n)}$ many $n$-bit strings, then it is non-trivial to test.</summary>
    <updated>2022-02-05T16:37:06Z</updated>
    <published>2022-02-05T16:37:06Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-15T08:37:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/05/assistant-professor-at-linkoping-university-at-department-of-computer-and-information-science-apply-by-march-1-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/05/assistant-professor-at-linkoping-university-at-department-of-computer-and-information-science-apply-by-march-1-2022/" rel="alternate" type="text/html"/>
    <title>Assistant professor at Linköping University at Department of Computer and Information Science (apply by March 1 , 2022)</title>
    <summary>Linköping University announces an assistant professor position in computer science that focuses on the borderland between theoretical computer science, mathematics, and artificial intelligence. Website: https://liu.se/en/work-at-liu/vacancies?rmpage=job&amp;rmjob=18113&amp;rmlang=UK Email: peter.jonsson@liu.se</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Linköping University announces an assistant professor position in computer science<br/>
that focuses on the borderland between theoretical computer science, mathematics, and artificial intelligence.</p>
<p>Website: <a href="https://liu.se/en/work-at-liu/vacancies?rmpage=job&amp;rmjob=18113&amp;rmlang=UK">https://liu.se/en/work-at-liu/vacancies?rmpage=job&amp;rmjob=18113&amp;rmlang=UK</a><br/>
Email: peter.jonsson@liu.se</p></div>
    </content>
    <updated>2022-02-05T15:39:01Z</updated>
    <published>2022-02-05T15:39:01Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-15T08:37:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6256</id>
    <link href="https://scottaaronson.blog/?p=6256" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6256#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6256" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Scott Aaronson Speculation Grant WINNERS!</title>
    <summary xml:lang="en-US">Two weeks ago, I announced on this blog that, thanks to the remarkable generosity of Jaan Tallinn, and the Speculation Grants program of the Survival and Flourishing Fund that Jaan founded, I had $200,000 to give away to charitable organizations of my choice. So, inspired by what Scott Alexander had done, I invited the readers […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Two weeks ago, I <a href="https://scottaaronson.blog/?p=6232">announced</a> on this blog that, thanks to the remarkable generosity of Jaan Tallinn, and the Speculation Grants program of the <a href="https://survivalandflourishing.fund/">Survival and Flourishing Fund</a> that Jaan founded, I had $200,000 to give away to charitable organizations of my choice.  So, inspired by what Scott Alexander had <a href="https://astralcodexten.substack.com/p/acx-grants-results">done</a>, I invited the readers of <em>Shtetl-Optimized</em> to pitch their charities, mentioning only some general areas of interest to me (e.g., advanced math education at the precollege level, climate change mitigation, pandemic preparedness, endangered species conservation, and any good causes that would enrage the people who attack me on Twitter).</p>



<p>I’m grateful to have gotten more than twenty well-thought-out pitches; you can read a subset of them in the <a href="https://scottaaronson.blog/?p=6232#comments">comment thread</a>.  Now, having studied them all, I’ve decided—as I hadn’t at the start—to use my entire allotment to make as strong a statement as I can about a single cause: namely, <strong>subject-matter passion and excellence in precollege STEM education</strong>.</p>



<p>I’ll be directing funds to some shockingly cash-starved math camps, math circles, coding outreach programs, magnet schools, and enrichment programs, in Maine and Oregon and England and Ghana and Ethiopia and Jamaica.  The programs I’ve chosen target a variety of ability levels, not merely the “mathematical elite.”  Several explicitly focus on minority and other underserved populations.  But they share a goal of raising every student they work with as high as possible, rather than pushing the students down to fit some standardized curriculum.</p>



<p>Language like that ought to be meaningless boilerplate, but alas, it no longer is.  We live in a time when the state of California, in a misguided pursuit of “modernization” and “equity,” is <a href="https://sites.google.com/view/k12mathmatters/home">poised</a> to eliminate 8th-grade algebra, make it nearly impossible for high-school seniors to take AP Calculus, and shunt as many students as possible from serious mathematical engagement into a “data science pathway” that in practice might teach little more than how to fill in spreadsheets.  (This watering-down effort now <em>itself</em> looks liable to be watered down—but only because of a furious pushback from parents and STEM professionals, pushback in which I’m proud that this blog <a href="https://scottaaronson.blog/?p=6146">played a small role</a>.)  We live in a time when elite universities are racing to eliminate the SAT—thus, for all their highminded rhetoric, effectively slamming the door on thousands of nerdy kids from poor or immigrant backgrounds who know how to think, but not how to shine in a college admissions popularity pageant.  We live in a time when America’s legendary STEM magnet high schools, from Thomas Jefferson in Virginia to Bronx Science to Lowell in San Francisco, rather than being celebrated as the national treasures that they are, or better yet replicated, are bitterly attacked as “elitist” (even while competitive sports and music programs are not similarly attacked)—and are now being forcibly “demagnetized” by bureaucrats, made all but indistinguishable from other high schools, over the desperate pleas of their students, parents, and alumni.</p>



<p>And—alright, fine, on a global scale, arresting climate change is surely a higher-priority issue than protecting the intellectual horizons of a few teenage STEM nerds.  The survival of liberal democracy is a higher-priority issue.  Pandemic preparedness, poverty, malnutrition are higher-priority issues.  Some of my friends strongly believe that <em>the danger of AI becoming super-powerful and taking over the world</em> is the highest-priority issue … and truthfully, with this week’s announcements of <a href="https://deepmind.com/blog/article/Competitive-programming-with-AlphaCode">AlphaCode</a> and <a href="https://openai.com/blog/formal-math/">OpenAI’s theorem prover</a>, which achieve human-competitive performance in elite programming and math competitions respectively, I can’t confidently declare that they’re wrong.</p>



<p>On the other hand, when you think about the astronomical returns on every penny that was invested in setting a teenage Ramanujan or Einstein or Turing or Sofya Kovalevskaya or Norman Borlaug or Mario Molina onto their trajectories in life … and the comically tiny budgets of the world-leading programs that aim to nurture the <em>next</em> Ramanujans, to the point where $10,000 often seems like a windfall to those programs … well, you might come to the conclusion that the “protecting nerds” thing actually isn’t <em>that</em> far down the global priority list!  Like, it probably cracks the top ten.</p>



<p>And there’s more to it than that.  There’s a reason beyond parochialism, it dawned on me, why individual charities tend to specialize in wildlife conservation in Ecuador or deworming in Swaziland or some other little domain, rather than simply casting around for the highest-priority cause on earth.  <em>Expertise matters</em>—since one wants to make, not only good judgments about which stuff to support, but good judgments that most others can’t or haven’t made.  In my case, it would seem sensible to leverage the fact that I’m Scott Aaronson.  I’ve spent much of my career in math/CS education and outreach—mostly, of course, at the university level, but <em>by god</em> did I personally experience the good and the bad in nearly every form of precollege STEM education!  I’m pretty confident in my ability to distinguish the two, and for whatever I don’t know, I have close friends in the area who I trust.</p>



<p>There’s also a practical issue: in order for me to fund something, the recipient has to fill out a somewhat time-consuming application to SFF.  If I’d added, say, another $20,000 drop into the bucket of global health or sustainability or whatever, there’s no guarantee that the intended recipients of my largesse would even notice, or care enough to go through the application process if they did.  With STEM education, by contrast, holy crap!  I’ve got an inbox full of <em>Shtetl-Optimized</em> readers explaining how their little math program is an intellectual oasis that’s changed the lives of hundreds of middle-schoolers in their region, and how $20,000 would mean the difference between their program continuing or not.  <em>That’s</em> someone who I trust to fill out the form.</p>



<p>Without further ado, then, here are the first-ever Scott Aaronson Speculation Grants:</p>



<ul><li>$57,000 for <a href="https://www.mathcamp.org/">Canada/USA Mathcamp</a>, which changed my life when I attended it as a 15-year-old in 1996, and which I returned to as a lecturer in 2008.  The funds will be used for COVID testing to allow Mathcamp to resume in-person this summer, and perhaps scholarships and off-season events as well.</li><li>$30,000 for <a href="https://www.addiscoder.com/">AddisCoder</a>, which has had spectacular success teaching computer science to high-school students in Ethiopia, placing some of its alumni at elite universities in the US, to help them expand to a new “JamCoders” program in Jamaica.  These programs were founded by UC Berkeley’s amazing <a href="https://en.wikipedia.org/wiki/Jelani_Nelson">Jelani Nelson</a>, also with involvement from friend and <em>Shtetl-Optimized</em> semi-regular <a href="https://en.wikipedia.org/wiki/Boaz_Barak">Boaz Barak</a>.</li><li>$30,000 for the <a href="https://www.mssm.org/">Maine School of Science and Mathematics</a>, which seems to offer a curriculum comparable to those of Thomas Jefferson, Bronx Science, or the nation’s other elite magnet high schools, but (1) on a shoestring budget and (2) in rural Maine.  I hadn’t even heard of MSSM before Alex Altair, an alum and <em>Shtetl-Optimized</em> reader, told me about it, but now I couldn’t be prouder to support it.</li><li>$30,000 for the <a href="https://pages.uoregon.edu/nemirovm/emc.html">Eugene Math Circle</a>, which provides a math enrichment lifeline to kids in Oregon, and whose funding was just cut.  This donation will keep the program alive for another year.</li><li>$13,000 for the <a href="https://summerscience.org/">Summer Science Program</a>, which this summer will offer research experiences to high-school juniors in astrophysics, biochemistry, and genomics.</li><li>$10,000 for the <a href="https://misemaths.wordpress.com/">MISE Foundation</a>, which provides math enrichment for the top middle- and high-school students in Ghana.</li><li>$10,000 for <a href="https://www.numberchampions.org.uk/">Number Champions</a>, which provides one-on-one coaching to kids in the UK who struggle with math.</li><li>$10,000 for <a href="https://www.beammath.org/">Bridge to Enter Advanced Mathematics (BEAM)</a>, which runs math summer programs in New York, Los Angeles, and elsewhere for underserved populations.</li><li>$10,000 for <a href="https://powderhouse.org/">Powderhouse</a>, an innovative lab school being founded in Somerville, MA.</li></ul>



<p>While working on this, it crossed my mind that, on my deathbed, I might be at least as happy about having directed funds to efforts like these as about any of my research or teaching.</p>



<p>To the applicants who weren’t chosen: I’m sorry, as many of you had wonderful projects too!  As I said in the earlier post, you remain warmly invited to apply to SFF, and to make your pitch to the other Speculators and/or the main SFF committee.</p>



<p>Needless to say, anyone who feels inspired should add to my (or rather, SFF’s) modest contributions to these STEM programs.  My sense is that, while $200k can go eye-poppingly far in this area, it still hasn’t come <em>close</em> to exhausting even the lowest-hanging fruit.</p>



<p>Also needless to say, the opinions in this post are my own and are not necessarily shared by SFF or by the organizations I’m supporting.  The latter are welcome to disagree with me as long as they keep up their great work!</p>



<p>Huge thanks again to Jaan, to SFF, to my SFF contact Andrew Critch, to everyone (whether chosen or not) who participated in this contest, and to everyone who’s putting in work to broaden kids’ intellectual horizons or otherwise make the world a little less horrible.</p></div>
    </content>
    <updated>2022-02-04T17:26:02Z</updated>
    <published>2022-02-04T17:26:02Z</published>
    <category scheme="https://scottaaronson.blog" term="Announcements"/>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <category scheme="https://scottaaronson.blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-02-14T19:44:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/04/postdoc-at-lip-ens-lyon-apply-by-march-1-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/04/postdoc-at-lip-ens-lyon-apply-by-march-1-2022/" rel="alternate" type="text/html"/>
    <title>postdoc at LIP, ENS Lyon (apply by March 1, 2022)</title>
    <summary>A postdoctoral position in Computer Science is available at LIP, ENS Lyon. Details on the website. Website: http://perso.ens-lyon.fr/edouard.bonnet/postdocOffer.html Email: edouard.bonnet@ens-lyon.fr</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A postdoctoral position in Computer Science is available at LIP, ENS Lyon. Details on the website.</p>
<p>Website: <a href="http://perso.ens-lyon.fr/edouard.bonnet/postdocOffer.html">http://perso.ens-lyon.fr/edouard.bonnet/postdocOffer.html</a><br/>
Email: edouard.bonnet@ens-lyon.fr</p></div>
    </content>
    <updated>2022-02-04T16:59:38Z</updated>
    <published>2022-02-04T16:59:38Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-15T08:37:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/04/phd-privacy-by-design-computing-for-iot-data-at-graduate-school-of-technical-sciences-aarhus-university-denmark-apply-by-march-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/04/phd-privacy-by-design-computing-for-iot-data-at-graduate-school-of-technical-sciences-aarhus-university-denmark-apply-by-march-15-2022/" rel="alternate" type="text/html"/>
    <title>Phd – Privacy-by-design Computing for IoT data at Graduate School of Technical Sciences, Aarhus University, Denmark (apply by March 15, 2022)</title>
    <summary>Applications are invited for a PhD fellowship/scholarship at Graduate School of Technical Sciences, Aarhus University, Denmark, within the Electrical and Computer Engineering programme. The position is available from 1 May 2022 or later. Website: https://phd.tech.au.dk/for-applicants/apply-here/saeropslag/privacy-by-design-computing-for-iot-data/ Email: daniel.lucani@ece.au.dk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a PhD fellowship/scholarship at Graduate School of Technical Sciences, Aarhus University, Denmark, within the Electrical and Computer Engineering programme. The position is available from 1 May 2022 or later.</p>
<p>Website: <a href="https://phd.tech.au.dk/for-applicants/apply-here/saeropslag/privacy-by-design-computing-for-iot-data/">https://phd.tech.au.dk/for-applicants/apply-here/saeropslag/privacy-by-design-computing-for-iot-data/</a><br/>
Email: daniel.lucani@ece.au.dk</p></div>
    </content>
    <updated>2022-02-04T09:17:46Z</updated>
    <published>2022-02-04T09:17:46Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-15T08:37:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19620</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/02/03/next-big-thing/" rel="alternate" type="text/html"/>
    <title>Next Big Thing?</title>
    <summary>Big ideas we tend to like are the ones that seem impossible or crazy—Bill Maris UW History page Margaret O’Mara is a historian at the University of Washington. She specializes in the history of Silicon Valley. Of course we are most interested in the future of Silicon Valley. Today—between history and the future—we channel her […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Big ideas we tend to like are the ones that seem impossible or crazy—Bill Maris</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/03/next-big-thing/mo/" rel="attachment wp-att-19622"><img alt="" class="alignright wp-image-19622" height="175" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/mo.png?resize=140%2C175&amp;ssl=1" width="140"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">UW History <a href="https://history.washington.edu/people/margaret-omara">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Margaret O’Mara is a <a href="https://www.margaretomara.com/">historian</a> at the University of Washington. She specializes in the history of Silicon Valley. Of course we are most interested in the future of Silicon Valley. </p>
<p>
Today—between history and the future—we channel her insights to ask what next-big-things may intersect our fields.<br/>
<span id="more-19620"/></p>
<p>
An <a href="https://www.nytimes.com/2022/01/24/technology/silicon-valley-next-big-thing.html">article</a> last week in the New York Times quotes her on recent developments:</p>
<ol>
<li>
“The age of mobile and cloud computing has created so many new business opportunities,” O’Mara said. “But now there are trickier problems.” <p/>
</li><li>
“Imagine the economic impact of the pandemic had there not been the infrastructure— the hardware and the software— that allowed so many white-collar workers to work from home and so many other parts of the economy to be conducted in a digitally mediated way”, she added.
</li></ol>
<p>
But what’s next?</p>
<p>
</p><p/><h2> The Next Big Idea? </h2><p/>
<p/><p>
The NYT article talks about the future of Silicon Valley as seen by O’Mara and other experts. The main issue is: what are the next big ideas that will come out of Silicon Valley? Big ideas are defined by ones that will change the future and generate billions if not trillions in dollars. Some possible ones are:</p>
<ol>
<li>
Self-driving cars; <p/>
</li><li>
Advanced artificial intelligence; <p/>
</li><li>
Brain implants—to control devices with only thoughts; <p/>
</li><li>
Quantum computing; <p/>
</li><li>
<img alt="{\dots ?}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots+%3F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>
</li></ol>
<p>
The article quotes Jake Taylor, the chief science officer at the quantum start-up <a href="https://www.riverlane.com">Riverlane</a>, as saying that “building a quantum computer might may be the most difficult task ever undertaken, [one that] defies the physics of everyday life.” </p>
<p/><h2> Next Big Theory Ideas? </h2><p/>
<p/><p>
I am quite interested in hearing what role complexity theory might play in creating the next big thing. If the area is quantum based then perhaps theory could play a major role. It helped start the explosion in interest in quantum computing. The famous results of Peter Shor on <a href="https://en.wikipedia.org/wiki/Shor%27s_algorithm">factoring</a> could no doubt play a major role. But the paradox is that theory does not seem to be central to thoughts on what the next big idea will be? Even if the idea is quantum based. </p>
<p>
What goal, result, breakthrough will make theory play a major role in the next <b>big idea</b>? </p>
<p>
One answer is to search the Internet. We find that Kurt Mehlhorn has had a course on the main ideas of theory. Perhaps we could imagine a direction for the next big idea based on one of these <a href="http://resources.mpi-inf.mpg.de/departments/d1/teaching/ss14/gitcs/syllabus.pdf">ideas</a> from his course:</p>
<ol>
<li>
Time vs. Space, P vs. NP, and More. <p/>
</li><li>
Interactive System, Zero Knowledge Proofs, the PCP Theorem. <p/>
</li><li>
Expander Graphs. <p/>
</li><li>
Learning Theory. <p/>
</li><li>
Streaming Algorithms. <p/>
</li><li>
Public-Key Cryptography. <p/>
</li><li>
Linear Programming. <p/>
</li><li>
Randomness in Computation. <p/>
</li><li>
Introduction to Approximation Algorithms. <p/>
</li><li>
Algorithms for Big Data. <p/>
</li><li>
Algebraic Techniques in Algorithm Design
</li></ol>
<p>
Here are the opening <a href="https://www.anilada.com/courses/15251f18/www/slides/lec1.pdf">slides</a> from a related course at CMU by Anil Ada and Bernhard Haeupler.</p>
<p>
</p><p/><h2> The Next is <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>? </h2><p/>
<p/><p>
Another idea is to search for other groups that have more directly looked at possible next ideas. For example: in 2014, a team of technical leaders from the IEEE Computer Society joined forces to write a technical report, entitled <a href="https://www.computer.org/publications/tech-news/trends/2022-report">IEEE CS 2022</a>, surveying 23 technologies that could potentially change the landscape of computer science and industry by the year 2022. By the way, 23 is special: <i>The famous Hilbert Problems are 23 in number.</i> See <a href="https://en.wikipedia.org/wiki/Hilbert%27s_problems">here</a>.</p>
<p>
Here are some of the top few that we might consider. Note we left out some that seem less special for computer science.  That leaves 14 problems.  OK, 14 is the number of Steve Smale’s problems that are fully or partly unresolved according to <a href="https://en.wikipedia.org/wiki/Smale%27s_problems">this</a>.</p>
<ol>
<li>
Security Cross-Cutting Issues The growth of large data repositories and emergence of data analytics have combined with intrusions by bad actors, governments, and corporations to open a Pandora’s box of issues. How can we balance security and privacy in this environment? <p/>
</li><li>
Sustainability Can electronic cars, LED lighting, new types of batteries and chips, and increasing use of renewables combat rising energy use and an explosion in the uptake of computing? <p/>
</li><li>
Device and Nanotechnology It is clear that MEMS devices, nanoparticles, and their use in applications are here to stay. Nanotechnology has already been useful in manufacturing sunscreen, tires, and medical devices that can be swallowed. <p/>
</li><li>
3D Integrated Circuits The transition from printed circuit boards to 3D-ICs is already underway in the mobile arena, and will eventually spread across the entire spectrum of IT products. <p/>
</li><li>
Photonics Silicon photonics will be a fundamental technology to address the bandwidth, latency, and energy challenges in the fabric of high-end systems. <p/>
</li><li>
Networking and Interconnectivity Developments at all levels of the network stack will continue to drive research and the Internet economy. <p/>
</li><li>
Software-Defined Networks OpenFlow and SDN will make networks more secure, transparent, flexible, and functional. <p/>
</li><li>
High-Performance Computing While some governments are focused on reaching exascale, some researchers are intent on moving HPC to the cloud. <p/>
</li><li>
The Internet of Things From clothes that monitor our movements to smart homes and cities, the Internet of Things knows no bounds, except for our concerns about ensuring privacy amid such convenience. <p/>
</li><li>
Natural User Interfaces The long-held dreams of computers that can interface with us through touch, gesture, and speech are finally coming true, with more radical interfaces on the horizon. <p/>
</li><li>
3D Printing 3D printing promises a revolution in fabrication, with many opportunities to produce designs that would have been prohibitively expensive. <p/>
</li><li>
Big Data and Analytics The growing availability of data and demand for its insights holds great potential to improve many data-driven decisions. <p/>
</li><li>
Machine Learning and Intelligent Systems Machine learning plays an increasingly important role in our lives, whether it’s ranking search results, recommending products, or building better models of the environment. <p/>
</li><li>
Computer Vision and Pattern Recognition Unlocking information in pictures and videos has had a major impact on consumers and more significant advances are in the pipeline.
</li></ol>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Any thoughts? Can theory play a main role in the future? </p>
<p/></font></font></div>
    </content>
    <updated>2022-02-04T04:47:33Z</updated>
    <published>2022-02-04T04:47:33Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="ideas"/>
    <category term="Margaret O'Mara"/>
    <category term="Next Big Thing"/>
    <category term="predictions"/>
    <category term="Theory"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-02-15T08:37:29Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1841700560229331052</id>
    <link href="http://blog.computationalcomplexity.org/feeds/1841700560229331052/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/the-beginnings-of-zero-knowledge.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/1841700560229331052" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/1841700560229331052" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/the-beginnings-of-zero-knowledge.html" rel="alternate" type="text/html"/>
    <title>The Beginnings of Zero-Knowledge</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Wired runs this <a href="https://www.youtube.com/playlist?list=PLibNZv5Zd0dyCoQ6f4pdXUFnpAIlKgm3N">video series</a> where topic expert explain concepts to five levels of difficulty, typically a child, teen, undergrad, grad student and expert. UCLA professor Amit Sahai <a href="https://www.youtube.com/watch?v=fOGdb1CTu5c">took this on</a> for zero-knowledge. </p><p>I'd recommend the whole thing but I'd like to focus on the last segment with USC Professor Shanghua Teng (<a href="https://youtu.be/fOGdb1CTu5c?t=1025">starts at 17:05</a>). Amit nicely summed up the importance of the paper.</p><blockquote><p>What was such a beautiful insight is that the idea of zero-knowledge being something that you can already predict. If you can already predict the answer, then you must not be gaining any knowledge by that interaction. This insight of being able to predict the future accurately, and that being an evidence of a lack of new knowledge.</p></blockquote><p>Like Shanghua I was also assigned the seminal zero-knowledge paper by Goldwasser-Micali-Rackoff from my advisor. In many ways the <a href="https://dl.acm.org/doi/10.1145/22145.22178">original STOC paper</a> was rough. The definitions were buggy, the examples uninspiring. Supposedly the paper didn't even get accepted into a conference in its first try. And yet as you read the paper you realize the potential, the beauty of not one but two new models that would go on to change both cryptography and complexity forever.</p><p>In the fall of 1985 when I started graduate school I took a cryptography class from Manuel Blum. Much of that class was spent on protocols that would convince you that, for example, a number was the product of three primes. By the spring of 1986, Goldreich, Micali and Wigderson distributed <a href="https://dl.acm.org/doi/abs/10.1145/116825.116852">their paper</a> showing, among other things, all NP problems has zero-knowledge proofs, making many of the protocols discussed in Blum's course a few months earlier trivial corollaries.</p><p>But it wasn't just zero-knowledge. Goldwasser, Micali and Rackoff (and independently <a href="https://doi.org/10.1016/0022-0000(88)90028-1">Babai and Moran</a>) developed the notion of interactive proof, a proof system with statistical confidence, a model that would lead to probabilistically checkable proofs and helping us understand the limits of approximation.</p><p>I owe most of my early research to the models developed in the GMR paper and glad that Amit has found a way to share these ideas so well.</p></div>
    </content>
    <updated>2022-02-02T21:46:00Z</updated>
    <published>2022-02-02T21:46:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-14T13:32:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4607</id>
    <link href="https://lucatrevisan.wordpress.com/2022/02/02/%e6%81%ad%e5%96%9c%e5%8f%91%e8%b4%a2-13/" rel="alternate" type="text/html"/>
    <title>恭喜发财!</title>
    <summary>新年快乐！</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><figure class="wp-block-image size-full"><a href="https://lucatrevisan.files.wordpress.com/2010/02/calvin-and-hobbes.jpg"><img alt="" class="wp-image-1680" src="https://lucatrevisan.files.wordpress.com/2010/02/calvin-and-hobbes.jpg"/></a></figure>



<p>新年快乐！</p></div>
    </content>
    <updated>2022-02-02T20:15:12Z</updated>
    <published>2022-02-02T20:15:12Z</published>
    <category term="&#x65B0;&#x5E74;"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2022-02-15T08:37:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/02/tenure-track-faculty-at-university-of-haifa-at-oranim-campus-apply-by-february-28-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/02/tenure-track-faculty-at-university-of-haifa-at-oranim-campus-apply-by-february-28-2022/" rel="alternate" type="text/html"/>
    <title>Tenure-Track Faculty at University of Haifa at Oranim Campus (apply by February 28, 2022)</title>
    <summary>The Department of Mathematics-Physics-Computer Science of the University of Haifa at Oranim College invites applications for a tenure-track faculty position in all areas of Computer Science, to begin October 1st 2022. More details on our website. Applications will be considered until the position is filled. Website: https://mathphys.haifa.ac.il/en/announcements/ Email: ackerman@math.haifa.ac.il</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Mathematics-Physics-Computer Science of the University of Haifa at Oranim College invites applications for a tenure-track faculty position in all areas of Computer Science, to begin October 1st 2022. More details on our website.<br/>
Applications will be considered until the position is filled.</p>
<p>Website: <a href="https://mathphys.haifa.ac.il/en/announcements/">https://mathphys.haifa.ac.il/en/announcements/</a><br/>
Email: ackerman@math.haifa.ac.il</p></div>
    </content>
    <updated>2022-02-02T14:47:55Z</updated>
    <published>2022-02-02T14:47:55Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-15T08:37:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/02/postdoc-at-university-of-bergen-apply-by-february-11-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/02/postdoc-at-university-of-bergen-apply-by-february-11-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Bergen (apply by February 11, 2022)</title>
    <summary>Two postdoctoral positions in Algorithmic foundations of data science (in a very broad sense), funded by ERC Consolidator grant of Saket Saurabh. Competitive salary, solid travel funds, and friendly research environment. Website: https://www.jobbnorge.no/en/available-jobs/job/218932/researcher-in-informatics-algorithmic-foundations-of-data-science Email: fedor.fomin@uib.no</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Two postdoctoral positions in Algorithmic foundations of data science (in a very broad sense), funded by ERC Consolidator grant of Saket Saurabh. Competitive salary, solid travel funds, and friendly research environment.</p>
<p>Website: <a href="https://www.jobbnorge.no/en/available-jobs/job/218932/researcher-in-informatics-algorithmic-foundations-of-data-science">https://www.jobbnorge.no/en/available-jobs/job/218932/researcher-in-informatics-algorithmic-foundations-of-data-science</a><br/>
Email: fedor.fomin@uib.no</p></div>
    </content>
    <updated>2022-02-02T12:06:04Z</updated>
    <published>2022-02-02T12:06:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-15T08:37:33Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://gradientscience.org/datamodels-1/</id>
    <link href="https://gradientscience.org/datamodels-1/" rel="alternate" type="text/html"/>
    <title>Predicting Predictions with Datamodels</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="bbutton" href="https://arxiv.org/abs/2202.00622" style="float: left; width: 45%;">
<i class="fas fa-file-pdf"/>
    Paper
</a>
<a class="bbutton" href="https://github.com/MadryLab/datamodels-data" style="float: left; width: 45%;">
<i class="fab fa-github"/>
   Data
</a>
<br/>
<em>What drives machine learning (ML) models’ predictions?</em></p>

<p>This question is rarely an easy one to answer. On one hand, we know that predictions are a product of <em>training data</em> and <em>learning algorithms</em>. On the other hand, it is often hard to characterize exactly how these two elements interact.</p>

<p>In our <a href="https://arxiv.org/abs/2202.00622">latest work</a>, we introduce <em>datamodels</em>—a step towards acquiring a more fine-grained understanding of how learning algorithms use training data to make predictions. This post introduces the datamodeling framework, describes its simplest, <em>linear</em> instantiation, and illustrates its success in modeling data-to-prediction mapping for deep neural networks. Our future posts will tour through some of the applications of the datamodeling framework that we are most excited about.</p>

<h2 id="what-is-a-datamodel">What is a datamodel?</h2>

<p>In the standard machine learning setup, we have both a learning algorithm (say, stochastic gradient descent applied to a deep neural network) and a training set to learn from (say, the CIFAR-10 training set).</p>

<p>Now, suppose that we want to evaluate model behavior on a specific input \(x\). For example, \(x\) might be one of the following input-label pairs from the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a> test set:</p>



<div class="row">
     <div class="img_holder">
         <img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse7.png"/>
         <span>"horse"</span>
     </div>
     <div class="img_holder">
         <img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog7.png"/>
         <span>"dog"</span>
     </div>
     <div class="img_holder">
         <img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship5.png"/>
         <span>"boat"</span>
     </div>
     <div class="img_holder">
         <img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck5.png"/>
         <span>"firetruck"</span>
     </div>
 </div>

<p>A natural question that might arise in this context is: <em>for such an example \(x\), how does the learning algorithm use the training data to arrive at its prediction?</em> Answering this question is difficult—think of the underlying complexity stemming from training  a deep neural network using thousands of stochastic gradient descent (SGD) steps.</p>

<p>Our <em>datamodeling</em> framework is motivated exactly by this challenge. Specifically, the goal of datamodeling is to bypass that complexity of model training entirely, and instead find a <em>simple</em> function that <em>directly</em> maps training data to predictions. So, roughly speaking, a <em>datamodel</em> for a specific example of interest \(x\) is a function \(g(S’)\) that takes as input any subset \(S’\) of the original training \(S\), and as output predicts the outcome of training a model on \(S’\) and then evaluating on \(x\).</p>
<div class="footnote">
Note that “evaluating” is left intentionally vague here as we expect the specific form to be task dependent: one might be interested in, for instance, the predicted label (e.g., in classification tasks), squared error (e.g., in regression tasks), or log-likelihood (e.g., in language modeling tasks).
</div>

<p>For the visual learners out there, datamodels have the following interface:</p>

<p><img src="https://gradientscience.org/images/datamodels/flow.png" style="width: 75%;"/></p>

<p>The hope is to find datamodels that are <em>simple</em> enough to analyze directly, yet <em>accurate</em> enough to faithfully capture model behavior. We then can use such datamodels to gain insight into how the algorithm and data combine <em>through</em> the lens of the training dynamics (but without having to analyze that dynamics directly).</p>

<p>At first glance, this of task of <em>predicting</em> the output of a learning algorithm trained on different subsets of the original training set does not appear any easier than <em>analyzing</em> the learning algorithm on that original training set—in fact, it might seem even harder. At the very least, one would expect that any function approximating such a learning algorithm would need to be rather complicated. It turns out, however, that a (very) simple instantiation of datamodels—as linear functions—is already expressive enough to accurately capture the intended mapping, even for real-world deep neural networks!</p>

<h2 id="linear-datamodels-for-deep-classifiers">Linear datamodels for deep classifiers</h2>

<p>How exactly do we formulate <em>linear datamodels</em>? We represent each subset \(S’\) of the training set as an <em>indicator vector</em> \(\mathbf{1}_{S’}\), and then have our datamodel \(g_\theta\) map such indicator vectors to scalars. Specifically, we parameterize linear datamodels as:</p>

\[g_\theta(S’) = \mathbf{1}_{S’}^\top \theta + \theta_0,\]

<p>where \(\theta\) are our model’s parameters.</p>

<div class="footnote">
An <a href="https://en.wikipedia.org/wiki/Indicator_vector">indicator vector</a>
is a binary vector of dimension equal to the size of the training set, whose
\(i\)-th index is equal to \(1\) if and only if the \(i\)-th training example is present in \(S’\). 
</div>

<h2 id="estimating-linear-datamodels">Estimating linear datamodels</h2>

<p>Now, how do we actually select parameters \(\theta\) for such a linear datamodel? Recall that our goal is to find a \(\theta\) such that our linear datamodel satisfies:</p>

<center>
$$
g_\theta(S’) \approx \mbox{the output on \(x\) of a model trained on \(S’\).}
$$
</center>

<p>Our idea is to frame this task as a <em>supervised learning problem</em> in which we infer \(g_\theta\) from “input-label pairs.” Here, each of these pairs consists of a specific training subset \(S’\) (“input”) and the corresponding model output on \(x\) (“label”). Indeed, obtaining such pairs is rather easy—for a given choice of \(S’\), we retrieve corresponding outputs by just executing the learning algorithm on \(S’\) and evaluating on \(x\).</p>

<p>From this perspective, estimating \(g_\theta\) for a given \(x\) becomes a two-step process:</p>

<ul>
  <li><strong>Collecting our datamodel train set</strong>:  Sample a training subset \(S_i\), train
 a model on \(S_i\), and, finally, add the corresponding “input-label pair”
 \((S_i, \text{trained model output on }x)\) to our datamodel training set. 
 Rinse and repeat (until that training set becomes sufficiently large).</li>
  <li><strong>Datamodel training</strong>: Solve for \(\theta\) by regressing from our “training subsets” \(S_i\) to their corresponding model outputs on \(x\).</li>
</ul>

<p>Now: how many such input-label pairs do we need to be able to solve the corresponding (very high-dimensional) regression problem? (Note that the dimension here is 50k, the size of the training set!) The answer is: a lot. Specifically, to fit CIFAR-10 datamodels we trained a few <em>hundred thousand</em> CIFAR-10 models. (Moreover, looking across all our paper’s experiments, we train more than 4 million such models in total.) To make this task feasible, we designed (and released!) a <a href="https://ffcv.io/">fast fast model training library</a>—you might find this library helpful for your training tasks, however big or small. With our library, we were able to bring CIFAR training down to <em>seconds</em> on a single (A100) GPU, meaning that training hundreds of thousands of models takes (only) a few days (on a single machine).</p>

<div class="footnote">
Use our <i>data release</i>! Both pre-computed datamodels and the predictions of 4 million trained CIFAR models are available for download at <a href="https://github.com/MadryLab/datamodels-data">https://github.com/MadryLab/datamodels-data</a>.
</div>

<h2 id="evaluating-datamodels">Evaluating datamodels</h2>

<p>Now, after all this setup, the key question is: how accurately do such linear datamodels predict model behavior? Following our supervised learning perspective, the gold standard is to evaluate via a held-out test set: a set of (held-out) input-label (or rather, in our case, subset-model output) pairs.</p>

<p>Specifically, we make a <em>datamodel “test set”</em> using the same sampling process employed to generate the datamodel train set. We then compare <em>datamodel-predicted</em> outputs for these (previously unseen) collected subsets to the <em>true outputs</em> (i.e., the output of training a model on the subset and evaluating on the relevant example). It turns out that datamodels predictions predict the result of model training rather well!</p>

<p>
    <img src="https://gradientscience.org/images/datamodels/blog_xy.svg" style="width: 50%;"/>
</p>

<div class="footnote">
    The plotted points range across both choice of training set and target example \(x\). The magnified clusters of the same color each correspond to the same \(x\) for different sampled training sets \(S’\). The output here that we measure is correct-label margin, i.e., the difference between the logit for the correct class and the largest incorrect logit.
</div>

<p>The predicted and actual margins here—even conditioned on a specific \(x\)—correspond nearly one-to-one, despite that our predicted margins come from a linear model, and the actual margins stem from thousands of SGD steps on a ResNet-9!</p>

<h2 id="how-can-we-use-datamodels">How can we use datamodels?</h2>

<p>We’ve already seen that a simple linear model can predict the output of end-to-end model training (for a single target example) relatively well. We found this phenomenon surprising on its own, and hope that studying it further might yield theoretical or empirical insights into the generalization of deep networks (and when applied to new settings, other classes of machine learning models).</p>

<p>That said, in a series of follow up posts we’ll also highlight some of the other direct datamodel applications:</p>

<ul>
  <li>In Part 2, we’ll take a deeper dive into datamodels’ ability to predict outcomes of model training, and find that this ability extends beyond just the subsets sampled from the distribution they were fitted to. We’ll then use this capability to identify <em>brittle predictions</em>, test examples for which model predictions can be flipped by removing just a small number of examples from the training set.</li>
  <li>In Part 3, we’ll discuss how to use datamodels to identify training examples that are similar to any given test example, and will then employ this capability to find (non-trivial) train-test leakage in both CIFAR-10 and FMoW datasets. (FMoW is the other dataset that we investigate in our paper.)</li>
  <li>In Part 4, we’ll explore leveraging linear datamodels as <em>feature representation</em>. Specifically, we find that datamodels yield a natural way to embed every example into a well-behaved representation space. We use the corresponding embeddings to perform clustering and identify <em>model-driven</em> data subpopulations.</li>
</ul>

<p>All of these applications are fully detailed in <a href="https://arxiv.org/abs/2202.00622">our paper</a>, along with more experiments, a more formal introduction to datamodels, and an extensive discussion of the related and future work in this area. Also, check out our <a href="https://github.com/MadryLab/datamodels-data">data release</a> with both pre-computed datamodels and predictions corresponding to million CIFAR-10 models. Stay tuned for more!</p></div>
    </summary>
    <updated>2022-02-02T00:00:00Z</updated>
    <published>2022-02-02T00:00:00Z</published>
    <source>
      <id>https://gradientscience.org/</id>
      <author>
        <name>Gradient Science</name>
      </author>
      <link href="https://gradientscience.org/" rel="alternate" type="text/html"/>
      <link href="https://gradientscience.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Research highlights and perspectives on machine learning and optimization from MadryLab.</subtitle>
      <title>gradient science</title>
      <updated>2022-02-14T22:47:46Z</updated>
    </source>
  </entry>
</feed>
