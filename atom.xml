<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-03-17T21:22:21Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3321636530900479641</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3321636530900479641/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/03/richard-guy-passed-away-at-age-of-103.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3321636530900479641" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3321636530900479641" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/03/richard-guy-passed-away-at-age-of-103.html" rel="alternate" type="text/html"/>
    <title>Richard Guy passed away at the age of 103</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Richard Guy passed away on March 9, 2020 at the age of 103. Before he died he was the worlds oldest living mathematician (see <a href="https://en.wikipedia.org/wiki/List_of_centenarians_(scientists_and_mathematicians)">here</a> for a list of centenarians who are famous scientists or mathematicians). He was also the oldest <i>active </i>mathematician-- he had a paper on arxiv (see <a href="https://arxiv.org/abs/1910.03379">here</a>) in October of 2019.<br/>
<br/>
I met him twice- once at a Gathering for Gardner, and once at an AMS meeting. I told him that Berlekamp-Conway-Guy had a great influence on me. He asked if it was a positive or negative influence. He also seemed to like my talk on The Muffin Problem, though he might have been being polite.<br/>
<br/>
<br/>
I did a blog about Richard Guy on his 103rd birthday, so I recommend readers to go <a href="https://blog.computationalcomplexity.org/2019/09/richard-guy-is-102-years-old-today.html">there</a><br/>
for more about him.  One point I want to re-iterate:<br/>
<br/>
Richard Guy thought of himself of an amateur mathematician. If he means someone who does it for love of the subject then this is clearly true.  If it is a measure of how good he is (the term `amateur' is sometimes used as an insult) then it is clearly false. If it means someone who does not have formal training than it is partially true.<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2020-03-17T16:43:00Z</updated>
    <published>2020-03-17T16:43:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-03-17T17:41:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.07345</id>
    <link href="http://arxiv.org/abs/2003.07345" rel="alternate" type="text/html"/>
    <title>Symmetric Grothendieck inequality</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Friedland:Shmuel.html">Shmuel Friedland</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lim:Lek=Heng.html">Lek-Heng Lim</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.07345">PDF</a><br/><b>Abstract: </b>We establish an analogue of the Grothendieck inequality where the rectangular
matrix is replaced by a symmetric/Hermitian matrix and the bilinear form by a
quadratic form. We call this the symmetric Grothendieck inequality; despite its
name, it is a generalization -- the original Grothendieck inequality is a
special case. While there are other proposals for such an inequality, ours
differs in two important ways: (i) we have no additional requirement like
positive semidefiniteness; (ii) our symmetric Grothendieck constant is
universal, i.e., independent of the matrix and its dimensions. A consequence of
our symmetric Grothendieck inequality is a "conic Grothendieck inequality" for
any family of cones of symmetric matrices: The original Grothendieck inequality
is a special case; as is the Nesterov $\pi/2$-Theorem, which corresponds to the
cones of positive semidefinite matrices; as well as the Goemans-Williamson
inequality, which corresponds to the cones of Laplacians. For yet other cones,
e.g., of diagonally dominant matrices, we get new Grothendieck-like
inequalities. A slight extension leads to a unified framework that treats any
Grothendieck-like inequality as an inequality between two norms within a family
of "Grothendieck norms" restricted to a family of cones. This allows us to
place on equal footing the Goemans-Williamson inequality, Nesterov
$\pi/2$-Theorem, Ben-Tal-Nemirovski-Roos $4/\pi$-Theorem, generalized
Grothendieck inequality, order-$p$ Grothendieck inequality, rank-constrained
positive semidefinite Grothendieck inequality; and in turn allows us to
simplify proofs, extend results from real to complex, obtain new bounds or
establish sharpness of existing ones. The symmetric Grothendieck inequality may
also be applied to obtain polynomial-time approximation bounds for NP-hard
combinatorial, integer, and nonconvex optimization problems.
</p></div>
    </summary>
    <updated>2020-03-17T01:22:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.07341</id>
    <link href="http://arxiv.org/abs/2003.07341" rel="alternate" type="text/html"/>
    <title>Complexity of Shapes Embedded in ${\mathbb Z^n}$ with a Bias Towards Squares</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>M. Ferhat Arslan, Sibel Tari Middle East Technical University) <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.07341">PDF</a><br/><b>Abstract: </b>Shape complexity is a hard-to-quantify quality, mainly due to its relative
nature. Biased by Euclidean thinking, circles are commonly considered as the
simplest. However, their constructions as digital images are only
approximations to the ideal form. Consequently, complexity orders computed in
reference to circle are unstable. Unlike circles which lose their circleness in
digital images, squares retain their qualities. Hence, we consider squares
(hypercubes in $\mathbb Z^n$) to be the simplest shapes relative to which
complexity orders are constructed. Using the connection between $L^\infty$ norm
and squares we effectively encode squareness-adapted simplification through
which we obtain multi-scale complexity measure, where scale determines the
level of interest to the boundary. The emergent scale above which the effect of
a boundary feature (appendage) disappears is related to the ratio of the
contacting width of the appendage to that of the main body. We discuss what
zero complexity implies in terms of information repetition and constructibility
and what kind of shapes in addition to squares have zero complexity.
</p></div>
    </summary>
    <updated>2020-03-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.07285</id>
    <link href="http://arxiv.org/abs/2003.07285" rel="alternate" type="text/html"/>
    <title>Approximating LCS in Linear Time: Beating the $\sqrt{n}$ Barrier</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hajiaghayi:MohammadTaghi.html">MohammadTaghi Hajiaghayi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seddighin:Masoud.html">Masoud Seddighin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seddighin:Saeed.html">Saeed Seddighin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Xiaorui.html">Xiaorui Sun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.07285">PDF</a><br/><b>Abstract: </b>Longest common subsequence (LCS) is one of the most fundamental problems in
combinatorial optimization. Apart from theoretical importance, LCS has enormous
applications in bioinformatics, revision control systems, and data comparison
programs. Although a simple dynamic program computes LCS in quadratic time, it
has been recently proven that the problem admits a conditional lower bound and
may not be solved in truly subquadratic time. In addition to this, LCS is
notoriously hard with respect to approximation algorithms. Apart from a trivial
sampling technique that obtains a $n^{x}$ approximation solution in time
$O(n^{2-2x})$ nothing else is known for LCS. This is in sharp contrast to its
dual problem edit distance for which several linear time solutions are obtained
in the past two decades.
</p></div>
    </summary>
    <updated>2020-03-17T01:21:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.07190</id>
    <link href="http://arxiv.org/abs/2003.07190" rel="alternate" type="text/html"/>
    <title>On the parameterized complexity of 2-partitions</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jonas Bamse Andersen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bang=Jensen:J=oslash=rgen.html">Jørgen Bang-Jensen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yeo:Anders.html">Anders Yeo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.07190">PDF</a><br/><b>Abstract: </b>We give an FPT algorithm for deciding whether the vertex set a digraph $D$
can be partitioned into two disjoint sets $V_1,V_2$ such that the digraph
$D[V_1]$ induced by $V_1$ has a vertex that can reach all other vertices by
directed paths, the digraph $D[V_2]$ has no vertex of in-degree zero and
$|V_i|\geq k_i$, where $k_1,k_2$ are part of the input. This settles an open
problem from[1,4].
</p></div>
    </summary>
    <updated>2020-03-17T01:20:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.07113</id>
    <link href="http://arxiv.org/abs/2003.07113" rel="alternate" type="text/html"/>
    <title>Scheduling Lower Bounds via AND Subset Sum</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abboud:Amir.html">Amir Abboud</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bringmann:Karl.html">Karl Bringmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hermelin:Danny.html">Danny Hermelin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shabtay:Dvir.html">Dvir Shabtay</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.07113">PDF</a><br/><b>Abstract: </b>Given $N$ instances $(X_1,t_1),\ldots,(X_N,t_N)$ of Subset Sum, the AND
Subset Sum problem asks to determine whether all of these instances are
yes-instances; that is, whether each set of integers $X_i$ has a subset that
sums up to the target integer $t_i$. We prove that this problem cannot be
solved in $\tilde{O}((N \cdot t_{max})^{1-\epsilon})$ time, for $t_{max}=\max_i
t_i$ and any $\epsilon &gt; 0$, assuming the $\forall \exists$ Strong Exponential
Time Hypothesis ($\forall \exists$-SETH). We then use this result to exclude
$\tilde{O}(n+P_{max} \cdot n^{1-\epsilon})$-time algorithms for several
scheduling problems on $n$ jobs with maximum processing time $P_{max}$, based
on $\forall \exists$-SETH. These include classical problems such as $1||\sum
w_jU_j$, the problem of minimizing the total weight of tardy jobs on a single
machine, and $P_2||\sum U_j$, the problem of minimizing the number of tardy
jobs on two identical parallel machines.
</p></div>
    </summary>
    <updated>2020-03-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.07104</id>
    <link href="http://arxiv.org/abs/2003.07104" rel="alternate" type="text/html"/>
    <title>Faster Minimization of Tardy Processing\newline Time on a Single Machine</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bringmann:Karl.html">Karl Bringmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fischer:Nick.html">Nick Fischer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hermelin:Danny.html">Danny Hermelin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shabtay:Dvir.html">Dvir Shabtay</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wellnitz:Philip.html">Philip Wellnitz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.07104">PDF</a><br/><b>Abstract: </b>This paper is concerned with the $1||\sum p_jU_j$ problem, the problem of
minimizing the total processing time of tardy jobs on a single machine. This is
not only a fundamental scheduling problem, but also a very important problem
from a theoretical point of view as it generalizes the Subset Sum problem and
is closely related to the 0/1-Knapsack problem. The problem is well-known to be
NP-hard, but only in a weak sense, meaning it admits pseudo-polynomial time
algorithms. The fastest known pseudo-polynomial time algorithm for the problem
is the famous Lawler and Moore algorithm which runs in $O(P \cdot n)$ time,
where $P$ is the total processing time of all $n$ jobs in the input. This
algorithm has been developed in the late 60s, and has yet to be improved to
date.
</p>
<p>In this paper we develop two new algorithms for $1||\sum p_jU_j$, each
improving on Lawler and Moore's algorithm in a different scenario. Both
algorithms rely on basic primitive operations between sets of integers and
vectors of integers for the speedup in their running times. The second
algorithm relies on fast polynomial multiplication as its main engine, while
for the first algorithm we define a new "skewed" version of
$(\max,\min)$-convolution which is interesting in its own right.
</p></div>
    </summary>
    <updated>2020-03-17T01:25:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.07061</id>
    <link href="http://arxiv.org/abs/2003.07061" rel="alternate" type="text/html"/>
    <title>The $\epsilon$-$t$-Net Problem</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alon:Noga.html">Noga Alon</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jartoux:Bruno.html">Bruno Jartoux</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Keller:Chaya.html">Chaya Keller</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Smorodinsky:Shakhar.html">Shakhar Smorodinsky</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yuditsky:Yelena.html">Yelena Yuditsky</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.07061">PDF</a><br/><b>Abstract: </b>We study a natural generalization of the classical $\epsilon$-net problem
(Haussler--Welzl 1987), which we call the "$\epsilon$-$t$-net problem": Given a
hypergraph on $n$ vertices and parameters $t$ and $\epsilon\geq \frac t n$,
find a minimum-sized family $S$ of $t$-element subsets of vertices such that
each hyperedge of size at least $\epsilon n$ contains a set in $S$. When $t=1$,
this corresponds to the $\epsilon$-net problem.
</p>
<p>We prove that any sufficiently large hypergraph with VC-dimension $d$ admits
an $\epsilon$-$t$-net of size $O(\frac{ (1+\log t)d}{\epsilon} \log
\frac{1}{\epsilon})$. For some families of geometrically-defined hypergraphs
(such as the dual hypergraph of regions with linear union complexity), we prove
the existence of $O(\frac{1}{\epsilon})$-sized $\epsilon$-$t$-nets.
</p>
<p>We also present an explicit construction of $\epsilon$-$t$-nets (including
$\epsilon$-nets) for hypergraphs with bounded VC-dimension. In comparison to
previous constructions for the special case of $\epsilon$-nets (i.e., for
$t=1$), it does not rely on advanced derandomization techniques. To this end we
introduce a variant of the notion of VC-dimension which is of independent
interest.
</p></div>
    </summary>
    <updated>2020-03-17T01:33:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.07010</id>
    <link href="http://arxiv.org/abs/2003.07010" rel="alternate" type="text/html"/>
    <title>Adversarial Perturbations of Opinion Dynamics in Networks</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jason Gaitonde, Jon Kleinberg, Eva Tardos <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.07010">PDF</a><br/><b>Abstract: </b>We study the connections between network structure, opinion dynamics, and an
adversary's power to artificially induce disagreements. We approach these
questions by extending models of opinion formation in the social sciences to
represent scenarios, familiar from recent events, in which external actors seek
to destabilize communities through sophisticated information warfare tactics
via fake news and bots. In many instances, the intrinsic goals of these efforts
are not necessarily to shift the overall sentiment of the network, but rather
to induce discord. These perturbations diffuse via opinion dynamics on the
underlying network, through mechanisms that have been analyzed and abstracted
through work in computer science and the social sciences. We investigate the
properties of such attacks, considering optimal strategies both for the
adversary seeking to create disagreement and for the entities tasked with
defending the network from attack. We show that for different formulations of
these types of objectives, different regimes of the spectral structure of the
network will limit the adversary's capacity to sow discord; this enables us to
qualitatively describe which networks are most vulnerable against these
perturbations. We then consider the algorithmic task of a network defender to
mitigate these sorts of adversarial attacks by insulating nodes
heterogeneously; we show that, by considering the geometry of this problem,
this optimization task can be efficiently solved via convex programming.
Finally, we generalize these results to allow for two network structures, where
the opinion dynamics process and the measurement of disagreement become
uncoupled, and determine how the adversary's power changes; for instance, this
may arise when opinion dynamics are controlled an online community via social
media, while disagreement is measured along "real-world" connections.
</p></div>
    </summary>
    <updated>2020-03-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.06993</id>
    <link href="http://arxiv.org/abs/2003.06993" rel="alternate" type="text/html"/>
    <title>Space Hardness of Solving Structured Linear Systems</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Xuangui.html">Xuangui Huang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.06993">PDF</a><br/><b>Abstract: </b>We show that if the probabilistic logarithmic-space solver or the
deterministic nearly logarithmic-space solver for undirected Laplacian matrices
can be extended to solve slightly larger subclasses of linear systems, then
they can be use to solve all linear systems with similar space complexity.
Previously Kyng and Zhang proved similar results in the time complexity setting
using reductions between approximate solvers. We prove that their reductions
can be implemented using constant-depth, polynomial-size threshold circuits.
</p></div>
    </summary>
    <updated>2020-03-17T01:20:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.06879</id>
    <link href="http://arxiv.org/abs/2003.06879" rel="alternate" type="text/html"/>
    <title>Selecting Voting Locations for Fun and Profit</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fitzsimmons:Zack.html">Zack Fitzsimmons</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lev:Omer.html">Omer Lev</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.06879">PDF</a><br/><b>Abstract: </b>While manipulative attacks on elections have been well-studied, only recently
has attention turned to attacks that account for geographic information, which
are extremely common in the real world. The most well known in the media is
gerrymandering, in which district border-lines are changed to increase a
party's chance to win, but a different geographical manipulation involves
influencing the election by selecting the location of polling places, as many
people are not willing to go to any distance to vote. In this paper we initiate
the study of this manipulation. We find that while it is easy to manipulate the
selection of polling places on the line, it becomes difficult already on the
plane or in the case of more than two candidates. Moreover, we show that for
more than two candidates the problem is inapproximable. However, we find a few
restricted cases on the plane where some algorithms perform well. Finally, we
discuss how existing results for standard control actions hold in the
geographic setting, consider additional control actions in the geographic
setting, and suggest directions for future study.
</p></div>
    </summary>
    <updated>2020-03-17T01:22:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.06875</id>
    <link href="http://arxiv.org/abs/2003.06875" rel="alternate" type="text/html"/>
    <title>Recommending Deployment Strategies for Collaborative Tasks</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wei:Dong.html">Dong Wei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roy:Senjuti_Basu.html">Senjuti Basu Roy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Amer=Yahia:Sihem.html">Sihem Amer-Yahia</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.06875">PDF</a><br/><b>Abstract: </b>Our work contributes to aiding requesters in deploying collaborative tasks in
crowdsourcing. We initiate the study of recommending deployment strategies for
collaborative tasks to requesters that are consistent with deployment
parameters they desire: a lower-bound on the quality of the crowd contribution,
an upper-bound on the latency of task completion, and an upper-bound on the
cost incurred by paying workers. A deployment strategy is a choice of value for
three dimensions: Structure (whether to solicit the workforce sequentially or
simultaneously), Organization (to organize it collaboratively or
independently), and Style (to rely solely on the crowd or to combine it with
machine algorithms). We propose StratRec, an optimization-driven middle layer
that recommends deployment strategies and alternative deployment parameters to
requesters by accounting for worker availability. Our solutions are grounded in
discrete optimization and computational geometry techniques that produce
results with theoretical guarantees. We present extensive experiments on Amazon
Mechanical Turk and conduct synthetic experiments to validate the qualitative
and scalability aspects of StratRec.
</p></div>
    </summary>
    <updated>2020-03-17T01:28:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.06742</id>
    <link href="http://arxiv.org/abs/2003.06742" rel="alternate" type="text/html"/>
    <title>Four-Dimensional Dominance Range Reporting in Linear Space</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nekrich:Yakov.html">Yakov Nekrich</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.06742">PDF</a><br/><b>Abstract: </b>In this paper we study the four-dimensional dominance range reporting problem
and present data structures with linear or almost-linear space usage. Our
results can be also used to answer four-dimensional queries that are bounded on
five sides. The first data structure presented in this paper uses linear space
and answers queries in $O(\log^{1+\varepsilon}n + k\log^{\varepsilon} n)$ time,
where $k$ is the number of reported points, $n$ is the number of points in the
data structure, and $\varepsilon$ is an arbitrarily small positive constant.
Our second data structure uses $O(n \log^{\varepsilon} n)$ space and answers
queries in $O(\log n+k)$ time.
</p>
<p>These are the first data structures for this problem that use linear (resp.
$O(n\log^{\varepsilon} n)$) space and answer queries in poly-logarithmic time.
For comparison the fastest previously known linear-space or
$O(n\log^{\varepsilon} n)$-space data structure supports queries in
$O(n^{\varepsilon} + k)$ time (Bentley and Mauer, 1980). Our results can be
generalized to $d\ge 4$ dimensions. For example, we can answer $d$-dimensional
dominance range reporting queries in $O(\log\log n (\log n/\log\log n)^{d-3} +
k)$ time using $O(n\log^{d-4+\varepsilon}n)$ space. Compared to the fastest
previously known result (Chan, 2013), our data structure reduces the space
usage by $O(\log n)$ without increasing the query time.
</p></div>
    </summary>
    <updated>2020-03-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.06706</id>
    <link href="http://arxiv.org/abs/2003.06706" rel="alternate" type="text/html"/>
    <title>Universal Function Approximation on Graphs using Multivalued Functions</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Rickard Brüel-Gabrielsson <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.06706">PDF</a><br/><b>Abstract: </b>In this work we produce a framework for constructing universal function
approximators on graph isomorphism classes. Additionally, we prove how this
framework comes with a collection of theoretically desirable properties and
enables novel analysis. We show how this allows us to outperform state of the
art on four different well known datasets in graph classification and how our
method can separate classes of graphs that other graph-learning methods cannot.
Our approach is inspired by persistence homology, dependency parsing for
Natural Language Processing, and multivalued functions. The complexity of the
underlying algorithm is O(mn) and code is publicly available.
</p></div>
    </summary>
    <updated>2020-03-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.06691</id>
    <link href="http://arxiv.org/abs/2003.06691" rel="alternate" type="text/html"/>
    <title>Shorter Labels for Routing in Trees</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Paweł Gawrychowski, Wojciech Janczewski, Jakub Łopuszański <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.06691">PDF</a><br/><b>Abstract: </b>A routing labeling scheme assigns a binary string, called a label, to each
node in a network, and chooses a distinct port number from $\{1,\ldots,d\}$ for
every edge outgoing from a node of degree $d$. Then, given the labels of $u$
and $w$ and no other information about the network, it should be possible to
determine the port number corresponding to the first edge on the shortest path
from $u$ to $w$. In their seminal paper, Thorup and Zwick [SPAA 2001] designed
several routing methods for general weighted networks. An important technical
ingredient in their paper that according to the authors ``may be of independent
practical and theoretical interest'' is a routing labeling scheme for trees of
arbitrary degrees. For a tree on $n$ nodes, their scheme constructs labels
consisting of $(1+o(1))\log n$ bits such that the sought port number can be
computed in constant time. Looking closer at their construction, the labels
consist of $\log n + O(\log n\cdot \log\log\log n / \log\log n)$ bits. Given
that the only known lower bound is $\log n+\Omega(\log\log n)$, a natural
question that has been asked for other labeling problems in trees is to
determine the asymptotics of the smaller-order term.
</p>
<p>We make the first (and significant) progress in 19 years on determining the
correct second-order term for the length of a label in a routing labeling
scheme for trees on $n$ nodes. We design such a scheme with labels of length
$\log n+O((\log\log n)^{2})$. Furthermore, we modify the scheme to allow for
computing the port number in constant time at the expense of slightly
increasing the length to $\log n+O((\log\log n)^{3})$.
</p></div>
    </summary>
    <updated>2020-03-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.06639</id>
    <link href="http://arxiv.org/abs/2003.06639" rel="alternate" type="text/html"/>
    <title>Graph Profiling for Vertex Cover: Targeted Reductions in a Branch and Reduce Solver</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stallmann:Matthias_F=.html">Matthias F. Stallmann</a>, Yang Ho, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goodrich:Timothy_D=.html">Timothy D. Goodrich</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.06639">PDF</a><br/><b>Abstract: </b>Akiba and Iwata [TCS, 2016] demonstrated that a branch and reduce (B&amp;R)
solver for the vertex cover problem can compete favorably with integer linear
programming solvers (e.g., CPLEX). Our research question is are there graph
characteristics that determine which reductions will be most effective? Not
only is the answer affirmative, but relevant characteristics are easy to
identify. To explore our ideas, we provide an enhanced version of the
Akiba-Iwata solver that can (a) be configured with any subset of reductions and
lower bounds; (b) print statistics such as time taken and number of vertices
reduced by each reduction. Based on extensive experiments with benchmark and
random instances we demonstrate that (i) more reductions do not necessarily
lead to better runtimes; (ii) the subset of reductions leading to the best (or
nearly the best) runtime can be predicted based on measurable characteristics
of a graph, e.g., density and degree distribution; and (iii) exceptions have
structural characteristics known in advance. Our primary contributions are 1. A
thorough examination reduction routine performance in the context of graph
characteristics. 2. Three primary hypotheses suggesting simple suites of
reductions as the most efficient options. 3. Experiments with a large corpus of
data to validate our hypotheses. 4. Measures that quantify a problem instance
on two key dimensions to make our hypotheses concrete. 5. An enhanced
open-source version of the Akiba-Iwata solver that enables our investigations
and creates opportunities for future exploration. Our main objective is to
provide guidance to a user so that, faced with a given problem instance or set
of instances, they may most effectively use the available reductions.
Ultimately these efforts can lead to an automated process.
</p></div>
    </summary>
    <updated>2020-03-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.06622</id>
    <link href="http://arxiv.org/abs/2003.06622" rel="alternate" type="text/html"/>
    <title>Approximation Schemes for Subset Sum Ratio Problems</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Melissinos:Nikolaos.html">Nikolaos Melissinos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pagourtzis:Aris.html">Aris Pagourtzis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Triommatis:Theofilos.html">Theofilos Triommatis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.06622">PDF</a><br/><b>Abstract: </b>We consider the Subset Sum Ratio Problem ($SSR$), in which given a set of
integers the goal is to find two subsets such that the ratio of their sums is
as close to~1 as possible, and introduce a family of variations that capture
additional meaningful requirements. Our main contribution is a generic
framework that yields fully polynomial time approximation schemes (FPTAS) for
problems in this family that meet certain conditions. We use our framework to
design explicit FPTASs for two such problems, namely Two-Set Subset-Sum Ratio
and Factor-$r$ Subset-Sum Ratio, with running time
$\mathcal{O}(n^4/\varepsilon)$, which coincides with the best known running
time for the original $SSR$ problem [15].
</p></div>
    </summary>
    <updated>2020-03-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.06462</id>
    <link href="http://arxiv.org/abs/2003.06462" rel="alternate" type="text/html"/>
    <title>A Persistent Homology Approach to Time Series Classification</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chung:Yu=Min.html">Yu-Min Chung</a>, William Cruse, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lawson:Austin.html">Austin Lawson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.06462">PDF</a><br/><b>Abstract: </b>Topological Data Analysis (TDA) is a rising field of computational topology
in which the topological structure of a data set can be observed by persistent
homology. By considering a sequence of sublevel sets, one obtains a filtration
that tracks changes in topological information. These changes can be recorded
in multi-sets known as {\it persistence diagrams}. Converting information
stored in persistence diagrams into a form compatible with modern machine
learning algorithms is a major vein of research in TDA. {\it Persistence
curves}, a recently developed framework, provides a canonical and flexible way
to encode the information presented in persistence diagrams into vectors. In
this work, we propose a new set of metrics based on persistence curves. We
prove the stability of the proposed metrics. Finally, we apply these metrics to
the UCR Time Series Classification Archive. These empirical results show that
our metrics perform better than the relevant benchmark in most cases and
warrant further study.
</p></div>
    </summary>
    <updated>2020-03-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2002.08892</id>
    <link href="http://arxiv.org/abs/2002.08892" rel="alternate" type="text/html"/>
    <title>Reliable Distributed Clustering with Redundant Data Assignment</title>
    <feedworld_mtime>1584403200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gandikota:Venkata.html">Venkata Gandikota</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mazumdar:Arya.html">Arya Mazumdar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rawat:Ankit_Singh.html">Ankit Singh Rawat</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2002.08892">PDF</a><br/><b>Abstract: </b>In this paper, we present distributed generalized clustering algorithms that
can handle large scale data across multiple machines in spite of straggling or
unreliable machines. We propose a novel data assignment scheme that enables us
to obtain global information about the entire data even when some machines fail
to respond with the results of the assigned local computations. The assignment
scheme leads to distributed algorithms with good approximation guarantees for a
variety of clustering and dimensionality reduction problems.
</p></div>
    </summary>
    <updated>2020-03-17T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-17T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.06292</id>
    <link href="http://arxiv.org/abs/2003.06292" rel="alternate" type="text/html"/>
    <title>Algorithms in Linear Algebraic Groups</title>
    <feedworld_mtime>1584316800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Sushil Bhunia, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahalanobis:Ayan.html">Ayan Mahalanobis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shinde:Pralhad.html">Pralhad Shinde</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singh:Anupam.html">Anupam Singh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.06292">PDF</a><br/><b>Abstract: </b>This paper presents some algorithms in linear algebraic groups. These
algorithms solve the word problem and compute the spinor norm for orthogonal
groups. This gives us an algorithmic definition of the spinor norm. We compute
the double coset decomposition with respect to a Siegel maximal parabolic
subgroup, which is important in computing infinite-dimensional representations
for some algebraic groups.
</p></div>
    </summary>
    <updated>2020-03-16T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.06096</id>
    <link href="http://arxiv.org/abs/2003.06096" rel="alternate" type="text/html"/>
    <title>Shortest Paths on Cubes</title>
    <feedworld_mtime>1584316800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldstone:Richard.html">Richard Goldstone</a>, Rachel Roca, Robert Suzzi Valli <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.06096">PDF</a><br/><b>Abstract: </b>In 1903, noted puzzle-maker Henry Dudeney published The Spider and the Fly
puzzle, which asks for the shortest path along the surfaces of a square prism
between two points (source and target) located on the square faces, and
surprisingly showed that the shortest path traverses five faces. Dudeney's
source and target points had very symmetrical locations; in this article, we
allow the source and target points to be anywhere in the interior of opposite
faces, but now require the square prism to be a cube. In this context, we find
that, depending on source and target locations, a shortest path can traverse
either three or four faces, and we investigate the conditions that lead to
four-face solutions and estimate the probability of getting a four-face
shortest path. We utilize a combination of numerical calculations, elementary
geometry, and transformations we call corner moves of cube unfolding diagrams,
</p></div>
    </summary>
    <updated>2020-03-16T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-03-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2003.06076</id>
    <link href="http://arxiv.org/abs/2003.06076" rel="alternate" type="text/html"/>
    <title>Joint Alignment From Pairwise Differences with a Noisy Oracle</title>
    <feedworld_mtime>1584316800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitzenmacher:Michael.html">Michael Mitzenmacher</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsourakakis:Charalampos_E=.html">Charalampos E. Tsourakakis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2003.06076">PDF</a><br/><b>Abstract: </b>In this work we consider the problem of recovering $n$ discrete random
variables $x_i\in \{0,\ldots,k-1\}, 1 \leq i \leq n$ (where $k$ is constant)
with the smallest possible number of queries to a noisy oracle that returns for
a given query pair $(x_i,x_j)$ a noisy measurement of their modulo $k$ pairwise
difference, i.e., $y_{ij} = (x_i-x_j) \mod k$. This is a joint discrete
alignment problem with important applications in computer vision, graph mining,
and spectroscopy imaging. Our main result is a polynomial time algorithm that
learns exactly with high probability the alignment (up to some unrecoverable
offset) using $O(n^{1+o(1)})$ queries.
</p></div>
    </summary>
    <updated>2020-03-16T23:20:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-03-16T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/03/15/stay-home-linkage</id>
    <link href="https://11011110.github.io/blog/2020/03/15/stay-home-linkage.html" rel="alternate" type="text/html"/>
    <title>Stay-at-home linkage</title>
    <summary>Looks like we’ll all be seeing a long time at home with little to do but go online. So here is my usual update of links I recently found interesting. (I’m deliberately not linking Coronavirus information, despite its importance, both because I’m not an expert and have neither useful original opinions to contribute nor adequate filters between information and misinformation, and because I suspect that many people’s mental health depends on not getting overloaded with that stuff while there’s so little to do but staying isolated and avoiding becoming part of the problem).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Looks like we’ll all be seeing a long time at home with little to do but go online. So here is my usual update of links I recently found interesting. (I’m deliberately not linking Coronavirus information, despite its importance, both because I’m not an expert and have neither useful original opinions to contribute nor adequate filters between information and misinformation, and because I suspect that many people’s mental health depends on not getting overloaded with that stuff while there’s so little to do but staying isolated and avoiding becoming part of the problem).</p>

<ul>
  <li>
    <p><a href="https://mathstodon.xyz/@11011110/103750490648260310">Claim: Any partition of a unit square into  rectangles has an axis-parallel line crossing a subset of rectangles with area </a>. Proof: Rectangles of area  cover less than half the square, so larger ones cover at least half. Random axis-parallel lines cross rectangles with probability proportional to perimeter,  for large rectangles. Some line crosses at least the expected area: the sum over rectangles of area × probability.</p>
  </li>
  <li>
    <p>Mary Beard is “Britain’s best known classicist, a Cambridge don with formidable intellect and a knack for getting people interested in all things ancient”. She was also a nominee for trustee of the British Museum, but (in the latest iteration of politicians sticking their nose where it isn’t wanted or needed) <a href="https://www.theguardian.com/books/2020/mar/01/british-museum-put-mary-beard-on-the-board-despite-downing-st-veto">was vetoed by the Tory government for opposing Brexit</a> (<a href="https://mathstodon.xyz/@11011110/103756819167366612"/>). Result: the museum will use one of the slots it controls to appoint her despite the veto.</p>
  </li>
  <li>
    <p>If you really want to see some links I posted on US politics related to the Coronavirus, a couple weeks before we realized how immediate the problem was, see <a href="https://mathstodon.xyz/@11011110/103763260041701547">here</a>.</p>
  </li>
  <li>
    <p><a href="https://emathgroup.github.io/blog/orchard-planting-problem">A Chinese blog on new solutions to the orchard planting problem with four trees per line</a> (<a href="https://mathstodon.xyz/@11011110/103769258677244712"/>, <a href="http://www.mathpuzzle.com/">via</a>, <a href="https://en.wikipedia.org/wiki/Orchard-planting_problem">see also</a>). It seems to be quite readable through Google translate.</p>
  </li>
  <li>
    <p><a href="https://blog.cloudflare.com/when-bloom-filters-dont-bloom/">When Bloom filters don’t bloom</a> (<a href="https://mathstodon.xyz/@11011110/103774986303898695"/>, <a href="https://news.ycombinator.com/item?id=22463979">via</a>). A cautionary tale by Marek Majkowski of how when your filter doesn’t fit into cache it can actually slow you down instead of speeding you up.</p>
  </li>
  <li>
    <p><a href="https://www.johndcook.com/blog/2020/02/27/numerical-heron/">Computing the area of a thin triangle</a> (<a href="https://mathstodon.xyz/@jsiehler/103765201263486902"/>). How to avoid numerical accuracy issues when using Heron’s formula.</p>
  </li>
  <li>
    <p><a href="https://www.theguardian.com/australia-news/2020/mar/08/melbourne-professor-quits-after-health-department-pressures-her-over-data-breach">Australian cryptographer Vanessa Teague resigns from her University of Melbourne professorship</a> (<a href="https://mathstodon.xyz/@11011110/103785134816639696"/>, <a href="https://news.ycombinator.com/item?id=22515193">via</a>), in protest of the government refusal to notify citizens whose medical data was breached, pressure to silence her over the discovery of the breach, and efforts to prevent her from continuing to study the problem. See also <a href="https://twitter.com/VTeagueAus/status/1233241830994481152">Teague’s twitter post</a> and <a href="https://www.righttoknow.org.au/request/correspondence_on_re_identificat">government-university correspondence</a>.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2003.04280">Adjacency labelling for planar graphs (and beyond)</a> (<a href="https://mathstodon.xyz/@patmorin/103796330052092318"/>). You can assign labels to the vertices of a planar graph, with  bits per label, and test whether vertices are adjacent by looking over their label. This implies also that planar graphs are induced subgraphs of <a href="https://en.wikipedia.org/wiki/Universal_graph">universal graphs</a> of near-linear size. New preprint by Dujmović, Esperet, Joret, Gavoille, Micek, and Morin.</p>
  </li>
  <li>
    <p><a href="https://terrytao.wordpress.com/2020/03/10/options-for-giving-math-talks-and-lectures-online/">Options for giving math talks and lectures online</a> (<a href="https://mathstodon.xyz/@11011110/103800856267350730"/>, <a href="https://erikdemaine.org/classes/recording/">see also</a>). Now that we have to. Best choices for me at this point are looking like YuJa and Zoom.</p>
  </li>
  <li>
    <p><a href="https://www.wunderlist.com/blog/join-us-on-our-new-journey/">My favorite shared to-do-list, Wunderlist, is going away</a> (<a href="https://mathstodon.xyz/@11011110/103810987800264328"/>) and being replaced by a Microsoft thing requiring a Microsoft account that I don’t want or have. All I want is multiple to-do lists, with or without deadlines; ability to share individual lists with other users; OS X, iPhone, and Android integration. Anyone have suggestions for replacements?</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@jsiehler/103810743052286323">Pair up!</a> @jsiehler posts an animation of a result from <a href="https://doi.org/10.4153%2FCMB-1959-013-x">Lambek and Moser (1959)</a>: the partition of the non-negative integers into <a href="https://en.wikipedia.org/wiki/Odious_number">odious numbers</a> and <a href="https://en.wikipedia.org/wiki/Evil_number">evil numbers</a> is uniquely determined by the property that the two subsets have equal multisets of pairwise sums.</p>
  </li>
  <li>
    <p><a href="http://bit-player.org/2020/mathjax-turns-3-0">Brian Hayes converts to MathJax 3.0</a> (<a href="https://mathstodon.xyz/@11011110/103825076990194154"/>, <a href="https://news.ycombinator.com/item?id=22582343">see also</a>). With an interesting discussion at the end about how, after initially seeming like a hack and a patchover of the failure of more principled solutions like MathML to actually work, browser-side MathJax is starting to seem like the right way to do things after all.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@kimreece/103812593467637467">People with “and” in their names cause problems in BibTeX</a>. And they <a href="https://en.wikipedia.org/wiki/Alex_And">actually exist</a>. Probably you can work around it using extra curly brackets in the name.</p>
  </li>
</ul></div>
    </content>
    <updated>2020-03-15T16:40:00Z</updated>
    <published>2020-03-15T16:40:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-03-15T23:42:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/036</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/036" rel="alternate" type="text/html"/>
    <title>TR20-036 |  Strong (D)QBF Dependency Schemes via Tautology-free Resolution Paths | 

	Olaf Beyersdorff, 

	Joshua Blinkhorn, 

	Tomáš Peitl</title>
    <summary>We suggest a general framework to study dependency schemes for dependency quantified Boolean formulas (DQBF). As our main contribution, we exhibit a new tautology-free DQBF dependency scheme that generalises the reflexive resolution path dependency scheme. We establish soundness of the tautology-free scheme, implying that it can be used in any DQBF proof system. We further explore the power of DQBF resolution systems parameterised by dependency schemes and show that our new scheme results in exponentially shorter proofs in comparison to the reflexive resolution path dependency scheme when used in the basic DQBF expansion proof system.

On QBFs, we demonstrate that our new scheme is exponentially stronger than the reflexive resolution path dependency scheme when used in Q Resolution, thus resulting in the strongest QBF dependency scheme known to date.</summary>
    <updated>2020-03-15T09:16:59Z</updated>
    <published>2020-03-15T09:16:59Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-03-17T21:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/035</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/035" rel="alternate" type="text/html"/>
    <title>TR20-035 |  No-Signaling MIPs and Faster-Than-Light Communication, Revisited | 

	Justin Holmgren</title>
    <summary>We revisit one original motivation for the study of no-signaling multi-prover
  interactive proofs (NS-MIPs): specifically, that two spatially separated
  provers are guaranteed to be no-signaling by the physical principle that
  information cannot travel from one point to another faster than light.

  We observe that with more than two provers, the physical connection between
  no-signaling and faster-than-light communication is more nuanced, depending on
  the relative positioning of the provers.  In particular, we observe that
  provers are guaranteed to be no-signaling if and only if their positions are
  convexly independent.  Other prover positionings provide weaker guaranteees.

  We consider a new issue that thus arises only in the many-prover setting:
  how precisely must provers be positioned in order to guarantee the
    soundness of a (NS-)MIP?  We prove that substantially more precision is
  required to guarantee full no-signaling than to guarantee soundness of a
  specific NS-MIP for PSPACE implicit in the work of Kalai and Raz (CRYPTO 2009).</summary>
    <updated>2020-03-15T06:28:11Z</updated>
    <published>2020-03-15T06:28:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-03-17T21:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19479</id>
    <link href="https://gilkalai.wordpress.com/2020/03/14/to-cheer-you-up-in-complicated-times-a-book-proof-by-rom-pinchasi-and-alexandr-polyanskii-for-a-1978-conjecture-by-erdos-and-purdy/" rel="alternate" type="text/html"/>
    <title>To cheer you up in complicated times – A book proof by Rom Pinchasi and Alexandr Polyanskii for a 1978 Conjecture by Erdős and Purdy!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Things do not look that good, and these are difficult times. But here on the blog we have plenty of things to cheer you up and assure you. And today we point to two book proofs — two book proofs … <a href="https://gilkalai.wordpress.com/2020/03/14/to-cheer-you-up-in-complicated-times-a-book-proof-by-rom-pinchasi-and-alexandr-polyanskii-for-a-1978-conjecture-by-erdos-and-purdy/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Things do not look that good, and these are difficult times. But here on the blog we have plenty of things to cheer you up and assure you. And today we point to two book proofs — two book proofs to the same theorem– and, as a matter of fact, two book proofs to the same theorem by the same person, <a href="http://www2.math.technion.ac.il/~room/">Rom Pinchasi</a>.  One of the proofs, the one chosen for presentation, is by Rom Pinchasi and  <a href="http://polyanskii.com/">Alexandr Polyanskii</a>.</p>
<p><a href="https://gilkalai.files.wordpress.com/2015/08/drg_1567-douglas-guthrie-photos.jpg"><img alt="" class="alignnone size-full wp-image-13104" height="424" src="https://gilkalai.files.wordpress.com/2015/08/drg_1567-douglas-guthrie-photos.jpg?w=640&amp;h=424" width="640"/></a></p>
<p><span style="color: #ff0000;">Rom Pinchasi has an immense proving power, both for difficult proofs at all costs, for book proofs, and for a large variety of proofs in between. (See, for example, <a href="https://gilkalai.wordpress.com/2010/02/03/a-discrepency-problem-for-planar-configurations/"> this post</a>.)</span></p>
<p>Before moving on, let me mention that there is a <a href="https://terrytao.wordpress.com/2020/03/10/options-for-giving-math-talks-and-lectures-online/">timely blog post</a> by Terry Tao on Online teaching, and here is <a href="https://mathoverflow.net/questions/349283/software-and-ideas-for-workshops-and-conferences-with-long-distance-participants">a related MO question about online conferences</a> that I asked last December.</p>
<h2>Proofs from the book</h2>
<p>Famously, the mathematician Paul Erdős, often referred to “The Book” in which God keeps the most elegant proof of each mathematical theorem. During a lecture in 1985, Erdős said, “You don’t have to believe in God, but you should believe in The Book.” (And you do not have even to believe in the book to enjoy proofs from the book.)</p>
<h2>The Theorem: a 1978 conjecture by Erdős and Purdy</h2>
<p><strong>Theorem: </strong> Let <em>P</em> be a set of <em>n</em> points in general position in the plane. Suppose that <em>R</em> is a set of red points disjoint from <em>P</em> such that every line determined by <em>P</em> passes through a point in <em>R</em>. Then <em>|R|≥ n</em> for <em>n &gt; 6</em>.</p>
<p>This theorem settles a problem by Erdős and Purdy from 1978. Erdős and Purdy also asked about the case where the set of points is not required to be in general position. For that problem the best known lower bound, also proved by Rom Pinchasi, is <em>n/3</em>.</p>
<p>Book Proof I: <a href="http://www2.math.technion.ac.il/~room/ps_files/EP_genpos.pdf">An algebraic solution of a problem of Erdős and Purdy</a>, by Rom Pinchasi</p>
<p>Book Proof II: <a href="http://www2.math.technion.ac.il/~room/ps_files/EP_book.pdf">A one-page solution of a problem of Erdős and Purdy, by Rom Pinchasi and Alexandr Polyanskii</a></p>
<h2>Murty’s magic configurations conjecture.</h2>
<p>The <a href="http://www2.math.technion.ac.il/~room/ps_files/magic.pdf">first proof of the Erdős-Purdy 1978 Conjecture</a> was achieved in 2008 by Eyal Ackerman, Kevin Buchin, Christian Knauer, Rom Pinchasi, and Günter Rote. They derived it from their solution to the 1971 conjecture on magic configurations by Murty. A planar set of points P is called magic if it possible to assign positive weights to the points so that the sum of weights in every line determined by the points is one. Murty conjectured that the only magic configurations are those in general position, and those which have a line missing at most one of the points, and a certain configuration of seven points.</p>
<h2>The Pinchasi-Polyanskii Book-Proof:</h2>
<p>Here, we very closely follow the Pinchasi-Polyanskii’s paper.</p>
<p>We say that a line is determined by a set of points in the plane if it contains at least two of the points. Since the points in P are in general position, each pair of points determines a different line.</p>
<p>Under the contrary assumption we must have <em>|R| = n−1</em>. Then it must be that every point in <em>R</em> is incident to precisely <em>n/2</em> lines determined by <em>P</em> and every line determined by <em>P</em> is incident to precisely one point in <em>R</em>. We would like to reach a contradiction.</p>
<p><span style="color: #0000ff;">Preliminary step: apply a projective transformation to the plane such that the convex hull of <em>P</em> becomes a triangle.</span></p>
<p><strong>Observation 1:</strong>  No point of R lies outside the convex hull of P.</p>
<p>Such a point <em>r</em> should be incident to two lines supporting the convex hull of <em>P</em>. Each of these supporting lines must contain precisely two points of <em>P</em>. Since the convex hull of <em>P</em> is a triangle this is impossible.</p>
<p><span style="color: #ff0000;"><strong>Regard the points in the plane as complex numbers. </strong></span></p>
<p><span style="color: #339966;">(This is really cool. I am not aware of many examples in discrete geometry that thinking about planar points as complex numbers helps.)</span></p>
<p>Notation: for every point<em> p</em> in the plane we denote by <img alt="p_x" class="latex" src="https://s0.wp.com/latex.php?latex=p_x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p_x"/>  the <em>x</em>-coordinate of <em>p</em>.</p>
<p>Crucial definition: For every point <em>p ∈ P</em> deﬁne</p>
<p><img alt="f(p) = \prod_{r \in R}(p-r) / \prod_{p' \in P\backslash \{p\}}(p-p')." class="latex" src="https://s0.wp.com/latex.php?latex=f%28p%29+%3D+%5Cprod_%7Br+%5Cin+R%7D%28p-r%29+%2F+%5Cprod_%7Bp%27+%5Cin+P%5Cbackslash+%5C%7Bp%5C%7D%7D%28p-p%27%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(p) = \prod_{r \in R}(p-r) / \prod_{p' \in P\backslash \{p\}}(p-p')."/></p>
<p><strong>Observation 2:</strong> <em>f(p)</em> is a real number!</p>
<p>The proof will surely make you smile: For every <em>p’ ∈ P \{p}</em> there is a unique <em>r ∈ R</em> such that <em>p, p’</em>, and <em>r</em> are collinear. So <em>(p-r)/(p-p’)</em> is real. And the big ratio between products split to many small fractions that are all real.  <span style="color: #993366;"><strong>Walla!</strong></span></p>
<p>Note that <em>f(p)</em> is thus also invariant under rotations of the plane.</p>
<p>Now, if the vertical line through p does not contain any other point in P ∪ R, then, for the unique <em>r ∈ R</em> such that <em>p, p’</em>, and<em> r</em> are collinear, we have that:</p>
<p><img alt="(1)~~~(p-r)/(p-p')~=~(p_x-r_x)/(p_x-p'_x)" class="latex" src="https://s0.wp.com/latex.php?latex=%281%29%7E%7E%7E%28p-r%29%2F%28p-p%27%29%7E%3D%7E%28p_x-r_x%29%2F%28p_x-p%27_x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(1)~~~(p-r)/(p-p')~=~(p_x-r_x)/(p_x-p'_x)"/>.</p>
<p>This leads to:</p>
<p><strong>Observation 3:</strong>  if the vertical line through <em>p</em> does not contain any other point in <em>P ∪ R</em>, then</p>
<p><img alt="(2)~~~ f(p) = \prod_{r \in R}(p_x-r_x) / \prod_{p' \in P\backslash \{p\}}(p_x-p'_x)." class="latex" src="https://s0.wp.com/latex.php?latex=%282%29%7E%7E%7E+f%28p%29+%3D+%5Cprod_%7Br+%5Cin+R%7D%28p_x-r_x%29+%2F+%5Cprod_%7Bp%27+%5Cin+P%5Cbackslash+%5C%7Bp%5C%7D%7D%28p_x-p%27_x%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(2)~~~ f(p) = \prod_{r \in R}(p_x-r_x) / \prod_{p' \in P\backslash \{p\}}(p_x-p'_x)."/></p>
<p><strong>Crucial observation 4:</strong>  Let <em>p</em> and <em>q</em> be any two points in <em>P</em> and let <em>r</em> be the unique point in <em>R</em> collinear with <em>p</em> and<em> q</em>. Then</p>
<h3 style="text-align: center;"><em>f(p)/f(q)=-(p-r)/(q-r).</em></h3>
<p>To see this rotate the plane so that the x-coordinates of <em>p,q</em>, and <em>r</em> are equal (or nearly equal) and apply Equations (2) and (1). (You will get the same, or nearly the same, contributions for <em>r’ ≠ r</em>  and you are left with the contribution for <em>r</em>. ) This also leads to:</p>
<p><strong>Observation 5:</strong> <em>f(p)/f(q)</em> <em>&gt;0</em>  if and only if the unique point <em>r ∈ R</em> that is collinear with <em>p</em> and<em> q</em> lies in the straight line segment delimited by <em>p</em> and <em>q</em>.</p>
<h3>A complete graph with green and red edges.</h3>
<p>Consider the complete graph <em>G</em> whose vertices are the points in <em>P</em>. For every two points <em>p, q ∈ P</em> we color the edge connecting  <em>p</em> and <em>q</em> <span style="color: #ff0000;"><strong>red</strong></span> if the unique point in <em>R</em> collinear with <em>p</em> and <em>q</em> lies outside the straight line segment connecting <em>p</em> and<em> q. </em>Otherwise we color the edge <span style="color: #008000;"><strong>green</strong></span>. In other words, the edge is <strong><span style="color: #ff0000;">red</span></strong> if<strong><span style="color: #ff0000;"> f(p)/f(q) &lt; 0</span></strong>, and <strong><span style="color: #339966;">green</span></strong> if <strong><span style="color: #339966;">f(p)/f(q) &gt; 0</span></strong>.</p>
<p>The vertices of G can naturally be partitioned into two sets:<i> U = {p ∈ P | f(p) &gt; 0}</i> and<i> W = {p ∈ P | f(p) &lt; 0}</i>.</p>
<p>Without loss of generality assume that the three vertices of the convex hull of P belong to <em>U</em>. (Since no point of R is outside this convex hull all edges of the triangle forming the convex hull are green.)</p>
<p><strong>Observation 6:</strong> <em>|U| = n/2 + 1.</em></p>
<p>To see this let <em>a,b</em> ∈ <em>U</em> be two vertices of the convex hull of <em>P</em>. Let <em>c</em> ∈ <em>R</em> be the point in <em>R</em> collinear with <em>a</em> and <em>b</em>. The point <em>c</em> must be between <em>a</em> and <em>b</em> on the boundary of the convex hull of <em>P</em>. Therefore, all the other n/2 −1 pairs of points of <em>P</em> that are collinear with c must form red edges. Consequently, precisely one point of every such pair belongs to U. Together with <em>a</em> and <em>b</em>, we obtain <em>|U| = n/2+1</em>.</p>
<p><strong>End of proof:</strong></p>
<p><span id="more-19479"/></p>
<p>Consider now any triangulation of the convex hull of <em>P</em> using all the vertices of <em>U</em>. This triangulation contains precisely <em>3|U|−6</em> edges all of which correspond to green edges in the graph <em>G</em>. Each edge in the triangulation contains a unique point in <em>R</em>. Therefore,</p>
<p style="text-align: center;"><em>|R|≥ 3|1|−6 = 3n/2 −3.</em></p>
<p>This expression is greater than or equal to <em>n</em> for every <em>n ≥ 6</em>, as desired. <span style="color: #993366;"><strong>ahla!</strong></span></p>
<p><span style="color: #339966;">(Good old Euler’s theorem is used.)</span></p>
<h2>Related things.</h2>
<p>Yesterday, our PM explained on TV what geometric (exponential) growth is.  If I try to describe related results and problems to the theorem presented here, and move on to related results and problems to those and so on, the amount of beautiful results from discrete geometry will grow exponentially but this post will never be completed.</p>
<p>So let me mention just a few things.</p>
<ol>
<li>The result is related to the Motzkin-Rabin Colorful Sylvester-Gallai theorem. Given a set of red points and blue points in the plane, not all on a line, the Motzkin-Rabin theorem asserts that there is a line that contains two or more points in the set, such that all the points on the line have the same color.</li>
<li>Starting with the Sylvester-Gallai theorem itself, there is a rich Gallai-Sylvester theory, with recent deep connections to the theory of computing; My <a href="https://mathoverflow.net/questions/4661/the-sylvester-gallai-theorem-and-sections-of-varieties-with-simple-topology">third MathOverflow question</a> was about a Sylvester-Gallai type problem and here is a link to <a href="https://mathoverflow.net/questions/4661/the-sylvester-gallai-theorem-and-sections-of-varieties-with-simple-topology#comment8133_4661">Greg Kuperberg remark</a>‘s regarding potential Gylvester-Kalai theorems.</li>
<li>Let me mention the <a href="https://terrytao.wordpress.com/2012/08/24/on-sets-defining-few-ordinary-lines/">2012 solution by Ben Green and Terry Tao</a> of the ordinary line conjecture and the Orchard conjecture.</li>
<li>Let me mention the proof of Andreii Kupavskii and Alexandr Polyanskii to <a href="https://arxiv.org/pdf/1402.3694.pdf">Shur’s conjecture</a>.</li>
<li>Here is a <a href="http://www2.math.technion.ac.il/~room/ps_files/EPnCubic_s2.pdf">link to a very recent paper</a> by Chaya Keller and Rom Pinchasi. There they make the following <strong>bold conjecture</strong>: Let <em>P</em> be a set of n points in general position and and let <em>R</em> be a set of n points disjoint from P. If every line determined by P passes through a point in<em> R,</em> then <em>P </em>∪<em> R</em> is contained in a cubic curve.</li>
<li>There is, of course the famous book by Martin Aigner and Günter Ziegler: Proofs from the book.</li>
<li>At some point I tried to interest Günter with a companion book: The book of examples. We did not proceed with this project but this motivated my successful <a href="https://mathoverflow.net/questions/4994/fundamental-examples">MathOverflow questions about fundamental examples</a>.</li>
<li>Eventually, Günter and I decided to write instead: the book of examples of polytopes. We went as far as writing a list of chapters of the book! (Which is a very advanced stage of writing a book, I suppose.)</li>
<li>When I took a class for high-school students interested in mathematics, the Sylvester problem was a starred problem in the first problem set and the assertion of the Motzkin-Rabin colored theorem was a double starred problem. Among the 20-30 students none of us found a (correct) solution. (We referred to it in a trivia question in <a href="https://gilkalai.wordpress.com/2008/05/26/natis-influence/">this post</a>.) Years later, I gave the same class and gave the same starred problems, and one student managed to prove the Gallai-Sylvester theorem. Can you guess who he was?</li>
</ol>
<p> </p></div>
    </content>
    <updated>2020-03-14T18:47:47Z</updated>
    <published>2020-03-14T18:47:47Z</published>
    <category term="Combinatorics"/>
    <category term="Geometry"/>
    <category term="What is Mathematics"/>
    <category term="Alexandr Polyanskii"/>
    <category term="Rom Pinchasi"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-03-17T21:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://bit-player.org/?p=2230</id>
    <link href="http://bit-player.org/2020/mathjax-turns-3-0" rel="alternate" type="text/html"/>
    <link href="http://bit-player.org/2020/mathjax-turns-3-0#comments" rel="replies" type="text/html"/>
    <link href="http://bit-player.org/2020/mathjax-turns-3-0/feed/atom" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">MathJax turns 3.0</title>
    <summary type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml">When I launched bit-player.org in 2006, displaying any sort of mathematical notation on the web was torture. I would typeset an equation in LaTeX, convert the output to a JPEG image, upload the image file to a directory on the … <a href="http://bit-player.org/2020/mathjax-turns-3-0">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>When I launched bit-player.org in 2006, displaying any sort of mathematical notation on the web was torture. I would typeset an equation in LaTeX, convert the output to a JPEG image, upload the image file to a directory on the server, and embed a reference to the file in an HTML <code>img</code> tag. The process was cumbersome and the product was ugly. In 2009 I wrote <a href="http://bit-player.org/bph-publications/AmSci-2009-03-Hayes-webmath.pdf">an <em>American Scientist</em> article</a> whining about this sorry state of affairs—but at just that moment an elegant solution was coming on the scene. Davide Cervone of Union College had created a program called jsMath, which could process TeX commands placed directly in an HTML document. For example, I could write:</p>
<pre style="text-align: center;"><code>e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \cdots</code></pre>
<p>and it would appear on your screen as:</p>
<p>\[e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \cdots\]</p>
<p class="undent">All the work of parsing the TeX code and typesetting the math was done by a JavaScript program downloaded into your browser along with the rest of the web page.</p>
<p>Cervone’s jsMath soon evolved into <a href="https://www.mathjax.org/">MathJax</a>, an <a href="https://github.com/mathjax">open-source project</a> initially supported by the AMS and SIAM. There are now about two dozen sponsors, and the project is under the aegis of <a href="https://numfocus.org/">NumFOCUS</a>. From the MathJax web page: “The MathJax team consists of Davide Cervone and Volker Sorge. Regular contributors include Christian Lawson-Perfect, Omar Al-Ithawi, and Peter Krautzberger.”Cervone remains the principal author, though not the only contributor.</p>
<p>MathJax has made a big difference in my working life, transforming a problem into a pleasure. Putting math on the web is fun! Sometimes I do it just to show off. Furthermore, the software has served as an inspiration as well as a helpful tool. Until I saw MathJax in action, it simply never occurred to me that interesting computations could be done within the JavaScript environment of a web browser, which I had thought was there mainly to make things blink and jiggle. With the example of MathJax in front of me, I realized that I could not only display mathematical ideas but also explore and animate them within a web page.</p>
<hr/>
<p>Last fall I began hearing rumors about MathJax 3.0, “a complete rewrite of MathJax from the ground up using modern techniques.” It’s the kind of announcement that inspires both excitement and foreboding. What will the new version add? What will it take away? What will it fix? What will it break?</p>
<p>Before committing all of bit-player to the new version, I thought I would try a small-scale experiment. I have a standalone web page that makes particularly tricky use of MathJax. The page is a repository of the <a href="https://bit-player.github.io/dotster/">Dotster</a> programs extracted from a recent bit-player post, <a href="http://bit-player.org/2019/my-god-its-full-of-dots">My God, it’s full of dots</a>. In January I got the Dotster page running with MathJax 3.</p>
<p>Most math in web documents is static content: An equation needs to be formatted once, when the page is first displayed, and it never changes after that. The initial type­setting is handled automatically by MathJax, in both the old and the new versions. As soon as the page is downloaded from the server, MathJax makes a pass through the entire text, identifying elements flagged as TeX code and replacing them with typeset math. Once that job is done, MathJax can go to sleep.</p>
<p>The Dotster programs are a little different; they include equations that change dynamically in response to user input. Here’s an example:</p>


<p>The slider on the left sets a numerical value that gets plugged into the two equation on the right. Each time the slider is moved, the equations need to be updated and reformatted. Thus with each change to the slider setting, MathJax has to wake up from its slumbers and run again to typeset the altered content.</p>
<p>The MathJax program running in the little demo above is the older version, 2.7. Cosmetically, the result is not ideal. With each change in the slider value, the two equations contract a bit, as if pinched between somebody’s fingers, and then snap back to their original size. They seem to wink at us. The progress banner would normally appear in the lower left corner of the browser window, where it is less intrusive. It has a more prominent position here because the demo is encapsulated in an iFrame, which acts as a window within the window. This structure is necessary in order to run two versions of MathJax in a single page. Also, a small gray progress indicator pops up in the lower left corner and hangs around just long enough to grab your attention. It says: “Typesetting math: 100%.” I find these visual distractions pretty annoying. They are analogous to the dreaded FOUC—the “flash of unstyled content”—that appears when a web browser displays the text of a page before the associated stylesheets are fully loaded and processed.</p>
<p>The winking effect is caused by a MathJax feature called Fast Preview. The system does a quick-and-dirty rendering of the math content without calculating <img alt="Math settings submenus" border="0" class="alignright" height="180" src="http://bit-player.org/wp-content/uploads/2020/02/math-settings-submenus.png" width="350"/> the correct final sizes for the various typographic ele­ments. (Evi­dently that calculation takes a little time). You can turn off Fast Preview by right-clicking or control-clicking one of the equa­tions and then navigating through the sub­menus shown at right. How­ever, you’ll probably judge the result to be worse rather than better. Without Fast Preview, you’ll get a  glimpse of the raw TeX commands. Instead of winking, the equations do jumping jacks.</p>
<p>I am delighted to report that all of this visual noise has been eliminated in the new MathJax. On changing a slider setting, the equations are updated in place, with no unnecessary visual fuss. And there’s no need for a progress indication, because the change is so quick it appears to be instantaneous. See for yourself:</p>


<p>Thus version 3 looks like a big win. There’s a caveat: Getting it to work did not go quite as smoothly as I had hoped. Nevertheless, this is a story with a happy ending.</p>
<hr/>
<p>If you have only static math content in your documents, making the switch to MathJax 3 is easy. In your HTML file you change a URL to load the new MathJax version, and convert any configuration options to a new format. As it happens, all the default options work for me, so I had nothing to convert. What’s most important about the upgrade path is what you <em>don’t</em> need to do. In most cases you should not have to alter any of the TeX commands present in the HTML files being processed by MathJax. (There are a <a href="http://docs.mathjax.org/en/latest/upgrading/v2.html#input-changes">few small exceptions</a>.)</p>
<p>With dynamic content, further steps are needed. Here is the JavaScript statement I used to reawaken the typesetting engine in MathJax version 2.7:</p>
<pre class="language-js"><code>MathJax.Hub.Queue(["Typeset", MathJax.Hub, mathjax_demo_box]);
</code></pre>
<p>The statement enters a <code>Typeset</code> command into a queue of pending tasks. When the command reaches the front of the queue, MathJax will typeset any math found inside the HTML element designated by the identifier <code>mathjax_demo_box</code>, ignoring the rest of the document.</p>
<p>In MathJax 3, the <a href="http://docs.mathjax.org/en/latest/web/typeset.html#typesetting-math-in-a-web-page">documentation</a> suggested I could simply replace this command with a slightly different and more direct one:</p>
<pre class="language-js"><code>MathJax.typeset([mathjax_demo_box]);
</code></pre>
<p>I did that. It didn’t work. When I moved the slider, the displayed math reverted to raw TeX form, and I found an error message in the JavaScript console:</p>
<p><img alt="AppendChild null error 530x170" border="0" class="centered" height="170" src="http://bit-player.org/wp-content/uploads/2020/02/appendChild-null-error-530x170.png" width="530"/></p>
<p>What has gone wrong here? JavaScript’s <code>appendChild</code> method adds a new node to the treelike structure of an HTML document. It’s like hanging an ornament from some specified branch of a Christmas tree. The error reported here indicates that the specified branch does not exist; it is <code>null</code>.</p>
<p>Let’s not tarry over my various false starts and wrong turns as I puzzled over the source of this bug. I eventually found the cause and the solution in the “issues” section of the MathJax repository on GitHub. Back in September of last year Mihai Borobocea had <a href="https://github.com/mathjax/MathJax/issues/2191">reported a similar problem</a>, along with the interesting observation that the error occurs only when an existing TeX expression is being replaced in a document, not when a new expression is being added. Borobocea had also discovered that invoking the procedure <code>MathJax.typesetClear()</code> before <code>MathJax.typeset()</code> would prevent the error.</p>
<p>A comment by Cervone explains much of what’s going on:</p>
<blockquote><p>You are correct that you should use <code>MathJax.typesetClear()</code> if you have removed previously typeset math from the page. (In version 3, there is information stored about the math in a list of typeset expressions, and if you remove typeset math from the page and replace it with new math, that list will hold pointers to math that no longer exists in the page. That is what is causing the error you are seeing . . . )</p></blockquote>
<p>I found that adding <code>MathJax.typesetClear()</code> did indeed eliminate the error. As a practical matter, that solved my problem. But Borobocea pointed out a remaining loose end. Whereas <code>MathJax.typeset([mathjax_demo_box])</code> operates only on the math inside a specific container, <code>MathJax.typesetClear()</code> destroys the list of math objects for the entire document, an act that might later have unwanted consequences. Thus it seemed best to reformat all the math in the document whenever any one expression changes. This is inefficient, but with the 20-some equations in the Dotster web page the typesetting is so fast there’s no perceptible delay.</p>
<p>In January a fix for this problem was merged into MathJax 3.0.1, which is now the shipping version. Cervone’s comment on this change says that it “prevents the error message,” which left me with the impression that it might suppress the message without curing the error itself. But as far as I can tell the entire issue has been cleared up. There’s no longer any need to invoke <code>MathJax.typesetClear()</code>.</p>
<hr/>
<p>In my first experiments with version 3.0 I stumbled onto another bit of weirdness, but it turned out to be a quirk of my own code, not something amiss in MathJax. </p>
<p>I was seeing occasional size variations in typeset math that seemed reminiscent of the winking problem in version 2.7. <img alt="large and small math superimposed" border="0" class="alignright" height="99" src="http://bit-player.org/wp-content/uploads/2020/02/zs-large-and-small-math.png" width="159"/>Sometimes the initial, automatic typesetting would leave the equations in a slightly smaller size; they would grow back to normal as soon as <code>MathJax.typeset()</code> was applied. In the image at right I have superimposed the two states, with the correct, larger image colored red. It looks like Fast Preview has come back to haunt us, but that can’t be right, because Fast Preview has been removed entirely from version 3.</p>
<p>My efforts to solve this mystery turned into quite a debugging debacle. I got a promising clue from an exchange on the <a href="https://github.com/mathjax/mathjax-docs/wiki/Dealing-with-display:none">MathJax wiki</a>, discussing size anomalies when math is composed inside an HTML element temporarily flagged <code>display: none</code>, a style rule that makes the math invisible. In that circumstance MathJax has no information about the surrounding text, and so it leaves the typeset math in a default state. The same mechanism might account for what I was seeing—except that my page has no elements with a <code>display: none</code> style.</p>
<p>I first observed this problem in the Chrome browser, where it is intermittent; when I repeatedly reloaded the page, the small type would appear about one time out of five. What fun! It takes multiple trials just to know whether an attempted fix has had any effect. Thus I was pleased to discover that in Firefox the shrunken type appears consistently, every time the page is loaded. Testing became a great deal easier.</p>
<p>I soon found a cure, though not a diagnosis. While browsing again in the MathJax issues archive and in a <a href="https://groups.google.com/forum/?pli=1#!forum/mathjax-users">MathJax user forum</a>, I came across suggestions to try a different form of output, with mathematical expressions constructed not from text elements in HTML and style rules in CSS but from paths drawn in Scalable Vector Graphics, or SVG. I found that the SVG expressions were stable and consistent in size, and in other respects indistinguishable from their HTML siblings. Again my problem was solved, but I still wanted to know the underlying cause.</p>
<p>Here’s where the troubleshooting report gets a little embarrassing. Thinking I might have a new bug to report, I set out to build a minimal exemplar—the smallest and simplest program that would trigger the bug. I failed. I was starting from a blank page and adding more and more elements of the original program—<code>div</code>s nested inside <code>div</code>s in the HTML, various stylesheet rules in the CSS, bigger collections of more complex equations—but none of these additions produced the slightest glitch in typesetting. So I tried working in the other direction, starting with the complex misbehaving program and stripping away elements until the problem disappeared. But it didn’t disappear, even when I reduced the page to a single equation in a plain white box.</p>
<p>As often happens, I found the answer not by banging my head against the problem but by going for a walk. Out in the fresh air, I finally noticed the one oddity that distinguished the failing program from all of the correctly working ones. Because the Dotster program began life embedded in a WordPress blog post, I could not include a link to the CSS stylesheet in the <code>head</code> section of the HTML file. Instead, a JavaScript function constructed the link and inserted it into the <code>head</code>. That happened <em>after</em> MathJax made its initial pass over the text. At the time of typesetting, the elements in which the equations were placed had no styles applied, and so MathJax had no way of determining appropriate sizes.</p>
<hr/>
<p>When Don Knuth unveiled TeX, circa 1980, I was amazed. Back then, typewriter-style word processing was impressive enough. TeX did much more: real typesetting, with multiple fonts (which Knuth also had to create from scratch), automatic hyphenation and justification, and beautiful mathematics.</p>
<p>Thirty years later, when Cervone created MathJax, I was amazed again—though perhaps not for the right reasons. I had supposed that the major programming challenge would be capturing all the finicky rules and heuristics for building up math expressions—placing and sizing superscripts, adjusting the height and width of parentheses or a radical sign to match the dimensions of the expression enclosed, spacing and aligning the elements of a matrix. Those are indeed nontrivial tasks, but they are just the beginning. My recent adventures have helped me see that another major challenge is making TeX work in an alien environment.</p>
<p>In classic TeX, the module that typesets equations has direct access to everything it might ever need to know about the surrounding text—type sizes, line spacing, column width, the amount of interword “glue” needed to justify a line of type. Sharing this information is easy because all the formatting is done by the same program. MathJax faces a different situation. Formatting duties are split, with MathJax handling mathematical content but the browser’s layout engine doing everything else. Indeed, the document is written in two different languages, TeX for the math and HTML/CSS for the rest. Coordinating actions in the two realms is not straightforward.</p>
<p>There are other complications of importing TeX into a web page. The classic TeX system runs in batch mode. It takes some inputs, produces its output, and then quits. Batch processing would not offer a pleasant experience in a web browser. The entire user interface (such as the buttons and sliders in my Dotster programs) would be frozen for the duration. To avoid this kind of rudeness to the user, MathJax is never allowed to monopolize JavaScript’s single thread of execution for more than a fraction of a second. To ensure this cooperative behavior, earlier versions relied on a hand-built scheme of queues (where procedures wait their turn to execute) and callbacks (which signal when a task is complete). Version 3 takes advantage of a new JavaScript construct called a <em>promise</em>. When a procedure cannot compute a result immediately, it hands out a promise, which it then redeems when the result becomes available.</p>
<p>Wait, there’s more! MathJax is not just a TeX system. It also accepts input written in MathML, a dialect of XML specialized for mathematical notation. Indeed, the internal language of MathJax is based on MathML. And MathJax can also be configured to handle <a href="http://asciimath.org/">AsciiMath</a>, a cute markup language that aims to make even the raw form of an expression readable. Think of it as math with emoticons: Type <code>`oo`</code> and you’ll get \(\infty\), or <code>`:-`</code> for \(\div\).</p>
<p>MathJax also provides an extensive suite of tools for accessibility. Visually impaired readers can have an equation read aloud. As I learned at the January Joint Math Meetings, there are even provisions for generating Braille output—but that’s a subject that deserves a post of its own.</p>
<hr/>
<p>When I first encountered MathJax, I saw it as a marvel, but I also considered it a workaround or stopgap. Reading a short document that includes a single equation entails downloading the entire MathJax program, which can be much larger than the document itself. And you need to download it all again for every other mathy document (unless your browser cache hangs onto a copy). What an appalling waste of bandwidth. </p>
<p>Several alternatives seemed more promising as a long-term solution. The best approach, it seemed to me then, was to have support for mathematical notation built into the browser. Modern browsers handle images, audio, video, SVG, animations—why not math? But it hasn’t happened. Firefox and Safari have limited support for MathML; none of the browsers I know are equipped to deal with TeX.</p>
<p>Another strategy that once seemed promising was the browser plugin. A plugin could offer the same capabilities as MathJax, but you would download and install it only once. This sounds like a good deal for readers, but it’s not so attractive for the author of web content. If there are multiple plugins in circulation, they are sure to have quirks, and you need to accommodate all of them. Furthermore, you need some sort of fallback plan for those who have not installed a plugin.</p>
<p>Still another option is to run MathJax on the server, rather than sending the whole program to the browser. The document arrives with TeX or MathML already converted to HTML/CSS or SVG for display. This is the preferred modus operandi for several large websites, most notably Wikipedia. I’ve considered it for bit-player, but it has a drawback: Running on the server, MathJax cannot provide the kind of on-demand typesetting seen in the demos above.</p>
<p>As the years go by, I am coming around to the view that MathJax is not just a useful stopgap while we wait for the right thing to come along; it’s quite a good approximation to the right thing. As the author of a web page, I get to write mathematics in a familiar and well-tested notation, and I can expect that any reader with an up-to-date browser will see output that’s much like what I see on my own screen. At the same time, the reader also has control over how the math is rendered, via the context menu. And the program offers accessibility features that I could never match on my own.</p>
<p>To top it off, the software is open-source—freely available to everyone. That is not just an economic advantage but also a social one. The project has a community that stands ready to fix bugs, listen to suggestions and complaints, offer help and advice. Without that resource, I would still be struggling with the hitches and hiccups described above.</p></div>
    </content>
    <updated>2020-03-14T18:06:50Z</updated>
    <published>2020-03-14T18:06:50Z</published>
    <category scheme="http://bit-player.org" term="computing"/>
    <category scheme="http://bit-player.org" term="mathematics"/>
    <author>
      <name>Brian Hayes</name>
      <uri>http://bit-player.org</uri>
    </author>
    <source>
      <id>http://bit-player.org/feed/atom</id>
      <link href="http://bit-player.org" rel="alternate" type="text/html"/>
      <link href="http://bit-player.org/feed/atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">An amateur's outlook on computation and mathematics</subtitle>
      <title xml:lang="en-US">bit-player</title>
      <updated>2020-03-14T18:49:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/034</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/034" rel="alternate" type="text/html"/>
    <title>TR20-034 |  On Proof complexity of Resolution over Polynomial Calculus | 

	Erfan Khaniki</title>
    <summary>The refutation system ${Res}_R({PC}_d)$ is a natural extension of resolution refutation system such that it operates with disjunctions of degree $d$ polynomials over ring $R$ with boolean variables. For $d=1$, this system is called ${Res}_R({lin})$. Based on properties of $R$, ${Res}_R({lin})$ systems can be too strong to prove lower bounds for CNFs with current methods. The reachable goal might be proving lower bounds for ${Res}_R({lin})$ when $R$ is a finite field such as $\mathbb{F}_2$. Interestingly, ${Res}_{\mathbb{F}_2}({lin})$ is also fairly strong, and there is no known nontrivial lower bound for it, but for ${Res}^*_R({lin})$ (tree-like ${Res}_R({lin})$) we know exponential lower bounds for every finite field.
 For the stronger systems ${Res}_R({PC}_d)$ and ${Res}_R^*({PC}_d)$ for $d&gt;1$ on finite ring $R$, there is no known lower bounds till now. In this paper we will investigate these refutation systems and make some progress toward understanding these systems, including the case $d=1$. We prove a size-width relation for ${Res}_R({PC}_d)$ and ${Res}^*_R({PC}_d)$ for every finite ring $R$. This relation is proved by a new idea to reduce the problem to the original Ben-Sasson and Wigderson size-width relation for ${Res}$ and ${Res}^*$ using extension variables. As a by product, we get the following new lower bounds for every finite field $\mathbb{F}$:
(1) We prove the first nontrivial lower bounds for ${Res}_\mathbb{F}({PC}_d)$ for fixed $d$: a nearly quadratic lower bounds for mod $q$ Tseitin formulas ($char(\mathbb{F})\neq q$) for suitable graphs.
(2) We also prove superpolynomial and exponential lower bounds for ${Res}^*_\mathbb{F}({PC}_{d})$ where $d$ is not too large with respect to $n$ for the following principles:
 (a) mod $q$ Tseitin formulas ($char(\mathbb{F})\neq q$),
 (b) Random $k$-CNFs.</summary>
    <updated>2020-03-13T15:56:30Z</updated>
    <published>2020-03-13T15:56:30Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-03-17T21:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/03/13/postdoc-at-university-of-edinburgh-apply-by-april-9-2020/</id>
    <link href="https://cstheory-jobs.org/2020/03/13/postdoc-at-university-of-edinburgh-apply-by-april-9-2020/" rel="alternate" type="text/html"/>
    <title>postdoc at University of Edinburgh (apply by April 9, 2020)</title>
    <summary>Applications are invited for a position of Research Associate on Algorithms and Machine Learning, which is provided by Dr He Sun’s 5-year £1.51M EPSRC Fellowship “Efficient Spectral Algorithms for Massive and Dynamic Graphs”. The post associated with the Fellowship is to work on graph clustering, and the post will receive many support for attending conferences […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a position of Research Associate on Algorithms and Machine Learning, which is provided by Dr He Sun’s 5-year £1.51M EPSRC Fellowship “Efficient Spectral Algorithms for Massive and Dynamic Graphs”. The post associated with the Fellowship is to work on graph clustering, and the post will receive many support for attending conferences and academic visits.</p>
<p>Website: <a href="https://www.vacancies.ed.ac.uk/pls/corehrrecruit/erq_jobspec_version_4.jobspec?p_id=051734">https://www.vacancies.ed.ac.uk/pls/corehrrecruit/erq_jobspec_version_4.jobspec?p_id=051734</a><br/>
Email: h.sun@ed.ac.uk</p></div>
    </content>
    <updated>2020-03-13T10:25:24Z</updated>
    <published>2020-03-13T10:25:24Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-03-17T21:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=741</id>
    <link href="https://emanueleviola.wordpress.com/2020/03/12/1348-1665-2020/" rel="alternate" type="text/html"/>
    <title>1348, 1665, 2020</title>
    <summary>Besides unimaginable suffering and horror, the Black Death of the 1340’s also brought increased wages and better living standards. It came back, among other times, in 1665. Then like now, universities closed and students went home. Among them was Newton, who spent his time alone in the countryside thus: In the beginning of the year […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Besides unimaginable suffering and horror, the Black Death of the 1340’s also brought increased wages and better living standards.  It came back, among other times, in 1665.  Then like now, universities closed and students went home.  Among them was Newton, who spent his time alone in the countryside thus:</p>



<p><strong>In the beginning of the year 1665 I found the method of approximating series and the rule for reducing any dignity [power] of any binomial into such a series. The same year in May I found the method of tangents of Gregory and Slusius, and in November had the direct method of fluxions and the next year [1666] in January had the theory of colours and in May following I had entrance into the inverse method of fluxions. And the same year I began to think of gravity extending to the orb of the moon … All this was in the two plague years of 1665 and 1666, for in those days I was in the prime of my age for invention and minded Mathematics and Philosophy more than at any time since.</strong></p>



<p>Today’s Coronavirus pandemic is probably the first in history that’s been fought with telecommunication.  People are advised to work remotely, and many universities are switching to online courses.  Besides the suffering and horror, it is also an opportunity <a href="https://emanueleviola.wordpress.com/2020/02/18/working-remotely-will-be-the-most-significant-transformation-since-agriculture/">to realize that many things can be done remotely just as well if not better, change our lifestyle, and stop polluting the environment.</a></p></div>
    </content>
    <updated>2020-03-13T01:50:01Z</updated>
    <published>2020-03-13T01:50:01Z</published>
    <category term="Uncategorized"/>
    <category term="health"/>
    <category term="Utopia"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-03-17T21:21:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16778</id>
    <link href="https://rjlipton.wordpress.com/2020/03/12/group-testing-for-the-coronavirus/" rel="alternate" type="text/html"/>
    <title>Group Testing For The Coronavirus</title>
    <summary>Plus other mathematical ideas that may be helping History of Econ. Thought src Robert Dorfman was a professor of political economy at Harvard University, who helped create the notion of group testing. Today Ken and I discuss this notion and its possible application to the current epidemic crisis. We also discuss other mathematical aspects that […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Plus other mathematical ideas that may be helping</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/03/dorfman.jpg"><img alt="" class="alignright wp-image-16780" height="170" src="https://rjlipton.files.wordpress.com/2020/03/dorfman.jpg?w=125&amp;h=170" width="125"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">History of Econ. Thought <a href="https://www.hetwebsite.net/het/profiles/dorfman.htm">src</a></font></td>
</tr>
</tbody>
</table>
<p>
Robert Dorfman was a professor of political economy at Harvard University, who helped create the notion of group testing. </p>
<p>
Today Ken and I discuss this notion and its possible application to the current epidemic crisis. We also discuss other mathematical aspects that have clear and immediate value.</p>
<p>
The novel coronavirus (and its disease <a href="https://en.wikipedia.org/wiki/Coronavirus_disease_2019">COVID-19</a>) is the nasty issue we all face today. I live in New York City and can see the reduced foot traffic every day. The issue is discussed every minute on the news. I hope you are all safe, and well. But we are all worried about this. </p>
<p>
The point of group testing is that it can reduce the number of tests needed to find out who has the virus. I assume that we are not using Dorfman’s idea because it does not apply to today’s testing. But it seems like it could fit. One issue is the need for more individual testing kits. As we write this, the US is still well short of the needed supply of kits. Are there situations where group testing can still help economize?</p>
<p>
</p><p/><h2> Group Testing </h2><p/>
<p/><p>
Dorfman created the notion of <em>group testing</em> in 1943. You could say he was driven by the need to test light bulbs:</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/03/test.png"><img alt="" class="aligncenter size-medium wp-image-16781" height="188" src="https://rjlipton.files.wordpress.com/2020/03/test.png?w=300&amp;h=188" width="300"/></a></p>
<p>As Wikipedia group-testing <a href="https://en.wikipedia.org/wiki/Group_testing">article</a> explains:</p>
<blockquote><p><b> </b> <em> [Suppose] one is searching for a broken bulb among six light bulbs. Here, the first three are connected to a power supply, and they light up (A). This indicates that the broken bulb must be one of the last three (B). If instead the bulbs did not light up, one could be sure that the broken bulb was among the first three. Continuing this procedure can locate the broken bulb in no more than three tests, compared to a maximum of six tests if the bulbs are checked individually. </em>
</p></blockquote>
<p/><p>
Okay, Dorfman’s motivation was not light bulbs. It was testing soldiers during WWII for a certain disease, that will go unnamed. This type of testing reduced the number of blood samples needed. What was analogous to connecting groups of light bulbs into one circuit was combining portions of individual blood samples into one sample. If it tested negative then that entire group could be dismissed without further testing.</p>
<p>
</p><p/><h2> Fewer Kits </h2><p/>
<p/><p>
The point of using group testing is made stark when you think about recent issues with cruise ships. On one ship there were around <img alt="{3500}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3500%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3500}"/> passengers who were eventually found to be almost all okay. I believe only <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/> were infected. This could have been checked by group testing with many fewer than <img alt="{3500}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3500%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3500}"/> tests. </p>
<p>
According to the current outbreak <a href="https://www.nytimes.com/interactive/2020/world/coronavirus-maps.html">maps</a>, known <a href="https://www.nytimes.com/interactive/2020/world/coronavirus-maps.html#us">cases</a> in the US are still fairly sparse. Those in New York are mainly in the city, Westchester, and along the Hudson River to Albany. Let’s say we wish assurance that all non-virus related admits to a hospital are free of the virus. Can group testing apply?</p>
<p>
The original version of group testing would apply if it were deemed mandatory that all new admits give a blood sample. Some kinds of coronavirus <a href="https://en.wikipedia.org/wiki/COVID-19_testing">test kits</a> use blood samples. Taking blood samples might however be as costly and intrusive as having the individual tests to begin with. There are other kinds of tests involving taking swabs, but it is not apparent whether those samples can be combined at scale as readily as blood samples can.</p>
<p>
At least the <em>idea</em> of group testing has interesting connections to other parts of theory. Here is a 2000 <a href="https://www.cs.umn.edu/sites/cs.umn.edu/files/tech_reports/00-007.pdf">survey</a> by Ken’s former Buffalo colleague Hung Ngo with his PhD advisor, Ding-Zhu Du, where the application is to large scale screening of DNA samples. Hung and Ken’s colleague Atri Rudra taught a <a href="https://cse.buffalo.edu/~hungngo/classes/2011/709/">course</a> in Buffalo on group testing in relation to <em>compressed sensing</em>. More recent is a 2015 <a href="https://ieeexplore.ieee.org/document/7308980">paper</a> that tries to solve problems of counting the number of positive cases, not just whether they exist. </p>
<p>
</p><p/><h2> Other Mathematical Effects </h2><p/>
<p/><p>
As we write, New York Governor Andrew Cuomo has just declared a cap of 500 attendees for any assembly. This is forcing the suspension of Broadway shows among many other activities. Yesterday the entire SUNY system joined numerous other institutions in moving to distance-only learning after this week.  </p>
<p>
The cap is based on the likelihood of <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> persons including someone who is already infected. That likelihood in turn is based on the density of known cases and what is known about the proportion of unknown to known cases. The virus has a long (two weeks) incubation time during which it is contagious but not symptomatic.</p>
<p>
Here is a graph from a PSA <a href="https://marginalrevolution.com/marginalrevolution/2020/03/covid-19-event-risk-assessment-planner.html">item</a> posted just today by Alex Tabarrok for the <em>Marginal Revolution</em> blog (note that the calculations are by <a href="https://biosciences.gatech.edu/people/joshua-weitz">Joshua</a> <a href="http://ecotheory.biology.gatech.edu/">Weitz</a> of Georgia Tech):</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/03/riskassessment-1024x776-1.jpg"><img alt="" class="aligncenter wp-image-16782" height="425" src="https://rjlipton.files.wordpress.com/2020/03/riskassessment-1024x776-1.jpg?w=550&amp;h=425" width="550"/></a></p>
<p>
The <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/>-axis is the number of cases (in proportion to the US on the whole) and the <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>-axis is the group size. Which axis is more important—has more effect on the danger? Tabarrok notes:</p>
<blockquote><p><b> </b> <em> Now here is the most important point. It’s the size of the group, not the number of carriers that most drives the result. </em>
</p></blockquote>
<p/><p>
This involves comparing two partial derivatives. The <a href="https://marginalrevolution.com/marginalrevolution/2020/03/covid-19-event-risk-assessment-planner.html">item</a> gives a brief worked-out example without using calculus. </p>
<p>
I, Ken, have been connected this week to another example. I was statistically monitoring the World Senior Team Chess Championship, which began last Friday in Prague. Almost 500 players in teams of 4 or 5 players took part. Initially the players were roughly evenly divided between two halls. Effective Tuesday, a cap of 100 was declared for the Czech Republic, so more playing rooms were found and spectators were banned. Today, however, after an update on the density of cases in the Czech Republic, the cap was lowered to 30 effective tomorrow.  Thus the tournament was forced to finish today, two rounds earlier than planned. Even though chess events have a lower size footprint than all of the spectator sports whose seasons have been suspended in recent days, the growth of the outbreak is making cancellation the only reasonable policy for all but the smallest events.</p>
<p>
The main purpose of these and other <em>social isolation</em> measures is to flatten out the growth of cases. The target is not just to contain the outbreak but also to stay below the number of serious cases that our treatment systems can bear at once. Here is one of numerous versions of a <a href="https://healthblog.uofmhealth.org/wellness-prevention/flattening-curve-for-covid-19-what-does-it-mean-and-how-can-you-help">graphic</a> that is being widely circulated:</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/03/coronavirus_flattening_curve_1.jpg"><img alt="" class="aligncenter wp-image-16783" height="223" src="https://rjlipton.files.wordpress.com/2020/03/coronavirus_flattening_curve_1.jpg?w=400&amp;h=223" width="400"/></a></p>
<p>
The graphic is not necessarily talking about reducing the number of cases <em>total</em>. The area under both curves is the same. A sentence in accompanying article—</p>
<blockquote><p><b> </b> <em> If individuals and communities take steps to slow the virus’s spread, that means the number of cases of COVID-19 will stretch out across a longer period of time. </em>
</p></blockquote>
<p/><p>
—seems to imply that “the number of cases” is the same in both scenarios, but stretched out over time in the latter. The point is how the stretching keeps the <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/>-value bounded.  <b>Update 3/15:</b> To complete the thoughts here, we <i>should</i> be talking about reducing the number of cases—see <a href="https://medium.com/@joschabach/flattening-the-curve-is-a-deadly-delusion-eea324fe9727">this</a>.</p>
<p>
We certainly hope that isolation can reduce that number—i.e., that containment data out of Southeast Asia in particular holds true, as opposed to fears being voiced in the West that the virus will spread to a large percentage of the population over time. See charts <a href="https://medium.com/@tomaspueyo/coronavirus-act-today-or-people-will-die-f4d3d9cd99ca">here</a>, especially chart 7.  This tracking <a href="https://www.washingtonpost.com/world/2020/01/22/mapping-spread-new-coronavirus/?arc404=true">map</a> has free access and is updated daily.</p>
<p>
What governs the spreading process? This is being understood via simple mathematical models of contagion, such as come from <a href="https://en.wikipedia.org/wiki/Percolation_theory">percolation theory</a> and its associated <img alt="{R_0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{R_0}"/> <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2895684/">factor</a>. Almost a month ago, the Washington Post made an <a href="https://www.washingtonpost.com/graphics/2020/health/coronavirus-how-epidemics-spread-and-end/">interactive</a> showing how epidemics spread according to the parameters in these models. How and whether the COVID-19 pandemic follows these models remains to be seen. Of course we hope it stays on the better side of the equations.  <b>Update 3/15:</b> This new <a href="https://www.washingtonpost.com/graphics/2020/world/corona-simulator/">animation</a> from the Washington Post shows how the “better side” can arise.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Is group testing a practical <em>mechanism</em> for mapping and constraining the epidemic? How can we promote the understanding of mechanisms and equations and models, not only for those shaping policy but for us who must abide by it and know why.</p>
<p>
[added note about UB and others going to online learning, added small-event qualifier about chess, clarified COVID-19 is the disease, added map link and two updates.]</p></font></font></div>
    </content>
    <updated>2020-03-12T23:54:25Z</updated>
    <published>2020-03-12T23:54:25Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="coronavirus"/>
    <category term="COVID-19"/>
    <category term="epidemic"/>
    <category term="group testing"/>
    <category term="pandemic"/>
    <category term="percolation"/>
    <category term="public health"/>
    <category term="Robert Dorfman"/>
    <category term="statistics"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-03-17T21:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7645</id>
    <link href="https://windowsontheory.org/2020/03/12/life-and-cs-theory-in-the-age-of-coronavirus/" rel="alternate" type="text/html"/>
    <title>Life and CS theory in the age of Coronavirus</title>
    <summary>Harvard University, as well most other places that I know of will be moving to remote lectures. I just gave the last in-person lecture in my cryptography course. I would appreciate technical suggestions on the best format for teaching remotely. At the moment I plan to use Zoom and log-in from both my laptop (for […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Harvard University, as well most other places that I know of will be moving to remote lectures. I just gave the last in-person lecture in my <a href="https://cs127.boazbarak.org/schedule/">cryptography course</a>. I would appreciate technical suggestions on the best format for teaching remotely. At the moment I plan to use Zoom and log-in from both my laptop (for the video) and from my iPad pro (for the interactive whiteboard).  </p>



<p>The one silver lining is that more lectures will be available online. In particular, if you’re teaching algorithms, you might find <a href="https://gt-algorithms.com/">Eric Vigoda’s videos helpful</a>. (If you know of more sources, please let us know.)</p>



<p>I was hoping that reducing meetings and activities will be good for research, but currently find it hard to concentrate on anything except this train-wreck of a situation. The <a href="https://www.ft.com/content/ff3affea-63c7-11ea-b3f3-fe4680ea68b5">financial times</a> has a chart that summarizes the progress of the  disease in several countries:</p>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-7646" src="https://windowsontheory.files.wordpress.com/2020/03/http___com.ft_.imagepublish.upp-prod-us.s3.amazonaws.png?w=700"/></figure>



<p>The number of confirmed cases grows by about 33% each day. This growth in confirmed cases is partially due to increased testing  as cases increase – there is <a href="https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(20)30260-9/fulltext">some evidence</a>  that the doubling time of the disease (time between <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> infected people to <img alt="2n" class="latex" src="https://s0.wp.com/latex.php?latex=2n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2n"/> infected) is about 6 days (rather than the 2.4 days that this figure suggest). However, a doubling time of 6 days still means that the number of cases grows 10-fold in a month, and so if there are 10K actual cases in the U.S., today, there would be 100K by mid April and 1M by mid May.</p>



<p/>



<p>Strong quarantine regimes, contact tracing, and drastically reducing activity and increasing “social distance” can very significantly reduce the base of this exponent. Reducing the base of the exponent is more than simply “delaying the inevitable”. The mortality statistics mask the fact that this can be a very serious illness even for the people who don’t die of it – about 5% of the cases need intensive care (see this <a href="https://www.economist.com/united-states/2020/03/12/covid-19-is-rapidly-spreading-in-america-the-country-does-not-look-ready">Economist article</a>). Spreading the infections over time will enable the healthcare system to handle the increased caseload, which will completely overwhelm it otherwise.</p>



<p>Such steps are clearly much easier to achieve before the number of cases is too large to be manageable, but despite having “advance warning” from other countries, this lesson does not seem at the moment to have sunk in, at least here in the U.S. At the moment no such initiatives are taken at the federal level, the states are doing more but still not enough, and it’s up to private companies and institutions to come up with their own policies. As faculty and citizens there is not much we can do about it except support such decisions even when they are <a href="https://www.thecrimson.com/article/2020/3/12/parents-petition-coronavirus-measure/">unpopular</a>, and just try to make the remote experience as good as possible for us, our colleagues, and our students.</p></div>
    </content>
    <updated>2020-03-12T20:09:04Z</updated>
    <published>2020-03-12T20:09:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-03-17T21:21:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/033</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/033" rel="alternate" type="text/html"/>
    <title>TR20-033 |  New Exponential Size Lower Bounds against Depth Four Circuits of Bounded Individual Degree | 

	Suryajith Chillara</title>
    <summary>Kayal, Saha and Tavenas [Theory of Computing, 2018] showed that for all large enough integers $n$ and $d$ such that $d\geq \omega(\log{n})$, any syntactic depth four circuit of bounded individual degree $\delta = o(d)$ that computes the Iterated Matrix Multiplication polynomial ($IMM_{n,d}$) must have size $n^{\Omega\left(\sqrt{d/\delta}\right)}$. Unfortunately, this bound deteriorates as the value of $\delta$ increases. Further, the bound is superpolynomial only when $\delta$ is $o(d)$. It is natural to ask if the dependence on $\delta$ in the bound could be weakened. Towards this, in an earlier result [STACS, 2020], we showed that for all large enough integers $n$ and $d$ such that $d = \Theta(\log^2{n})$, any syntactic depth four circuit of bounded individual degree $\delta\leq n^{0.2}$ that computes $IMM_{n,d}$ must have size $n^{\Omega(\log{n})}$.

  In this paper, we make further progress by proving that for all large enough integers $n$ and $d$, and absolute constants $a$ and $b$ such that $\omega(\log^2n)\leq d\leq n^{a}$, any syntactic depth four circuit of bounded individual degree $\delta\leq n^{b}$ that computes $IMM_{n,d}$ must have size $n^{\Omega(\sqrt{d})}$. Our bound is obtained by carefully adapting the proof of Kumar and Saraf [SIAM J. Computing, 2017] to the complexity measure introduced in our earlier work [STACS, 2020].</summary>
    <updated>2020-03-12T13:49:39Z</updated>
    <published>2020-03-12T13:49:39Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-03-17T21:20:28Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7966517894480895355</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7966517894480895355/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/03/the-importance-of-networking.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7966517894480895355" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7966517894480895355" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/03/the-importance-of-networking.html" rel="alternate" type="text/html"/>
    <title>The Importance of Networking</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">People skip conferences because of the coronavirus or for <a href="https://cacm.acm.org/magazines/2020/1/241717-publish-and-perish/fulltext">global</a> <a href="https://www.change.org/p/organizers-of-data-science-and-machine-learning-conferences-neurips-icml-aistats-iclr-uai-allow-remote-paper-poster-presentations-at-conferences">warming</a> or just because conferences are too expensive and time consuming. I'm certainly <a href="https://cacm.acm.org/magazines/2009/8/34492-viewpoint-time-for-computer-science-to-grow-up/fulltext">no fan</a> of the current conference structure but I would never want to virtualize all of them. Even if we could completely recreate the conference experience in virtual reality, people would not hang out in the halls without the commitment of having made the physical trip. I made this point in a tweet with a depressing response.<br/>
<blockquote class="twitter-tweet">
<div dir="ltr" lang="en">
At least in CS theory, I don't see any crucial importance. These days it's easy to follow the latest developments online. If you're interested in someone's work, you just email them and start a collaboration. Sooner or later networking in hallways may become a thing of the past.</div>
— Mahdi Cheraghchi (@cheraghchi) <a href="https://twitter.com/cheraghchi/status/1235792583516975104?ref_src=twsrc%5Etfw">March 6, 2020</a></blockquote>


<br/>
<div>
I don't disagree with anything Mahdi says except for the "crucial importance". Great ideas come from chance encounters and random conversations. Many of my research papers would never have happened if not for a conversation had at a conference or on the plane or train rides that took me there. Harken Gilles Brassard's <a href="https://arxiv.org/abs/quant-ph/0604072">origin story</a> of quantum cryptography.<br/>
<blockquote class="tr_bq">
One fine afternoon in late October 1979, I was swimming at the beach of a posh
hotel in San Juan, Puerto Rico. Imagine my surprise when this complete stranger
swims up to me and starts telling me, without apparent provocation on my part,
about Wiesner’s quantum banknotes! This was probably the most bizarre, and
certainly the most magical, moment in my professional life<sup>6</sup>. Within hours, we had
found ways to mesh Wiesner’s coding scheme with some of the then-new concepts
of public-key cryptography.... The ideas that Bennett and I tossed around on the beach that day resulted
in the first paper ever published on quantum cryptography, indeed the paper
in which the term “Quantum Cryptography” was coined. </blockquote>
And Footnote 6 read as follows.<br/>
<blockquote class="tr_bq">
At the risk of taking some of the magic away, I must confess that it was not by accident that
Bennett and I were swimming at the same beach in Puerto Rico. We were both there for the
20th Annual IEEE Symposium on the Foundations of Computer Science. Bennett approached
me because I was scheduled to give a talk on relativized cryptography on the last day of the
Symposium and he thought I might be interested in Wiesner’s ideas. By an amazing coincidence,
on my way to San Juan, I had read Martin Gardner’s account of Bennett’s report on
Chaitin’s Omega, which had just appeared in the November 1979 “Mathematical Games” column
of Scientific American—so, I knew the name but I could not recognize Bennett in that swimmer
because I did not know what he looked like.</blockquote>
After we see a slate of conferences held virtually due to the virus, networking may indeed become a thing of the past. But we'll never know the research not done because of people who never connected.</div></div>
    </content>
    <updated>2020-03-12T13:17:00Z</updated>
    <published>2020-03-12T13:17:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-03-17T17:41:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4675</id>
    <link href="https://www.scottaaronson.com/blog/?p=4675" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4675#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4675" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">First it came for Wuhan</title>
    <summary xml:lang="en-US">Update (March 13): One day after I put up this post—a post that many commenters criticized as too alarmist—the first covid cases were detected in Austin. As a result, UT Austin closed its campus (including my son’s daycare), and at 3:30am, the Austin Independent School District announced its decision to suspend all schools until further […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Update (March 13):</strong> One day after I put up this post—a post that many commenters criticized as too alarmist—the first covid cases were detected in Austin.  As a result, UT Austin closed its campus (including my son’s daycare), and at 3:30am, the Austin Independent School District announced its decision to suspend all schools until further notice.  All my remaining plans for the semester (including visits to Berkeley, Stanford, Harvard, CU Boulder, Fermilab, Yale, and CMU) are obviously cancelled.  My family is now on lockdown, in our house, probably at least until the summer.  The war on the virus has reached us.  The “1939” analogy that I mentioned in the post turned out to be more precise than I thought: then, as now, there were intense debates about how just serious the crisis would be, but those debates never even had a chance to get settled by argument; events on the ground simply rendered them irrelevant.</p>



<p><strong>Scott’s foreword:</strong> This week Steve Ebin, a longtime <em>Shtetl-Optimized</em> reader (and occasional commenter) from the San Francisco tech world, sent me the essay below.  Steve’s essay fit too well with my own recent thoughts, and indeed with this blog’s title, for me not to offer to share it here—and to my surprise and gratitude, Steve agreed.</p>



<p>I guess there are only two things I’d add to what Steve wrote.  First, some commenters took me to task for a misplaced emphasis in <a href="https://www.scottaaronson.com/blog/?p=4671">my last coronavirus post</a>, and on further reflection, I now concede that they were right.  When a preventable catastrophe strikes the world, what’s always terrified me most are <em>not</em> the ranting lunatics and conspiracy theorists, even if some of those lunatics actually managed to attain the height of power, from where they played a central role in the catastrophe.  No, what’s terrified me more are the blank-faced bureaucrats who’ve signed the paperwork that amounted to death warrants.  Like, for example, the state regulators who <a href="https://www.nytimes.com/2020/03/10/us/coronavirus-testing-delays.html?referringSource=articleShare">ordered the Seattle infectious disease expert to stop</a>, after she’d had enough of the government’s failure to allow corona tests, took it upon herself to start testing anyway, and found lots of positive results.  Notably, only some countries have empowered lunatics, but the blank-faced bureaucrats rule everywhere unless something stronger overrides them.</p>



<p>Second, I’ll forever ask myself what went wrong with me, that it took me until metaphorical 1939 to acknowledge the scale of an unfolding catastrophe (on more than a purely intellectual level)—even while others were trying to tell me way back in metaphorical 1933.  Even so, better metaphorical 1939 than metaphorical 1946.</p>



<p><strong>Without further ado, Steve’s essay:</strong></p>



<p>The most expensive meal I ever ate was in San Francisco at a restaurant called Eight Tables. As the name implies, the restaurant has only eight tables. The meal cost $1,000 and featured 12 courses, prepared by award-winning chefs.</p>



<p>The most expensive meal a person ever ate was in late 2019, in China, and consisted of under-cooked bat meat. It cost trillions of dollars. The person who ate it, possibly a peasant, changed the course of the 21st century. The bat he ate contained a virus, and the virus threatened to spread from this man to the rest of humanity.</p>



<p>I’m making up some details, of course. Maybe the man wasn’t a peasant. Or he could have been a woman. Or the bat could have been a pangolin. Or maybe, through a lucky accident (the guy was a loner perhaps), it could have not spread. That could have happened, but it didn’t. Or maybe sometimes that does happen and we don’t know it. These are just accidents of history.</p>



<p>I’m writing this on March 9, 2020. The good news is that the virus, in its current form, doesn’t kill children. I am so thankful for that. The bad news is that the virus does kill adults. The virus is like a grim reaper, culling the sick, the debilitated, and the elderly from the population. It attacks the pulmonary system. I heard a 25-year-old survivor describing how he became unable to control his breathing and could not fall asleep or he would die. Even for healthy young people, the prognosis is often poor. </p>



<p>There were Jews in Europe in the 1930s who sat around tables with the elders of their families and villages and debated whether to leave for America, or Palestine, or South America. Most of them, including my grandmother’s family, didn’t leave, and were largely exterminated. The virus of the time was Nazism, and it too attacked the pulmonary systems of the old and the debilitated, in that case with poisonous gasses.</p>



<p>When you grow up as I did, you are taught to have a paranoia in the back of your mind that there is a major disaster about to happen. That a holocaust, or something of that magnitude, might occur in your lifetime. And so you are never complacent. For your whole life, you’re looking and waiting for a history changing event. You try to ensure that you are willing to follow your thoughts to their logical conclusion and take the necessary actions as a result, unlike many of the Jews of 1930s Europe, who refused to confront the obstacle in front of them until it was too late, and unlike many politicians and world leaders today, who are doing the same.</p>



<p>And the conclusion we must now confront is clear. We are watching a once-in-a-century event unfold. Coronavirus–its mutations, its spawn–will change the course of human history. It will overwhelm our defense system and may kill millions. It may continue to mutate and kill millions more. We will develop painful social measures to slow its spread. We will produce vaccines and better treatment protocols. Some of this will help, but none of this will work perfectly. What will happen to society as this unfolds?</p>



<p>My favorite biblical verse comes from Ecclesiastes: To everything there is a season, and a time to every purpose under the heaven. A time to be born, and a time to die. A time to plant and a time to pluck that which is planted. And so on.</p>



<p>The season has changed, and the seven years of famine have begun.</p></div>
    </content>
    <updated>2020-03-12T13:16:15Z</updated>
    <published>2020-03-12T13:16:15Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-03-13T17:37:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/032</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/032" rel="alternate" type="text/html"/>
    <title>TR20-032 |  On Computing Multilinear Polynomials Using Multi-r-ic Depth Four Circuits | 

	Suryajith Chillara</title>
    <summary>In this paper, we are interested in understanding the complexity of computing multilinear polynomials using depth four circuits in which polynomial computed at every node has a bound on the individual degree of $r$ (referred to as multi-$r$-ic circuits). The goal of this study is to make progress towards proving superpolynomial lower bounds for general depth four circuits computing multilinear polynomials, by proving better and better bounds as the value of $r$ increases.
	
  Recently, Kayal, Saha and Tavenas (Theory of Computing, 2018) showed that any depth four arithmetic circuit of bounded individual degree $r$ computing a multilinear polynomial on $n^{O(1)}$ variables and degree $d=o(n)$, must have size at least $\left(\frac{n}{r^{1.1}}\right)^{\Omega\left(\sqrt{\frac{d}{r}}\right)}$ when $r$ is $o(d)$ and is strictly less than $n^{1.1}$. This bound however deteriorates with increasing $r$. It is a natural question to ask if we can prove a bound that does not deteriorate with increasing $r$ or a bound that holds for a "larger" regime of $r$.

  We here prove a lower bound which does not deteriorate with $r$, however for a specific instance of $d = d(n)$ but for a wider range of $r$. Formally, we show that there exists an explicit polynomial on $n^{O(1)}$ variables and degree $\Theta(\log^2 n)$ such that any depth four circuit of bounded individual degree $r&lt;n^{0.2}$ must have size at least $\exp(\Omega(\log^2 n))$. This improvement is obtained by suitably adapting the complexity measure of Kayal et al. (Theory of Computing, 2018). This adaptation of the measure is inspired by the complexity measure used by Kayal et al. (SIAM J. Computing, 2017).</summary>
    <updated>2020-03-12T09:57:52Z</updated>
    <published>2020-03-12T09:57:52Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-03-17T21:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/03/11/canada-research-chair-tier-2-at-university-of-victoria-apply-by-april-30-2020/</id>
    <link href="https://cstheory-jobs.org/2020/03/11/canada-research-chair-tier-2-at-university-of-victoria-apply-by-april-30-2020/" rel="alternate" type="text/html"/>
    <title>Canada Research Chair, Tier 2 at University of Victoria  (apply by April 30, 2020)</title>
    <summary>The Department of Electrical and Computer Engineering and Department of Computer Science, University of Victoria, invite applications for a Canada Research Chair (CRC) Tier 2 in Quantum Computing and Engineering. For full details, please visit our website at https://www.uvic.ca/opportunities/faculty-librarian/current/engn_220_102.php. Website: https://www.uvic.ca/opportunities/faculty-librarian/current/engn_220_102.php Email: engradr@uvic.ca</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Electrical and Computer Engineering and Department of Computer Science, University of Victoria, invite applications for a Canada Research Chair (CRC) Tier 2 in Quantum Computing and Engineering.</p>
<p>For full details, please visit our website at <a href="https://www.uvic.ca/opportunities/faculty-librarian/current/engn_220_102.php.">https://www.uvic.ca/opportunities/faculty-librarian/current/engn_220_102.php.</a></p>
<p>Website: <a href="https://www.uvic.ca/opportunities/faculty-librarian/current/engn_220_102.php">https://www.uvic.ca/opportunities/faculty-librarian/current/engn_220_102.php</a><br/>
Email: engradr@uvic.ca</p></div>
    </content>
    <updated>2020-03-11T21:54:50Z</updated>
    <published>2020-03-11T21:54:50Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-03-17T21:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/031</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/031" rel="alternate" type="text/html"/>
    <title>TR20-031 |  Algebraic Branching Programs, Border Complexity, and Tangent Spaces | 

	Markus Bläser, 

	Christian Ikenmeyer, 

	Meena Mahajan, 

	Anurag Pandey, 

	Nitin Saurabh</title>
    <summary>Nisan showed in 1991 that the width of a smallest noncommutative single-(source,sink) algebraic branching program (ABP) to compute a noncommutative polynomial is given by the ranks of specific matrices. This means that the set of noncommutative polynomials with ABP width complexity at most $k$ is Zariski-closed, an important property in geometric complexity theory. It follows that approximations cannot help to reduce the required ABP width.

It was mentioned by Forbes that this result would probably break when going from single-(source,sink) ABPs to trace ABPs. We prove that this is correct. Moreover, we study the commutative monotone setting and prove a result similar to Nisan, but concerning the analytic closure. We observe the same behavior here: The set of polynomials with ABP width complexity at most $k$ is closed for single-(source,sink) ABPs and not closed for trace ABPs. The proofs reveal an intriguing connection between tangent spaces and the vector space of flows on the ABP.
We close with additional observations on VQP and the closure of VNP which allows us to establish a separation between the two classes.</summary>
    <updated>2020-03-11T08:31:35Z</updated>
    <published>2020-03-11T08:31:35Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-03-17T21:20:28Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/03/11/more-uniqueness-sudoku</id>
    <link href="https://11011110.github.io/blog/2020/03/11/more-uniqueness-sudoku.html" rel="alternate" type="text/html"/>
    <title>More on uniqueness in Sudoku</title>
    <summary>My first post on this blog, lo these nearly 15 years ago, discussed a program I had written to try to solve Sudoku puzzles deductively (rather than by the easier computational method, backtracking), with the goal of being able to automatically grade the puzzles and automatically generate explanations for how to solve a given puzzle. And a few months later I posted again, on deduction rules that take advantage of the assumption that a puzzle has a unique solution, by ruling out choices that would cause any solution consistent with them to become non-unique. Since then, that part of my solver has been relatively stable, although I have added other rules for Nishio and 2SAT and posted here about more general uniqueness deduction rules in map-coloring puzzles.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://11011110.github.io/blog/2005/07/20/updated-python-library.html">My first post on this blog</a>, lo these nearly 15 years ago, discussed a program I had written to try to solve Sudoku puzzles deductively (rather than by the easier computational method, backtracking), with the goal of being able to automatically grade the puzzles and automatically generate explanations for how to solve a given puzzle. And a few months later I posted again, on <a href="https://11011110.github.io/blog/2005/10/15/assuming-uniqueness-in.html">deduction rules that take advantage of the assumption that a puzzle has a unique solution</a>, by ruling out choices that would cause any solution consistent with them to become non-unique. Since then, that part of my solver has been relatively stable, although I have added other rules for <a href="https://11011110.github.io/blog/2012/02/23/solving-single-digit-sudoku.html">Nishio</a> and <a href="https://11011110.github.io/blog/2009/04/26/sudoku-and-2sat.html">2SAT</a> and posted here about <a href="https://11011110.github.io/blog/2019/07/28/any-order-puzzle.html">more general uniqueness deduction rules in map-coloring puzzles</a>.</p>

<p>I’ve also occasionally been using my program to generate puzzles for me to work on, and today it found an interesting test case, a puzzle that it thought would be much more difficult than it turned out to be for me. This mis-rating happened because the uniqueness deduction rules I’m using in my own deductions are stronger than the ones in my program (although some of its other rules are stronger than I typically apply myself). In its initial state, the puzzle looks like:</p>

<p style="text-align: center;"><img alt="Sudoku puzzle" src="https://11011110.github.io/blog/assets/2020/ambig-sudoku-givens.svg"/></p>

<p>My program tells me that it’s at the second highest level of difficulty that it knows about: it has to resort to using 2SAT, but it can successfully solve it that way. (The highest level is for puzzles where it is forced to use backtracking.) Usually, for me, puzzles at that level require me to use written notes to keep track of the deductions, rather than doing it all in my head, but not this time. Using more-or-less standard reasoning, one can fill in the cells of the puzzle to reach the state:</p>

<p style="text-align: center;"><img alt="Partially solved Sudoku puzzle" src="https://11011110.github.io/blog/assets/2020/ambig-sudoku-partial.svg"/></p>

<p>This is where my program gets stuck and has to resort to more powerful deduction rules. But as a human solving this puzzle, here is what I see: In row 3, the two empty cells must contain the pair of digits 3 and 5. In the center right block of nine cells, the two empty cells must again be 3 and 5. And in the center block of cells, the 5 digit is confined to three cells aligned with those two pairs of empty cells. If the 3 digit were also confined to the same three cells in the center block, it and the five would have to occupy the two diagonally aligned cells out of the three, because otherwise they would line up and prevent one of the other pairs of 3-5 cells from having any value. But then the 3-5 cells in row 3, the center block, and column 7 would form a closed system (shown by the red squares below): nothing else outside those cells could affect which of those six cells contains 3, and which contains 5. Within that closed system, there are two solutions, obtained from each other by swapping the locations of the 3 and the 5. But that would violate the assumption of uniqueness.</p>

<p style="text-align: center;"><img alt="Closed system of cells in a partially solved Sudoku puzzle" src="https://11011110.github.io/blog/assets/2020/ambig-sudoku-closed.svg"/></p>

<p>Even if the 7 in the center cell weren’t there, the same reasoning would apply. Since this closed system with a non-unique solution would happen automatically if we confine the digit 3 to the same three center-block cells as the digit 5, the digit 3 must be elsewhere in the center block, which can only mean that it is in column 4. Once we make this deduction, the rest of the puzzle falls into place.</p>

<p>My program only has built into it a couple of ad-hoc rules to prevent closed systems of four cells with two solutions, and it misses the one in this example because it involves six cells. It’s making me think that I need a more general description of the possible closed systems (at least the ones involving only two digit values, like this), in order to match the deductions I’m making by hand and make my program’s difficulty estimates more accurate.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/103803219892010865">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-03-11T00:06:00Z</updated>
    <published>2020-03-11T00:06:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-03-15T23:42:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/03/10/workshop-in-quantum-information-complexity-cryptography/</id>
    <link href="https://cstheory-events.org/2020/03/10/workshop-in-quantum-information-complexity-cryptography/" rel="alternate" type="text/html"/>
    <title>Workshop in Quantum Information, Complexity &amp; Cryptography</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">June 11-12, 2020 University of York, UK https://sites.google.com/york.ac.uk/quicc/quicc We are organising a two-day event at the University of York in collaboration with York Interdisciplinary Centre for Cyber Security, which brings researchers in Quantum Information, Complexity and Cryptography together. The goal is to cover recent topics in these areas and facilitate interactions between them. The event … <a class="more-link" href="https://cstheory-events.org/2020/03/10/workshop-in-quantum-information-complexity-cryptography/">Continue reading <span class="screen-reader-text">Workshop in Quantum Information, Complexity &amp; Cryptography</span></a></div>
    </summary>
    <updated>2020-03-10T17:40:42Z</updated>
    <published>2020-03-10T17:40:42Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-03-17T21:21:21Z</updated>
    </source>
  </entry>
</feed>
