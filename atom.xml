<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-06-21T03:21:45Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4867</id>
    <link href="https://www.scottaaronson.com/blog/?p=4867" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4867#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4867" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Quantum Computing Since Democritus: New Foreword!</title>
    <summary xml:lang="en-US">Time for a non-depressing post. Quantum Computing Since Democritus, which is already available in English and Russian, is about to be published in both Chinese and Japanese. (So if you read this blog, but have avoided tackling QCSD because your Chinese or Japanese is better than your English, today’s your day.) To go along with […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Time for a non-depressing post.  <a href="https://www.amazon.com/Quantum-Computing-since-Democritus-Aaronson/dp/0521199565">Quantum Computing Since Democritus</a>, which is already available in English and Russian, is about to be published in both Chinese and Japanese.  (So if you read this blog, but have avoided tackling QCSD because your Chinese or Japanese is better than your English, today’s your day.)  To go along with the new editions, Cambridge University Press asked me to write a new foreword, reflecting on what happened in the seven years since the book was first published.  The editor, Paul Dobson, kindly gave me permission to share the new foreword on my blog.  So without further ado…</p>



<p/><hr/><p/>



<p><em>Quantum Computing Since Democritus</em> began its life as a course that I taught at the University of Waterloo in 2006.  Seven years later, it became the book that you now hold.  Its preface ended with the following words:</p>



<blockquote class="wp-block-quote"><p>Here’s hoping that, in 2020, this book will be as badly in need of revision as the 2006 lecture notes were in 2013.</p></blockquote>



<p>As I write this, in June 2020, a lot has happened that I would never have predicted in 2013.  Donald Trump is the President of the United States, and is up for reelection shortly.  This is not a political book, so let me resist the urge to comment further.  Meanwhile, the coronavirus pandemic is ravaging the world, killing hundreds of thousands of people, crashing economies, and shutting down schools and universities (including mine).  And in the past few weeks, protests against racism and police brutality started in America and then spread to the world, despite the danger of protesting during a pandemic.</p>



<p>Leaving aside the state of the world, my own life is also very different than it was seven years ago.  Along with my family, I’ve moved from MIT to the University of Texas in Austin.  My daughter, who was born at almost exactly the same time as <em>Quantum Computing Since Democritus</em>, is now a first-grader, and is joined by a 3-year-old son.  When my daughter’s school shut down due to the coronavirus, I began home-schooling her in math, computer science, and physics—in some of the exact same topics covered in this book.  I’m now engaged in an experiment to see what portion of this material can be made accessible to a 7-year-old.</p>



<p>But what about the material itself?  How has it held up over seven years?  Both the bad news and the (for you) good news, I suppose, is that it’s <em>not</em> particularly out of date.  The intellectual underpinnings of quantum computing and its surrounding disciplines remain largely as they were.  Still, let me discuss what <em>has</em> changed.</p>



<p>Between 2013 and 2020, the field of quantum computing made a striking transition, from a mostly academic pursuit to a major technological arms race.  The Chinese government, the US government, and the European Union have all pledged billions of dollars for quantum computing research.  Google, Microsoft, IBM, Amazon, Alibaba, Intel, and Honeywell also now all have well-funded groups tasked with building quantum computers, or providing quantum-computing-related software and services, or even just doing classical computing that’s “quantum-inspired.”  These giants are joined by dozens of startups focused entirely on quantum computing.</p>



<p>The new efforts vary greatly in caliber; some efforts seem rooted in visions of what quantum computers will be able to help with, and how soon, that I find to be wildly overoptimistic or even irresponsible.  But perhaps it’s always this way when a new technology moves from an intellectual aspiration to a commercial prospect.  Having joined the field around 1999, before there were <em>any</em> commercial efforts in quantum computing, I’ve found the change disorienting.</p>



<p>But while some of the new excitement is based on pure hype—on marketers now mixing some “quantum” into their word-salad of “blockchain,” “deep learning,” etc., with no particular understanding of any of the ingredients—there really have been some scientific advances in quantum computing since 2013, a fire underneath the smoke.</p>



<p>Surely the crowning achievement of quantum computing during this period was the achievement of “quantum supremacy,” which a team at Google announced in the fall of 2019.  For the first time, a programmable quantum computer was used to outperform any classical computer on earth, running any currently known algorithm.  Google’s device, called “Sycamore,” with 53 superconducting qubits cooled to a hundredth of a degree above absolute zero, solved a well-defined albeit probably useless sampling problem in about 3 minutes.  To compare, current state-of-the-art simulations on classical computers need a few days, even with hundreds of thousands of parallel processors.  Ah, but will a better classical simulation be possible?  That’s an open question in quantum complexity!  The discussion of that question draws on theoretical work that various colleagues and I did over the past decade.  That work in turn draws on my so-called <strong>PostBQP</strong>=<strong>PP</strong> theorem from 2004, explained in this book.</p>



<p>In the past seven years, there were also several breakthroughs in quantum computing theory—some of which resolved open problems mentioned in this book. </p>



<p>In 2018, Ran Raz and Avishay Tal gave an oracle relative to which <strong>BQP</strong> (Bounded-Error Quantum Polynomial-Time) is not contained in <strong>PH</strong> (the Polynomial Hierarchy).  This solved one of the main open questions, since 1993, about where <strong>BQP</strong> fits in with classical complexity classes, at least in the black-box setting.  (What does that mean?  Read the book!)  Raz and Tal’s proof used a candidate problem that I had defined in 2009 and called “Forrelation.”</p>



<p>Also in 2018, Urmila Mahadev gave a protocol, based on cryptography, by which a polynomial-time quantum computer (i.e., a <strong>BQP</strong> machine) could always prove the results of its computation to a classical polynomial-time skeptic, purely by exchanging classical messages with the skeptic.  Following Urmila’s achievement, I was delighted to give her a $25 prize for solving the problem that I’d announced on my blog back in 2007.</p>



<p>Perhaps most spectacularly of all, in 2020, Zhengfeng Ji, Anand Natarajan, Thomas Vidick, John Wright, and Henry Yuen proved that <strong>MIP*</strong>=<strong>RE</strong>.  Here <strong>MIP*</strong> means the class of problems solvable using multi-prover interactive proof systems with quantumly entangled provers (and classical polynomial-time verifiers), while <strong>RE</strong> means Recursively Enumerable: a class that includes not only all the computable problems, but even the infamous halting problem (!).  To say it more simply, <em>entangled provers can convince a polynomial-time verifier that an arbitrary Turing machine halts</em>.  Besides its intrinsic interest, a byproduct of this breakthrough was to answer a decades-old question in pure math, the so-called Connes Embedding Conjecture (by <em>refuting</em> the conjecture).  To my knowledge, the new result represents the first time that quantum computing has reached “all the way up the ladder of hardness” to touch uncomputable problems.  It’s also the first time that non-relativizing techniques, like the ones central to the study of interactive proofs, were ever used in computability theory.</p>



<p>In a different direction, the last seven years have witnessed an astonishing convergence between quantum information and quantum gravity—something that was just starting when <em>Quantum Computing Since Democritus</em> appeared in 2013, and that I mentioned as an exciting new direction.  Since then, the so-called “It from Qubit” collaboration has brought together quantum computing theorists with string theorists and former string theorists—experts in things like the black hole information problem—to develop a shared language.  One striking proposal that’s emerged from this is a fundamental role for <em>quantum circuit complexity</em>—that is, the smallest number of 1- and 2-qubit gates needed to prepare a given n-qubit state from the all-0 state—in the so-called AdS/CFT (Anti de Sitter / Conformal Field Theory) correspondence.  AdS/CFT is a duality between physical theories involving different numbers of spatial dimensions; for more than twenty years, it’s been a central testbed for ideas about quantum gravity.  But the duality is extremely nonlocal: a “simple” quantity in the AdS theory, like the volume of a wormhole, can correspond to an incredibly “complicated” quantity in the dual CFT.  The new proposal is that the CFT quantity might be not just complicated, but literally circuit complexity itself.  Fanciful as that sounds, the truth is that no one has come up with any other proposal that passes the same sanity checks.  A related new insight is that the nonlocal mapping between the AdS and CFT theories is not merely analogous to, but literally an example of, a quantum error-correcting code: the same mathematical objects that will be needed to build scalable quantum computers.</p>



<p>When <em>Quantum Computing Since Democritus</em> was first published, some people thought it went too far in elevating computer science, and computational complexity in particular, to fundamental roles in understanding the physical world.  But even I wasn’t audacious enough to posit connections like the ones above, which are now more-or-less mainstream in quantum gravity research.</p>



<p>I’m proud that I wrote <em>Quantum Computing Since Democritus</em>, but as the years go by, I find that I have no particular desire to revise it, or even reread it.  It seems far better for the book to stand as a record of what I knew and believed and cared about at a certain moment in time.</p>



<p>The intellectual quest that’s defined my life—the quest to wrap together computation, physics, math, and philosophy into some sort of coherent picture of the world—might never end.  But it does need to start somewhere.  I’m honored that you chose <em>Quantum Computing Since Democritus</em> as a place to start or continue your own quest.  I hope you enjoy it.</p>



<p>Scott Aaronson<br/>Austin, Texas<br/>June 2020</p></div>
    </content>
    <updated>2020-06-20T23:48:04Z</updated>
    <published>2020-06-20T23:48:04Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum Computing Since Democritus"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-06-20T23:48:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10715</id>
    <link href="http://arxiv.org/abs/2006.10715" rel="alternate" type="text/html"/>
    <title>List-Decodable Mean Estimation via Iterative Multi-Fitering</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diakonikolas:Ilias.html">Ilias Diakonikolas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kane:Daniel_M=.html">Daniel M. Kane</a>, Daniel Kongsgaard <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10715">PDF</a><br/><b>Abstract: </b>We study the problem of {\em list-decodable mean estimation} for bounded
covariance distributions. Specifically, we are given a set $T$ of points in
$\mathbb{R}^d$ with the promise that an unknown $\alpha$-fraction of points in
$T$, where $0&lt; \alpha &lt; 1/2$, are drawn from an unknown mean and bounded
covariance distribution $D$, and no assumptions are made on the remaining
points. The goal is to output a small list of hypothesis vectors such that at
least one of them is close to the mean of $D$. We give the first practically
viable estimator for this problem. In more detail, our algorithm is sample and
computationally efficient, and achieves information-theoretically near-optimal
error. While the only prior algorithm for this setting inherently relied on the
ellipsoid method, our algorithm is iterative and only uses spectral techniques.
Our main technical innovation is the design of a soft outlier removal procedure
for high-dimensional heavy-tailed datasets with a majority of outliers.
</p></div>
    </summary>
    <updated>2020-06-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10698</id>
    <link href="http://arxiv.org/abs/2006.10698" rel="alternate" type="text/html"/>
    <title>Resource Pools and the CAP Theorem</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lewis=Pye:Andrew.html">Andrew Lewis-Pye</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roughgarden:Tim.html">Tim Roughgarden</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10698">PDF</a><br/><b>Abstract: </b>Blockchain protocols differ in fundamental ways, including the mechanics of
selecting users to produce blocks (e.g., proof-of-work vs. proof-of-stake) and
the method to establish consensus (e.g., longest chain rules vs. BFT-inspired
protocols). These fundamental differences have hindered "apples-to-apples"
comparisons between different categories of blockchain protocols and, in turn,
the development of theory to formally discuss their relative merits.
</p>
<p>This paper presents a parsimonious abstraction sufficient for capturing and
comparing properties of many well-known permissionless blockchain protocols,
simultaneously capturing essential properties of both proof-of-work and
proof-of-stake protocols, and of both longest-chain-type and BFT-type
protocols. Our framework blackboxes the precise mechanics of the user selection
process, allowing us to isolate the properties of the selection process which
are significant for protocol design.
</p>
<p>We illustrate our framework's utility with two results. First, we prove an
analog of the CAP theorem from distributed computing for our framework in a
partially synchronous setting. This theorem shows that a fundamental dichotomy
holds between protocols (such as Bitcoin) that are adaptive, in the sense that
they can function given unpredictable levels of participation, and protocols
(such as Algorand) that have certain finality properties. Second, we formalize
the idea that proof-of-work (PoW) protocols and non-PoW protocols can be
distinguished by the forms of permission that users are given to carry out
updates to the state.
</p></div>
    </summary>
    <updated>2020-06-20T23:31:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10692</id>
    <link href="http://arxiv.org/abs/2006.10692" rel="alternate" type="text/html"/>
    <title>A Competitive B-Matching Algorithm for Reconfigurable Datacenter Networks</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bienkowski:Marcin.html">Marcin Bienkowski</a>, David Fuchssteiner, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marcinkowski:Jan.html">Jan Marcinkowski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmid:Stefan.html">Stefan Schmid</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10692">PDF</a><br/><b>Abstract: </b>This paper initiates the study of online algorithms for the maintaining a
maximum weight b-matching problem, a generalization of maximum weight matching
where each node has at most b &gt; 0 adjacent matching edges. The problem is
motivated by emerging optical technologies which allow to enhance datacenter
networks with reconfigurable matchings, providing direct connectivity between
frequently communicating racks. These additional links may improve network
performance, by leveraging spatial and temporal structure in the workload. We
show that the underlying algorithmic problem features an intriguing connection
to online paging,but introduces a novel challenge. Our main contribution is an
online algorithm which is O (b)-competitive; we also prove that this is
asymptotically optimal. We complement our theoretical results with extensive
trace-driven simulations, based on real-world datacenter workloads as well as
synthetic traffic traces.
</p></div>
    </summary>
    <updated>2020-06-20T23:21:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10689</id>
    <link href="http://arxiv.org/abs/2006.10689" rel="alternate" type="text/html"/>
    <title>Free Energy Wells and Overlap Gap Property in Sparse PCA</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arous:G=eacute=rard_Ben.html">Gérard Ben Arous</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wein:Alexander_S=.html">Alexander S. Wein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zadik:Ilias.html">Ilias Zadik</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10689">PDF</a><br/><b>Abstract: </b>We study a variant of the sparse PCA (principal component analysis) problem
in the "hard" regime, where the inference task is possible yet no
polynomial-time algorithm is known to exist. Prior work, based on the
low-degree likelihood ratio, has conjectured a precise expression for the best
possible (sub-exponential) runtime throughout the hard regime. Following
instead a statistical physics inspired point of view, we show bounds on the
depth of free energy wells for various Gibbs measures naturally associated to
the problem. These free energy wells imply hitting time lower bounds that
corroborate the low-degree conjecture: we show that a class of natural MCMC
(Markov chain Monte Carlo) methods (with worst-case initialization) cannot
solve sparse PCA with less than the conjectured runtime. These lower bounds
apply to a wide range of values for two tuning parameters: temperature and
sparsity misparametrization. Finally, we prove that the Overlap Gap Property
(OGP), a structural property that implies failure of certain local search
algorithms, holds in a significant part of the hard regime.
</p></div>
    </summary>
    <updated>2020-06-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10592</id>
    <link href="http://arxiv.org/abs/2006.10592" rel="alternate" type="text/html"/>
    <title>On the complexity of detecting hazards</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Komarath:Balagopal.html">Balagopal Komarath</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Nitin.html">Nitin Saurabh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10592">PDF</a><br/><b>Abstract: </b>Detecting and eliminating logic hazards in Boolean circuits is a fundamental
problem in logic circuit design. We show that there is no $O(3^{(1-\epsilon)n}
\text{poly}(s))$ time algorithm, for any $\epsilon &gt; 0$, that detects logic
hazards in Boolean circuits of size $s$ on $n$ variables under the assumption
that the strong exponential time hypothesis is true. This lower bound holds
even when the input circuits are restricted to be formulas of depth four. We
also present a polynomial time algorithm for detecting $1$-hazards in DNF (or,
$0$-hazards in CNF) formulas. Since $0$-hazards in DNF (or, $1$-hazards in CNF)
formulas are easy to eliminate, this algorithm can be used to detect whether a
given DNF or CNF formula has a hazard in practice.
</p></div>
    </summary>
    <updated>2020-06-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10456</id>
    <link href="http://arxiv.org/abs/2006.10456" rel="alternate" type="text/html"/>
    <title>Palette Sparsification Beyond $(\Delta+1)$ Vertex Coloring</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alon:Noga.html">Noga Alon</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Assadi:Sepehr.html">Sepehr Assadi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10456">PDF</a><br/><b>Abstract: </b>A recent palette sparsification theorem of Assadi, Chen, and Khanna [SODA'19]
states that in every $n$-vertex graph $G$ with maximum degree $\Delta$,
sampling $O(\log{n})$ colors per each vertex independently from $\Delta+1$
colors almost certainly allows for proper coloring of $G$ from the sampled
colors. Besides being a combinatorial statement of its own independent
interest, this theorem was shown to have various applications to design of
algorithms for $(\Delta+1)$ coloring in different models of computation on
massive graphs such as streaming or sublinear-time algorithms.
</p>
<p>In this paper, we further study palette sparsification problems:
</p>
<p>* We prove that for $(1+\varepsilon) \Delta$ coloring, sampling only
$O_{\varepsilon}(\sqrt{\log{n}})$ colors per vertex is sufficient and necessary
to obtain a proper coloring from the sampled colors.
</p>
<p>* A natural family of graphs with chromatic number much smaller than
$(\Delta+1)$ are triangle-free graphs which are $O(\frac{\Delta}{\ln{\Delta}})$
colorable. We prove that sampling $O(\Delta^{\gamma} + \sqrt{\log{n}})$ colors
per vertex is sufficient and necessary to obtain a proper
$O_{\gamma}(\frac{\Delta}{\ln{\Delta}})$ coloring of triangle-free graphs.
</p>
<p>* We show that sampling $O_{\varepsilon}(\log{n})$ colors per vertex is
sufficient for proper coloring of any graph with high probability whenever each
vertex is sampling from a list of $(1+\varepsilon) \cdot deg(v)$ arbitrary
colors, or even only $deg(v)+1$ colors when the lists are the sets
$\{1,\ldots,deg(v)+1\}$.
</p>
<p>Similar to previous work, our new palette sparsification results naturally
lead to a host of new and/or improved algorithms for vertex coloring in
different models including streaming and sublinear-time algorithms.
</p></div>
    </summary>
    <updated>2020-06-20T23:33:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10444</id>
    <link href="http://arxiv.org/abs/2006.10444" rel="alternate" type="text/html"/>
    <title>Parameterized Inapproximability of Independent Set in $H$-Free Graphs</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Pavel Dvořák, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldmann:Andreas_Emil.html">Andreas Emil Feldmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rai:Ashutosh.html">Ashutosh Rai</a>, Paweł Rzążewski <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10444">PDF</a><br/><b>Abstract: </b>We study the Independent Set (IS) problem in $H$-free graphs, i.e., graphs
excluding some fixed graph $H$ as an induced subgraph. We prove several
inapproximability results both for polynomial-time and parameterized
algorithms.
</p>
<p>Halld\'orsson [SODA 1995] showed that for every $\delta&gt;0$ IS has a
polynomial-time $(\frac{d-1}{2}+\delta)$-approximation in $K_{1,d}$-free
graphs. We extend this result by showing that $K_{a,b}$-free graphs admit a
polynomial-time $O(\alpha(G)^{1-1/a})$-approximation, where $\alpha(G)$ is the
size of a maximum independent set in $G$. Furthermore, we complement the result
of Halld\'orsson by showing that for some $\gamma=\Theta(d/\log d),$ there is
no polynomial-time $\gamma$-approximation for these graphs, unless NP = ZPP.
</p>
<p>Bonnet et al. [IPEC 2018] showed that IS parameterized by the size $k$ of the
independent set is W[1]-hard on graphs which do not contain (1) a cycle of
constant length at least $4$, (2) the star $K_{1,4}$, and (3) any tree with two
vertices of degree at least $3$ at constant distance.
</p>
<p>We strengthen this result by proving three inapproximability results under
different complexity assumptions for almost the same class of graphs (we weaken
condition (2) that $G$ does not contain $K_{1,5}$). First, under the ETH, there
is no $f(k)\cdot n^{o(k/\log k)}$ algorithm for any computable function $f$.
Then, under the deterministic Gap-ETH, there is a constant $\delta&gt;0$ such that
no $\delta$-approximation can be computed in $f(k) \cdot n^{O(1)}$ time. Also,
under the stronger randomized Gap-ETH there is no such approximation algorithm
with runtime $f(k)\cdot n^{o(k)}$.
</p>
<p>Finally, we consider the parameterization by the excluded graph $H$, and show
that under the ETH, IS has no $n^{o(\alpha(H))}$ algorithm in $H$-free graphs
and under Gap-ETH there is no $d/k^{o(1)}$-approximation for $K_{1,d}$-free
graphs with runtime $f(d,k) n^{O(1)}$.
</p></div>
    </summary>
    <updated>2020-06-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10365</id>
    <link href="http://arxiv.org/abs/2006.10365" rel="alternate" type="text/html"/>
    <title>Efficient Planar Two-Center Algorithms</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jongmin Choi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ahn:Hee=Kap.html">Hee-Kap Ahn</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10365">PDF</a><br/><b>Abstract: </b>We consider the planar Euclidean two-center problem in which given $n$ points
in the plane find two congruent disks of the smallest radius covering the
points. We present a deterministic $O(n \log n)$-time algorithm for the case
that the centers of the two optimal disks are close together, that is, the
overlap of the two optimal disks is a constant fraction of the disk area. This
improves the previous best $O(n\log n\log\log n)$ bound by Wang for the case.
We also present a deterministic $O(n\log n)$-time algorithm for the case that
the input points are in convex position.
</p></div>
    </summary>
    <updated>2020-06-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10364</id>
    <link href="http://arxiv.org/abs/2006.10364" rel="alternate" type="text/html"/>
    <title>On the Parameterized Approximability of Contraction to Classes of Chordal Graphs</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Spoorthy Gunda, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Pallavi.html">Pallavi Jain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lokshtanov:Daniel.html">Daniel Lokshtanov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Saket.html">Saket Saurabh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tale:Prafullkumar.html">Prafullkumar Tale</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10364">PDF</a><br/><b>Abstract: </b>A graph operation that {\em contracts edges} is one of the fundamental
operations in the theory of graph minors. Parameterized Complexity of editing
to a family of graphs by contracting $k$ edges has recently gained substantial
scientific attention, and several new results have been obtained. Some
important families of graphs, namely the subfamilies of chordal graphs, in the
context of edge contractions, have proven to be significantly difficult than
one might expect. In this paper, we study the \textsc{$\cal F$-Contraction}
problem, where $\cal F$ is a subfamily of chordal graphs, in the realm of
parameterized approximation. Formally, given a graph $G$ and an integer $k$,
\textsc{ $\cal F$-Contraction} asks whether there exists $X \subseteq E(G)$
such that $G/X \in \cal F$ and $|X| \leq k$. Here, $G/X$ is the graph obtained
from $G$ by contracting edges in $X$. We obtain the following results for the
\textsc{ $\cal F$-Contraction} problem. $(1)$ We show that \textsc{Clique
Contraction} admits a polynomial-size approximate kernelization scheme
(\textsf{PSAKS}). $(2)$ We give a $(2+\epsilon)$-approximate polynomial kernel
for \textsc{Split Contraction} (which also implies a factor
$(2+\epsilon)$-\FPT-approximation algorithm for \textsc{ Split Contraction}).
Furthermore, we show that, assuming \textsf{ Gap-ETH}, there is no
$\left(\frac{5}{4}-\delta \right)$-\FPT-approximation algorithm for
\textsc{Split Contraction}. Here, $\epsilon, \delta&gt;0$ are fixed constants.
$(3)$ \textsc{Chordal Contraction} is known to be \WTH. We complement this
result by observing that the existing \textsf{W[2]-hardness} reduction can be
adapted to show that, assuming \FPT $\neq$ \textsf{W[1]}, there is no
$F(k)$-\FPT-approximation algorithm for \textsc{Chordal Contraction}. Here,
$F(k)$ is an arbitrary function depending on $k$ alone.
</p></div>
    </summary>
    <updated>2020-06-20T23:23:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10361</id>
    <link href="http://arxiv.org/abs/2006.10361" rel="alternate" type="text/html"/>
    <title>A 3/2--approximation for big two-bar charts packing</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Adil Erzin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nazarenko:Stepan.html">Stepan Nazarenko</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Melidi:Gregory.html">Gregory Melidi</a>, Roman Plotnikov <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10361">PDF</a><br/><b>Abstract: </b>We consider a Two-Bar Charts Packing Problem (2-BCPP), in which it is
necessary to pack two-bar charts (2-BCs) in a unit-height strip of minimum
length. The problem is a generalization of the Bin Packing Problem (BPP).
Earlier, we proposed an $O(n^2)$-time algorithm that constructs the packing
which length at most $2\cdot OPT+1$, where $OPT$ is the minimum length of the
packing of $n$ 2-BCs. In this paper, we propose an $O(n^4)$-time
3/2-approximate algorithm when each BC has at least one bar greater than 1/2.
</p></div>
    </summary>
    <updated>2020-06-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10302</id>
    <link href="http://arxiv.org/abs/2006.10302" rel="alternate" type="text/html"/>
    <title>Approximate bi-criteria search by efficient representation of subsets of the Pareto-optimal frontier</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Salzman:Oren.html">Oren Salzman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10302">PDF</a><br/><b>Abstract: </b>We consider the bi-criteria shortest-path problem where we want to compute
shortest paths on a graph that simultaneously balance two cost functions. While
this problem has numerous applications, there is usually no path minimizing
both cost functions simultaneously. Thus, we typically consider the set of
paths where no path is strictly better then the others in both cost functions,
a set called the Pareto-optimal frontier. Unfortunately, the size of this set
may be exponential in the number of graph vertices and the general problem is
NP-hard. While existing schemes to approximate this set exist, they may be
slower than exact approaches when applied to relatively small instances and
running them on graphs with even a moderate number of nodes is often
impractical. The crux of the problem lies in how to efficiently approximate the
Pareto-optimal frontier. Our key insight is that the Pareto-optimal frontier
can be approximated using pairs of paths. This simple observation allows us to
run a best-first-search while efficiently and effectively pruning away
intermediate solutions in order to obtain an approximation of the Pareto
frontier for any given approximation factor. We compared our approach with an
adaptation of BOA*, the state-of-the-art algorithm for computing exact
solutions to the bi-criteria shortest-path problem. Our experiments show that
as the problem becomes harder, the speedup obtained becomes more pronounced.
Specifically, on large roadmaps, we obtain an average speedup of more than
$\times 8.5$ and a maximal speedup of over $\times 148$.
</p></div>
    </summary>
    <updated>2020-06-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10286</id>
    <link href="http://arxiv.org/abs/2006.10286" rel="alternate" type="text/html"/>
    <title>Cyclic space-filling curves and their clustering property</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Igor V. Netay <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10286">PDF</a><br/><b>Abstract: </b>In this paper we introduce an algorithm of construction of cyclic
space-filling curves. One particular construction provides a family of
space-filling curves in all dimensions (H-curves). They are compared here with
the Hilbert curve in the sense of clustering properties, and it turns out that
the constructed curve is very close and sometimes a bit better than the Hilbert
curve. At the same time, its construction is more simple and evaluation is
significantly faster.
</p></div>
    </summary>
    <updated>2020-06-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10268</id>
    <link href="http://arxiv.org/abs/2006.10268" rel="alternate" type="text/html"/>
    <title>A Fast Binary Splitting Approach to Non-Adaptive Group Testing</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Price:Eric.html">Eric Price</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scarlett:Jonathan.html">Jonathan Scarlett</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10268">PDF</a><br/><b>Abstract: </b>In this paper, we consider the problem of noiseless non-adaptive group
testing under the for-each recovery guarantee, also known as probabilistic
group testing. In the case of $n$ items and $k$ defectives, we provide an
algorithm attaining high-probability recovery with $O(k \log n)$ scaling in
both the number of tests and runtime, improving on the best known $O(k^2 \log k
\cdot \log n)$ runtime previously available for any algorithm that only uses
$O(k \log n)$ tests. Our algorithm bears resemblance to Hwang's adaptive
generalized binary splitting algorithm (Hwang, 1972); we recursively work with
groups of items of geometrically vanishing sizes, while maintaining a list of
"possibly defective" groups and circumventing the need for adaptivity. While
the most basic form of our algorithm requires $\Omega(n)$ storage, we also
provide a low-storage variant based on hashing, with similar recovery
guarantees.
</p></div>
    </summary>
    <updated>2020-06-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10221</id>
    <link href="http://arxiv.org/abs/2006.10221" rel="alternate" type="text/html"/>
    <title>Fair Hierarchical Clustering</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ahmadian:Sara.html">Sara Ahmadian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Epasto:Alessandro.html">Alessandro Epasto</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Knittel:Marina.html">Marina Knittel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Ravi.html">Ravi Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahdian:Mohammad.html">Mohammad Mahdian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moseley:Benjamin.html">Benjamin Moseley</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pham:Philip.html">Philip Pham</a>, Sergei Vassilvtiskii, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yuyan.html">Yuyan Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10221">PDF</a><br/><b>Abstract: </b>As machine learning has become more prevalent, researchers have begun to
recognize the necessity of ensuring machine learning systems are fair.
Recently, there has been an interest in defining a notion of fairness that
mitigates over-representation in traditional clustering.
</p>
<p>In this paper we extend this notion to hierarchical clustering, where the
goal is to recursively partition the data to optimize a specific objective. For
various natural objectives, we obtain simple, efficient algorithms to find a
provably good fair hierarchical clustering. Empirically, we show that our
algorithms can find a fair hierarchical clustering, with only a negligible loss
in the objective.
</p></div>
    </summary>
    <updated>2020-06-20T23:27:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10207</id>
    <link href="http://arxiv.org/abs/2006.10207" rel="alternate" type="text/html"/>
    <title>Political Advertising Dataset: the use case of the Polish 2020 Presidential Elections</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Łukasz Augustyniak, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rajda:Krzysztof.html">Krzysztof Rajda</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kajdanowicz:Tomasz.html">Tomasz Kajdanowicz</a>, Michał Bernaczyk <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10207">PDF</a><br/><b>Abstract: </b>Political campaigns are full of political ads posted by candidates on social
media. Political advertisements constitute a basic form of campaigning,
subjected to various social requirements. We present the first publicly open
dataset for detecting specific text chunks and categories of political
advertising in the Polish language. It contains 1,705 human-annotated tweets
tagged with nine categories, which constitute campaigning under Polish
electoral law. We achieved a 0.65 inter-annotator agreement (Cohen's kappa
score). An additional annotator resolved the mismatches between the first two
annotators improving the consistency and complexity of the annotation process.
We used the newly created dataset to train a well established neural tagger
(achieving a 70% percent points F1 score). We also present a possible direction
of use cases for such datasets and models with an initial analysis of the
Polish 2020 Presidential Elections on Twitter.
</p></div>
    </summary>
    <updated>2020-06-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10129</id>
    <link href="http://arxiv.org/abs/2006.10129" rel="alternate" type="text/html"/>
    <title>Smoothed Analysis of Online and Differentially Private Learning</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haghtalab:Nika.html">Nika Haghtalab</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roughgarden:Tim.html">Tim Roughgarden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shetty:Abhishek.html">Abhishek Shetty</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10129">PDF</a><br/><b>Abstract: </b>Practical and pervasive needs for robustness and privacy in algorithms have
inspired the design of online adversarial and differentially private learning
algorithms. The primary quantity that characterizes learnability in these
settings is the Littlestone dimension of the class of hypotheses [Ben-David et
al., 2009, Alon et al., 2019]. This characterization is often interpreted as an
impossibility result because classes such as linear thresholds and neural
networks have infinite Littlestone dimension. In this paper, we apply the
framework of smoothed analysis [Spielman and Teng, 2004], in which
adversarially chosen inputs are perturbed slightly by nature. We show that
fundamentally stronger regret and error guarantees are possible with smoothed
adversaries than with worst-case adversaries. In particular, we obtain regret
and privacy error bounds that depend only on the VC dimension and the
bracketing number of a hypothesis class, and on the magnitudes of the
perturbations.
</p></div>
    </summary>
    <updated>2020-06-20T23:29:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.10085</id>
    <link href="http://arxiv.org/abs/2006.10085" rel="alternate" type="text/html"/>
    <title>Fair k-Means Clustering</title>
    <feedworld_mtime>1592611200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghadiri:Mehrdad.html">Mehrdad Ghadiri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Samadi:Samira.html">Samira Samadi</a>, Santosh Vempala <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.10085">PDF</a><br/><b>Abstract: </b>We show that the popular $k$-means clustering algorithm (Lloyd's heuristic),
used for a variety of scientific data, can result in outcomes that are
unfavorable to subgroups of data (e.g., demographic groups). Such biased
clusterings can have deleterious implications for human-centric applications
such as resource allocation. We present a fair $k$-means objective and
algorithm to choose cluster centers that provide equitable costs for different
groups. The algorithm, Fair-Lloyd, is a modification of Lloyd's heuristic for
$k$-means, inheriting its simplicity, efficiency, and stability. In comparison
with standard Lloyd's, we find that on benchmark data sets, Fair-Lloyd exhibits
unbiased performance by ensuring that all groups have balanced costs in the
output $k$-clustering, while incurring a negligible increase in running time,
thus making it a viable fair option wherever $k$-means is currently used.
</p></div>
    </summary>
    <updated>2020-06-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7753</id>
    <link href="https://windowsontheory.org/2020/06/19/stoc-2020-information-guest-post-by-madhur-tulsiani/" rel="alternate" type="text/html"/>
    <title>STOC 2020 information (guest post by Madhur Tulsiani)</title>
    <summary>Dear fellow theorists, As you already know, STOC 2020 this year will be a virtual conference. If you are interested in attending the conference, but haven’t registered yet, please do so soon (students: $25, regular: $50). This will help us ensure we have capacity for various online events.  Upon registration, you should receive a confirmation […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Dear fellow theorists,</p>



<p>As you already know, STOC 2020 this year will be a virtual conference. If you are interested in attending the conference, but haven’t registered yet, <a href="http://www.cvent.com/events/52nd-annual-acm-symposium-on-theory-of-computing-stoc-2020-/event-summary-ea5fa7861d1a476d82bc10f667a1c0f4.aspx" rel="noreferrer noopener" target="_blank">please do so soon</a> (students: $25, regular: $50). This will help us ensure we have capacity for various online events. </p>



<p>Upon registration, you should receive a confirmation email from CVENT, also containing access information for various conference events. Also, if you are a student looking to register for STOC but the cost is a burden, please email us at <a>stoc2020@ttic.edu</a>.</p>



<p><strong>How will the conference work?</strong></p>



<ul><li><strong>Videos</strong>: The videos for all conference talks are now available on YouTube, and can be accessed through the links in the <a href="http://acm-stoc.org/stoc2020/STOCprogram.html" rel="noreferrer noopener" target="_blank">conference program</a>. Registration is <em>not required</em> to view the talks on Youtube.</li></ul>



<ul><li>Slack: The conference has a Slack workspace, with one channel for every paper and workshop, and additional channels for information, announcements, social events, help, etc. The invitations for the Slack workspace will be sent to registered participants. Authors are also encouraged to monitor the channels for their papers. All access information for the conference will also be available here. The workspace is currently active, and will remain active for at least one week after the conference.</li></ul>



<ul><li><strong>Zoom sessions</strong>: The conference will feature Zoom sessions with short presentations by the speakers. The total time for each paper is 10 minutes. Given that participants have access to the full talks by the speakers on Youtube, these can be thought of as being analogues of poster sessions. The workshops will also be held as separate sessions. The links for the Zoom sessions are available via information in the registration confirmation email.</li></ul>



<ul><li><strong>Social events</strong>: The conference will include junior/senior “lunches”, breakout tables for impromptu and scheduled hangouts, and a group event using <a href="https://gather.town/" rel="noreferrer noopener" target="_blank">gather.town</a>. The timings for the events can be found in the conference program. Sign-up links for various events will be sent to all registered participants – please do sign-up soon!</li></ul>



<p>See you all at (virtual) STOC 2020. Please do let us know if you have any questions or suggestions.</p>



<p>TheoryFest organization team</p>



<p>(<a>stoc2020@ttic.edu</a>)</p></div>
    </content>
    <updated>2020-06-19T22:05:41Z</updated>
    <published>2020-06-19T22:05:41Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-06-21T03:21:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=180</id>
    <link href="https://kamathematics.wordpress.com/2020/06/19/stoc-2020-goes-virtual/" rel="alternate" type="text/html"/>
    <title>STOC 2020 Goes Virtual!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Starting on Monday, STOC is joining the trend of conferences going online, I believe the biggest theory conference to do so thus far. Given my experience with TCS+, I volunteered to lend a hand with the organization and logistics. It’s been a journey (with some unusual technical challenges), but I think we have something which … <a class="more-link" href="https://kamathematics.wordpress.com/2020/06/19/stoc-2020-goes-virtual/">Continue reading<span class="screen-reader-text"> "STOC 2020 Goes Virtual!"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Starting on Monday, STOC is joining the trend of conferences going online, I believe the biggest theory conference to do so thus far. Given my experience with <a href="https://sites.google.com/site/plustcs/">TCS+</a>, I volunteered to lend a hand with the organization and logistics. It’s been a journey (with some <a href="https://twitter.com/thegautamkamath/status/1273055827092549634">unusual technical challenges</a>), but I think we have something which I hope will be engaging and generally a lot of fun. In addition to the typical academic component, we also have a social component planned as well. We learnt from the work of others, including the <a href="https://www.acm.org/virtual-conferences">ACM virtual conferences guide</a>, <a href="https://iclr.cc/Conferences/2020">ICLR 2020</a>, and <a href="https://www.daniellitt.com/blog/2020/4/20/wagon-lessons-learned">WAGON</a>. I may make some version of our logistics docs available to others after the conference, so others can learn from our experience as well. Anyway, read on for an announcement from me and the other General Chairs, Konstantin Makarychev, Yury Makarychev, and Madhur Tulsiani. See also the <a href="http://acm-stoc.org/stoc2020/">main STOC page</a> for a more complete list of credits.</p>



<hr class="wp-block-separator"/>



<p>Dear fellow theorists,</p>



<p>As you already know, STOC 2020 this year will be a virtual conference. If you are interested in attending the conference, but haven’t registered yet, <a href="http://www.cvent.com/events/52nd-annual-acm-symposium-on-theory-of-computing-stoc-2020-/event-summary-ea5fa7861d1a476d82bc10f667a1c0f4.aspx">please do so soon</a> (students: $25, regular: $50). This will help us ensure we have capacity for various online events. </p>



<p>Upon registration, you should receive a confirmation email from CVENT, also containing access information for various conference events. Also, if you are a student looking to register for STOC but the cost is a burden, please email us at <a href="mailto:stoc2020@ttic.edu">stoc2020@ttic.edu</a>.</p>



<p><strong>How will the conference work?</strong></p>



<ul><li><strong>Videos</strong>: The videos for all conference talks are now available on YouTube, and can be accessed through the links in the <a href="http://acm-stoc.org/stoc2020/STOCprogram.html">conference program</a>. Registration is <em>not required</em> to view the talks on Youtube.</li></ul>



<ul><li><strong>Slack</strong>: The conference has a Slack workspace, with one channel for every paper and workshop, and additional channels for information, announcements, social events, help, etc. The invitations for the Slack workspace will be sent to registered participants. Authors are also encouraged to monitor the channels for their papers. All access information for the conference will also be available here. The workspace is currently active, and will remain active for at least one week after the conference.</li></ul>



<ul><li><strong>Zoom sessions</strong>: The conference will feature Zoom sessions with short presentations by the speakers. The total time for each paper is 10 minutes. Given that participants have access to the full talks by the speakers on Youtube, these can be thought of as being analogues of poster sessions. The workshops will also be held as separate sessions. The links for the Zoom session via information in the confirmation email.</li></ul>



<ul><li><strong>Social events</strong>: The conference will include junior/senior “lunches”, breakout tables for impromptu and scheduled hangouts, and a group event using <a href="https://gather.town">gather.town</a>. The timings for the events can be found in the conference program. Sign-up links for various events will be sent to all registered participants – please do sign-up soon!</li></ul>



<p>See you all at (virtual) STOC 2020. Please do let us know if you have any questions or suggestions.</p></div>
    </content>
    <updated>2020-06-19T20:20:16Z</updated>
    <published>2020-06-19T20:20:16Z</published>
    <category term="Events"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2020-06-21T03:21:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/19/postdoc-phd-student-at-ben-gurion-university-apply-by-november-20-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/19/postdoc-phd-student-at-ben-gurion-university-apply-by-november-20-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc, PhD student at Ben-Gurion University (apply by November 20, 2020)</title>
    <summary>Excellent students with a strong background in Theoretical Computer Science and Mathematics, interested to conduct research in Error-Correcting Codes, Information Theory, or Learning Theory, are welcome to apply to postdoctoral and PhD student positions. The position includes a generous salary, as well as funding for equipment and travel. Website: https://www.cs.bgu.ac.il/~klim/Links/Call Email: klim@bgu.ac.il</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Excellent students with a strong background in Theoretical Computer Science and Mathematics, interested to conduct research in Error-Correcting Codes, Information Theory, or Learning Theory, are welcome to apply to postdoctoral and PhD student positions. The position includes a generous salary, as well as funding for equipment and travel.</p>
<p>Website: <a href="https://www.cs.bgu.ac.il/~klim/Links/Call">https://www.cs.bgu.ac.il/~klim/Links/Call</a><br/>
Email: klim@bgu.ac.il</p></div>
    </content>
    <updated>2020-06-19T13:47:44Z</updated>
    <published>2020-06-19T13:47:44Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-21T03:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4859</id>
    <link href="https://www.scottaaronson.com/blog/?p=4859" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4859#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4859" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Justice has no faction</title>
    <summary xml:lang="en-US">(1) To start with some rare good news: I was delighted that the US Supreme Court, in a 5-4 holding led by Chief Justice Roberts (!), struck down the Trump administration’s plan to end DACA (Deferred Action for Childhood Arrivals). Dismantling DACA would’ve been a first step toward deporting 700,000 overwhelmingly blameless and peaceful people from, in […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-group"><div class="wp-block-group__inner-container"/></div>



<p>(1) To start with some rare good news: I was delighted that the US Supreme Court, in a 5-4 <a href="https://www.supremecourt.gov/opinions/19pdf/18-587_5ifl.pdf">holding</a> led by Chief Justice Roberts (!), struck down the Trump administration’s plan to end DACA (Deferred Action for Childhood Arrivals). Dismantling DACA would’ve been a first step toward deporting 700,000 overwhelmingly blameless and peaceful people from, in many cases, the only homes they remember, for no particular reason other than to slake the resentment of Trump’s base. Better still was the majority’s argument: that when, by law, a federal agency has to supply a <em>reason</em> for a policy change (in this case, ending DACA), its reason can’t just be blatantly invented <em>post facto</em>.</p>



<p>To connect to my <a href="https://www.scottaaronson.com/blog/?p=4845">last post</a>: I hope this gives some evidence that, if Trump refuses to accept an electoral loss in November, and if it ends up in the Supreme Court as Bush v. Gore did, then Roberts might once again break from the Court’s other four rightists, in favor of the continued survival of the Republic.</p>



<p>(2) Along with Steven Pinker, Scott Alexander, Sam Altman, Jonathan Haidt, Robert Solovay, and others who might be known to this blog’s readership, I decided after reflection to sign a <a href="https://sites.google.com/view/petition-letter-stephen-hsu/home?authuser=0">petition</a> in support of Steve Hsu, a theoretical physicist turned genomics researcher, and the Senior Vice President for Research and Innovation at Michigan State University.</p>



<figure class="wp-block-image"><img alt="Information Processing: Hail to the Chief" src="https://1.bp.blogspot.com/-dVAprDWO_YI/UzGkunExlkI/AAAAAAAAEq4/MuApiqQsX_I/s1600/photo+(4).JPG"/>Hsu is the one on the right.</figure>



<p>Hsu now faces possible firing, because of a social media campaign apparently started by an MSU grad student and SneerClub poster named Kevin Bird.  What are the <a href="https://twitter.com/GradEmpUnion/status/1270829003130261504">charges</a>?  Hsu appeared in 2017 on an alt-right podcast (albeit, one that Noam Chomsky has also appeared on).  On Hsu’s own podcast, he <a href="https://manifoldlearning.com/episode-010-transcript/">interviewed Ron Unz</a>, who despite Jewish birth has become a <a href="https://www.unz.com/runz/american-pravda-holocaust-denial/">nutcase Holocaust denier</a>—yet somehow that topic never came up on the podcast.  Hsu said that, as a scientist, he doesn’t know whether group differences in average IQ have a genetic component, but our commitment to anti-racism should never hinge on questions of biology (a view also espoused by Peter Singer, perhaps the leading liberal moral philosopher of our time).  Hsu has championed genomics research that, in addition to medical uses, <em>might someday</em> help enable embryo screening for traits like IQ.  Finally, Hsu supports the continued use of standardized tests in university admissions (yes, that’s one of the listed charges).</p>



<p>Crucially, <strong>it doesn’t matter</strong> for present purposes if you disagree with many of Hsu’s views. The question is more like: <em>is agreement with Steven Pinker, Jonathan Haidt, and other mild-mannered, Obama-supporting thinkers featured in your local airport bookstore now a firing offense in academia?  And will those who affirm that it is, claim in the next breath to be oppressed, marginalized, the Rebel Alliance?</em></p>



<p>To be fair to the cancelers, I think they have two reasonable arguments in their favor.</p>



<p>The first that they’re “merely” asking for Hsu to step down as vice president, not for him to lose his tenured professorship in physics.  Only <em>professors</em>, say the activists, enjoy academic freedom; <em>administrators</em> need to uphold the values and public image of their university, as Larry Summers learned fifteen years ago.  (And besides, we might add, what intellectual iconoclast in their right mind would ever <em>become</em> a university VP, or want to stay one??)  I’d actually be fine with this if I had any confidence that it was going to end here.  But I don’t.  Given the now-enshrined standards—e.g., that professors hold positions of power, and that the powerful can oppress the powerless, or even do violence to them, just by expressing or entertaining thoughts outside an ever-shrinking range—why should Hsu trust any assurances that he’ll be left alone, if he <em>does</em> go back to being a physics professor?  If the SneerClubbers can cancel him, then how long until they cancel Pinker, or Haidt, or me?  (I <em>hope</em> the SneerClubbers enthusiastically embrace those ideas!  If they do, then no one ever again gets to call me paranoid about Red Guards behind every bush.)</p>



<p>The second reasonable argument is that, as far as I can tell, Hsu really did grant undeserved legitimacy to a Holocaust denier, via a friendly interview about other topics on his podcast.  I think it would help if, without ceding a word that he doesn’t believe, Hsu were now to denounce racism, Holocaust denial, and specifically Ron Unz’s flirtation with Holocaust denial in the strongest possible terms, and explain why he didn’t bring the topic up with his guest (e.g., did he not know Unz’s views?).</p></div>
    </content>
    <updated>2020-06-18T21:35:08Z</updated>
    <published>2020-06-18T21:35:08Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Obviously I'm Not Defending Aaronson"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-06-20T23:48:04Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-785371757594389601</id>
    <link href="http://processalgebra.blogspot.com/feeds/785371757594389601/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=785371757594389601" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/785371757594389601" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/785371757594389601" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2020/06/an-interview-with-hans-huttel-concur.html" rel="alternate" type="text/html"/>
    <title>An interview with Hans Hüttel, CONCUR Test-of-Time Award recipient</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">This post is devoted to the fourth, and last, interview with the <a href="https://concur2020.forsyte.at/test-of-time/index.html">colleagues</a> who were selected for the first edition of the CONCUR  Test-of-Time Award. (See <a href="https://processalgebra.blogspot.com/2020/04/an-interview-with-davide-sangiorgi.html">here</a> for the interview with <a href="http://www.cs.unibo.it/~sangio/">Davide Sangiorgi</a>,  <a href="https://processalgebra.blogspot.com/2020/04/an-interview-with-nancy-lynch-and.html">here</a> for the interview with <a href="https://people.csail.mit.edu/lynch/">Nancy Lynch</a> and <a href="http://profs.sci.univr.it/~segala/">Roberto Segala</a>, and <a href="https://processalgebra.blogspot.com/2020/04/an-interview-with-rob-van-glabbeek.html">here</a> for the interview with </span></span></span></span></span></span><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><a href="http://theory.stanford.edu/~rvg/">Rob van Glabbeek</a></span></span></span></span></span></span>.) In keeping with my previous interviews, I asked  <a href="http://people.cs.aau.dk/~hans/index-eng.html">Hans  Hüttel</a> (Aalborg University, Denmak) a few questions via email and you can find his answers below. </span></span></span></span></span></span><br/><br/><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Hans receives the award for his paper</span></span></span></span></span></span><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"> "Bisimulation Equivalence is Decidable for all Context-Free Processes", which he wrote  with S</span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">ø</span></span></span><span><span style="font-size: x-small;"><span lang="en-US">ren Christensen and Colin Stirling. </span></span></span></span></span></span></span></span></span></span></span></span><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">S</span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">ø</span></span></span><span><span style="font-size: x-small;"><span lang="en-US">ren moved to industry after finishing his PhD. Colin is now retired.  </span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><br/><br/><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: You receive one of the two CONCUR ToT Awards for the period 1990-1993 for the paper</span></span></span><span><span style="font-size: x-small;">  </span></span><span><span style="font-size: x-small;"><span lang="en-US">"<a href="https://www.lfcs.inf.ed.ac.uk/reports/92/ECS-LFCS-92-218/">BisimulationEquivalence is Decidable for all Context-Free Processes</a>" you published with S</span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">ø</span></span></span><span><span style="font-size: x-small;"><span lang="en-US">ren Christensen and Colin Stirling at CONCUR 1992. Could you tell us briefly what the context for that work was and how it came about? </span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: I was working on my PhD which was on the topic of decidability of behavioural equivalences for process calculi that allow processes to have infinite state spaces. Baeten, Bergstra and Klop had proved that strong bisimilarity is in fact decidable for the BPA calculus even though the class of trace languages for BPA is exactly the class of context-free languages. The result only held for normed BPA processes, that is, processes that could always terminate. Colin was my supervisor in Edinburgh, and he suggested that I try to find a simpler proof of that result (much can be said about the original proof, but simple it was not!). This turned out to be really interesting; I met Didier Caucal from IRISA who had found a nice, much shorter proof that relied on finite characterizations and I was able to use his notion of self-bisimilarity to prove that a tableau system for bisimilarity was sound and complete wrt. bisimilary. Jan Friso Groote, who was a PhD student at the CWI at the time, and myself proved that all other known equivalences are undecidable for normed BPA (and therefore </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>a fortiori</i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">also for full, unnormed BPA). But one problem that Colin and I were never able to solve was if the decidability result also held for the full BPA calculus.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Søren arrived in Edinburgh in 1990 and we shared a flat there, in St Leonards Bank just across from Holyrood Park. We hung out with the same people in the LFCS, many of whom were clever Italians such as Davide Sangiorgi and clever quasi-Italians such as Marcelo Fiore. It is no surprise that Søren and I often discussed our work or that he, given that Colin was also his supervisor, moved on to study decidability problems as well, the only difference being that Søren was mostly interested in the BPP calculus that has parallel composition instead of sequential composition.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">When I left Edinburgh at the end of August of 1991, Colin and I had managed to make some progress on the decidability problem for unnormed BPA. We realised that a finite characterization of the maximal bisimulation </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>á la</i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">Caucal was the way ahead but the actual characterization escaped us. When I returned for my viva in December, Søren had found an important lemma on finite characterizations and everything fell into place. The decidability result relied on proving that bisimilarity is semi-decidable using the finite characterization; non-bisimilarity was already known to be semi-decidable. </span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: Both S</span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">ø</span></span></span><span><span style="font-size: x-small;"><span lang="en-US">ren Christensen and you wrote the award-winning paper as PhD students in Edinburgh. Could you tell us about the research environment in Edinburgh at that time, and the influence it had on you then and in the rest of your career? </span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: The LFCS in Edinburgh was a great place to be at the time. Robin Milner was still around and busy working on the pi-calculus together with Davide Sangiorgi, who was his student at the time. Watching them at the blackboard was interesting, even though the rest of us often could not follow their discussions! Gordon Plotkin was there (and still is, fortunately). Rod Burstall was still active, and so was Mike Fourman. Plus many, many others. There was always someone to talk to, and it was perfectly legitimate to have an interest in basic research. Unlike the other professors, Colin had no background in maths – he was originally a philosopher! – and maybe that was why he was trying to avoid heavy mathematical lingo, trying to be simple and precise in his writing at the same time. I learned a lot from him, also in that respect.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">After Søren returned to Denmark, he left academia and got a job in the private sector. He still lives near Aarhus. Sadly we lost touch with each other, in all likelihood because our lives turned out so different. We got back in touch recently, when we were told about the reward and we look forward to finally meeting each other again. Colin retired recently, and I really hope to see him again, when I am able to travel to Scotland again some day.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: medium none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: How much of your later work has built on your award-winning paper? What follow-up results of yours are you most proud of and why?</span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: I worked on decidability issues for another few years after that but there was no-one to talk to in Aalborg, or rather, there was no-one there that shared my interest in the area at the time. What is more, the open problems that remained were major challenges. Some were only solved much later (such as the decidability of bisimilarity for pushdown automata, a result due to Sénizergues, the proof later greatly simplified by Colin) or remain open (such as the decidability of weak bisimilarity for BPA). Eventually I drifted down the slippery slope and became interested in other, related topics, and focused somewhat more directly on program properties. The follow-up result that most directly relates to my paper with Søren and Colin is the result from 1994 that bisimilarity is also the only equivalence that is decidable for BPP. This is a result that I am also quite proud of. It grew out of discussions with Javier Esparza and Yoram Hirshfeld, when I was back in Edinburgh for a while in 1993. Ironically, there was a subtle flaw in the proof that Naoki Kobayashi discovered many years later. Naoki and one of his student found out how to repair the proof, and the three of us co-authored the journal version that came out many years later. The reason why Naoki became interested in BPP was that he was trying to use the calculus as a behavioural type system for a pi-calculus. As it happened, this was also the route that I had taken.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Those of my later results that I am most proud of have to do with this area: My work on type systems for psi-calculus (CONCUR 2011 and later) and a session type system for bounded name use in the pi-calculus (Acta Informatica 2019). The latter paper also has a CONCUR connection; it grew out of attending a talk by Roland Meyer at CONCUR 2013 and wondering why they were not trying to characterize notions of name-boundedness in the pi-calculus by means of a type system. It turned out that Meyer et al. were not familiar with type systems at all. It took me an awful long time to work out a type-based characterization (using session types), as you can probably tell.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">As you can tell, I have not worked on bisimulation for quite some time. Not that there is anything wrong with bisimulation, of course, but if one wants results that are applicable for automated reasoning about program behaviour, decidability is important. One can then either choose to go for a less expressive model of computation (which is what researchers in the model checking community do) or keep the model of computation and go for sound, but incomplete characterizations of program properties (which is what researchers interested in type systems and related static analysis methods do). I ended up in the latter camp.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: To your mind, what are the most interesting or unexpected uses in the literature of the notions and techniques you developed in "Bisimulation Equivalence is Decidable for all Context-Free Processes"? </span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: BPA, BPP and similar process calculi can be used as the basis of behavioural type systems, and I am thrilled that my old research interests and my current research interests are so directly related. </span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">In 2018 I discovered that Vasco Vasconcelos and Peter Thiemann had devised a session type system for a functional programming language in which session types were not regular expressions (which is essentially what they are in the original work by Honda, Kubo and Vasconcelos) but BPA processes. Vasco and Peter knew that type equivalence should be decidable but they were not so familiar with our results from the early 1990s. At POPL 2019 I attended a talk by Andreia Mordido, one of Vasco’s collaborators, and she mentioned our paper from CONCUR 1992! Later that day, I ended up talking to Andreia and Vasco about my work on BPA from all those years ago.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: The last forty years have seen a huge amount of work on process algebra and process calculi. However, the emphasis on that field of research within concurrency theory seems to have diminished over the last few years, even in Europe. What advice would you give to a young researcher interested in working on process calculi today? </span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: That they should still work on process calculi! There remains a lot of interesting work to be done. One reason why research topics drift in and out of focus is simply that researchers lose interest; it is hardly ever the case that a topic runs out of interesting research questions. Another reason is rather grim: Basic research is nowhere near as well-respected as it used to be. If you look at the funding schemes that we have today, only the very successful few can get funding for basic research; I am not among them and it does get frustrating quite often. Most topics these days deal with applied research. There is nothing wrong with applied research per se; some of what I do is on that side of things, but there has to be more to research than that. </span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: medium none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: What are the research topics that currently excite you the most?</span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: I have slowly become more and more interested in programming language theory, and some of my current collaborators have taken a similar route, beginning in concurrency theory, drifting into the world of behavioural type systems and finally wanting to apply all of their skills to actual programming languages. Right now Mario Bravetti, Adrian Francalanza, António Ravara and myself are involved in working on a behavioural type system related to the Mungo tool for a subset of Java. I am fortunately enough to have had three exceptionally clever and productive MSc students involved as well, and this has been extremely helpful. Mungo is in many ways the work of Simon Gay and Ornela Dardha at Glasgow University, and they, too, began their careers working on process calculi.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: medium none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="en-US">Luca: You have a keen interest in teaching at university level. Is there anything you think we should do better in conveying the beauty and usefulness of theoretical computer science in general, and concurrency theory in particular, to our students today? Do you have any thoughts you'd like to share with us on how to combine digital resources and in-person meetings in the teaching of subjects in the theory of computing?</span></span></span></span></span></span></div><div align="justify" style="border: none; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">Hans: Personally I think there is a tendency to present any academic topic – and in particular topics in the mathematical sciences, broadly speaking – in such a way that the definitions and theorems appear as if they fell from the heavens, fully formed. As any researcher will know, that is certainly </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>not </i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">how they came about. In this way, we focus a lot on what Imre Lakatos and Karl Popper called the </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>context of justification. </i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">A well-honed presentation of a theory may appear to be beautiful, but in my opinion the actual beauty is the one that one experiences when one has finally understood the theory and understands why the definitions and theorem turned out the way they did – that is, one must understand the </span></span></span><span><span style="font-size: x-small;"><span lang="da-DK"><i>context of discovery.</i></span></span></span><span><span style="font-size: x-small;"><span lang="da-DK">I think problem-based learning (which is something that we talk about a lot at Aalborg University and at Roskilde University) is the key here, because it puts the focus on student-centered active learning.</span></span></span></span></span></span></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><br/></div><div align="justify" style="border: none; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 100%; margin-bottom: 0in; padding: 0in; text-decoration: none;"><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK">I have lectured a lot over the years but since 2013 I have drifted away from traditional lectures towards flipped teaching in which I use pre-recorded podcasts (of my own making) that students can watch whenever they want; I then use the plenary sessions for activities that focus on active learning. I by far prefer having a dialogue with students that focuses on the problems that they encounter to the monologue style of a lecture. All my teaching activities are now flipped and I am happy to say that some of my colleagues are now thinking along similar lines. It is always good to have someone to talk to. </span></span></span></span></span></span><br/><span style="color: black;"><span><span style="background: transparent;"><span><span style="font-size: x-small;"><span lang="da-DK"> </span></span></span></span></span></span></div></div>
    </content>
    <updated>2020-06-18T21:29:00Z</updated>
    <published>2020-06-18T21:29:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2020-06-20T12:42:34Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5834988441622500007</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5834988441622500007/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/on-chain-letters-and-pandemics.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5834988441622500007" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5834988441622500007" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/on-chain-letters-and-pandemics.html" rel="alternate" type="text/html"/>
    <title>On Chain Letters and Pandemics</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div><i>Guest post by Varsha Dani.</i></div><div><br/></div><div>My 11-year-old child received a letter in the mail. "Send a book to the first person named," it said, "then move everyone's name up the list, add your own name and send copies of the letter to six friends. In a few weeks you will receive 36 books from all over the world!". Wow. When I first encountered chain letters in the mid eighties, it was postcards, but even then it hadn't taken me in. Since then I hadn't seen one of these in a long time, but I guess with a lot of people suddenly at home for extended periods, people crave both entertainment and a connection to others. </div><div><br/></div><div>What's wrong with chain letters? Well quite apart from the fact that they are illegal, even a child can comprehend that the number of books (or postcards or other gifts) received must equal the number sent, and that for every participant who does get a rich reward, there will be many who get nothing. </div><div><br/></div><div>But there is another kind of chain communication going around. It is an email, asking the recipient to send a poem or meditation to somebody, and later they will receive many communications of the same sort. How endearing. Poetry. Sweetness and Light. No get-rich-quick pyramid schemes here. What's wrong with that? </div><div><br/></div><div>Of course, it depends on what one means by "wrong". Maybe you like exchanging poetry with strangers. Maybe you don't find it onerous or wish that your spam filter would weed it out. But let's leave aside those issues and look at the math alone. You send the email to two friends, each of whom forwards it to two of their friends and so on. So the number of people the email reaches ostensibly doubles every step. Exponential growth. But in fact that is not what the graph of human connections looks like. Instead, what happens is that the sets of friends overlap, so that after a while the growth stops being exponential and tapers down. </div><div><br/></div><div>Where else have we seen something like that? Oh, right. The pandemic. The virus jumps from infected people to the people they meet, and from them to the people they meet and so on. Initially, that's exponential growth fof new cases, but after a while  it tapers off, forms a peak and then starts to decrease. Why? Because eventually there is overlap in the sets of people that each infected person is "trying" (unintentionally) to infect, and a newly infected person who got the virus from one or many previously infected people is still just one newly infected person.  </div><div><br/></div><div>So the chain letter spreads just like a virus. Indeed if one were to, somewhat fancifully, think of the chain letter as an independent entity whose goal is to self-replicate, then it looks even more like a virus, and, like a virus, it can only achieve its self-replication goal through the help of a host. But here's a way in which it is not like a virus. Once one has got the virus and recovered, one (hopefully) does not get it again. Not so the chain letter, of which one may get many copies over time! So maybe you will get some gifts or poetry, but you will likely also get more requests for them!</div><div><br/></div><div>So what's wrong with the poetry chain email? It depends on your perspective.  To those of you who are wistfully waiting for that Poem from a Stranger, I dedicate the following to you.</div><div><br/></div><hr/><div><br/></div><div><i>An open letter to my 2<sup>n</sup> dearest friends:</i></div><div><br/></div><div>A letter came for me today</div><div>It promised wondrous ends</div><div>If only I would forward it </div><div>To just two other friends.</div><div><br/></div><div>If they in turn should send it on</div><div>to two more that they know,</div><div>the goodwill that we're sending out</div><div>would grow and grow and grow.</div><div><br/></div><div>Is this as pleasant as it seems?</div><div>Alas, dear friends, it's not.</div><div>This exponential growth can lead</div><div>To quite a sticky spot.</div><div><br/></div><div>Friends of friends of friends of mine</div><div>May very well be linked</div><div>The further that the letters go.</div><div>These folks are not distinct!</div><div><br/></div><div>Ensuring there's no overlap</div><div>Is a logistic* pain.</div><div>As you will see, when you receive</div><div>That letter yet again. </div><div><br/></div><div>So while you're stuck at home this year</div><div>And pacing in your room.</div><div>Pick up the phone and make a call</div><div>Or see your friends on Zoom.</div><div><br/></div><div>Your real thoughts would make me smile.</div><div>Chain letters are a con.</div><div>Do everyone a favor and</div><div>Don't send that letter on!</div><div><br/></div><div>--------------</div><div>* Pun intended. <a href="https://en.wikipedia.org/wiki/Logistic_function#In_medicine:_modeling_of_a_pandemic">https://en.wikipedia.org/wiki/Logistic_function#In_medicine:_modeling_of_a_pandemic</a></div><div><br/></div><div><br/></div></div>
    </content>
    <updated>2020-06-18T13:57:00Z</updated>
    <published>2020-06-18T13:57:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-06-20T14:01:03Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://gradientscience.org/background/</id>
    <link href="https://gradientscience.org/background/" rel="alternate" type="text/html"/>
    <title>Noise or Signal&amp;#58; The Role of Backgrounds in Image Classification</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="bbutton" href="http://arxiv.org/abs/2006.09994" style="float: left;">
<i class="fas fa-file-pdf"/>
    Read the paper
</a>
<a class="bbutton" href="https://github.com/MadryLab/backgrounds_challenge" style="float: right;">
<i class="fab fa-github"/>
   Download the datasets
</a></p>

<p><em>We discuss our recent <a href="https://arxiv.org/abs/2006.09994">paper</a> 
on identifying the role of backgrounds in image classification. Along with our
results, we’re releasing our code and datasets <a href="https://github.com/MadryLab/backgrounds_challenge">as a benchmark</a>.</em></p>

<p>As we discussed in our <a href="https://gradientscience.org/benchmarks">last post</a>, quantitative
benchmarks are key drivers of progress across many computer vision tasks. 
On tasks like image classification, state of the art is often determined by models’
accuracies on standard datasets, such as CIFAR-10 and ImageNet. 
Still, model accuracy isn’t all that matters, as evidenced by investigations into
robustness (e.g., <a href="https://gradientscience.org/intro_adversarial">[1]</a>), 
reliability (e.g., <a href="https://arxiv.org/abs/1903.12261">[2]</a>), 
and out-of-distribution performance (e.g., <a href="https://arxiv.org/abs/1706.02690">[3]</a>). 
These properties are governed not only by models’ predictions on test data, but
also by the specific set of correlations models use, and by how these
correlations are combined to make predictions. 
For example, previous work has shown that model predictions can behave
unexpectedly due to reliance on correlations that we humans 
don’t rely on (e.g. <a href="https://arxiv.org/abs/1711.11561">[4]</a>,
<a href="https://arxiv.org/abs/1807.04200">[5]</a>,
<a href="https://arxiv.org/abs/1905.02175">[6]</a>, 
<a href="https://arxiv.org/abs/1811.00401">[7]</a>); or due to overusing even
human-recognizable correlations such as texture (e.g., 
<a href="https://arxiv.org/abs/1811.12231">[8]</a>,
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6306249/">[9]</a>) or color 
(e.g., <a href="https://journals.sagepub.com/doi/10.1068/p3376">[10]</a>). 
So it follows that if we want to understand these more complex properties of
machine learning models, we must first be able to characterize the correlations
that these models leverage.</p>

<p>Needless to say, a full characterization of the features and signals exploited
by deep neural networks is far beyond the scope of any single paper. In our
<a href="https://arxiv.org/abs/2006.09994">latest paper</a>, 
we thus take a deep dive into one specific kind of signal: <em>image backgrounds</em>.</p>

<p>Backgrounds are an established source of correlation between images and
their labels in object detection: ML models may use backgrounds in
classification (cf.
<a href="https://hal.archives-ouvertes.fr/hal-00171412/file/ZhangMarszalekLazebnikSchmid-IJCV07-ClassificationStudy.pdf">[11]</a>,
<a href="https://arxiv.org/abs/1602.04938">[12]</a>, 
<a href="https://arxiv.org/abs/1611.06596">[13]</a>,
<a href="https://arxiv.org/abs/1911.08731">[14]</a>), and even human
vision can make use of image context (cf.
<a href="http://people.csail.mit.edu/torralba/IJCVobj.pdf">[15]</a> and references). 
We thus want to understand better how current
state-of-the-art image classifiers rely on image backgrounds. 
Specifically, we investigate the extent of this reliance, its implications, and how models’ use of
backgrounds has evolved over time.</p>

<h2 id="a-new-dataset-or-seven">A new dataset (or seven)</h2>

<p>Our main tool for understanding how models use background signals is a set of
synthetic datasets that we refer to as ImageNet-9 (IN9). These datasets aim
to disentangle images’ foreground and background signals and thus enable us
to study their relative effects.</p>

<p>To generate ImageNet-9, we start by organizing a subset of ImageNet into nine
coarse-grained classes based on common ancestry in the <a href="https://wordnet.princeton.edu">WordNet hierarchy</a>: the
resulting “super-classes” are dog, bird, vehicle, reptile, carnivore, insect, 
instrument, primate, and fish. We call the 9-class dataset of unmodified images
Original.
We then use a combination of the bounding boxes
provided by ImageNet and the computer vision library <a href="https://opencv.org">OpenCV</a> to separate the
foreground and background in each imagewe deleted any images where this
process was unsuccessful (e.g., if there is no bounding box provided by ImageNet, or the bounding box takes up the entirety of the image).</p>

<p>Once we’ve separated the foreground and background signals, we introduce
 <em>seven</em> new datasets, falling into three categories:</p>

<ul>
  <li>Background-only datasets
    <ul>
      <li><strong>Only-BG-B</strong>: Black out the bounding boxes given by ImageNet annotations,
leaving only the background.</li>
      <li><strong>Only-BG-T</strong>: Take Only-BG-B and replace the blacked-out region with a
tiled version of the rest of the image (the background).</li>
      <li><strong>No-FG</strong>: Use OpenCV to extract the exact shape of the foreground, and
replace it with black.</li>
    </ul>
  </li>
  <li>Foreground-only datasets
    <ul>
      <li><strong>Only-FG</strong>: The exact complement of No-FG—rather than removing
the foreground, remove everything else.</li>
    </ul>
  </li>
  <li>Mixed datasets
    <ul>
      <li><strong>Mixed-Rand</strong>: For each image, overlay the foreground (extracted using
OpenCV) onto the background from a different random image (again,
extracted using OpenCV).</li>
      <li><strong>Mixed-Next</strong>: Assign each class a number from 1 to 9. For each image of
class $y$, add the background from a random image of class $y+1$ (or $1$, if
$y=9$).</li>
      <li><strong>Mixed-Same</strong>: For each image, add the background from a random image of
the same class.</li>
    </ul>
  </li>
</ul>

<div class="widget" style="display: flex;">
    <div class="choices_one" id="left_in9">
	<span class="widgetheading">Choose an Image</span>
    </div>
    <div class="selected_one" id="in9_selected"/>
</div>
<div style="clear: both;"/>
<div class="footnote">
        8 versions of the same image, with each version capturing a different
        combination of foreground and background signals.
</div>

<h2 id="putting-imagenet-9-to-work">Putting ImageNet-9 to work</h2>

<p>It turns out that these proposed ImageNet-9 datasets allow us to ask (and
answer) a variety of questions about the role of background signals in image
classification.</p>

<h3 id="1-is-background-signal-enough-for-classification">1. Is background signal enough for classification?</h3>

<p>Before we look at the behaviour of standard ML models, we first double-check
that background signals are exploitable in the first place—i.e., that models
can learn reasonably accurate classifiers for natural images while being trained
on backgrounds alone. 
We are not the first ones to consider this question (e.g.,
<a href="https://arxiv.org/abs/1611.06596">[13]</a>) but it serves as a useful sanity 
check and gives us a baseline to compare the rest of our experiments to.</p>

<p>We train models on the Only-BG-T, Only-BG-B, and No-FG datasets; the models
generalize reasonably well to both their corresponding test sets <em>and</em> the Original
test set (each model gets around 40-50% accuracy: a random classifier would get
11%). Thus, image backgroundsInterestingly, the No-FG model doesn't do
significantly better than the others, despite having access to the shape of the
foregrounds in the training set. <em>do</em> contain signal that
models can use to classify images.</p>

<p><img alt="The results of training models on background-only datasets and testing on the original." src="https://gradientscience.org/images/background/bg_only_train.png" style="width: 70%;"/></p>

<h3 id="2-do-models-actually-use-background-signals">2. Do models actually use background signals?</h3>

<p>So, backgrounds are indeed a useable signal for deep learning classifiers.
That’s not necessarily bad, or even different to humans: if you see an
occluded picture with an underwater background, you’d (hopefully) say that the
pictured object is more likely to be a fish than a dog.
On the other hand, humans are still able to call a dog a dog when it’s
underwater, i.e., a misleading/irrelevant background usually does not preclude us from
making the correct predictions. Is the same true for models?</p>

<p>To answer this question, we study model accuracies on the Mixed-Rand dataset,
where image backgrounds are randomized and thus provide no information 
about the correct label. 
Specifically, we compare model performance on Mixed-Rand and Mixed-Same: the
latter maintains the foreground-background correlation (since the background is
from the correct class), while controlling for artifactsSee
Appendix D of our paper for more details! from image
splicing process.</p>

<p>We denote the accuracy gap between Mixed-Same and Mixed-Rand as the BG-Gap,
i.e., the drop in model accuracy due to changing the class signal from the
background. The table below summarizes our observations: the BG-Gap is
13-22% and 6-14% for models trained on IN-9 and ImageNet, respectively,
suggesting that backgrounds often mislead state-of-the-art models even
when the correct foreground is present. (As we discuss in Appendix B of <a href="https://arxiv.org/abs/2006.09994">our
paper</a>, ImageNet-trained models do seem to be
more robust in this sense, but the reason for this robustness is hard to pin down.)</p>

<p><img alt="Evaluating pretrained models on Imagenet, Mixed-Rand, and Mixed-Same to compute the BG-Gap." src="https://gradientscience.org/images/background/table.png" style="width: 100%;"/></p>

<h3 id="3-ok-but-how-bad-can-it-get">3. Ok, but how bad can it get?</h3>

<p>The BG-Gap introduced in the previous experiment measures, in some sense,
models’ average robustness to misleading backgrounds. What does the worst case
look like? To diagnose just how large of an issue background over-reliance
can be, we search for the worst extracted background corresponding for each
extracted foreground. It turns out that a ResNet-50 model can be fooled on
87.5% of foregrounds by overlaying them on a corresponding “adversarial background.”</p>

<p>In fact, there also turn out to exist backgrounds that consistently affect the
prediction of the classifier <em>regardless</em> of what foreground is overlaid onto
them. The backgrounds below (extracted from insect images) fool our model into
predicting “insect” on up to 52\% of non-insect foregrounds:
<img alt="Adversarial Backgrounds" src="https://gradientscience.org/images/background/insect_result.png" style="width: 100%;"/></p>
<div class="footnote">
        The 5 most fooling backgrounds from the insect class, as well as the percent of non-insect foregrounds that they individually fool.
</div>

<p>Further, we can make the classifier predict “insect” on over 2/3 of the
foregrounds in the ImageNet-9 dataset, just by combining the foregrounds with
different insect backgrounds.</p>

<h3 id="4-what-is-the-effect-of-the-training-dataset">4. What is the effect of the training dataset?</h3>

<p>So far, all of the models that we’ve looked at have been trained on natural
data, i.e., either on the Original dataset from IN9, or on ImageNet itself.
We now want to test whether the previously-observed dependence on backgrounds
can be reduced (or removed altogether) by appropriately altering the training data.</p>

<p>To this end, we train models on Mixed-Rand, where background signals have been
decorrelated from class labels. 
We find these models perform only slightly better than
random on datasets with no foregrounds (e.g., a ResNet-50 trained on Mixed-Rand
achieves 15% accuracy on Only-BG-T and Only-BG-B).
They also perform better in the presence of misleading backgrounds:
training on Mixed-Rand improves accuracy on Mixed-Rand by 17%, and improves
accuracy on Mixed-NextRecall that Mixed-Next
images have foregrounds from class $y$ mixed with backgrounds from class $y+1$,
labeled as class $y$. by 22%. The model trained on
Mixed-Rand also has very little variation in accuracy across all five test sets
that contain the correct foreground (providing more evidence for its invariance
to other factors).</p>

<p><img alt="Training on Mixed-Rand and evaluating on other datasets" src="https://gradientscience.org/images/background/mixed_rand_results.png" style="width: 100%;"/></p>

<p>Qualitatively, the Mixed-Rand model also appears to place more relative
importance on foreground pixels than its original counterpart, as demonstrated
by the saliency maps below:</p>

<p><img alt="Saliency maps for models trained on original versus on Mixed-Rand" src="https://gradientscience.org/images/background/saliency_other.png" style="width: 100%;"/></p>

<h3 id="5-are-we-really-making-progress">5. Are we really making progress?</h3>

<p>We’ve now shown that models can exploit backgrounds, do exploit backgrounds, and
may actually do so to a fault. Considering that the development of these models
is driven by standard computer vision benchmarks, our results beg the question: to
what extent have improvements on ImageNet come with (or resulted from)
improvements in leveraging background correlations? And relatedly, how has
model robustness
to misleading background signals evolved over time?</p>

<p>As a first step towards answering these questions, we study the progress made by
ImageNet models on our proposed synthetic datasets. Below, we plot accuracy on
these datasets against ImageNet accuracy for a variety of different
network architectures:</p>

<p><img alt="ImageNet accuracy plotted against accuracy on synthetic datasets" src="https://gradientscience.org/images/background/in_vs_bg.png" style="width: 100%;"/></p>

<p>The plot indicates that accuracy increases on ImageNet generally correspond to
accuracy increases on all of the synthetic datasets that we consider. 
This includes the datasets that only contain background signals (Only-BG-T
in the graph above), which means that models <em>do</em> improve at extracting correlations
from image backgrounds. The fact that better models are also better at
classifying background-only images suggests that the use of background
signals might be inherent to the current training paradigm, and may
not disappearThough again, this might not be a bad
thing! on its own (i.e., without explicit regularization
or training).</p>

<p>Still, models’ <em>relative</em> improvement in accuracy across dataset variants is
promising—accuracy on background-only datasets is improving slower than
accuracy on datasets where the background is misleading, such as Mixed-Rand or
Mixed-Next. Another promising sign is that the
performance gap between the Mixed-Rand and Mixed-Same dataset (which we
previously referred to as the BG-Gap) trends towards closing, indicating that
models are not only better at using foreground features, but also more
robust to misleading background features.</p>

<p>Overall, our analysis reveals that better models in terms of ImageNet accuracy
are (a) increasingly capable of exploiting background correlations, but at the
same time (b) becoming more robust to changes in background, suggesting that
over-reliance on background features may not be necessary to maximize the
benchmark accuracy.</p>

<h3 id="conclusions">Conclusions</h3>

<p>In this post, we saw how computer vision models tend to over-rely on image
backgrounds in image classification. On one hand, our findings provide more
evidence that our models are not fully aligned with the human vision system. On the
other hand, we have shown that advances in computer vision models, such as new
architectures and training methods, have led to models that tend to use the
foreground more effectively and are more robust to misleading backgrounds.
We hope that the datasets and findings in this work provide a way to monitor
progress towards reliable, human-aligned machine learning.</p>

<p>For more detailed information about the <a href="https://github.com/MadryLab/backgrounds_challenge">datasets</a> we created, full
experimental results, and additional analysis, see <a href="https://gradientscience.org/background.pdf">our paper</a>!</p></div>
    </summary>
    <updated>2020-06-18T00:00:00Z</updated>
    <published>2020-06-18T00:00:00Z</published>
    <source>
      <id>https://gradientscience.org/</id>
      <author>
        <name>Gradient Science</name>
      </author>
      <link href="https://gradientscience.org/" rel="alternate" type="text/html"/>
      <link href="https://gradientscience.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Research highlights and perspectives on machine learning and optimization from MadryLab.</subtitle>
      <title>gradient science</title>
      <updated>2020-06-20T23:51:04Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-6952358197668395658</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/6952358197668395658/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=6952358197668395658" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/6952358197668395658" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/6952358197668395658" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2020/06/algorithms-with-predictions-survey-and.html" rel="alternate" type="text/html"/>
    <title>Algorithms with Predictions:  Survey and Workshop</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">There's a whole new, interesting theory trend  -- Algorithms with Predictions.  The idea, spurred by advances in machine learning, is that you assume you have predictor that tells you something about your input.  For example, in caching, you might have a prediction of when the item you are currently accessing will be next accessed.  Of course, machine learning predictions aren't perfect.  Still, you'd like to use this prediction to improve your caching algorithm, but from the theory side, we'd like provable statements.  For example, you could say, if my prediction is THIS good (e.g., the error is bounded under some metric), then my caching performance will correspondingly be at least THIS good (e.g., performance bounded in some way).<br/><br/>If you haven't seen the burgeoning spread of this line of work and are interested, you're in luck.  First, Sergei Vassilvitskii and I have written a <a href="https://arxiv.org/abs/2006.09123">brief survey that's now on the arxiv</a>.  We had written it for a collection Tim Roughgarden is organizing on Beyond Worst-Case Analysis (that we thought we be out by now, and should be out from the publisher soon-ish), but we've gone ahead and put a version on the arxiv to make it available.  The area is moving fast, so there are already many new results --  we hope to update the "survey" with new material as the area grows.<br/><br/>Second, one of the <a href="https://www.mit.edu/~vakilian/stoc-workshop.html">STOC'20 Workshops will be on Algorithms with Predictions</a>.  It will be on Friday from 1-4pm, with speakers Tim Roughgarden, Edith Cohen,  Ravi Kumar, and me.  I'll be talking about some of my recent work  (in submission) on queues with predictions, and partitioned learned Bloom filters.  (Arxiv papers are <a href="https://arxiv.org/abs/1902.00732">here</a>, <a href="https://arxiv.org/abs/1905.12155">here</a>, and <a href="https://arxiv.org/abs/2006.03176">here</a>, but maybe you want to see the talk first.)  I'll also do a blog post on partitioned learned Bloom filters in the near future.</div>
    </content>
    <updated>2020-06-17T17:52:00Z</updated>
    <published>2020-06-17T17:52:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2020-06-19T03:55:47Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-2271116647104476479</id>
    <link href="http://processalgebra.blogspot.com/feeds/2271116647104476479/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=2271116647104476479" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2271116647104476479" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/2271116647104476479" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2020/06/logic-mentoring-workshop-2020.html" rel="alternate" type="text/html"/>
    <title>Logic Mentoring Workshop 2020</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="_5pbx userContent _3576" id="js_k"><a href="https://www2.csc.liv.ac.uk/~lehtinen/">Karoliina Lehtinen</a> asked me to encourage young researchers of all ages to attend this year's edition of the Logic Mentoring Workshop. (See <a href="https://lmw.mpi-sws.org/">here</a> for information.) The <a href="https://lmw.mpi-sws.org/speakers.html">set of speakers</a> is top class, registration is  free and I am sure that attending the event would be beneficial  to  many. Spread the news!<br/><br/>FWIW, I gave a talk at the <a href="https://lics.siglog.org/lics17/lmw.html">2017 edition</a> of the event and thoroughly enjoyed it. Even though the event is targeted at students, from senior undergraduates to graduates, I feel that I always learn something new from attending this kind of workshops/talks. </div></div>
    </content>
    <updated>2020-06-17T16:10:00Z</updated>
    <published>2020-06-17T16:10:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2020-06-20T12:42:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17204</id>
    <link href="https://rjlipton.wordpress.com/2020/06/16/pnp/" rel="alternate" type="text/html"/>
    <title>P&lt;NP</title>
    <summary>Some thoughts on P versus NP Norbert Blum is a computer science theorist at the University of Bonn, Germany. He has made important contributions to theory over his career. Another claim to fame is he was a student of Kurt Mehlhorn, indeed the third of Mehlhorn’s eighty-eight listed students. Today I wish to discuss a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Some thoughts on P versus NP</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/?attachment_id=17188" rel="attachment wp-att-17188"><img alt="" class="alignright size-full wp-image-17188" src="https://rjlipton.files.wordpress.com/2020/06/unknown.jpeg?w=600"/></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p>
Norbert Blum is a computer science theorist at the University of Bonn, Germany. He has made important contributions to theory over his career. Another claim to fame is he was a student of Kurt Mehlhorn, indeed the <a href="https://www.genealogy.math.ndsu.nodak.edu/id.php?id=35475&amp;fChrono=1">third</a> of Mehlhorn’s eighty-eight listed students.</p>
<p>
Today I wish to discuss a new paper by Blum.</p>
<p>
No, it does not solve the P versus NP problem. The title of his paper is: <i>On the Approximation Method and the P versus NP Problem</i>. Its is available <a href="https://arxiv.org/pdf/1708.03486.pdf">here</a>.</p>
<p>
Blum. like most complexity theorists, believes that P is weaker than NP. This is usually stated as P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/>NP. The staff at GLL have the idea that we should state this as 	</p>
<p align="center"><img alt="\displaystyle  P &lt; NP. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P+%3C+NP.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  P &lt; NP. "/></p>
<p>This is clearer, more to the point, and logically what P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/>NP actually says. We will soon have T-shirts, mugs, and other stuff available in our web store at https:donotgotothisaddressplease.com. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/06/16/pnp/mug2-2/" rel="attachment wp-att-17207"><img alt="" class="aligncenter size-medium wp-image-17207" height="257" src="https://rjlipton.files.wordpress.com/2020/06/mug2-1.png?w=300&amp;h=257" width="300"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
</p><p/><h2> Three Years Ago </h2><p/>
<p/><p>
In 2017 Blum released a <a href="https://arxiv.org/abs/1708.03486">paper</a> that tried to prove P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. It caused a sensation—it was discussed on the complexity blogs such as <a href="https://lucatrevisan.wordpress.com/2017/08/15/on-norbert-blums-claimed-proof-that-p-does-not-equal-np/">In theory</a> and <a href="https://www.scottaaronson.com/blog/?p=3409">Shtetl-Optimized</a>. And also at <a href="https://rjlipton.wordpress.com/2017/08/17/on-the-edge-of-eclipses-and-pnp/">GLL</a>. Blum’s paper got thousands of Twitter mentions. Unfortunately he had to retract it, since it is wrong: He said: </p>
<blockquote><p><b> </b> <em> The proof is wrong. I shall elaborate precisely what the mistake is. For doing this, I need some time. I shall put the explanation on my homepage </em>
</p></blockquote>
<p>Look at <a href="https://johncarlosbaez.wordpress.com/2017/08/15/norbert-blum-on-p-versus-np/">here</a> for more comments that were made after his paper was released. </p>
<p>
He did, months later in 2017, post a two-page retraction<br/>
<a href="http://theory.cs.uni-bonn.de/blum/PvsNP/mistake.pdf">here</a>. His original paper’s abstract: </p>
<blockquote><p><b> </b> <em> Berg and Ulfberg and Amano and Maruoka have used CNF-DNF-approximators to prove exponential lower bounds for the monotone network complexity of the clique function and of Andreev’s function. We show that these approximators can be used to prove the same lower bound for their non-monotone network complexity. This implies P not equal NP. </em>
</p></blockquote>
<p>This approach is what we will discuss.</p>
<p>
</p><p/><h2> Today </h2><p/>
<p/><p>
Blum’s new paper does not claim to prove P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP, but gives his thoughts on P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. I think he has earned our attention. It must have been difficult to go from thinking you have solved <i>the problem</i> to retracting your paper. I have thought, privately, that I had solved some neat problems. Only later to discover that I was wrong. I cannot imagine how tough it was to do this in public. </p>
<p>
</p><p/><h2> The Idea </h2><p/>
<p/><p>
Blum’s work on proving lower bounds began with his dissertation under Mehlhorn, which included a 1985 <a href="https://www.sciencedirect.com/science/article/pii/0304397585900301">paper</a> on monotone network complexity for convolutions. Earlier in 1984 Blum <a href="https://reader.elsevier.com/reader/sd/pii/0304397583900294? which was improved token=1F67F05B416D89618750BC409200E17D536C46207555E1A9FD524B2592630E400FC2C597EA81F7190D2A747A4B82F28B">proved</a> a lower bound of order <img alt="{3n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3n}"/>. This stood for thirty years until in 2015 Magnus Find, Alexander Golovnev, Edward Hirsch, and Alexander Kulikov <a href="https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=919494">improved</a> it to order <img alt="{3.011n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3.011n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3.011n}"/>. A long way from super-polynomial lower bounds. See also a <a href="https://simons.berkeley.edu/sites/default/files/docs/3815/20151001gateelimination.pdf">talk</a> about this work. </p>
<p>
Blum’s new paper discusses an old approach to prove boolean circuit lower bounds. The methods he used in 1984 and those improved in 2015 do not seem to be on track to prove even non-linear circuit lower bounds. </p>
<p>
Let’s look at his comments at a high level. See his paper for details. </p>
<p>
Suppose that one has a boolean function <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> that is monotone: recall this means that if <img alt="{f(x)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)=1}"/>, then changing some input <img alt="{x_{k}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bk%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{k}}"/> from <img alt="{0 \rightarrow 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%5Crightarrow+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0 \rightarrow 1}"/> does not change the value of <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/>. Then it is always possible to compute <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> without using any negations: only and/or operations are needed. Sometimes one can prove that the number of such operations is super-linear, sometimes even super-polynomial. Even bounds in this restricted model can be deep.</p>
<p>
The idea that has tempted Blum and many other complexity theorists is: Can we extend the proofs for lower bounds without negations to ones with negations? One problem is there is a function <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> so that the following are true: </p>
<ol>
<li>
The function is monotone; <p/>
</li><li>
The function can be computed in polynomial time; <p/>
</li><li>
Any monotone circuit for computing the function requires exponential size
</li></ol>
<p>This is the famous <a href="https://en.wikipedia.org/wiki/Tardos_function">Tardos function</a> due to Éva Tardos. The existence of this function sunk Blum’s original paper. And it makes life hard for this general program—this is an instance of what our previous <a href="https://rjlipton.wordpress.com/2020/06/13/proof-checking-not-line-by-line/">post</a> meant by a proof attempt running up against a fundamental law. Negations can help tremendously in computing a function. </p>
<p>
</p><p/><h2> Blum’s Paper </h2><p/>
<p/><p>
In his new <a href="https://arxiv.org/pdf/1708.03486.pdf">paper</a> he surveys boolean complexity ideas—especially those linked to monotone complexity. He begins by trying to argue that the largeness feature of the <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">natural proofs</a> barrier, which applies to combinatorial properties defined via sub-additive circuit complexity measures, does not constrain approximation complexity measures of the kind he envisions. He then proceeds to define <em>CNF-DNF approximators</em> and further what he calls <em>sunflower approximators</em>. He does enough development to highlight a missing piece of information about monomial representations of <em>non-</em>approximated pieces of the Boolean function one is trying to prove hard. He concludes that without this information, his methods cannot even prove super-<em>linear</em> size lower bounds on general circuits.</p>
<p>
He ends with this assessment: </p>
<blockquote><p><b> </b> <em> How to proceed the work with respect to the P versus NP problem? Currently, I am convinced that we are far away to prove a super-polynomial lower bound for the non-monotone complexity of any explicit Boolean function. On the other hand, the strongest barrier towards proving P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP could be that it holds P = NP. To ensure that the whole time spent for working on the P versus NP problem is not used to prove an impossible theorem, I would switch to the try to develop a polynomial algorithm for the solution of an NP-complete problem. </em>
</p></blockquote>
<p/><p>
Note, we have changed his P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/>NP to P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. Ken and I agree with him on trying to work both on P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP and P=NP. However, see our comments below. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
I applaud Blum for thinking about P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. We need people to be fearless if it is ever going to be solved. However, I personally believe that his approach may be wrong:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> I am not as sure as he is that P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. I do think that P=NP is possible, especially if algorithms are allowed to be <a href="https://en.wikipedia.org/wiki/Galactic_algorithm">galactic</a>. Recall these are algorithms that run in polynomial time, but in polynomials of astronomical degree.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Also I am not sure if the boolean approach to P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP is the right one. Suppose there is a <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> so that SAT has boolean circuits of size <img alt="{n^{C}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n^{C}}"/> where 	</p>
<p align="center"><img alt="\displaystyle  C = 2^{2^{2^{10000}}}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%3D+2%5E%7B2%5E%7B2%5E%7B10000%7D%7D%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C = 2^{2^{2^{10000}}}. "/></p>
<p>It still could be the case that P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP, since there may be no uniform algorithm for SAT.</p>
<p>
Restating the last point: I believe we should try to prove what is needed, and not any more. The approach to P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP based on boolean circuit complexity is trying to prove too much. A proof that SAT has super-polynomial circuits does imply more than P<img alt="{&lt;}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{&lt;}"/>NP. A proof that SAT cannot be solved in time <img alt="o(n\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28n%5Clog+n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="o(n\log n)"/> on a multitape Turing machine would imply much less than P &lt; NP, yet still be a breakthrough</p>
<p>
Be cheap, prove the least possible. </p>
<p/></font></font></div>
    </content>
    <updated>2020-06-16T20:40:41Z</updated>
    <published>2020-06-16T20:40:41Z</published>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-06-21T03:20:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/092</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/092" rel="alternate" type="text/html"/>
    <title>TR20-092 |  Computing Igusa&amp;#39;s local zeta function of univariates in deterministic polynomial-time | 

	Ashish Dwivedi, 

	Nitin Saxena</title>
    <summary>Igusa's local zeta function $Z_{f,p}(s)$ is the generating function that counts the number of integral roots, $N_{k}(f)$, of $f(\mathbf x) \bmod p^k$, for all $k$. It is a famous result, in analytic number theory, that $Z_{f,p}$ is a rational function in $\mathbb{Q}(p^s)$. We give an elementary proof of this fact for a univariate polynomial $f$. Our proof is constructive as it gives a closed-form expression for the number of roots $N_{k}(f)$. 

Our proof, when combined with the recent root-counting algorithm of (Dwivedi, Mittal, Saxena, CCC, 2019), yields the first deterministic poly($|f|, \log p$) time algorithm to compute $Z_{f,p}(s)$. Previously, an algorithm was known only in the case when $f$ completely splits over $\mathbb{Q_p}$; it required the rational roots to use the concept of generating function of a tree (Zuniga-Galindo, J.Int.Seq., 2003).</summary>
    <updated>2020-06-16T08:32:14Z</updated>
    <published>2020-06-16T08:32:14Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-21T03:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/15/postdoc-positions-in-tcs-at-university-of-copenhagen-apply-by-july-6-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/15/postdoc-positions-in-tcs-at-university-of-copenhagen-apply-by-july-6-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc positions in TCS at University of Copenhagen (apply by July 6, 2020)</title>
    <summary>The CS department at the University of Copenhagen invites applications for postdoc positions in TCS. The application deadline is July 6, 2020. See https://employment.ku.dk/faculty/?show=151975 for the full announcement with more information and instructions for how to apply. Informal enquiries are welcome and may be sent to mthorup@di.ku.dk or jn@di.ku.dk. Website: https://employment.ku.dk/faculty/?show=151975 Email: jn@di.ku.dk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The CS department at the University of Copenhagen invites applications for postdoc positions in TCS. The application deadline is July 6, 2020. See <a href="https://employment.ku.dk/faculty/?show=151975">https://employment.ku.dk/faculty/?show=151975</a> for the full announcement with more information and instructions for how to apply. Informal enquiries are welcome and may be sent to mthorup@di.ku.dk or jn@di.ku.dk.</p>
<p>Website: <a href="https://employment.ku.dk/faculty/?show=151975">https://employment.ku.dk/faculty/?show=151975</a><br/>
Email: jn@di.ku.dk</p></div>
    </content>
    <updated>2020-06-15T21:51:22Z</updated>
    <published>2020-06-15T21:51:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-21T03:20:46Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/06/15/linkage</id>
    <link href="https://11011110.github.io/blog/2020/06/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Graduata data structures online (), finally done and graded. Warning: dry voice-over-slides videos, and some mistakes, because I didn’t have time to put together anything more sophisticated or edit more carefully.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.ics.uci.edu/~eppstein/261/">Graduata data structures online</a> (<a href="https://mathstodon.xyz/@11011110/104266993520726615"/>), finally done and graded. Warning: dry voice-over-slides videos, and some mistakes, because I didn’t have time to put together anything more sophisticated or edit more carefully.</p>
  </li>
  <li>
    <p><a href="https://boingboing.net/2020/06/02/list-100-times-law-enforceme.html">Freedom of the press under attack: 100+ times law enforcement violently assaulted journalists in US at George Floyd protests</a> (<a href="https://mathstodon.xyz/@11011110/104276714124643888"/>). Of course this is only a small piece of an enormous pattern of awfulness by the current administration, law enforcement, and the prison-industrial complex, but it’s a piece that I think is important to document.</p>
  </li>
  <li>
    <p><a href="https://blog.archive.org/2020/06/01/four-commercial-publishers-filed-a-complaint-about-the-internet-archives-lending-of-digitized-books/">Four book publishing corporations claim that what libraries always have done (lending out copies of books they have purchased as physical objects) is illegal, because computer, and are suing the Internet Archive over it</a> (<a href="https://mathstodon.xyz/@11011110/104283895750093044"/>, <a href="https://www.theverge.com/2020/6/1/21277036/internet-archive-publishers-lawsuit-open-library-ebook-lending">via</a>, <a href="https://torrentfreak.com/publishers-sue-the-internet-archive-over-its-open-library-declare-it-a-pirate-site-200601/">via2</a>). One of them, Wiley, is also a major publisher of academic works. Perhaps that should give some of us pause in which journals we send our papers to and referee for.</p>
  </li>
  <li>
    <p><a href="https://observablehq.com/@otaviocv/moire-patterns-from-random-dots">Moiré patterns from random dots</a> (<a href="https://mathstodon.xyz/@11011110/104290097720006041"/>). Overlaying the same random dot pattern on a translated and rotated copy of itself shows concentric dots around the center of rotation, illustrating <a href="https://en.wikipedia.org/wiki/Chasles%27_theorem_(kinematics)">Chasles’ theorem</a> that every rigid transformation of the plane is a translation or rotation. The effect seems to have first been observed by Leon Glass in “<a href="https://doi.org/10.1038/223578a0">Moiré patterns from random dots</a>” (<em>Nature</em>, 1969).</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1007/978-3-030-48966-3_3">“The Micro-world of Cographs”, Alecu, Lozin, and de Werra, <em>IWOCA</em> 2020</a> (<a href="https://mathstodon.xyz/@11011110/104295850760016598"/>). <a href="https://en.wikipedia.org/wiki/Cograph">Cographs</a> have a simple structure, but there’s still an interesting hierarchy of subclasses of graphs within them restricting different parameters of graph complexity to be bounded. A typical result: Every cograph with large h-index must contain a large complete graph, balanced bipartite graph, or forest of many high-degree stars.</p>
  </li>
  <li>
    <p><a href="https://www.theguardian.com/technology/2020/jun/01/cutting-edge-japanese-paper-art-inspires-a-non-slip-shoe">Japanese scientists use kirigami to design a shoe sole with pop-up non-slip spikes</a>.</p>
  </li>
  <li>
    <p><a href="https://mamot.fr/@starifi/104246098809527372">Ombre et lumière</a>. Artwork in which random-looking blocks on a wall create a recognizable shadow in side-light.</p>
  </li>
  <li>
    <p><a href="https://mathoverflow.net/a/362569/440">Brian Hopkins answers his own 9-year-old question on the history of  Fibonacci numbers and compositions</a> (<a href="https://mathstodon.xyz/@11011110/104312192948087479"/>). The ancient Indians knew that compositions (ordered partitions of integers) into ’s and ’s are counted by Fibonacci numbers. For instance, there five ways of forming  as an ordered sum of ’s and ’s:     . Cayley knew that the compositions with all parts bigger than  have Fibonacci counts. But who first knew that compositions with all parts odd are also counted by Fibonacci? Hopkins suggests: de Morgan, 1846.</p>
  </li>
  <li>
    <p>Despite new US covid cases being more or less the same level (or worse) as the start of the lockdown in March, <a href="https://www.chronicle.com/article/Faculty-Want-a-Say-in-Whether/248951">some universities are telling their students that it’s safe to return to normal and at the same time telling their faculty that unless they’re close to retirement age and have additional medical conditions, they must teach face to face</a> (<a href="https://mathstodon.xyz/@11011110/104318055800990449"/>).</p>
  </li>
  <li>
    <p><a href="https://drericsilverman.wordpress.com/games/">A nice page of recent writings about abstract strategy games, mostly connection games</a> (<a href="https://mathstodon.xyz/@jsiehler/104241019767261031"/>).</p>
  </li>
  <li>
    <p><a href="https://news.mit.edu/2020/guided-by-open-access-principles-mit-ends-elsevier-negotiations-0611">MIT gives up on trying to get an equitable subscription deal from Elsevier, ends negotiations</a> (<a href="https://mathstodon.xyz/@11011110/104326335350221116"/>, <a href="https://news.ycombinator.com/item?id=23489068">via</a>).</p>
  </li>
  <li>
    <p><em><a href="https://drops.dagstuhl.de/opus/portals/lipics/index.php?semnr=16150">The Proceedings of the 17th Scandinavian Symposium and Workshops on Algorithm Theory (SWAT 2020)</a></em> (<a href="https://mathstodon.xyz/@11011110/104334978432657954"/>), newly published open-access through LIPIcs. Sadly, the conference will be online rather than in the Faroe Islands as originally planned. <em><a href="https://drops.dagstuhl.de/opus/portals/lipics/index.php?semnr=16149">The Proceedings of the 36th International Symposium on Computational Geometry (SoCG 2020)</a></em> is also now out.</p>
  </li>
  <li>
    <p><a href="https://www.win.tue.nl/~kbuchin/proj/ruler/art/">Illuminate</a> (<a href="https://mathstodon.xyz/@11011110/104340239573347579"/>). An online puzzle based on the art gallery theorem, part of the media exposition of this year’s Symposium on Computational Geometry. See also the <a href="https://doi.org/10.4230/LIPIcs.SoCG.2020.80">theoretical writeup</a>.</p>
  </li>
  <li>
    <p><a href="https://link.springer.com/book/10.1007/978-1-84800-070-4">Skiena’s <em>Algorithm Design Manual</em></a> (<a href="https://mathstodon.xyz/@11011110/104349420443124730"/>, <a href="https://news.ycombinator.com/item?id=23529759">via</a>, <a href="https://news.ycombinator.com/item?id=23055340">via2</a>, <a href="https://www.metafilter.com/187489/Free-Textbooks">see also</a>), one of 500 Springer textbooks still available for free download from the publisher.</p>
  </li>
</ul></div>
    </content>
    <updated>2020-06-15T17:54:00Z</updated>
    <published>2020-06-15T17:54:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-06-16T00:55:22Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3523309889572389823</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3523309889572389823/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/presentations-of-diffie-helman-leave.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3523309889572389823" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3523309889572389823" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/presentations-of-diffie-helman-leave.html" rel="alternate" type="text/html"/>
    <title>Presentations of Diffie-Helman leave out how to find g</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">When I first taught Diffie Helman I read the following<br/>
1) Alice and Bob agree on p a prime and g a generator<br/>
2) Alice picks a, sends g^a to Bob, Bob picks b, sends g^b to Alice<br/>
3) Alice computes (g^b)^a and Bob computes (g^a)^b so they both have g^{ab}<br/>
<br/>
I knew how to find a prime- pick a number of length n (perhaps make sure the last digit is not even) and test for primality, if not then try again, you'll get one soon enough. I did not know how to find g. I had thought you<i> first </i>find p, and<i> then</i> given p you find g. I then figured out that you make actually pick  p to be a  <i>safe prime</i>, so q=(p-1)/2 is a prime, and then just pick random g and test them via computing  g^2  and g^q: if neither is 1 then g is a generator. You will find a generator soon enough.<br/>
<br/>
That was all fine. But how come my source didn't <i>say </i>how to find g.?You need to know that to run the algorithm. That was years ago. Then I wondered how common it is for an explanation to not say how to find g. So I Googled ``Diffie-Helman'' I only record those that had some technical content to them, and were not about other DH such as Elliptic Curves.<br/>
<br/>
0) <a href="http://www.cs.jhu.edu/~rubin/courses/sp03/papers/diffie.hellman.pdf">The Original DH paper</a> Page 34:<i> alpha is a fixed primitive element of GF(alpha)</i>. No mention of how to find either the prime q or the prim root alpha.<br/>
<br/>
1) <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange">Wikiepdia</a>: ... <i>protocol uses the mult group of integers mod p, where p is a prime and g is a prim</i> <i>root mod p</i>. NO mention of how they find p or g.<br/>
<br/>
2) <a href="https://mathworld.wolfram.com/Diffie-HellmanProtocol.html">Wolfram's MathWorld</a>:<i> They agree on two prime numbers g and p, where p is large and g is a prim root mod p. In practice it is good to choose p such that (p-1)/2 is also prime. </i>They mention (p-1)/2 but not for the reason I give. (There are algorithms for Discrete Log that do well if (p-1)/2 has many factors.)<br/>
<br/>
3) <a href="https://www.comparitech.com/blog/information-security/diffie-hellman-key-exchange/">Comparatech</a>: <i>Alice and Bob start out by deciding two numbers p and g.</i> No mention of how to find p or g.<br/>
<br/>
4) <a href="https://searchsecurity.techtarget.com/definition/Diffie-Hellman-key-exchange">Searchsecurity</a> Won't bother quoting, but more of the same, no mention of how to find p or g.<br/>
<br/>
5) <a href="https://doubleoctopus.com/security-wiki/encryption-and-cryptography/diffie-hellman-algorithm/">The Secret Security Wiki</a> <i>Alice and Bob agree on p and g</i>.<br/>
<br/>
6) <a href="https://www.sciencedirect.com/topics/computer-science/diffie-hellman">Science Direct</a> More of the same.<br/>
<br/>
7) <a href="https://www.math.ucla.edu/~baker/40/handouts/rev_DH/node1.html">Notes from a UCLA Crypto Course</a> YEAH! They say how to find g.<br/>
<br/>
8) <a href="https://brilliant.org/wiki/diffie-hellman-protocol/">Brilliant (yes that really is the name of this site)</a> Brilliant? Not brilliant enough to realize you need to say how to find p and g.<br/>
<br/>
9) <a href="https://wiki.openssl.org/index.php/Diffie_Hellman">OpenSSL</a> Hard to tell. Their intuitive explanation leaves it out, but they have details below and code that might have it.<br/>
<br/>
<br/>
I looked at a few more but it was the same story.<br/>
<br/>
This is NOT a RANT or even a complaint, but its a question:<br/>
<br/>
<b>Why do so few expositions of DH mention how to find p,g? You really need to do that if you really want to DO DH.</b><br/>
<b><br/></b>
Speculation<br/>
<br/>
1) Some of the above are for the laymen and hence can not get into that. But some are not.<br/>
<br/>
2) Some of them are for advanced audiences who would know how to do it. Even so, how to find the generator really needs to be mentioned.<br/>
<br/>
3) Goldilocks: Some papers are for the layman who would not notice the gap, and some papers are for the expert who can fill in the gap themselves, so no paper in between. I do not believe that.<br/>
<br/>
4) The oddest of the above is that the original paper did not say how to find g.<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2020-06-15T15:17:00Z</updated>
    <published>2020-06-15T15:17:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-06-20T14:01:03Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/06/14/infinite-threshold-graphs</id>
    <link href="https://11011110.github.io/blog/2020/06/14/infinite-threshold-graphs.html" rel="alternate" type="text/html"/>
    <title>Infinite threshold graphs, four different ways</title>
    <summary>One of the difficulties of extending results from finite graphs to infinite ones is that it is not always obvious how to extend the definitions. A single class of finite graphs may correspond, in the infinite graph world, to several different natural classes of infinite graphs. One of the ways this can happen is through orderings: if a class of graphs has a natural ordering on its vertices (say, through a construction in which graphs in this class are built up by adding one vertex at a time) then we might get several classes of infinite graphs with different ways of restricting or not restricting this vertex ordering.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>One of the difficulties of extending results from finite graphs to infinite ones is that it is not always obvious how to extend the definitions. A single class of finite graphs may correspond, in the infinite graph world, to several different natural classes of infinite graphs. One of the ways this can happen is through orderings: if a class of graphs has a natural ordering on its vertices (say, through a construction in which graphs in this class are built up by adding one vertex at a time) then we might get several classes of infinite graphs with different ways of restricting or not restricting this vertex ordering.</p>

<p style="text-align: center;"><img alt="Threshold graph" src="https://11011110.github.io/blog/assets/2020/threshold.svg"/></p>

<p>As an example of this phenomenon, consider the <a href="https://en.wikipedia.org/wiki/Threshold_graph">threshold graphs</a>, one of the simplest classes of finite graphs. An example is shown above. These can be defined in multiple equivalent ways:</p>

<ul>
  <li>
    <p>The finite threshold graphs are the graphs that can be built up by repeatedly adding either a universal vertex or an isolated vertex to a smaller graph. In the example, the vertices have been added in left-to-right order, with isolated vertices depicted in yellow and universal vertices in blue. This can be formalized in a way that extends to infinite graphs by saying that they are the graphs in which every nonempty induced subgraph contains either a universal vertex or an isolated vertex. Let’s call these graphs the “inductive threshold graphs”.</p>
  </li>
  <li>
    <p>We can also construct graphs in the reverse ordering, by repeatedly adding a vertex whose neighbors form a clique and whose non-neighbors form an independent set. More concisely, the vertex is both simplicial and cosimplicial. The example above can be constructed in this way by adding the vertices in right-to-left order, with the blue neighbors of each added vertex forming a clique and the yellow neighbors forming an independent set. This can be formalized in a way that extends to infinite graphs by requiring that every induced subgraph has a vertex that is simplicial and cosimplicial. Let’s call a graph with this property a “coinductive threshold graph”.</p>
  </li>
  <li>
    <p>The finite threshold graphs are the -free finite graphs, meaning that no four vertices form an induced subgraph that is a path, cycle, or perfect matching.</p>
  </li>
  <li>
    <p>The finite threshold graphs get their name from the following property: they are the graphs that we can generate by assigning weights in the interval  to the vertices and connecting two vertices by an edge whenever their sum of weights is at least one. Let’s call a graph with this property a “real threshold graph”.</p>
  </li>
</ul>

<p>All four of these properties are <a href="https://en.wikipedia.org/wiki/Hereditary_property">hereditary</a>: if a graph has the property, so do all its induced subgraphs. Because the three forbidden subgraphs , , and  have no universal or isolated vertex, have no simplicial and cosimplicial vertex, and have no valid weight assignment, the inductive threshold graphs, coinductive threshold graphs, and real threshold graphs are all subclasses of the -free graphs.</p>

<p>If a graph is -free, we can define a relation  on its vertices by saying that  if there is no vertex  with  forming an induced path or complement of a path. It follows from the nonexistence of the forbidden subgraphs that this is a total preorder, that every vertex  is universal or isolated among the vertices , and that every vertex  is simplicial and cosimplicial among the vertices . In the example above, two vertices are in the same equivalence class of the ordering if they are in a contiguous block of vertices with the same color, and otherwise their ordering according to  is the same as their left-to-right ordering. Because every finite total preorder has a minimal and a maximal element, every finite -free graph is an inductive threshold graph and a coinductive threshold graph.</p>

<p>However, these properties differ for infinite graphs. In an infinite inductive threshold graph, the total preorder must obey the <a href="https://en.wikipedia.org/wiki/Ascending_chain_condition">ascending chain condition</a> that there be no strictly-increasing infinite sequence of vertices, for the subgraph induced by the vertices of such a sequence would have no isolated or universal vertex. Conversely, if the order does obey the ascending chain condition, one could find an isolated or universal vertex in any subgraph by starting from an arbitrary vertex and repeatedly moving upwards in the order until getting stuck. So the inductive threshold graphs are exactly the ones whose order obeys the ascending chain condition. Similarly, the coinductive threshold graphs are exactly the ones whose order obeys the descending chain condition. But it is easy to construct orders that violate one or both of these conditions. A graph can only be a real threshold graph if the total order on the equivalence classes of its preorder can be embedded into , and again this is not true of all total orders.</p>

<p>One consequence of this difference between classes of infinite graphs is the construction of natural statements in the first-order <a href="https://en.wikipedia.org/wiki/Logic_of_graphs">logic of graphs</a> that are true for all finite graphs but untrue for some infinite graphs. For instance, the statements that a -free graph has an isolated or universal vertex, and that a -free graph has a simplicial and cosimplicial vertex, are both true of all finite graphs, but untrue of some infinite graphs.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104345188939710302">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-06-14T15:50:00Z</updated>
    <published>2020-06-14T15:50:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-06-16T00:55:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/091</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/091" rel="alternate" type="text/html"/>
    <title>TR20-091 |  Randomized polynomial-time equivalence between determinant and trace-IMM equivalence tests | 

	Janaky Murthy, 

	vineet nair, 

	Chandan Saha</title>
    <summary>Equivalence testing for a polynomial family $\{g_m\}_{m \in \mathbb{N}}$ over a field F is the following problem: Given black-box access to an $n$-variate polynomial $f(\mathbb{x})$, where $n$ is the number of variables in $g_m$ for some $m \in \mathbb{N}$, check if there exists an $A \in \text{GL}(n,\text{F})$ such that $f(\mathbb{x}) = g_m(A\mathbb{x})$. If yes, then output such an $A$. The complexity of equivalence testing has been studied for a number of important polynomial families, including the determinant (Det) and the family of iterated matrix multiplication polynomials. Two popular variants of the iterated matrix multiplication polynomial are: IMM$_{w,d}$ (the $(1,1)$ entry of the product of $d$ many $w\times w$  symbolic matrices) and Tr-IMM$_{w,d}$ (the trace of the product of $d$ many $w\times w$ symbolic matrices). The families - Det, IMM and Tr-IMM - are VBP-complete under $p$-projections, and so, in this sense, they have the same complexity. But, do they have the same equivalence testing complexity? We show that the answer is 'yes' for Det and Tr-IMM (modulo the use of randomness). 

The above result may appear a bit surprising as the complexity of equivalence testing for IMM and that for Det are quite different over rationals: a randomized polynomial-time equivalence testing for IMM over rationals is known [Kayal,Nair,Saha,Tavenas 2019], whereas [Garg,Gupta,Kayal,Saha 2019] showed that equivalence testing for Det over rationals is integer factoring hard (under randomized reductions and assuming GRH). To our knowledge, the complexity of equivalence testing for Tr-IMM was not known before this work. We show that, despite the syntactic similarity between IMM and Tr-IMM, equivalence testing for Tr-IMM and that for Det are randomized polynomial-time Turing reducible to each other over any field of characteristic zero or sufficiently large. The result is obtained by connecting the two problems via another well-studied problem in computer algebra, namely the full matrix algebra isomorphism problem (FMAI). In particular, we prove the following: 

1.Testing equivalence of polynomials to Tr-IMM$_{w,d}$, for $d\geq 3$ and $w\geq 2$, is randomized polynomial-time Turing reducible to testing equivalence of polynomials to Det$_w$, the determinant of the $w \times w$ matrix of formal variables. (Here, $d$ need not be a constant.)

2. FMAI is randomized polynomial-time Turing reducible to equivalence testing (in fact, to tensor isomorphism testing) for the family of matrix multiplication tensors $\{$Tr-IMM$_{w,3}\}_{w \in \mathbb{N}}$.

These results, in conjunction with the randomized poly-time reduction (shown in [GGKS19]) from determinant equivalence testing to FMAI, imply that the four problems - FMAI, equivalence testing for Tr-IMM and for Det, and the $3$-tensor isomorphism problem for the family of matrix multiplication tensors - are randomized poly-time equivalent under Turing reductions.</summary>
    <updated>2020-06-14T13:41:43Z</updated>
    <published>2020-06-14T13:41:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-21T03:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17191</id>
    <link href="https://rjlipton.wordpress.com/2020/06/13/proof-checking-not-line-by-line/" rel="alternate" type="text/html"/>
    <title>Proof Checking: Not Line by Line</title>
    <summary>Proofs and perpetual motion machines Leonardo da Vinci is, of course, famous for his paintings and drawings, but was also interested in inventions, and in various parts of science including mathematics and engineering. It is hard to imagine that he died over 500 years ago, given his continued impact on our world. He invented practical […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Proofs and perpetual motion machines</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2020/06/picture.png"><img alt="" class="alignright  wp-image-17193" height="150" src="https://rjlipton.files.wordpress.com/2020/06/picture.png?w=200&amp;h=150" width="200"/></a></p>
<p>
Leonardo da Vinci is, of course, famous for his paintings and drawings, but was also interested in inventions, and in various parts of science including mathematics and engineering. It is hard to imagine that he died over 500 years ago, given his continued impact on our world. He invented practical and impractical <a href="https://en.wikipedia.org/wiki/Leonardo_da_Vinci">inventions</a>: musical instruments, a mechanical knight, hydraulic pumps, reversible crank mechanisms, finned mortar shells, and a steam cannon.</p>
<p>
Today I wish to discuss proofs and perpetual motion machines.</p>
<p>
You might ask: <i>What do proofs and perpetual motion machines have in common?</i> Proofs refer to math proofs that claim to solve open problems like P <img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/> NP. Ken and I get such claims all time. I take a look at them, not because I think they are likely to be correct. Rather because I am interested in understanding how people think. </p>
<p>
I started to work on discussing such proofs when I realized that such “proofs” are related to claims about perpetual motion machines. Let’s see how.</p>
<p>
</p><p/><h2> Perpetual Motion Machines </h2><p/>
<p/><p>
A perpetual motion <a href="https://en.wikipedia.org/wiki/Perpetual_motion">machine</a> is a machine that operates indefinitely without an energy source. This kind of machine is impossible, as da Vinci knew already:</p>
<blockquote><p><b> </b> <em> Oh ye seekers after perpetual motion, how many vain chimeras have you pursued? Go and take your place with the alchemists. <br/>
—da Vinci, 1494 </em>
</p></blockquote>
<p/><p>
I like this statement about applying for US patents on such machines: </p>
<blockquote><p><b> </b> <em> Proposals for such inoperable machines have become so common that the United States Patent and Trademark Office (USPTO) has made an official policy of refusing to grant patents for perpetual motion machines without a working model. </em>
</p></blockquote>
<p/><p>
Here is a classic attempt at perpetual motion: The motion goes on “forever” since the right side floats up and the left side falls down. </p>
<p><a href="https://rjlipton.files.wordpress.com/2020/06/float.png"><img alt="" class="aligncenter size-full wp-image-17194" src="https://rjlipton.files.wordpress.com/2020/06/float.png?w=600"/></a></p>
<p>
The analogy of proofs and to perpetual motion machines is: The debunking such a machine is not done by looking carefully at each gear and lever to see why the machine fails to work. Rather is done like this: </p>
<blockquote><p><b> </b> <em> Your machine violates the fundamental laws of thermodynamics and is thus impossible. </em>
</p></blockquote>
<p>Candidate machines are not studied to find the exact flaw in their design. The force of fundamental laws allows a sweeping, simple, and powerful argument against them. There are similar ideas in checking a proof. Let’s take a look at them.</p>
<p>
</p><p/><h2> Proofs </h2><p/>
<p/><p>
Claims are made about proofs of open problems all the time. Often these are made for solutions to famous open problems, like P<img alt="{\neq}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cneq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\neq}"/>NP or the Riemann Hypothesis (RH).</p>
<p>
Math proofs are used to try to get to the <i>truth</i>. As we said <a href="https://rjlipton.wordpress.com/2019/04/24/why-check-a-proof/">before</a> proofs are only as good as the assumptions made and the rules invoked. The beauty of the proof concept is that arguments can be checked, even long and complex ones. If the assumptions and the rules are correct, then no matter how strange the conclusion is, it must be true.</p>
<p>
For <a href="https://math.stackexchange.com/questions/2949/which-one-result-in-mathematics-has-surprised-you-the-most">example</a>:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The Riemann rearrangement <a href="https://en.wikipedia.org/wiki/Ri emann_series_theorem#Statement_of_the_theorem">theorem</a>. A sum 	</p>
<p align="center"><img alt="\displaystyle  a_{1} + a_{2} + a_{3} + \dots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a_%7B1%7D+%2B+a_%7B2%7D+%2B+a_%7B3%7D+%2B+%5Cdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  a_{1} + a_{2} + a_{3} + \dots "/></p>
<p>that is conditionally convergent can be reordered to yield any number. Thus there is series 	</p>
<p align="center"><img alt="\displaystyle  b_{1} + b_{2} + b_{3} + \dots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++b_%7B1%7D+%2B+b_%7B2%7D+%2B+b_%7B3%7D+%2B+%5Cdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  b_{1} + b_{2} + b_{3} + \dots "/></p>
<p>that sums conditionally to your favorite number <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> and yet the <img alt="{b_{1},b_{2},\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb_%7B1%7D%2Cb_%7B2%7D%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b_{1},b_{2},\dots}"/> is just a arrangement of the <img alt="{a_{1},a_{2},\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_%7B1%7D%2Ca_%7B2%7D%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_{1},a_{2},\dots}"/>. This says that addition is not commutative for infinite series.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Cover the largest triangle by two <a href="https://www2.stetson.edu/~efriedma/squcotri/">unit squares</a>: what is the best? The following shows that it is unexpected: </p>
<p/><p/>
<p><a href="https://rjlipton.files.wordpress.com/2020/06/cover.png"><img alt="" class="aligncenter size-full wp-image-17195" src="https://rjlipton.files.wordpress.com/2020/06/cover.png?w=600"/></a></p>
<p/><p><br/>
The point of a proof is that it is a series of small steps. If each step is correct, then the whole is correct. But in practice proofs are often checked in other ways.</p>
<p>
</p><p/><h2> Checking Proofs </h2><p/>
<p/><p>
The starting point for my thoughts—joined here with Ken’s—are these two issues:</p>
<ol>
<li>
A proof that <em>only</em> has many small steps but no global picture is hard to motivate. <p/>
</li><li>
A proof with complex logic at the high level is hard to understand.
</li></ol>
<p>
Note that a deep, hard theorem can still have straightforward logic. A famous <a href="https://en.wikipedia.org/wiki/Riemann_hypothesis#Littlewood's_theorem">theorem</a> of Littlewood has for its proof the structure:</p>
<ul>
<li>
Case the RH is false: Then <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/> <p/>
</li><li>
Case the RH is true: Then <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/>
</li></ul>
<p>
The RH-false case takes under a page. The benefit with this logic is that one gets to assume RH for the rest. The strategy for the famous proof by Andrew Wiles of Fermat’s Last Theorem (FLT)—incorporating the all-important fix by Richard Taylor—has this structure:</p>
<ul>
<li>
If <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> then <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>. <p/>
</li><li>
If not-<img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> then <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>. <p/>
</li><li>
<img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> implies FLT. <p/>
</li><li>
<img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/> implies FLT.
</li></ul>
<p>
Wiles had done the last step long before but had put aside since he didn’t know how to get <img alt="{Z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Z}"/>. The key was framing <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> so that it enabled bridged the gap in his originally-announced proof while its negation enabled the older proof.</p>
<p>
Thus what we should seek are proofs with simple logic at the high level that breaks into cases or into sequential sub-goals so that the proof is a chain or relatively few of those goals. </p>
<p>
</p><p/><h2> Shapes and Barriers </h2><p/>
<p/><p>
This makes Ken and I think again about an old <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.73.7682">paper</a> by Juris Hartmanis with his students Richard Chang, Desh Ranjan, and Pankaj Rohatgi in the May 1990 <em>Bulletin of the EATCS</em> titled, “On IP=PSPACE and Theorems With Narrow Proofs.” Ken’s <a href="https://rjlipton.wordpress.com/2015/05/17/the-shapes-of-computations/">post</a> on it included this nice diagram of what the paper calls “shapes of proofs”:</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/06/proofshapes.png"><img alt="" class="aligncenter  wp-image-17197" height="252" src="https://rjlipton.files.wordpress.com/2020/06/proofshapes.png?w=400&amp;h=252" width="400"/></a></p>
<p/><p><br/>
Ken’s thought now is that this taxonomy needs to be augmented with a proof shape corresponding to certain classes believed to be properly below polynomial time—classes within the <a href="https://en.wikipedia.org/wiki/NC_(complexity)">NC</a> hierarchy. Those proofs branch at the top into manageable-size subcases, and/or have a limited number of sequential stages, where each stage may be wide but is shallow in its chains of dependencies. Call this shape a “macro-tree.”</p>
<p>
The difference between the macro-tree shape and the sequential shapes pictured above is neatly captured by Ashley Ahlin on a <a href="http://www.math.wichita.edu/~pparker/classes/thms.htm">page</a> about “Reading Theorems”:</p>
<blockquote><p><b> </b> <em> Note that, in some ways, the easiest way to read a proof is to check that each step follows from the previous ones. This is a bit like following a game of chess by checking to see that each move was legal, or like running a spell-checker on an essay. It’s important, and necessary, but it’s not really the point. … The problem with this is that you are unlikely to remember anything about how to prove the theorem, if you’ve only read in this manner. Once you’re read a theorem and its proof, you can go back and ask some questions to help synthesize your understanding. </em>
</p></blockquote>
<p/><p>
The other high-level structure that a proof needs to make evident—before seeing it is reasonable to expend the effort to check it—is shaped by <em>barriers</em>. We have <a href="https://rjlipton.wordpress.com/2012/11/29/barriers-to-pnp-proofs/">touched</a> on <a href="https://rjlipton.wordpress.com/2013/03/13/no-go-theorems/">this</a> topic <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">several</a> <a href="https://rjlipton.wordpress.com/2019/04/18/a-reason-why-circuit-lower-bounds-are-hard/">times</a> but maybe have not stated it full on for P versus NP. A recent <a href="http://theory.stanford.edu/~liyang/teaching/projects/formal-barriers-to-proving-P-ne-NP.pdf">essay</a> for a course led by Li-Yang Tan at Stanford does so in just a few pages. A proof should state up front how it works around barriers, and this alone makes its strategy easier to follow.</p>
<p>
The idea of barriers extends outside P versus NP, of course. Peter Scholze seems to be invoking it in a <a href="https://www.math.columbia.edu/~woit/wordpress/?p=11709&amp;cpage=1#comment-235940">comment</a> two months ago in a <a href="https://www.math.columbia.edu/~woit/wordpress/?p=11709">post</a> by Peter Woit in April on the status of Shinichi Mochizuki’s claimed proof of the ABC conjecture:</p>
<blockquote><p><b> </b> <em> I may have not expressed this clearly enough in my manuscript with Stix, but there is just no way that anything like what Mochizuki does can work. … The reason it cannot work is a[nother] theorem of Mochizuki himself. … If the above claims [which are negated by the theorem] would have been true, I would see how Mochizuki’s strategy might have a nonzero chance of succeeding. … </em>
</p></blockquote>
<p/><p>
Thus what Ken and I conclude is that in order for a proof to be checkable <em>chunk by chunk</em>—not line by line—it needs to have:</p>
<ol>
<li>
A top-level decomposition into a relatively small number of components and stages—like legs in a sailing race—and <p/>
</li><li>
A demonstration of how the stages navigate around known barriers.
</li></ol>
<p>
Lack of a clear plan in the first already says the proof attempt cannot avoid being snagged on a barrier, as surely as natural laws prevent building a perpetual-motion machine.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Does this help in ascertaining what shape a proof that resolves the P versus NP problem must have?</p>
<p/></font></font></div>
    </content>
    <updated>2020-06-14T01:33:31Z</updated>
    <published>2020-06-14T01:33:31Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="P=NP"/>
    <category term="Proofs"/>
    <category term="Teaching"/>
    <category term="barriers"/>
    <category term="Leonardo da Vinci"/>
    <category term="perpetual motion"/>
    <category term="proof checking"/>
    <category term="shapes of proofs"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-06-21T03:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3504</id>
    <link href="https://agtb.wordpress.com/2020/06/14/submitting-papers-to-jet/" rel="alternate" type="text/html"/>
    <title>Suggestions for computer scientists submitting papers to JET</title>
    <summary>Guest post by Tilman Borgers (JET Lead Editor), Marciano Siniscalchi (JET Editor), and Jason Hartline (JET Associate Editor): The Journal of Economic Theory (JET) would like to encourage submissions from computer scientists. JET is a leading journal of the economic theory community, and has a broader readership among economists and covers a broader range of […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i>Guest post by <a href="http://www-personal.umich.edu/~tborgers/">Tilman Borgers</a> (JET Lead Editor), <a href="https://faculty.wcas.northwestern.edu/~msi661/">Marciano Siniscalchi</a> (JET Editor), and <a href="https://sites.northwestern.edu/hartline/">Jason Hartline</a> (JET Associate Editor):</i></p>
<p>The <a href="https://www.journals.elsevier.com/journal-of-economic-theory">Journal of Economic Theory (JET)</a> would like to encourage submissions from computer scientists. JET is a leading journal of the economic theory community, and has a broader readership among economists and covers a broader range of topics than other theory journals. JET is also the first field journal of the economic theory community, having been founded more than 50 years ago. Many publications in JET in those 50 years have changed not just the direction of economic theory, but also the direction of economics overall.</p>
<p>The convergence of research interests of computer scientists and economic theorists has been a remarkable development, and JET would like to do more to help facilitate the exchange of ideas across fields. Therefore, we compile here some suggestions for computer scientists who are interested in submitting their work to JET.</p>
<p>The basic standard for a publication in JET is that the paper should be original, make a substantial contribution, and be of interest to a broad group of readers, and this group should include economic theorists. Of course, editors make subjective, and fallible, judgments when assessing whether a paper meets these criteria. Typically, the substantive contribution is a contribution to economic theory, i.e. to our understanding of models of markets, strategic games, mechanisms, etc. Papers may be computer-science centric in its contributions, but then these contributions should be on a topic of interest to economists. For example, new algorithmic results related to game theory or mechanism design may be of interest to JET, if it is the editors’ judgment that these algorithms will be of interest to economists. On the other hand, results on more applied computational problems, such as faster algorithms for winner determination in auctions, or for clearing prediction markets, may be out of scope for JET.</p>
<p>In terms of style, successful JET submissions include an introduction that is accessible to a broad theory audience, and that explains the motivation for the work, overviews the main results, and explains some key intuitions. The introduction, or a separate literature review section, should precisely situate the work relative to the most closely related research. The main body of the paper should explain the model rigorously, and state the results precisely. Proofs which are not very long, and which provide insight, are typically included in the main body of the paper, whereas other proofs are moved to an appendix. It is often useful to paraphrase results in words after stating them formally, and to give explanations of intuitions as well as explanations of proof structures. We encourage authors to make their work as simple as is possible without losing the main message.</p>
<p>There is no length limit per se, but published papers have rarely more than 40 pages, including appendix and references, in print. We value conciseness, and focus on a main theme throughout the paper. Minor results can be left out. On the other hand, we do provide authors with the space needed to be precise and clear.</p>
<p>One general recommendation for computer science authors in preparing manuscripts for economics journals is to have an economist colleague look over the paper before submitting.  This is a good way to identify inaccurate assumptions about readers’ knowledge, or omitted relationships to the prior literature in economics.  Such advice can also help better motivate the results of the paper from an economic perspective.</p>
<p>To be publishable, if an earlier version of a paper was published as an extended abstract in conference proceedings, then the journal version must make additional contributions beyond the conference version.  This additional contribution may include important conceptual aspects of economic interest that were omitted from the original extended abstract, proofs that were omitted from the extended abstract, and additional results that did not appear in the extended abstract. Authors should explain the differences between the conference version and the journal version in a cover letter. Papers that have previously appeared as one or two page abstracts in a conference volume do not need to distinguish themselves.  Mentioning these appearances in a cover letter would useful, however.</p></div>
    </content>
    <updated>2020-06-14T00:53:10Z</updated>
    <published>2020-06-14T00:53:10Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Jason Hartline</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2020-06-21T03:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://grigory.github.io/blog/theory-jobs-2020</id>
    <link href="http://grigory.github.io/blog/theory-jobs-2020/" rel="alternate" type="text/html"/>
    <title xml:lang="en">Theory Jobs 2020</title>
    <content type="xhtml" xml:lang="en"><div xmlns="http://www.w3.org/1999/xhtml"><p>It’s been an unusually challenging year for both sides of the TCS job market with some unexpected obstacles and delays. Apologies for putting up the spreadsheet later than usual and congrats to both sides in each converged process!</p>

<p><a href="https://docs.google.com/spreadsheets/d/1kzq4xVyU1k5CUTrV0yjIgzqlcv8agZqN_jiVlbYJb9g/edit?usp=sharing">Here is a link</a> to a crowdsourced spreadsheet created to collect information about theory jobs this year. 
I put in a biased pseudorandom seed, please help populate and share!
Rules for the spreadsheet have been copied from previous years (with one substantial suggestion regarding senior hires based on one of my friends’ recommendation, see below) and all edits to the document are anonymized. Please, post a comment if you have any suggestions about the rules.</p>
<ul>
 <li>Separate sheets for faculty, industry and postdocs/visitors. </li>
 <li>People should be connected to theoretical computer science, broadly defined.</li>
 <li>Only add jobs that you are absolutely sure have been offered and accepted. This is not the place for speculation and rumors. <b>New:</b> Please, be particularly careful when adding senior hires (people who already have an academic or industrial job) -- end dates of their current positions might be still in the future. </li>
 <li>You are welcome to add yourself, or people your department has hired. </li>
</ul>


  <p><a href="http://grigory.github.io/blog/theory-jobs-2020/">Theory Jobs 2020</a> was originally published by Grigory Yaroslavtsev at <a href="http://grigory.github.io/blog">The Big Data Theory</a> on June 14, 2020.</p></div>
    </content>
    <updated>2020-06-14T00:00:00Z</updated>
    <published>2020-06-14T00:00:00Z</published>
    <author>
      <name>Grigory Yaroslavtsev</name>
      <email>grigory@grigory.us</email>
      <uri>http://grigory.github.io/blog</uri>
    </author>
    <source>
      <id>http://grigory.github.io/blog/</id>
      <author>
        <name>Grigory Yaroslavtsev</name>
        <email>grigory@grigory.us</email>
        <uri>http://grigory.github.io/blog/</uri>
      </author>
      <link href="http://grigory.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="http://grigory.github.io/blog" rel="alternate" type="text/html"/>
      <title xml:lang="en">The Big Data Theory</title>
      <updated>2020-06-15T04:23:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/12/phd-positions-at-international-max-planck-research-school-on-trustworthy-computing-apply-by-june-30-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/12/phd-positions-at-international-max-planck-research-school-on-trustworthy-computing-apply-by-june-30-2020/" rel="alternate" type="text/html"/>
    <title>PhD Positions at International Max Planck Research School on Trustworthy Computing (apply by June 30, 2020)</title>
    <summary>The International Max Planck Research School on Trustworthy Computing is a graduate program jointly run by the Max Planck Institutes for Informatics and Software Systems, Saarland University, and TU Kaiserslautern. It offers a fully funded PhD program that leads to a doctoral degree from one of the participating universities and is open to students with […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The International Max Planck Research School on Trustworthy Computing is a graduate program jointly run by the Max Planck Institutes for Informatics and Software Systems, Saarland University, and TU Kaiserslautern. It offers a fully funded PhD program that leads to a doctoral degree from one of the participating universities and is open to students with a degree in computer science or equivalent.</p>
<p>Website: <a href="https://www.imprs-trust.mpg.de">https://www.imprs-trust.mpg.de</a><br/>
Email: imprs@mpi-klsb.mpg.de</p></div>
    </content>
    <updated>2020-06-12T19:45:16Z</updated>
    <published>2020-06-12T19:45:16Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-21T03:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/06/12/logic-mentoring-workshop-2020/</id>
    <link href="https://cstheory-events.org/2020/06/12/logic-mentoring-workshop-2020/" rel="alternate" type="text/html"/>
    <title>Logic Mentoring Workshop 2020</title>
    <summary>July 6, 2020 Online http://lmw.mpi-sws.org/index.html The Logic Mentoring Workshop (LMW) will introduce young researchers to the technical and practical aspects of a career in logic research. It is targeted at students, from senior undergraduates to graduates, and will include talks and a panel session from leaders in the subject.</summary>
    <updated>2020-06-12T18:31:23Z</updated>
    <published>2020-06-12T18:31:23Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-06-21T03:21:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3496</id>
    <link href="https://agtb.wordpress.com/2020/06/12/virtual-ec-2020/" rel="alternate" type="text/html"/>
    <title>Virtual EC 2020</title>
    <summary>EC 2020 will be held virtually with events from June 15 to July 22 (details of virtual format).  Participation by members of related fields is strongly encouraged.   Since 1999 the ACM Special Interest Group on Economics and Computation (SIGecom) has sponsored the leading scientific conference on advances in theory, empirics, and applications at the interface […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>EC 2020 will be held virtually with events from June 15 to July 22 (<a href="http://ec20.sigecom.org/participation/covid/">details of virtual format</a>).  Participation by members of related fields is strongly encouraged.  </p>



<p>Since 1999 the ACM Special Interest Group on Economics and Computation (<a href="http://sigecom.org/">SIGecom</a>) has sponsored the leading scientific conference on advances in theory, empirics, and applications at the interface of economics and computation. The 21st ACM Conference on Economics and Computation (<a href="http://ec20.sigecom.org/">Virtual EC 2020</a>) will feature invited speakers, a highlight of papers from other conferences and journals, a technical program of submitted paper presentations and posters, workshops, and tutorials.  </p>



<p>Registration is mandatory (<a href="http://ec20.sigecom.org/participation/registration/">register here</a>) but complimentary with SIGecom membership of $10 ($5 for students).  Details on joining EC events will be emailed to registered participants.</p>



<p>An overview of the schedule:</p>



<p><strong>June 15 – 19:</strong> <a href="http://ec20.sigecom.org/program/mentoring-workshop">Mentoring Workshop</a> and <a href="http://ec20.sigecom.org/program/workshops-tutorials/">Live Tutorial Pre-recording Sessions</a>.<br/>
<strong>June 22 – July 3:</strong> <a href="http://ec20.sigecom.org/program/pre-recording/">Live EC Paper Pre-recording Plenary Sessions</a>.<br/>
<strong>July 13:</strong> <a href="http://ec20.sigecom.org/program/workshops-tutorials/">Tutorial Watch Parties</a>, Business Meeting, and <a href="http://ec20.sigecom.org/call-for-contributions-acm/posters/">Poster Session</a><br/>
<strong>July 14 – 16:</strong> <a href="http://ec20.sigecom.org/program/main/">EC Conference</a> (Paper Watch Parties, Paper Poster Sessions, and Plenaries).<br/>
<strong>July 17 – 22:</strong> <a href="http://ec20.sigecom.org/program/workshops-tutorials/">Workshops</a>.</p>



<p>Areas of interest include, but are not limited to:</p>



<p><strong>Design of economic mechanisms:</strong> algorithmic mechanism design; market design; matching; auctions; revenue maximization; pricing; fair division; computational social choice; privacy and ethics.</p>



<p><strong>Game theory:</strong> equilibrium computation; price of anarchy; learning in games.</p>



<p><strong>Information elicitation and generation:</strong> prediction markets; recommender, reputation and trust systems; social learning; data markets.</p>



<p><strong>Behavioral models:</strong> behavioral game theory and bounded rationality; decision theory; computational social science; agent-based modeling.</p>



<p><strong>Online systems:</strong> online advertising; electronic commerce; economics of cloud computing; social networks; crowdsourcing; ridesharing and transportation; labor markets; cryptocurrencies; industrial organization.</p>



<p><strong>Methodological developments:</strong> machine learning; econometrics; data mining.</p></div>
    </content>
    <updated>2020-06-12T16:09:54Z</updated>
    <published>2020-06-12T16:09:54Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Jason Hartline</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2020-06-21T03:20:40Z</updated>
    </source>
  </entry>
</feed>
