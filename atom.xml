<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2022-07-20T10:38:49Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.09439</id>
    <link href="http://arxiv.org/abs/2207.09439" rel="alternate" type="text/html"/>
    <title>All Paths Lead to Rome</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Kevin Goergen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fernau:Henning.html">Henning Fernau</a>, Esther Oest, Petra Wolf <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.09439">PDF</a><br/><b>Abstract: </b>All roads lead to Rome is the core idea of the puzzle game Roma. It is played
on an $n \times n$ grid consisting of quadratic cells. Those cells are grouped
into boxes of at most four neighboring cells and are either filled, or to be
filled, with arrows pointing in cardinal directions. The goal of the game is to
fill the empty cells with arrows such that each box contains at most one arrow
of each direction and regardless where we start, if we follow the arrows in the
cells, we will always end up in the special Roma-cell. In this work, we study
the computational complexity of the puzzle game Roma and show that completing a
Roma board according to the rules is an \NP-complete task, counting the number
of valid completions is #Ptime-complete, and determining the number of preset
arrows needed to make the instance \emph{uniquely} solvable is
$\Sigma_2^P$-complete. We further show that the problem of completing a given
Roma instance on an $n\times n$ board cannot be solved in time
$\mathcal{O}\left(2^{{o}(n)}\right)$ under ETH and give a matching dynamic
programming algorithm based on the idea of Catalan structures.
</p></div>
    </summary>
    <updated>2022-07-20T01:02:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.09435</id>
    <link href="http://arxiv.org/abs/2207.09435" rel="alternate" type="text/html"/>
    <title>Regret Minimization with Noisy Observations</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahdian:Mohammad.html">Mohammad Mahdian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mao:Jieming.html">Jieming Mao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Kangning.html">Kangning Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.09435">PDF</a><br/><b>Abstract: </b>In a typical optimization problem, the task is to pick one of a number of
options with the lowest cost or the highest value. In practice, these
cost/value quantities often come through processes such as measurement or
machine learning, which are noisy, with quantifiable noise distributions. To
take these noise distributions into account, one approach is to assume a prior
for the values, use it to build a posterior, and then apply standard stochastic
optimization to pick a solution. However, in many practical applications, such
prior distributions may not be available. In this paper, we study such
scenarios using a regret minimization model.
</p>
<p>In our model, the task is to pick the highest one out of $n$ values. The
values are unknown and chosen by an adversary, but can be observed through
noisy channels, where additive noises are stochastically drawn from known
distributions. The goal is to minimize the regret of our selection, defined as
the expected difference between the highest and the selected value on the
worst-case choices of values. We show that the na\"ive algorithm of picking the
highest observed value has regret arbitrarily worse than the optimum, even when
$n = 2$ and the noises are unbiased in expectation. On the other hand, we
propose an algorithm which gives a constant-approximation to the optimal regret
for any $n$. Our algorithm is conceptually simple, computationally efficient,
and requires only minimal knowledge of the noise distributions.
</p></div>
    </summary>
    <updated>2022-07-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.09397</id>
    <link href="http://arxiv.org/abs/2207.09397" rel="alternate" type="text/html"/>
    <title>Composition Theorems for Interactive Differential Privacy</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lyu:Xin.html">Xin Lyu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.09397">PDF</a><br/><b>Abstract: </b>An interactive mechanism is an algorithm that stores a data set and answers
adaptively chosen queries to it. The mechanism is called differentially
private, if any adversary cannot distinguish whether a specific individual is
in the data set by interacting with the mechanism. We study composition
properties of differential privacy in concurrent compositions. In this setting,
an adversary interacts with k interactive mechanisms in parallel and can
interleave its queries to the mechanisms arbitrarily. Previously, [Vadhan and
Wang, TCC 2021] proved an optimal concurrent composition theorem for
pure-differential privacy. We significantly generalize and extend their
results. Namely, we prove optimal parallel composition properties for several
major notions of differential privacy in the literature, including approximate
DP, R\'enyi DP, and zero-concentrated DP. Our results demonstrate that the
adversary gains no advantage by interleaving its queries to independently
running mechanisms. Hence, interactivity is a feature that differential privacy
grants us for free.
</p></div>
    </summary>
    <updated>2022-07-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.09391</id>
    <link href="http://arxiv.org/abs/2207.09391" rel="alternate" type="text/html"/>
    <title>A Near-Linear Time Sampler for the Ising Model</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Xiaoyu.html">Xiaoyu Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Xinyuan.html">Xinyuan Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.09391">PDF</a><br/><b>Abstract: </b>We give a near-linear time sampler for the Gibbs distribution of the
ferromagnetic Ising models with edge activities $\boldsymbol{\beta} &gt; 1$ and
external fields $\boldsymbol{\lambda}&lt;1$ (or symmetrically,
$\boldsymbol{\lambda}&gt;1$) on general graphs with bounded or unbounded maximum
degree.
</p>
<p>Our algorithm is based on the field dynamics given in [CLV21]. We prove the
correctness and efficiency of our algorithm by establishing spectral
independence of distribution of the random cluster model and the rapid mixing
of Glauber dynamics on the random cluster model in a low-temperature regime,
which may be of independent interest.
</p></div>
    </summary>
    <updated>2022-07-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.09354</id>
    <link href="http://arxiv.org/abs/2207.09354" rel="alternate" type="text/html"/>
    <title>On Regularity Lemma and Barriers in Streaming and Dynamic Matching</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Assadi:Sepehr.html">Sepehr Assadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Behnezhad:Soheil.html">Soheil Behnezhad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khanna:Sanjeev.html">Sanjeev Khanna</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Huan.html">Huan Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.09354">PDF</a><br/><b>Abstract: </b>We present a new approach for finding matchings in dense graphs by building
on Szemer\'edi's celebrated Regularity Lemma. This allows us to obtain
non-trivial albeit slight improvements over longstanding bounds for matchings
in streaming and dynamic graphs. In particular, we establish the following
results for $n$-vertex graphs:
</p>
<p>* A deterministic single-pass streaming algorithm that finds
</p>
<p>a $(1-o(1))$-approximate matching in $o(n^2)$ bits of space. This constitutes
the first single-pass algorithm for this problem in sublinear space that
improves over the $\frac{1}{2}$-approximation of the greedy algorithm.
</p>
<p>* A randomized fully dynamic algorithm that with high probability maintains a
$(1-o(1))$-approximate matching in $o(n)$ worst-case update time per each edge
insertion or deletion. The algorithm works even against an adaptive adversary.
This is the first $o(n)$ update-time dynamic algorithm with approximation
guarantee arbitrarily close to one.
</p>
<p>Given the use of regularity lemma, the improvement obtained by our algorithms
over trivial bounds is only by some $(\log^*{n})^{\Theta(1)}$ factor.
Nevertheless, in each case, they show that the ``right'' answer to the problem
is not what is dictated by the previous bounds.
</p>
<p>Finally, in the streaming model, we also present a randomized
$(1-o(1))$-approximation algorithm whose space can be upper bounded by the
density of certain Ruzsa-Szemer\'edi (RS) graphs. While RS graphs by now have
been used extensively to prove streaming lower bounds, ours is the first to use
them as an upper bound tool for designing improved streaming algorithms.
</p></div>
    </summary>
    <updated>2022-07-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.09262</id>
    <link href="http://arxiv.org/abs/2207.09262" rel="alternate" type="text/html"/>
    <title>Efficient Constructions for the Gy\H{o}ri-Lov\'{a}sz Theorem on Almost Chordal Graphs</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Casel:Katrin.html">Katrin Casel</a>, Tobias Friedrich, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Issac:Davis.html">Davis Issac</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Niklanovits:Aikaterini.html">Aikaterini Niklanovits</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zeif:Ziena.html">Ziena Zeif</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.09262">PDF</a><br/><b>Abstract: </b>In the 1970s, Gy\H{o}ri and Lov\'{a}sz showed that for a $k$-connected
$n$-vertex graph, a given set of terminal vertices $t_1, \dots, t_k$ and
natural numbers $n_1, \dots, n_k$ satisfying $\sum_{i=1}^{k} n_i = n$, a
connected vertex partition $S_1, \dots, S_k$ satisfying $t_i \in S_i$ and
$|S_i| = n_i$ exists. However, polynomial algorithms to actually compute such
partitions are known so far only for $k \leq 4$. This motivates us to take a
new approach and constrain this problem to particular graph classes instead of
restricting the values of $k$. More precisely, we consider $k$-connected
chordal graphs and a broader class of graphs related to them. For the first, we
give an algorithm with $O(n^2)$ running time that solves the problem exactly,
and for the second, an algorithm with $O(n^4)$ running time that deviates on at
most one vertex from the given required vertex partition sizes.
</p></div>
    </summary>
    <updated>2022-07-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.09201</id>
    <link href="http://arxiv.org/abs/2207.09201" rel="alternate" type="text/html"/>
    <title>Subsequences in Bounded Ranges: Matching and Analysis Problems</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kosche:Maria.html">Maria Kosche</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Ko=szlig=:Tore.html">Tore Koß</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manea:Florin.html">Florin Manea</a>, Viktoriya Pak <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.09201">PDF</a><br/><b>Abstract: </b>In this paper, we consider a variant of the classical algorithmic problem of
checking whether a given word $v$ is a subsequence of another word $w$. More
precisely, we consider the problem of deciding, given a number $p$ (defining a
range-bound) and two words $v$ and $w$, whether there exists a factor
$w[i:i+p-1]$ (or, in other words, a range of length $p$) of $w$ having $v$ as
subsequence (i.\,e., $v$ occurs as a subsequence in the bounded range
$w[i:i+p-1]$). We give matching upper and lower quadratic bounds for the time
complexity of this problem. Further, we consider a series of algorithmic
problems in this setting, in which, for given integers $k$, $p$ and a word $w$,
we analyse the set $p$-Subseq$_{k}(w)$ of all words of length $k$ which occur
as subsequence of some factor of length $p$ of $w$. Among these, we consider
the $k$-universality problem, the $k$-equivalence problem, as well as problems
related to absent subsequences. Surprisingly, unlike the case of the classical
model of subsequences in words where such problems have efficient solutions in
general, we show that most of these problems become intractable in the new
setting when subsequences in bounded ranges are considered. Finally, we provide
an example of how some of our results can be applied to subsequence matching
problems for circular words.
</p></div>
    </summary>
    <updated>2022-07-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.09118</id>
    <link href="http://arxiv.org/abs/2207.09118" rel="alternate" type="text/html"/>
    <title>Solving the unit-load pre-marshalling problem in block stacking storage systems with multiple access directions</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jakob Pfrommer, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meyer:Anne.html">Anne Meyer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tierney:Kevin.html">Kevin Tierney</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.09118">PDF</a><br/><b>Abstract: </b>Block stacking storage systems are highly adaptable warehouse systems with
low investment costs. With multiple, deep lanes they can achieve high storage
densities, but accessing some unit loads can be time-consuming. The unit-load
pre-marshalling problem sorts the unit loads in a block stacking storage system
in off-peak time periods to prepare for upcoming orders. The goal is to find a
minimum number of unit-load moves needed to sequence a storage bay in ascending
order based on the retrieval priority group of each unit load. In this paper,
we present two solution approaches for determining the minimum number of
unit-load moves. We show that for storage bays with one access direction, it is
possible to adapt existing, optimal tree search procedures and lower bound
heuristics from the container pre-marshalling problem. For multiple access
directions, we develop a novel, two-step solution approach based on a network
flow model and an A* algorithm with an adapted lower bound that is applicable
in all scenarios. We further analyze the performance of the presented solutions
in computational experiments for randomly generated problem instances and show
that multiple access directions greatly reduce both the total access time of
unit loads and the required sorting effort.
</p></div>
    </summary>
    <updated>2022-07-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.09102</id>
    <link href="http://arxiv.org/abs/2207.09102" rel="alternate" type="text/html"/>
    <title>Identity Testing for High-Dimensional Distributions via Entropy Tensorization</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blanca:Antonio.html">Antonio Blanca</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Zongchen.html">Zongchen Chen</a>, Daniel Štefankovič, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vigoda:Eric.html">Eric Vigoda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.09102">PDF</a><br/><b>Abstract: </b>We present improved algorithms and matching statistical and computational
lower bounds for the problem of identity testing $n$-dimensional distributions.
In the identity testing problem, we are given as input an explicit distribution
$\mu$, an $\varepsilon&gt;0$, and access to a sampling oracle for a hidden
distribution $\pi$. The goal is to distinguish whether the two distributions
$\mu$ and $\pi$ are identical or are at least $\varepsilon$-far apart. When
there is only access to full samples from the hidden distribution $\pi$, it is
known that exponentially many samples may be needed, and hence previous works
have studied identity testing with additional access to various conditional
sampling oracles. We consider here a significantly weaker conditional sampling
oracle, called the Coordinate Oracle, and provide a fairly complete
computational and statistical characterization of the identity testing problem
in this new model.
</p>
<p>We prove that if an analytic property known as approximate tensorization of
entropy holds for the visible distribution $\mu$, then there is an efficient
identity testing algorithm for any hidden $\pi$ that uses
$\tilde{O}(n/\varepsilon)$ queries to the Coordinate Oracle. Approximate
tensorization of entropy is a classical tool for proving optimal mixing time
bounds of Markov chains for high-dimensional distributions, and recently has
been established for many families of distributions via spectral independence.
We complement our algorithmic result for identity testing with a matching
$\Omega(n/\varepsilon)$ statistical lower bound for the number of queries under
the Coordinate Oracle. We also prove a computational phase transition: for
sparse antiferromagnetic Ising models over $\{+1,-1\}^n$, in the regime where
approximate tensorization of entropy fails, there is no efficient identity
testing algorithm unless RP=NP.
</p></div>
    </summary>
    <updated>2022-07-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.09063</id>
    <link href="http://arxiv.org/abs/2207.09063" rel="alternate" type="text/html"/>
    <title>Algorithms for the Euclidean Bipartite Edge Cover Problem</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Castro:Rodrigo_A=.html">Rodrigo A. Castro</a>, José M. Díaz-Báñez, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heredia:Marco_A=.html">Marco A. Heredia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Urrutia:Jorge.html">Jorge Urrutia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Ventura:Inmaculada.html">Inmaculada Ventura</a>, Francisco J. Zaragoza Departamento de Sistemas, Universidad Autónoma Metropolitana - Azcapotzalco, Mexico City, Mexico, Departamento de Matemática Aplicada II, Universidad de Sevilla, Seville, Spain, Instituto de Matemáticas, Universidad Nacional Autónoma de México, Mexico City, Mexico) <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.09063">PDF</a><br/><b>Abstract: </b>Given a graph $G=(V,E)$ with costs on its edges, the minimum-cost edge cover
problem consists of finding a subset of $E$ covering all vertices in $V$ at
minimum cost. If $G$ is bipartite, this problem can be solved in time
$O(|V|^3)$ via a well-known reduction to a maximum-cost matching problem on
$G$. If in addition $V$ is a set of points on the Euclidean line, Collanino et
al. showed that the problem can be solved in time $O(|V| \log |V|)$ and asked
whether it can be solved in time $o(|V|^3)$ if $V$ is a set of points on the
Euclidean plane. We answer this in the affirmative, giving an $O(|V|^{2.5} \log
|V|)$ algorithm based on the Hungarian method using weighted Voronoi diagrams.
We also propose some 2-approximation algorithms and give experimental results
of our implementations.
</p></div>
    </summary>
    <updated>2022-07-20T00:58:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.09035</id>
    <link href="http://arxiv.org/abs/2207.09035" rel="alternate" type="text/html"/>
    <title>PackCache: An Online Cost-driven Data Caching Algorithm in the Cloud</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Jiashu.html">Jiashu Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dai:Hao.html">Hao Dai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yang.html">Yang Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Yong.html">Yong Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Dong.html">Dong Huang</a>, Chengzhong Xu <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.09035">PDF</a><br/><b>Abstract: </b>In this paper, we study a data caching problem in the cloud environment,
where multiple frequently co-utilised data items could be packed as a single
item being transferred to serve a sequence of data requests dynamically with
reduced cost. To this end, we propose an online algorithm with respect to a
homogeneous cost model, called PackCache, that can leverage the FP-Tree
technique to mine those frequently co-utilised data items for packing whereby
the incoming requests could be cost-effectively served online by exploiting the
concept of anticipatory caching. We show the algorithm is 2\alpha competitive,
reaching the lower bound of the competitive ratio for any deterministic online
algorithm on the studied caching problem, and also time and space efficient to
serve the requests. Finally, we evaluate the performance of the algorithm via
experimental studies to show its actual cost-effectiveness and scalability.
</p></div>
    </summary>
    <updated>2022-07-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.09002</id>
    <link href="http://arxiv.org/abs/2207.09002" rel="alternate" type="text/html"/>
    <title>Accelerating Frank-Wolfe Algorithm using Low-Dimensional and Adaptive Data Structures</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Zhao Song, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Zhaozhuo.html">Zhaozhuo Xu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Yuanyuan.html">Yuanyuan Yang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Lichen.html">Lichen Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.09002">PDF</a><br/><b>Abstract: </b>In this paper, we study the problem of speeding up a type of optimization
algorithms called Frank-Wolfe, a conditional gradient method. We develop and
employ two novel inner product search data structures, improving the prior
fastest algorithm in [Shrivastava, Song and Xu, NeurIPS 2021].
</p>
<p>* The first data structure uses low-dimensional random projection to reduce
the problem to a lower dimension, then uses efficient inner product data
structure. It has preprocessing time $\tilde O(nd^{\omega-1}+dn^{1+o(1)})$ and
per iteration cost $\tilde O(d+n^\rho)$ for small constant $\rho$.
</p>
<p>* The second data structure leverages the recent development in adaptive
inner product search data structure that can output estimations to all inner
products. It has preprocessing time $\tilde O(nd)$ and per iteration cost
$\tilde O(d+n)$.
</p>
<p>The first algorithm improves the state-of-the-art (with preprocessing time
$\tilde O(d^2n^{1+o(1)})$ and per iteration cost $\tilde O(dn^\rho)$) in all
cases, while the second one provides an even faster preprocessing time and is
suitable when the number of iterations is small.
</p></div>
    </summary>
    <updated>2022-07-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.08965</id>
    <link href="http://arxiv.org/abs/2207.08965" rel="alternate" type="text/html"/>
    <title>Bernoulli Factories for Flow-Based Polytopes</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Niazadeh:Rad.html">Rad Niazadeh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leme:Renato_Paes.html">Renato Paes Leme</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schneider:Jon.html">Jon Schneider</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.08965">PDF</a><br/><b>Abstract: </b>We construct explicit combinatorial Bernoulli factories for the class of
\emph{flow-based polytopes}; integral 0/1-polytopes defined by a set of network
flow constraints. This generalizes the results of Niazadeh et al. (who
constructed an explicit factory for the specific case of bipartite perfect
matchings) and provides novel exact sampling procedures for sampling paths,
circulations, and $k$-flows. In the process, we uncover new connections to
algebraic combinatorics.
</p></div>
    </summary>
    <updated>2022-07-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.08955</id>
    <link href="http://arxiv.org/abs/2207.08955" rel="alternate" type="text/html"/>
    <title>Recursive McCormick Linearization of Multilinear Programs</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Arvind U Raghunathan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cardonha:Carlos.html">Carlos Cardonha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bergman:David.html">David Bergman</a>, Carlos J Nohra <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.08955">PDF</a><br/><b>Abstract: </b>Linear programming (LP) relaxations are widely employed in exact solution
methods for multilinear programs (MLP). One example is the family of Recursive
McCormick Linearization (RML) strategies, where bilinear products are
substituted for artificial variables, which deliver a relaxation of the
original problem when introduced together with concave and convex envelopes. In
this article, we introduce the first systematic approach for identifying RMLs,
in which we focus on the identification of linear relaxation with a small
number of artificial variables and with strong LP bounds. We present a novel
mechanism for representing all the possible RMLs, which we use to design an
exact mixed-integer programming (MIP) formulation for the identification of
minimum-size RMLs; we show that this problem is NP-hard in general, whereas a
special case is fixed-parameter tractable. Moreover, we explore structural
properties of our formulation to derive an exact MIP model that identifies RMLs
of a given size with the best possible relaxation bound is optimal. Our
numerical results on a collection of benchmarks indicate that our algorithms
outperform the RML strategy implemented in state-of-the-art global optimization
solvers.
</p></div>
    </summary>
    <updated>2022-07-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.08913</id>
    <link href="http://arxiv.org/abs/2207.08913" rel="alternate" type="text/html"/>
    <title>Robust Factorizations and Colorings of Tensor Graphs</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brakensiek:Joshua.html">Joshua Brakensiek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Davies:Sami.html">Sami Davies</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.08913">PDF</a><br/><b>Abstract: </b>Since the seminal result of Karger, Motwani, and Sudan, algorithms for
approximate 3-coloring have primarily centered around SDP-based rounding.
However, it is likely that important combinatorial or algebraic insights are
needed in order to break the $n^{o(1)}$ threshold. One way to develop new
understanding in graph coloring is to study special subclasses of graphs. For
instance, Blum studied the 3-coloring of random graphs, and Arora and Ge
studied the 3-coloring of graphs with low threshold-rank.
</p>
<p>In this work, we study graphs which arise from a tensor product, which appear
to be novel instances of the 3-coloring problem. We consider graphs of the form
$H = (V,E)$ with $V =V( K_3 \times G)$ and $E = E(K_3 \times G) \setminus E'$,
where $E' \subseteq E(K_3 \times G)$ is any edge set such that no vertex has
more than an $\epsilon$ fraction of its edges in $E'$. We show that one can
construct $\widetilde{H} = K_3 \times \widetilde{G}$ with $V(\widetilde{H}) =
V(H)$ that is close to $H$. For arbitrary $G$, $\widetilde{H}$ satisfies $|E(H)
\Delta E(\widetilde{H})| \leq O(\epsilon|E(H)|)$. Additionally when $G$ is a
mild expander, we provide a 3-coloring for $H$ in polynomial time. These
results partially generalize an exact tensor factorization algorithm of Imrich.
On the other hand, without any assumptions on $G$, we show that it is NP-hard
to 3-color $H$.
</p></div>
    </summary>
    <updated>2022-07-20T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-20T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.08120</id>
    <link href="http://arxiv.org/abs/2207.08120" rel="alternate" type="text/html"/>
    <title>On the Practical Power of Automata in Pattern Matching</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Amir:Ora.html">Ora Amir</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Amir:Amihood.html">Amihood Amir</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fraenkel:Aviezri.html">Aviezri Fraenkel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sarne:David.html">David Sarne</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.08120">PDF</a><br/><b>Abstract: </b>The classical pattern matching paradigm is that of seeking occurrences of one
string - the pattern, in another - the text, where both strings are drawn from
an alphabet set $\Sigma$. Assuming the text length is $n$ and the pattern
length is $m$, this problem can naively be solved in time $O(nm)$. In Knuth,
Morris and Pratt's seminal paper of 1977, an automaton, was developed that
allows solving this problem in time $O(n)$ for any alphabet.
</p>
<p>This automaton, which we will refer to as the {\em KMP-automaton}, has proven
useful in solving many other problems. A notable example is the {\em
parameterized pattern matching} model. In this model, a consistent renaming of
symbols from $\Sigma$ is allowed in a match. The parameterized matching
paradigm has proven useful in problems in software engineering, computer
vision, and other applications.
</p>
<p>It has long been suspected that for texts where the symbols are uniformly
random, the naive algorithm will perform as well as the KMP algorithm. In this
paper we examine the practical efficiency of the KMP algorithm vs. the naive
algorithm on a randomly generated text. We analyse the time under various
parameters, such as alphabet size, pattern length, and the distribution of
pattern occurrences in the text. We do this for both the original exact
matching problem and parameterized matching. While the folklore wisdom is
vindicated by these findings for the exact matching case, surprisingly, the KMP
algorithm works significantly faster than the naive in the parameterized
matching case.
</p>
<p>We check this hypothesis for DNA texts, and observe a similar behaviour as in
the random text. We also show a very structured case where the automaton is
much more efficient.
</p></div>
    </summary>
    <updated>2022-07-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.08075</id>
    <link href="http://arxiv.org/abs/2207.08075" rel="alternate" type="text/html"/>
    <title>Streaming Algorithms with Large Approximation Factors</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Yi.html">Yi Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Honghao.html">Honghao Lin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Yuheng.html">Yuheng Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.08075">PDF</a><br/><b>Abstract: </b>We initiate a broad study of classical problems in the streaming model with
insertions and deletions in the setting where we allow the approximation factor
$\alpha$ to be much larger than $1$. Such algorithms can use significantly less
memory than the usual setting for which $\alpha = 1+\epsilon$ for an $\epsilon
\in (0,1)$. We study large approximations for a number of problems in sketching
and streaming and the following are some of our results.
</p>
<p>For the $\ell_p$ norm/quasinorm $\|x\|_p$ of an $n$-dimensional vector $x$,
$0 &lt; p \le 2$, we show that obtaining a $\poly(n)$-approximation requires the
same amount of memory as obtaining an $O(1)$-approximation for any $M =
n^{\Theta(1)}$.
</p>
<p>For estimating the $\ell_p$ norm, $p &gt; 2$, we show an upper bound of
$O(n^{1-2/p} (\log n \allowbreak \log M)/\alpha^{2})$ bits for an
$\alpha$-approximation, and give a matching lower bound, for almost the full
range of $\alpha \geq 1$ for linear sketches.
</p>
<p>For the $\ell_2$-heavy hitters problem, we show that the known lower bound of
$\Omega(k \log n\log M)$ bits for identifying $(1/k)$-heavy hitters holds even
if we are allowed to output items that are $1/(\alpha k)$-heavy, for almost the
full range of $\alpha$, provided the algorithm succeeds with probability
$1-O(1/n)$. We also obtain a lower bound for linear sketches that is tight even
for constant probability algorithms.
</p>
<p>For estimating the number $\ell_0$ of distinct elements, we give an
$n^{1/t}$-approximation algorithm using $O(t\log \log M)$ bits of space, as
well as a lower bound of $\Omega(t)$ bits, both excluding the storage of random
bits.
</p></div>
    </summary>
    <updated>2022-07-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.08015</id>
    <link href="http://arxiv.org/abs/2207.08015" rel="alternate" type="text/html"/>
    <title>Collaborative Best Arm Identification with Limited Communication on Non-IID Data</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karpov:Nikolai.html">Nikolai Karpov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Qin.html">Qin Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.08015">PDF</a><br/><b>Abstract: </b>In this paper, we study the tradeoffs between time-speedup and the number of
communication rounds of the learning process in the collaborative learning
model on non-IID data, where multiple agents interact with possibly different
environments and they want to learn an objective in the aggregated environment.
We use a basic problem in bandit theory called best arm identification in
multi-armed bandits as a vehicle to deliver the following conceptual message:
</p>
<p>Collaborative learning on non-IID data is provably more difficult than that
on IID data.
</p>
<p>In particular, we show the following:
</p>
<p>a) The speedup in the non-IID data setting can be less than $1$ (that is, a
slowdown). When the number of rounds $R = O(1)$, we will need at least a
polynomial number of agents (in terms of the number of arms) to achieve a
speedup greater than $1$. This is in sharp contrast with the IID data setting,
in which the speedup is always at least $1$ when $R \ge 2$ regardless of number
of agents.
</p>
<p>b) Adaptivity in the learning process cannot help much in the non-IID data
setting. This is in sharp contrast with the IID data setting, in which to
achieve the same speedup, the best non-adaptive algorithm requires a
significantly larger number of rounds than the best adaptive algorithm.
</p>
<p>In the technique space, we have further developed the generalized round
elimination technique introduced in <a href="http://export.arxiv.org/abs/1904.03293">arXiv:1904.03293</a>. We show that implicit
representations of distribution classes can be very useful when working with
complex hard input distributions and proving lower bounds directly for adaptive
algorithms.
</p></div>
    </summary>
    <updated>2022-07-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.07983</id>
    <link href="http://arxiv.org/abs/2207.07983" rel="alternate" type="text/html"/>
    <title>New and improved approximation algorithms for Steiner Tree Augmentation Problems</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>R. Ravi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Weizhong.html">Weizhong Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zlatin:Michael.html">Michael Zlatin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.07983">PDF</a><br/><b>Abstract: </b>In the Steiner Tree Augmentation Problem (STAP), we are given a graph $G =
(V,E)$, a set of terminals $R \subseteq V$, and a Steiner tree $T$ spanning
$R$. The edges $L := E \setminus E(T)$ are called links and have non-negative
costs. The goal is to augment $T$ by adding a minimum cost set of links, so
that there are 2 edge-disjoint paths between each pair of vertices in $R$. This
problem is a special case of the Survivable Network Design Problem which can be
approximated to within a factor of 2 using iterative rounding \cite{J2001}.
</p>
<p>We give the first polynomial time algorithm for STAP with approximation ratio
better than 2. In particular we achieve a ratio of $(1+ \ln 2 + \varepsilon)
\approx 1.69 + \varepsilon$. To do this, we use the Local Greedy approach of
\cite{TZ2021} for the Tree Augmentation Problem and generalize their main
decomposition theorem from links (of size two) to hyper-links.
</p>
<p>We also consider the Node-Weighted Steiner Tree Augmentation Problem
(NW-STAP) in which the non-terminal nodes have non-negative costs. We seek a
cheapest subset $S \subseteq V \setminus R$ so that $G[R \cup S]$ is
2-edge-connected. We provide a $O(\log^2 (|R|))$-approximation algorithm for
NW-STAP. To do this, we use a greedy algorithm leveraging the spider
decomposition of optimal solutions.
</p></div>
    </summary>
    <updated>2022-07-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.07974</id>
    <link href="http://arxiv.org/abs/2207.07974" rel="alternate" type="text/html"/>
    <title>Online Prediction in Sub-linear Space</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Binghui.html">Binghui Peng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Fred.html">Fred Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.07974">PDF</a><br/><b>Abstract: </b>We provide the first sub-linear space and sub-linear regret algorithm for
online learning with expert advice (against an oblivious adversary), addressing
an open question raised recently by Srinivas, Woodruff, Xu and Zhou (STOC
2022). We also demonstrate a separation between oblivious and (strong) adaptive
adversaries by proving a linear memory lower bound of any sub-linear regret
algorithm against an adaptive adversary. Our algorithm is based on a novel pool
selection procedure that bypasses the traditional wisdom of leader selection
for online learning, and a generic reduction that transforms any weakly
sub-linear regret $o(T)$ algorithm to $T^{1-\alpha}$ regret algorithm, which
may be of independent interest. Our lower bound utilizes the connection of
no-regret learning and equilibrium computation in zero-sum games, leading to a
proof of a strong lower bound against an adaptive adversary.
</p></div>
    </summary>
    <updated>2022-07-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.07949</id>
    <link href="http://arxiv.org/abs/2207.07949" rel="alternate" type="text/html"/>
    <title>A Nearly Tight Analysis of Greedy k-means++</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grunau:Christoph.html">Christoph Grunau</a>, Ahmet Alper Özüdoğru, Václav Rozhoň, Jakub Tětek <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.07949">PDF</a><br/><b>Abstract: </b>The famous $k$-means++ algorithm of Arthur and Vassilvitskii [SODA 2007] is
the most popular way of solving the $k$-means problem in practice. The
algorithm is very simple: it samples the first center uniformly at random and
each of the following $k-1$ centers is then always sampled proportional to its
squared distance to the closest center so far. Afterward, Lloyd's iterative
algorithm is run. The $k$-means++ algorithm is known to return a $\Theta(\log
k)$ approximate solution in expectation.
</p>
<p>In their seminal work, Arthur and Vassilvitskii [SODA 2007] asked about the
guarantees for its following \emph{greedy} variant: in every step, we sample
$\ell$ candidate centers instead of one and then pick the one that minimizes
the new cost. This is also how $k$-means++ is implemented in e.g. the popular
Scikit-learn library [Pedregosa et al.; JMLR 2011].
</p>
<p>We present nearly matching lower and upper bounds for the greedy $k$-means++:
We prove that it is an $O(\ell^3 \log^3 k)$-approximation algorithm. On the
other hand, we prove a lower bound of $\Omega(\ell^3 \log^3 k / \log^2(\ell\log
k))$. Previously, only an $\Omega(\ell \log k)$ lower bound was known
[Bhattacharya, Eube, R\"oglin, Schmidt; ESA 2020] and there was no known upper
bound.
</p></div>
    </summary>
    <updated>2022-07-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.07839</id>
    <link href="http://arxiv.org/abs/2207.07839" rel="alternate" type="text/html"/>
    <title>On Non-Negative Quadratic Programming in Geometric Optimization</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheng:Siu=Wing.html">Siu-Wing Cheng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wong:Man_Ting.html">Man Ting Wong</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.07839">PDF</a><br/><b>Abstract: </b>We present experimental and theoretical results on a method that applies a
numerical solver iteratively to solve several non-negative quadratic
programming problems in geometric optimization. The method gains efficiency by
exploiting the potential sparsity of the intermediate solutions. We implemented
the method to call quadprog of MATLAB iteratively. In comparison with a single
call of quadprog, we obtain a 10-fold speedup on two proximity graph problems
in $\mathbb{R}^d$ on some public data sets, a 10-fold speedup on the minimum
enclosing ball problem on random points in a unit cube in $\mathbb{R}^d$, and a
5-fold speedup on the polytope distance problem on random points from a cube in
$\mathbb{R}^d$ when the input size is significantly larger than the dimension;
we also obtain a 2-fold or more speedup on deblurring some gray-scale space and
thermal images via non-negative least square. We compare with two minimum
enclosing ball software by G\"{a}rtner and Fischer et al.; for 1000 nearly
cospherical points or random points in a unit cube, the iterative method
overtakes the software by G\"{a}rtner at 20 dimensions and the software by
Fischer et al. at 170 dimensions. In the image deblurring experiments, the
iterative method compares favorably with other software that can solve
non-negative least square, including FISTA with backtracking, SBB, FNNLS, and
lsqnonneg of MATLAB. We analyze theoretically the number of iterations taken by
the iterative scheme to reduce the gap between the current solution value and
the optimum by a factor $e$. Under certain assumptions, we prove a bound
proportional to the square root of the number of variables.
</p></div>
    </summary>
    <updated>2022-07-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.07822</id>
    <link href="http://arxiv.org/abs/2207.07822" rel="alternate" type="text/html"/>
    <title>Adaptive Sketches for Robust Regression with Importance Sampling</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahabadi:Sepideh.html">Sepideh Mahabadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Samson.html">Samson Zhou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.07822">PDF</a><br/><b>Abstract: </b>We introduce data structures for solving robust regression through stochastic
gradient descent (SGD) by sampling gradients with probability proportional to
their norm, i.e., importance sampling. Although SGD is widely used for large
scale machine learning, it is well-known for possibly experiencing slow
convergence rates due to the high variance from uniform sampling. On the other
hand, importance sampling can significantly decrease the variance but is
usually difficult to implement because computing the sampling probabilities
requires additional passes over the data, in which case standard gradient
descent (GD) could be used instead. In this paper, we introduce an algorithm
that approximately samples $T$ gradients of dimension $d$ from nearly the
optimal importance sampling distribution for a robust regression problem over
$n$ rows. Thus our algorithm effectively runs $T$ steps of SGD with importance
sampling while using sublinear space and just making a single pass over the
data. Our techniques also extend to performing importance sampling for
second-order optimization.
</p></div>
    </summary>
    <updated>2022-07-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.07809</id>
    <link href="http://arxiv.org/abs/2207.07809" rel="alternate" type="text/html"/>
    <title>Curve Simplification and Clustering under Fr\'echet Distance</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheng:Siu=Wing.html">Siu-Wing Cheng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Haoqiang.html">Haoqiang Huang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.07809">PDF</a><br/><b>Abstract: </b>We present new approximation results on curve simplification and clustering
under Fr\'echet distance. Let $T = \{\tau_i : i \in [n] \}$ be polygonal curves
in $R^d$ of $m$ vertices each. Let $l$ be any integer from $[m]$. We study a
generalized curve simplification problem: given error bounds $\delta_i &gt; 0$ for
$i \in [n]$, find a curve $\sigma$ of at most $l$ vertices such that
$d_F(\sigma,\tau_i) \le \delta_i$ for $i \in [n]$. We present an algorithm that
returns a null output or a curve $\sigma$ of at most $l$ vertices such that
$d_F(\sigma,\tau_i) \le \delta_i + \epsilon\delta_{\max}$ for $i \in [n]$,
where $\delta_{\max} = \max_{i \in [n]} \delta_i$. If the output is null, there
is no curve of at most $l$ vertices within a Fr\'echet distance of $\delta_i$
from $\tau_i$ for $i \in [n]$. The running time is $\tilde{O}\bigl(n^{O(l)}
m^{O(l^2)} (dl/\epsilon)^{O(dl)}\bigr)$. This algorithm yields the first
polynomial-time bicriteria approximation scheme to simplify a curve $\tau$ to
another curve $\sigma$, where the vertices of $\sigma$ can be anywhere in
$R^d$, so that $d_F(\sigma,\tau) \le (1+\epsilon)\delta$ and $|\sigma| \le
(1+\alpha) \min\{|c| : d_F(c,\tau) \le \delta\}$ for any given $\delta &gt; 0$ and
any fixed $\alpha, \epsilon \in (0,1)$. The running time is
$\tilde{O}\bigl(m^{O(1/\alpha)} (d/(\alpha\epsilon))^{O(d/\alpha)}\bigr)$.
</p>
<p>By combining our technique with some previous results in the literature, we
obtain an approximation algorithm for $(k,l)$-median clustering. Given $T$, it
computes a set $\Sigma$ of $k$ curves, each of $l$ vertices, such that $\sum_{i
\in [n]} \min_{\sigma \in \Sigma} d_F(\sigma,\tau_i)$ is within a factor
$1+\epsilon$ of the optimum with probability at least $1-\mu$ for any given
$\mu, \epsilon \in (0,1)$. The running time is $\tilde{O}\bigl(n m^{O(kl^2)}
\mu^{-O(kl)} (dkl/\epsilon)^{O((dkl/\epsilon)\log(1/\mu))}\bigr)$.
</p></div>
    </summary>
    <updated>2022-07-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.07708</id>
    <link href="http://arxiv.org/abs/2207.07708" rel="alternate" type="text/html"/>
    <title>Approximating Highly Inapproximable Problems on Graphs of Bounded Twin-Width</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berg=eacute=:Pierre.html">Pierre Bergé</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonnet:=Eacute=douard.html">Édouard Bonnet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/D=eacute=pr=eacute=s:Hugues.html">Hugues Déprés</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Watrigant:R=eacute=mi.html">Rémi Watrigant</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.07708">PDF</a><br/><b>Abstract: </b>For any $\varepsilon &gt; 0$, we give a polynomial-time
$n^\varepsilon$-approximation algorithm for Max Independent Set in graphs of
bounded twin-width given with an $O(1)$-sequence. This result is derived from
the following time-approximation trade-off: We establish an
$O(1)^{2^q-1}$-approximation algorithm running in time $\exp(O_q(n^{2^{-q}}))$,
for every integer $q \geqslant 0$. Guided by the same framework, we obtain
similar approximation algorithms for Min Coloring and Max Induced Matching. In
general graphs, all these problems are known to be highly inapproximable: for
any $\varepsilon &gt; 0$, a polynomial-time $n^{1-\varepsilon}$-approximation for
any of them would imply that P$=$NP [Hastad, FOCS '96; Zuckerman, ToC '07;
Chalermsook et al., SODA '13]. We generalize the algorithms for Max Independent
Set and Max Induced Matching to the independent (induced) packing of any fixed
connected graph $H$. In contrast, we show that such approximation guarantees on
graphs of bounded twin-width given with an $O(1)$-sequence are very unlikely
for Min Independent Dominating Set, and somewhat unlikely for Longest Path and
Longest Induced Path. Regarding the existence of better approximation
algorithms, there is a (very) light evidence that the obtained approximation
factor of $n^\varepsilon$ for Max Independent Set may be best possible. This is
the first in-depth study of the approximability of problems in graphs of
bounded twin-width. Prior to this paper, essentially the only such result was
a~polynomial-time $O(1)$-approximation algorithm for Min Dominating Set [Bonnet
et al., ICALP '21].
</p></div>
    </summary>
    <updated>2022-07-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2207.07696</id>
    <link href="http://arxiv.org/abs/2207.07696" rel="alternate" type="text/html"/>
    <title>Algorithmic Determination of the Combinatorial Structure of the Linear Regions of ReLU Neural Networks</title>
    <feedworld_mtime>1658275200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Masden:Marissa.html">Marissa Masden</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2207.07696">PDF</a><br/><b>Abstract: </b>We algorithmically determine the regions and facets of all dimensions of the
canonical polyhedral complex, the universal object into which a ReLU network
decomposes its input space. We show that the locations of the vertices of the
canonical polyhedral complex along with their signs with respect to layer maps
determine the full facet structure across all dimensions. We present an
algorithm which calculates this full combinatorial structure, making use of our
theorems that the dual complex to the canonical polyhedral complex is cubical
and it possesses a multiplication compatible with its facet structure. The
resulting algorithm is numerically stable, polynomial time in the number of
intermediate neurons, and obtains accurate information across all dimensions.
This permits us to obtain, for example, the true topology of the decision
boundaries of networks with low-dimensional inputs. We run empirics on such
networks at initialization, finding that width alone does not increase observed
topology, but width in the presence of depth does. Source code for our
algorithms is accessible online at https://github.com/mmasden/canonicalpoly.
</p></div>
    </summary>
    <updated>2022-07-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-07-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6576</id>
    <link href="https://scottaaronson.blog/?p=6576" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6576#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6576" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">A low-tech solution</title>
    <summary xml:lang="en-US">Thanks so much to everyone who offered help and support as this blog’s comment section endured the weirdest, most motivated and sophisticated troll attack in its 17-year history. For a week, a parade of self-assured commenters showed up to demand that I explain and defend my personal hygiene, private thoughts, sexual preferences, and behavior around […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Thanks so much to everyone who offered help and support as this blog’s comment section endured the weirdest, most motivated and sophisticated troll attack in its 17-year history.  For a week, a parade of self-assured commenters showed up to demand that I explain and defend my personal hygiene, private thoughts, sexual preferences, and behavior around female students (and, absurdly, to cajole me into taking my family on a specific Disney cruise ship).  In many cases, the troll or trolls <em>appropriated the names and email addresses of real academics</em>, imitating them so convincingly that those academics’ closest colleagues told me they were confident it was really them.  And when some trolls finally “outed” themselves, I had no way to know whether that was just another chapter in the trolling campaign.  It was enough to precipitate an epistemic crisis, where one actively doubts the authenticity of just about <em>every</em> piece of text.</p>



<p>The irony isn’t lost on me that I’ve endured this just as I’m <a href="https://scottaaronson.blog/?p=6484">starting my year-long gig at OpenAI</a>, to think, among other things, about the potential avenues for misuse of Large Language Models like GPT-3, and what theoretical computer science could contribute to mitigating them.  To say this episode has given me a more vivid understanding of the risks would be an understatement.</p>



<p><strong><em>But why didn’t I just block and ignore the trolls immediately?  Why did I bother engaging?</em></strong>  </p>



<p>At least a hundred people asked some variant of this question, and the answer is this.  For most of my professional life, this blog has been my forum, where anyone in the world could show up to raise any issue they wanted, as if we were tunic-wearing philosophers in the Athenian agora.  I prided myself on my refusal to take the coward’s way out and ignore anything—even, <em>especially</em>, severe personal criticism.  I’d witnessed how Jon Stewart, let’s say, would night after night completely eviscerate George W. Bush, his policies and worldview and way of speaking and justifications and lies, and then Bush would just continue the next day, totally oblivious, never deigning to rebut any of it.  And it became a core part of my identity that I’d never be like that.  If anyone on earth had a narrative of me where I was an arrogant bigot, a clueless idiot, etc., I’d confront that narrative head-on and refute it—or if I couldn’t, I’d reinvent my whole life.  What I’d <em>never</em> do is suffer anyone’s monstrous caricature of me to strut around the Internet unchallenged, as if conceding that only my academic prestige or tenure or power, rather than a reasoned rebuttal, could protect me from the harsh truths that the caricature revealed.</p>



<p>Over the years, of course, I carved out some exceptions: P=NP provers and quantum mechanics deniers enraged that I’d dismissed their world-changing insights.  Raving antisemites.  <em>Their</em> caricatures of me had no legs in any community I cared about.  But if an attack carried the implied backing of the whole modern social-justice movement, of thousands of angry grad students on Twitter, of <em>Slate</em> and <em>Salon</em> and <em>New York Times</em> writers and Wikipedia editors and university DEI offices, then the coward’s way out was closed.  The monstrous caricature then loomed directly over me; I could either parry his attacks or die.</p>



<p>With this stance, you might say, the astounding part is not that this blog’s “agora” model eventually broke down, but rather that it survived for so long!  I started blogging in October 2005.  It took until July 2022 for me to endure a full-scale “social/emotional denial of service attack” (not counting the comment-171 affair).  Now that I have, though, it’s obvious even to me that the old way is no longer tenable.</p>



<p>So what’s the solution?  Some of you liked the idea of requiring registration with real email addresses—but alas, when I tried to implement that, I found that WordPress’s registration system is a mess and I couldn’t see how to make it work.  Others liked the idea of moving to Substack, but others actively hated it, and in any case, even if I moved, I’d <em>still</em> have to figure out a comment policy!  Still others liked the idea of an army of volunteer moderators.  At least ten people volunteered themselves.</p>



<p>On reflection, the following strikes me as most directly addressing the actual problem.  I’m hereby establishing the <strong>Shtetl-Optimized Committee of Guardians</strong>, or SOCG (same acronym as the <a href="https://cse.buffalo.edu/socg21/socg.html">computational geometry conference</a> <img alt="&#x1F642;" class="wp-smiley" src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f642.png" style="height: 1em;"/> ).  If you’re interested in joining, shoot me an email, or leave a comment on this post with your (real!) email address.  I’ll accept members only if I know them in real life, personally or by reputation, or if they have an honorable history on this blog.</p>



<p>For now, the SOCG’s only job is this: whenever I get a comment that gives me a feeling of unease—because, e.g., it seems trollish or nasty or insincere, it asks a too-personal question, or it challenges me to rebut a hostile caricature of myself—I’ll email the comment to the SOCG and ask what to do.  I precommit to respecting the verdict of those SOCG members who respond, whenever a clear verdict exists.  The verdict could be, e.g., “this seems fine,” “if you won’t be able to resist responding then don’t let this appear,” or “email the commenter first to confirm their identity.”  And if I simply need reassurance that the commenter’s view of me is false, I’ll seek it from the SOCG before I seek it from the whole world.</p>



<p>Here’s what SOCG members can expect in return: I continue pouring my heart into this subscription-free, ad-free blog, and I credit you for making it possible—publicly if you’re comfortable with your name being listed, privately if not.  I buy you a fancy lunch or dinner if we’re ever in the same town.</p>



<p>Eventually, we might move to a model where the SOCG members can log in to WordPress and directly moderate comments themselves.  But let’s try it this way first and see if it works.</p></div>
    </content>
    <updated>2022-07-19T18:27:35Z</updated>
    <published>2022-07-19T18:27:35Z</published>
    <category scheme="https://scottaaronson.blog" term="Announcements"/>
    <category scheme="https://scottaaronson.blog" term="Self-Referential"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-07-19T22:39:28Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4813311592001744524</id>
    <link href="http://blog.computationalcomplexity.org/feeds/4813311592001744524/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/07/an-open-question-about-sequence-mod-m.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/4813311592001744524" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/4813311592001744524" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/07/an-open-question-about-sequence-mod-m.html" rel="alternate" type="text/html"/>
    <title>An open question about a sequence mod M.</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In this post n/2 means floor{n/2}<div><br/></div><div>Consider the recurrence</div><div><br/></div><div><br/></div><div>a_1=1</div><div><br/></div><div>for all n\ge 2, a_n = a_{n-1} + a_{n/2}.</div><div><br/></div><div>For which M does this recurrence have infinitely many n such that a_n \equiv  0 mod M?</div><div><br/></div><div><br/></div><div>I have written an open problems column on this for SIGACT News which also says</div><div>what is known (or at least what I know is known).  It will appear in the next issue.</div><div><br/></div><div>I will post that open problems column here on my next post.</div><div><br/>Until then  I would like you to work on it, untainted by what I know. </div><div><br/></div><div><br/></div><div><br/></div><div><br/></div></div>
    </content>
    <updated>2022-07-19T02:52:00Z</updated>
    <published>2022-07-19T02:52:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-07-20T09:42:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/105</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/105" rel="alternate" type="text/html"/>
    <title>TR22-105 |  On vanishing sums of roots of unity in polynomial calculus and sum-of-squares | 

	Ilario Bonacina, 

	Nicola Galesi, 

	Massimo Lauria</title>
    <summary>Vanishing sums of roots of unity can be seen as a natural generalization of knapsack from Boolean variables to variables taking values over the roots of unity. We show that these sums are hard to prove for polynomial calculus and for sum-of-squares, both in terms of degree and size.</summary>
    <updated>2022-07-18T13:04:40Z</updated>
    <published>2022-07-18T13:04:40Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-07-20T10:37:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/104</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/104" rel="alternate" type="text/html"/>
    <title>TR22-104 |  On One-Sided Testing Affine Subspaces | 

	Nader Bshouty</title>
    <summary>We study the query complexity of one-sided $\epsilon$-testing the class of Boolean functions $f:F^n\to \{0,1\}$ that describe affine subspaces and Boolean functions that describe axis-parallel affine subspaces, where $F$ is any finite field. We give a polynomial-time $\epsilon$-testers that ask $\tilde O(1/\epsilon)$ queries. This improves the query complexity $\tilde O(|F|/\epsilon)$ in~[16]. 

We then show that any one-sided $\epsilon$-tester with proximity parameter $\epsilon&lt;1/|F|^d$ for the class of Boolean functions that describe $(n-d)$-dimensional affine subspaces and Boolean functions that describe axis-parallel $(n-d)$-dimensional affine subspaces must make at least
$\Omega(1/\epsilon+|F|^{d-1}\log n)$ and $\Omega(1/\epsilon+|F|^{d-1}n)$ queries, respectively.
This improves the lower bound $\Omega(\log n/\log\log n)$  that is proved in~[16] for $F=GF(2)$. We also give  testers for those classes with query complexity that almost match the lower bounds.</summary>
    <updated>2022-07-18T12:43:42Z</updated>
    <published>2022-07-18T12:43:42Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-07-20T10:37:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=20239</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/07/18/complexity-2022/" rel="alternate" type="text/html"/>
    <title>Complexity 2022</title>
    <summary>Weaving patterns of proof and the accepted papers for this week’s conference her bio page Karen Donde is the Chair of Complexity 2022, which is being held this month in Knoxville, Tennessee. This is not the same as the Computational Complexity 2022 (CCC22) conference, which is being held in-person at the University of Pennsylvania this […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Weaving patterns of proof and the accepted papers for this week’s conference</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/07/18/complexity-2022/karendonde/" rel="attachment wp-att-20241"><img alt="" class="alignright wp-image-20241" height="159" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/KarenDonde.jpg?resize=151%2C159&amp;ssl=1" width="151"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><a href="https://karendondehandwovens.com/page/1-Statement-Bio.html">her bio page</a></font></td>
</tr>
</tbody>
</table>
<p>
Karen Donde is the Chair of <a href="https://complexityexhibition.org/">Complexity 2022</a>, which is being held this month in Knoxville, Tennessee. This is not the same as the <a href="https://computationalcomplexity.org/Archive/2022/fullsite/">Computational Complexity 2022</a> (CCC22) conference, which is being held <b>in-person</b> at the University of Pennsylvania this <b>Wednesday, July 20</b>, through <b>Saturday, July 23</b>. The Knoxville event is not about computer science, nor dynamical nor biological complexity. It is about the art of weaving complex patterns in textiles by hand.</p>
<p>
Today we collect pointers to the papers at CCC22 after saying something separate about weaving and proofs.</p>
<p>
Unlike CCC22, the Knoxville exhibition is also <a href="https://complexityexhibition.org/all-works/">open online</a>. Here is a detail from the Complex Weaver first prize <a href="https://complexityexhibition.org/melanie-olde-morphology-i/">winner</a>, an example of three-dimensional weaving:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/07/18/complexity-2022/complexweavingprize/" rel="attachment wp-att-20242"><img alt="" class="aligncenter wp-image-20242" height="270" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/07/ComplexWeavingPrize.jpg?resize=250%2C270&amp;ssl=1" width="250"/></a></p>
<p>
Like CCC22, the Knoxville event has a program committee. It consists of <a href="http://www.juliehedges.co.uk/">Julie Hedges</a>, <a href="https://www.spadystudios.com/">Robyn Spady</a>, and <a href="https://www.bettyvera.com/">Betty Vera</a>. Also like CCC22, it has a steering committee. Besides Donde, the committee consists of <a href="https://www.etsy.com/shop/MargepyeTextiles?ref=profile_header">Margaret Dugger</a>, <a href="https://www.pinterest.com/dyen2weave/">Diane Smith</a>, <a href="https://wovenful.com/an-interview-with-sarah-fortin/">Sarah Fortin</a>, <a href="https://pikespeakweavers.org/member-galleries/nggallery/member-galleries/susan-bowman">Susan Bowman</a>, <a href="https://newworldtextiles.com/about/">Eileen Hallman</a>, <a href="https://www.woodlandsgallerync.com/artists/pat-brown">Pat Brown</a>, <a href="https://www.facebook.com/katiedoanhandweaver/">Katie Doan</a>, <a href="https://www.weavingschool.com/Geri.html">Geri Forkner</a>, <a href="https://www.linkedin.com/in/cathy-mccarthy-42347828/">Cathy McCarthy</a>, <a href="http://www.spinningforth.com/perso/perso.html">Ruth MacGregor</a>, and <a href="https://weavingspace.co.uk/#About-Weaving-Space">Cally Booker</a>. The gender imbalance is more extreme than for CCC22 or what we <a href="https://rjlipton.wpcomstaging.com/2021/11/13/popl-2022-et-tu-brute/">noted</a> last fall for POPL22 (also see end of <a href="https://rjlipton.wpcomstaging.com/2021/11/24/best-to-dean-mynatt/">this</a>). Oh well.</p>
<p>
</p><p/><h2> Weaving Into Theory </h2><p/>
<p/><p>
Karen Donde also writes a <a href="https://karen63615.wixsite.com/karendondeblog">blog</a>, <em>Speaking of Weaving</em>. The blog has numerous technical how-to articles. In some places they verge on mathematical theory. </p>
<p>
There are more express connections between mathematics and weaving. The mathematics teacher <a href="http://www.patrickhonner.com/about.html">Patrick Honner</a> has a <a href="https://mrhonner.com/weaving">page</a> of posts on weaving. He was featured in an <a href="https://naturalmath.com/2012/07/weaving-mathematics/">article</a> “Weaving your way through mathematics” by the mathematics educator Maria Droujkova. See also a <a href="https://www.youtube.com/watch?v=Breul3cnW9s">video</a> on weaving and the mathematics of <a href="https://en.wikipedia.org/wiki/Spirograph">Spirograph</a> patterns.</p>
<p>
On the computing theory side, connections to cellular automata are shown in a 2017 <a href="https://www.semanticscholar.org/paper/The-Complexity-of-Braids,-Cables,-and-Weaves-with-Holden/5b83e108623548c8b073a1e96b00d027eefb197e">paper</a> by Joshua Holden. There is also a recent <a href="https://dl.acm.org/doi/fullHtml/10.1145/3411764.3445750">paper</a> from CMU’s Human-Computer Interaction Institute on “Enabling Personal Computational Handweaving with a Low-Cost Jacquard Loom.” </p>
<p>
</p><p/><h2> Weaving Into Proofs </h2><p/>
<p/><p>
Our association to weaving was really motivated, however, by an <a href="https://www.quantamagazine.org/how-do-mathematicians-know-their-proofs-are-correct-20220713/">article</a> last Wednesday by Steven Strogatz, a Cornell mathematician and extraordinary popularizer whom I (Ken) have known since we were undergraduates together at Princeton. The article interviews the Harvard mathematician Melanie Matchett Wood and is titled, “How Do Mathematicians Know Their Proofs Are Correct?”</p>
<p>
We have written about proofs and the social issue of verification <a href="https://rjlipton.wpcomstaging.com/2022/06/13/sorting-and-proving/">several</a> <a href="https://rjlipton.wpcomstaging.com/2022/05/23/hilberts-lost-problem/">times</a> <a href="https://rjlipton.wpcomstaging.com/2020/12/10/the-future-of-mathematics/">recently</a>. But this article goes into a more particular topic that we tried to get at in a <a href="https://rjlipton.wpcomstaging.com/2014/09/09/a-challenge-from-dyson/">series</a> of <a href="https://rjlipton.wpcomstaging.com/2014/06/06/is-this-a-proof-2/">posts</a> in <a href="https://rjlipton.wpcomstaging.com/2014/10/11/more-on-testing-dysons-conjecture/">2014</a>. This is about whether probabilistic modeling—not the <a href="https://en.wikipedia.org/wiki/Probabilistic_method">Probabilistic Method</a> which is airtight—can give confidence in conjectures that is tantamount to proof.</p>
<p>
Strogatz’s interview leads off with a reference to a 2019 <a href="https://www.quantamagazine.org/where-proof-evidence-and-imagination-intersect-in-math-20190314/">article</a> for <em>Quanta</em> titled, “Where Proof, Evidence, and Imagination Intersect.” That article is by the same Patrick Honner whom we just mentioned for weaving, and gives caveats of how bias and unrecognized implicit constraints can creep into models, so as to invalidate them. </p>
<p>
Wood begins with basic “coinflip” random models of primes—such as mentioned in the above-listed posts—and fixes on a bias-revealing model that we also covered <a href="https://rjlipton.wpcomstaging.com/2016/03/26/bias-in-the-primes/">here</a>. She then describes how they incrementally build rules for adjusting coin weights to compensate for biases introduced by small-number cases: </p>
<blockquote><p><b> </b> <em> “So the model is something that starts with this coin-flipping model, but then it’s modified by all these other rules, and all the other things that we know about the primes. And once you put all of those things that we do know into the model, you then ask [it] well, do you see, infinitely often, coins coming up prime just 2 apart? And the model tells you, oh, yes, we do see that. In fact, we see it at this very particular rate we can give you a formula for. And then … you see that the model gives you a very accurate prediction for the number of pairs of twin primes you’ll find as you go along. And so then you think, you know, maybe this model knows what it’s talking about.” </em>
</p></blockquote>
<p/><p>
In response to Strogatz noting that the accuracy must be judged by long computer runs, Wood is quick to emphasize that the rules given to the model are determined manually:</p>
<blockquote><p><b> </b> <em> “But for building this model and coming up with the formula that the model gives. You know, that’s done by hand, essentially, by mathematicians thinking about the model and figuring out with it. … [A]t some point, the computer stops. You know, there’s only so much computing power. But that formula that you would get, that the model would give you, that you could prove is true, again, about this model coin-flipping situation, that formula will keep going. You can put bigger and bigger numbers into that formula, much bigger than your computer could ever, ever compute with.” </em>
</p></blockquote>
<p>
</p><p/><h2> Proof of the Loom? </h2><p/>
<p/><p>
Wood goes on to describe <em>universality</em> in probability theory as signifying “that there are certain kinds of machines that if you put in a lot of random inputs, you can predict the output.” She gives as a bellwether example how the Central Limit Theorem creates such a universal machine for the bell curve. Regardless of an unknown distribution <em>D</em>, if you take means of samples from <em>D</em>, then the bell curve gives progressively—and provably—more accurate predictions of your outputs. Strogatz catches the warp and asks whether “somehow we’re getting the idea of universality to show up in number theory? Or am I dreaming?” Her peroration is:</p>
<blockquote><p><b> </b> <em> “[W]hat my collaborators and I work on is trying to make that kind of dream a reality so that, that some of these puzzling questions about numbers that we don’t know the answer to, maybe we could understand that there are patterns that come out, like a bell curve, like a normal distribution, that we can prove came out of the machine even if we don’t know what mysteries were put in.” </em>
</p></blockquote>
<p/><p>
So she is building a machine that takes rules as input—like Jacquard cards for a loom—and produces patterns that are analyzable. We use the computational success of the machine to judge how well universality has taken hold—as theoretically it must—and generate proofs from formulas based on the <em>a-priori</em> predicted outputs using the rules input thus far. </p>
<p>
This is like building a loom for weaving proofs—where, however, there is still the question of confidence in how well the patterns obtained match reality. Such doubt notwithstanding, the process may also augment non-linear ways of evaluating claimed proofs of the kind we discussed <a href="https://rjlipton.wpcomstaging.com/2020/06/13/proof-checking-not-line-by-line/">here</a> and recently debated <a href="https://rjlipton.wpcomstaging.com/2022/04/10/discussion-about-proving-again/">here</a>.</p>
<p>
</p><p/><h2> The Papers </h2><p/>
<p/><p>
The proofs in the accepted papers were, to be sure, evaluated by the standard expert social process. Here they are, lifted from the conference’s own program <a href="https://computationalcomplexity.org/Archive/2022/program.php">page</a>. Clicking on the time of the talk gives a pointer to the paper. </p>
<p>
<b>Wednesday, July 20</b></p>
<p>
<a href="https://arxiv.org/pdf/2205.10749.pdf">9:00</a> “Vanishing Spaces of Random Sets and Applications to Reed-Muller Codes.”<br/>
Siddharth Bhandari, Prahladh Harsha, Ramprasad Saptharishi, Srikanth Srinivasan</p>
<p>
<a href="https://drops.dagstuhl.de/opus/volltexte/2022/16572/pdf/LIPIcs-CCC-2022-10.pdf">9:30</a> “New Near-Linear Time Decodable Codes Closer to the GV Bound.”<br/>
Guy Blanc and Dean Doron</p>
<p>
<a href="https://drops.dagstuhl.de/opus/volltexte/2022/16576/pdf/LIPIcs-CCC-2022-14.pdf">10:00</a> “The plane test is a local tester for Multiplicity Codes.”<br/>
Dan Karliner, Roie Salama and Amnon Ta-Shma</p>
<p>
<a href="https://eccc.weizmann.ac.il/report/2022/025/">13:30</a> “Efficient Low-Space Simulations From the Failure of the Weak Pigeonhole Principle” (co-winner Best student paper).<br/>
Oliver Korten</p>
<p>
<a href="https://eccc.weizmann.ac.il/report/2022/023/">14:00</a> “Nisan-Wigderson generators in Proof Complexity: New lower bounds.”<br/>
Erfan Khaniki</p>
<p>
<a href="https://drops.dagstuhl.de/opus/volltexte/2022/16577/pdf/LIPIcs-CCC-2022-15.pdf">14:30</a> “Pseudorandom Generators, Resolution and Heavy Width.”<br/>
Dmitry Sokolov</p>
<p>
<a href="https://drops.dagstuhl.de/opus/volltexte/2022/16565/pdf/LIPIcs-CCC-2022-3.pdf">15:30</a> “Hitting Sets for Regular Branching Programs.”<br/>
Andrej Bogdanov, William Hoza, Gautam Prakriya and Edward Pyne</p>
<p>
<a href="https://eccc.weizmann.ac.il/report/2022/021/">16:00</a> “Improved Pseudorandom Generators for <img alt="{AC^0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAC%5E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> Circuits” (co-winner Best student paper).<br/>
Xin Lyu</p>
<p>
<a href="https://arxiv.org/abs/2103.14134">16:40</a> “Random restrictions and PRGs for PTFs in Gaussian Space.”<br/>
Zander Kelley and Raghu Meka</p>
<p>
<a href="https://eccc.weizmann.ac.il/report/2022/024/">17:00</a> “Pseudorandomness of Expander Random Walks for Symmetric Functions and Permutation Branching Programs.”<br/>
Louis Golowich and Salil Vadhan</p>
<p>
<b>Thursday, July 21</b></p>
<p>
<a href="https://arxiv.org/abs/2111.02999">9:00</a> “Quantum search-to-decision reductions and the state synthesis problem.”<br/>
Sandy Irani, Anand Natarajan, Chinmay Nirkhe, Sujit Rao and Henry Yuen</p>
<p>
<a href="https://drops.dagstuhl.de/opus/volltexte/2022/16590/pdf/LIPIcs-CCC-2022-28.pdf">9:30</a> “Influence in Completely Bounded Block-multilinear Forms and Classical Simulation of Quantum Algorithms.”<br/>
Nikhil Bansal, Makrand Sinha and Ronald de Wolf</p>
<p>
<a href="https://arxiv.org/abs/2111.10409">10:00</a> “The Acrobatics of BQP” (winner – Best paper award).<br/>
Scott Aaronson, Devon Ingram and William Kretschmer</p>
<p>
<a href="https://eprint.iacr.org/2021/513">13:30</a> “On One-way Functions from NP-Complete Problems.”<br/>
Yanyi Liu and Rafael Pass</p>
<p>
<a href="https://nanashima.github.io">14:00</a> “Finding Errorless Pessiland in Error-Prone Heuristica.”<br/>
Shuichi Hirahara and Mikito Nanashima</p>
<p>
<a href="https://eccc.weizmann.ac.il/report/2022/084/">14:30</a> “Characterizing Derandomization Through Fine-Grained Hardness of Levin-Kolmogorov Complexity.”<br/>
Yanyi Liu and Rafael Pass</p>
<p>
<a href="https://www.researchgate.net/publication/356891307_Almost_Polynomial_Factor_Inapproximability_for_Parameterized_k-Clique">15:30</a> “Almost Polynomial Factor Inapproximability for Parameterized k-Clique.”<br/>
Karthik C. S. and Subhash Khot</p>
<p>
<a href="https://arxiv.org/abs/2106.12710">16:00</a> “Certifying solution geometry in random CSPs: counts, clusters and balance.”<br/>
Jun-Ting Hsieh, Sidhanth Mohanty and Jeff Xu</p>
<p>
<a href="https://arxiv.org/abs/2203.03705">16:40</a> “High-Dimensional Expanders from Chevalley Groups.”<br/>
Ryan O’Donnell and Kevin Pratt</p>
<p>
<a href="https://arxiv.org/abs/2205.02374">17:10</a> “The composition complexity of majority.”<br/>
Victor Lecomte, Prasanna Ramakrishnan and Li-Yang Tan</p>
<p>
<b>Friday, July 22</b></p>
<p>
<a href="https://arxiv.org/abs/2004.14318">9:00</a> “The Approximate Degree of Bipartite Perfect Matching.”<br/>
Gal Beniamini</p>
<p>
<a href="https://arxiv.org/abs/2205.06249">9:30</a> “Optimal-Degree Polynomial Approximations for Exponentials and Gaussian Kernel Density Estimation.”<br/>
Amol Aggarwal and Josh Alman</p>
<p>
<a href="https://arxiv.org/abs/2108.13578">10:00</a> “<img alt="{\ell_p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-Spread and Restricted Isometry Properties of Sparse Random Matrices.”<br/>
Venkatesan Guruswami, Peter Manohar and Jonathan Mosheiff</p>
<p>
<a href="https://eccc.weizmann.ac.il/report/2022/074/">13:30</a> “On Randomized Reductions to the Random Strings.”<br/>
Michael Saks and Rahul Santhanam</p>
<p>
<a href="https://eccc.weizmann.ac.il/report/2022/086/">14:00</a> “Extremely Efficient Constructions of Hash Functions, with Applications to Hardness Magnification and PRFs.”<br/>
Lijie Chen, Jiatu Li and Tianqi Yang</p>
<p>
<a href="https://drops.dagstuhl.de/opus/volltexte/2022/16575/pdf/LIPIcs-CCC-2022-13.pdf">14:30</a> “A better-than-3log(n) depth lower bound for De Morgan formulas with restrictions on top gates.”<br/>
Ivan Mihajlin and Anastasia Sofronova</p>
<p>
<a href="https://eccc.weizmann.ac.il/report/2022/072/">15:30</a> “Probabilistic Kolmogorov Complexity with Applications to Average-Case Complexity.”<br/>
Halley Goldberg, Valentine Kabanets, Zhenjian Lu and Igor C. Oliveira</p>
<p>
<a href="https://drops.dagstuhl.de/opus/volltexte/2022/16588/pdf/LIPIcs-CCC-2022-26.pdf">16:00</a> “Symmetry of Information from Meta-Complexity.”<br/>
Shuichi Hirahara</p>
<p>
<a href="https://arxiv.org/abs/2201.08895">16:30</a> “On the Satisfaction Probability of k-CNF Formulas.”<br/>
Till Tantau</p>
<p>
<b>Saturday, July 23</b></p>
<p>
<a href="https://arxiv.org/abs/2202.09883">9:00</a> “On Efficient Noncommutative Polynomial Factorization via Higman Linearization.”<br/>
Vikraman Arvind and Pushkar Joglekar</p>
<p>
<a href="https://www.researchgate.net/publication/360332836_Improved_Low-Depth_Set-Multilinear_Circuit_Lower_Bounds">9:30</a> “Improved Low-Depth Set-Multilinear Circuit Lower Bounds.”<br/>
Deepanshu Kush and Shubhangi Saraf</p>
<p>
<a href="https://drops.dagstuhl.de/opus/volltexte/2022/16594/pdf/LIPIcs-CCC-2022-32.pdf">10:15</a> “On the Partial Derivative Method Applied to Lopsided Set-Multilinear Polynomials.”<br/>
Nutan Limaye, Srikanth Srinivasan and Sebastien Tavenas</p>
<p>
<a href="https://arxiv.org/abs/2205.15168">10:45</a> “Subrank and Optimal Reduction of Scalar Multiplications to Generic Tensors.”<br/>
Harm Derksen, Visu Makam and Jeroen Zuiddam</p>
<p>
<a href="https://eccc.weizmann.ac.il/report/2022/026/">11:00</a> “Trading Time and Space in Catalytic Branching Programs.”<br/>
Ian Mertz and James Cook</p>
<p>
<a href="https://arxiv.org/abs/2201.10997">12:30</a> “Linear Branching Programs and Directional Affine Extractors.”<br/>
Svyatoslav Gryaznov, Pavel Pudlak and Navid Talebanfard</p>
<p>
<a href="https://www.cs.mcgill.ca/~robere/research.html">14:00</a> “Further collapses in TFNP.”<br/>
Mika Goos, Alexandros Hollender, Siddhartha Jain, Gilbert Maystre, William Pires, Robert Robere and Ran Tao</p>
<p>
<a href="https://drops.dagstuhl.de/opus/volltexte/2022/16592/pdf/LIPIcs-CCC-2022-30.pdf">14:30</a> “Interactive Oracle Proofs of Proximity to Algebraic Geometry Codes.”<br/>
Sarah Bordage, Mathieu Lhotel, Jade Nardi and Hugues Randriam</p>
<p>
<a href="https://eprint.iacr.org/2022/168">15:00</a> “Hardness of Approximation for Stochastic Problems via Interactive Oracle Proofs.”<br/>
Gal Arnon, Alessandro Chiesa and Eylon Yogev</p>
<p>
We congratulate all the authors of the accepted papers.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Can we really build mathematical looms for helping us generate proofs at high level?</p></font></font></div>
    </content>
    <updated>2022-07-18T05:34:57Z</updated>
    <published>2022-07-18T05:34:57Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="primes"/>
    <category term="Proofs"/>
    <category term="CCC22"/>
    <category term="Computational Complexity Conference"/>
    <category term="computer proofs"/>
    <category term="Karen Donde"/>
    <category term="Melanie Matchett Wood"/>
    <category term="Patrick Honner"/>
    <category term="probabilistic proofs"/>
    <category term="Steven Strogatz"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-07-20T10:37:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/07/17/full-professorships-and-tenure-track-professorships-at-ruhr-university-bochum-germany-apply-by-july-29-2022/</id>
    <link href="https://cstheory-jobs.org/2022/07/17/full-professorships-and-tenure-track-professorships-at-ruhr-university-bochum-germany-apply-by-july-29-2022/" rel="alternate" type="text/html"/>
    <title>Full Professorships and Tenure-Track Professorships at Ruhr-University Bochum, Germany (apply by July 29, 2022)</title>
    <summary>We invite outstanding applicants from all areas of computer science, including the Foundations of Computer Science. Salary and working conditions are internationally very competitive and come with civil servant status. Full professorships are chair positions with administrative staff. We offer dual-career &amp; relocation support and a family-friendly environment. Knowledge of German is not required. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We invite outstanding applicants from all areas of computer science, including the Foundations of Computer Science. Salary and working conditions are internationally very competitive and come with civil servant status. Full professorships are chair positions with administrative staff. We offer dual-career &amp; relocation support and a family-friendly environment. Knowledge of German is not required.</p>
<p>Website: <a href="https://informatik.rub.de/en/news/openings-professorships-in-computer-science-w3-and-w2-tenure-track-w3/">https://informatik.rub.de/en/news/openings-professorships-in-computer-science-w3-and-w2-tenure-track-w3/</a><br/>
Email: career@casa.rub.de</p></div>
    </content>
    <updated>2022-07-17T10:15:42Z</updated>
    <published>2022-07-17T10:15:42Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-07-20T10:37:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/103</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/103" rel="alternate" type="text/html"/>
    <title>TR22-103 |  Almost Chor--Goldreich Sources and Adversarial Random Walks | 

	Dean Doron, 

	Dana Moshkovitz, 

	Justin Oh, 

	David Zuckerman</title>
    <summary>A Chor--Goldreich (CG) source [CG88] is a sequence of random variables  $X = X_1 \circ \ldots \circ X_t$, each $X_i \sim \{0,1 \{^d$, such that each $X_i$ has $\delta d$ min-entropy for some constant $\delta &gt; 0$, even conditioned on any fixing of $X_1 \circ \ldots \circ X_{i-1}$. We typically think of $d$ as constant. We extend this notion in several ways, and most notably allow each $X_i$ to be only $\gamma$-close to having $\delta d$ min entropy.

Studying such almost CG sources allows us to achieve pseudorandomness results which were not known to hold even for standard CG sources, and even for the weaker model of Santha--Vazirani sources [SV86]. We construct a deterministic condenser that on input $X$, outputs a distribution which is close to having constant entropy gap, namely a distribution $Z \sim \{0,1 \}^m$ for $m \approx \delta dt$ with min-entropy $m-O(1)$. 

Our new primitive readily implies fast simulation results:

*	We can simulate $\mathbf{BPP}$ using almost CG sources with constant multiplicative slowdown.
*	When the randomized algorithm has small failure probability, we can simulate it using almost CG sources with no multiplicative slowdown. This result extends to randomized protocols as well, and any setting in which we cannot simply cycle over all seeds, and a ``one-shot'' simulation is needed.

Moreover, our framework is flexible enough to work even when the $X_i$-s only have Shannon entropy rather than min-entropy, and in some cases, even when a few $X_i$-s are completely damaged.

Our main technical contribution is a novel analysis of random walks which may be of independent interest. We analyze walks with adversarially correlated steps, each step being entropy-deficient, on good enough lossless expanders. We prove that such walks (or certain interleaved walks on two expanders), starting from a fixed vertex and walking according to $X_1\circ \ldots \circ X_t$, accumulate most of the entropy in $X$.</summary>
    <updated>2022-07-15T19:42:52Z</updated>
    <published>2022-07-15T19:42:52Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-07-20T10:37:18Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/07/15/linkage</id>
    <link href="https://11011110.github.io/blog/2022/07/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Creating weaving patterns from subdivision schemes (\(\mathbb{M}\)), new paper by Lipschütz, Reitebuch, Skrodzi, and Polthier, and explanatory thread by Skrodzi.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://doi.org/10.1080/17513472.2022.2069417">Creating weaving patterns from subdivision schemes</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@msmathcomputer/108561058326179122">\(\mathbb{M}\)</a>),</span> new paper by Lipschütz, Reitebuch, Skrodzi, and Polthier, and explanatory thread by Skrodzi.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@peterrowlett/108578769727211199">How would you make a sphere from three circles?</a>, asks Peter Rowlett after his son said he could do it.</p>
  </li>
  <li>
    <p><a href="http://blog.computationalcomplexity.org/2022/06/a-gadget-for-3-colorings.html">Counting 3-colorings</a> and <a href="https://blog.computationalcomplexity.org/2022/06/counting-number-of-3-colorings-of-graph">follow-up post</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108584298969286802">\(\mathbb{M}\)</a>).</span> Like all “natural” \(\mathsf{NP}\)-complete problems (and many easier problems), the 3-coloring problem should have a \(\#\mathsf{P}\)-complete counting version, but the gadgets needed to prove it are a little subtle and tracking down the history of proof of this result took some effort.</p>
  </li>
  <li>
    <p><a href="https://youtu.be/tH6vLXMaCwQ">Polyhedra in which all but one edge have a right angle</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@henryseg/108584342158901821">\(\mathbb{M}\)</a>),</span> 3d-printed based on a construction used by Sydler to study Dehn invariants. Achieving this property leads to surprisingly complicated polyhedra.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/tag/2022-fields-and-abacus-medals/">The 2022 Fields medals</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@mathcination/108595654085200673">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://11011110.github.io/blog/2020/07/31/linkage.html">Two years ago</a> I linked to <a href="https://cp4space.wordpress.com/2020/07/25/rational-dodecahedron-inscribed-in-unit-sphere/">a post by Adam Goucher</a>, solving <a href="https://mathoverflow.net/q/234212/440">an old MathOverflow question</a> by showing that it is possible to find a dodecahedron, combinatorially equivalent to a regular one, with rational coordinates, inscribed in a unit sphere. But <a href="https://cp4space.hatsya.com/2022/06/20/infinitely-many-rational-dodecahedra/">now there are infinitely many</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108602499475969576">\(\mathbb{M}\)</a>)!</span> Some messy algebra, and then some work with elliptic curve group operations, eventually simplifies down to a parametric family with a dodecahedron for each integer right triangle.</p>
  </li>
  <li>
    <p>For integer \(A\), a grid of  \(n\) points has roughly \(n^2\sigma(A)/A\) area-\(A\) triangles, where \(\sigma\) is the sum of divisors <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108606089910227326">\(\mathbb{M}\)</a>);</span> see <a href="https://users.renyi.hu/~p_erdos/1971-20.pdf">Erdős &amp; Purdy 1971</a> who used non-square grids and factorial \(A\) to find points with \(\Omega(n\log\log n)\) unit-area triangles. So how big is \(\sigma(A)/A\)? <a href="https://en.wikipedia.org/wiki/Divisor_function#Robin's_theorem">It depends on the Riemann hypothesis!</a> If RH is true, at most \(e^\gamma\log\log A\) for \(A&gt;5040\). If not, slightly larger infinitely often.</p>
  </li>
  <li>
    <p><a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-ICGT-22.pdf">Slides from my talk on “Graphs in Nature”</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108611451435162895">\(\mathbb{M}\)</a>)</span> at the International Colloquium on Graph Theory and Combinatorics in Montpellier, France.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Prince_Rupert%27s_cube">Prince Rupert’s cube</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108623867716491741">\(\mathbb{M}\)</a>):</span> a cube can fit through a square hole drilled through another cube its size, or even slightly smaller. Now a Good Article on Wikipedia. I’ve been wondering: is it possible to make Prince Rupert’s Borromean rings, by drilling square holes into three unit cubes, each simultaneously passing through the hole in the next one?</p>
  </li>
  <li>
    <p>On the CSTheory stackexchange, Alexey Milovanov asks for updates on the (as far as I know still unknown) complexity of an old problem, <a href="https://cstheory.stackexchange.com/q/51680/95">finding shortest addition chains</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108627574398080196">\(\mathbb{M}\)</a>).</span> This highlights something I love about editing Wikipedia: if you take the effort to track down a repeated error in the literature, and <a href="https://en.wikipedia.org/wiki/Special:Diff/206806087">document it properly in the right Wikipedia article</a>, then maybe 14 years later the correction rather than the error can be common knowledge.</p>
  </li>
  <li>
    <p><a href="https://www.maa.org/press/maa-reviews/pop-up-geometry">The MAA reviews Joe O’Rourke’s new book, <em>Pop-Up Geometry: The Mathematics Behind Pop-Up Cards</em></a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108632717277132574">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2207.04923">Killing a vortex</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108637362908341033">\(\mathbb{M}\)</a>),</span> by Thilikos and Wiederrecht. Robertson and Seymour’s structural decomposition of minor-closed graph families glues together surface-embedded graphs, a few arbitrarily-connected “apex” vertices, and “vortices”, bounded-pathwidth graphs attached to faces. For graph matching, vortices are problematic. This new preprint describes the families that don’t need them and shows that they are exactly the ones whose matchings can be counted quickly.</p>
  </li>
  <li>
    <p>Scott Aaronson, quantum complexity theorist and debunker of quantum hype on <a href="https://scottaaronson.blog/">his blog</a>, is also a <a href="https://scottaaronson.blog/?p=6552">target of trolls who have pushed him to back down from his free-speech principles and restrict comments</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108641124975905102">\(\mathbb{M}\)</a>).</span> <a href="https://windowsontheory.org/2022/07/13/my-friend-scott-aaronson/">Boaz Barak gives some support</a>. Via Boaz I re-found Scott’s 2005 “<a href="https://arxiv.org/abs/quant-ph/0502072">NP-complete Problems and Physical Reality</a>” debunking soap bubble and rubber band solvers for hard optimization problems. Worth a re-read!</p>
  </li>
  <li>
    <p>I tend to pick technologically better solutions over popular ones, despite popularity’s importance for long-term viability <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108649887665081093">\(\mathbb{M}\)</a>).</span> Which is why I just switched from a gas range to induction. It has all the responsiveness of gas (vs the glacial response of conventional electric), is more efficient, has a smaller carbon footprint, fewer noxious emissions, etc. These are still uncommon in Southern California, but new laws require electric appliances for new construction, and I hope that with familiarity they will become better liked as well.</p>
  </li>
  <li>
    <p><a href="https://www.surgehq.ai//blog/30-percent-of-googles-reddit-emotions-dataset-is-mislabeled">Seriously bad data in Google’s GoEmotions dataset</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108653832818847808">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=32090389">via</a>), some 58K reddit comments categorized by affect. Opinions in the post and comments vary on why the categorization was so inaccurate, including lack of context, farming it out to poorly-paid workers in countries less likely to be familiar with the specific idioms used in the comments, or maybe just that it’s a hard problem.</p>
  </li>
</ul></div>
    </content>
    <updated>2022-07-15T16:57:00Z</updated>
    <published>2022-07-15T16:57:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-07-16T00:26:38Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2022/07/15/imp-reg-htf-cnn/</id>
    <link href="http://offconvex.github.io/2022/07/15/imp-reg-htf-cnn/" rel="alternate" type="text/html"/>
    <title>Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Networks</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The ability of large neural networks to generalize is commonly believed to stem from an implicit regularization — a tendency of gradient-based optimization towards predictors of low complexity.
A lot of effort has gone into theoretically formalizing this intuition.
Tackling modern neural networks head-on can be quite difficult, so existing analyses often focus on simplified models as stepping stones.
Among these, matrix and tensor factorizations have attracted significant attention due to their correspondence to linear neural networks and certain shallow non-linear convolutional networks, respectively. 
Specifically, they were shown to exhibit an implicit tendency towards low matrix and tensor ranks, respectively.</p>

<p>This post overviews a recent <a href="https://arxiv.org/abs/2201.11729">ICML 2022 paper</a> with <a href="https://asafmaman101.github.io/">Asaf Maman</a> and <a href="http://www.cohennadav.com/">Nadav Cohen</a>, in which we draw closer to practical deep learning by analyzing <em>hierarchical tensor factorization</em>, a model equivalent to certain <em>deep non-linear</em> convolutional networks. 
We find that, analogously to matrix and tensor factorizations, the implicit regularization in hierarchical tensor factorization strives to lower a notion of rank (called hierarchical tensor rank).
This turns out to have surprising implications on the origin of locality in convolutional networks, inspiring a practical method (explicit regularization scheme) for improving their performance on tasks with long-range dependencies.</p>

<h2 id="background-matrix-and-tensor-factorizations">Background: Matrix and Tensor Factorizations</h2>

<p>To put our work into context, let us briefly go over existing dynamical characterizations of implicit regularization in matrix and tensor factorizations.
In both cases they suggest an incremental learning process that leads to low rank solutions (for respective notions of rank). We will then see how these characterizations transfer to the considerably richer hierarchical tensor factorization.</p>

<h3 id="matrix-factorization-incremental-matrix-rank-learning">Matrix factorization: Incremental matrix rank learning</h3>
<p><em>Matrix factorization</em> is arguably the most extensively studied model in the context of implicit regularization. 
Indeed, it was already discussed in four previous posts (<a href="https://www.offconvex.org/2021/07/08/imp-reg-tf/">1</a>, <a href="https://www.offconvex.org/2020/11/27/reg_dl_not_norm/">2</a>, <a href="http://www.offconvex.org/2019/07/10/trajectories-linear-nets/">3</a>, <a href="http://www.offconvex.org/2019/06/03/trajectories/">4</a>), but for completeness we will present it once more. 
Consider the task of minimizing a loss $\mathcal{L}_M : \mathbb{R}^{D, D’} \to \mathbb{R}$ over matrices, e.g. $\mathcal{L}_M$ can be a matrix completion loss — mean squared error over observed entries from some ground truth matrix. 
Matrix factorization refers to parameterizing the solution $W_M \in \mathbb{R}^{D, D’}$ as a product of $L$ matrices, and minimizing the resulting objective using <em>gradient descent (GD)</em>:</p>
<div style="text-align: center;">
\[
    \min\nolimits_{W^{(1)}, \ldots, W^{(L)}} \mathcal{L}_M \big ( W_M \big ) := \mathcal{L}_M \big ( W^{(1)} \cdots W^{(L)} \big ) ~.
\]
</div>
<p>Essentially, matrix factorization amounts to applying a linear neural network (fully connected neural network with no non-linearity) for minimizing $\mathcal{L}_M$. 
We can explicitly constrain the matrix rank of $W_M$ by limiting the shared dimensions of the weight matrices $\{ W^{(l)} \}_l$. However, from an implicit regularization standpoint, the most interesting case is where rank is unconstrained. 
In this case there is no explicit regularization, and the kind of solution we get is determined implicitly by the parameterization and the optimization algorithm.</p>

<p>Although it was initially conjectured that GD (with small initialization and step size) over matrix factorization minimizes a norm (see the seminal work of <a href="https://arxiv.org/abs/1705.09280">Gunasekar et al. 2017</a>), recent evidence points towards an implicit matrix rank minimization (see <a href="https://arxiv.org/abs/1905.13655">Arora et al. 2019</a>; <a href="https://arxiv.org/abs/1904.13262">Gidel et al. 2019</a>; <a href="https://arxiv.org/abs/2005.06398">Razin &amp; Cohen 2020</a>; <a href="https://arxiv.org/abs/2011.13772">Chou et al. 2020</a>; <a href="https://arxiv.org/abs/2012.09839">Li et al. 2021</a>).
In particular, <a href="https://arxiv.org/abs/1905.13655">Arora et al. 2019</a> characterized the dynamics of $W_M$’s singular values throughout optimization:</p>

<blockquote>
  <p><strong>Theorem (informal; <a href="https://arxiv.org/abs/1905.13655">Arora et al. 2019</a>):</strong>
Gradient flow (GD with infinitesimal step size) over matrix factorization initialized near zero leads the $r$’th singular value of $W_M$, denoted $\sigma_M^{(r)} (t)$, to evolve by:
[ 
    \color{brown}{\frac{d}{dt} \sigma_M^{(r)} (t) \propto \sigma_M^{(r)} (t)^{2 - 2/L}} ~.
]</p>
</blockquote>

<p>As can be seen from the theorem above, singular values evolve at a rate proportional to their size exponentiated by $2 - 2 / L$. This means that they are subject to a momentum-like effect, by which they move slower when small and faster when large. 
When initializing near the origin (as commonly done in practice), we therefore expect singular values to progress slowly at first, and then, upon reaching a certain threshold, to quickly rise until convergence. 
<strong>These dynamics create an incremental learning process that promotes solutions with few large singular values and many small ones, i.e. low matrix rank solutions</strong>.
In their paper, <a href="https://arxiv.org/abs/1905.13655">Arora et al. 2019</a> support this qualitative explanation through theoretical illustrations and empirical evaluations. 
For example, the following plot reproduces one of their experiments:</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/imp_reg_htf/mf_dyn_blog.png" style="width: 380px; padding-bottom: 0px; padding-top: 0px;"/>
<br/>
<i><b>Figure 1:</b> 
Dynamics of singular values during GD over matrix factorization <br/> — incremental learning leads to low matrix rank.
</i>
</div>
<p><br/>
We note that the incremental matrix rank learning phenomenon was later on used to prove exact matrix rank minimization, under certain technical conditions (<a href="https://arxiv.org/abs/2012.09839">Li et al. 2021</a>).</p>

<h3 id="tensor-factorization-incremental-tensor-rank-learning">Tensor factorization: Incremental tensor rank learning</h3>

<p>Despite the significant interest in matrix factorization, as a theoretical surrogate for deep learning its practical relevance is rather limited. 
It corresponds to linear neural networks, and thus misses non-linearity — a crucial aspect of modern neural networks.
As was mentioned in a <a href="https://www.offconvex.org/2021/07/08/imp-reg-tf/">previous post</a>, by moving from matrix (two-dimensional array) to tensor (multi-dimensional array) factorizations it is possible to address this limitation.</p>

<p>A classical scheme for factorizing tensors, named CANDECOMP/PARAFAC (CP), parameterizes a tensor as a sum of outer products (for more details on this scheme, see <a href="http://www.kolda.net/publication/TensorReview.pdf">this excellent survey</a>).
Given a loss $\mathcal{L}_T : \mathbb{R}^{D_1, \ldots, D_N} \to \mathbb{R}$ over $N$-dimensional tensors, e.g. $\mathcal{L}_T$ can be a tensor completion loss, we simply refer by <em>tensor factorization</em> to parameterizing the solution $\mathcal{W}_T \in \mathbb{R}^{D_1, \ldots, D_N}$ as a CP factorization, and minimizing the resulting objective via GD:</p>
<div style="text-align: center;">
\[
    \min\nolimits_{ \{ \mathbf{w}_r^n \}_{r , n} } \mathcal{L}_T \big ( \mathcal{W}_T \big ) := \mathcal{L}_T \big (  {\textstyle \sum}_{r = 1}^R \mathbf{w}_r^1 \otimes \cdots \otimes \mathbf{w}_r^N \big) ~.
\]
</div>
<p>Each term $\mathbf{w}_r^{(1)} \otimes \cdots \otimes \mathbf{w}_r^{(N)}$ in the sum is called a <em>component</em>, and $\otimes$ stands for outer product.
The concept of rank naturally extends from matrices to tensors.
For a given tensor $\mathcal{W}$, its <em>tensor rank</em> is defined to be the minimal number of components (i.e. of outer product summands) $R$ required for CP parameterization to express it.
Note that we can explicitly constrain the tensor rank of $\mathcal{W}_T$ by limiting the number of components $R$.
But, since our interest lies in implicit regularization, we consider the case where $R$ is large enough for any tensor to be expressed.</p>

<p>Similarly to how matrix factorization captures linear neural networks, tensor factorization is equivalent to certain <em>shallow non-linear</em> convolutional networks (with multiplicative non-linearity).
This equivalence was discussed in a couple of previous posts (<a href="https://www.offconvex.org/2020/11/27/reg_dl_not_norm/">1</a>, <a href="https://www.offconvex.org/2021/07/08/imp-reg-tf/">2</a>), for the exact details behind it feel free to check out the preliminaries section of <a href="https://arxiv.org/abs/2201.11729">our paper</a> and references therein.
The bottom line is that tensor factorization takes us one step closer to practical neural networks.</p>

<p>Motivated by the incremental learning dynamics in matrix factorization, in a <a href="https://arxiv.org/abs/2102.09972">previous paper</a> (see accompanying <a href="https://www.offconvex.org/2021/07/08/imp-reg-tf/">blog post</a>) we analyzed the behavior of component norms during optimization of tensor factorization:</p>

<blockquote>
  <p><strong>Theorem (informal; <a href="https://arxiv.org/abs/2102.09972">Razin et al. 2021</a>):</strong>
Gradient flow over tensor factorization initialized near zero leads the $r$’th component norm, $\sigma_T^{(r)} (t) := || \mathbf{w}_r^1 (t) \otimes \cdots \otimes \mathbf{w}_r^N (t) ||$, to evolve by:
[ 
    \color{brown}{\frac{d}{dt} \sigma_T^{(r)} (t) \propto \sigma_T^{(r)} (t)^{2 - 2/N}} ~.
]</p>
</blockquote>

<p>The dynamics of component norms in tensor factorization are structurally identical to those of singular values in matrix factorization.
Accordingly, we get a momentum-like effect that attenuates the movement of small component norms and accelerates that of large ones.
This suggests that, <strong>in analogy with matrix factorization, when initializing near zero components tend to be learned incrementally, resulting in a bias towards low tensor rank</strong>.
The following plot empirically demonstrates this phenomenon:</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/imp_reg_htf/tf_dyn_blog.png" style="width: 380px; padding-bottom: 0px; padding-top: 0px;"/>
<br/>
<i><b>Figure 2:</b> 
Dynamics of component norms during GD over tensor factorization <br/> — incremental learning leads to low tensor rank.
</i>
</div>
<p><br/>
Continuing with the analogy to matrix factorization, the incremental tensor rank learning phenomenon formed the basis for proving exact tensor rank minimization, under certain technical conditions (<a href="https://arxiv.org/abs/2102.09972">Razin et al. 2021</a>).</p>

<h2 id="hierarchical-tensor-factorization">Hierarchical Tensor Factorization</h2>

<p>Tensor factorization took us beyond linear predictors, yet it still lacks a critical feature of modern neural networks — depth (recall that it corresponds to <em>shallow</em> non-linear convolutional networks).
A natural extension that accounts for both non-linearity and depth is <em>hierarchical tensor factorization</em> — our protagonist — which corresponds to certain <em>deep</em> non-linear convolutional networks (with multiplicative non-linearity).
This equivalence is actually not new, and has facilitated numerous analyses of expressive power in deep learning (see <a href="https://arxiv.org/abs/1705.02302">this survey</a> for a high-level overview).</p>

<p>As opposed to tensor factorization, which is a simple construct dating back to at least the early 20’th century (<a href="https://onlinelibrary.wiley.com/doi/10.1002/sapm192761164">Hitchcock 1927</a>), hierarchical tensor factorization was formally introduced only recently (<a href="https://link.springer.com/article/10.1007/s00041-009-9094-9">Hackbusch &amp; Kuhn 2009</a>), and is much more elaborate.
Its exact definition is rather technical (the interested reader can find it in <a href="https://arxiv.org/abs/2201.11729">our paper</a>).
For our current purpose it suffices to know that a hierarchical tensor factorization consists of multiple local tensor factorizations, whose components we call the <em>local components</em> of the hierarchical factorization.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/imp_reg_htf/tf_htf_cnn_blog.png" style="width: 900px; padding-bottom: 15px; padding-top: 10px;"/>
<br/>
<i><b>Figure 3:</b> 
Tensor factorization, which is a sum of components (outer products), <br/> corresponds to a shallow non-linear convolutional neural network (CNN).
<br/> Hierarchical tensor factorization, which consists of multiple local tensor <br/> factorizations, corresponds to a deep non-linear CNN.
</i>
</div>
<p><br/>
In contrast to matrices, which have a single standard definition for rank, tensors posses several different definitions for rank.
Hierarchical tensor factorizations induce their own such notion, known as <em>hierarchical tensor rank</em>.
Basically, if a tensor can be represented through hierarchical tensor factorization with few local components, then it has low hierarchical tensor rank.
This stands in direct analogy with tensor rank, which is low if the tensor can be represented through tensor factorization with few components.</p>

<p>Seeing that the implicit regularization in matrix and tensor factorizations leads to low matrix and tensor ranks, respectively, in <a href="https://arxiv.org/abs/2201.11729">our paper</a> we investigated whether the implicit regularization in hierarchical tensor factorization leads to low hierarchical tensor rank. 
That is, whether GD (with small initialization and step size) over hierarchical tensor factorization learns solutions that can be represented with few local components.
Turns out it does.</p>

<h2 id="dynamical-analysis-incremental-hierarchical-tensor-rank-learning">Dynamical Analysis: Incremental Hierarchical Tensor Rank Learning</h2>

<p>At the heart of our analysis is the following dynamical characterization for local component norms during optimization of hierarchical tensor factorization:</p>

<blockquote>
  <p><strong>Theorem (informal):</strong>
Gradient flow over hierarchical tensor factorization initialized near zero leads the $r$’th local component norm in a local tensor factorization, denoted $\sigma_H^{(r)} (t)$, to evolve by:
[ 
    \color{brown}{\frac{d}{dt} \sigma_H^{(r)} (t) \propto \sigma_H^{(r)} (t)^{2 - 2/K}} ~,
]
where $K$ is the number of axes of the local tensor factorization.</p>
</blockquote>

<p>This should really feel like deja vu, as these <strong>dynamics are structurally identical to those of singular values in matrix factorization and component norms in tensor factorization!</strong>
Again, we have a momentum-like effect, by which local component norms move slower when small and faster when large.
As a result, <strong>when initializing near zero local components tend to be learned incrementally, yielding a bias towards low hierarchical tensor rank</strong>.
In <a href="https://arxiv.org/abs/2201.11729">the paper</a> we provide theoretical and empirical demonstrations of this phenomenon.
For example, the following plot shows the evolution of local component norms at some local tensor factorization under GD:</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/imp_reg_htf/htf_dyn_blog.png" style="width: 380px; padding-bottom: 0px; padding-top: 0px;"/>
<br/>
<i><b>Figure 4:</b> 
Dynamics of local component norms during GD over hierarchical <br/> tensor factorization — incremental learning leads to low hierarchical tensor rank.
</i>
</div>
<p><br/></p>

<h2 id="practical-implication-countering-locality-in-convolutional-networks-via-explicit-regularization">Practical Implication: Countering Locality in Convolutional Networks via Explicit Regularization</h2>

<p>We saw that in hierarchical tensor factorization GD leads to solutions of low hierarchical tensor rank.
But what does this even mean for the associated convolutional networks?</p>

<p>Hierarchical tensor rank is known (<a href="https://arxiv.org/abs/1605.06743">Cohen &amp; Shashua 2017</a>) to measure the strength of long-range dependencies modeled by a network.
In the context of image classification, e.g., it quantifies how well we take into account dependencies between distant patches of pixels.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/imp_reg_htf/local_vs_non_local_dep.png" style="width: 430px; padding-bottom: 8px; padding-top: 8px;"/>
<br/>
<i><b>Figure 5:</b> 
Illustration of short-range (local) vs. long-range dependencies in image data.
</i>
</div>
<p><br/>
<strong>The implicit regularization towards low hierarchical tensor rank in hierarchical tensor factorization therefore translates to an implicit regularization towards <em>locality</em> in the corresponding convolutional networks</strong>.
At first this may not seem surprising, since convolutional networks typically struggle or completely fail to learn tasks entailing long-range dependencies.
However, conventional wisdom attributes this failure to expressive properties (i.e. to an inability of convolutional networks to realize functions modeling long-range dependencies), suggesting that addressing the problem requires modifying the architecture.
Our analysis, on the other hand, reveals that implicit regularization also plays a role: it is not just a matter of expressive power, the optimization algorithm is implicitly pushing towards local solutions.
Inspired by this observation, we asked:</p>

<blockquote>
  <p><strong>Question:</strong>
Is it possible to improve the performance of modern convolutional networks on long-range tasks via explicit regularization (without modifying their architecture)?</p>
</blockquote>

<p>To explore this prospect, <strong>we designed explicit regularization that counteracts locality by promoting high hierarchical tensor rank (i.e. long-range dependencies)</strong>.
Then, through a series of controlled experiments, <strong>we confirmed that it can greatly improve the performance of modern convolutional networks (e.g. ResNets) on long-range tasks</strong>.</p>

<p>For example, the following plot displays test accuracies achieved by a ResNet on an image classification benchmark, in which it is possible to control the spatial range of dependencies required to model.
When increasing the range of dependencies, the test accuracy obtained by an unregularized network substantially deteriorates, reaching performance no better than random guessing.
As evident from the plot, our regularization closes the gap between short- and long-range tasks, significantly boosting generalization on the latter.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/imp_reg_htf/pathfinder_resnet18_with_reg_blog.png" style="width: 430px; padding-bottom: 0px; padding-top: 0px;"/>
<br/>
<i><b>Figure 6:</b> 
Specialized explicit regularization promoting high hierarchical tensor rank (i.e. long-range dependencies between image regions) can counter the locality of convolutional networks, significantly improving their performance on long-range tasks.
</i>
</div>
<p><br/></p>

<h2 id="concluding-thoughts">Concluding Thoughts</h2>
<p>Looking forward, there are two main takeaways from our work:</p>

<ol>
  <li>
    <p>Across three different neural network types (equivalent to matrix, tensor, and hierarchical tensor factorizations), we have an architecture-dependant notion of rank that is implicitly lowered. Moreover, the underlying mechanism for this implicit regularization is identical in all cases. This leads us to believe that implicit regularization towards low rank may be a general phenomenon. If true, finding notions of rank lowered for different architectures can facilitate an understanding of generalization in deep learning.</p>
  </li>
  <li>
    <p>Our findings imply that the tendency of modern convolutional networks towards locality may largely be due to implicit regularization, and not an inherent limitation of expressive power as often believed. More broadly, they showcase that deep learning architectures considered suboptimal for certain tasks can be greatly improved through a right choice of explicit regularization. 
Theoretical understanding of implicit regularization may be key to discovering such regularizers.</p>
  </li>
</ol>

<p><strong><em><a href="https://noamrazin.github.io/">Noam Razin</a></em></strong></p></div>
    </summary>
    <updated>2022-07-15T09:00:00Z</updated>
    <published>2022-07-15T09:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2022-07-20T00:02:59Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/102</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/102" rel="alternate" type="text/html"/>
    <title>TR22-102 |  Range Avoidance for Low-depth Circuits and Connections to Pseudorandomness | 

	Xiuhan Wang, 

	Venkatesan Guruswami, 

	Xin Lyu</title>
    <summary>In the range avoidance problem, the input is a multi-output Boolean circuit with more outputs than inputs, and the goal is to find a string outside its range (which is guaranteed to exist). We show that well-known explicit construction questions such as finding binary linear codes achieving the Gilbert-Varshamov bound or list-decoding capacity, and constructing rigid matrices, reduce to the range avoidance problem of log-depth circuits, and by a further recent reduction [Ren, Santhanam, and Wang, ECCC 2022] to $NC^0_4$ circuits where each output depends on at most $4$ input bits. 

On the algorithmic side, we show that range avoidance for $NC^0_2$ circuits can be solved in polynomial time. We identify a general condition relating to correlation with low-degree parities that implies that any almost pairwise independent set has some string that avoids the range of every circuit in the class. We apply this to $NC^0$ circuits, and to small width CNF/DNF and general De Morgan formulae (via a connection to approximate-degree), yielding non-trivial small hitting sets for range avoidance in these cases.</summary>
    <updated>2022-07-15T07:11:28Z</updated>
    <published>2022-07-15T07:11:28Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-07-20T10:37:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/07/15/postdoc-at-university-of-cologne-apply-by-august-31-2022/</id>
    <link href="https://cstheory-jobs.org/2022/07/15/postdoc-at-university-of-cologne-apply-by-august-31-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Cologne (apply by August 31, 2022)</title>
    <summary>A postdoc position in theoretical computer sciece, algorithms and data structures or algorithmic data analysis is available in the Algorithmic Data Analysis group led by Prof. Dr. Christian Sohler in the department of mathematics/computer science at University of Cologne. Website: https://jobportal.uni-koeln.de/ausschreibung/renderFile/893?propertyName=flyer Email: sohler@cs.uni-koeln.de</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A postdoc position in theoretical computer sciece, algorithms and data structures or algorithmic data analysis is available in the Algorithmic Data Analysis group led by Prof. Dr. Christian Sohler in the department of mathematics/computer science at University of Cologne.</p>
<p>Website: <a href="https://jobportal.uni-koeln.de/ausschreibung/renderFile/893?propertyName=flyer">https://jobportal.uni-koeln.de/ausschreibung/renderFile/893?propertyName=flyer</a><br/>
Email: sohler@cs.uni-koeln.de</p></div>
    </content>
    <updated>2022-07-15T06:10:56Z</updated>
    <published>2022-07-15T06:10:56Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-07-20T10:37:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/101</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/101" rel="alternate" type="text/html"/>
    <title>TR22-101 |  A Near-Cubic Lower Bound for 3-Query Locally Decodable Codes from Semirandom CSP Refutation | 

	Omar Alrabiah, 

	Pravesh Kothari, 

	Venkatesan Guruswami, 

	Peter Manohar</title>
    <summary>A code $C \colon \{0,1\}^k \to \{0,1\}^n$ is a $q$-locally decodable code ($q$-LDC) if one can recover any chosen bit $b_i$ of the message $b \in \{0,1\}^k$ with good confidence by randomly querying the encoding $x = C(b)$ on at most $q$ coordinates. Existing constructions of $2$-LDCs achieve $n = \exp(O(k))$, and lower bounds show that this is in fact tight. However, when $q = 3$, far less is known: the best constructions achieve $n = \exp(k^{o(1)})$, while the best known results only show a quadratic lower bound $n \geq \widetilde{\Omega}(k^2)$ on the blocklength.

In this paper, we prove a near-cubic lower bound of $n \geq \widetilde{\Omega}(k^3)$ on the blocklength of $3$-query LDCs. This improves on the best known prior works by a polynomial factor in $k$. Our proof relies on a new connection between LDCs and refuting constraint satisfaction problems with limited randomness. Our quantitative improvement builds on the new techniques for refuting semirandom instances of CSPs developed in [GKM22] and, in particular, relies on bounding the $(\infty \to 1)$-norm of appropriate Kikuchi matrices.</summary>
    <updated>2022-07-14T21:14:52Z</updated>
    <published>2022-07-14T21:14:52Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-07-20T10:37:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/100</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/100" rel="alternate" type="text/html"/>
    <title>TR22-100 |  Streaming complexity of CSPs with randomly ordered constraints | 

	Santhoshini Velusamy, 

	Noah Singer, 

	Raghuvansh Saxena, 

	Madhu Sudan</title>
    <summary>We initiate a study of the streaming complexity of constraint satisfaction problems (CSPs) when the constraints arrive in a random order. We show that there exists a CSP, namely Max-DICUT, for which random ordering makes a provable difference. Whereas a $4/9 \approx 0.445$ approximation of DICUT requires $\Omega(\sqrt{n})$ space with adversarial ordering, we show that with random ordering of constraints there exists a $0.48$-approximation algorithm that only needs $O(\log n)$ space. We also give new algorithms for Max-DICUT in variants of the adversarial ordering setting. Specifically, we give a two-pass  $O(\log n)$ space $0.48$-approximation algorithm for general graphs and a single-pass $\tilde{O}(\sqrt{n})$ space $0.48$-approximation algorithm for bounded degree graphs.
    
    On the negative side, we prove that CSPs where the satisfying assignments of the constraints support a one-wise independent distribution require $\Omega(\sqrt{n})$-space for any non-trivial approximation, even when the constraints are randomly ordered. This was previously known only for adversarially ordered constraints. Extending the results to randomly ordered constraints requires switching the hard instances from a union of random matchings to simple Erdos-Renyi random (hyper)graphs and extending tools that can perform Fourier analysis on such instances. 
    
    The only CSP to have been considered previously with random ordering is Max-CUT where the ordering is not known to change the approximability. Specifically, it is known to be as hard to approximate with random ordering as with adversarial ordering, for $o(\sqrt{n})$ space algorithms. Our results show a richer variety of possibilities and motivate further study of CSPs with randomly ordered constraints.</summary>
    <updated>2022-07-14T18:39:48Z</updated>
    <published>2022-07-14T18:39:48Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-07-20T10:37:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/099</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/099" rel="alternate" type="text/html"/>
    <title>TR22-099 |  Equivalence Test for Read-Once Arithmetic Formulas | 

	Nikhil Gupta, 

	Chandan Saha, 

	Bhargav Thankey</title>
    <summary>We study the polynomial equivalence problem for orbits of read-once arithmetic formulas (ROFs). Read-once formulas have received considerable attention in both algebraic and Boolean complexity and have served as a testbed for developing effective tools and techniques for analyzing circuits. Two $n$-variate polynomials $f, g \in \mathbb{F}[\mathbf{x}]$ are equivalent, denoted as $f \sim g$, if there is an $A \in \mathrm{GL}(n, \mathbb{F})$ such that $f = g(A\mathbf{x})$. The orbit of $f$ is the set of all polynomials equivalent to $f$. We investigate the complexity of the following two natural problems on ROFs:

1. Equivalence test for ROFs: Given black-box access to $f$, check if it is in the orbit of an ROF. If yes, output an ROF $C$ and an $A \in \mathrm{GL}(n, \mathbb{F})$ such that $f = C(A\mathbf{x})$.  
2. Polynomial equivalence for orbits of ROFs: Given black-box access to $f$ and $g$ in the orbits of two unknown ROFs, check if $f \sim g$. If yes, output an $A \in \mathrm{GL}(n, \mathbb{F})$ such that $f = g(A\mathbf{x})$.

These problems are significant generalizations of two well-studied problems in algebraic complexity, namely reconstruction of ROFs and quadratic form equivalence. In this work, we give the first randomized polynomial-time algorithms (with oracle access to quadratic form equivalence) to solve the two problems. The equivalence test works for general ROFs; it also implies an efficient learning algorithm for random arithmetic formulas of unbounded depth and fan-in (in the high number of variables setting). The algorithm for the second problem, which invokes the equivalence test, works for mildly restricted ROFs, namely additive-constant-free ROFs.  	
	
The equivalence test is based on a novel interplay between the factors and the essential variables of the Hessian determinant of an ROF, the essential variables of the ROF, and certain special structures in the ROF that we call "skewed paths". To our knowledge, the Hessian of a general ROF (or even a depth-4 ROF) has not been analyzed before. Analyzing the Hessian and combining the knowledge gained from it with the skewed paths to recursively discover formulas in the orbits of sub-ROFs of lower depth (without incurring an exponential blow-up due to unbounded depth) constitute the main technical contributions of this work.</summary>
    <updated>2022-07-14T12:43:08Z</updated>
    <published>2022-07-14T12:43:08Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-07-20T10:37:18Z</updated>
    </source>
  </entry>
</feed>
