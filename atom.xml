<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-04-29T09:43:24Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>https://11011110.github.io/blog/2021/04/28/how-good-greed</id>
    <link href="https://11011110.github.io/blog/2021/04/28/how-good-greed.html" rel="alternate" type="text/html"/>
    <title>How good is greed for the no-three-in-line problem?</title>
    <summary>The 37th European Workshop on Computational Geometry (EuroCG 2021) was earlier this month, but its book of abstracts remains online. This has an odd position in the world of academic publishing: the “abstracts” are really short papers, so it looks a lot like a published conference proceedings. However, it declares that you should really pretend that it’s not a proceedings, in order to allow the same work to go on to another conference with a published proceedings, getting around the usual prohibitions on double publication. Instead, its papers “should be considered a preprint rather than a formally reviewed paper”. But I think that doesn’t preclude citing them, with care, just as you might occasionally cite arXiv preprints. The workshop’s lack of peer review and selectivity is actually a useful feature, allowing it to act as an outlet for works that are too small or preliminary for publication elsewhere. In North America, the Canadian Conference on Computational Geometry performs much the same role, but does publish a proceedings; its submission deadline is rapidly approaching.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The <a href="http://eurocg21.spbu.ru/">37th European Workshop on Computational Geometry (EuroCG 2021)</a> was earlier this month, but its <a href="http://eurocg21.spbu.ru/wp-content/uploads/2021/04/proceedings.pdf">book of abstracts</a> remains online. This has an odd position in the world of academic publishing: the “abstracts” are really short papers, so it looks a lot like a published conference proceedings. However, it declares that you should really pretend that it’s not a proceedings, in order to allow the same work to go on to another conference with a published proceedings, getting around the usual prohibitions on double publication. Instead, its papers “should be considered a preprint rather than a formally reviewed paper”. But I think that doesn’t preclude citing them, with care, just as you might occasionally cite arXiv preprints. The workshop’s lack of peer review and selectivity is actually a useful feature, allowing it to act as an outlet for works that are too small or preliminary for publication elsewhere. In North America, the <a href="http://cccg.ca/">Canadian Conference on Computational Geometry</a> performs much the same role, but does publish a proceedings; its <a href="https://projects.cs.dal.ca/cccg2021/the-call-for-papers-is-out/">submission deadline</a> is rapidly approaching.</p>

<p>Anyway, one of the EuroCG not-really-a-published-paper things is mine: “Geometric dominating sets – A minimum version of the no-three-in-line problem”, with Oswin Aichholzer and Eva-Maria Hainzl. As the title suggests, it’s related to the <a href="https://en.wikipedia.org/wiki/No-three-in-line_problem">no-three-in-line problem</a>, in which one must place as many points as possible in a grid so that no three are collinear. I’ve written about the same problem here <a href="https://11011110.github.io/blog/2018/11/10/random-no-three.html">several</a> <a href="https://11011110.github.io/blog/2018/11/12/gurobi-vs-no.html">times</a> <a href="https://11011110.github.io/blog/2018/12/08/general-position-hypercube.html">already</a>. On an \(n\times n\) grid, there’s an easy upper bound of \(2n\) on the number of points, but it’s widely conjectured that the actual number is a smaller linear function of \(n\). It was a big step forward when Erdős showed that \(n\bigl(1-o(1)\bigr)\) points can be placed, and this was later improved to \(\tfrac{3}{2}n\bigl(1-o(1)\bigr)\).</p>

<p>These big no-three-in-line sets are constructed algebraically, but what if we try something simpler, a greedy algorithm that just adds points one by one (in a random or systematic order) until getting stuck? This question was already asked in the 1970s by Martin Gardner, and studied by several other authors since. But it is, if anything, even more frustratingly unknown than the no-three-in-line problem itself. We don’t know whether, in general, it’s possible to get stuck with fewer points than the maximum solution to the no-three-in-line problem, or even whether it’s possible to get stuck with fewer than \(2n\) points for infinitely many values of \(n\). For some values of \(n\) we do know smaller stuck solutions, though: for instance, here’s one with \(28\) points on a \(36\times 36\) grid.</p>

<p style="text-align: center;"><img alt="A 28-point greedy solution to the no-three-in-line problem on a 36x36 grid" src="https://11011110.github.io/blog/assets/2021/greedy-no3-36x36.svg"/></p>

<p>It was known that greedy solutions always have \(\Omega(\sqrt{n})\) points, and one of our main results is to improve this bound to \(\Omega(n^{2/3})\). The known \(\Omega(\sqrt{n})\) lower bound is easy to see: A single line through two selected points can cover at most \(n\) other grid points, so you need \(n\) lines to cover the whole grid, and you need \(\Omega(\sqrt{n})\) points to determine this many lines. With fewer points, there won’t be enough lines through your points to cover the whole grid, and your greedy solution won’t be stuck. Our new \(\Omega(n^{2/3})\) bound looks more carefully at the tradeoff between numbers of lines and numbers of points per line. It can be divided into two cases:</p>

<ul>
  <li>
    <p>Suppose, first, that the selected point set has the property that, for any selected point \(p\), the lines through \(p\) cover fewer than \(n^{4/3}\) grid points. Because each selected point covers few grid points, we need to select many points to cover the whole grid: at least \(\Omega(n^{2/3})\) points.</p>
  </li>
  <li>
    <p>Suppose on the other hand that the lines through some point \(p\) cover at least  \(n^{4/3}\) grid points. Parameterize these lines by the \(L_\infty\) distance to the closest grid point (regardless of whether that point is one of the selected ones). Then there are \(O(k)\) lines with parameter \(k\), each of which covers \(O(n/k)\) grid points. Summing over small values of \(k\) shows that, even if we use lines that cover as many grid points as possible, we need  \(\Omega(n^{2/3})\) lines through \(p\) to cover this many grid points. Each of these lines is determined by another selected point, so we need \(\Omega(n^{2/3})\) selected points.</p>
  </li>
</ul>

<p>The actual proof in the paper takes into account that not all the grid points near \(p\) are the nearest on their line, and does the summation over small values of \(k\) more carefully, to get more precise constant factors in the bounds. Our paper also includes another variation of the problem in which we allow our selected points to be collinear but require the lines through them to cover all unselected points. There, we can make a little progress: we show that \(n\) points, or in some cases slightly fewer than \(n\) points, are sufficient. The same \(\Omega(n^{2/3})\) lower bound is still valid for this case, but there’s still a big gap between the lower bound and the upper bound.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/106146843522019241">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2021-04-28T18:23:00Z</updated>
    <published>2021-04-28T18:23:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-04-29T04:59:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=18647</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/" rel="alternate" type="text/html"/>
    <title>Congrats to the New Members</title>
    <summary>If you know you are on the right track, if you have this inner knowledge, then nobody can turn you off no matter what they say—Barbara McClintock David Oxtoby is the president of AAAS. He just announced the 2021 new members. See the press release. Today I thought I would explain which choices are correct […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>If you know you are on the right track, if you have this inner knowledge, then nobody can turn you off <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> no matter what they say—Barbara McClintock</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/oxtobycropped/" rel="attachment wp-att-18671"><img alt="" class="alignright size-full wp-image-18671" height="150" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/oxtobyCropped.png?resize=121%2C150&amp;ssl=1" width="121"/></a></p>
<p>
David Oxtoby is the president of <a href="https://www.amacad.org/new-members-2021">AAAS</a>. He just announced the 2021 new members. See the <a href="https://www.amacad.org/news/2021-member-announcement">press release</a>.</p>
<p>
Today I thought I would explain which choices are correct and which are <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>
Just kidding. Of course they all are terrific choices. Here are some choices in previous years—going back a little while: </p>
<blockquote><p><b> </b> <em> The new class joins Academy members elected before them, including Benjamin Franklin (elected 1781) and Alexander Hamilton (1791) in the eighteenth century; Ralph Waldo Emerson (1864), Maria Mitchell (1848), and Charles Darwin (1874) in the nineteenth; Albert Einstein (1924), Robert Frost (1931), Margaret Mead (1948), Groucho Marx (1951), Milton Friedman (1959), Martin Luther King, Jr. (1966), and Anthony Fauci (1991) in the twentieth. </em>
</p></blockquote>
<p>
</p><p/><h2> Computer Science </h2><p/>
<p/><p>
Here they are with some fun facts.</p>
<p>
<a href="https://en.wikipedia.org/wiki/Demis_Hassabis">Demis Hassabis</a> (International Honorary Member), DeepMind <br/>
Child chess prodigy: at the age of 13 had an Elo rating of 2300.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/dh/" rel="attachment wp-att-18657"><img alt="" class="aligncenter size-thumbnail wp-image-18657" height="150" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/dh-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://en.wikipedia.org/wiki/Charles_Lee_Isbell_Jr.">Charles Isbell</a>, Georgia Institute of Technology <br/>
Started the Black History Database. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/ci/" rel="attachment wp-att-18659"><img alt="" class="aligncenter size-thumbnail wp-image-18659" height="150" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ci-150x150.jpg?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://en.wikipedia.org/wiki/Fei-Fei_Li">Fei-Fei Li</a>, Stanford University <br/>
Helped create ImageNet. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/fl/" rel="attachment wp-att-18660"><img alt="" class="aligncenter size-thumbnail wp-image-18660" height="150" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/fl-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://www.linkedin.com/in/murielmedard/">Muriel Medard</a>, Massachusetts Institute of Technology <br/>
Co-founded multiple companies. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/mm-3/" rel="attachment wp-att-18661"><img alt="" class="aligncenter size-thumbnail wp-image-18661" height="150" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/mm-1-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://en.wikipedia.org/wiki/Stefan_Savage">Stefan Savage</a>, University of California, San Diego <br/>
Uses cool names for projects: Jetset, Trufflehunter, <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/ss/" rel="attachment wp-att-18666"><img alt="" class="aligncenter size-thumbnail wp-image-18666" height="150" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ss-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://en.wikipedia.org/wiki/Margo_Seltzer">Margo Seltzer</a>, University of British Columbia <br/>
Very busy: see her <a href="https://www.seltzer.com/margo/calendar/">calendar</a> </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/ms-2/" rel="attachment wp-att-18663"><img alt="" class="aligncenter size-thumbnail wp-image-18663" height="150" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ms-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://en.wikipedia.org/wiki/Daniel_Spielman">Daniel Spielman</a>, Yale University <br/>
Once held a professorship named for “Hank the Deuce” or “HF2”. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/ds/" rel="attachment wp-att-18664"><img alt="" class="aligncenter size-thumbnail wp-image-18664" height="150" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ds-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
[re-aligned photo at top]</p>
<p/><h2> Mathematics </h2><p/>
<p/><p>
<a href="https://en.wikipedia.org/wiki/Yakov_Eliashberg">Yakov Eliashberg</a>, Stanford University <br/>
<a href="https://en.wikipedia.org/wiki/Benson_Farb">Benson Farb</a>, University of Chicago <br/>
<a href="https://www.math.nyu.edu/faculty/masmoudi/">Nader Masmoudi</a>, New York University <br/>
<a href="https://en.wikipedia.org/wiki/Kavita_Ramanan">Kavita Ramanan</a>, Brown University <br/>
<a href="https://en.wikipedia.org/wiki/Scott_D._Sheffield">Scott Sheffield</a>, Massachusetts Institute of Technology <br/>
<a href="https://en.wikipedia.org/wiki/Karen_E._Smith">Karen Smith</a>, University of Michigan <br/>
<a href="https://en.wikipedia.org/wiki/Amie_Wilkinson">Amie Wilkinson</a>, University of Chicago </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Do you have better fun facts on the winners? Let us know if you do.</p>
<p/></font></font></div>
    </content>
    <updated>2021-04-28T16:20:07Z</updated>
    <published>2021-04-28T16:20:07Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="AAAS"/>
    <category term="Awards"/>
    <category term="congrats"/>
    <category term="new members"/>
    <category term="who"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-04-29T09:38:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2104.13362</id>
    <link href="http://arxiv.org/abs/2104.13362" rel="alternate" type="text/html"/>
    <title>There is no APTAS for 2-dimensional vector bin packing: Revisited</title>
    <feedworld_mtime>1619568000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Arka Ray <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2104.13362">PDF</a><br/><b>Abstract: </b>In the Bin Packing problem, given a set of items, the objective is to find a
packing of the items into the minimum number of bins possible. Vector Bin
Packing is a natural generalization of the classic bin packing problem where
given a set of $d$-dimensional vectors from $(0,1]^d$, and the aim is to
partition the set into bins such that for each bin B, we have
$\left\|\sum_{v\in B}v\right\|_\infty\leq 1$. Woeginger claimed to prove (in
[Woe97]) that the problem has no APTAS for dimensions greater than 2.
</p>
<p>We note that there was a slight oversight in the original proof. Hence, we
give a revised proof using some additional ideas from [BCKS06]. In fact, we
show that it is NP-hard to get an asymptotic approximation ratio better than
$\frac{600}{599}$.
</p></div>
    </summary>
    <updated>2021-04-28T22:53:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2104.13209</id>
    <link href="http://arxiv.org/abs/2104.13209" rel="alternate" type="text/html"/>
    <title>K-Clique Counting on GPUs</title>
    <feedworld_mtime>1619568000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Almasri:Mohammad.html">Mohammad Almasri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hajj:Izzat_El.html">Izzat El Hajj</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nagi:Rakesh.html">Rakesh Nagi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xiong:Jinjun.html">Jinjun Xiong</a>, Wen-mei Hwu <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2104.13209">PDF</a><br/><b>Abstract: </b>Counting k-cliques in a graph is an important problem in graph analysis with
many applications. Counting k-cliques is typically done by traversing search
trees starting at each vertex in the graph. An important optimization is to
eliminate search tree branches that discover the same clique redundantly.
Eliminating redundant clique discovery is typically done via graph orientation
or pivoting. Parallel implementations for both of these approaches have
demonstrated promising performance on CPUs. In this paper, we present our GPU
implementations of k-clique counting for both the graph orientation and
pivoting approaches. Our implementations explore both vertex-centric and
edge-centric parallelization schemes, and replace recursive search tree
traversal with iterative traversal based on an explicitly-managed shared stack.
We also apply various optimizations to reduce memory consumption and improve
the utilization of parallel execution resources. Our evaluation shows that our
best GPU implementation outperforms the best state-of-the-art parallel CPU
implementation by a geometric mean speedup of 12.39x, 6.21x, and 18.99x for k =
4, 7, and 10, respectively. We also evaluate the impact of the choice of
parallelization scheme and the incremental speedup of each optimization. Our
code will be open-sourced to enable further research on parallelizing k-clique
counting on GPUs.
</p></div>
    </summary>
    <updated>2021-04-28T22:55:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2104.13174</id>
    <link href="http://arxiv.org/abs/2104.13174" rel="alternate" type="text/html"/>
    <title>Poncelet Guitar Picks</title>
    <feedworld_mtime>1619568000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaud:Daniel.html">Daniel Jaud</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Reznik:Dan.html">Dan Reznik</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garcia:Ronaldo.html">Ronaldo Garcia</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2104.13174">PDF</a><br/><b>Abstract: </b>We show that Poncelet 3-periodics in a confocal pair (elliptic billiard)
conserve the same sum of cosines as their affine image with a fixed incircle.
Cosine triples in either family sweep the same planar curve: an equilateral
cubic resembling a guitar pick. We also show that the family of excentral
triangles to the confocal family conserves the same product of cosines as its
affine image with fixed circumcircle. In cosine space cosine triples in either
family sweep the same spherical curve. The associated planar curve in log
cosine space is also shaped as guitar pick, though rounder than the one swept
by its parent confocal family.
</p></div>
    </summary>
    <updated>2021-04-28T22:58:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2104.13098</id>
    <link href="http://arxiv.org/abs/2104.13098" rel="alternate" type="text/html"/>
    <title>Fully-dynamic Weighted Matching Approximation in Practice</title>
    <feedworld_mtime>1619568000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Angriman:Eugenio.html">Eugenio Angriman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meyerhenke:Henning.html">Henning Meyerhenke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schulz:Christian.html">Christian Schulz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/U=ccedil=ar:Bora.html">Bora Uçar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2104.13098">PDF</a><br/><b>Abstract: </b>Finding large or heavy matchings in graphs is a ubiquitous combinatorial
optimization problem. In this paper, we engineer the first non-trivial
implementations for approximating the dynamic weighted matching problem. Our
first algorithm is based on random walks/paths combined with dynamic
programming. The second algorithm has been introduced by Stubbs and Williams
without an implementation. Roughly speaking, their algorithm uses dynamic
unweighted matching algorithms as a subroutine (within a multilevel approach);
this allows us to use previous work on dynamic unweighted matching algorithms
as a black box in order to obtain a fully-dynamic weighted matching algorithm.
We empirically study the algorithms on an extensive set of dynamic instances
and compare them with optimal weighted matchings. Our experiments show that the
random walk algorithm typically fares much better than Stubbs/Williams
(regarding the time/quality tradeoff), and its results are often not far from
the optimum.
</p></div>
    </summary>
    <updated>2021-04-28T22:54:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2104.13097</id>
    <link href="http://arxiv.org/abs/2104.13097" rel="alternate" type="text/html"/>
    <title>Minimum Stable Cut and Treewidth</title>
    <feedworld_mtime>1619568000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lampis:Michael.html">Michael Lampis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2104.13097">PDF</a><br/><b>Abstract: </b>A stable cut of a graph is a cut whose weight cannot be increased by changing
the side of a single vertex. Equivalently, a cut is stable if all vertices have
the (weighted) majority of their neighbors on the other side. In this paper we
study Min Stable Cut, the problem of finding a stable cut of minimum weight,
which is closely related to the Price of Anarchy of the Max Cut game. Since
this problem is NP-hard, we study its complexity on graphs of low treewidth,
low degree, or both. We show that the problem is weakly NP-hard on severely
restricted trees, so bounding treewidth alone cannot make it tractable. We
match this with a pseudo-polynomial DP algorithm running in time $(\Delta\cdot
W)^{O(tw)}n^{O(1)}$, where $tw$ is the treewidth, $\Delta$ the maximum degree,
and $W$ the maximum weight. On the other hand, bounding $\Delta$ is also not
enough, as the problem is NP-hard for unweighted graphs of bounded degree. We
therefore parameterize Min Stable Cut by both $tw+\Delta$ and obtain an FPT
algorithm running in time $2^{O(\Delta tw)}(n+\log W)^{O(1)}$. Our main result
is to provide a reduction showing that both aforementioned algorithms are
essentially optimal, even if we replace treewidth by pathwidth: if there exists
an algorithm running in $(nW)^{o(pw)}$ or $2^{o(\Delta pw)}(n+\log W)^{O(1)}$,
then the ETH is false. Complementing this, we show that we can obtain an FPT
approximation scheme parameterized by treewidth, if we consider almost-stable
solutions.
</p>
<p>Motivated by these mostly negative results, we consider Unweighted Min Stable
Cut. Here our results already imply a much faster exact algorithm running in
time $\Delta^{O(tw)}n^{O(1)}$. We show that this is also probably essentially
optimal: an algorithm running in $n^{o(pw)}$ would contradict the ETH.
</p></div>
    </summary>
    <updated>2021-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2104.12946</id>
    <link href="http://arxiv.org/abs/2104.12946" rel="alternate" type="text/html"/>
    <title>Exponentially Improved Dimensionality Reduction for $\ell_1$: Subspace Embeddings and Independence Testing</title>
    <feedworld_mtime>1619568000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Yi.html">Yi Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a>, Taisuke Yasuda <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2104.12946">PDF</a><br/><b>Abstract: </b>Despite many applications, dimensionality reduction in the $\ell_1$-norm is
much less understood than in the Euclidean norm. We give two new oblivious
dimensionality reduction techniques for the $\ell_1$-norm which improve
exponentially over prior ones:
</p>
<p>1. We design a distribution over random matrices $S \in \mathbb{R}^{r \times
n}$, where $r = 2^{\textrm{poly}(d/(\varepsilon \delta))}$, such that given any
matrix $A \in \mathbb{R}^{n \times d}$, with probability at least $1-\delta$,
simultaneously for all $x$, $\|SAx\|_1 = (1 \pm \varepsilon)\|Ax\|_1$. Note
that $S$ is linear, does not depend on $A$, and maps $\ell_1$ into $\ell_1$.
Our distribution provides an exponential improvement on the previous best known
map of Wang and Woodruff (SODA, 2019), which required $r = 2^{2^{\Omega(d)}}$,
even for constant $\varepsilon$ and $\delta$. Our bound is optimal, up to a
polynomial factor in the exponent, given a known $2^{\sqrt d}$ lower bound for
constant $\varepsilon$ and $\delta$.
</p>
<p>2. We design a distribution over matrices $S \in \mathbb{R}^{k \times n}$,
where $k = 2^{O(q^2)}(\varepsilon^{-1} q \log d)^{O(q)}$, such that given any
$q$-mode tensor $A \in (\mathbb{R}^{d})^{\otimes q}$, one can estimate the
entrywise $\ell_1$-norm $\|A\|_1$ from $S(A)$. Moreover, $S = S^1 \otimes S^2
\otimes \cdots \otimes S^q$ and so given vectors $u_1, \ldots, u_q \in
\mathbb{R}^d$, one can compute $S(u_1 \otimes u_2 \otimes \cdots \otimes u_q)$
in time $2^{O(q^2)}(\varepsilon^{-1} q \log d)^{O(q)}$, which is much faster
than the $d^q$ time required to form $u_1 \otimes u_2 \otimes \cdots \otimes
u_q$. Our linear map gives a streaming algorithm for independence testing using
space $2^{O(q^2)}(\varepsilon^{-1} q \log d)^{O(q)}$, improving the previous
doubly exponential $(\varepsilon^{-1} \log d)^{q^{O(q)}}$ space bound of
Braverman and Ostrovsky (STOC, 2010).
</p></div>
    </summary>
    <updated>2021-04-28T22:39:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2104.12800</id>
    <link href="http://arxiv.org/abs/2104.12800" rel="alternate" type="text/html"/>
    <title>Beyond PCSP(1-in-3,NAE)</title>
    <feedworld_mtime>1619568000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brandts:Alex.html">Alex Brandts</a>, Stanislav Živný <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2104.12800">PDF</a><br/><b>Abstract: </b>The promise constraint satisfaction problem (PCSP) is a recently introduced
vast generalisation of the constraint satisfaction problem (CSP) that captures
approximability of satisfiable instances. A PCSP instance comes with two forms
of each constraint: a strict one and a weak one. Given the promise that a
solution exists using the strict constraints, the task is to find a solution
using the weak constraints. While there are by now several dichotomy results
for fragments of PCSPs, they all consider (in some way) symmetric PCSPs.
</p>
<p>1-in-3-SAT and Not-All-Equal-3-SAT are classic examples of Boolean symmetric
(non-promise) CSPs. While both problems are NP-hard, Brakensiek and Guruswami
showed [SODA'18] that given a satisfiable instance of 1-in-3-SAT one can find a
solution to the corresponding instance of (weaker) Not-All-Equal-3-SAT. In
other words, the PCSP template (1-in-3,NAE) is tractable.
</p>
<p>We focus on non-symmetric PCSPs. In particular, we study PCSP templates
obtained from the Boolean template (t-in-k,NAE) by either adding tuples to
t-in-k or removing tuples from NAE. For the former, we classify all templates
as either tractable or not solvable by the currently strongest known algorithm
for PCSPs, the combined basic LP and affine IP relaxation of Brakensiek and
Guruswami [SODA'20]. For the latter, we classify all templates as either
tractable or NP-hard.
</p></div>
    </summary>
    <updated>2021-04-28T22:39:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2012.02617</id>
    <link href="http://arxiv.org/abs/2012.02617" rel="alternate" type="text/html"/>
    <title>On Line Sum Optimization</title>
    <feedworld_mtime>1619568000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Onn:Shmuel.html">Shmuel Onn</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2012.02617">PDF</a><br/><b>Abstract: </b>We show that the {\em column sum optimization problem}, of finding a
$(0,1)$-matrix with prescribed row sums which minimizes the sum of evaluations
of given functions at its column sums, can be solved in polynomial time, either
when all functions are the same or when all row sums are bounded by any
constant. We conjecture that the more general {\em line sum optimization
problem}, of finding a matrix minimizing the sum of given functions evaluated
at its row sums and column sums, can also be solved in polynomial time.
</p></div>
    </summary>
    <updated>2021-04-28T22:53:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.09932</id>
    <link href="http://arxiv.org/abs/2011.09932" rel="alternate" type="text/html"/>
    <title>Uniform and Monotone Line Sum Optimization</title>
    <feedworld_mtime>1619568000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Martin Koutecky, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Onn:Shmuel.html">Shmuel Onn</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.09932">PDF</a><br/><b>Abstract: </b>The {\em line sum optimization problem} asks for a $(0,1)$-matrix minimizing
the sum of given functions evaluated at its row and column sums. We show that
the {\em uniform} problem, with identical row functions and identical column
functions, and the {\em monotone} problem, over matrices with nonincreasing row
and column sums, are polynomial time solvable.
</p></div>
    </summary>
    <updated>2021-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8105</id>
    <link href="https://windowsontheory.org/2021/04/27/google-research-workshop-on-deep-learning-theory/" rel="alternate" type="text/html"/>
    <title>Google Research Workshop on Deep Learning Theory</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">[Guest post from Pranjal Awasthi and Rina Panigrahy – workshop looks great! –Boaz] Please join us for a virtual Google workshop on “Conceptual Understanding of Deep Learning”  When: May 17th 9am-4pm. Where: Live over Youtube, Goal: How does the Brain/Mind (perhaps even an artificial one) work at an algorithmic level? While deep learning has produced tremendous technological … <a class="more-link" href="https://windowsontheory.org/2021/04/27/google-research-workshop-on-deep-learning-theory/">Continue reading <span class="screen-reader-text">Google Research Workshop on Deep Learning Theory</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>[Guest post from Pranjal Awasthi and Rina Panigrahy – workshop looks great! –Boaz]</em><br/></p>



<p>Please join us for a virtual Google workshop on “<a href="https://sites.google.com/view/conceptualdlworkshop/home" rel="noreferrer noopener" target="_blank">Conceptual Understanding of Deep Learning</a>” </p>



<p>When: May 17th 9am-4pm. Where: <a href="https://www.youtube.com/watch?v=g5DGBWjiULQ" rel="noreferrer noopener" target="_blank">Live over Youtube</a>,</p>



<p><strong>Goal: </strong>How does the Brain/Mind (perhaps even an artificial one) work at an algorithmic level? While deep learning has produced tremendous technological strides in recent decades, there is an unsettling feeling of a lack of “conceptual” understanding of why it works and to what extent it will work in the current form. The goal of the workshop is to bring together theorists and practitioners to develop an understanding of the right algorithmic view of deep learning, characterizing the class of functions that can be learned, coming up with the right learning architecture that may (provably) learn multiple functions, concepts and remember them over time as humans do, theoretical understanding of language, logic, RL, meta learning and lifelong learning.</p>



<p>The speakers and panelists include Turing award winners Geoffrey Hinton, Leslie Valiant, and Godel Prize winner Christos Papadimitriou (<a href="https://sites.google.com/corp/view/conceptualdlworkshop/home" rel="noreferrer noopener" target="_blank">full-details</a>).   </p>



<p><strong>Panel Discussion: </strong>There will also be a panel discussion on the fundamental question of “Is there a mathematical model for the Mind?”. We will explore basic questions such as “Is there a provable algorithm that captures the essential capabilities of the mind?”, “How do we remember complex phenomena?”, “How is a knowledge graph created automatically?”, “How do we learn new concepts, function and action hierarchies over time?” and “Why do human decisions seem so interpretable?”<br/><br/>Twitter:<a href="https://twitter.com/search?q=%23ConceptualDLWorkshop&amp;src=recent_search_click" rel="noreferrer noopener" target="_blank"> #ConceptualDLWorkshop</a>. Please help advertise on mailing-lists/blog-posts and <a href="https://twitter.com/rinapy/status/1384311169519788032" rel="noreferrer noopener" target="_blank">Retweet</a>.<br/>Hope to see you there!</p>



<p>Rina Panigrahy<br/>(<a href="http://theory.stanford.edu/~rinap" rel="noreferrer noopener" target="_blank">http://theory.stanford.edu/~rinap</a>)</p></div>
    </content>
    <updated>2021-04-27T18:55:31Z</updated>
    <published>2021-04-27T18:55:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-04-29T09:40:13Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/alt-highlights/</id>
    <link href="https://differentialprivacy.org/alt-highlights/" rel="alternate" type="text/html"/>
    <title>ALT Highlights - An Equivalence between Private Learning and Online Learning (ALT '21 Tutorial)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference <a href="http://algorithmiclearningtheory.org/alt2021/">ALT 2021</a>, including plenary talks, tutorials, trends in learning theory, and more! 
To reach a broad audience, the series will be disseminated as guest posts on different blogs in machine learning and theoretical computer science. 
Given the topic of this post, we felt <a href="https://differentialprivacy.org/">DifferentialPrivacy.org</a> was a great fit.
This initiative is organized by the <a href="https://www.let-all.com/">Learning Theory Alliance</a>, and overseen by <a href="http://www.gautamkamath.com/">Gautam Kamath</a>. 
All posts in ALT Highlights are indexed on the official <a href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/">Learning Theory Alliance blog</a>.</p>

<p>The second post is coverage of <a href="http://www.cs.technion.ac.il/~shaymrn">Shay Moran</a>’s <a href="https://www.youtube.com/watch?v=wk910Aj559A">tutorial</a>, by <a href="https://people.eecs.berkeley.edu/~kush/">Kush Bhatia</a> and <a href="https://web.stanford.edu/~mglasgow/">Margalit Glasgow</a>.</p>

<hr/>

<p>The tutorial at ALT was given by <a href="http://www.cs.technion.ac.il/~shaymrn/">Shay Moran</a>, an assistant professor at the Technion in Haifa.
His <a href="https://www.youtube.com/watch?v=wk910Aj559A">talk</a> focused on recent results showing a deep connection between two important areas in learning theory: online learning and differentially private learning. 
While online learning is a well-established area that has been studied since the invention of the Perceptron algorithm in 1954, differential privacy (DP) - introduced in the seminal work of Dwork, McSherry, Nissim, and Smith in 2006 <a href="https://journalprivacyconfidentiality.org/index.php/jpc/article/view/405"><strong>[DMNS06]</strong></a> - has received increasing attention in recent years from both theoretical and applied research communities along with industry and the government. 
This recent interest in differential privacy comes from a need to protect the privacy rights of the individuals, while still allowing one to derive useful conclusions from the dataset.
Shay, in a sequence of papers with co-authors Noga Alon, Mark Bun, Roi Livni, and Maryanthe Malliaris, revealed a surprising qualitative connection between these two models of learning: a concept class can be learned in an online fashion if and only if this concept class can be learned in an offline fashion by a differentially private algorithm.</p>

<p>The main objectives of this tutorial were to give an in-depth foray into this recent work, and present an opportunity to young researchers to identify interesting research problems at the intersection of these two fields. This line of work (<a href="https://arxiv.org/abs/1806.00949"><strong>[ALMM19]</strong></a>, <a href="https://arxiv.org/abs/2003.00563"><strong>[BLM20]</strong></a>) - which has been primarily featured in general CS Theory conferences, including recently winning a best paper award at FOCS -  introduced several new techniques which could be of use to the machine learning theory community. The first part of this article focuses on the technical challenges of characterizing DP learnability and the solutions used in Shay’s work, which originate from combinatorics and model theory. In the rest of this article, we highlight some of the exciting open directions Shay sees more broadly in learning theory.</p>

<h2 id="background-pac-learning-online-learning-and-dp-pac-learning">Background: PAC Learning, Online Learning, and DP PAC Learning</h2>

<p>We begin by reviewing the classical setting of PAC learning. 
The goal of PAC learning is to learn some function from a <em>concept class</em> \(\mathcal{H} \), a set of functions from some domain \( \mathcal{X} \) to \( \{0, 1\} \). 
<img align="right" src="https://differentialprivacy.org/images/PACLearning.png" style="width: 300px; height: 300px;"/> 
In the realizable setting of PAC learning, which we will focus on here, the learner is presented with \( n \) labeled training samples \( \{(x_i, y_i)\}_{i=1}^{n} \) where \( x_i \in \mathcal{X} \) and \( y_i = h(x_i) \) for some function \( h \in \mathcal{H} \). While the learner knows the concept class \( \mathcal{H} \), the function \( h \) is unknown, and after seeing the \( n \) samples, the learner algorithm \( A \) must output some function \( \hat{h}: \mathcal{X} \rightarrow \{0, 1\} \). A concept class is <em>PAC-learnable</em> if there exists an algorithm \( A \) such that for any distribution over samples, as the number of labeled training samples goes to infinity, the probability that \( \hat{h} \) incorrectly labels a new random sample goes to 0. We will say that \( A \) is a <em>proper</em> learner if \( A \) outputs a function in \(\mathcal{H}\), while \( A \) is <em>improper</em> if it may output a function outside of \( \mathcal{H} \). More quantitative measures of learnability concern the exact number of samples \( n \) needed for the learner to correctly predict future labels with nontrivial probability.</p>

<p>DP PAC learning imposes an additional restriction on PAC learning: the learner must output a function which does not reveal too much about any one sample in the input. Formally, we say an algorithm \( A \) is \( (\varepsilon, \delta) \)-DP if for any two neighboring inputs \( X = (X_1, \cdots,  X_i, \cdots, X_n) \) and \( X’ = (X_1, \cdots, X_i’,\cdots, X_n) \) which differ at exactly one sample, for any set \( S \), \( \Pr[A(X) \in S] \leq e^\varepsilon Pr[A(X’) \in S] + \delta \) . A concept class is <em>DP PAC learnable</em> if it can be PAC-learned by a \( (0.1, o(1/n)) \)-DP algorithm \( A \). That is, changing any one training sample \( (x_i, y_i) \) should not affect the distribution over concepts output by \( A \) by too much.</p>

<p>Online learning considers a setting where the samples arrive one-by-one, and the learner must make predictions as this process unfolds. <img align="right" src="https://differentialprivacy.org/images/OnlineLearning.png" style="width: 300px; height: 300px;"/>Formally, in realizable online learning, at each round \( i = 1,\dots,T \), the learner is presented with a sample \( x_i\). The learner must predict the label, and then the true label \( y_i \) is revealed to the learner. The sequence of examples \( x_i \) and the labels \( y_i \) may be chosen adversarially, but they must be consistent with some function \( h \in \mathcal{H} \). The goal of the learner is to minimize the total number of mistakes made by round \( T \), also called the <em>mistake bound</em>. If there is a learner such that at \( T \rightarrow \infty \), the number of mistakes is \( o(T) \), we say that the class of functions \( \mathcal{H} \) is <em>online learnable</em>. Because of the adversarial nature of the examples, online learning is well known to be much harder than PAC learning, and is possible precisely when the <em>Littlestone Dimension</em> of the concept class is finite. Figure 1 below illustrates the definition of the Littlestone Dimension. One important PAC-learnable concept class which is not online learnable is the infinite class of thresholds on \( \mathbb{R} \): The set of functions \(\{h_t\}_{t \in \mathbb{R}} \) where \( h_t(x) = \textbf{1}(x &gt; t) \).</p>

<p><img alt="Figure 1: Littlestone Dimension" src="https://differentialprivacy.org/images/LD.png" title="Figure 1: Littlestone Dimension"/></p>

<p><strong>Figure 1</strong>: The Littlestone dimension is the maximum depth of a tree shattered by \( \mathcal{H} \), where each node may contain a unique element from \(\mathcal{X}\). The tree is shattered if each leaf can be labeled by a function in \(\mathcal{H} \) that labels each element on the path to the root according to the value of the edge entering it. In this figure, we show how the set of thresholds on \( [0, 1] \) shatters this tree of depth 3.</p>

<p>It’s worth taking a moment to understand intuitively why learning thresholds might be hard for both an online learner and a DP learner. In an online setting, suppose the adversary chooses the next example to be any value of \( x \) in between all previously 0-labeled examples and all 1-labeled examples. Then no matter what label \( A \) chooses, the adversary can say \( A \) was incorrect. In a DP setting, a simple proper learner that outputs a threshold that makes no errors on the training data will reveal too much information about the samples at the boundary of 0-labeled samples and 1-labeled samples.</p>

<h2 id="a-challenging-question">A Challenging Question</h2>

<p>The journey to characterizing DP PAC learnability started soon after the introduction of DP, in <a href="https://arxiv.org/abs/0803.0924"><strong>[KLNRS08]</strong></a>, where the concept of DP PAC learning was introduced. This work primarily considered the more stringent <em>pure</em> DP-learning, where \( \delta = 0\). This work established that any finite concept class could be learned privately by applying the <em>exponential mechanism</em> (a standard technique in DP) to the empirical error of each candidate concept. Using the exponential mechanism, the learner could output each function \( h \in \mathcal{H}\) with probability proportional to \( \exp(- \varepsilon(\# \text{ of errors h on the training data})) \). This was sufficiently private because the empirical error is not too sensitive to a change of one training sample. Later works <a href="https://arxiv.org/abs/1402.2224"><strong>[BNS14]</strong></a> combinatorially characterized the complexity of pure DP PAC learning in terms of a measure called <em>representation dimension</em>, showing that in some cases where PAC learning was possible, pure DP PAC learning was not. <a href="https://arxiv.org/abs/1504.07553"><strong>[BNSV15]</strong></a> further yielded lower bounds on the limits of proper DP PAC learning.<sup id="fnref:1"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:1" rel="footnote">1</a></sup><br/>
Both pure and proper DP learning though are significantly more stringent than improper DP learning, and proving lower bounds against an improper DP learner posed a serious challenge. Even the following simple-sounding question was unsolved:</p>

<blockquote>
  <p>Can an improper DP algorithm learn the infinite class of thresholds over [0, 1]? (*)</p>
</blockquote>

<p>This question stands at the center of Shay’s work, which unfolded while Shay was residing at the Institute for Advanced Study (IAS) at Princeton from 2017 to 2019.<sup id="fnref:2"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:2" rel="footnote">2</a></sup> At the time, Shay was working on understanding the expressivity of limited mutual-information algorithms, that is, algorithms which expose little information about the total input. “If we were to have directly worked on this problem, I believe we wouldn’t have solved it,” Shay says. Instead, they came from the angle of mutual-information, a concept qualitatively similar to DP, but armed with a rich toolkit from 70 years of information theory. One of Shay’s prior works with Raef Bassily, Ido Nachum, Jonathan Shafer, and Amir Yehudayof established lower bounds on the mutual information of any proper algorithm that learns thresholds <a href="https://arxiv.org/abs/1710.05233"><strong>[BMNSY18]</strong></a>, though this didn’t yet address the challenge presented by improper learners.</p>

<p>Unlike most lower bounds in theoretical computer science, proving hardness of learning the infinite class of thresholds on the line against an improper DP algorithm would require coming up with algorithm-specific distributions over samples. That is, instead of showing that one distribution over samples would be impossible to learn for all algorithms — in the way the a uniform distribution over the set in \(\mathcal{X}\) shattered by the concept class is hard to PAC-learn for any algorithm — they would have to come up with a distribution on \(\mathcal{X}\) specific to each candidate learning algorithm. Indeed, if the distribution was known to the learner, it was possible to devise a DP algorithm using the exponential mechanism (again!) which could learn any PAC-learnable concept class. Similar to the case of finite concept classes, here we can apply the exponential mechanism to some finite set of representative functions forming a cover of the concept class.</p>

<h2 id="uncovering-a-solution">Uncovering a Solution</h2>

<p>At the IAS, Shay met his initial team to tackle this obstacle: Noga Alon, a combinatorialist, Roi Livni, a learning theorist, and Maryanthe Malliaris, a model theorist. Shay and Maryanthe would walk together from IAS to their combinatorics class at Princeton taught by Noga and discuss mathematics. While Marayathe studied the abstract mathematical field of model theory, Shay and Maryanthe soon noticed a connection between model theory and machine learning: the Littlestone dimension. “There is applied math, then pure math, and then model theory is way over there,” Shay elaborates. “If theoretical machine learning is between applied math and pure math, model theory is on the other extreme.” This surprising interdisciplinary connection led them to use a result from model theory: a concept class had finite Littlestone Dimension precisely when the concept class had finite threshold dimension (formally, the maximum number of threshold functions that could be embedded in the class). This meant that answering (*) negatively was enough to show that DP PAC learning was as hard as online learning.</p>

<p>The idea for showing a lower bound for improper DP learning of thresholds came from Ramsey Theory, a famous area in combinatorics. Ramsey theory guarantees the existence of structured subsets among large, but arbitrary, combinatorial objects. A toy example of Ramsey Theory is that in any graph on 6 or more nodes, there must be a group of 3 nodes which form either a clique or an independent set. In the case of DP learning thresholds, the learning algorithm \( A \) is the arbitrary (and unstructured) combinatorial object. Ramsey Theory guarantees that for any PAC learner \( A \), there exists some large subset \( \mathcal{X}’ \) of the domain \(\mathcal{X}=[0, 1]\) on which \( A \) is close to behaving “normally”. The next step is to show that behaving normally contradicts differentially privacy. We’ll dig more technically into this argument in the next couple paragraphs. Note that we invent a couple definitions for the sake of exposition (“proper-normal” and “improper-normal”) that don’t appear in <a href="https://arxiv.org/abs/1504.07553"><strong>[BNSV15]</strong></a> or <a href="https://arxiv.org/abs/1806.00949"><strong>[ALMM19]</strong></a>.</p>

<p>Let’s start by seeing how a simpler version of this argument from <a href="https://arxiv.org/abs/1504.07553"><strong>[BNSV15]</strong></a> works to show that proper DP algorithms cannot learn thresholds. Recall that in a proper algorithm, after seeing \( n \) labeled samples, \( A \) must output a threshold. To be a PAC learner, if exactly half of the \( n \) samples are labeled \( 1 \) (which we will call a <em>balanced</em> sample), \( A \) must output a threshold between the smallest and largest sample with constant probability. Indeed, otherwise the empirical error of \( A \) will be too large to even hope to generalize. This implies that for a balanced list of samples \( S = [(x_1, 0), \ldots ,(x_{n/2}, 0), (x_{n/2+1}, 1), \ldots ,(x_n, 1)] \) (ordered by \(x\)-value), there must exist an integer \( k \in [n] \) for which with probability \( \Omega(1/n) \), \(A \) outputs a threshold in between 
\( x_k \) and \( x_{k+1} \). We’ll say that \( A \) is <em>\(k\)-proper-normal</em> on a set \( \mathcal{X}’ \) if for any balanced sample \( S \) of \( n \) points in \( \mathcal{X}’ \), \( A \) outputs a threshold in between the \(k\)th and \(k+1\)th ordered samples with probability \( \Omega(1/n) \). For example, the naive algorithm that always outputs a threshold between the 0-labeled samples and 1-labeled samples is \(n/2\)-normal on the entire domain \([0, 1]\). Ramsey theory guarantees that there is an arbitrary large subset of the domain \([0, 1]\) on which \(A \) is \(k\)-proper-normal for some \(k\). (See Figure 2).</p>

<p><img alt="Figure 2: Ramsey's Theorem" src="https://differentialprivacy.org/images/RamseyTheorem.png" title="Figure 2: Ramsey's Theorem"/>
<strong>Figure 2</strong>: Ramsey’s Theorem guarantees a large subset \( \mathcal{X}’ \) on which \( A \) is \( k \)-proper-normal for some \( k \).</p>

<p>The second part of the argument shows that being \( k \)-proper-normal on a large set is in direct conflict with differential privacy. We show this argument in Figure 3 by constructing a set of \( n \) samples \( S^* \) on which \( A \) must output a threshold in many distinct regions with substantial probability.</p>

<p><img alt="Figure 3: A Hard Distribution" src="https://differentialprivacy.org/images/DP_Construction.png" title="Figure 2: Ramsey's Theorem"/></p>

<p><strong>Figure 3:</strong> A distribution showing the conflict between \(A \) being DP and \(k\)-proper normal. By DP, the behaviour of \(A\) on \(S^* \) must be similar to its behaviour on \(S_i\) for \(i = 1 \ldots \Omega(n).\) Namely, since \(S^* \) and \( S_i \) differ by at most two points, \( A(S^*) \) must output a threshold in \( I_i \) with probability \( p \geq (q - 2\delta)e^{-(2\varepsilon)} \) for each \( i \), where \( q \) is a lower bound on the probability that \( A(S_i) \) outputs a threshold in \( I_i \). Because \( A \) is \(k\)-proper-normal, \( q &gt; c/n \), so \( p = \Omega(1/n) \). This yields a contradiction for \( m &gt;1/p \) because \( A \) cannot simultaneously output a threshold in two of the intervals \( I_i \).</p>

<p>For the case of improper algorithms, Shay and his coauthors considered an alternative notion of normality, which we will term <em>improper-normal</em>. Recall that in this case the output \( A(S) \) of the learner on a sample \( S \) is <em>any function</em> from \( [0, 1] \) to \( \{0, 1\} \) and not necessarly a threshold. We’ll say that \( A \) is \(k\)-improper-normal on a set \( \mathcal{X}’ \) if for any balanced sample \( S = [(x_1, 0), \ldots, (x_{n/2}, 0), (x_{n/2 +1}, 1), \ldots,  (x_n, 1)] \) of \( n \) points in \( \mathcal{X}’, \Pr[A(S)(w) = 1] - \Pr[A(S)(v) = 1] &gt; \Omega(1/n) \) for any \( w \in (x_{k - 1}, x_k) \) and \( v \in  (x_k, x_{k + 1}) \) in \( \mathcal{X}’ \setminus \{x_1, … x_n\} \). To PAC learn, A must be \(k\)-improper-normal for some \(k\) on any set of \(n + 1\) points. Applying the same Ramsey Theorem to a graph with colored hyperedges of size \(n + 1\) shows that there must exist an arbitrarily large set \( \mathcal{X}’ \) on which \( A \) is \(k\)-improper normal for some \( k \). A similar (but more nuanced) argument as before shows that a learner cannot be simultaneously private and \(k\)-improper-normal on some distribution over \( \mathcal{X}’ \).</p>

<p>For the last piece of the puzzle, showing the upper bound converse, Mark Bun, an expert in differential privacy at Princeton at the time, joined in. Beginning in the fall of 2019, Mark, Shay, and Roi worked out an upper bound that showed that any class with finite Littlestone dimension could be learned privately. Their technique introduced a new notion of stability, called <em>global stability</em>, which is a property of algorithms that frequently output the same hypothesis. Given a globally stable PAC learner \( A \), to obtain a DP PAC learner, one can run \( A \) many times and produce a histogram of the output hypotheses, add noise to this histogram for the sake of privacy, and then select the most frequent output hypothesis. The construction for the globally stable learner uses the Standard Optimal Algorithm for online learning as a black box - though the reduction is very computationally intensive and results in a sample complexity depending exponentially on the Littlestone Dimension. This reduction was improved in <a href="https://arxiv.org/abs/2012.03893"><strong>[GGKM20]</strong></a>, where the authors gave a reduction requiring only polynomially many samples in the Littlestone dimension.</p>

<h2 id="outlook">Outlook</h2>

<p>Shay mentions that these results are only a first step towards understanding differentially private PAC learning. This work establishes a deep connection between online learning and DP learning, qualitatively showing that these two problems have similar underlying complexity. Recent works <a href="https://arxiv.org/abs/1905.11311"><strong>[GHM19]</strong></a> have gone a step further and established polynomial time reductions from DP learning to online learning under certain conditions. At the same time, Bun <a href="https://arxiv.org/abs/2007.05665"><strong>[B20]</strong></a> demonstrates a computational gap between the two problems: they exhibit a concept class which is DP PAC learnable in polynomial time, but no algorithm can learn it online in polynomial time and sample complexity.</p>

<p>An interesting question here is whether a polynomial time online learning algorithm implies a polynomial time DP learning algorithm? With regards to sample complexity, tighter quantitative bounds relating the sample complexity of DP learning to the Threshold dimension and the Littlestone Dimension, along with constructive reductions from DP learning to online learning are wide open. An interesting conjecture, also highlighted in the talk, is whether DP PAC learning and PAC learning are actually equivalent up to a \(log*\) factor of the Littlestone dimension? Solving this would mean that for most natural function classes, one need not pay a very high price for private learning as compared to PAC learning.</p>

<p>From a more practical perspective, studying such qualitative equivalences can lay the groundwork allowing one to use the vast existing knowledge in the field of online learning to design better algorithms for DP learning, and vice versa. Despite its abstractness, Shay believes this result still has significance for engineers: “If they want to do something differentially privately, if they already have a good online learning algorithm for this, maybe they can modify it,” Shay says. “It gives some kind of inspiration.”</p>

<p>From a broader perspective, Shay believes that discovering clean, beautiful mathematical models that are more realistic than the PAC learning model and understanding the price one pays for privacy in those models are important directions for future research. One model, highlighted in the tutorial by Shay is that of <em>Universal Learning</em>, introduced in a recent work <a href="https://arxiv.org/abs/2011.04483"><strong>[BHMVY21]</strong></a> with Olivier Bousquet, Steve Hanneke, Ramon van Handel and Amir Yehudayoff. This model considers a learning task with a fixed distribution of samples and studies the hardness of the problem as the number of samples \( n \to \infty \). This setup better captures the practical aspects of modern machine learning and overcomes the limitations of the PAC model, which studies worst-case distributions for each sample size.</p>

<p>And how should one go about identifying such better mathematical models? “Pick the simplest problem that you don’t know how to solve and see where that leads you”, says Shay. One should begin by trying to understand the deficiencies of existing learning models, by identifying simple examples which go beyond these existing models. For example, Livni and Moran <a href="https://arxiv.org/abs/2006.13508"><strong>[LM20]</strong></a> exhibit the limitations of PAC-Bayes framework through a simple 1D linear classification problem. Fixing such limitations can often lead one to discover better learning models.</p>

<hr/>
<p><em>Thanks to Gautam Kamath, Shay Moran, and Keziah Naggita for helpful conversations and comments.</em></p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>For a more complete background on the progress in DP PAC learning, we refer the reader to the excellent survey blog post <a href="https://differentialprivacy.org/private-pac/">here</a>. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:1">↩</a></p>
    </li>
    <li id="fn:2">
      <p>At the time, Shay was additionally affiliated with Princeton University and Google Brain. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:2">↩</a></p>
    </li>
  </ol>
</div></div>
    </summary>
    <updated>2021-04-26T16:00:00Z</updated>
    <published>2021-04-26T16:00:00Z</published>
    <author>
      <name>Margalit Glasgow</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2021-04-29T03:41:58Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-9152128988613149804</id>
    <link href="https://blog.computationalcomplexity.org/feeds/9152128988613149804/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/04/ferrers-diagrams-can-be-used-to-prove-x.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9152128988613149804" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9152128988613149804" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/04/ferrers-diagrams-can-be-used-to-prove-x.html" rel="alternate" type="text/html"/>
    <title>Ferrer's Diagrams can be used to prove X theorems about partitions. What is X?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>1978: I took an excellent  ugrad course in combinatorics from James C Frauenthal (he sometimes wrote his name as the biniomial cofficient (J choose F))  and he covered Ferrer's diagrams. They are a nice way to prove equalities about types of partitions.   See <a href="https://www.britannica.com/science/combinatorics/The-Ferrer-diagram">here</a> for a definition and a few examples. I have this (possibly false) memory that there were LOTS of partition theorems proven nicely with Ferrer's diagrams.</p><p>Fast forward to 2021:</p><p>2021: My TA Emily  needs a topic to cover in Honors Discrete Math. I have this memory that there were LOTS of theorems about partitions proven with Ferrer's diagrams. We look at many websites on Ferrer diagrams  and  find only TWO examples:</p><p>The numb of partitions of n into k parts is the numb of partitions of n into parts the largest of which is k.</p><p><br/></p><p>The numb of partitions of n into \le k parts is the numb of partitions of n into parts the largest of which is \le k</p><p>We DO find many theorems about partitions such as this corollary to the Rogers-Ramanujan theorem:</p><p>The numb of partitions of n such that adjacent parts differ by at least 2 is the numb of partitions of n such that each partition is either \equiv 1 mod 5 or \equiv 4 mod 5.</p><p>This is a HARD theorem and there is no Ferrer-diagram or other elementary proof. </p><p>SO, I have one MEMORY but the reality seems different. Possibilities:</p><p>1) My memory is wrong. There really are only 2 examples (or some very small number).</p><p>2) There are other examples but I can't find them on the web. I HOPE this is true--- if someone knows of other ways to use Ferrer diagrams to get partition results, please comment. </p><p><br/></p></div>
    </content>
    <updated>2021-04-26T02:01:00Z</updated>
    <published>2021-04-26T02:01:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-04-28T21:02:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5481</id>
    <link href="https://www.scottaaronson.com/blog/?p=5481" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5481#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5481" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">The easiest exercise in the moral philosophy book</title>
    <summary xml:lang="en-US">Peter Singer, in the parable that came to represent his whole worldview and that of the effective altruism movement more generally, asked us to imagine that we could save a drowning child at the cost of jumping into a lake and ruining an expensive new suit. Assuming we’d do that, he argued that we do […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Peter Singer, in the parable that came to represent his whole worldview and that of the effective altruism movement more generally, asked us to imagine that we could save a drowning child at the cost of jumping into a lake and ruining an expensive new suit.  Assuming we’d do that, he argued that we do in fact face an ethically equivalent choice; if we don’t donate most of our income to save children in the Third World, then we need to answer for why, as surely as the person who walked past the kid thrashing in the water.</p>



<p>In this post, I don’t want to take a position on Singer’s difficult but important hypothetical.  I merely want to say: suppose that to save the child, you didn’t even have to jump in the water.  Suppose you just had to toss a life preserver, one you weren’t using.  Or suppose you just had to assure the child that it was OK to grab your life raft that was already in the water.</p>



<p>That, it seems, is the situation that the US and other rich countries will increasingly face with covid vaccines.  What’s happening in India right now looks on track to become a humanitarian tragedy, if it isn’t already.  Even if, as Indian friends tell me, this was a staggering failure of the Modi government, people shouldn’t pay for it with their lives.  And we in the US now have tens of millions of vaccine doses sitting in warehouses unused, for regulatory and vaccine hesitancy reasons—stupidly, but we do.  We’re past the time, in my opinion, when it’s morally obligatory either to use the doses or to give them away.  Anyone in a position to manufacture more vaccines for distribution to poor countries, should also immediately get the intellectual property rights to do so.</p>



<p>I was glad to read, just this weekend, that the US is finally starting to move in the right direction.  I hope it moves faster.</p>



<p>And I’m sorry that this brief post doesn’t contain any information or insight that you can’t find elsewhere.  It just made me feel better to write it, is all.</p></div>
    </content>
    <updated>2021-04-25T20:04:49Z</updated>
    <published>2021-04-25T20:04:49Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-04-25T20:04:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/060</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/060" rel="alternate" type="text/html"/>
    <title>TR21-060 |  Optimal Error Resilience of Adaptive Message Exchange | 

	Raghuvansh Saxena, 

	Klim Efremenko, 

	Gillat Kol</title>
    <summary>We study the error resilience of the message exchange task: Two parties, each holding a private input, want to exchange their inputs. However, the channel connecting them is governed by an adversary that may corrupt a constant fraction of the transmissions. What is the maximum fraction of corruptions that still allows the parties to exchange their inputs? 

For the non-adaptive channel, where the parties must agree in advance on the order in which they communicate, the maximum error resilience was shown to be $\frac{1}{4}$ (see Braverman and Rao, STOC 2011).
The problem was also studied over the adaptive channel, where the order in which the parties communicate may not be predetermined (Ghaffari, Haeupler, and Sudan, STOC 2014; Efremenko, Kol, and Saxena, STOC 2020). These works show that the adaptive channel admits much richer set of protocols but leave open the question of finding its maximum error resilience.

In this work, we show that the maximum error resilience of a protocol for message exchange over the adaptive channel is $\frac{5}{16}$, thereby settling the above question. Our result requires improving both the known upper bounds and the known lower bounds for the problem.</summary>
    <updated>2021-04-25T13:09:50Z</updated>
    <published>2021-04-25T13:09:50Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-04-29T09:38:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/059</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/059" rel="alternate" type="text/html"/>
    <title>TR21-059 |  On One-way Functions from NP-Complete Problems | 

	Yanyi Liu, 

	Rafael Pass</title>
    <summary>We present the first natural $\NP$-complete problem whose average-case hardness w.r.t. the uniform distribution over instances implies the existence of one-way functions (OWF). In fact, we prove that the existence of OWFs is \emph{equivalent} to mild average-case hardness of this $\NP$-complete problem. The problem, which originated in the 1960s, is the \emph{Conditional Time-Bounded Kolmogorov Complexity Problem}: let $K^t(x \mid z)$ be the length of the shortest ``program'' that, given the ``auxiliary input'' $z$, outputs the string $x$ within time $t(|x|)$, and let $\mcktp[t,\zeta]$ be the set of strings $(x,z,k)$ where $|z| = \zeta(|x|)$, $|k| = \log |x|$ and $K^t(x \mid z)&lt; k$, where, for our purposes, a ``program'' is defined as a RAM machine.

Our main results shows that for every polynomial $t(n)\geq n^2$, there exists some polynomial $\zeta$ such that $\mcktp[t,\zeta]$ is $\NP$-complete. We additionally observe that the result of Liu-Pass (FOCS'20) extends to show that for every polynomial $t(n)\geq 1.1n$, and every polynomial $\zeta(\cdot)$, mild average-case hardness of $\mcktp[t,\zeta]$ is equivalent to the existence of OWFs.</summary>
    <updated>2021-04-25T10:26:23Z</updated>
    <published>2021-04-25T10:26:23Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-04-29T09:38:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/058</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/058" rel="alternate" type="text/html"/>
    <title>TR21-058 |  Average-Case Hardness of NP from Exponential Worst-Case Hardness Assumptions | 

	Shuichi Hirahara</title>
    <summary>A long-standing and central open question in the theory of average-case complexity is to base average-case hardness of NP on worst-case hardness of NP.  A frontier question along this line is to prove that PH is hard on average if UP requires (sub-)exponential worst-case complexity.  The difficulty of resolving this question has been discussed from various perspectives based on technical barrier results, such as the limits of black-box reductions and the non-existence of worst-case hardness amplification procedures in PH.

In this paper, we overcome these barriers and resolve the open question by presenting the following main results:

1.  $UP \not\subseteq DTIME(2^{O(n / \log n)})$ implies $DistNP \not\subseteq AvgP$.

2.  $PH \not\subseteq DTIME(2^{O(n / \log n)})$ implies $DistPH \not\subseteq AvgP$.

3.  $NP \not\subseteq DTIME(2^{O(n / \log n)})$ implies $DistNP \not\subseteq Avg_P P$.
Here, $Avg_P P$ denotes P-computable average-case polynomial time, which interpolates average-case polynomial-time and worst-case polynomial-time.  We complement this result by showing that $DistPH \not\subseteq AvgP$ if and only if $DistPH \not\subseteq Avg_P P$.

At the core of all of our results is a new notion of universal heuristic scheme, whose running time is P-computable average-case polynomial time under every polynomial-time samplable distribution.  Our proofs are based on the meta-complexity of time-bounded Kolmogorov complexity: We analyze average-case complexity through the lens of worst-case meta-complexity using a new "algorithmic" proof of language compression and weak symmetry of information for time-bounded Kolmogorov complexity.</summary>
    <updated>2021-04-25T10:22:37Z</updated>
    <published>2021-04-25T10:22:37Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-04-29T09:38:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8089</id>
    <link href="https://windowsontheory.org/2021/04/24/towards-a-theory-of-generalization-in-reinforcement-learning-guest-lecture-by-sham-kakade/" rel="alternate" type="text/html"/>
    <title>Towards a Theory of Generalization in Reinforcement Learning: guest lecture by Sham Kakade</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Scribe notes by Hamza Chaudhry and Zhaolin Ren Previous post: Natural Language Processing – guest lecture by Sasha Rush Next post: TBD. See also all seminar posts and course webpage. See also video of lecture. Lecture slides: Original form: main / bandit analysis. Annotated: main / bandit analysis. Sham Kakade is a professor in the … <a class="more-link" href="https://windowsontheory.org/2021/04/24/towards-a-theory-of-generalization-in-reinforcement-learning-guest-lecture-by-sham-kakade/">Continue reading <span class="screen-reader-text">Towards a Theory of Generalization in Reinforcement Learning: guest lecture by Sham Kakade</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>Scribe notes by <a href="https://pehlevan.seas.harvard.edu/people/hamza-chaudhry">Hamza Chaudhry</a> and Zhaolin Ren</em></p>



<p><strong>Previous post:</strong> <a href="https://windowsontheory.org/2021/04/03/natural-language-processing-guest-lecture-by-sasha-rush/">Natural Language Processing – guest lecture by Sasha Rush</a> <strong>Next post:</strong> TBD. See also <a href="https://windowsontheory.org/category/ml-theory-seminar/">all seminar posts</a> and <a href="https://boazbk.github.io/mltheoryseminar/cs229br.html#plan">course webpage</a>.</p>



<p>See also <a href="https://harvard.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=5d1a4401-6dee-4e49-881c-ad13017f606c">video of lecture</a>. <strong>Lecture slides:</strong> Original form: <a href="http://files.boazbarak.org/misc/mltheory/sham1.pdf">main</a> / <a href="http://files.boazbarak.org/misc/mltheory/sham2.pdf">bandit analysis</a>. Annotated: <a href="http://files.boazbarak.org/misc/mltheory/sham1_ink.pdf">main</a> / <a href="http://files.boazbarak.org/misc/mltheory/sham2_ink.pdf">bandit analysis</a>.</p>



<p><a href="https://homes.cs.washington.edu/~sham/">Sham Kakade</a> is a professor in the Department of Computer Science and the Department of Statistics at the University of Washington, as well as a senior principal researcher at Microsoft Research New York City. He works on the mathematical foundations of machine learning and AI. He is the recipient of the several awards, including the ICML Test of Time Award (2020), the IBM Pat Goldberg best paper award (in 2007), and the INFORMS Revenue Management and Pricing Prize (2014).</p>



<p>Sham is writing a <a href="https://rltheorybook.github.io/">book on the theory of reinforcement learning</a> with Agarwal, Jiang and Sun.</p>



<h2>Introduction:</h2>



<p>Reinforcement learning has found success in a great number of fields because it is a very “natural framework” for interactive learning. It is based around the notion of experimenting with different behaviors in one’s environment and learning from mistakes to identify the optimal strategy. However, there is a lack of understanding regarding how to best optimize reinforcement learning algorithms when there is uncertainty about the agent’s environment and potential rewards. Therefore, it is important to develop a theoretical foundation about this to study generalization in reinforcement learning. The primary question these notes will address is as follows:</p>



<p><strong>What are necessary representational and distributional conditions that enable provably sample-efficient reinforcement learning?</strong></p>



<p>We will answer this question in the following parts.</p>



<ul><li><strong>Part I: Bandits &amp; Linear Bandits</strong> “Bandit problems” correspond to RL where the environment is reset in each step (horizon H=1). This captures the aspect of having an unknown reward function of RL, but does not capture the aspect of a changing environment based on agent’s actions. This part will be based on the papers <a href="https://homes.cs.washington.edu/~sham/papers/ml/bandit_rates.pdf">Dani-Hayes-Kakade 08</a> and <a href="https://arxiv.org/abs/0912.3995">Srinivas-Kakade-Krause-Seeger 10</a></li><li><strong>Part II: Lower Bounds</strong> RL is very much <em>not</em> a solved problem in neither theory nor practice. Even the RL analog of linear regression, when the expected reward is a linear function of the actions, is not solved. We will see that this is for a good reason: there is an exponential lower bound on the number of steps it takes to find a nearly-optimal policy in this case. This part is based on the recent paper <a href="https://arxiv.org/abs/2010.01374">Weisz-Amortila-Szepesvári 20</a> and the follow-up <a href="https://arxiv.org/abs/2103.12690">Wang-Wang-Kakade 21</a></li><li><strong>Interlude:</strong> Do these lower bounds matter in practice?</li><li><strong>Part III: Upper Bounds</strong> Given the lower bound, we see that to get positive results (aka <em>upper bounds</em> on the number of steps) we need to make strong assumptions on the structure of reqards. There have been a number of incomparable such assumptions used, and we will see that there is a way to unify them. This part is based on the recent paper <a href="https://arxiv.org/abs/2103.10897">Du-Kakade-Lee-Lovett-Mahajan-Sun-Wang 21</a></li></ul>



<p>Before all of these parts, we will start by introducing the general framework of Markov Decision Processes (MDPs) and do a quick tour of generalization for static learning and RL.</p>



<h3>Markov Decision Processes: A Framework for Reinforcement Learning</h3>



<p>We have an agent in an environment at state <img alt="s_t" class="latex" src="https://s0.wp.com/latex.php?latex=s_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> that takes some action <img alt="a_t" class="latex" src="https://s0.wp.com/latex.php?latex=a_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> which will observe some reward <img alt="r_{t}" class="latex" src="https://s0.wp.com/latex.php?latex=r_%7Bt%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and update the environment to state <img alt="s_{t+1}" class="latex" src="https://s0.wp.com/latex.php?latex=s_%7Bt%2B1%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<figure class="wp-block-image"><img alt="" src="https://windowsontheory.files.wordpress.com/2021/04/f7a66-17cuaqjq97x1h_sbieavvzg.png"/></figure>



<p>The following are some key terms that we will need throughout the rest of the notes:</p>



<ol><li><em>State Space, Action Space, Policy</em>: We denote the state space as <img alt="\mathcal{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BS%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and the action space as <img alt="\mathcal{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BA%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. A policy <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a mapping from states to actions: <img alt="\pi: \mathcal{S} \to \mathcal{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi%3A+%5Cmathcal%7BS%7D+%5Cto+%5Cmathcal%7BA%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li><strong>Trajectory</strong>: The sequence of states, actions, rewards an agent sees for a horizon of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> timesteps. <img alt="(s_1, a_1, r_1, s_2, a_2, r_2, \dots, s_{H}, a_{H}, r_{H})" class="latex" src="https://s0.wp.com/latex.php?latex=%28s_1%2C+a_1%2C+r_1%2C+s_2%2C+a_2%2C+r_2%2C+%5Cdots%2C+s_%7BH%7D%2C+a_%7BH%7D%2C+r_%7BH%7D%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li><em>State Value at time <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></em>: The expected cumulative reward starting from state <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and using policy <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> afterwards.</li><li><img alt="V_h^\pi(s) = \mathbb{E} \left[ \sum_{t=h}^{H} r_t \vert s_h = s \right]" class="latex" src="https://s0.wp.com/latex.php?latex=V_h%5E%5Cpi%28s%29+%3D+%5Cmathbb%7BE%7D+%5Cleft%5B+%5Csum_%7Bt%3Dh%7D%5E%7BH%7D+r_t+%5Cvert+s_h+%3D+s+%5Cright%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li><em>State Action Value at time <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></em>: The expected cumulative reward given a state-action tuple <img alt="(s,a)" class="latex" src="https://s0.wp.com/latex.php?latex=%28s%2Ca%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> starting from time <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and using policy <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> afterwards. <img alt="Q_h^\pi(s,a) = \mathbb{E} \left[ \sum_{t=h}^{H} r_t \vert s_h = s, a_h = a \right]" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cpi%28s%2Ca%29+%3D+%5Cmathbb%7BE%7D+%5Cleft%5B+%5Csum_%7Bt%3Dh%7D%5E%7BH%7D+r_t+%5Cvert+s_h+%3D+s%2C+a_h+%3D+a+%5Cright%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li><em>Optimal value and state-value function</em>: we define an optimal policy by <img alt="\pi^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and the associated optimal <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-function and value function by <img alt="Q^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="V^\star" class="latex" src="https://s0.wp.com/latex.php?latex=V%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> respectively (or equivalently, <img alt="Q^{\pi^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=Q%5E%7B%5Cpi%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, <img alt="V^{\pi^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=V%5E%7B%5Cpi%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>). Note that <img alt="Q^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="V^\star" class="latex" src="https://s0.wp.com/latex.php?latex=V%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> can be defined via the Bellman optimality equation as follows:</li></ol>



<p><img alt="V_h^\star(s) = \max_{a \in \mathcal{A}} Q_h^\star(s,a)" class="latex" src="https://s0.wp.com/latex.php?latex=V_h%5E%5Cstar%28s%29+%3D+%5Cmax_%7Ba+%5Cin+%5Cmathcal%7BA%7D%7D+Q_h%5E%5Cstar%28s%2Ca%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><img alt="Q_h^\star(s,a) = \mathbb{E}\left[R_h(s,a) + V_{h+1}^\star(s_{h+1}) \mid s_h = s, a_h = a \right]" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28s%2Ca%29+%3D+%5Cmathbb%7BE%7D%5Cleft%5BR_h%28s%2Ca%29+%2B+V_%7Bh%2B1%7D%5E%5Cstar%28s_%7Bh%2B1%7D%29+%5Cmid+s_h+%3D+s%2C+a_h+%3D+a+%5Cright%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>where we additionally define <img alt="V_{H+1}(s) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=V_%7BH%2B1%7D%28s%29+%3D+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for all <img alt="s \in \mathcal{S}" class="latex" src="https://s0.wp.com/latex.php?latex=s+%5Cin+%5Cmathcal%7BS%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<ol start="6"><li><strong>Goal:</strong> To find a policy <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> that maximizes the cumulative H-step reward <img alt="V_1^\pi(s)" class="latex" src="https://s0.wp.com/latex.php?latex=V_1%5E%5Cpi%28s%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> starting from an initial state <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> with a horizon <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. In the episodic setting, one starts at state <img alt="s_1" class="latex" src="https://s0.wp.com/latex.php?latex=s_1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, acts for <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> steps, and then repeats.</li></ol>



<h3>Challenges in Reinforcement Learning</h3>



<p>There are three main challenges that we face in reinforcement learning</p>



<ol><li><strong>Exploration:</strong> The total size and states of the environment may be unknown.</li><li><em>Credit Assignment:</em> We need to assign rewards to actions even if the rewards are delayed.</li><li><em>Large State/Action Spaces:</em> We face the curse of dimensionality.<ul><li><a href="https://openai.com/blog/learning-dexterity/">OpenAI 2019 Dexterous Robotic Hand Manipulation</a></li></ul><img alt="" src="https://i.imgur.com/PIIli4L.gif"/></li></ol>



<p><strong>We will deal with these problems by framing them in terms of generalization.</strong></p>



<h2>Part 0: A Whirlwind Tour of Generalization</h2>



<h3>Provable Generalization in Supervised Learning</h3>



<p>As we have seen in <a href="https://windowsontheory.org/2021/01/31/a-blitz-through-classical-statistical-learning-theory/">the first lecture of this course</a>, generalization is possible in the supervised learning setting, when the data follows an i.i.d distribution.<br/>Specifically we have the following bound</p>



<blockquote class="wp-block-quote"><p><strong>Occam’s Razor Bound (Finite Hypothesis Class):</strong> To learn a policy that is <img alt="\epsilon-" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon-&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>close to the best policy in a hypothesis class <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we need a number of samples that is <img alt="\mathcal{O} (\log(|\mathcal{F}|) / \epsilon^2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BO%7D+%28%5Clog%28%7C%5Cmathcal%7BF%7D%7C%29+%2F+%5Cepsilon%5E2%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p></blockquote>



<p>This means we can try lots of things on our data to see which hypotheses are <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-best. To handle infinite hypothesis classes, we can replace <img alt="\log |\mathcal{F}|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog+%7C%5Cmathcal%7BF%7D%7C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> with various other “complexity measures” to obtain generalization bounds such as:</p>



<ul><li>VC Dimension: <img alt="\mathcal{O} (\text{VC}(\mathcal{F}) / \epsilon^2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BO%7D+%28%5Ctext%7BVC%7D%28%5Cmathcal%7BF%7D%29+%2F+%5Cepsilon%5E2%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li>Classification (Margin Bounds): <img alt="\mathcal{O} (\text{margin} / \epsilon^2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BO%7D+%28%5Ctext%7Bmargin%7D+%2F+%5Cepsilon%5E2%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li>Linear Regression: <img alt="\mathcal{O}(\text{dimension}/\epsilon^2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BO%7D%28%5Ctext%7Bdimension%7D%2F%5Cepsilon%5E2%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li>Deep Learning: Algorithm also determines the complexity control</li></ul>



<p>Another way to say this is that in all of these cases, we can bound the generalization gap <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> by a quantity of the form <img alt="O(\sqrt{d/n})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7Bd%2Fn%7D%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> where <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is some “complexity measure” of the class <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the number of samples.</p>



<p>One reference for these generalization results in the supervised learning setting is the following <a href="https://www.cs.princeton.edu/courses/archive/fall19/cos597B/lecnotes/bookdraft.pdf">book</a> by Sanjeev Arora and collaborators.</p>



<p>The key enabler of generalization in supervised learning is <em>data reuse</em>. For a given training set, we can in principle simultaneously evaluate the loss of all hypotheses in our class. For example, given the fixed ImageNet dataset, we can evaluate performance on any classifier. As we will see, this is not a property that will always hold in RL (when it does hold, sample-efficient generalization is likely to follow).</p>



<h3>Sample Efficient RL in the Tabular Case with few states and actions (No Generalization involved):</h3>



<p>Consider a tabular MDP setting where <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> , <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> denote the number of states, number of actions and length of the horizon respectively. Suppose we are operating in a setup where <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are both small. Suppose also that the MDP is <strong>unknown</strong>.</p>



<p>Our goal in such a setting is to find a <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-optimal policy <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that <img alt="V_{1}^{\pi}(s_1) \geq V_1^{\pi^\star}(s_1) - \epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=V_%7B1%7D%5E%7B%5Cpi%7D%28s_1%29+%5Cgeq+V_1%5E%7B%5Cpi%5E%5Cstar%7D%28s_1%29+-+%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, where <img alt="s_1" class="latex" src="https://s0.wp.com/latex.php?latex=s_1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the initial state (for concreteness let’s assume it is deterministic), and <img alt="\pi^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is <strong>truly</strong> an optimal policy for this MDP. Since we assume the number of states and actions to be small, it is possible to explore the entire world, and finding such an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-optimal policy is in principle possible. We thus do not have to consider any hypothesis class here (so no generalization involved), and can instead seek to be optimal under all possible mappings from states to actions.</p>



<p>Think for example of the following maze MDP, where the state of the world is the cell the agent is in and the action it can take at each state is a move to each of say 4 neighboring cells. Then, if we are able to get to every state and try every action there, we would have learned the world.</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/BxUuayQ.png"/></figure>



<p>In this particular scenario, randomly exploring the world will allow us to learn the world. However, if we consider a modified random exploration strategy, where the probability of going left is significantly larger (say 5 times larger) than the probability of going right, then it will take exponential time to hit the goal state. In general, even for MDPs with small state and action spaces, a purely random exploration approach may be insufficient, as we may not be exploring the world enough. What alternative approach might we then adopt in order to achieve a sample-efficient learning algorithm?</p>



<blockquote class="wp-block-quote"><p><a href="https://www.cis.upenn.edu/~mkearns/papers/KearnsSinghE3.pdf"><strong>Theorem: (Kearns &amp; Singh ’98)</strong></a>. In the episodic setting, <img alt="poly(S,A,H,1/\epsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=poly%28S%2CA%2CH%2C1%2F%5Cepsilon%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> samples suffice to find an <img alt="\epsilon-" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon-&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>opt policy, where <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the number of states, <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the number of actions, and <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the length of the horizon.</p></blockquote>



<p>The above breakthrough result was the first to demonstrate that learning an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-opt policy is possible using just polynomially many samples. The key idea behind this is optimism and dynamic programming. In proving the result, the authors designed an algorithm called the E<img alt="^3" class="latex" src="https://s0.wp.com/latex.php?latex=%5E3&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> algorithm (Explicit Explore or Exploit). The E<img alt="^3" class="latex" src="https://s0.wp.com/latex.php?latex=%5E3&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> algorithm adopts a model-based approach, and relies on a “plan-to-explore” mechanism. As we act randomly, we will learn some part of the state space, and having learned this region well, we can thus accurately plan to escape it. This is where optimism comes in, since we give ourselves a bonus for escaping a region we know well.</p>



<p>Based on the Kearns and Singh result, there has been a number of followup works on the tabular MDP setting. One line of work seeks to improve on the precise factors in the sample complexity.</p>



<p><strong>Improvements on the sample complexity:</strong></p>



<ul><li><a href="https://jmlr.org/papers/volume3/brafman02a/brafman02a.pdf">A General Polynomial Time Algorithm for Near-Optimal Reinforcement Learning</a> / Brafman-Tennenholtz 2002</li><li><a href="https://homes.cs.washington.edu/~sham/papers/thesis/sham_thesis.html">On the Sample Complexity of Reinforcement Learning</a> – Kakade 2003 (PhD Thesis).</li><li><a href="https://www.jmlr.org/papers/volume11/jaksch10a/jaksch10a.pdf">Near-Optimal Regret Bounds for Reinforcement Learning</a> – Jaksch, Ortner, Auer 2010</li><li><a href="https://arxiv.org/abs/1705.07041">Posterior sampling for reinforcement learning: worst-case regret bounds</a> – Agrawal Jia 2017</li></ul>



<p>Another line of work seeks to show that <a href="https://en.wikipedia.org/wiki/Q-learning">Q-learning</a>, a model-free approach, can also achieve similar polynomial complexity, if an appropriate optimism bonus is incorporated.</p>



<p><strong>Provable Q-Learning (+Bonus)</strong></p>



<ul><li><a href="https://cseweb.ucsd.edu/~ewiewior/06efficient.pdf">PAC Model-Free Reinforcement Learning</a> – Strehl-Li-Wiewiora-Langford-Littman 2006</li><li><a href="https://castlelab.princeton.edu/html/ORF544/Readings/Szepesvari%20-%20Algorithms%20for%20reinforcement%20learning.pdf">Algorithms for Reinforcement Learning</a> – lecture by Szepesv´ari 2009</li><li><a href="https://arxiv.org/abs/1807.03765">Is Q-learning Provably Efficient?</a> – Jin Allen-ZhuBubeck Jordan 2018</li></ul>



<p>As the range and technical depth of the above results demonstrate, even in the relatively simple tabular case, the problem is already challenging, and a precise sharp characterization of sample complexity is even more difficult. The chief source of difficulty is the unknown nature of the world (if the world was known, then we can just run dynamic programming).</p>



<h3>Provable Generalization in RL:</h3>



<p>Ultimately, we want to move beyond small tabular MDPs, where a polynomial dependence in the sample complexity on <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is acceptable, and achieve sample-efficient learning in big problems where the space space could be massive. Think for instance of the game of Go.</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/DNHJgnJ.jpg"/></figure>



<p>In such a setting, requiring polynomially (in <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>) many samples is clearly unacceptable. This gives rise to the following question.</p>



<p><strong>Question 1: Can we find an <img alt="\epsilon-" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon-&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>opt policy with no <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> dependence?</strong></p>



<p>In order to do so, it is necessary to reutilize data in some way since we will not be able to see all the possible states in the world. How then might we reuse data to estimate the value of all policies in a policy class <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>? A naive approach is the following:</p>



<ul><li>Idea: Trajectory tree algorithm</li><li>Dataset Collection: Choose actions uniformly at random for all H steps in an episode.</li><li>Estimation: Uses importance sampling to evaluate every <img alt="f \in \mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</li></ul>



<blockquote class="wp-block-quote"><p><a href="https://www.cis.upenn.edu/~mkearns/papers/traj.pdf"><strong>Theorem: (Kearns, Mansour, &amp; Ng ’00)</strong></a> To find an <img alt="\epsilon-" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon-&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>best in class policy, the trajectory tree algorithm uses <img alt="O(A^H\log(|\mathcal{F}|)/\epsilon^2)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28A%5EH%5Clog%28%7C%5Cmathcal%7BF%7D%7C%29%2F%5Cepsilon%5E2%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> samples.</p></blockquote>



<p>Observe that when <img alt="H = 1" class="latex" src="https://s0.wp.com/latex.php?latex=H+%3D+1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> (i.e. a contextual bandit) this is exactly the kind of generalization bound we saw in the Occam Razor’s bound for supervised learning. Since there may be stochasticity in the MDP, such that <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> could be infinite or even uncountable, this dependence on <img alt="A^H" class="latex" src="https://s0.wp.com/latex.php?latex=A%5EH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a genuine improvement on the results for the tabular MDP setting which depended polynomially on <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. In this sense, this really is a generalization result, since we are learning an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-best in class policy without having seen the entire world (i.e. all the states in the world).<br/>We note that the result only has <img alt="\log(\mathcal{F}|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog%28%5Cmathcal%7BF%7D%7C%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> dependence on hypothesis class size and similar to the supervised learning setting, there are VC analogues as well. However, we can not avoid the <img alt="A^H" class="latex" src="https://s0.wp.com/latex.php?latex=A%5EH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> dependence to find an <img alt="\epsilon-" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon-&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>best-in-class policy agnostically (without assumptions on the MDP). To see why, consider a binary tree with <img alt="2^H" class="latex" src="https://s0.wp.com/latex.php?latex=2%5EH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-policies and a sparse reward at a leaf node.</p>



<p>This <img alt="A^H" class="latex" src="https://s0.wp.com/latex.php?latex=A%5EH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> dependence, while unavoidable without further assumptions, is clearly undesirable. This brings us to the following question.</p>



<p><strong>Question 2: Can we find an <img alt="\epsilon-" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon-&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>opt policy with no <img alt="S,A" class="latex" src="https://s0.wp.com/latex.php?latex=S%2CA&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> dependence and <img alt="poly(H,1/ \epsilon, \text{&quot;complexity measure&quot;})" class="latex" src="https://s0.wp.com/latex.php?latex=poly%28H%2C1%2F+%5Cepsilon%2C+%5Ctext%7B%22complexity+measure%22%7D%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> samples?</strong></p>



<p>As we just saw, agnostically we cannot learn an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-best-in-class policy without an <img alt="A^H" class="latex" src="https://s0.wp.com/latex.php?latex=A%5EH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> dependence. However, as we will see it is possible when appropriate assumptions are made. But what is the nature of the assumptions under which this kind of sample-efficient RL generalization is possible (when there is no (or mild) dependence on <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>)? What assumptions are necessary? What assumptions are sufficient? We will seek to address these questions.</p>



<p>To do so, we start simple, and first look at the bandits and linear bandits problem, where the horizon <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is just 1. Note that this is still an interactive learning problem, just that we reset the episode after one time-step, and that it is an example of a problem with a potentially large action space.</p>



<h2>Part 1: Bandits and Linear Bandits</h2>



<h3>Multi-Armed Bandits:</h3>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/LHEqOwn.png"/></figure>



<p>The multi-armed bandits algorithm is intimately interwoven with the theory of reinforcement learning. It is based around the question of how to allocate T tokens to A “arms” to maximize one’s return:</p>



<ul><li><a href="https://www.ams.org/journals/bull/1952-58-05/S0002-9904-1952-09620-8/S0002-9904-1952-09620-8.pdf">Some Aspects of the Sequential Design of Experiments</a> – Robbins 1952</li><li><a href="https://people.eecs.berkeley.edu/~russell/classes/cs294/s11/readings/Gittins:1979.pdf">Bandit Processes and Dynamic Allocations Indices</a> – Gittins 1979</li><li><a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.674.1620&amp;rep=rep1&amp;type=pdf">Asymptotically Efficient Adaptive Allocation Rules</a> – Lai and Robbins 1985</li></ul>



<p>It is a very successful algorithm when <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is small. What can we do when <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is large?</p>



<h4>Large-Action Case:</h4>



<p>The bandits have to make a decision regarding which arm to pull. There is a widely used linear formulation of this problem that will assist us in understanding generalization. The <a href="http://phillong.info/publications/peval.pdf">linear bandit model</a> is successful in many applications (scheduling, ads, etc.)</p>



<p><strong>Linear (RKHS) Bandits:</strong></p>



<ul><li>Decision: <img alt="x_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>; Reward: <img alt="r_t" class="latex" src="https://s0.wp.com/latex.php?latex=r_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>; Reward model:<br/><img alt="r_t = f(x_t) + \text{noise}; f(x) = w^\star \cdot \phi(x)" class="latex" src="https://s0.wp.com/latex.php?latex=r_t+%3D+f%28x_t%29+%2B+%5Ctext%7Bnoise%7D%3B+f%28x%29+%3D+w%5E%5Cstar+%5Ccdot+%5Cphi%28x%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li>The hypothesis class <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a set of linear/RKHS functions (an overview of RKHS, which stands for Reproducing Kernel Hilbert Space, can be found <a href="https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space">here</a>).</li></ul>



<h4>Linear/Gaussian Process Upper Confidence Bounds (UCB):</h4>



<p>The principle underlying the Linear Bandits algorithm is <strong>optimism in the face of uncertainty</strong>:<br/>Pick an input that maximizes the upper confidence bound:</p>



<p><img alt="x_t = \text{arg}\max_{x \in D} \mu_{t-1}(x) + \beta_t \sigma_{t-1}(x)." class="latex" src="https://s0.wp.com/latex.php?latex=x_t+%3D+%5Ctext%7Barg%7D%5Cmax_%7Bx+%5Cin+D%7D+%5Cmu_%7Bt-1%7D%28x%29+%2B+%5Cbeta_t+%5Csigma_%7Bt-1%7D%28x%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Note that <img alt="\mu_{t-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu_%7Bt-1%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the best estimate of the ground-truth and <img alt="\sigma_{t-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma_%7Bt-1%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a standard deviation that we have to estimate. In choosing the term <img alt="\beta_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have to navigate a trade-off between exploration and exploitation. As we can see, this algorithm will only pick plausible maximizers.</p>



<h4>Regret of Linear-UCB / Gaussian Process-UCB (Generalization in Action Space)</h4>



<blockquote class="wp-block-quote"><p><strong><a href="http://people.cs.uchicago.edu/~varsha/pubs/stoch_bandit.pdf">Theorem: (Dani, Hayes, &amp; K. ’08)</a>, <a href="https://arxiv.org/pdf/0912.3995.pdf">(Srinivas, Krause, K., &amp; Seeger ’10)</a></strong>. Assuming <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is an RKHS (with bounded norm), if we choose <img alt="\beta_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> “correctly”, then the regret satisfies<br/><img alt="\frac{1}{T} \sum_{t=1}^T[f(x^\star) - f(x_t)] = \tilde{\mathcal{O}} \left( \sqrt{\frac{\gamma_T}{T}} \right)," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7BT%7D+%5Csum_%7Bt%3D1%7D%5ET%5Bf%28x%5E%5Cstar%29+-+f%28x_t%29%5D+%3D+%5Ctilde%7B%5Cmathcal%7BO%7D%7D+%5Cleft%28+%5Csqrt%7B%5Cfrac%7B%5Cgamma_T%7D%7BT%7D%7D+%5Cright%29%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/>where <img alt="\tilde{\mathcal{O}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7B%5Cmathcal%7BO%7D%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> hides logarithmic terms, and </p></blockquote>



<figure class="wp-block-image size-large"><a href="https://windowsontheory.files.wordpress.com/2021/04/image.png"><img alt="" class="wp-image-8095" src="https://windowsontheory.files.wordpress.com/2021/04/image.png?w=1024"/></a></figure>



<p>The key complexity concept here is “Maximum Information Gain”: <img alt="\gamma_T" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma_T&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, which one can think of as the “effective dimension,” determines the regret because <img alt="\gamma_T \approx d \log T" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma_T+%5Capprox+d+%5Clog+T&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> in <img alt="\mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Here are some relevant papers for further understanding regret, which is the difference between the reward of a possible action and the reward of an action that has been taken.</p>



<ul><li><a href="https://homes.di.unimi.it/cesa-bianchi/Pubblicazioni/ml-02.pdf">Finite-time Analysis of the Multiarmed Bandit Problem</a> – Auer Cesa-Bianchi Fischer 2002</li><li><a href="https://papers.nips.cc/paper/2011/file/e1d5be1c7f2f456670de3d53c7b54f4a-Paper.pdf">Improved Algorithms for Linear Stochastic Bandits</a> – Abbasi-yadkori, Pál, Szepesvári 2011</li></ul>



<h3>Linear Upper Confidence Bound Analysis</h3>



<h4>Handling Large Action Spaces</h4>



<p>On each round, we must choose a decision <img alt="x_t \in D \subset R^d" class="latex" src="https://s0.wp.com/latex.php?latex=x_t+%5Cin+D+%5Csubset+R%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. This yields a reward <img alt="r_t \in [-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=r_t+%5Cin+%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, where</p>



<p><img alt="\mathbb{E}[r_t | x_t = x] = \mu^\star \cdot x \in [-1,1]." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D%5Br_t+%7C+x_t+%3D+x%5D+%3D+%5Cmu%5E%5Cstar+%5Ccdot+x+%5Cin+%5B-1%2C1%5D.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Above, <img alt="\mu^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is an unknown weight vector and <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> may be replaced by <img alt="\phi(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28x%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> if we have access to such a representation. Note that this tells us that the conditional expectation of <img alt="r_t" class="latex" src="https://s0.wp.com/latex.php?latex=r_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> upon <img alt="x_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is linear. We have the a corresponding i.i.d. noise sequence <img alt="\eta_t = r_t - \mu^\star \cdot x_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ceta_t+%3D+r_t+-+%5Cmu%5E%5Cstar+%5Ccdot+x_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. If <img alt="(x_0, \dots, x_{T-1})" class="latex" src="https://s0.wp.com/latex.php?latex=%28x_0%2C+%5Cdots%2C+x_%7BT-1%7D%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are our decisions, then our <em>cumulative regret</em> in expectation is</p>



<p><img alt="R_T = T(\mu^\star \cdot x^\star) - \sum_{t=0}^{T - 1} \mu^\star \cdot x_t" class="latex" src="https://s0.wp.com/latex.php?latex=R_T+%3D+T%28%5Cmu%5E%5Cstar+%5Ccdot+x%5E%5Cstar%29+-+%5Csum_%7Bt%3D0%7D%5E%7BT+-+1%7D+%5Cmu%5E%5Cstar+%5Ccdot+x_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>where <img alt="x^\star\in D" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%5Cstar%5Cin+D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is an optimal decision for <img alt="\mu^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, i.e.</p>



<p><img alt="x^\star \in \text{arg}\max_{x \in D} \mu^\star \cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%5Cstar+%5Cin+%5Ctext%7Barg%7D%5Cmax_%7Bx+%5Cin+D%7D+%5Cmu%5E%5Cstar+%5Ccdot+x&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<h4>LinUCB and the Confidence Ball</h4>



<p>After t rounds, we can define our uncertainty region <img alt="\text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> with center <img alt="\hat{\mu_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cmu_t%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and shape <img alt="\Sigma_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> using the <img alt="\lambda-" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda-&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>regularized least squares solution:</p>



<ul><li><img alt="\hat{\mu_t} = \text{arg}\min_\mu \sum_{\tau = 0}^{t-1} \left\| \mu \cdot x_\tau - r_\tau \right\|_2^2 + \lambda \left \| \mu \right\|_2^2," class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cmu_t%7D+%3D+%5Ctext%7Barg%7D%5Cmin_%5Cmu+%5Csum_%7B%5Ctau+%3D+0%7D%5E%7Bt-1%7D+%5Cleft%5C%7C+%5Cmu+%5Ccdot+x_%5Ctau+-+r_%5Ctau+%5Cright%5C%7C_2%5E2+%2B+%5Clambda+%5Cleft+%5C%7C+%5Cmu+%5Cright%5C%7C_2%5E2%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li><img alt="\Sigma_t = \lambda I + \sum_{\tau = 0}^{t-1} x_\tau x_\tau^\top \text{, with } \Sigma_0 = \lambda I," class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma_t+%3D+%5Clambda+I+%2B+%5Csum_%7B%5Ctau+%3D+0%7D%5E%7Bt-1%7D+x_%5Ctau+x_%5Ctau%5E%5Ctop+%5Ctext%7B%2C+with+%7D+%5CSigma_0+%3D+%5Clambda+I%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li><img alt="\text{BALL}_t = \left\{ \mu: (\hat{\mu_t} - \mu)^\top \Sigma_t (\hat{\mu_t} - \mu) \leq \beta_t \right\}," class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BBALL%7D_t+%3D+%5Cleft%5C%7B+%5Cmu%3A+%28%5Chat%7B%5Cmu_t%7D+-+%5Cmu%29%5E%5Ctop+%5CSigma_t+%28%5Chat%7B%5Cmu_t%7D+-+%5Cmu%29+%5Cleq+%5Cbeta_t+%5Cright%5C%7D%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li><img alt="\beta_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a parameter of the algorithm and <img alt="\Sigma_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> determines how accurately we know <img alt="\hat{\mu_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cmu_t%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li></ul>



<p>The LinUCB Algorithm can be understood as follows: For <img alt="t = 0,1,\dots" class="latex" src="https://s0.wp.com/latex.php?latex=t+%3D+0%2C1%2C%5Cdots&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<ol><li>Execute <img alt="x_t = \text{arg}\max_{x \in D} \max_{\mu \in \text{BALL}_t} \mu \cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=x_t+%3D+%5Ctext%7Barg%7D%5Cmax_%7Bx+%5Cin+D%7D+%5Cmax_%7B%5Cmu+%5Cin+%5Ctext%7BBALL%7D_t%7D+%5Cmu+%5Ccdot+x&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li>Observe the reward <img alt="r_t" class="latex" src="https://s0.wp.com/latex.php?latex=r_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and update <img alt="\text{BALL}_{t+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BBALL%7D_%7Bt%2B1%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li></ol>



<h4>LinUCB Regret Bound</h4>



<p>As the following theorem shows, the regret <img alt="R_T \leq \tilde{\mathcal{O} }(d\sqrt T)" class="latex" src="https://s0.wp.com/latex.php?latex=R_T+%5Cleq+%5Ctilde%7B%5Cmathcal%7BO%7D+%7D%28d%5Csqrt+T%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is sublinear with polynomial dependence on <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and no dependence on the cardinality <img alt="|D|" class="latex" src="https://s0.wp.com/latex.php?latex=%7CD%7C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> of the decision space <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<blockquote class="wp-block-quote"><p><a href="https://homes.cs.washington.edu/~sham/papers/ml/bandit_linear_long.pdf"><strong>Theorem (regret): (Dani, Hayes, Kakade 2009)</strong></a>. Suppose we have bounded noise <img alt="|\eta_t|" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ceta_t%7C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>; <img alt="|| \mu^\star || \leq W" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7C+%5Cmu%5E%5Cstar+%7C%7C+%5Cleq+W&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>; <img alt="||x|| \leq B" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7Cx%7C%7C+%5Cleq+B&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, for <img alt="x\ \in D" class="latex" src="https://s0.wp.com/latex.php?latex=x%5C+%5Cin+D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Set <img alt="\lambda = \sigma^2/W^2, \quad \beta_t := c_1 \sigma^2\left(d \log\left(1 + \frac{TB^2}{d}\right) + \log(1 /\delta)\right)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda+%3D+%5Csigma%5E2%2FW%5E2%2C+%5Cquad+%5Cbeta_t+%3A%3D+c_1+%5Csigma%5E2%5Cleft%28d+%5Clog%5Cleft%281+%2B+%5Cfrac%7BTB%5E2%7D%7Bd%7D%5Cright%29+%2B+%5Clog%281+%2F%5Cdelta%29%5Cright%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> Then, with probability greater than <img alt="1 - \delta" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+%5Cdelta&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, for all <img alt="t \geq 0" class="latex" src="https://s0.wp.com/latex.php?latex=t+%5Cgeq+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>,<br/><img alt="R_T \leq c_2 \sigma \sqrt{T} \left ( d \log\left(1 + \frac{TB^2}{d \sigma^2}\right) + \sqrt{\log(1 /\delta)}\sqrt{d \log\left(1 + \frac{TB^2}{d}\right)} \right)," class="latex" src="https://s0.wp.com/latex.php?latex=R_T+%5Cleq+c_2+%5Csigma+%5Csqrt%7BT%7D+%5Cleft+%28+d+%5Clog%5Cleft%281+%2B+%5Cfrac%7BTB%5E2%7D%7Bd+%5Csigma%5E2%7D%5Cright%29+%2B+%5Csqrt%7B%5Clog%281+%2F%5Cdelta%29%7D%5Csqrt%7Bd+%5Clog%5Cleft%281+%2B+%5Cfrac%7BTB%5E2%7D%7Bd%7D%5Cright%29%7D+%5Cright%29%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/>where <img alt="c_1,c_2" class="latex" src="https://s0.wp.com/latex.php?latex=c_1%2Cc_2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are absolute constants.</p></blockquote>



<p>To prove the regret theorem above, we will require the following two lemmas.</p>



<blockquote class="wp-block-quote"><p><strong>Lemma 1 (Confidence):</strong> Let <img alt="\delta &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We have that <img alt="Pr(\forall t, \mu^\star \in \text{BALL}_t) \geq 1 - \delta." class="latex" src="https://s0.wp.com/latex.php?latex=Pr%28%5Cforall+t%2C+%5Cmu%5E%5Cstar+%5Cin+%5Ctext%7BBALL%7D_t%29+%5Cgeq+1+-+%5Cdelta.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p><p><strong>Lemma 2 (Sum of Squares Regret Bound):</strong> Define <img alt="\text{regret}_t = \mu^\star \cdot x^\star - \mu^\star \cdot x_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bregret%7D_t+%3D+%5Cmu%5E%5Cstar+%5Ccdot+x%5E%5Cstar+-+%5Cmu%5E%5Cstar+%5Ccdot+x_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Suppose <img alt="\beta_t \geq 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_t+%5Cgeq+1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is increasing and that for all <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have <img alt="\mu^\star \in \text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar+%5Cin+%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Then, <img alt="\sum_{t=0}^{T-1} \text{regret}_t^2 \leq 8 \beta_T d \log \left ( 1 + \frac{TB^2}{d\lambda} \right )." class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bt%3D0%7D%5E%7BT-1%7D+%5Ctext%7Bregret%7D_t%5E2+%5Cleq+8+%5Cbeta_T+d+%5Clog+%5Cleft+%28+1+%2B+%5Cfrac%7BTB%5E2%7D%7Bd%5Clambda%7D+%5Cright+%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p>We note that Lemma 2 actually depends on Lemma 1, since it assumes that <img alt="\mu^\star \in \text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar+%5Cin+%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for each <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, a property that Lemma 1 tells us happens with probability at least <img alt="1-\delta" class="latex" src="https://s0.wp.com/latex.php?latex=1-%5Cdelta&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We defer the proofs of the two lemmas to later, and first show why they can be used to prove the regret theorem.</p>



<p><strong>Proof of regret theorem:</strong> Using the two lemmas above along with the Cauchy-Schwarz inequality, we have with probability at least <img alt="1 - \delta" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+%5Cdelta&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> that</p>



<p><img alt="R_T = \sum_{t=0}^{T-1} \text{regret}_t \leq \sqrt{T \sum{t=0}^{T-1} \text{regret}_t^2} \leq \sqrt{8 T \beta_T d \log \left( 1 + \frac{TB^2}{d\lambda} \right)}." class="latex" src="https://s0.wp.com/latex.php?latex=R_T+%3D+%5Csum_%7Bt%3D0%7D%5E%7BT-1%7D+%5Ctext%7Bregret%7D_t+%5Cleq+%5Csqrt%7BT+%5Csum%7Bt%3D0%7D%5E%7BT-1%7D+%5Ctext%7Bregret%7D_t%5E2%7D+%5Cleq+%5Csqrt%7B8+T+%5Cbeta_T+d+%5Clog+%5Cleft%28+1+%2B+%5Cfrac%7BTB%5E2%7D%7Bd%5Clambda%7D+%5Cright%29%7D.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>The rest of the proof follows from our chosen value of <img alt="\beta_T" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_T&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>We now proceed to sketch out the proofs of Lemma 1 (confidence bound) and Lemma 2 (sum of squares regret bound). We begin with showing why Lemma 2 holds.</p>



<h4>Analysis and proof of Lemma 2 (sum of squares regret bound)</h4>



<p>Our first auxilliary result bounds the pointwise width of the confidence ball.</p>



<blockquote class="wp-block-quote"><p><strong>Lemma (pointwise width of confidence ball)</strong>. Let <img alt="x \in D" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Consider any <img alt="\mu \in \text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu+%5Cin+%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Then,<br/><img alt="| (\mu - \hat{\mu}_t)^\top x| \leq \sqrt{\beta_t x^\top \Sigma_t^{-1}x}." class="latex" src="https://s0.wp.com/latex.php?latex=%7C+%28%5Cmu+-+%5Chat%7B%5Cmu%7D_t%29%5E%5Ctop+x%7C+%5Cleq+%5Csqrt%7B%5Cbeta_t+x%5E%5Ctop+%5CSigma_t%5E%7B-1%7Dx%7D.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p><em><strong>Proof</strong></em>. We have</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/ghNhZRo.png"/></figure>



<p>where the first inequality follows from Cauchy-Schwarx and the second (i.e last) inequality holds by the definition of <img alt="\text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and our assumption that <img alt="\mu \in \text{BALL}_t." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu+%5Cin+%5Ctext%7BBALL%7D_t.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Let us now define</p>



<p><img alt="w_t := \sqrt{x_t^\top \Sigma_t^{-1}x_t}," class="latex" src="https://s0.wp.com/latex.php?latex=w_t+%3A%3D+%5Csqrt%7Bx_t%5E%5Ctop+%5CSigma_t%5E%7B-1%7Dx_t%7D%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>which we can think of as the “normalized width” at time <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> in the direction of our decision. We have the following bound on the instantaneous regret <img alt="\text{regret}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bregret%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<blockquote class="wp-block-quote"><p><strong>Lemma (instantaneous regret lemma)</strong>. Fix <img alt="t \leq T" class="latex" src="https://s0.wp.com/latex.php?latex=t+%5Cleq+T&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. If <img alt="\mu^\star \in \text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar+%5Cin+%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, then<br/><img alt="\text{regret}_t \leq 2 \min (\sqrt{\beta_t}w_t, 1) \leq 2 \sqrt{\beta_t} \min(w_t,1)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bregret%7D_t+%5Cleq+2+%5Cmin+%28%5Csqrt%7B%5Cbeta_t%7Dw_t%2C+1%29+%5Cleq+2+%5Csqrt%7B%5Cbeta_t%7D+%5Cmin%28w_t%2C1%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p><em><strong>Proof</strong></em>. The basic idea is to use “optimism”. Let <img alt="\tilde{\mu} \in \text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7B%5Cmu%7D+%5Cin+%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> denote the vector maximizing the dot product <img alt="\hat{\mu}^\top x_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cmu%7D%5E%5Ctop+x_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. By choice of <img alt="x_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, <img alt="\tilde{\mu}^\top x_t = \max{\mu \in \text{BALL}_t} \max_{x \in D}\mu^\top x \geq (\mu^\star)^\top x^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7B%5Cmu%7D%5E%5Ctop+x_t+%3D+%5Cmax%7B%5Cmu+%5Cin+%5Ctext%7BBALL%7D_t%7D+%5Cmax_%7Bx+%5Cin+D%7D%5Cmu%5E%5Ctop+x+%5Cgeq+%28%5Cmu%5E%5Cstar%29%5E%5Ctop+x%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, where the inequality used the hypothesis that <img alt="\mu^\star \in \text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar+%5Cin+%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. This manifestation of “optimism” is crucial, since it tells us that the “ideal” reward we think we can get at time <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> exceeds the optimal expected reward <img alt="(\mu^\star)^\top x^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cmu%5E%5Cstar%29%5E%5Ctop+x%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Hence,</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/CO4lDFc.png"/></figure>



<p>where the last step follows from the pointwise width lemma (note <img alt="\tilde{\mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is in <img alt="\text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="\mu^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is assumed to be <img alt="\text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> by the hypothesis in Lemma 2). Since in the linear bandits setup we assumed that <img alt="\mu^\star \cdot x \in [-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar+%5Ccdot+x+%5Cin+%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for all <img alt="x \in D" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the simple bound <img alt="\text{regret}_t \leq 2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bregret%7D_t+%5Cleq+2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> holds as well. We may also assume for simplicity that <img alt="\beta_t \geq 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_t+%5Cgeq+1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. This then yields the bound in the result. <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>In the next two lemmas, we use a geometric potential function argument to bound the sum of widths independently of the choices made by the algorithm (e.g. choice of <img alt="\lambda" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="{\beta_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta_t%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> sequence).</p>



<blockquote class="wp-block-quote"><p><strong>Geometric Lemma 1</strong>. We have <img alt="\det(\Sigma_T) = \det(\Sigma_0) \prod_{t=0}^{T-1} (1+w_t^2)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdet%28%5CSigma_T%29+%3D+%5Cdet%28%5CSigma_0%29+%5Cprod_%7Bt%3D0%7D%5E%7BT-1%7D+%281%2Bw_t%5E2%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p><em><strong>Proof</strong></em>. By definition of <img alt="\Sigma_{t+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma_%7Bt%2B1%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/qX7Q3Ft.png"/></figure>



<p>We complete the proof by noting that <img alt="w_t^2 = x_t^\top \Sigma_t^{-1}x_t = |\Sigma_t^{-1/2}x_t |^2" class="latex" src="https://s0.wp.com/latex.php?latex=w_t%5E2+%3D+x_t%5E%5Ctop+%5CSigma_t%5E%7B-1%7Dx_t+%3D+%7C%5CSigma_t%5E%7B-1%2F2%7Dx_t+%7C%5E2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<blockquote class="wp-block-quote"><p><strong>Geometric Lemma 2</strong>. For any sequence <img alt="x_0,\dots,x_{T-1}" class="latex" src="https://s0.wp.com/latex.php?latex=x_0%2C%5Cdots%2Cx_%7BT-1%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that for <img alt="t &lt; T" class="latex" src="https://s0.wp.com/latex.php?latex=t+%3C+T&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, <img alt="|x_t|_2 \leq B" class="latex" src="https://s0.wp.com/latex.php?latex=%7Cx_t%7C_2+%5Cleq+B&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have<br/><img alt="\log\left(\det(\Sigma_{T-1})/\det(\Sigma_0)\right) = \log \det \left(I + \frac{1}{\gamma} \sum_{t=0}^{T-1} x_tx_t^\top \right) \leq d \log \left(1 + \frac{TB^2}{d\lambda}\right)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog%5Cleft%28%5Cdet%28%5CSigma_%7BT-1%7D%29%2F%5Cdet%28%5CSigma_0%29%5Cright%29+%3D+%5Clog+%5Cdet+%5Cleft%28I+%2B+%5Cfrac%7B1%7D%7B%5Cgamma%7D+%5Csum_%7Bt%3D0%7D%5E%7BT-1%7D+x_tx_t%5E%5Ctop+%5Cright%29+%5Cleq+d+%5Clog+%5Cleft%281+%2B+%5Cfrac%7BTB%5E2%7D%7Bd%5Clambda%7D%5Cright%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p><em><strong>Proof</strong></em>. Denote the eigenvalues of <img alt="\sum_{t=0}^{T-1}x_tx_t^\top" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bt%3D0%7D%5E%7BT-1%7Dx_tx_t%5E%5Ctop&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> as <img alt="\sigma_1,\dots,\sigma_d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma_1%2C%5Cdots%2C%5Csigma_d&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and note<br/><img alt="\sum_{i=1}^d \sigma_i = \text{Trace}\left(\sum_{t=0}^{T-1} x_t x_t^\top \right) = \sum_{t=0}^{T-1} |x_t|^2 \leq TB^2." class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%3D1%7D%5Ed+%5Csigma_i+%3D+%5Ctext%7BTrace%7D%5Cleft%28%5Csum_%7Bt%3D0%7D%5E%7BT-1%7D+x_t+x_t%5E%5Ctop+%5Cright%29+%3D+%5Csum_%7Bt%3D0%7D%5E%7BT-1%7D+%7Cx_t%7C%5E2+%5Cleq+TB%5E2.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/>Using the AM-GM inequality,</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/jQDxDYm.png"/></figure>



<p>We are now finally ready to prove Lemma 2 (sum of squares regret bound).</p>



<p><strong>Proof of Lemma 2 (sum of squares regret bound)</strong>.<br/>Assume <img alt="\mu^\star \in \text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar+%5Cin+%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for all <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We have<br/><img alt="" src="https://i.imgur.com/1rzWWOT.png"/></p>



<p>where the first inequality follows from the instantaneous regret lemma, the second from that <img alt="\beta_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is an increasing function of <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the third uses the fact that for <img alt="0 \leq y \leq 1, \ln(1+y) \geq y/2" class="latex" src="https://s0.wp.com/latex.php?latex=0+%5Cleq+y+%5Cleq+1%2C+%5Cln%281%2By%29+%5Cgeq+y%2F2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the final equality holds by Geometric Lemma 1, and the final inequality follows from Geometric Lemma 2. <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>This wraps up our discussion of Lemma 2.</p>



<h4>Analysis of Lemma 1 (Confidence bound)</h4>



<p>Recall that our goal here is to show that <img alt="\mu^\star \in \text{Ball}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar+%5Cin+%5Ctext%7BBall%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> with high probability. We begin with the following result, which is a general version of the self-normalized sum argument in <a href="https://homes.cs.washington.edu/~sham/papers/ml/bandit_linear_long.pdf">Dani, Hayes, Kakade 2009</a>.</p>



<blockquote class="wp-block-quote"><p><strong>Lemma (Self-normalized bound for vector-valued Martingalues, <a href="https://arxiv.org/abs/1102.2670">Abbasi et al. 2011</a>)</strong>. Suppose <img alt="{\epsilon_i}_{i=1}^{\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_i%7D_%7Bi%3D1%7D%5E%7B%5Cinfty%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are mean zero random variables (can be generalized to martingalues), and <img alt="\epsilon_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon_i&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is bounded by <img alt="\sigma" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Let <img alt="{X_i}_{i=1}^{\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_i%7D_%7Bi%3D1%7D%5E%7B%5Cinfty%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> be a stochastic process. Define <img alt="\Sigma_t := \Sigma_0 + \sum_{i=1}^t X_i X_i^\top" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma_t+%3A%3D+%5CSigma_0+%2B+%5Csum_%7Bi%3D1%7D%5Et+X_i+X_i%5E%5Ctop&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. With probability at least <img alt="1 - \delta" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+%5Cdelta&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have for all <img alt="t \geq 1" class="latex" src="https://s0.wp.com/latex.php?latex=t+%5Cgeq+1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>,<br/><img alt="\left|\sum_{t=1}^t X_i \epsilon_i \right|_{\Sigma_t^{-1}}^2 \leq \sigma^2 \log \left(\frac{\det(\Sigma_t)\det(\Sigma_0)^{-1}}{\delta^2} \right)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Csum_%7Bt%3D1%7D%5Et+X_i+%5Cepsilon_i+%5Cright%7C_%7B%5CSigma_t%5E%7B-1%7D%7D%5E2+%5Cleq+%5Csigma%5E2+%5Clog+%5Cleft%28%5Cfrac%7B%5Cdet%28%5CSigma_t%29%5Cdet%28%5CSigma_0%29%5E%7B-1%7D%7D%7B%5Cdelta%5E2%7D+%5Cright%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p>Equipped with the lemma above, we are now ready to prove Lemma 1, which we will restate here again.</p>



<blockquote class="wp-block-quote"><p><strong>Lemma 1 (Confidence):</strong> Let <img alt="\delta &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We have that <img alt="Pr(\forall t, \mu^\star \in \text{BALL}_t) \geq 1 - \delta." class="latex" src="https://s0.wp.com/latex.php?latex=Pr%28%5Cforall+t%2C+%5Cmu%5E%5Cstar+%5Cin+%5Ctext%7BBALL%7D_t%29+%5Cgeq+1+-+%5Cdelta.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p><strong>Proof of Lemma 1</strong>. Since <img alt="r_{\tau} = x_{\tau}\cdot \mu^\star + \eta_{\tau}" class="latex" src="https://s0.wp.com/latex.php?latex=r_%7B%5Ctau%7D+%3D+x_%7B%5Ctau%7D%5Ccdot+%5Cmu%5E%5Cstar+%2B+%5Ceta_%7B%5Ctau%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have<br/><img alt="" src="https://i.imgur.com/fsVT5QQ.png"/></p>



<p>To get the last equality, we recall that <img alt="\Sigma_t = \lambda I + \sum_{\tau=0}^{t-1}\eta_{\tau}x_{\tau}" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma_t+%3D+%5Clambda+I+%2B+%5Csum_%7B%5Ctau%3D0%7D%5E%7Bt-1%7D%5Ceta_%7B%5Ctau%7Dx_%7B%5Ctau%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. By the triangle inequality, it follows that we have</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/8Pr0zPB.png"/></figure>



<p>where the last inequality holds with probability at least <img alt="1 - \delta" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+%5Cdelta&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for every <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, using the self-normalized bound above, as well as the fact that <img alt="\Sigma_t^{-1/2} \leq 1/\sqrt{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma_t%5E%7B-1%2F2%7D+%5Cleq+1%2F%5Csqrt%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Since <img alt="(|v_1 | + |v_2|)^2 \leq 2|v_1|^2 + 2|v_2|^2" class="latex" src="https://s0.wp.com/latex.php?latex=%28%7Cv_1+%7C+%2B+%7Cv_2%7C%29%5E2+%5Cleq+2%7Cv_1%7C%5E2+%2B+2%7Cv_2%7C%5E2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for any vectors <img alt="v_1,v_2" class="latex" src="https://s0.wp.com/latex.php?latex=v_1%2Cv_2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, it follows that with probability at least <img alt="1 - \delta" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+%5Cdelta&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, for every <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>,<br/><img alt="" src="https://i.imgur.com/TS18lfK.png"/></p>



<p>where the final inequality is a consequence of the choice <img alt="\lambda = \sigma^2/W^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda+%3D+%5Csigma%5E2%2FW%5E2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> in the algorithm (where we recall the upper bound <img alt="|\mu^\star| \leq W" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmu%5E%5Cstar%7C+%5Cleq+W&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>), as well as Geometric Lemma 2. The result then follows by our choice of <img alt="\beta_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, which is</p>



<p><img alt="\beta_t := c_1 \sigma^2\left(d \log\left(1 + \frac{TB^2}{d\lambda}\right) + \log(1 /\delta)\right)," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_t+%3A%3D+c_1+%5Csigma%5E2%5Cleft%28d+%5Clog%5Cleft%281+%2B+%5Cfrac%7BTB%5E2%7D%7Bd%5Clambda%7D%5Cright%29+%2B+%5Clog%281+%2F%5Cdelta%29%5Cright%29%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>where <img alt="c_1" class="latex" src="https://s0.wp.com/latex.php?latex=c_1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is an absolute constant (note in doing so we also subsumed the <img alt="2\sigma^2" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Csigma%5E2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> term, simplifying the exposition). <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>We move on now to more challenging RL problems where the horizon <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is larger than 1, and explore lower bounds in this regime.</p>



<h2>Part 2: What are necessary assumptions for generalization in RL?</h2>



<h3>Approximate dynamic programming with linear function approximation</h3>



<p>We begin by considering generalization with a very natural assumption: suppose that the value function <img alt="Q(s,a)" class="latex" src="https://s0.wp.com/latex.php?latex=Q%28s%2Ca%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> can be approximated by linear basis functions</p>



<p><img alt="\phi(s,a) = (\phi_1(s,a),\dots,\phi_d(s,a)), \quad \phi(s,a) \in \mathbb{R}^d." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28s%2Ca%29+%3D+%28%5Cphi_1%28s%2Ca%29%2C%5Cdots%2C%5Cphi_d%28s%2Ca%29%29%2C+%5Cquad+%5Cphi%28s%2Ca%29+%5Cin+%5Cmathbb%7BR%7D%5Ed.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>We assume that the dimension of the representation, <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, is low compared the state and action dimensions. The idea of using a linear function approximation in RL and dynamic programming is not new, and had been explored in early works by Shannon (<a href="https://vision.unipv.it/IA1/ProgrammingaComputerforPlayingChess.pdf">“Programming a digital computer for playing chess.”, Philosophical Magazine, 1950</a>) as well as Bellman and Dreyfus (<a href="https://www.rand.org/content/dam/rand/pubs/papers/2006/P1176.pdf">“Functional approximations and dynamic programming”, 1959</a>). There has also since been significant work on this approach, see e.g. <a href="https://dl.acm.org/doi/10.1145/203330.203343">Tesauro 1995</a>, <a href="http://www.mit.edu/~pucci/discountedLP.pdf">de Farias and Van Roy 2003</a>, <a href="https://arxiv.org/abs/1307.4847">Wen and Van Roy 2013</a>.</p>



<p>One natural question that arises is this: <strong>what conditions must the representation <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> satisfy in order for this approach to work?</strong></p>



<p>We proceed by studying the simplest possible case: assuming that the optimal <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-function <img alt="Q_h^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is linearly realizable.</p>



<h4>RL with linearly realizable <img alt="Q_h^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> function approximation: does there exist a sample efficient algorithm?</h4>



<p>Suppose we have access to a feature map <img alt="\phi(s,a) \in \mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28s%2Ca%29+%5Cin+%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Concretely, the assumption we consider is the following:</p>



<blockquote class="wp-block-quote"><p><strong>Assumption 1 (Linearly realizable <img alt="Q_h^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>)</strong>: Assume for all <img alt="s,a,h \in [H]" class="latex" src="https://s0.wp.com/latex.php?latex=s%2Ca%2Ch+%5Cin+%5BH%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> that there exists <img alt="w_1^\star,\dots,w_H^\star \in \mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=w_1%5E%5Cstar%2C%5Cdots%2Cw_H%5E%5Cstar+%5Cin+%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that<br/><img alt="Q_h^\star(s,a) = w_h^\star \cdot \phi(s,a)." class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28s%2Ca%29+%3D+w_h%5E%5Cstar+%5Ccdot+%5Cphi%28s%2Ca%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p>As an aside, with Assumption 1, we can consider the problem from a linear programming viewpoint. Note that:</p>



<ul><li>We have an underlying LP with <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> variables and <img alt="O(SA)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28SA%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> constraints.</li><li>The LP is specific to the dynamic programming problem at hand (and hence not general) because it encodes the Bellman optimality constraints.</li><li>We have sampling access (in the episodic setting).</li></ul>



<p>It may be tempting to think that Assumption 1 is sufficient to enable a sample-efficient algorithm for RL (if we assume we already know the representation <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>). However, that is <strong>not</strong> true, as the following theorem from a very recent work demonstrates:</p>



<blockquote class="wp-block-quote"><p><a href="https://arxiv.org/abs/2010.01374"><strong>Theorem 1 (Weisz, Amortila, Szepesvári 2021):</strong></a> There exists an MDP and a representation <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> satisfying Assumption 1, such that any online RL algorithm (with knowledge of <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>) requires <img alt="\Omega(\min(2^d,2^H))" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%28%5Cmin%282%5Ed%2C2%5EH%29%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> samples to output the value <img alt="V_1^\star(s_1)" class="latex" src="https://s0.wp.com/latex.php?latex=V_1%5E%5Cstar%28s_1%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> up to constant additive error, with probability at least 0.9.</p></blockquote>



<p>While linear realizability alone is insufficient for sample efficiency in online RL, one might consider imposing further assumptions that could suffice for sample-efficient RL. One candidate assumption is to assume that at each state, the optimal action yields significantly more value than the next-best action:</p>



<blockquote class="wp-block-quote"><p><strong>Assumption 2 (Large suboptimality gap)</strong>: Assume for all <img alt="a \neq \pi^\star(s)" class="latex" src="https://s0.wp.com/latex.php?latex=a+%5Cneq+%5Cpi%5E%5Cstar%28s%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have<br/><img alt="V_h^\star(s) - Q_h^\star(s,a) \geq \frac{1}{16}." class="latex" src="https://s0.wp.com/latex.php?latex=V_h%5E%5Cstar%28s%29+-+Q_h%5E%5Cstar%28s%2Ca%29+%5Cgeq+%5Cfrac%7B1%7D%7B16%7D.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p>Perhaps surprisingly, the following theorem shows that an exponential lower bound for online RL remains under <strong>both</strong> Assumption 1 and Assumption 2.</p>



<blockquote class="wp-block-quote"><p><a href="https://arxiv.org/abs/2103.12690"><strong>Theorem 2 (Wang, Wang, Kakade 2021):</strong></a> There exists an MDP and a representation <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> satisfying both Assumption 1 and Assumption 2, such that any online RL algorithm (with knowledge of <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>) requires <img alt="\Omega(\min(2^d,2^H))" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%28%5Cmin%282%5Ed%2C2%5EH%29%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> samples to output the value <img alt="V_1^\star(s_1)" class="latex" src="https://s0.wp.com/latex.php?latex=V_1%5E%5Cstar%28s_1%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> up to constant additive error, with probability at least 0.9.</p></blockquote>



<p><em><strong>Remark</strong></em>: We note a subtle distinction between the online RL setting and the simulator access setting. In the online RL setting, during each episode, we start at some state <img alt="s_0" class="latex" src="https://s0.wp.com/latex.php?latex=s_0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and the subsequent states we see are entirely dependent on the policy we choose and the environment dynamics. Meanwhile, in the simulator access setting, at each time-step, we are free to input <strong>any</strong> <img alt="(s,a)" class="latex" src="https://s0.wp.com/latex.php?latex=%28s%2Ca%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> pair, and the simulator will return the next state <img alt="s' \sim P(\cdot \mid s,a)" class="latex" src="https://s0.wp.com/latex.php?latex=s%27+%5Csim+P%28%5Ccdot+%5Cmid+s%2Ca%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, as well as the reward <img alt="r(s,a)" class="latex" src="https://s0.wp.com/latex.php?latex=r%28s%2Ca%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. While Theorem 1 (when only Assumption 1 is satisfied) holds for both online RL and simulator access, Theorem 2 (when both Assumption 1 and Assumption 2 hold) is valid only in the online RL setting. In the simulator access setting, <a href="https://arxiv.org/abs/1910.03016">Du et al. 2019</a> proved that there exists a sample-efficient approach (i.e. polynomial in all relevant problem parameters) to find an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-optimal policy, when both Assumption 1 and Assumption 2 hold. This demonstrates an <em>exponential separation</em> between the online RL and simulator access settings.</p>



<p>We next introduce the counterexample used to prove Theorem 2 in detail.</p>



<h4>Construction sketch for counterexample in Theorem 2</h4>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/ReAcF8x.png"/></figure>



<p>Above, we have a pictorial representation of the MDP family in the counterexample. We first describe its state and action spaces.</p>



<ul><li>The state space is <img alt="{\bar{1},\dots,\bar{m}, f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7B1%7D%2C%5Cdots%2C%5Cbar%7Bm%7D%2C+f%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We use <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> to denote an integer, which we set to be approximately <img alt="2^d" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</li><li>State <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a special state, which we can think of as a “terminal state”.</li><li>At state <img alt="\bar{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbar%7Bi%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the feasible action set is <img alt="[m] \setminus {i}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bm%5D+%5Csetminus+%7Bi%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. At state <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the feasible action set is <img alt="[m-1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bm-1%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Hence, there are <img alt="m-1" class="latex" src="https://s0.wp.com/latex.php?latex=m-1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> feasible actions at each state.</li><li>Each MDP in this “hard” family is specified by an index <img alt="a^\star \in [m]" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar+%5Cin+%5Bm%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and denoted by <img alt="\mathcal{M}_{a^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D_%7Ba%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</li></ul>



<p>Before we proceed, we first recall the Johnson-Lindenstrauss lemma, which states that a set of points in a high-dimensional space can be embedded into a space of much lower dimension in such a way that the distances between the points are nearly preserved.</p>



<blockquote class="wp-block-quote"><p><a href="https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma">Johnson-Lindenstrauss Lemma</a>: Suppose we are given <img alt="0 &lt; \epsilon &lt; 1" class="latex" src="https://s0.wp.com/latex.php?latex=0+%3C+%5Cepsilon+%3C+1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, a set <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> of <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> points in <img alt="\mathbb{R}^N" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5EN&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and a number <img alt="n &gt; 8 \ln m/\epsilon^2" class="latex" src="https://s0.wp.com/latex.php?latex=n+%3E+8+%5Cln+m%2F%5Cepsilon%5E2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Then, there is a linear map <img alt="f \in \mathbb{R}^N \to \mathbb{R}^n" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathbb%7BR%7D%5EN+%5Cto+%5Cmathbb%7BR%7D%5En&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that<br/><img alt="(1-\epsilon)|u-v|^2 \leq |f(u) - f(v)|^2 \leq (1+\epsilon)|u-v|^2." class="latex" src="https://s0.wp.com/latex.php?latex=%281-%5Cepsilon%29%7Cu-v%7C%5E2+%5Cleq+%7Cf%28u%29+-+f%28v%29%7C%5E2+%5Cleq+%281%2B%5Cepsilon%29%7Cu-v%7C%5E2.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p>Consider a collection <img alt="\mathcal{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BX%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> of <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> orthogonal unit vectors in the high-dimensional space <img alt="\mathbb{R}^N" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5EN&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. For any two vectors <img alt="u\neq v \in \mathcal{X}" class="latex" src="https://s0.wp.com/latex.php?latex=u%5Cneq+v+%5Cin+%5Cmathcal%7BX%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, after applying the linear embedding <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we observe by Johnson-Lindenstrauss that</p>



<p><img alt="\pm\left \langle f(u),f(v)\right \rangle= \frac{|f(u) \pm f(v)|^2 - |f(u)|^2 - |f(v)|^2}{2} \leq \frac{2(1+\epsilon) - 2(1-\epsilon)}{2} = 2\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm%5Cleft+%5Clangle+f%28u%29%2Cf%28v%29%5Cright+%5Crangle%3D+%5Cfrac%7B%7Cf%28u%29+%5Cpm+f%28v%29%7C%5E2+-+%7Cf%28u%29%7C%5E2+-+%7Cf%28v%29%7C%5E2%7D%7B2%7D+%5Cleq+%5Cfrac%7B2%281%2B%5Cepsilon%29+-+2%281-%5Cepsilon%29%7D%7B2%7D+%3D+2%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>where we used the fact that <img alt="(1-\epsilon) \leq |f(u) - 0|^2 = |f(u)|^2\leq (1+\epsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=%281-%5Cepsilon%29+%5Cleq+%7Cf%28u%29+-+0%7C%5E2+%3D+%7Cf%28u%29%7C%5E2%5Cleq+%281%2B%5Cepsilon%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> holds for any unit <img alt="u \in \mathcal{X}" class="latex" src="https://s0.wp.com/latex.php?latex=u+%5Cin+%5Cmathcal%7BX%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> by linearity of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Hence, we can apply Johnson-Lindenstrauss to derive the following lemma, which will be useful in our construction.</p>



<blockquote class="wp-block-quote"><p><a href="https://arxiv.org/pdf/2103.12690.pdf">Lemma 1 (Johnson-Lindenstrauss)</a>: For any <img alt="\gamma &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma+%3E+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, there exists <img alt="m = \left\lfloor\exp\left(\frac{1}{8} \gamma^2 d\right)\right\rfloor" class="latex" src="https://s0.wp.com/latex.php?latex=m+%3D+%5Cleft%5Clfloor%5Cexp%5Cleft%28%5Cfrac%7B1%7D%7B8%7D+%5Cgamma%5E2+d%5Cright%29%5Cright%5Crfloor&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> unit vectors <img alt="{v_1,\dots,v_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_1%2C%5Cdots%2Cv_m%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> in <img alt="\mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that <img alt="\forall i,j \in [m]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+i%2Cj+%5Cin+%5Bm%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="i \neq j" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cneq+j&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, <img alt="|\langle v_i,v_j \rangle| \leq \gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Clangle+v_i%2Cv_j+%5Crangle%7C+%5Cleq+%5Cgamma&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p></blockquote>



<p>Throughout our discussion, we will set <img alt="\gamma := \frac{1}{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma+%3A%3D+%5Cfrac%7B1%7D%7B4%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<p>Equipped with the lemma above, we can now describe the transitions, features and rewards of the constructed MDP family. In the sequel, <img alt="a_1 \in [m]" class="latex" src="https://s0.wp.com/latex.php?latex=a_1+%5Cin+%5Bm%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="a_2 \in [m]" class="latex" src="https://s0.wp.com/latex.php?latex=a_2+%5Cin+%5Bm%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> represent integers associated with the state and action respectively.</p>



<p><em><strong>Transitions</strong></em>: The initial state <img alt="s_0" class="latex" src="https://s0.wp.com/latex.php?latex=s_0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> follows the uniform distribution <img alt="\mu = \mathrm{Unif}\left({\bar{1},\dots,\bar{m}}\right)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu+%3D+%5Cmathrm%7BUnif%7D%5Cleft%28%7B%5Cbar%7B1%7D%2C%5Cdots%2C%5Cbar%7Bm%7D%7D%5Cright%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. The transition probabilities are set as follows:</p>



<figure class="wp-block-image size-large"><a href="https://windowsontheory.files.wordpress.com/2021/04/image-1.png"><img alt="" class="wp-image-8096" src="https://windowsontheory.files.wordpress.com/2021/04/image-1.png?w=1024"/></a></figure>



<p>After taking action <img alt="a_2" class="latex" src="https://s0.wp.com/latex.php?latex=a_2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the next state is either <img alt="\overline{a_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Coverline%7Ba_2%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> or <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We might observe then that this MDP resembles a “leaking complete graph”. It is possible to visit any other state (except for <img alt="\overline{a^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Coverline%7Ba%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>). However, importantly, there is at least <img alt="1 - 3\gamma = \frac{1}{4}" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+3%5Cgamma+%3D+%5Cfrac%7B1%7D%7B4%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> probability of going to the terminal state <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Also, observe that the transition probabilities are indeed valid, since by Lemma 1 above, <img alt="0 &lt; \gamma \leq \left\langle v(a_1),v(a_2) \right\rangle + 2\gamma \leq 3\gamma &lt; 1." class="latex" src="https://s0.wp.com/latex.php?latex=0+%3C+%5Cgamma+%5Cleq+%5Cleft%5Clangle+v%28a_1%29%2Cv%28a_2%29+%5Cright%5Crangle+%2B+2%5Cgamma+%5Cleq+3%5Cgamma+%3C+1.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><em><strong>Features</strong></em>: The feature map, which maps state-action pairs to <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-dimensional vectors, is defined as<br/><img alt="\phi(\overline{a_1},a_2) := \left(\left\langle v(a_1),v(a_2) \right\rangle + 2\gamma \right) v(a_2), \; \forall a_1,a_2 \in [m], a_1 \neq a_2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28%5Coverline%7Ba_1%7D%2Ca_2%29+%3A%3D+%5Cleft%28%5Cleft%5Clangle+v%28a_1%29%2Cv%28a_2%29+%5Cright%5Crangle+%2B+2%5Cgamma+%5Cright%29+v%28a_2%29%2C+%5C%3B+%5Cforall+a_1%2Ca_2+%5Cin+%5Bm%5D%2C+a_1+%5Cneq+a_2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/><img alt="\phi(f,\cdot) := 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28f%2C%5Ccdot%29+%3A%3D+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Note that the feature map is independent of <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and is shared across the MDP family.</p>



<p><em><strong>Rewards</strong></em>: For <img alt="1 \leq h \leq H" class="latex" src="https://s0.wp.com/latex.php?latex=1+%5Cleq+h+%5Cleq+H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the rewards are defined as</p>



<p><img alt="R_h(\overline{a_1},a^\star) := \left\langle v(a_1),v(a^\star) \right\rangle + 2 \gamma" class="latex" src="https://s0.wp.com/latex.php?latex=R_h%28%5Coverline%7Ba_1%7D%2Ca%5E%5Cstar%29+%3A%3D+%5Cleft%5Clangle+v%28a_1%29%2Cv%28a%5E%5Cstar%29+%5Cright%5Crangle+%2B+2+%5Cgamma&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><img alt="R_h(\overline{a_1},a_2) := -2\gamma \left[\left\langle v(a_1),v(a_2) \right\rangle + 2\gamma\right], \; (a_2 \neq a^\star, a_2 \neq a_1)" class="latex" src="https://s0.wp.com/latex.php?latex=R_h%28%5Coverline%7Ba_1%7D%2Ca_2%29+%3A%3D+-2%5Cgamma+%5Cleft%5B%5Cleft%5Clangle+v%28a_1%29%2Cv%28a_2%29+%5Cright%5Crangle+%2B+2%5Cgamma%5Cright%5D%2C+%5C%3B+%28a_2+%5Cneq+a%5E%5Cstar%2C+a_2+%5Cneq+a_1%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><img alt="R_h(f,\cdot) := 0" class="latex" src="https://s0.wp.com/latex.php?latex=R_h%28f%2C%5Ccdot%29+%3A%3D+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>For <img alt="h = H" class="latex" src="https://s0.wp.com/latex.php?latex=h+%3D+H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we set <img alt="r_H(s,a) := \langle \phi(s,a), v(a^\star)\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=r_H%28s%2Ca%29+%3A%3D+%5Clangle+%5Cphi%28s%2Ca%29%2C+v%28a%5E%5Cstar%29%5Crangle&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for every state-action pair.</p>



<p>We now verify that our construction satisfies both the linear realizability and large suboptimality gap assumptions (Assumption 1 and Assumption 2).</p>



<blockquote class="wp-block-quote"><p><strong>Lemma (Linear realizability)</strong>. For all <img alt="(s,a)" class="latex" src="https://s0.wp.com/latex.php?latex=%28s%2Ca%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have <img alt="Q_h^\star(s,a) = \langle \phi(s,a), v(a^\star) \rangle" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28s%2Ca%29+%3D+%5Clangle+%5Cphi%28s%2Ca%29%2C+v%28a%5E%5Cstar%29+%5Crangle&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p></blockquote>



<p><em><strong>Proof</strong></em>: Throughout, we assume that <img alt="a_2 \neq a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a_2+%5Cneq+a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We first verify the statement for the terminal state <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. At the state <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, regardless of the action taken, the next state is always <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and the reward is always 0. Hence, <img alt="Q_h^\star(f,\cdot) = V_h^\star(f) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28f%2C%5Ccdot%29+%3D+V_h%5E%5Cstar%28f%29+%3D+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for all <img alt="h \in [H]" class="latex" src="https://s0.wp.com/latex.php?latex=h+%5Cin+%5BH%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Thus, <img alt="Q_h^\star(f,\cdot) = \langle \phi(f,\cdot),v(a^\star)\rangle = 0" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28f%2C%5Ccdot%29+%3D+%5Clangle+%5Cphi%28f%2C%5Ccdot%29%2Cv%28a%5E%5Cstar%29%5Crangle+%3D+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We next verify realizability for other states via backwards induction on <img alt="h = H, H-1,\dots,1" class="latex" src="https://s0.wp.com/latex.php?latex=h+%3D+H%2C+H-1%2C%5Cdots%2C1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. The inductive hypothesis is <img alt="\forall a_1 \in [m], a_2 \neq a_1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+a_1+%5Cin+%5Bm%5D%2C+a_2+%5Cneq+a_1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>,</p>



<p><img alt="Q_h^\star(\overline{a_1},a_2) = \left(\left\langle v(a_1),v(a_2) \right\rangle + 2\gamma \right) \left\langle v(a_1),v(a^\star) \right\rangle. \;(1)" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28%5Coverline%7Ba_1%7D%2Ca_2%29+%3D+%5Cleft%28%5Cleft%5Clangle+v%28a_1%29%2Cv%28a_2%29+%5Cright%5Crangle+%2B+2%5Cgamma+%5Cright%29+%5Cleft%5Clangle+v%28a_1%29%2Cv%28a%5E%5Cstar%29+%5Cright%5Crangle.+%5C%3B%281%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>and that <img alt="\forall a_1 \neq a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+a_1+%5Cneq+a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>,</p>



<p><img alt="V_h^\star(\overline{a_1}) = Q_h^\star(\overline{a_1},a^\star) = \left\langle v(a_1),v(a^\star) \right\rangle + 2\gamma \; (2)" class="latex" src="https://s0.wp.com/latex.php?latex=V_h%5E%5Cstar%28%5Coverline%7Ba_1%7D%29+%3D+Q_h%5E%5Cstar%28%5Coverline%7Ba_1%7D%2Ca%5E%5Cstar%29+%3D+%5Cleft%5Clangle+v%28a_1%29%2Cv%28a%5E%5Cstar%29+%5Cright%5Crangle+%2B+2%5Cgamma+%5C%3B+%282%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>When <img alt="h = H" class="latex" src="https://s0.wp.com/latex.php?latex=h+%3D+H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, (1) holds by the definition of the rewards at that level. Next, note that <img alt="\forall h" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, (2) follows from (1). This is because for <img alt="a_2 \neq a^\star,a_1" class="latex" src="https://s0.wp.com/latex.php?latex=a_2+%5Cneq+a%5E%5Cstar%2Ca_1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>,</p>



<p><img alt="Q_h^\star(\overline{a_1},a_2) = \left(\left\langle v(a_1),v(a_2) \right\rangle + 2\gamma \right) \left\langle v(a_1),v(a^\star) \right\rangle \leq 3\gamma^2," class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28%5Coverline%7Ba_1%7D%2Ca_2%29+%3D+%5Cleft%28%5Cleft%5Clangle+v%28a_1%29%2Cv%28a_2%29+%5Cright%5Crangle+%2B+2%5Cgamma+%5Cright%29+%5Cleft%5Clangle+v%28a_1%29%2Cv%28a%5E%5Cstar%29+%5Cright%5Crangle+%5Cleq+3%5Cgamma%5E2%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>while (recall <img alt="\gamma := 1/4" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma+%3A%3D+1%2F4&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>)</p>



<p><img alt="Q_h^\star(\overline{a_1},a^\star) = \left\langle v(a_1),v(a^\star) \right\rangle + 2\gamma \geq \gamma &gt; 3\gamma^2." class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28%5Coverline%7Ba_1%7D%2Ca%5E%5Cstar%29+%3D+%5Cleft%5Clangle+v%28a_1%29%2Cv%28a%5E%5Cstar%29+%5Cright%5Crangle+%2B+2%5Cgamma+%5Cgeq+%5Cgamma+%3E+3%5Cgamma%5E2.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>This means that proving (1) suffices to show that <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is always the optimal action. A simple verification via Bellman’s optimality equation suffices to prove the inductive hypothesis for (1) for every <img alt="h \in [H]" class="latex" src="https://s0.wp.com/latex.php?latex=h+%5Cin+%5BH%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, since the base case <img alt="h = H" class="latex" src="https://s0.wp.com/latex.php?latex=h+%3D+H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> holds. Thus, both (1) and (2) hold for all <img alt="h \in [H]" class="latex" src="https://s0.wp.com/latex.php?latex=h+%5Cin+%5BH%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, concluding our proof. <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>We next show that the constant suboptimality gap (Assumption 2) is also (approximately) satisfied by our constructed MDP family.</p>



<blockquote class="wp-block-quote"><p><strong>Lemma (Suboptimality gap)</strong>. For all state <img alt="\overline{a_1} \neq \overline{a^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Coverline%7Ba_1%7D+%5Cneq+%5Coverline%7Ba%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and <img alt="a_2 \neq a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a_2+%5Cneq+a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the suboptimality gap is<br/><img alt="\Delta_h(\overline{a_1},a_2) := V_h^\star(\overline{a_1}) -Q_h^\star(\overline{a_1},a_2) &gt; \gamma - 3\gamma^2 \geq \frac{1}{4} \gamma." class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta_h%28%5Coverline%7Ba_1%7D%2Ca_2%29+%3A%3D+V_h%5E%5Cstar%28%5Coverline%7Ba_1%7D%29+-Q_h%5E%5Cstar%28%5Coverline%7Ba_1%7D%2Ca_2%29+%3E+%5Cgamma+-+3%5Cgamma%5E2+%5Cgeq+%5Cfrac%7B1%7D%7B4%7D+%5Cgamma.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/>Hence, in this MDP, Assumption 2 is satisfied with <img alt="\Delta_{\min} \geq \frac{1}{4}\gamma = \Omega(1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta_%7B%5Cmin%7D+%5Cgeq+%5Cfrac%7B1%7D%7B4%7D%5Cgamma+%3D+%5COmega%281%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p></blockquote>



<p><em><strong>Remark</strong></em>. Note that that here we ignored the terminal state <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and the essentially unreachable state <img alt="\overline{a^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Coverline%7Ba%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for simplicity. This seems reasonable intuitively, since reaching <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is effectively the end of the episode, and the state <img alt="\overline{a^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Coverline%7Ba%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> can only be reached with negligible probability(recall that <img alt="m \approx 2^d" class="latex" src="https://s0.wp.com/latex.php?latex=m+%5Capprox+2%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is exponentially large). For a more rigorous treatment of this issue, refer to Appendix B in <a href="https://arxiv.org/pdf/2103.12690.pdf">Wang, Wang, Kakade 2021</a>.</p>



<p>We can now state and prove the following key technical lemma, which directly implies Theorem 2 in <a href="https://arxiv.org/pdf/2103.12690.pdf">Wang, Wang, Kakade 2021</a>.</p>



<blockquote class="wp-block-quote"><p><em><strong>Lemma</strong></em>. For any algorithm, there exists <img alt="a^\star \in [m]" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar+%5Cin+%5Bm%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that in order to output <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> with<br/><img alt="\mathbb{E}_{s_1 \sim \mu} V_1^{\pi}(s_0) \geq \mathbb{E}_{s_1 \sim \mu} V_1^\star(s_1) - 0.05" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7Bs_1+%5Csim+%5Cmu%7D+V_1%5E%7B%5Cpi%7D%28s_0%29+%5Cgeq+%5Cmathbb%7BE%7D_%7Bs_1+%5Csim+%5Cmu%7D+V_1%5E%5Cstar%28s_1%29+-+0.05&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/>with probability at least 0.1 for <img alt="\mathcal{M}_{a^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D_%7Ba%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the number of samples required is <img alt="2^{\Omega(\min(d,H))}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B%5COmega%28%5Cmin%28d%2CH%29%29%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p></blockquote>



<p><strong>Proof sketch</strong>. We take an information-theoretic perspective. Observe that the feature map of <img alt="\mathcal{M}_{a^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D_%7Ba%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> does not depend on <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and that for <img alt="h &lt; H" class="latex" src="https://s0.wp.com/latex.php?latex=h+%3C+H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="a_2 \neq a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a_2+%5Cneq+a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the reward <img alt="R_h(\overline{a_1},a_2)" class="latex" src="https://s0.wp.com/latex.php?latex=R_h%28%5Coverline%7Ba_1%7D%2Ca_2%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> also has no information about <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. The transition probabilities are also independent of <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, unless the action <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is taken, and the reward at state <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is always 0. Thus, to receive information about the optimal action <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the agent either needs to take the action <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, or be a non-game-over state at the final time step <img alt="h= H" class="latex" src="https://s0.wp.com/latex.php?latex=h%3D+H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> (i.e <img alt="s_H \neq f" class="latex" src="https://s0.wp.com/latex.php?latex=s_H+%5Cneq+f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.)</p>



<p>However, by the design of the transition probabilities, the probability of remaining at a non-game-over state at the next time step is at most</p>



<p><img alt="\sup_{a_1 \neq a_2} \langle v(a_1),v(a_2)\rangle + 2\gamma \leq 3\gamma \leq \frac{3}{4}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Csup_%7Ba_1+%5Cneq+a_2%7D+%5Clangle+v%28a_1%29%2Cv%28a_2%29%5Crangle+%2B+2%5Cgamma+%5Cleq+3%5Cgamma+%5Cleq+%5Cfrac%7B3%7D%7B4%7D.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Hence, for any algorithm, <img alt="P(s_H \neq f) \leq \left(\frac{3}{4}\right)^H" class="latex" src="https://s0.wp.com/latex.php?latex=P%28s_H+%5Cneq+f%29+%5Cleq+%5Cleft%28%5Cfrac%7B3%7D%7B4%7D%5Cright%29%5EH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, which is exponentially small.</p>



<p>Summarizing, any algorithm that does not know <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> either needs to “get lucky” so that <img alt="s_H = f" class="latex" src="https://s0.wp.com/latex.php?latex=s_H+%3D+f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, or take the optimal action <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. For each episode, the first event happens with probability less than <img alt="\left(\frac{3}{4}\right)^H" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%28%5Cfrac%7B3%7D%7B4%7D%5Cright%29%5EH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and the second event happens with probability less than <img alt="\frac{H}{m-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BH%7D%7Bm-1%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Since the number of actions is <img alt="m-1 = 2^{\Theta(d)}" class="latex" src="https://s0.wp.com/latex.php?latex=m-1+%3D+2%5E%7B%5CTheta%28d%29%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, it follows that neither event can happen with constant probability unless the number of episodes is exponential in <img alt="\min(d,H)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmin%28d%2CH%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. This wraps up the sketch. <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>We note that our construction is not quite rigorous due to the remark earlier that the suboptimality gap assumption does not hold for the states <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="\overline{a^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Coverline%7Ba%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. A more rigorous construction can be found in Appendix B of <a href="https://arxiv.org/pdf/2103.12690.pdf">Wang, Wang, Kakade 2021</a>. Note that this lower bound is silent on the dependence of the sample complexity on the size of the action space, giving rise to the following question, which appears to be still unsolved.</p>



<blockquote class="wp-block-quote"><p><strong>Open problem</strong>: Could we get a lower bound that also depends on the action space dimension <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, such that the number of samples required to obtain an approximately optimal policy scales with<br/><img alt="\exp(\min(A,d,H))?" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cexp%28%5Cmin%28A%2Cd%2CH%29%29%3F&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<h2>Interlude: do these lower bounds matter in practice?</h2>



<p>A natural question to ask is this: are these exponential lower bounds in Part 2 (when we only assume linear realizability) actually relevant for practice?</p>



<p>To answer this, we take a brief detour into <em>offline RL</em>. In offline RL (see <a href="https://arxiv.org/abs/2005.01643">Levine et al. 2020</a> for a survey), we assume that the agent has no direct access to the MDP, and is instead provided with a static dataset of transitions, <img alt="\mathcal{D} = {{s_h^i,a_h^i,r_h^i,s_{h+1}^i}_{h=1}^{H}}_{i=1}^m" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D+%3D+%7B%7Bs_h%5Ei%2Ca_h%5Ei%2Cr_h%5Ei%2Cs_%7Bh%2B1%7D%5Ei%7D_%7Bh%3D1%7D%5E%7BH%7D%7D_%7Bi%3D1%7D%5Em&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> (<img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> denotes number of independent episodes in the offline data). The goal here could be to learn a policy <img alt="\pi(a\mid s)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi%28a%5Cmid+s%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> (based on the static dataset <img alt="\mathcal{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>) that attains the largest possible cumulative reward when applied to the MDP, or to evaluate the performance of some target policy <img alt="\pi(a \mid s)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi%28a+%5Cmid+s%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> based on the offline data. We use <img alt="\pi_{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> to denote the distribution over states and actions in <img alt="\mathcal{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, such that we assume the state-action tuples <img alt="(s,a) \in \mathcal{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%28s%2Ca%29+%5Cin+%5Cmathcal%7BD%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are sampled according to <img alt="s \sim d^{\pi_{\beta}}(s)" class="latex" src="https://s0.wp.com/latex.php?latex=s+%5Csim+d%5E%7B%5Cpi_%7B%5Cbeta%7D%7D%28s%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and the actions are sampled according to the behaviour policy, such that <img alt="a \sim \pi_{\beta}(a \mid s)" class="latex" src="https://s0.wp.com/latex.php?latex=a+%5Csim+%5Cpi_%7B%5Cbeta%7D%28a+%5Cmid+s%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<p>Analogous to the online RL lower bound, the following theorem shows that linear realizability is also insufficient for sample-efficient evaluation of a target policy using offline data.</p>



<blockquote class="wp-block-quote"><p><strong>Theorem (informal, from <a href="https://arxiv.org/pdf/2010.11895.pdf">Wang, Foster, Kakade 2020</a>))</strong>. In the offline RL setting, suppose the data distributions have (polynomially) lower bounded eigenvalues, and the <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-functions of every policy are linear with respect to a given feature mapping. Then, any algorithm requires an exponential number of samples in the horizon <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> to output a non-trivially accurate estimate of the value of any given policy <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, with constant probability.</p></blockquote>



<p>Some remarks are in order. First, note that the above hardness result for policy evaluation also holds for finding near-optimal policies using offline data. For a simple reduction, consider an example where at the initial state, one action <img alt="a_1" class="latex" src="https://s0.wp.com/latex.php?latex=a_1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> leads to a fixed reward and another action <img alt="a_2" class="latex" src="https://s0.wp.com/latex.php?latex=a_2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> transits us to an instance which is hard to evaluate using offline data. Then, in order to find a good policy, it is necessary for the agent to approximately evaluate the value of the optimal policy in the hard instance. Second, an appropriate eigenvalue lower bound on the offline data distribution ensures that there is sufficient feature coverage in the dataset, without which linear realizability alone is clearly insufficient for sample-efficient estimation. Third, note that the representation condition in the theorem is significantly stronger than assuming than assuming realizability with regards to only a single target policy, and so the result carries over to the latter setting as well. Fourth, the key idea to prove the result is the error amplification (exponential in the horizon <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>) induced by the <em>distribution shift</em> from the offline policy to the target policy we wish to evaluate.</p>



<p>Empirical work performed in <a href="https://arxiv.org/pdf/2103.04947.pdf">Wang et al. 2021</a> show that the these negative results do manifest themselves in experimental examples. The methology considered by <a href="https://arxiv.org/pdf/2103.04947.pdf">Wang et al. 2021</a> is as follows:</p>



<ol><li>Decide on a target policy to be evaluated, along with a good feature mapping for this policy (could be the last layer of a deep neural network trained to evaluate the policy).</li><li>Collect offline data using trajectories that are a mixture of the target policy and another distribution (perhaps generated by a random policy).</li><li>Run offline RL methods to evaluate the target policy using feature mapping found in Step 1 and the offline data obtained in Step 2.</li></ol>



<p>We note that features extracted from pre-trained deep neural networks should be able to satisfy the linear realizibility assumption approximately (for the target policy). Moreover, the offline dataset is relatively favorable for evaluation of the target policy, since we would not expect realistic offline datasets to have a large number of trajectories from the target policy itself.</p>



<p>However, numerical results show substantial degradation in the accuracy of policy evaluation, even for a relatively mild distribution shift (e.g. where there is a 50/50 split in target policy and random policy in the offline data). As an example, consider the following plot.</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/WUpg5nW.png"/></figure>



<p>The figure above depicts the performance of Fitted Q-Iteration (FQI) on Walker2d-v2, an environment from the <a href="https://github.com/openai/gym">OpenAI gym benchmark suite</a> which has continuous action space. Here, the <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-axis is the number of rounds of FQI used, and the <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-axis is the square root of the mean squared error of the predicted values (smaller is better). The blue line corresponds to performance when the dataset is generated by the target policy itself with 1 million samples, and other lines correspond to the performance when adding more offline data induced by random trajectories. As we can see, adding more random trajectories lead to significant degradation of FQI. See <a href="https://arxiv.org/pdf/2103.04947.pdf">Wang et al. 2021</a> for more such experiments.</p>



<p>These empirical results seem to affirm the hardness results in <a href="https://arxiv.org/pdf/2103.04947.pdf">Wang et al. 2021</a> (offline RL) and <a href="https://arxiv.org/pdf/2103.12690.pdf">Wang, Wang, Kakade 2021</a> (online RL), in that the definition of a good representation in RL is more subtle than in supervised learning, and certainly goes beyond just linear realizibility.</p>



<h2>Part 3: Sufficient conditions for provable generalization in RL</h2>



<p>We have seen from Part 1 and Part 2 that finding an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-optimal policy with mild (e.g. logarithmic) dependence on <img alt="S,A" class="latex" src="https://s0.wp.com/latex.php?latex=S%2CA&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="poly(H,1/\epsilon,\mbox{&quot;complexity measure&quot;})" class="latex" src="https://s0.wp.com/latex.php?latex=poly%28H%2C1%2F%5Cepsilon%2C%5Cmbox%7B%22complexity+measure%22%7D%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> samples is <strong>NOT</strong> possible agnostically, or even with linearly realizable <img alt="Q^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. This leads us to the following question.</p>



<p><strong>Q: What kind of assumptions enable provable generalization in RL?</strong></p>



<p>In fact, under various stronger assumptions, sample-efficient generalization <strong>is</strong> possible in many special cases. Amongst others, these include</p>



<ul><li>Linear Bellman Completion [<a href="https://www.aaai.org/Library/AAAI/2005/aaai05-159.php">Munos 2005</a>, <a href="https://arxiv.org/abs/2003.00153">Zanette et al. 2020</a>]<ul><li>Linear MDPs (low-rank transition matrix) [<a href="https://arxiv.org/abs/1902.04779">Wang and Yang 2018</a>; <a href="https://arxiv.org/abs/1907.05388">Jin et al. 2019</a>]</li><li>Linear Quadratic Regulators (LQR): standard control theory model (see e.g. <a href="https://en.wikipedia.org/wiki/Linear%E2%80%93quadratic_regulator">Wikipedia page for LQR</a>)</li></ul></li><li>FLAMBE/Feature Selection: <a href="https://arxiv.org/abs/2006.10814">Agarwal, Kakade, Krishnamurthy, Sun 2020</a></li><li>Linear Mixture MDPs: [<a href="http://proceedings.mlr.press/v108/modi20a/modi20a.pdf">Modi et al. 2020</a>, <a href="http://proceedings.mlr.press/v119/ayoub20a/ayoub20a.pdf">Ayoub et al. 2020</a>]</li><li>Block MDPs <a href="https://arxiv.org/pdf/1901.09018.pdf">Du et al. 2019</a></li><li>Factored MDPs <a href="https://arxiv.org/abs/1811.08540">Sun et al 2019</a></li><li>Kernelized Nonlinear Regulator <a href="https://arxiv.org/abs/2006.12466">Kakade et al. 2020</a></li></ul>



<p>What structural commonalities are shared between these underlying assumptions and models? To answer this question, we go back to the start, and revisit the case of linear bandits (<img alt="H=1" class="latex" src="https://s0.wp.com/latex.php?latex=H%3D1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> RL problem) for intuition.</p>



<h3>Intuition from properties satisfied by linear bandits</h3>



<p>We consider linear contextual bandits, where the context is <img alt="s \in\mathcal{S}" class="latex" src="https://s0.wp.com/latex.php?latex=s+%5Cin%5Cmathcal%7BS%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the action is <img alt="a \in \mathcal{A}" class="latex" src="https://s0.wp.com/latex.php?latex=a+%5Cin+%5Cmathcal%7BA%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="\mathcal{S}, \mathcal{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BS%7D%2C+%5Cmathcal%7BA%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> denote the state (or context) and action space respectively. We assume as before that associated with each state-action pair is a representation <img alt="\phi(s,a) \in \mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28s%2Ca%29+%5Cin+%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. The observed reward is <img alt="r(s,a) = w^\star \cdot \phi(s,a) + \epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=r%28s%2Ca%29+%3D+w%5E%5Cstar+%5Ccdot+%5Cphi%28s%2Ca%29+%2B+%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, where <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a mean-zero stochastic noise term. The hypothesis class is</p>



<p><img alt="\mathcal{F} = {f(s,a) = w(f) \cdot \phi(s,a), w(f) \in \mathcal{W}}," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D+%3D+%7Bf%28s%2Ca%29+%3D+w%28f%29+%5Ccdot+%5Cphi%28s%2Ca%29%2C+w%28f%29+%5Cin+%5Cmathcal%7BW%7D%7D%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>where <img alt="\mathcal{W}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BW%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a subset of <img alt="\mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We let <img alt="\pi_f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> denote the greedy policy for <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, i.e.</p>



<p><img alt="\pi_f(s) = \mathrm{argmax}_{a} f(s,a)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_f%28s%29+%3D+%5Cmathrm%7Bargmax%7D_%7Ba%7D+f%28s%2Ca%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>An important structural property satisfied by linear contextual bandits is the following: <em>data reuse</em>. Indeed, the difference between any <img alt="f \in \mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and the observed reward <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is estimable when we had in fact played <img alt="\pi_g" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_g&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for some hypothesis <img alt="g \neq f" class="latex" src="https://s0.wp.com/latex.php?latex=g+%5Cneq+f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Via direct calculation, we see that</p>



<p><img alt="\mathbb{E}_{(s,a) \sim \pi_g} [f(s,a) - r(s,a)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7B%28s%2Ca%29+%5Csim+%5Cpi_g%7D+%5Bf%28s%2Ca%29+-+r%28s%2Ca%29%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><img alt="= \mathbb{E}_{(s,a) \sim \pi_g} [w(f) \cdot \phi(s,a) - (w^\star \cdot \phi(s,a) + \epsilon)]" class="latex" src="https://s0.wp.com/latex.php?latex=%3D+%5Cmathbb%7BE%7D_%7B%28s%2Ca%29+%5Csim+%5Cpi_g%7D+%5Bw%28f%29+%5Ccdot+%5Cphi%28s%2Ca%29+-+%28w%5E%5Cstar+%5Ccdot+%5Cphi%28s%2Ca%29+%2B+%5Cepsilon%29%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><img alt="= \left\langle w(f) - w^\star, \mathbb{E}_{(s,a) \sim \pi_g} [\phi(s,a)] \right\rangle." class="latex" src="https://s0.wp.com/latex.php?latex=%3D+%5Cleft%5Clangle+w%28f%29+-+w%5E%5Cstar%2C+%5Cmathbb%7BE%7D_%7B%28s%2Ca%29+%5Csim+%5Cpi_g%7D+%5B%5Cphi%28s%2Ca%29%5D+%5Cright%5Crangle.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Intuitively, assuming that <img alt="\pi_g" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_g&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> induces “sufficient exploration” of the <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-dimensional representation space, this implies that we can evaluate the quality of any policy/hypothesis <img alt="f \in \mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> using just the one set of data collected by <img alt="\pi_g" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_g&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. This is <strong>precisely</strong> the kind of data reuse property we saw for supervised learning, which enables sample-efficient generalization there. This suggests that to ensure sample-efficient generalization in general RL, it may be fruitful to look for assumptions that enable data reuse. One special case where such data reuse is possible is the class of linear Bellman complete models.</p>



<h3>Special case: linear Bellman complete class</h3>



<p>Let <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> be the length of each episode as before. We recall that a hypothesis class <img alt="\mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is <strong>realizable</strong> for an MDP <img alt="\mathcal{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> if there exists a hypothesis <img alt="f^\star \in \mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=f%5E%5Cstar+%5Cin+%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that</p>



<p><img alt="Q_h^\star(s,a) = Q_{h}^{f^\star}(s,a) \quad \forall h \in [h]," class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28s%2Ca%29+%3D+Q_%7Bh%7D%5E%7Bf%5E%5Cstar%7D%28s%2Ca%29+%5Cquad+%5Cforall+h+%5Cin+%5Bh%5D%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>where <img alt="Q_h^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the optimal state-action value at time step <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Having defined realizability, we are now ready to define the notion of linear Bellman completeness.</p>



<p>For any <img alt="f = (\theta_1,\dots,\theta_{H}) \in \mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=f+%3D+%28%5Ctheta_1%2C%5Cdots%2C%5Ctheta_%7BH%7D%29+%5Cin+%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, let <img alt="\pi_f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> be the greedy policy associated with <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. By the definition of a linear Bellman complete class, it follows that given some fixed <img alt="g = (\theta_1^g,\dots,\theta_{H}^g) \in \mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=g+%3D+%28%5Ctheta_1%5Eg%2C%5Cdots%2C%5Ctheta_%7BH%7D%5Eg%29+%5Cin+%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, for any <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have<br/><img alt="\mathbb{E}_{s_h,a_h, s{h+1} \sim \pi_g} \left[Q_{h}^f(s_h,a_h) - r(s_h,a_h) - V_{h+1}^f(s_{h+1}) \right]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7Bs_h%2Ca_h%2C+s%7Bh%2B1%7D+%5Csim+%5Cpi_g%7D+%5Cleft%5BQ_%7Bh%7D%5Ef%28s_h%2Ca_h%29+-+r%28s_h%2Ca_h%29+-+V_%7Bh%2B1%7D%5Ef%28s_%7Bh%2B1%7D%29+%5Cright%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/><img alt="= \mathbb{E}_{s_h, a_h \sim \pi_g} \left[ (\theta_h - \mathcal{T}_h(\theta{h+1}) \cdot \phi(s_h,a_h) \right]" class="latex" src="https://s0.wp.com/latex.php?latex=%3D+%5Cmathbb%7BE%7D_%7Bs_h%2C+a_h+%5Csim+%5Cpi_g%7D+%5Cleft%5B+%28%5Ctheta_h+-+%5Cmathcal%7BT%7D_h%28%5Ctheta%7Bh%2B1%7D%29+%5Ccdot+%5Cphi%28s_h%2Ca_h%29+%5Cright%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/><img alt="= (\theta_h - \mathcal{T}h(\theta{h+1}) \cdot \mathbb{E}_{s_h, a_h \sim \pi_g} \left[ \phi(s_h,a_h) \right]." class="latex" src="https://s0.wp.com/latex.php?latex=%3D+%28%5Ctheta_h+-+%5Cmathcal%7BT%7Dh%28%5Ctheta%7Bh%2B1%7D%29+%5Ccdot+%5Cmathbb%7BE%7D_%7Bs_h%2C+a_h+%5Csim+%5Cpi_g%7D+%5Cleft%5B+%5Cphi%28s_h%2Ca_h%29+%5Cright%5D.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<blockquote class="wp-block-quote"><p><strong>Definition (linear Bellman complete)</strong>. A hypothesis class <img alt="\mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, with respect to some known feature <img alt="\phi:\mathcal{S} \times \mathcal{A} \mapsto \mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%3A%5Cmathcal%7BS%7D+%5Ctimes+%5Cmathcal%7BA%7D+%5Cmapsto+%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, is linear Bellman complete for an MDP <img alt="\mathcal{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> if <img alt="\mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is realizable and there exists <img alt="\mathcal{T}_h: \mathbb{R}^d \to \mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BT%7D_h%3A+%5Cmathbb%7BR%7D%5Ed+%5Cto+%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that for all <img alt="(\theta_1,\dots,\theta&lt;_{H}) \in \mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Ctheta_1%2C%5Cdots%2C%5Ctheta%3C_%7BH%7D%29+%5Cin+%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="h \in [H]" class="latex" src="https://s0.wp.com/latex.php?latex=h+%5Cin+%5BH%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>,<br/><img alt="T_h(\theta_{h+1}) \cdot \phi(s,a) = r(s,a) + \mathbb{E}_{s' \sim P_h(s,a)} \left[\max_{a' \in \mathcal{A}} \theta_{h+1}^\top \phi(s',a') \right], \quad \forall (s,a) \in \mathcal{S} \times \mathcal{A}." class="latex" src="https://s0.wp.com/latex.php?latex=T_h%28%5Ctheta_%7Bh%2B1%7D%29+%5Ccdot+%5Cphi%28s%2Ca%29+%3D+r%28s%2Ca%29+%2B+%5Cmathbb%7BE%7D_%7Bs%27+%5Csim+P_h%28s%2Ca%29%7D+%5Cleft%5B%5Cmax_%7Ba%27+%5Cin+%5Cmathcal%7BA%7D%7D+%5Ctheta_%7Bh%2B1%7D%5E%5Ctop+%5Cphi%28s%27%2Ca%27%29+%5Cright%5D%2C+%5Cquad+%5Cforall+%28s%2Ca%29+%5Cin+%5Cmathcal%7BS%7D+%5Ctimes+%5Cmathcal%7BA%7D.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p>This shows that data reuse is possible for any linear Bellman complete class <img alt="\mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, since any <img alt="f \in \mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> can be evaluated using offline data collected by some fixed policy <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<p>As an aside, note that linear Bellman completeness is a very strong condition that can break when new features are added. This is because adding new features expands the hypothesis space (of linear functions), and there is no guarantee that the new hypothesis class will again satisfy linear Bellman completeness.</p>



<p>It turns out that linear Bellman complete classes are just one example of Bilinear Classes (<a href="https://arxiv.org/pdf/2103.10897.pdf">Du et al. 2021</a>), which encompass many RL models in which sample-efficient generalization has been shown to be possible.</p>



<h3>Bilinear Classes: structural properties to enable generalization in RL</h3>



<p>We assume access to a hypothesis class <img alt="\mathcal{H} = \mathcal{H}_1 \times \dots \times \mathcal{H}_{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+%3D+%5Cmathcal%7BH%7D_1+%5Ctimes+%5Cdots+%5Ctimes+%5Cmathcal%7BH%7D_%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, which can be abstract sets that permit for both model-based and value-based hypotheses. We assume that for all <img alt="f \in \mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, there is an associated state-action value function <img alt="Q_h^f" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5Ef&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and a value function <img alt="V_h^f" class="latex" src="https://s0.wp.com/latex.php?latex=V_h%5Ef&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for each <img alt="h \in {1,\dots,H}" class="latex" src="https://s0.wp.com/latex.php?latex=h+%5Cin+%7B1%2C%5Cdots%2CH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. As before, let <img alt="\pi_{h}^{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_%7Bh%7D%5E%7Bf%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> denote the greedy policy with respect to <img alt="Q_{h}^{f}" class="latex" src="https://s0.wp.com/latex.php?latex=Q_%7Bh%7D%5E%7Bf%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and let <img alt="\pi_f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> denote <img alt="{\pi_{h}^{f}}_{h=1}^{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi_%7Bh%7D%5E%7Bf%7D%7D_%7Bh%3D1%7D%5E%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We can now introduce the Bilinear Class.</p>



<p><strong>Definition (Bilinear Class)</strong>. Consider an MDP <img alt="\mathcal{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, a hypothesis class <img alt="\mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, a discrepancy function <img alt="\ell_f: \mathcal{S} \times \mathcal{A} \times \mathcal{S} \times \mathcal{H} \to \mathbb{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_f%3A+%5Cmathcal%7BS%7D+%5Ctimes+%5Cmathcal%7BA%7D+%5Ctimes+%5Cmathcal%7BS%7D+%5Ctimes+%5Cmathcal%7BH%7D+%5Cto+%5Cmathbb%7BR%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> (defined for each <img alt="f \in \mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>). Suppose <img alt="\mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is realizable in <img alt="\mathcal{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and that there exists functions <img alt="W_h: \mathcal{H} \to \mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=W_h%3A+%5Cmathcal%7BH%7D+%5Cto+%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="X_h: \mathcal{H} \to \mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=X_h%3A+%5Cmathcal%7BH%7D+%5Cto+%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for some <img alt="d \in \mathcal{N}" class="latex" src="https://s0.wp.com/latex.php?latex=d+%5Cin+%5Cmathcal%7BN%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Then, <img alt="(\mathcal{H},\ell_f)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cmathcal%7BH%7D%2C%5Cell_f%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> forms a Bilinear Class for <img alt="\mathcal{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> if the following two conditions hold.</p>



<ol><li>Bilinear regret: on-policy difference between claimed reward and true reward satisfies following upper bound,<br/><img alt="|\mathbb{E}_{a{1:h} \sim \pi_f} \left[Q_{h}^{f}(s_h,a_h) - r(s_h,a_h) - V_{h}^{f}(s_{h+1}) \right] | \leq \langle W_h(f)  - W_h(f^\star), X_h(f)\rangle.f" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb%7BE%7D_%7Ba%7B1%3Ah%7D+%5Csim+%5Cpi_f%7D+%5Cleft%5BQ_%7Bh%7D%5E%7Bf%7D%28s_h%2Ca_h%29+-+r%28s_h%2Ca_h%29+-+V_%7Bh%7D%5E%7Bf%7D%28s_%7Bh%2B1%7D%29+%5Cright%5D+%7C+%5Cleq+%5Clangle+W_h%28f%29++-+W_h%28f%5E%5Cstar%29%2C+X_h%28f%29%5Crangle.f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li>Data reuse: <img alt="|\mathbb{E}_{a{1:h} \sim \pi_f}\left[\ell_f(s_h,a_h,s_{h+1},g) \right]| = |\langle W_h(g) - W_h(f^\star), X_h(f)\rangle |." class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb%7BE%7D_%7Ba%7B1%3Ah%7D+%5Csim+%5Cpi_f%7D%5Cleft%5B%5Cell_f%28s_h%2Ca_h%2Cs_%7Bh%2B1%7D%2Cg%29+%5Cright%5D%7C+%3D+%7C%5Clangle+W_h%28g%29+-+W_h%28f%5E%5Cstar%29%2C+X_h%28f%29%5Crangle+%7C.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li></ol>



<p>As an example to demonstrate what the choices of <img alt="\ell_f,W_h" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_f%2CW_h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="X_h" class="latex" src="https://s0.wp.com/latex.php?latex=X_h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> might look like, for a linear Bellman complete class <img alt="\mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we can choose<br/><img alt="\ell_f(s_h,a_h,s_{h+1},g) = Q_{h}^{g}(s_h,a_h) - r(s_h,a_h) - V_{h+1}^{g}(s_{h+1})," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_f%28s_h%2Ca_h%2Cs_%7Bh%2B1%7D%2Cg%29+%3D+Q_%7Bh%7D%5E%7Bg%7D%28s_h%2Ca_h%29+-+r%28s_h%2Ca_h%29+-+V_%7Bh%2B1%7D%5E%7Bg%7D%28s_%7Bh%2B1%7D%29%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><img alt="W_h(g) = \theta_h - \mathcal{T}_h(\theta_{h+1})" class="latex" src="https://s0.wp.com/latex.php?latex=W_h%28g%29+%3D+%5Ctheta_h+-+%5Cmathcal%7BT%7D_h%28%5Ctheta_%7Bh%2B1%7D%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><img alt="X_h(f) = \mathbb{E}_{(s_h,a_h) \sim \pi_f}[\phi(s_h,a_h)]" class="latex" src="https://s0.wp.com/latex.php?latex=X_h%28f%29+%3D+%5Cmathbb%7BE%7D_%7B%28s_h%2Ca_h%29+%5Csim+%5Cpi_f%7D%5B%5Cphi%28s_h%2Ca_h%29%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Above, note that <img alt="W_h(f^\star) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=W_h%28f%5E%5Cstar%29+%3D+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for all <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for linear Bellman complete classes, and that the discrepancy function <img alt="\ell_f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> in this case does not depend on <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. As demonstrated in <a href="https://arxiv.org/pdf/2103.10897.pdf">Du et al. 2021</a>, the following models (in which sample-efficient generalization is known to be possible) can all be shown to be Bilinear Classes for some discrepancy function <img alt="\ell_f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>:</p>



<ul><li>Linear Bellman Completion [<a href="https://www.aaai.org/Library/AAAI/2005/aaai05-159.php">Munos 2005</a>, <a href="https://arxiv.org/abs/2003.00153">Zanette et al. 2020</a>]<ul><li>Linear MDPs (low-rank transition matrix) [<a href="https://arxiv.org/abs/1902.04779">Wang and Yang 2018</a>; <a href="https://arxiv.org/abs/1907.05388">Jin et al. 2019</a>]</li><li>Linear Quadratic Regulators (LQR): standard control theory model (see e.g. <a href="https://en.wikipedia.org/wiki/Linear%E2%80%93quadratic_regulator">Wikipedia page for LQR</a>)</li></ul></li><li>FLAMBE/Feature Selection: <a href="https://arxiv.org/abs/2006.10814">Agarwal, Kakade, Krishnamurthy, Sun 2020</a></li><li>Linear Mixture MDPs: [<a href="http://proceedings.mlr.press/v108/modi20a/modi20a.pdf">Modi et al. 2020</a>, <a href="http://proceedings.mlr.press/v119/ayoub20a/ayoub20a.pdf">Ayoub et al. 2020</a>]</li><li>Block MDPs <a href="https://arxiv.org/pdf/1901.09018.pdf">Du et al. 2019</a></li><li>Factored MDPs <a href="https://arxiv.org/abs/1811.08540">Sun et al 2019</a></li><li>Kernelized Nonlinear Regulator <a href="https://arxiv.org/abs/2006.12466">Kakade et al. 2020</a></li><li>and more (see <a href="https://arxiv.org/pdf/2103.10897.pdf">Du et al. 2021</a> for details.)</li></ul>



<p>Bilinear classes can be seen as a generalization of Bellman rank (<a href="https://arxiv.org/abs/1610.09512">Jiang et al. 2017</a>) and Witness rank (<a href="https://arxiv.org/abs/1811.08540">Wen et al. 2019</a>), which were previous works that sought to identify strucural commonalities between different RL models that enable sample-efficient generalization. That being said, there are still models (with known provable generalization) which Bilinear Classes does not cover. Two such exceptions are the deterministic linear <img alt="Q^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> (<a href="https://arxiv.org/abs/1307.4847">Wen and Van Roy 2013</a>) model and the <img alt="Q^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-state aggregation model (<a href="https://arxiv.org/abs/1912.06366">Dong et al. 2020</a>). On a heuristic level, the structural commonalities identified by the Bilinear Classes show that to a large extent, most RL models known to enable sample-efficient generalization resemble linear bandits, in that data reuse is possible. In this sense, understanding why generalization is possible in the linear bandit case gives one intuition for why generalization is possible in these other cases as well. On some level, this may be disappointing since we might hope to capture richer phenomenon than just linear bandits, but promisingly, there is a rich class of RL models which share these structural commonalities that enable generalization in RL (as the examples encompassed by the Bilinear Classes demonstrate).</p>



<h2>Conclusion</h2>



<p>From the discussion above, we see that a generalization theory for RL, while significantly distinct from that for supervised learning, is still possible. However, natural assumptions that might seem adequate, such as linear realizability, are in fact insufficient, and much stronger assumptions are required. One such example of sufficient assumptions is the Bilinear Class, which covers a rich set of models. Moreover, as the empirical results we saw in the interlude show, these representational issues identified by theory are relevant for practice. For more on the theory of RL, see the following <a href="https://rltheorybook.github.io">forthcoming book</a>.</p></div>
    </content>
    <updated>2021-04-24T14:56:43Z</updated>
    <published>2021-04-24T14:56:43Z</published>
    <category term="ML Theory seminar"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-04-29T09:40:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8083</id>
    <link href="https://windowsontheory.org/2021/04/23/tcs-women-rising-star-nominations/" rel="alternate" type="text/html"/>
    <title>TCS Women Rising star nominations</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">(Guest post by Virginia Vassilevska Williams) Dear colleagues We invite you to nominate speakers for our TCS Women Rising Star talks at the TCS Women Spotlight Workshop at STOC 2021. To be eligible, your nominee has to be a theoretical computer science researcher (all topics represented at STOC are welcome) who is female or an … <a class="more-link" href="https://windowsontheory.org/2021/04/23/tcs-women-rising-star-nominations/">Continue reading <span class="screen-reader-text">TCS Women Rising star nominations</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>(Guest post by Virginia Vassilevska Williams) <br/></em><br/></p>



<p>Dear colleagues</p>



<p>We invite you to nominate speakers for our TCS Women Rising Star talks at the TCS Women Spotlight Workshop at STOC 2021. To be eligible, your nominee has to be a theoretical computer science researcher (all topics represented at STOC are welcome) who is female or an underrepresented minority, and is a graduating PhD student or a postdoc. You can make your nomination by filling this form by May 15th:  <a href="https://forms.gle/g4mTS2MJzkenKrry6" rel="noreferrer noopener" target="_blank">https://forms.gle/g4mTS2MJzkenKrry6</a></p>



<p>The TCS Women Spotlight workshop at STOC 2021 will take place virtually between June 21st and June 25th (most likely on Tuesday, June 22<sup>nd</sup>, to be confirmed later on).</p>



<p>You can see the list of speakers from last year here: <a href="https://sigact.org/tcswomen/3rd-tcs-women-meeting/tcs-women-2020/">https://sigact.org/tcswomen/3rd-tcs-women-meeting/tcs-women-2020/</a></p>



<p/>



<p>Looking forward to your nominations and to seeing you at the TCS Women Spotlight Workshop!</p>



<p>Virginia Vassilevska Williams, Barna Saha, Sofya Raskhodnikova, Mary Wootters and Elena Grigorescu</p></div>
    </content>
    <updated>2021-04-23T15:10:25Z</updated>
    <published>2021-04-23T15:10:25Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-04-29T09:40:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/057</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/057" rel="alternate" type="text/html"/>
    <title>TR21-057 |  Hardness of KT Characterizes Parallel Cryptography | 

	Hanlin Ren, 

	Rahul Santhanam</title>
    <summary>A recent breakthrough of Liu and Pass (FOCS'20) shows that one-way functions exist if and only if the (polynomial-)time-bounded Kolmogorov complexity K^t is bounded-error hard on average to compute. In this paper, we strengthen this result and extend it to other complexity measures:

1. We show, perhaps surprisingly, that the KT complexity is bounded-error average-case hard if and only if there exist one-way functions in constant parallel time (i.e. NC^0). This result crucially relies on the idea of randomized encodings. Previously, a seminal work of Applebaum, Ishai and Kushilevitz (FOCS'04; SICOMP'06) used the same idea to show that NC^0-computable one-way functions exist if and only if logspace-computable one-way functions exist.
	
2. Inspired by the above result, we present randomized average-case reductions among the NC^1-versions and logspace-versions of K^t complexity, and KT complexity. Our reductions preserve both bounded-error average-case hardness and zero-error average-case hardness. To the best of our knowledge, this is the first reduction between KT complexity and a variant of K^t complexity.

3. We prove tight connections between the hardness of K^t complexity and the hardness of (the hardest) one-way functions. In analogy with the Exponential-Time Hypothesis and its variants, we define and motivate the Perebor Hypotheses for complexity measures such as K^t and KT. We show that a Strong Perebor Hypothesis for K^t implies the existence of (weak) one-way functions of near-optimal hardness 2^{n-o(n)}. To the best of our knowledge, this is the first construction of one-way functions of near-optimal hardness based on a natural complexity assumption about a search problem.

4. We show that a Weak Perebor Hypothesis for MCSP implies the existence of one-way functions, and establish a partial converse. This is the first unconditional construction of one-way functions from hardness of MCSP over a natural distribution.

5. Finally, we study the average-case hardness of MKtP. We show that it characterizes cryptographic pseudorandomness in one natural regime of parameters, and complexity-theoretic pseudorandomness in another natural regime.</summary>
    <updated>2021-04-23T13:36:00Z</updated>
    <published>2021-04-23T13:36:00Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-04-29T09:38:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/056</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/056" rel="alternate" type="text/html"/>
    <title>TR21-056 |  On the Possibility of Basing Cryptography on $\EXP \neq \BPP$ | 

	Yanyi Liu, 

	Rafael Pass</title>
    <summary>Liu and Pass (FOCS'20) recently demonstrated an equivalence between the existence of one-way functions (OWFs) and mild average-case hardness of the time-bounded Kolmogorov complexity problem. In this work, we establish a similar equivalence but to a different form of time-bounded Kolmogorov Complexity---namely, Levin's notion of Kolmogorov Complexity---whose hardness is closely related to the problem of whether $\EXP \neq \BPP$. In more detail, let $Kt(x)$ denote the Levin-Kolmogorov Complexity of the string $x$; that is, $Kt(x) = \min_{\desc \in \bitset^*, t \in \N}\{|\desc| + \lceil \log t \rceil: U(\desc, 1^t) = x\}$, where $U$ is a universal Turing machine, and $U(\desc,1^t)$ denotes the output of the program $\Pi$ after $t$ steps, and let $\mktp$ denote the language of pairs $(x,k)$ having the property that $Kt(x) \leq k$.
We demonstrate that:
- $\mktp \notin \HeurpBPP$ (i.e., $\mktp$ is infinitely-often \emph{two-sided error} mildly average-case hard) iff infinititely-often OWFs exist.
- $\mktp \notin \AvgpBPP$ (i.e., $\mktp$ is infinitely-often \emph{errorless} mildly average-case hard) iff $\EXP \neq \BPP$.
Thus, the only ``gap'' towards getting (infinitely-often) OWFs from the assumption that $\EXP \neq \BPP$ is the seemingly ``minor'' technical gap between two-sided error and errorless average-case hardness of the $\mktp$ problem. As a corollary of this result, we additionally demonstrate that any reduction from errorless to two-sided error average-case hardness for $\mktp$ implies (unconditionally) that $\NP \neq \P$. 

We finally consider other alternative notions of Kolmogorov complexity---including space-bounded Kolmogorov complexity and conditional Kolmogorov complexity---and show how average-case hardness of problems related to them characterize log-space computable OWFs, or OWFs in $\NC^0$.</summary>
    <updated>2021-04-23T09:45:30Z</updated>
    <published>2021-04-23T09:45:30Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-04-29T09:38:04Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1199907254169036789</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1199907254169036789/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/04/the-million-dollar-sermon.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1199907254169036789" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1199907254169036789" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/04/the-million-dollar-sermon.html" rel="alternate" type="text/html"/>
    <title>The Million Dollar Sermon</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Illinois Tech has one of the greatest origin stories for a university. In 1890 Frank Gunsaulus, a pastor on the south side of Chicago, gave a sermon where he said "If I had a million dollars I would build a school to provide students from all backgrounds meaningful roles in a changing industrial society". Philip Armour, a wealthy industrialist in the congregation, went up to Gunsaulus after the sermon and said, "if you give me five years for this school, I'll give you the million dollars". Thus started the Armour Institute of Technology which after some mergers became the Illinois Institute of Technology.</p><p>The "million dollar sermon" really happened, though the exact wording and even the exact year are lost to posterity or, as speculated, hidden in a cornerstone of one of the original campus buildings. </p><p>In 1890 we were in the beginnings of the second industrial revolution, a revolution of communication, transportation, electrification and soon the assembly line. The first revolution happened a century earlier with mechanization and the steam engine. The third revolution was computers and automation, and we are now in the early parts of the fourth industrial revolution, one based on data and information. </p><p>There are many parallels between 1890 and today. Like 1890, the private economy is dominated by a small number of large companies that have an outsized influence in our society. Like 1890, technology is changing faster than we can manage it. Like 1890, many workers are finding their skills quickly outdated.</p><p>Today Gunsaulus's words ring truer than ever. We more than ever need to provide students of all backgrounds meaningful roles in a changing technological society. </p></div>
    </content>
    <updated>2021-04-22T14:52:00Z</updated>
    <published>2021-04-22T14:52:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-04-28T21:02:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=18622</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/04/22/ken-turns-40/" rel="alternate" type="text/html"/>
    <title>Ken Turns 40</title>
    <summary>Every chess master was once a beginner—Irving Chernev Ken Regan started his Ph.D. 40 years ago from Oxford, in complexity theory, advised by Dominic Welsh. Ken continues to be a researcher in complexity theory, a teacher of computer science, a mentor of graduate students, a writer of books and more. He has long been on […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Every chess master was once a beginner—Irving Chernev</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/22/ken-turns-40/ken2/" rel="attachment wp-att-18624"><img alt="" class="alignright  wp-image-18624" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ken2.png?w=150&amp;ssl=1"/></a></p>
<p>
Ken Regan started his Ph.D. 40 years ago from Oxford, in complexity theory, advised by Dominic <a href="https://en.wikipedia.org/wiki/Dominic_Welsh">Welsh</a>. Ken continues to be a researcher in complexity theory, a teacher of computer science, a mentor of graduate students, a writer of books and more. He has long been on the faculty of the <a href="https://cse.buffalo.edu/~regan/">Department of Computer Science</a> and Engineering at Buffalo. </p>
<p>
Today I thought I would thank Ken for his many wonderful accomplishments. </p>
<p>
Ken is a great friend and long time co-author of mine. We also write this blog together. He has done many things—one colorful thing is the <a href="https://cse.buffalo.edu/~regan/papers/ComplexityPoster.jpg">poster</a>. Ken is a strong chess player—a chess International Master just below the grandmaster level and rated at 2372—roughly. </p>
<p>
We will highlight his continued work in complexity theory and his work in detecting chess cheating.</p>
<p/><h2> Complexity Theory </h2><p/>
<p/><p>
Ken and I have just released a second edition of our book on quantum algorithms: <a href="https://www.thriftbooks.com/w/introduction-to-quantum-algorithms-via-linear-algebra-second-edition_kenneth-w-regan_richard-j-lipton/26771326/item/44480377/?gclid=Cj0KCQjw1PSDBhDbARIsAPeTqrd5GXdcE5MG1a_Ue1T4vDhz4_adZNPdNAslCRxsyFUroKj6AgxRGlkaAulSEALw_wcB#idiq=44480377&amp;edition=41576984"> Introduction to Quantum Algorithms Via Linear Algebra, Second Edition</a> </p>
<blockquote><p><b> </b> <em> Quantum computing explained in terms of elementary linear algebra, emphasizing computation and algorithms and requiring no background in physics. This introduction to quantum algorithms is concise but comprehensive, covering many key algorithms. It is mathematically rigorous but requires minimal background and assumes no knowledge of quantum theory or quantum mechanics. </em>
</p></blockquote>
<p>I must add that Ken did the lion share of the work on writing this second edition.</p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/04/22/ken-turns-40/quantum/" rel="attachment wp-att-18625"><img alt="" class="aligncenter size-medium wp-image-18625" height="300" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/quantum.jpg?resize=201%2C300&amp;ssl=1" width="201"/></a>
</td>
</tr>
<tr>
</tr>
</tbody></table>
<p>Please note a special offer: Buy one, get another for full price. </p>
<p>
In another part of complexity theory, Ken has just had a paper accepted: <i>Multi-Structural Games and Number of Quantifiers</i> with Ronald Fagin, Jonathan Lenchner, and Nikhil Vyas. This will appear at <a href="http://easyconferences.eu/lics2021/">LICS 2021</a> this summer.</p>
<p>
The paper defines a new type of game that captures the number of quantifies needed for certain properties. This is neat—see the paper for details.</p>
<p>
</p><p/><h2> Chess Cheating—How? </h2><p/>
<p/><p>
The area of detecting chess cheating is one that Ken works in. Moreover he is perhaps the leader in the world. That is the leader in detecting when a player cheated at playing chess. </p>
<p>
What is this? In games like poker, games that rely on cards, it is long been an issue that people can <a href="https://en.wikipedia.org/wiki/Cheating_in_poker">cheat</a>. Cards can be marked for example. The dealer can try and control what cards a player gets. These are ancient issues for card games. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/04/22/ken-turns-40/card/" rel="attachment wp-att-18626"><img alt="" class="aligncenter size-medium wp-image-18626" height="182" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/card.png?resize=300%2C182&amp;ssl=1" width="300"/></a>
</td>
</tr>
<tr>
</tr>
</tbody></table>
<p>
What is this for <a href="https://en.wikipedia.org/wiki/Cheating_in_chess">chess</a>? The pieces cannot be marked to any advantage: a king is king, a pawn is a pawn and so on. But a player can cheat in a simple manner. They can use the moves of a computer program instead of their own. The problem in chess is that computer programs currently play at a level vastly higher than even a strong player. Stockfish, a top program, plays at around <a href="https://ccrl.chessdom.com/ccrl/4040/">3551</a>. </p>
<p>
Recall Ken is around 2372. That places him via the Elo <a href="https://en.wikipedia.org/wiki/Chess_rating_system">rating</a> at IM: </p>
<ul>
<li>
2500-2700	most Grandmasters (GM) <p/>
</li><li>
2400-2500	most International Masters (IM) and some Grandmasters (GM) <p/>
</li><li>
2300-2400	most FIDE Masters (FM) and some International Masters (IM) <p/>
</li><li>
2200-2300	FIDE Candidate Masters (CM), most national masters
</li></ul>
<p>Note: the computer therefore plays much better than all known GM’s. </p>
<p>
</p><p/><h2> Chess Cheating—Detecting? </h2><p/>
<p/><p>
Enter Ken. He has been studying how to detect whether or not a player is using a computer’s moves rather than their own moves. He has worked on this for many years, with good success. Note: this is a real <a href="https://www.theguardian.com/sport/2020/oct/16/chesss-cheating-crisis-paranoia-has-become-the-culture">problem</a>: </p>
<blockquote><p><b> </b> <em> In one chess tournament, five of the top six were disqualified for cheating. In another, the doting parents of 10-year-old competitors furiously rejected evidence that their darlings were playing at the level of the world No 1. </em>
</p></blockquote>
<p/><p>
An obvious idea is to not let a player have access to any computer. This is naive for several reasons: </p>
<ol>
<li>
A player can use their cellphone secretly—in the toilet? <p/>
</li><li>
A player could conceal the computer on themselves—computers are small? <p/>
</li><li>
A player could be playing chess online—impossible to stop them?
</li></ol>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/04/22/ken-turns-40/heel/" rel="attachment wp-att-18627"><img alt="" class="aligncenter size-medium wp-image-18627" height="169" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/heel.png?resize=300%2C169&amp;ssl=1" width="300"/></a>
</td>
</tr>
<tr>
</tr>
</tbody></table>
<p>
</p><p/><h2> Chess Cheating—How to Detect </h2><p/>
<p/><p>
This led Ken to consider the following problem: Suppose that some player makes a series of moves during a game. Check how well their moves agree with Stockfish or some other computer program. Then claim the player cheated provided they agree too often with the program. </p>
<p>
This sounds simple. Compare the computer’s move and the player’s moves. If these agree too often then say the player has cheated.</p>
<p>
Simple. Unfortunately not. There are many complications: </p>
<ol>
<li>
In chess sometimes moves are “in book”. Especially at the beginning the best move may be well known. <p/>
</li><li>
In chess sometimes moves are “forced”. There may be a unique legal move. <p/>
</li><li>
A player may only use the computer when the position is “hard”. <p/>
</li><li>
The computer may suggest several moves. These moves may all be about the same quality.
</li></ol>
<p>Clearly all these make the problem—did the player cheat—complex. Difficult. A further complicating factor is that even a weak player will sometimes randomly agree with the computer. That is even a weaker player can make a great move. </p>
<p>
Perhaps the shock is that Ken has been able to build software that is able to correctly decide when a player cheated or not. His method is good enough that it is used in practice on real players. It has led to actual penalties on players, and has saved others from false claims. </p>
<p>
I must add that his software is quite impressive. The test to see if a player cheated involves the running of chess computer programs. These programs like <a href="https://stockfishchess.org">Stockfish</a> were made to be used by one player. They were not designed to be used as a subroutine in an automated search. Perhaps for a complexity theorist Ken might have a top ranking for writing the most real programs. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p>
Correction: Ken is 40th from Princeton as an undergrad. Ken is 35th from Oxford for Ph.D. See Ken on a 40th Reunion for Princeton Class of ’81 <a href="https://www.youtube.com/watch?v=S1LDJZglNUg">panel</a>   [<b>Ken:</b> A one-word fix did the trick, changing “obtained” to “started” in the first sentence.  It’s a Trans-Pond-er difference: I count as ’81 both at Princeton and Oxford (Merton College) because the latter goes by the starting year.  The photo is from Glenveagh Castle, Ireland, on a June 2019 trip with my family.]</p>
<p>
Ken <a href="https://www.newser.com/story/297646/pandemic-has-caused-cheating-crisis-in-chess.html">says</a>: “The pandemic has brought me as much work in a single day as I have had in a year previously,” said Prof Kenneth Regan, an international chess master and computer scientist whose model is relied on by the sport’s governing body, FIDE, to detect suspicious patterns of play. “It has ruined my sabbatical.”</p>
<p>
See this <a href="https://cse.buffalo.edu/~regan/personal/JuneCLarticleKWR.pdf">article</a> for more detail on Ken’s work. This is by Howard Goldowsky.</p>
<p/></font></font></div>
    </content>
    <updated>2021-04-22T13:00:19Z</updated>
    <published>2021-04-22T13:00:19Z</published>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="People"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-04-29T09:38:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/04/22/postdoc-in-algorithms-at-university-of-vienna-apply-by-may-16-2021/</id>
    <link href="https://cstheory-jobs.org/2021/04/22/postdoc-in-algorithms-at-university-of-vienna-apply-by-may-16-2021/" rel="alternate" type="text/html"/>
    <title>Postdoc in Algorithms at University of Vienna (apply by May 16, 2021)</title>
    <summary>We are looking for an excellent researcher to join our project on “Fast Algorithms for a Reactive Network Layer” funded by the Austrian NSF. It will lay the algorithmic foundations of more adaptive networks, using algorithmic tools from many areas of algorithms research. This is a collaboration between the research groups of Monika Henzinger at […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We are looking for an excellent researcher to join our project on “Fast Algorithms for a Reactive Network Layer” funded by the Austrian NSF. It will lay the algorithmic foundations of more adaptive networks, using algorithmic tools from many areas of algorithms research. This is a collaboration between the research groups of Monika Henzinger at U Vienna and of Stefan Schmid at TU Berlin.</p>
<p>Website: <a href="https://taa.cs.univie.ac.at/">https://taa.cs.univie.ac.at/</a><br/>
Email: applications.taa@univie.ac.at</p></div>
    </content>
    <updated>2021-04-22T09:02:27Z</updated>
    <published>2021-04-22T09:02:27Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-04-29T09:39:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/04/21/postdoc-at-university-of-birmingham-uk-apply-by-may-20-2021/</id>
    <link href="https://cstheory-jobs.org/2021/04/21/postdoc-at-university-of-birmingham-uk-apply-by-may-20-2021/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Birmingham, UK (apply by May 20, 2021)</title>
    <summary>We seek a Research Fellow (3 yr) to work on an UKRI-funded project on co-evolution. Co-evolutionary algorithms mimick natural selection, e.g. for minmax optimisation or learning game playing strategies. The postdoc will develop time-complexity analysis of co-evolutionary algorithms, and should have a track record in theory of evolutionary computation, algorithmic game theory, and/or algorithms. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We seek a Research Fellow (3 yr) to work on an UKRI-funded project on co-evolution. Co-evolutionary algorithms mimick natural selection, e.g. for minmax optimisation or learning game playing strategies.</p>
<p>The postdoc will develop time-complexity analysis of co-evolutionary algorithms, and should have a track record in theory of evolutionary computation, algorithmic game theory, and/or algorithms.</p>
<p>Website: <a href="https://www.jobs.ac.uk/job/CFK453/research-fellow-in-theory-of-co-evolutionary-computation">https://www.jobs.ac.uk/job/CFK453/research-fellow-in-theory-of-co-evolutionary-computation</a><br/>
Email: p.k.lehre@cs.bham.ac.uk</p></div>
    </content>
    <updated>2021-04-21T14:30:28Z</updated>
    <published>2021-04-21T14:30:28Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-04-29T09:39:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=554</id>
    <link href="https://tcsplus.wordpress.com/2021/04/21/tcs-talk-wednesday-april-28-ronen-eldan-weizmann-institute/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, April 28 — Ronen Eldan, Weizmann Institute</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, April 28th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Ronen Eldan from the Weizmann Institute will speak about “Localization, stochastic localization, and Chen’s recent breakthrough on the Kannan-Lovasz-Simonivits conjecture” (abstract below). You can reserve a spot as […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, April 28th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <a href="http://www.wisdom.weizmann.ac.il/~ronene/"><strong>Ronen Eldan</strong></a> from the Weizmann Institute will speak about “<em>Localization, stochastic localization, and Chen’s recent breakthrough on the Kannan-Lovasz-Simonivits conjecture</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards, so people who did not sign up will still be able to watch the talk) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: The Kannan-Lovasz and Simonovits (KLS) conjecture considers the following isoperimetric problem on high-dimensional convex bodies: Given a convex body <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002"/>, consider the optimal way to partition it into two pieces of equal volume so as to minimize their interface. Is it true that up to a universal constant, the minimal partition is attained via a hyperplane cut? Roughly speaking, this question can be thought of as asking “to what extent is a convex set a good expander”?</p>
<p>In analogy to expander graphs, such lower bounds on the capacity would imply bounds on mixing times of Markov chains associated with the convex set, and so this question has direct implications on the complexity of many computational problems on convex sets. Moreover, it was shown that a positive answer would imply Bourgain’s slicing conjecture.</p>
<p>Very recently, Yuansi Chen obtained a striking breakthrough, nearly solving this conjecture. In this talk, we will overview some of the central ideas used in the proof. We will start with the classical concept of “localization” (a very useful tool to prove concentration inequalities) and its extension, stochastic localization – the main technique used in the proof.</p></blockquote></div>
    </content>
    <updated>2021-04-21T04:51:33Z</updated>
    <published>2021-04-21T04:51:33Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2021-04-29T09:41:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5460</id>
    <link href="https://www.scottaaronson.com/blog/?p=5460" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5460#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5460" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Doubts about teapot supremacy: my reply to Richard Borcherds</title>
    <summary xml:lang="en-US">Richard Borcherds is a British mathematician at Berkeley, who won the 1998 Fields Medal for the proof of the monstrous moonshine conjecture among many other contributions. A couple months ago, Borcherds posted on YouTube a self-described “rant” about quantum computing, which was recently making the rounds on Facebook and which I found highly entertaining. Borcherds […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://en.wikipedia.org/wiki/Richard_Borcherds">Richard Borcherds</a> is a British mathematician at Berkeley, who won the 1998 Fields Medal for the proof of the <a href="https://en.wikipedia.org/wiki/Monstrous_moonshine">monstrous moonshine conjecture</a> among many other contributions.  A couple months ago, Borcherds posted on YouTube a <a href="https://www.youtube.com/watch?v=sFhhQRxWTIM"><strong>self-described “rant” about quantum computing</strong></a>, which was recently making the rounds on Facebook and which I found highly entertaining.</p>



<p>Borcherds points out that the term “quantum supremacy” means only that quantum computers can outperform existing classical computers on <em>some</em> benchmark, which can be chosen to show maximum advantage for the quantum computer.  He allows that <a href="https://en.wikipedia.org/wiki/Boson_sampling">BosonSampling</a> could have some value, for example in calibrating quantum computers or in comparing one quantum computer to another, but he decries the popular conflation of quantum supremacy with the actual construction of a scalable quantum computer able (for example) to run Shor’s algorithm to break RSA.</p>



<p>Borcherds also proposes a “teapot test,” according to which any claim about quantum computers can be dismissed if an analogous claim would hold for a teapot (which he brandishes for the camera).  For example, there are many claims to solve practical optimization and machine learning problems by “quantum/classical hybrid algorithms,” wherein a classical computer does most of the work but a quantum computer is somehow involved.  Borcherds points out that, at least as things stand in early 2021, in most or all such cases, the classical computer could’ve probably done as well entirely on its own.  So then if you put a teapot on top of your classical computer while it ran, you could equally say you used a “classical/teapot hybrid approach.”</p>



<p>Needless to say, Borcherds is correct about all of this.  I’ve made similar points on this blog for 15 years, although less Britishly.  I’m delighted to have such serious new firepower on the scoffing-at-QC-hype team.</p>



<p>I do, however, have one substantive disagreement.  At one point, Borcherds argues that sampling-based quantum supremacy itself fails his teapot test.  For consider the computational problem of predicting how many pieces a teapot will break into if it’s dropped on the ground.  Clearly, he says, the teapot itself will outperform any simulation running on any existing classical computer at that task, and will therefore achieve “teapot supremacy.”  But who cares??</p>



<p>I’m glad that Borcherds has set out, rather crisply, an objection that’s been put to me many times over the past decade.  The response is simple: <em>I don’t believe the teapot really does achieve teapot supremacy on the stated task!  At the least, I’d need to be shown why.  You can’t just assert it without serious argument.</em></p>



<p>If we want to mirror the existing quantum supremacy experiments, then the teapot computational problem, properly formulated, should be: given as input a description of a teapot’s construction, the height from which it’s dropped, etc., <em>output a sample from the probability distribution</em> over the number of shards that the teapot will break into when it hits the floor.</p>



<p>If so, though, then clearly a classical computer can easily sample from the same distribution!  Why?  Because presumably we agree that there’s a negligible probability of more than (say) 1000 shards.  So the distribution is characterized by a list of at most 1000 probabilities, which can be estimated empirically (at the cost of a small warehouse of smashed teapots) and thereafter used to generate samples.  In the plausible event that the distribution is (say) a Gaussian, it’s even easier: just estimate the mean and variance.</p>



<p>A couple days ago, I was curious what the distribution looked like, so I decided to order some teapots from Amazon and check.  Unfortunately, real porcelain teapots are <em>expensive</em>, and it seemed vaguely horrific to order dozens (as would be needed to get reasonable data) for the sole purpose of smashing them on my driveway.  So I hit on what seemed like a perfect solution: I ordered <em>toy</em> teapots, which were much smaller and cheaper.  Alas, when my toy “porcelain” teapots arrived yesterday, they turned out (unsurprisingly in retrospect for a children’s toy) to be some sort of plastic or composite material, meaning that they <em>didn’t</em> break unless one propelled them downward forcefully.  So, while I can report that they tended to break into one or two large pieces along with two or three smaller shards, I found it impossible to get better data.  (There’s a reason why I became a <em>theoretical</em> computer scientist…)</p>



<figure class="wp-block-image size-large"><img alt="" src="https://www.scottaaronson.com/teapot.jpg"/></figure>



<p>The good news is that my 4-year-old son had an absolute <em>blast</em> smashing toy teapots with me on our driveway, while my 8-year-old daughter was thrilled to take the remaining, unbroken teapots for her dollhouse.  I apologize if this fails to defy gender stereotypes.</p>



<p>Anyway, it might be retorted that it’s not good enough to sample from a probability distribution: what’s wanted, rather, is to calculate how many pieces this <em>specific</em> teapot will break into, given all the microscopic details of it and its environment.  Aha, this brings us to a crucial conceptual point: in order for something to count as an “input” to a computer, <em>you need to be able to set it freely</em>.  Certainly, at the least, you need to be able to measure and record the input in its entirety, so that someone trying to reproduce your computation on a standard silicon computer would know exactly which computation to do.  You don’t get to claim computational supremacy based on a problem with secret inputs: that’s like failing someone on a math test without having fully told them the problems.</p>



<p>Ability to set and know the inputs is <em>the</em> key property that’s satisfied by Google’s quantum supremacy experiment, and to a lesser extent by the USTC BosonSampling experiment, but that’s not satisfied at all by the “smash a teapot on the floor” experiment.  Or perhaps it’s better to say: influences on a computation that vary uncontrollably and chaotically, like gusts of air hitting the teapot as it falls to the floor, shouldn’t be called “inputs” at all; they’re simply <em>noise sources</em>.  And what one does with noise sources is to try to estimate their distribution and average over them—but in that case, as I said, there’s no teapot supremacy.</p>



<p>A Facebook friend said to me: that’s well and good, but surely we could change Borcherds’s teapot experiment to address this worry?  For example: add a computer-controlled lathe (or even a 3D printer), with which you can build a teapot in an arbitrary shape of your choice.  Then consider the problem of sampling from the probability distribution over how many pieces <em>that</em> teapot will smash into, when it’s dropped from some standard height onto some standard surface.  I replied that this is indeed more interesting—in fact, it already seems more like what engineers do in practice (still, sometimes!) when building wind tunnels, than like a silly reductio ad absurdum of quantum supremacy experiments.  On the other hand, <em>if</em> you believe the <a href="https://inst.eecs.berkeley.edu/~cs191/fa08/lectures/lecture17.pdf">Extended Church-Turing Thesis</a>, then as long as your analog computer is governed by classical physics, it’s presumably inherently limited to an <a href="https://en.wikipedia.org/wiki/Avogadro_constant">Avogadro’s number</a> type speedup over a standard digital computer, whereas with a quantum computer, you’re limited only by the exponential dimensionality of Hilbert space, which seems more interesting.</p>



<p>Or maybe I’m wrong—in which case, I look forward to the first practical demonstration of teapot supremacy!  Just like with quantum supremacy, though, it’s not enough to <em>assert</em> it; you need to … put the tea where your mouth is.</p>



<p><strong><span class="has-inline-color has-vivid-red-color">Update:</span></strong> On the suggestion of <a href="https://cs.nyu.edu/davise/">Ernest Davis</a>, who I can now reveal as the Facebook friend mentioned above, I just ordered some <a href="https://www.ssww.com/item/terra-cotta-pots-3-1-8-PL807/index.php?cid=3358&amp;gclid=Cj0KCQjw9_mDBhCGARIsAN3PaFOKHOxEAHqA-WjzGS5lFgass_iNz27V88AZdGe5e26GTsrJUX0ZNL4aAqOzEALw_wcB&amp;fbclid=IwAR1eBc9xXODJ3a15ukebh1loN9XNpl7aD2Xiihsb2H7JvZVBKLKC10OwIys">terra cotta flower pots</a>, which look cheap, easily smashable, and environmentally friendly, and which will hopefully be acceptable substitutes for porcelain teapots in a new experiment.  (Not that my main arguments in this post hinge on the results of such an experiment!  That’s the power of theory.)</p>



<p><strong><span class="has-inline-color has-vivid-red-color">Another Update:</span></strong> Some of you might enjoy <a href="https://www.scientificamerican.com/article/will-quantum-computing-ever-live-up-to-its-hype/">John Horgan’s <em>Scientific American</em> column</a> on reality vs. hype in quantum computing, based on conversations with me and with Terry Rudolph of PsiQuantum.</p></div>
    </content>
    <updated>2021-04-20T18:55:39Z</updated>
    <published>2021-04-20T18:55:39Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-04-25T20:04:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.let-all.com/blog/?p=39</id>
    <link href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/" rel="alternate" type="text/html"/>
    <title>Introducing ALT Highlights 2021</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The 32nd International Conference on Algorithmic Learning Theory (ALT 2021) just wrapped up, featuring a wide selection of exciting results at the frontiers of learning theory. The proceedings and all talk recordings are available online for perusal.  Did you miss out on the conference? Don’t have time to go through all the proceedings? Fear not, […]</p>
<p>The post <a href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/" rel="nofollow">Introducing ALT Highlights 2021</a> appeared first on <a href="https://www.let-all.com/blog" rel="nofollow">The Learning Theory Alliance Blog</a>.</p></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The 32nd International Conference on Algorithmic Learning Theory (<a href="http://algorithmiclearningtheory.org/alt2021/">ALT 2021</a>) just wrapped up, featuring a wide selection of exciting results at the frontiers of learning theory. The <a href="http://proceedings.mlr.press/v132/">proceedings</a> and all <a href="https://www.youtube.com/channel/UC7wMo5OivSnsQJNfZm8zmJQ/videos">talk recordings</a> are available online for perusal. </p>



<p>Did you miss out on the conference? Don’t have time to go through all the proceedings? Fear not, the <a href="https://let-all.com/">Learning Theory Alliance</a> is pleased to bring you ALT Highlights, a series of blog posts spotlighting various happenings at ALT, including plenary talks, tutorials, trends in learning theory, and more!</p>



<p>In order to reach a broad audience in learning theory, we’ll be releasing these posts across a number of different blogs. All content will be linked from this post, so be sure to bookmark this post so you don’t miss anything!</p>



<p>ALT Highlights will be brought to you by an amazing team of junior researchers, written by <a href="https://people.eecs.berkeley.edu/~kush/">Kush Bhatia</a>, <a href="https://www.comp.nus.edu.sg/~sutanu/">Sutanu Gayen</a>, <a href="https://web.stanford.edu/~mglasgow/">Margalit Glasgow</a>, <a href="https://sites.google.com/view/michal-moshkovitz">Michal Moshkovitz</a>, <a href="https://www.ttic.edu/students/">Keziah Naggita</a>, and <a href="https://sites.google.com/site/cyrusrashtchian/">Cyrus Rashtchian</a>, and overseen and edited by <a href="http://www.gautamkamath.com/">Gautam Kamath</a>. </p>



<p>Links to articles:<br/>1. <a href="https://hunch.net/?p=13762948">An Interview with Joelle Pineau</a><br/>2. <a href="https://differentialprivacy.org/alt-highlights/">An Equivalence between Private Learning and Online Learning</a></p>



<p>Next article coming April 28!</p>
<p>The post <a href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/" rel="nofollow">Introducing ALT Highlights 2021</a> appeared first on <a href="https://www.let-all.com/blog" rel="nofollow">The Learning Theory Alliance Blog</a>.</p></div>
    </content>
    <updated>2021-04-20T16:26:22Z</updated>
    <published>2021-04-20T16:26:22Z</published>
    <category term="ALT Highlights"/>
    <author>
      <name>admin</name>
    </author>
    <source>
      <id>https://www.let-all.com/blog</id>
      <logo>https://i1.wp.com/www.let-all.com/blog/wp-content/uploads/2021/04/logo.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://www.let-all.com/blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://www.let-all.com/blog" rel="alternate" type="text/html"/>
      <title>The Learning Theory Alliance Blog</title>
      <updated>2021-04-29T09:43:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/04/20/early-career-scientists-at-amazon-apply-by-may-14-2021/</id>
    <link href="https://cstheory-jobs.org/2021/04/20/early-career-scientists-at-amazon-apply-by-may-14-2021/" rel="alternate" type="text/html"/>
    <title>Early career scientists at Amazon (apply by May 14, 2021)</title>
    <summary>Amazon Advertising is launching a new, 2-year program for recent PhDs. It offers full-time two-year positions, aimed at recent PhD graduates who want to innovate, publish, and have their work impact millions of customers. Key areas include but are not limited to: machine learning, economics, marketing, operations research, and statistics. The application deadline is May […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Amazon Advertising is launching a new, 2-year program for recent PhDs. It offers full-time two-year positions, aimed at recent PhD graduates who want to innovate, publish, and have their work impact millions of customers. Key areas include but are not limited to: machine learning, economics, marketing, operations research, and statistics. The application deadline is May 14.</p>
<p>Website: <a href="https://www.amazon.science/amazon-advertising-opens-applications-for-early-career-scientists">https://www.amazon.science/amazon-advertising-opens-applications-for-early-career-scientists</a><br/>
Email: advertising-es-program@amazon.com</p></div>
    </content>
    <updated>2021-04-20T15:56:51Z</updated>
    <published>2021-04-20T15:56:51Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-04-29T09:39:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/055</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/055" rel="alternate" type="text/html"/>
    <title>TR21-055 |  Cryptography from Sublinear-Time Average-Case Hardness of Time-Bounded Kolmogorov Complexity | 

	Yanyi Liu, 

	Rafael Pass</title>
    <summary>Let $\mktp[s]$ be the set of strings $x$ such that $K^t(x) \leq s(|x|)$, where $K^t(x)$ denotes the $t$-bounded Kolmogorov complexity of the truthtable described by $x$. Our main theorem shows that for an appropriate notion of mild average-case hardness, for every $\varepsilon&gt;0$, polynomial $t(n) \geq (1+\varepsilon)n$, and every ``nice'' class $\F$ of super-polynomial functions, the following are equivalent:
- the existence of some function $T \in \F$ such that $T$-hard one-way functions (OWF) exists (with non-uniform security);
- the existence of some function $T \in \F$ such that $\mktp[T^{-1}]$ is mildly average-case hard with respect to sublinear-time non-uniform algorithms (with running-time $n^{\delta}$ for some $0&lt;\delta&lt;1$).
For instance, existence of subexponentially-hard (resp. quasi-polynomially-hard) OWFs is equivalent to mild average-case hardness of $\mktp[\poly\log n]$ (resp. $\mktp[2^{O(\sqrt{\log n})})]$) w.r.t. sublinear-time non-uniform algorithms.

We additionally note that if we want to deduce $T$-hard OWFs where security holds w.r.t. \emph{uniform} $T$-time probabilistic attackers (i.e., uniformly-secure OWFs), it suffices to assume sublinear time hardness of $\mktp$ w.r.t. uniform probabilistic sublinear-time attackers. We complement this result by proving lower bounds that come surprisingly close to what is required to unconditionally deduce the existence of (uniformly-secure) OWFs: $\mktp[\poly\log n]$ is worst-case hard w.r.t. uniform probabilistic sublinear-time algorithms, and $\mktp[n-\log n]$ is mildly average-case hard for all $O(t(n)/n^3)$-time deterministic algorithms.</summary>
    <updated>2021-04-20T11:36:21Z</updated>
    <published>2021-04-20T11:36:21Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-04-29T09:38:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3517</id>
    <link href="https://agtb.wordpress.com/2021/04/20/the-stony-brook-international-conference-on-game-theory-july-5-8-2021/" rel="alternate" type="text/html"/>
    <title>The Stony Brook International Conference on Game Theory, July 5-8, 2021</title>
    <summary>Call for Participation and Poster submission: The 32nd annual Stony Brook International Conference on Game Theory  will be held online July 5 – 8, 2021. This year the conference will emphasize recent research at the intersection of computer science and economics. We will also celebrate the recent Nobel prize to Paul Milgrom and Robert Wilson, who will both deliver […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Call for Participation and Poster submission:</p>



<p><a href="http://www.gtcenter.org/?page=Conference.html" rel="noreferrer noopener" target="_blank">The 32nd annual Stony Brook International Conference on Game Theory </a> will be held online July 5 – 8, 2021. This year the conference will emphasize recent research at the intersection of computer science and economics. We will also celebrate the recent Nobel prize to Paul Milgrom and Robert Wilson, who will both deliver an extended version of their Nobel prize speech.</p>



<p>The conference will begin and end with a reception in honor of Paul Milgrom and Robert Wilson. The schedule is available <a href="http://www.gtcenter.org/index.php?page=Downloads/ConfSchedule.html" rel="noreferrer noopener" target="_blank">here</a>. The main program will consist of invited papers and talks.</p>



<p>We invite graduate students and junior faculty to submit recent work for <a href="https://docs.google.com/forms/d/1I4aipMKrhlmthfF8W0QeclGIJgF9oLa5xb5O-tJA7PA/viewform?edit_requested=true" rel="noreferrer noopener" target="_blank">poster sessions</a> which will be an integral part of the conference. The deadline for submission to the poster session is Friday, April 30<sup>th</sup>, 5pm est. The program for the poster session will be announced, Monday, May 17<sup>th</sup>.</p>



<p>If you would like to attend any of the sessions, please <a href="http://www.gtcenter.org/index.php?page=php/Login.php" rel="noreferrer noopener" target="_blank">Login</a> or <a href="http://www.gtcenter.org/index.php?page=php/Regform.php" rel="noreferrer noopener" target="_blank">Create Account</a> and RSVP for the events you would like to attend. As the conference date approaches, you will receive an email with more details on accessing and navigating Virtual Chair, the online, interactive event space that will host the conference.</p>



<p>Please feel free to share this information broadly. We look forward to your participation!</p>



<p><a href="https://campuspress.yale.edu/dirkbergemann/">Dirk Bergemann</a> and <a href="https://cs.tau.ac.il/~mfeldman">Michal Feldman</a></p>



<p>Organizers</p></div>
    </content>
    <updated>2021-04-20T10:40:49Z</updated>
    <published>2021-04-20T10:40:49Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>michalfeldman</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2021-04-29T09:38:26Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-628795981625377168</id>
    <link href="https://blog.computationalcomplexity.org/feeds/628795981625377168/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/04/an-investment-puzzle-and-speculation-as.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/628795981625377168" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/628795981625377168" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/04/an-investment-puzzle-and-speculation-as.html" rel="alternate" type="text/html"/>
    <title>An investment puzzle and speculation as to why some think its hard</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> This is a Guest Post by David Marcus. He gives a puzzle and its solution, which is interesting, and then speculates as to why some people get it wrong. </p><p>---------------------------------------------------------------------------</p><p>THE PROBLEM:</p><p>Investing Puzzle or Arithmetic Can Be Useful</p><p><br/></p><p>The following is an example of investment results that I saw in an</p><p>investment newsletter. There are two portfolios that use different</p><p>strategies. Both portfolios start with $1 million twenty years ago and</p><p>withdraw 5% each year. The idea is that you are retired and withdrawing</p><p>money to spend. Not all years are shown in the tables.</p><p><br/></p><p>Portfolio A</p><p><br/></p><p>Year   Return  Withdrawal    Balance</p><p>2000   15.31%      57,655  1,095,445</p><p>2005    1.81%      59,962  1,139,273</p><p>2008  -12.65%      51,000    969,004</p><p>2009   34.26%      65,049  1,235,936</p><p>2010   11.94%      69,175  1,314,331</p><p>2015   -2.48%      64,935  1,233,764</p><p>2020   10.27%      66,935  1,271,765</p><p>Total Withdrawal: 1,685,190</p><p>Change in Balance: 27.18%</p><p>======</p><p>Portfolio B</p><p>Year   Return  Withdrawal    Balance</p><p>2000   -0.95%      49,524    940,956</p><p>2005    3.80%      44,534    846,154</p><p>2008  -20.11%      35,922    682,523</p><p>2009   18.27%      40,360    766,833</p><p>2010   11.57%      42,777    812,764</p><p>2015    0.99%      50,767    964,567</p><p>2020   13.35%      65,602  1,246,433</p><p><br/></p><p>Total Withdrawal: 1,425,573</p><p>Change in Balance: 24.64%</p><p><br/></p><p>Portfolio A has a final balance that is 25,000 more than Portfolio B's and</p><p>had about 260,000 more in withdrawals. Does the example lend credence to</p><p>the Portfolio A strategy being better than the Portfolio B strategy?</p><p>---------------------------------------------------------------------------</p><p>THE ANSWER:</p><p>Investing Puzzle or Arithmetic Can Be Useful: Analysis</p><p><br/></p><p>Summary: The two portfolios have about the same performance over the 20</p><p>years. The difference is mainly due to Portfolio A having a good year or</p><p>years near the beginning before much money was withdrawn. The example</p><p>merely shows that it is better to withdraw money after a gain rather than</p><p>before.</p><p><br/></p><p>Detailed Analysis:</p><p><br/></p><p>The scenario is: Start with X = $1 million. Withdraw 5% a year.</p><p><br/></p><p>Define "gain factor" to be 1 plus the percentage return. For example, if a</p><p>portfolio returns 5%, then the gain factor is 1.05.</p><p><br/></p><p>Let A_j, j = 1, ..., 20, be the gain factors each year for portfolio A.</p><p><br/></p><p>Let B_j, j = 1, ..., 20 be the gain factors each year for portfolio B.</p><p><br/></p><p>The final amount in portfolio A is</p><p><br/></p><p>   F = X * A_1 * 0.95 * A_2 * 0.95 * ... * A_20 * 0.95 .</p><p><br/></p><p>The final amount in portfolio B is</p><p><br/></p><p>   G = X * B_1 * 0.95 * B_2 * 0.95 * ... * B_20 * 0.95 .</p><p><br/></p><p>From the "Change in Balance" values or the balances for year 2020, we see</p><p>that F and G are almost the same:</p><p><br/></p><p>   F = 1.271865 * X,</p><p>   G = 1.246433 * X.</p><p><br/></p><p>But, as we learned in elementary school, multiplication is commutative, so</p><p><br/></p><p>   F = X * 0.95^20 * \prod_{j=1}^20 A_j,</p><p>   G = X * 0.95^20 * \prod_{j=1}^20 B_j.</p><p><br/></p><p>Since F and G are almost the same, the total gains (product of the gain</p><p>factors) for the two portfolios are almost the same, i.e.,</p><p><br/></p><p>   \prod_{j=1}^20 A_j \approx \prod_{j=1}^20 B_j.</p><p><br/></p><p>Then what accounts for the big difference in the amounts withdrawn?</p><p>Portfolio A must have had some good years near the beginning. (We see in</p><p>the tables that Portfolio A did better in 2000 than Portfolio B.) So, all</p><p>the example shows is that it is better to withdraw your money after your</p><p>gains rather than before.</p><p><br/></p><p>To take an extreme example, suppose an investment is going to go up 100%</p><p>this year. It is better to take your money out at the end of the year</p><p>(after the gain) than at the beginning of the year (before the gain). This</p><p>is a triviality.</p><p><br/></p><p>The example tells us nothing useful about the two strategies.</p><p><br/></p><p>Note: The total gains aren't exactly the same, but the timing of the yearly</p><p>gains is what is driving the results. We have (rounding off)</p><p>   ( F - G ) / 0.95^20 = 70942.81 .</p><p>So, if there had been no withdrawals, the difference in the portfolio</p><p>balances would have been about $71,000, much less than the $260,000 +</p><p>$25,000 difference with the withdrawals.</p><p>---------------------------------------------------------</p><p>WHY IS THIS HARD FOR PEOPLE?</p><p>Many people have trouble with this puzzle. The difficulty may be that such</p><p>people don't make a mental model (or a written model) of the process that</p><p>is producing the balance. If you write down (or have in your head) a</p><p>formula for the balance, then you see that the gain factors are independent</p><p>of the withdrawal factors. That is, we could withdraw more or less money,</p><p>or even deposit money, without affecting the gain factors we would use in</p><p>the model. This then leads us to consider the gain factors on their own,</p><p>and to recognize that the gain factors are the true measures of how the</p><p>strategies perform.</p><p><br/></p><p><br/></p><div><br/></div></div>
    </content>
    <updated>2021-04-19T02:01:00Z</updated>
    <published>2021-04-19T02:01:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-04-28T21:02:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=18580</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/04/18/summing-up-the-primes/" rel="alternate" type="text/html"/>
    <title>Summing Up the Primes</title>
    <summary>Given the millennia that people have contemplated prime numbers, our continuing ignorance concerning the primes is stultifying—Richard Crandall and Carl Pomerance Sources: her site, Oberlin interview Lola Thompson is an Associate Professor of Mathematics at Utrecht University. She did her 2012 PhD thesis, Products of Distinct Cyclotomic Polynomials, under Pomerance at Dartmouth. Of course, she […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Given the millennia that people have contemplated prime numbers, our continuing ignorance concerning the primes is stultifying—Richard Crandall and Carl Pomerance</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/04/18/summing-up-the-primes/lola-2/" rel="attachment wp-att-18596"><img alt="" class="alignright wp-image-18596" height="175" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/lola.png?resize=165%2C175&amp;ssl=1" width="165"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Sources: <a href="http://www.lolathompson.com/">her site</a>, Oberlin <a href="https://www.oberlin.edu/news/conversation-lola-thompson">interview</a></font></td>
</tr>
</tbody>
</table>
<p>
Lola Thompson is an Associate Professor of Mathematics at Utrecht University. She did her 2012 PhD <a href="http://www.lolathompson.com/uploads/1/1/0/6/110629329/thesis.pdf">thesis</a>, <i>Products of Distinct Cyclotomic Polynomials</i>, under Pomerance at Dartmouth. Of course, she works in number theory.  Her thesis is numbered <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> on her publications <a href="http://www.lolathompson.com/research.html">page</a>.  </p>
<p>
Today we thought we would highlight a recent result of hers and its connections to complexity theory—indeed, to the realm of <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> vs. <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and beyond.</p>
<p>The interview linked below her photo at right includes these words:</p>
<blockquote><p>
Even [as an undergrad math major], I didn’t see myself having a future as a mathematician. I think that part of the issue was that I had never seen a female mathematician (none of my math professors at UChicago were women). A major turning point came when my department sent me to the Nebraska Conference for Undergraduate Women In Mathematics (NCUWM). While at NCUWM, I received a huge amount of encouragement. The idea of going to graduate school and becoming a mathematics professor had never occurred to me. It was also extremely helpful for me to see examples of female mathematicians. For the first time, I could imagine myself as a mathematician!
</p></blockquote>
<p>
She is paying that forward in mentoring women. See this <a href="https://women-in-numbers-europe-4.sites.uu.nl/wp-content/uploads/sites/658/2021/04/Poster-WIN.pdf">poster</a> for Utrecht’s hosting of next year’s 4th Women in Numbers – Europe <a href="https://women-in-numbers-europe-4.sites.uu.nl/">conference</a>, which is affiliated to the Women in Number Theory <a href="http://womeninnumbertheory.org/">network</a>. I also like her comments on undergraduate education <a href="http://www.lolathompson.com/uploads/1/1/0/6/110629329/jmm_2020_special_session_talk.pdf">here</a>. </p>
<p>
The <a href="http://www.lolathompson.com/uploads/1/1/0/6/110629329/mertensnew.pdf">paper</a> is joint with Harald Helfgott. The key “players” are the Möbius function and the Mertens function—named for August Möbius and for Franz Mertens. </p>
<p>
</p><h2> The Key Players </h2><p/>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/04/18/summing-up-the-primes/mm-2/" rel="attachment wp-att-18590"><img alt="" class="aligncenter size-medium wp-image-18590" height="140" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/mm.png?resize=300%2C140&amp;ssl=1" width="300"/></a></p>
<p>
The Möbius <a href="https://en.wikipedia.org/wiki/Mobius_function">function</a> was invented by Möbius in 1832. It is an important function throughout number theory. It is denoted by <img alt="{\mu(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>: </p>
<ul>
<li><img alt="{\mu(n) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%28n%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> if n is a square-free positive integer with an even number of prime factors.
</li><li><img alt="{\mu(n) = -1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%28n%29+%3D+-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> if n is a square-free positive integer with an odd number of prime factors.
</li><li><img alt="{\mu(n) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%28n%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> if n has a squared prime factor.
</li></ul>
<p>It is multiplicative: 	</p>
<p align="center"><img alt="\displaystyle  \mu(1) = 1 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmu%281%29+%3D+1+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>and 	</p>
<p align="center"><img alt="\displaystyle  \mu(ab) = \mu(a)\mu(b) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmu%28ab%29+%3D+%5Cmu%28a%29%5Cmu%28b%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>when <img alt="{a}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are co-prime. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/18/summing-up-the-primes/val/" rel="attachment wp-att-18586"><img alt="" class="aligncenter size-medium wp-image-18586" height="78" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/val.png?resize=300%2C78&amp;ssl=1" width="300"/></a></p>
<p>
Think of <img alt="{\mu(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> as a function that returns <img alt="{-1,0,+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%2C0%2C%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, which reveals important information about <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The <img alt="{M(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> part is the <a href="https://en.wikipedia.org/wiki/Mertens_function">Mertens</a> function, which gives average-like information on the value of <img alt="{\mu(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for <img alt="{0 \le n \le x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%5Cle+n+%5Cle+x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>: 	</p>
<p align="center"><img alt="\displaystyle  M(x) = \sum_{n \le x} \mu(n). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M%28x%29+%3D+%5Csum_%7Bn+%5Cle+x%7D+%5Cmu%28n%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>Of course <img alt="{M(x)/x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28x%29%2Fx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is exactly the average value. 	 </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/18/summing-up-the-primes/m/" rel="attachment wp-att-18587"><img alt="" class="aligncenter size-medium wp-image-18587" height="240" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/M.png?resize=300%2C240&amp;ssl=1" width="300"/></a></p>
<p>
A key property of the Möbius function is: 	</p>
<p align="center"><img alt="\displaystyle  \sum_{d | n} \mu(d) = 0 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bd+%7C+n%7D+%5Cmu%28d%29+%3D+0+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>unless <img alt="{n=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> then the sum is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>
</p><h2> Computing <img alt="{M(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>—the easy way </h2><p/>
<p>
Computing <img alt="{\mu(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for one value <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> seems to rely on the factorization of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Thus even computing it at a single value could be hard. That is it could require super-polynomial time in worst case. Clearly computing <img alt="{M(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is even harder: 	</p>
<p align="center"><img alt="\displaystyle  M(x+1)-M(x) = \mu(x+1). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M%28x%2B1%29-M%28x%29+%3D+%5Cmu%28x%2B1%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>	 One way to compute <img alt="{M(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is via complexity theory. This is <i>not</i> what Thompson does. </p>
<blockquote><p><b>Theorem 1</b> <em> Suppose that <img alt="{\mathsf{P = \#P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+%5C%23P%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Then we can compute <img alt="{M(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28x%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> in time polynomial in <img alt="{\log(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28x%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>. </em>
</p></blockquote>
<p>
This would be an exponential improvement over Thompson’s result. It probably shows how unlikely it is to get this collapse. But this is still open.</p>
<p>
Recall a set <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is in <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> provided given <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> one can decide whether <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is in the set <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in time polynomial in <img alt="{\log x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Recall <img alt="{\mathsf{\#P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5C%23P%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> given <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> computes the function that counts how many <img alt="{x \le N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cle+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> are in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> also in time polynomial in <img alt="{\log x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Certainly counting is at least as hard as deciding membership in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. We believe that in general it is much harder. Assuming they are equal means that any predicate that can be computed in polynomial time can also be exactly counted. For example: </p>
<ol>
<li>Given a graph: One can count the number of spanning trees.
</li><li>Given a graph: One can count the number of three colorings of the graph.
</li><li>Given a polynomial equation: One can count the number of solutions.
</li><li>And so on.
</li></ol>
<p>The conjecture is that <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is not equal to <img alt="{\mathsf{\#P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5C%23P%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. If <img alt="{\mathsf{P = \#P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+%5C%23P%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, then <img alt="{\mathsf{P=NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and more. Thus it probably is the case that they are not equal. But like much of complexity theory, this is wide open. </p>
<p>
</p><h2> Computing <img alt="{M(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>—the hard way </h2><p/>
<p>
Another way to compute <img alt="{M(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is via number theory not via complexity theory. This is what Thompson does—with no unproved assumption about <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and <img alt="{\#P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%23P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>
She proves this main result in her <a href="http://www.lolathompson.com/uploads/1/1/0/6/110629329/mertensnew.pdf">paper</a>—this is the paper we previously cited.</p>
<blockquote><p><b>Theorem 2</b> <em> There is an algorithm that computes <img alt="{M(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28x%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> in time 	</em></p><em>
<p align="center"><img alt="\displaystyle  O_{\epsilon}(x^{\delta} \log^{\delta+\epsilon} x). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++O_%7B%5Cepsilon%7D%28x%5E%7B%5Cdelta%7D+%5Clog%5E%7B%5Cdelta%2B%5Cepsilon%7D+x%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</em><p><em>Here <img alt="{\delta=3/5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%3D3%2F5%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> and the constant in <img alt="{O_{\epsilon}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO_%7B%5Cepsilon%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> depends on <img alt="{\epsilon&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>. </em>
</p></blockquote>
<p>
Note the time used is <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to some power. Before on the assumption that <img alt="{P=\#P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%3D%5C%23P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> we get that the time is polynomial in <img alt="{\log x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>
The proof is non-trivial. In order to give some idea we will give a few comments. Standard identities allow one to write, 	</p>
<p align="center"><img alt="\displaystyle  M(x) = 2M(\sqrt{x}) - \sum \mu(m_1)\mu(m_2), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M%28x%29+%3D+2M%28%5Csqrt%7Bx%7D%29+-+%5Csum+%5Cmu%28m_1%29%5Cmu%28m_2%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>over 	</p>
<p align="center"><img alt="\displaystyle  m_1,m_2 \le \sqrt{x}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++m_1%2Cm_2+%5Cle+%5Csqrt%7Bx%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>The insight is to look hardest at those values	</p>
<p align="center"><img alt="\displaystyle  m_1,m_2 \le x^{2/5}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++m_1%2Cm_2+%5Cle+x%5E%7B2%2F5%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>Their summary of what happens next:</p>
<blockquote><p><b> </b> <em> Our approach in Section 4 roughly amounts to analyzing the difference between reality and a model that we obtain via Diophantine approximation, in that we show that this difference has a simple description in terms of congruence classes and segments. This description allows us to compute the difference quickly, in part by means of table lookups. </em>
</p></blockquote>
<p/><p>
As often, we say to see the full paper for the details. Or you can follow her talk either in <a href="http://www.lolathompson.com/uploads/1/1/0/6/110629329/laten_charla.pdf">Spanish</a> or in <a href="http://www.lolathompson.com/uploads/1/1/0/6/110629329/copy_of_jmm_2021_talk.pdf">English</a>:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/04/18/summing-up-the-primes/mertens/" rel="attachment wp-att-18615"><img alt="" class="aligncenter wp-image-18615" height="308" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/Mertens.jpg?resize=480%2C308&amp;ssl=1" width="480"/></a></p>
<p/><p><br/>
The proof is clever and there seems to be no way to improve it to anything near what we get via complexity theory. Of course we can only do that in the presence of a very strong conjecture: 	</p>
<p align="center"><img alt="\displaystyle  \mathsf{P = \#P}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7BP+%3D+%5C%23P%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>
But what she could do was to implement the algorithm in her joint paper. The computation ran on a many-core machine for weeks. It gets <img alt="{M(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for <img alt="{x \le 10^{22}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cle+10%5E%7B22%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. </p>
<p>
This is one advantage of algorithms that do not rely on unproved conjectures. They can actually be implemented and executed. </p>
<p>
</p><h2> Open Problems </h2><p/>
<p>
Is there a richer fount for open problems than number theory?</p></font></font></div>
    </content>
    <updated>2021-04-18T13:25:29Z</updated>
    <published>2021-04-18T13:25:29Z</published>
    <category term="Ideas"/>
    <category term="P=NP"/>
    <category term="People"/>
    <category term="primes"/>
    <category term="Proofs"/>
    <category term="counting"/>
    <category term="Harald Helfgott"/>
    <category term="Lola Thompson"/>
    <category term="Mertens function"/>
    <category term="Mobius function"/>
    <category term="sieve"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-04-29T09:38:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/04/17/picks-shoelaces</id>
    <link href="https://11011110.github.io/blog/2021/04/17/picks-shoelaces.html" rel="alternate" type="text/html"/>
    <title>Pick’s shoelaces</title>
    <summary>Two important methods for computing area of polygons in the plane are Pick’s theorem and the shoelace formula. For a simple lattice polygon (a polygon with a single non-crossing boundary cycle, all of whose vertex coordinates are integers) with \(i\) integer points in its interior and \(b\) on the boundary, Pick’s theorem computes the area as</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Two important methods for computing area of polygons in the plane are <a href="https://en.wikipedia.org/wiki/Pick%27s_theorem">Pick’s theorem</a> and the <a href="https://en.wikipedia.org/wiki/Shoelace_formula">shoelace formula</a>. For a simple lattice polygon (a polygon with a single non-crossing boundary cycle, all of whose vertex coordinates are integers) with \(i\) integer points in its interior and \(b\) on the boundary, Pick’s theorem computes the area as</p>

\[A=i+b/2-1.\]

<p>The shoelace formula has various formulations, but in the version I’m going to use, it is a sum over oriented edges of the polygon. Let \((x,y)\to (x',y')\) denote an edge of the polygon that connects the two points \((x,y)\) and \((x',y')\), oriented in the clockwise direction around the polygon so that if you travel from \((x,y)\) to \((x',y')\) along this line segment, then the interior of the polygon will be on your right. Then, according to the shoelace formula, the area is</p>

\[A= \frac{1}{2}\sum_{(x,y)\to (x',y')}(x'-x)(y'+y).\]

<p>The shoelace formula looks messier than Pick’s formula but it’s much easier for computers to evaluate, both because polygons are generally represented in computers by their boundary rather than by the points they contain, and because there are often many fewer boundary edges than interior lattice points. It also doesn’t need the coordinates to be integers. But since these two formulas produce the same value, it would be interesting to see a more direct relation between them, explaining one formula in terms of the other.</p>

<h1 id="proof-of-the-shoelace-formula">Proof of the shoelace formula</h1>

<p>It is convenient to shift the polygon to lie entirely above the \(x\)-axis, without changing its area or number of grid points. After this shift, the nonzero terms \(\tfrac{1}{2}(x'-x)(y'+y)\) of the shoelace formula can be interpreted as the signed areas of trapezoids, extending vertically down from each non-vertical edge \((x,y)\to (x',y')\) to the \(x\)-axis. The reason for doing this shift is to orient all of the trapezoids the same way, downwards from their edges, and to avoid complications with edges that cross the \(x\)-axis.</p>

<p style="text-align: center;"><img alt="Trapezoids extending downward from each edge of a polygon" src="https://11011110.github.io/blog/assets/2021/pick-trapezoids.svg"/></p>

<p>Now consider what you would see from a generic point in the upper half-plane, if you looked straight upwards. (By “generic”, I mean that the point isn’t on an edge or directly below a vertex, because these would introduce additional and unimportant cases to our analysis.) Your line of site would pass through a sequence of zero or more polygon edges, whose trapezoids have positive sign when the line passes from inside the polygon to outside and negative sign when the line passes from outside to inside. Because of this alternation between inside and outside, between positive and negative, a point outside the polygon sees equally many edges of each sign, but a point in the polygon sees one more positive edge than negative.</p>

<p>Another way of expressing the same counts of signed edges above each point involves the <em>characteristic functions</em> of the polygon and the trapezoids, functions that are 1 inside each shape and zero outside it. The area of a shape is just the integral of its characteristic function. We’ll leave these functions undefined on the boundary of the shapes, but that’s ok because the boundary points contribute nothing to the total area. Then because of the cancellation between positive and negative signs, at the generic points where all of these functions are defined, the characteristic function of the polygon equals the signed sum of  characteristic functions of trapezoids. By the sum rule for integrals, the area of the polygon equals the signed sum of trapezoid areas. With a little more complication, the same argument can also be made to work directly for unshifted polygons.</p>

<h1 id="counting-lattice-points-in-trapezoids">Counting lattice points in trapezoids</h1>

<p>Can we use the same argument to prove Pick’s theorem, in the form that the shoelace formula equals Pick’s formula?  We’d like to interpret each term of the shoelace formula as a count over grid points, decompose the polygon in the same way into a sum of trapezoids, and argue that counting points in each trapezoid and then summing produces the same result as summing the trapezoids and then counting points. The difficulty is that now we can’t ignore the points on the axis or on boundary of the trapezoids, because their contribution to the count is nonzero.</p>

<p>First, let’s see how we can interpret each shoelace term as a grid point count.
Rotating a trapezoid around the midpoint of its defining edge produces another trapezoid whose union with the first trapezoid is an axis-aligned rectangle. Pick’s theorem is easy to see for these rectangles, in the simplified form that the area is the sum of one unit for integer points inside the rectangle, half a unit for integer points on its edges, and a quarter of a unit for integer points at its vertices. These fractional numbers of units are merely the amounts of rectangle area nearest to each point.</p>

<p style="text-align: center;"><img alt="The area of a lattice trapezoid equals the sum of units of lattice points: a whole unit for points in the trapezoid, half a unit on the boundary, and a quarter unit for the four corners" src="https://11011110.github.io/blog/assets/2021/pick-rectangle.svg"/></p>

<p>For the trapezoids we will use the same assignment of units to lattice points: one unit for points in the trapezoid, half on its boundary, and a quarter at its vertices, regardless of the actual trapezoid angles at those vertices. The figure above shows each point decorated in blue with its number of units.
The equality of area with total units still holds true, because both the area of the trapezoid and the total number of units for its integer points are half that of the rectangle. Each point off the edge that contributes its units to the trapezoid has a reflection that does not contribute its units. And each point on the edge contributes half its units to the trapezoid and half to the reflection. So the same terms \(\tfrac{1}{2}(x'-x)(y'+y)\) of the shoelace formula also count the contributions of units in each trapezoid to Pick’s formula.</p>

<h1 id="picks-formula-from-sums-of-trapezoids">Pick’s formula from sums of trapezoids</h1>

<p>We know how much each lattice point contributes to Pick’s formula: one unit if it is inside the polygon, half if it is on the boundary, or zero if it is outside. We also know how much each lattice point contributes to each trapezoid of the shoelace formula: one unit if it is interior to the trapezoid, half if it is on an edge, a quarter if it is on a corner, and none if it is exterior. In order to prove that Pick’s formula and the shoelace formula are equal, we want to show that all points make equal contributions. And for most points, this turns out to be true.</p>

<p>The vertical ray from any point \(p\) may pass through the boundary of the polygon in multiple ways: \(p\) itself may lie on the boundary, the ray may cross an edge of the boundary, it may pass through a vertex of the boundary that has edges to its left and right, or it may brush past the boundary at a vertex that has edges only to the left or only to the right. We can skip over these last “brush past” cases, because the two trapezoids from these edges have opposite signs and cancel each other in the total trapezoid contribution of \(p\). If \(p\) lies on an edge, then it gets a (positive or negative) contribution of \(1/2\), and when \(p\) is a vertex of the polygon with edges extending left and right, then it gets the same contribution in two quarters. The remaining cases make a contribution of \(\pm 1\), and as for the area calculation they alternate in sign. Canceling these alternating contributions shows that \(p\) always has a total contribution from its trapezoids equal to its contribution to Pick’s formula.</p>

<p>I thought at first that the points on the \(x\)-axis might need a different calculation, because they get only half as much from each trapezoid. But half zero is still zero; they contribute nothing to the sum of trapezoids and nothing to the Pick formula. The points that do need special treatment are the polygon vertices at which the two incident edges do not extend to the left and right, either because one is vertical or because both extend in the same direction. The contribution to Pick’s formula for these vertices is still \(1/2\), but the total contribution from the trapezoids is either an integer (if the incident edges extend in the same direction) or a quarter-integer (if one edges is vertical). So we’ll have to count how much we’ve missed at those points.</p>

<p>Consider driving around the polygon clockwise, in the same direction that we oriented the edges. As you drive, you can make a right turn (from rightward to vertically down, vertically down to leftward, etc), a double-right u-turn, a left turn, or a double-left turn. Points at which the polygon makes an angle but continues in the same general left-to-right or right-to-left direction don’t count as turns. Then at each right turn Pick’s formula will run a deficit of 1/4 unit in total contributions, compared to the sum of trapezoids. A double-right u-turn gives a deficit of 1/2 unit, the same as two right turns. A left turn gives 1/4 more unit to Pick than to the sum of trapezoids, and a double-left gives 1/2 more unit. To return to your starting direction, you must make four more right turns than left, so the total difference in contributions from these terms comes out to exactly the \(-1\) correction term in Pick’s formula.</p>

<p style="text-align: center;"><img alt="Differences in contributions at turning points of the e polygon" src="https://11011110.github.io/blog/assets/2021/pick-deficits.svg"/></p>

<p>In summary, when we sum contributions over all points, the points inside the polygon contribute one unit to Pick’s formula and one unit to the sum of trapezoids. The points outside the polygon contribute zero to both. The points on the boundary that are not turns contribute \(1/2\) to both. And the points on the boundary that are turns contribute different amounts to Pick’s formula and to the sum of trapezoids, with the total of these differences equalling the \(-1\) correction term in Pick’s formula. Therefore, the overall value of Pick’s formula equals the sum of point contributions in trapezoids, which equals the signed sum of trapezoid areas, which equals the polygon area.</p>

<h1 id="generalizations-of-picks-formula">Generalizations of Pick’s formula</h1>

<p>The same idea lets us generalize Pick’s formula to a polygon with holes, defined as a connected region of the plane whose boundary is a disjoint union of simple polygons. The shoelace formula for area in the version we’re using here, and its proof, need no change for this generalization. For each hole, we should drive counterclockwise rather than clockwise, to stay consistent with the orientation we have given the edges; the same argument shows that each hole produces a positive, rather than negative, total difference between the contributions to Pick’s formula and to the shoelace formula. Therefore, for a polygon with \(h\) holes, the total area becomes</p>

\[A=i+b/2+h-1.\]

<p>The basic idea for all this, by the way, comes from the paper “Pick’s theorem”, by Branko Grünbaum and G. C. Shephard (<a href="https://doi.org/10.2307/2323771"><em>Amer. Math. Monthly</em> 1993</a>). Rather than using the trapezoid version of the shoelace formula, Grünbaum and Shephard use a version of the formula that sums, over each edge of the polygon, the signed area of the triangle formed by each edge plus the origin. I think this makes the analysis a little messier, but it’s otherwise much the same as the analysis here. The formula for polygons with holes can be found in “On the compactness of subsets of digital pictures” by Sankar and Krishnamurthy (<a href="https://doi.org/10.1016/s0146-664x(78)80021-5"><em>CGIP</em> 1978</a>) but without the careful definition of polygons with holes that is necessary to avoid problems here.</p>

<p>Grünbaum and Shephard also generalize Pick’s formula in a slightly different direction: rather than allowing separate holes in their polygons, they define polygons to have only one boundary polygon, but they allow that polygon to cross itself. Their version of Pick’s theorem for this kind of generalized polygons sums a certain half-integral index of each lattice point (essentially, the winding number of the polygon around that point, averaged between open and closed versions of the polygon), with a correction term coming from the turning number of the whole polygon. It should be possible to combine both generalizations, and allow polygon boundaries that both cross and have multiple components. There’s a little ambiguity about which way the boundary is connected at vertices of degree higher than two, though, which would need to be resolved somehow if such vertices are to be allowed, because different choices are likely to cause pieces of the boundary to have different orientations leading to different areas.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/106084926459254807">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2021-04-17T23:23:00Z</updated>
    <published>2021-04-17T23:23:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-04-29T04:59:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/04/15/linkage</id>
    <link href="https://11011110.github.io/blog/2021/04/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Keller’s conjecture (\(\mathbb{M}\)), another new Good Article on Wikipedia. The conjecture was falsified in 1992 with all remaining cases solved by 2019, but the name stuck. It’s about tilings of \(n\)-space by unit cubes, and pairs of cubes that share \((n-1)\)-faces. In 2d, all squares share an edge with a neighbor, but a 3d tiling derived from tetrastix has many cubes with no face-to-face neighbor. Up to 7d, some cubes must be face-to-face, but tilings in eight or more dimensions can have no face-to-face pair.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Keller%27s_conjecture">Keller’s conjecture</a> (<a href="https://mathstodon.xyz/@11011110/105994491983819823">\(\mathbb{M}\)</a>), another new Good Article on Wikipedia. The conjecture was falsified in 1992 with all remaining cases solved by 2019, but the name stuck. It’s about tilings of \(n\)-space by unit cubes, and pairs of cubes that share \((n-1)\)-faces. In 2d, all squares share an edge with a neighbor, but a 3d tiling derived from <a href="https://en.wikipedia.org/wiki/Tetrastix">tetrastix</a> has many cubes with no face-to-face neighbor. Up to 7d, some cubes must be face-to-face, but tilings in eight or more dimensions can have no face-to-face pair.</p>
  </li>
  <li>
    <p><a href="https://lucatrevisan.wordpress.com/2021/04/02/bocconi-hired-poorly-qualified-computer-scientist/">Italians and bibliometrics</a> (<a href="https://mathstodon.xyz/@11011110/105996551762053680">\(\mathbb{M}\)</a>): Luca Trevisan (a leading theorist with 7 SODA papers, 2 FOCS papers, a JACM paper and a SICOMP paper in the last four years) gets dinged for poor productivity as the Italian system only counts journal papers that do not match conference papers. The fact that these are all in top venues is irrelevant, and the conference papers count only negatively against matching journal papers. Comments discuss similar problems in other countries.</p>
  </li>
  <li>
    <p><a href="https://www.scottaaronson.com/blog/?p=5402">What is the computational complexity of dinosaur train tracks?</a> (<a href="https://mathstodon.xyz/@11011110/106009429519024889">\(\mathbb{M}\)</a>).  Answer: not very high, because the only usable junction, a Y that remembers which way you came through it and sends you the same way if you come back through the other direction, is just not powerful enough to do much.</p>
  </li>
  <li>
    <p>Congratulations to Martín Farach-Colton, Shang-Hua Teng, and all of the other <a href="https://sinews.siam.org/Details-Page/siam-announces-class-of-2021-fellows">new SIAM Fellows</a> (<a href="https://mathstodon.xyz/@11011110/106016827432463028">\(\mathbb{M}\)</a>)!</p>
  </li>
  <li>
    <p><a href="https://writings.stephenwolfram.com/2021/03/a-little-closer-to-finding-what-became-of-moses-schonfinkel-inventor-of-combinators/">Stephen Wolfram tries to track down</a> what happened to logician <a href="https://en.wikipedia.org/wiki/Moses_Sch%C3%B6nfinkel">Moses Schönfinkel</a> (<a href="https://mathstodon.xyz/@11011110/106025064389253132">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=26694685">via</a>), who worked in Göttingen from 1914 to 1924, returned to Moscow, and then “basically vanished”. Wikipedia has more detail about what happened after (mental health issues, death around 1942), but Wolfram says the evidence for all that is weak. He doesn’t make direct progress on Schönfinkel himself but does find some relatives.</p>
  </li>
  <li>
    <p><a href="https://aperiodical.com/2021/04/my-robot-draws-tex/">How Christian Lawson-Perfect got a pen plotter to draw mathematical notation using TeX</a> (<a href="https://mathstodon.xyz/@christianp/106030474747952758">\(\mathbb{M}\)</a>).</p>
  </li>
  <li>
    <p><a href="https://www.improbable.com/2021/04/08/a-look-way-back-at-some-bearded-mathematicians/">When mathematicians wore geometric beards</a> (<a href="https://mathstodon.xyz/@11011110/106034106736789855">\(\mathbb{M}\)</a>).</p>
  </li>
  <li>
    <p><a href="https://www.scottaaronson.com/blog/?p=5437">Aaronson on politicization of research prizes</a> (<a href="https://mathstodon.xyz/@11011110/106039607813461033">\(\mathbb{M}\)</a>). Jeff Ullman won the Turing Award despite deplorable (some say racist) treatment of grad applicants for the crime of being Iranian, and Oded Goldreich was blocked from the Israel Prize for anti-settlement politics. Politicization is two-edged. I’d rather see Ullman awarded for his worthy contributions, and use the opportunity to decry his abhorrent actions and statements, than subject prizes to litmus tests from all sides.</p>
  </li>
  <li>
    <p><a href="https://thatsmaths.com/2021/04/08/circles-polygons-and-the-kepler-bouwkamp-constant/">Circles, polygons and the Kepler-Bouwkamp constant</a> (<a href="https://mathstodon.xyz/@11011110/106045568373359503">\(\mathbb{M}\)</a>). On the limiting behavior of infinitely-nested shapes alternating between circles and polygons with increasing numbers of sides.</p>
  </li>
  <li>
    <p><a href="https://www.technologyreview.com/2021/04/09/1022217/facebook-ad-algorithm-sex-discrimination">Continuing gender bias in who sees job-opening ads on Facebook</a> (<a href="https://mathstodon.xyz/@11011110/106051162687419819">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=26760790">via</a>): if an employer or industry has historically skewed male or female, Facebook replicates that bias, even for pairs of ads with identical qualifications. This is illegal, but Facebook appears unable to find a technical fix and unwilling to apply the obvious fix of not targeting its ads even when that targeting is illegal. As usual for Hacker News via links on topics related to social justice, don’t read the comments there.</p>
  </li>
  <li>
    <p>Amusing quote from McLarty’s 2003 “<a href="http://www.landsburg.com/grothendieck/mclarty1.pdf">Grothendieck on simplicity and generality</a>” (<a href="https://mathstodon.xyz/@11011110/106059214777848356">\(\mathbb{M}\)</a>, <a href="https://golem.ph.utexas.edu/category/2021/04/algebraic_closure.html">via</a>): “Serre created a series of concise elegant tools which Grothendieck and coworkers simplified into thousands of pages of category theory.” Nowadays I guess the people doing this sort of simplification are the ones formulating machine-verifiable proofs…</p>
  </li>
  <li>
    <p><a href="https://projects.cs.dal.ca/wads2021/wads-2021-accepted-papers/">WADS 2021 accepted papers</a> (<a href="https://mathstodon.xyz/@11011110/106062479142848045">\(\mathbb{M}\)</a>). 
The biennial Algorithms and Data Structures Symposium is usually in Canada, and this time was supposed to be in Halifax, but is looking very likely to be completely online, this August. I have one paper on the list; I’ll write more about it later when I have a preprint version ready to share.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=S5fPwE7GQOA">A “confounding topological curiosity”</a> (<a href="https://mathstodon.xyz/@11011110/106068163014347342">\(\mathbb{M}\)</a>, <a href="https://boingboing.net/2021/04/13/heres-a-confounding-topological-curiosity.html">via</a>): a double torus with a line through one of its holes can be continuously transformed so that the line instead goes through both holes.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.11818">Strange inverses in the group rings of torsion-free groups</a> (<a href="https://mathstodon.xyz/@11011110/106072203556292078">\(\mathbb{M}\)</a>, <a href="https://www.quantamagazine.org/mathematician-disproves-group-algebra-unit-conjecture-20210412/">via</a>, <a href="https://www.uni-muenster.de/MathematicsMuenster/news/artikel/2021-03-04.shtml">see also</a>). This result of Giles Gardam disproves the strongest of the three <a href="https://en.wikipedia.org/wiki/Kaplansky%27s_conjectures">Kaplansky conjectures on group rings</a>. It’s just an isolated example at this point but it does show that group rings are less well-behaved than had been hoped.</p>
  </li>
</ul></div>
    </content>
    <updated>2021-04-15T22:15:00Z</updated>
    <published>2021-04-15T22:15:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-04-29T04:59:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1863</id>
    <link href="https://theorydish.blog/2021/04/15/toc-a-personal-perspective-2021/" rel="alternate" type="text/html"/>
    <title>TOC: a Personal Perspective (2021)</title>
    <summary>Editorial note: this post has been written in celebration of 25 years for “TOC: a Scientific Perspective (1996),” by Oded Goldreich and Avi Wigderson. In the process, I have been made aware of a Facebook discussion from a few weeks ago (which I don’t know how to link to), and to Avi Wenderson’s recent talk that addresses this discussion (and more). I will not attribute statements from the Facebook discussion to individuals (nor will I specify its initiator), as they may not identify with the statements, when taken out of their original context or in the editorialized version here. In any case, this specific discussion is not the point. Feel free to claim ownership in comments . ———————————– I’m sure that, like me, you read on social media: “TOC is in crisis, scratch that, it is lost! We do not have agreed-upon challenges (that are not way out of reach) and do not know how to evaluate papers. Therefore our conferences are favoring progress in techniques and favor complicated papers on obscure problems over progress on important problems (in fact, there is shortage of interesting work on relevant problems). Our flagship conferences are broken and newer conferences, that aimed to [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>Editorial note</strong>: this post has been written in celebration of 25 years for “<a href="http://www.wisdom.weizmann.ac.il/~oded/toc-sp.html">TOC: a Scientific Perspective (1996),</a>” by <a href="http://www.wisdom.weizmann.ac.il/~oded/">Oded Goldreich</a> and <a href="https://www.math.ias.edu/avi/home">Avi Wigderson</a>. In the process, I have been made aware of a Facebook discussion from a few weeks ago (which I don’t know how to link to), and to <a href="https://simons.berkeley.edu/talks/tbd-271">Avi Wenderson’s recent talk</a> that addresses this discussion (and more). I will not attribute statements from the Facebook discussion to individuals (nor will I specify its initiator), as they may not identify with the statements, when taken out of their original context or in the editorialized version here. In any case, this specific discussion is not the point. Feel free to claim ownership in comments .</p>



<p>———————————–</p>



<p>I’m sure that, like me, you read on social media: “TOC is in crisis, scratch that, it is lost! We do not have agreed-upon challenges (that are not way out of reach) and do not know how to evaluate papers. Therefore our conferences are favoring progress in techniques and favor complicated papers on obscure problems over progress on important problems (in fact, there is shortage of interesting work on relevant problems). Our flagship conferences are broken and newer conferences, that aimed to do better, have become just more of the same. This is not TCS as we remember it!”</p>



<p>There are many points with which I agree. Like others, I have been critical at times about the way we do some things, mourning papers and subfields that our conferences have missed. On several occasions, I have been pushing for change. At times I was successful but in other instances <a href="https://windowsontheory.org/2015/06/08/can-we-get-serious/">my suggestions </a>were deemed radical by the powers that be (and more modest/timid suggestions were adopted). <strong><em>But did TOC really lose its way?</em> </strong> </p>



<p>One of the commenter was saying “I have been hearing these complaints about focs and Stoc for more than ten years. They have come from powerful people that sit on committees. … So why nothing changes?“ This comment strikes a chord with me, but let me revise it and say that I have been hearing such complaints for the last 25 years (since attending my first conference), and it is almost always stated by the powerful people, those that have the responsibility to shape the field.</p>



<p>Following the continuous self-criticism, we are likely to assume that TOC is a dysfunctional field and has been so for many years. But if we look at the research achievements of TOC in the last quarter century, we must conclude that this was a glorious period. And the contributions of TCS were on different fronts. Contributions to applied CS and industry, growing contributions outside of CS as well as progress on fundamental questions within TOC. Said progress was obtained by simple papers and by complex and long papers. By papers developing new techniques, by papers making progress on known problems and by papers that introduced new problems, models or even papers that initiated new subfields. They have been made by breakthrough papers and by long sequences of modest papers. By papers in FOCS/STOC and papers in other conferences. So <strong>if TOC is in a continuous crisis, it is the most wonderful crisis possible</strong>.</p>



<p>During my studies (ages ago), I was intensely attracted to TOC. But at the same time, I felt that the field is under constant external attack. It was claimed that we are not as deep as Math and not as useful as CS. Many fewer universities than today have been hiring theoreticians. The field was grossly underfunded (still underfunded but less grossly) but still calls have been made to reduce funding to any area in which TOC is not directly serving other, more applied areas. The dissonance between my intuitive attraction and external criticism could have deterred me from TOC, but there were incredible leaders of TOC that effectively defended the field and shouted – look, something amazing is happening here. “TOC: a Scientific Perspective (1996),” by Oded Goldreich and Avi Wigderson gave me courage to continue. 25 years later, the case they once made in defense of TOC is so much easier to support (and they kept on making this case throughout the years in essays and <a href="https://www.math.ias.edu/avi/book">books</a>). <a href="https://simons.berkeley.edu/talks/tbd-271">As Avi argued</a>, TOC’s success have brought growth and diversification, influx of young talent, scientific respect, industrial respect, and societal respect. <strong>We should do better on self-respect.</strong></p>



<p>I am of course not advocating resting on our laurels’. Like in Alice’s adventures, in our fast field, it takes all the running we can do, to keep in the same place. If we want to get somewhere else, we must run at least twice as fast as that! Constructive criticism is a good thing but our tendency for alarmist/defeatist cries is not serving us well. As someone who grew (scientifically) in an atmosphere of struggle, I am grateful for the progress made in establishing our field by the generations that preceded me. We shouldn’t take for granted how easy we have it. But more importantly, confidence in our field and optimism towards our future are important for our impact on the world (I discussed one aspect of this <a href="https://theorydish.blog/2019/06/24/on-the-importance-of-disciplinary-pride-for-multidisciplinary-collaboration/">here</a>). Finally, thinking of students interested in TOC today and hearing the most powerful people in the field announcing that it is lost. I ask myself, who are the Avi and Oded that will give them the needed courage and optimism? The answer is still that their Avi and Oded are the very same Avi and Oded from my student years. But isn’t it about time that we lend a hand?</p>



<p/></div>
    </content>
    <updated>2021-04-15T14:50:46Z</updated>
    <published>2021-04-15T14:50:46Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2021-04-29T09:42:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=18549</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/04/15/scott-wins-a-prize/" rel="alternate" type="text/html"/>
    <title>Scott Wins a Prize</title>
    <summary>Quantum mechanics makes absolutely no sense—Roger Penrose Scott Answers Big Questions source Scott Aaronson has just been named the 2020 ACM Prize in Computing for groundbreaking contributions to quantum computing, Penrose’s comment notwithstanding. The prize citation also credits Scott’s multifaceted public outreach for making our fields accessible to many. Today Ken and I send congrats […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Quantum mechanics makes absolutely no sense—Roger Penrose</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/04/15/scott-wins-a-prize/aaronsonhorgan/" rel="attachment wp-att-18565"><img alt="" class="alignright size-full wp-image-18565" height="170" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/AaronsonHorgan.jpg?resize=160%2C170&amp;ssl=1" width="160"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Scott Answers Big Questions <a href="https://blogs.scientificamerican.com/cross-check/scott-aaronson-answers-every-ridiculously-big-question-i-throw-at-him/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Scott Aaronson has just been named the 2020 ACM <a href="https://en.wikipedia.org/wiki/ACM_Prize_in_Computing">Prize</a> in Computing for groundbreaking contributions to quantum computing, Penrose’s comment notwithstanding.  The prize <a href="https://awards.acm.org/about/2020-acm-prize">citation</a> also credits Scott’s multifaceted public outreach for making our fields accessible to many.</p>
<p>
Today Ken and I send congrats to Scott for this singular honor.<br/>
<span id="more-18549"/></p>
<p>
The ACM Prize was founded in 2007.  It does not have the age limit of a Fields Medal but is similarly positioned.  Scott joins a impressive list of winners: </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/15/scott-wins-a-prize/who-2/" rel="attachment wp-att-18562"><img alt="" class="aligncenter wp-image-18562" height="625" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/who-1.png?resize=550%2C625&amp;ssl=1" width="550"/></a></p>
<p/><p><br/>
</p><h2> Not Why He Did Win? </h2><p/>
<p>
Scott perhaps could have won for the following three accomplishments:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> His wonderful <a href="https://www.scottaaronson.com/blog/">blog</a>. About the prize, he <a href="https://www.scottaaronson.com/blog/?p=5448">says</a> there: </p>
<blockquote><p><b> </b> <em> Last week I got an email from Dina Katabi, my former MIT colleague, asking me to call her urgently. Am I in trouble? … Luckily, Dina only wanted to tell me that I’d been selected to receive the 2020 ACM Prize in Computing, a mid-career award founded in 2007 that comes with $250,000 from Infosys. Not the Turing Award but I’d happily take it! And I could even look back on 2020 fondly for something. </em>
</p></blockquote>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> His <a href="https://www.amazon.com/Quantum-Computing-since-Democritus-Aaronson/dp/0521199565">book</a> on quantum: </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/15/scott-wins-a-prize/book-6/" rel="attachment wp-att-18554"><img alt="" class="aligncenter wp-image-18554" height="240" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/book-1.jpg?resize=160%2C240&amp;ssl=1" width="160"/></a></p>
<p>
Democritus was known as “the laughing philosopher,” though some other depictions of the laugh range from world-weary to pained.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> His sense of <a href="https://www.scottaaronson.com/blog/?p=62">humor</a>. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/15/scott-wins-a-prize/kl2/" rel="attachment wp-att-18563"><img alt="" class="aligncenter size-large wp-image-18563" height="351" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/kl2.png?resize=600%2C351&amp;ssl=1" width="600"/></a></p>
<p>
This is my returning thanks, in a way. Ken says that what impresses him is not the floor-length garment but the floor-length blackboard. Both of us hope that after handling “For All” and “Exists,” he went on to solve the problem of placing “Not” in English—for instance, “Why He Did Not Win?” is more grammatically natural but wrong.</p>
<p/><h2> Why He Did Win? </h2><p/>
<p>
Scott perhaps did win for the following four accomplishments:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> The theoretical foundations of the sampling-based quantum supremacy <a href="https://arxiv.org/pdf/1612.05903.pdf">experiments</a>—joint with Lijie Chen. Ken adds that this paper is also known for the “Schrödinger” and “Feynman” nomenclature for simulating quantum classically, and the idea of hybridizing those approaches.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> The algebrization <a href="https://www.scottaaronson.com/papers/alg.pdf">barrier</a> in complexity theory—joint with Avi Wigderson.  About Avi’s talk on this at my 60th birthday workshop, Ken <a href="https://blog.computationalcomplexity.org/2008/05/report-on-sym-for-liptons-60th-bday.html">wrote</a> that it “planted a Monty Python foot on further progress” on lower bounds.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> Limitations on quantum computers—work on the quantum lower bound for the <a href="https://www.scottaaronson.com/papers/collision.ps">collision problem</a>.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> The opposite of limitations—getting quantum advantage from the simplest of components in linear <a href="https://dl.acm.org/doi/10.1145/1993636.1993682">optics</a>. And <a href="https://arxiv.org/abs/1309.7460">this</a>, likewise joint with Alex Arkhipov. This approach has been followed by many, notably last <a href="https://science.sciencemag.org/content/370/6523/1460">December</a> by a large team in China.  We just <a href="https://rjlipton.wpcomstaging.com/2021/04/12/wobble-in-the-standard-model/">wrote</a> about envy of big experiments, but Scott has arguably done the most of anyone in our field to launch them.</p>
<p>
There are many more. But maybe the one that will get us all rich is Scott’s <a href="https://arxiv.org/abs/1110.5353">work</a> on <a href="https://en.wikipedia.org/wiki/Quantum_money">quantum money</a>. Qubitcoin, anyone?</p>
<p/><h2> Open Problems </h2><p/>
<p>
Wonderful to add Scott to the list of winners of this award. Congrats again.</p>
<p>
We also congratulate Paul Beame on the SIGACT Distinguished Service Award.</p></font></font></div>
    </content>
    <updated>2021-04-15T13:31:22Z</updated>
    <published>2021-04-15T13:31:22Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Oldies"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="award"/>
    <category term="experiments"/>
    <category term="Paul Beame"/>
    <category term="Prize"/>
    <category term="quantum"/>
    <category term="quantum advantage"/>
    <category term="Scott Aaronson"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-04-29T09:38:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3988126252359540708</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3988126252359540708/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/04/ordering-beauty.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3988126252359540708" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3988126252359540708" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/04/ordering-beauty.html" rel="alternate" type="text/html"/>
    <title>Ordering Beauty</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>First, congratulations to fellow complexity theorist and <a href="https://www.scottaaronson.com/blog/">blogger</a> Scott Aaronson for <a href="https://awards.acm.org/about/2020-acm-prize">receiving the 2020 ACM Prize in Computing</a> for "groundbreaking contributions to quantum computing". The prize is ACM's highest honor for mid-career researchers. Well deserved! </p><p>Now back to our regularly scheduled post...</p><p>Every freshman at Cornell back in 1981 had to take two seminar courses, basically one-shot courses in an usually humanities area which required no prerequisites but lots of writing. I took my first course in philosophy. The instructor, a PhD student, at one point described his research, a philosophical argument that there is an intrinsic total ordering of beauty, say that Beethoven would always sit above the Beatles, no matter the beholder. I didn't believe him then and still don't today. A few months ago the Washington Post ran a story with the same theme entitled <a href="https://www.washingtonpost.com/entertainment/maradona-messi-ronaldo-zlatan-shakespeare-beatles/2020/12/23/27654712-38a9-11eb-9276-ae0ca72729be_story.html">Maradona was great, and maybe the greatest. Can we make similar claims about artists?</a></p><p>Somehow we have this belief when it comes to conference submissions, that there is some perfect ordering of the submissions and a good PC can suss it out. That's not really how it works. Let's say a conference has an accept rate of 30%. Typically 10% of the submissions are strong and will be accepted by any committee. About half the submissions are just okay or worse and would be rejected. The other 40% of the submissions will be chosen seemingly randomly based on the tastes of the specific members of the program committee. Experiments in the NeurIPS and ESA conferences have bourn this out. </p><p>Why not make the randomness explicit instead of implicit? Have the PC divide the papers into three piles, definite accepts, definite rejects and the middle. Take the third group and randomly choose which ones to accept. It will create a more interesting program. Also randomness removes biases, randomness doesn't care about gender, race and nationality or whether the authors are at senior professors at MIT or first year grad students at Southern North Dakota. </p><p>We put far too much weight on getting accepted into a conference given the implicit randomness of a PC. If we make the randomness explicit that would devalue that weight. We would have to judge researchers on the quality of their research instead of their luck in conferences.</p><p>Given that conferences, especially the virtual ones, have no real limits on the number of papers and talks, you might say why not just accept all the papers in the middle. Works for me.</p></div>
    </content>
    <updated>2021-04-15T12:31:00Z</updated>
    <published>2021-04-15T12:31:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-04-28T21:02:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/054</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/054" rel="alternate" type="text/html"/>
    <title>TR21-054 |  Encodings and the Tree Evaluation Problem | 

	Ian Mertz, 

	James  Cook</title>
    <summary>We show that the Tree Evaluation Problem with alphabet size $k$ and height $h$ can be solved by branching programs of size $k^{O(h/\log h)} + 2^{O(h)}$. This answers a longstanding challenge of Cook et al. (2009) and gives the first general upper bound since the problem's inception.</summary>
    <updated>2021-04-14T19:29:12Z</updated>
    <published>2021-04-14T19:29:12Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-04-29T09:38:04Z</updated>
    </source>
  </entry>
</feed>
