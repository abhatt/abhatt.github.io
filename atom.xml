<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-04-29T23:21:44Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7481748881751465174</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7481748881751465174/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/a-guest-blog-on-pandemics-affect-on.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7481748881751465174" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7481748881751465174" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/a-guest-blog-on-pandemics-affect-on.html" rel="alternate" type="text/html"/>
    <title>A Guest Blog on the Pandemic's affect on disability students</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>I asked my Grad Ramsey Theory class to email me about whatever thoughts they have on the pandemic that they want to share with the world, with the intend of making some of them into a blog post. I thought there would be several short thoughts for one post. And I may still do that post. But I got a FANTASTIC long answer from one Emily Mae Kaplitz. Normally I would ask to shorten or edit a guest post, but I didn't do that here since that might make it less authentic.</div><div><br/></div><div>Here is Emily Kaplitz's email (with her enthusiastic permission)</div><div><br/></div><div>--------------------------------------------------------------------------------------</div><div><br/></div><div>Ok so this might be super ranty, (It definitely is.) but I think it is super important to bring up in a blog post written by an academic that will be probably read by other academics.Â </div><div><br/></div><div>The students that are being most affected by this pandemic with online learning are disability students. As a disability student, we carefully cultivate the way that we learn best based off of years of trial and error. This is harder than anything else, we have to face in our lifetime. Most of the time disability students are left on the back burner and that statement is so much more prevalent right now. My friends brother is autistic. He is struggling so much right now because he is at home. Disability students learn what environment works best for them and at home is usually not the best place. We have to split our lives into different boxes that each have different tools to help us get our brains to focus and work well when we need them too. Disability students will rely on everything being planned out, so that they can succeed. Teachers and professors cannot understand the stress and strain that having to work at home puts on the student. Every time I go to another school, it is a struggle to figure out what new thing I need to add into the mix and what old thing I need to throw away. It's exhausting, but when I go from one school to another I at least know that the basics are the same. I sit in a classroom, the professors lecturer, and then I do work at home that is assigned to me. Changing to online changes that dynamic so much. A professor cannot see when a student is visibly struggling with a topic because we'll all behind computers. A neurotypical person might ask, "well why don't you just ask a question? Why don't you just let the professor know that you don't understand". Let me answer that simply. If all your life you've been silenced because of something that you cannot control, is your first reaction to speak out or to stay silent. It is so hard for disability students to ask a question after we've been labeled the dumb kid. Every time we ask a question, we always have the thought of: is this going to make me sound stupid. We've worked so hard to eliminate that word from our vocabulary and from others who will throw that word back at us. Disability students are being left in the hands of their parents and teachers/professors who do not understand us and our needs even if they try to or want to. It is so hard for us to explain what our normal is because we don't live your normal and therefore don't know the difference. Many disability students have their confidence slashed the moment they enter a classroom and realize that they are not like the other kids. Even more so because they don't understand why they aren't. Disability students are one of the most hard-working individuals when we have a cheerleader to cheer us on because it's hard. It's harder than anything anyone has to do. Because no one listens to you when you are stupid and no one cares for you if you're not easy to care for unless they are given a specific reason to. Fighting a losing battle every day is awful. Now imagine all of your weapons that you have carefully crafted over the years have been taken away and you are left defenseless. While we have things like ADS that are supposed to help support us, it's not enough. Just like putting a Band-Aid on an open infected wound will not be enough. Now more than ever we need to learn from this as academics. We need to learn that helping disability students does not only help disability students. It helps all students because all students learn differently. All students if given the chance can excel at any field that we put them in. We just have to figure out the best way to get that student to shine. That is one of the reasons why I am a PhD student right now. I saw in the tutoring center at my undergrad how many students came to me with so much frustration about something they are doing in class. Both students with disabilities and without. These students are constantly apologizing because they don't understand something. In one session by just changing the way that we talk about a subject the student was able to get it in less time than the professor taught it. I've had students come to me after an exam and tell me that the only reason they got the grade that they did was because in their head was my voice coaching them on a subject. We are not teaching optimally. We are teaching the way that it has been done for years and years and years and that is not the best way to teach. It might be the best way to teach the strongest links but really the link that matters the most is the weakest link that will snap under pressure because you can't pull a tractor with a broken link. Disability students think differently. Imagine how many impossible problems we can solve when we have people that think differently. But that's just my two cents as a disability student who is struggling and sees other disability students struggling every day. And really just wants to help all students succeed.</div><div><br/></div><div>I blame any misspellings, grammar errors, and run on sentences on my speech to text and text to speech. This was a long email and if we were on tumblr, I would post a potato at the end. Since we aren't, I will leave this email with this. Thank you for taking the time to read this rant. Even if you don't include this in your blog post, I believe one person reading this has made the difference.</div><div><br/></div><div>Thanks!</div><div><br/></div><div>Emily Mae Kaplitz</div></div>
    </content>
    <updated>2020-04-29T13:44:00Z</updated>
    <published>2020-04-29T13:44:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-04-29T17:05:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/063</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/063" rel="alternate" type="text/html"/>
    <title>TR20-063 |  On the Existence of Algebraically Natural Proofs | 

	Prerona Chatterjee, 

	Mrinal Kumar, 

	C Ramya, 

	Ramprasad Saptharishi, 

	Anamay Tengse</title>
    <summary>For every constant c &gt; 0, we show that there is a family {P_{N,c}} of polynomials whose degree and algebraic circuit complexity are polynomially bounded in the number of variables, and that satisfies the following properties:
* For every family {f_n} of polynomials in VP, where f_n is an n variate polynomial of degree at most n^c with bounded integer coefficients and for N = \binom{n^c + n}{n}, P_{N,c} -vanishes- on the coefficient vector of f_n.
* There exists a family {h_n} of polynomials where h_n is an n variate polynomial of degree at most n^c with bounded integer coefficients such that for N = \binom{n^c + n}{n}, P_{N,c} -does not vanish- on the coefficient vector of h_n.

In other words, there are efficiently computable defining equations for polynomials in VP that have small integer coefficients.
In fact, we also prove an analogous statement for the seemingly larger class VNP. Thus, in this setting of polynomials with small integer coefficients, this provides evidence -against- a natural proof like barrier for proving algebraic circuit lower bounds, a framework for which was proposed in the works of Forbes, Shpilka and Volk (2018), and Grochow, Kumar, Saks and Saraf (2017).

Our proofs are elementary and rely on the existence of (non-explicit) hitting sets for VP (and VNP) to show that there are efficiently constructible, low degree defining equations for these classes, and also extend to finite fields of small size.</summary>
    <updated>2020-04-29T13:29:05Z</updated>
    <published>2020-04-29T13:29:05Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-29T23:20:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/062</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/062" rel="alternate" type="text/html"/>
    <title>TR20-062 |  Testing Data Binnings | 

	Clement Canonne, 

	Karl  Wimmer</title>
    <summary>Motivated by the question of data quantization and "binning," we revisit the problem of identity testing of discrete probability distributions. Identity testing (a.k.a. one-sample testing), a fundamental and by now well-understood problem in distribution testing, asks, given a reference distribution (model) $\mathbf{q}$ and samples from an unknown distribution $\mathbf{p}$, both over $[n]=\{1,2,\dots,n\}$, whether $\mathbf{p}$ equals $\mathbf{q}$, or is significantly different from it.

In this paper, we introduce the related question of identity up to binning, where the reference distribution $\mathbf{q}$ is over $k \ll n$ elements: the question is then whether there exists a suitable binning of the domain $[n]$ into $k$ intervals such that, once "binned," $\mathbf{p}$ is equal to $\mathbf{q}$. We provide nearly tight upper and lower bounds on the sample complexity of this new question, showing both a quantitative and qualitative difference with the vanilla identity testing one, and answering an open question of Canonne (2019). Finally, we discuss several extensions and related research directions.</summary>
    <updated>2020-04-29T03:23:33Z</updated>
    <published>2020-04-29T03:23:33Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-29T23:20:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.13673</id>
    <link href="http://arxiv.org/abs/2004.13673" rel="alternate" type="text/html"/>
    <title>Near Optimal Algorithm for the Directed Single Source Replacement Paths Problem</title>
    <feedworld_mtime>1588118400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chechik:Shiri.html">Shiri Chechik</a>, Ofer Magen <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.13673">PDF</a><br/><b>Abstract: </b>In the Single Source Replacement Paths (SSRP) problem we are given a graph $G
= (V, E)$, and a shortest paths tree $\widehat{K}$ rooted at a node $s$, and
the goal is to output for every node $t \in V$ and for every edge $e$ in
$\widehat{K}$ the length of the shortest path from $s$ to $t$ avoiding $e$.
</p>
<p>We present an $\tilde{O}(m\sqrt{n} + n^2)$ time randomized combinatorial
algorithm for unweighted directed graphs. Previously such a bound was known in
the directed case only for the seemingly easier problem of replacement path
where both the source and the target nodes are fixed.
</p>
<p>Our new upper bound for this problem matches the existing conditional
combinatorial lower bounds. Hence, (assuming these conditional lower bounds)
our result is essentially optimal and completes the picture of the SSRP problem
in the combinatorial setting.
</p>
<p>Our algorithm extends to the case of small, rational edge weights. We
strengthen the existing conditional lower bounds in this case by showing that
any $O(mn^{1/2-\epsilon})$ time (combinatorial or algebraic) algorithm for some
fixed $\epsilon &gt;0$ yields a truly subcubic algorithm for the weighted All
Pairs Shortest Paths problem (previously such a bound was known only for the
combinatorial setting).
</p></div>
    </summary>
    <updated>2020-04-29T22:32:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.13602</id>
    <link href="http://arxiv.org/abs/2004.13602" rel="alternate" type="text/html"/>
    <title>Recognizing Single-Peaked Preferences on an Arbitrary Graph: Complexity and Algorithms</title>
    <feedworld_mtime>1588118400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Escoffier:Bruno.html">Bruno Escoffier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spanjaard:Olivier.html">Olivier Spanjaard</a>, MagdalÃ©na TydrichovÃ¡ <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.13602">PDF</a><br/><b>Abstract: </b>This paper is devoted to a study of single-peakedness on arbitrary graphs.
Given a collection of preferences (rankings of a set of alternatives), we aim
at determining a connected graph G on which the preferences are single-peaked,
in the sense that all the preferences are traversals of G. Note that a
collection of preferences is always single-peaked on the complete graph. We
propose an Integer Linear Programming formulation (ILP) of the problem of
minimizing the number of edges in G or the maximum degree of a vertex in G. We
prove that both problems are NP-hard in the general case. However, we show that
if the optimal number of edges is m-1 (where m is the number of candidates)
then any optimal solution of the ILP is integer and thus the integrality
constraints can be relaxed. This provides an alternative proof of the
polynomial-time complexity of recognizing single-peaked preferences on a tree.
We prove the same result for the case of a path (an axis), providing here also
an alternative proof of polynomiality of the recognition problem. Furthermore,
we provide a polynomial-time procedure to recognize single-peaked preferences
on a pseudotree (a connected graph that contains at most one cycle). We also
give some experimental results, both on real and synthetic datasets.
</p></div>
    </summary>
    <updated>2020-04-29T23:20:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.13509</id>
    <link href="http://arxiv.org/abs/2004.13509" rel="alternate" type="text/html"/>
    <title>Related by Similiarity: Poristic Triangles and 3-Periodics in the Elliptic Billiard</title>
    <feedworld_mtime>1588118400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garcia:Ronaldo.html">Ronaldo Garcia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Reznik:Dan.html">Dan Reznik</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.13509">PDF</a><br/><b>Abstract: </b>Discovered by William Chapple in 1746, the Poristic family is a set of
variable-perimeter triangles with common Incircle and Circumcircle. By
definition, the family has constant Inradius-to-Circumradius ratio.
Interestingly, this invariance also holds for the family of 3-periodics in the
Elliptic Billiard, though here Inradius and Circumradius are variable and
perimeters are constant. Indeed, we show one family is mapped onto the other
via a varying similarity transform. This implies that any scale-free quantities
and invariants observed in one family must hold on the other.
</p></div>
    </summary>
    <updated>2020-04-29T22:38:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.13491</id>
    <link href="http://arxiv.org/abs/2004.13491" rel="alternate" type="text/html"/>
    <title>As Time Goes By: Reflections on Treewidth for Temporal Graphs</title>
    <feedworld_mtime>1588118400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fluschnik:Till.html">Till Fluschnik</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Molter:Hendrik.html">Hendrik Molter</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Niedermeier:Rolf.html">Rolf Niedermeier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Renken:Malte.html">Malte Renken</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zschoche:Philipp.html">Philipp Zschoche</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.13491">PDF</a><br/><b>Abstract: </b>Treewidth is arguably the most important structural graph parameter leading
to algorithmically beneficial graph decompositions. Triggered by a strongly
growing interest in temporal networks (graphs where edge sets change over
time), we discuss fresh algorithmic views on temporal tree decompositions and
temporal treewidth. We review and explain some of the recent work together with
some encountered pitfalls, and we point out challenges for future research.
</p></div>
    </summary>
    <updated>2020-04-29T22:32:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.13442</id>
    <link href="http://arxiv.org/abs/2004.13442" rel="alternate" type="text/html"/>
    <title>Fast algorithms for general spin systems on bipartite expanders</title>
    <feedworld_mtime>1588118400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galanis:Andreas.html">Andreas Galanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldberg:Leslie_Ann.html">Leslie Ann Goldberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stewart:James.html">James Stewart</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.13442">PDF</a><br/><b>Abstract: </b>A spin system is a framework in which the vertices of a graph are assigned
spins from a finite set. The interactions between neighbouring spins give rise
to weights, so a spin assignment can also be viewed as a weighted graph
homomorphism. The problem of approximating the partition function (the
aggregate weight of spin assignments) or of sampling from the resulting
probability distribution is typically intractable for general graphs.
</p>
<p>In this work, we consider arbitrary spin systems on bipartite expander
$\Delta$-regular graphs, including the canonical class of bipartite random
$\Delta$-regular graphs. We develop fast approximate sampling and counting
algorithms for general spin systems whenever the degree and the spectral gap of
the graph are sufficiently large. Our approach generalises the techniques of
Jenseen et al. and Chen et al. by showing that typical configurations on
bipartite expanders correspond to "bicliques" of the spin system; then, using
suitable polymer models, we show how to sample such configurations and
approximate the partition function in $\tilde{O}(n^2)$ time, where $n$ is the
size of the graph.
</p></div>
    </summary>
    <updated>2020-04-29T22:23:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.13389</id>
    <link href="http://arxiv.org/abs/2004.13389" rel="alternate" type="text/html"/>
    <title>Approximating longest common substring with $k$ mismatches: Theory and practice</title>
    <feedworld_mtime>1588118400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gourdel:Garance.html">Garance Gourdel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kociumaka:Tomasz.html">Tomasz Kociumaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Radoszewski:Jakub.html">Jakub Radoszewski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Starikovskaya:Tatiana.html">Tatiana Starikovskaya</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.13389">PDF</a><br/><b>Abstract: </b>In the problem of the longest common substring with $k$ mismatches we are
given two strings $X, Y$ and must find the maximal length $\ell$ such that
there is a length-$\ell$ substring of $X$ and a length-$\ell$ substring of $Y$
that differ in at most $k$ positions. The length $\ell$ can be used as a robust
measure of similarity between $X, Y$. In this work, we develop new
approximation algorithms for computing $\ell$ that are significantly more
efficient that previously known solutions from the theoretical point of view.
Our approach is simple and practical, which we confirm via an experimental
evaluation, and is probably close to optimal as we demonstrate via a
conditional lower bound.
</p></div>
    </summary>
    <updated>2020-04-29T22:28:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.13312</id>
    <link href="http://arxiv.org/abs/2004.13312" rel="alternate" type="text/html"/>
    <title>Certifying Certainty and Uncertainty in Approximate Membership Query Structures -- Extended Version</title>
    <feedworld_mtime>1588118400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gopinathan:Kiran.html">Kiran Gopinathan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sergey:Ilya.html">Ilya Sergey</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.13312">PDF</a><br/><b>Abstract: </b>Approximate Membership Query structures (AMQs) rely on randomisation for
time- and space-efficiency, while introducing a possibility of false positive
and false negative answers. Correctness proofs of such structures involve
subtle reasoning about bounds on probabilities of getting certain outcomes.
Because of these subtleties, a number of unsound arguments in such proofs have
been made over the years. In this work, we address the challenge of building
rigorous and reusable computer-assisted proofs about probabilistic
specifications of AMQs. We describe the framework for systematic decomposition
of AMQs and their properties into a series of interfaces and reusable
components. We implement our framework as a library in the Coq proof assistant
and showcase it by encoding in it a number of non-trivial AMQs, such as Bloom
filters, counting filters, quotient filters and blocked constructions, and
mechanising the proofs of their probabilistic specifications. We demonstrate
how AMQs encoded in our framework guarantee the absence of false negatives by
construction. We also show how the proofs about probabilities of false
positives for complex AMQs can be obtained by means of verified reduction to
the implementations of their simpler counterparts. Finally, we provide a
library of domain-specific theorems and tactics that allow a high degree of
automation in probabilistic proofs.
</p></div>
    </summary>
    <updated>2020-04-29T22:37:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.13302</id>
    <link href="http://arxiv.org/abs/2004.13302" rel="alternate" type="text/html"/>
    <title>Tree-depth and the Formula Complexity of Subgraph Isomorphism</title>
    <feedworld_mtime>1588118400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kush:Deepanshu.html">Deepanshu Kush</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rossman:Benjamin.html">Benjamin Rossman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.13302">PDF</a><br/><b>Abstract: </b>For a fixed "pattern" graph $G$, the $\textit{colored $G$-subgraph
isomorphism problem}$ (denoted $\mathrm{SUB}(G)$) asks, given an $n$-vertex
graph $H$ and a coloring $V(H) \to V(G)$, whether $H$ contains a properly
colored copy of $G$. The complexity of this problem is tied to parameterized
versions of $\mathit{P}$ ${=}?$ $\mathit{NP}$ and $\mathit{L}$ ${=}?$
$\mathit{NL}$, among other questions. An overarching goal is to understand the
complexity of $\mathrm{SUB}(G)$, under different computational models, in terms
of natural invariants of the pattern graph $G$.
</p>
<p>In this paper, we establish a close relationship between the $\textit{formula
complexity}$ of $\mathrm{SUB}$ and an invariant known as $\textit{tree-depth}$
(denoted $\mathrm{td}(G)$). $\mathrm{SUB}(G)$ is known to be solvable by
monotone $\mathit{AC^0}$ formulas of size $O(n^{\mathrm{td}(G)})$. Our main
result is an $n^{\tilde\Omega(\mathrm{td}(G)^{1/3})}$ lower bound for formulas
that are monotone $\textit{or}$ have sub-logarithmic depth. This complements a
lower bound of Li, Razborov and Rossman (SICOMP 2017) relating tree-width and
$\mathit{AC^0}$ circuit size. As a corollary, it implies a stronger
homomorphism preservation theorem for first-order logic on finite structures
(Rossman, ITCS 2017).
</p>
<p>The technical core of this result is an $n^{\Omega(k)}$ lower bound in the
special case where $G$ is a complete binary tree of height $k$, which we
establish using the $\textit{pathset framework}$ introduced in (Rossman, SICOMP
2018). (The lower bound for general patterns follows via a recent
excluded-minor characterization of tree-depth (Czerwi\'nski et al,
<a href="http://export.arxiv.org/abs/1904.13077">arXiv:1904.13077</a>).) Additional results of this paper extend the pathset
framework and improve upon both, the best known upper and lower bounds on the
average-case formula size of $\mathrm{SUB}(G)$ when $G$ is a path.
</p></div>
    </summary>
    <updated>2020-04-29T23:21:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.13231</id>
    <link href="http://arxiv.org/abs/2004.13231" rel="alternate" type="text/html"/>
    <title>Quantum Implications of Huang's Sensitivity Theorem</title>
    <feedworld_mtime>1588118400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aaronson:Scott.html">Scott Aaronson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ben=David:Shalev.html">Shalev Ben-David</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kothari:Robin.html">Robin Kothari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tal:Avishay.html">Avishay Tal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.13231">PDF</a><br/><b>Abstract: </b>Based on the recent breakthrough of Huang (2019), we show that for any total
Boolean function $f$, the deterministic query complexity, $D(f)$, is at most
quartic in the quantum query complexity, $Q(f)$: $D(f) = O(Q(f)^4)$. This
matches the known separation (up to log factors) due to Ambainis, Balodis,
Belovs, Lee, Santha, and Smotrovs (2017). We also use the result to resolve the
quantum analogue of the Aanderaa-Karp-Rosenberg conjecture. We show that if $f$
is a nontrivial monotone graph property of an $n$-vertex graph specified by its
adjacency matrix, then $Q(f) = \Omega(n)$, which is also optimal.
</p></div>
    </summary>
    <updated>2020-04-29T23:21:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.13197</id>
    <link href="http://arxiv.org/abs/2004.13197" rel="alternate" type="text/html"/>
    <title>Batched Predecessor and Sorting with Size-Priced Information in External Memory</title>
    <feedworld_mtime>1588118400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bender:Michael_A=.html">Michael A. Bender</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goswami:Mayank.html">Mayank Goswami</a>, Dzejla Mededovic, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Montes:Pablo.html">Pablo Montes</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsichlas:Kostas.html">Kostas Tsichlas</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.13197">PDF</a><br/><b>Abstract: </b>In the unit-cost comparison model, a black box takes an input two items and
outputs the result of the comparison. Problems like sorting and searching have
been studied in this model, and it has been generalized to include the concept
of priced information, where different pairs of items (say database records)
have different comparison costs. These comparison costs can be arbitrary (in
which case no algorithm can be close to optimal (Charikar et al. STOC 2000)),
structured (for example, the comparison cost may depend on the length of the
databases (Gupta et al. FOCS 2001)), or stochastic (Angelov et al. LATIN 2008).
Motivated by the database setting where the cost depends on the sizes of the
items, we consider the problems of sorting and batched predecessor where two
non-uniform sets of items $A$ and $B$ are given as input.
</p>
<p>(1) In the RAM setting, we consider the scenario where both sets have $n$
keys each. The cost to compare two items in $A$ is $a$, to compare an item of
$A$ to an item of $B$ is $b$, and to compare two items in $B$ is $c$. We give
upper and lower bounds for the case $a \le b \le c$. Notice that the case $b=1,
a=c=\infty$ is the famous ``nuts and bolts'' problem.
</p>
<p>(2) In the Disk-Access Model (DAM), where transferring elements between disk
and internal memory is the main bottleneck, we consider the scenario where
elements in $B$ are larger than elements in $A$. The larger items take more
I/Os to be brought into memory, consume more space in internal memory, and are
required in their entirety for comparisons.
</p>
<p>We first give output-sensitive lower and upper bounds on the batched
predecessor problem, and use these to derive bounds on the complexity of
sorting in the two models. Our bounds are tight in most cases, and require
novel generalizations of the classical lower bound techniques in external
memory to accommodate the non-uniformity of keys.
</p></div>
    </summary>
    <updated>2020-04-29T22:25:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.13086</id>
    <link href="http://arxiv.org/abs/2004.13086" rel="alternate" type="text/html"/>
    <title>Computing the Boolean product of two n\times n Boolean matrices using O(n^2) mechanical operation</title>
    <feedworld_mtime>1588118400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lingas:Andrzej.html">Andrzej Lingas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Persson:Mia.html">Mia Persson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.13086">PDF</a><br/><b>Abstract: </b>We study the problem of determining the Boolean product of two n\times n
Boolean matrices in an unconventional computational model allowing for
mechanical operations. We show that O(n^2) operations are sufficient to compute
the product in this model.
</p></div>
    </summary>
    <updated>2020-04-29T22:30:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.13018</id>
    <link href="http://arxiv.org/abs/2004.13018" rel="alternate" type="text/html"/>
    <title>An Extension of Pl\"ucker Relations with Applications to Subdeterminant Maximization</title>
    <feedworld_mtime>1588118400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Anari:Nima.html">Nima Anari</a>, Thuy-Duong Vuong <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.13018">PDF</a><br/><b>Abstract: </b>Given a matrix $A$ and $k\geq 0$, we study the problem of finding the
$k\times k$ submatrix of $A$ with the maximum determinant in absolute value.
This problem is motivated by the question of computing the determinant-based
lower bound of [LSV86] on hereditary discrepancy, which was later shown to be
an approximate upper bound as well [Mat13]. The special case where $k$
coincides with one of the dimensions of $A$ has been extensively studied.
[Nik15] gave a $2^{O(k)}$-approximation algorithm for this special case,
matching known lower bounds; he also raised as an open problem the question of
designing approximation algorithms for the general case.
</p>
<p>We make progress towards answering this question by giving the first
efficient approximation algorithm for general $k\times k$ subdeterminant
maximization with an approximation ratio that depends only on $k$. Our
algorithm finds a $k^{O(k)}$-approximate solution by performing a simple local
search. Our main technical contribution, enabling the analysis of the
approximation ratio, is an extension of Pl\"ucker relations for the
Grassmannian, which may be of independent interest; Pl\"ucker relations are
quadratic polynomial equations involving the set of $k\times k$ subdeterminants
of a $k\times n$ matrix. We find an extension of these relations to $k\times k$
subdeterminants of general $m\times n$ matrices.
</p></div>
    </summary>
    <updated>2020-04-29T22:27:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/04/28/cartesian-triangle-centers</id>
    <link href="https://11011110.github.io/blog/2020/04/28/cartesian-triangle-centers.html" rel="alternate" type="text/html"/>
    <title>Cartesian triangle centers</title>
    <summary>The usual definition of a Euclidean triangle center is a point defined from a triangle in a way that is equivariant under similarity transformations, meaning that applying the transformation to a triangle and then constructing its center produces the same point as constructing the center first and then transforming it. These include familiar points defined from triangles like the orthocenter (where perpendiculars to the sides meet), incenter (the center of the inscribed circle), and circumcenter (the center of the circumscribed circle). What I have in mind in this post is a similarly-defined concept, but with a different group of transformations than similarity: the combination of any two separate linear transformations to the two coordinate axes of the Cartesian plane, or transformations that swap the (transformed) axes. Another way of describing these transformations is that they preserve axis-parallel lines and relative area. They also preserve other lines and parallelism of lines.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The usual definition of a Euclidean <a href="https://en.wikipedia.org/wiki/Triangle_center">triangle center</a> is a point defined from a triangle in a way that is <a href="https://en.wikipedia.org/wiki/Equivariant_map">equivariant</a> under <a href="https://en.wikipedia.org/wiki/Similarity_(geometry)">similarity transformations</a>, meaning that applying the transformation to a triangle and then constructing its center produces the same point as constructing the center first and then transforming it. These include familiar points defined from triangles like the <a href="https://en.wikipedia.org/wiki/Orthocenter">orthocenter</a> (where perpendiculars to the sides meet), <a href="https://en.wikipedia.org/wiki/Incenter">incenter</a> (the center of the inscribed circle), and <a href="https://en.wikipedia.org/wiki/Circumcenter">circumcenter</a> (the center of the circumscribed circle). What I have in mind in this post is a similarly-defined concept, but with a different group of transformations than similarity: the combination of any two separate linear transformations to the two coordinate axes of the <a href="https://en.wikipedia.org/wiki/Cartesian_plane">Cartesian plane</a>, or transformations that swap the (transformed) axes. Another way of describing these transformations is that they preserve axis-parallel lines and relative area. They also preserve other lines and parallelism of lines.</p>

<p>One of the standard Euclidean triangle centers turns out to be a Cartesian center as well: the centroid has as its coordinates the average of the three triangle vertex coordinates, and this coordinatewise calculation (independent of the ordering of the three vertices) shows it to be equivariant under Cartesian transformations. It is also the point where the three lines through each vertex and opposite side midpoint meet.</p>

<p style="text-align: center;"><img alt="Centroid of a triangle" src="https://11011110.github.io/blog/assets/2020/centroid.svg"/></p>

<p>Similarly, we can find a Cartesian triangle center from the coordinatewise median of the three vertices.</p>

<p style="text-align: center;"><img alt="Median of a triangle" src="https://11011110.github.io/blog/assets/2020/median.svg"/></p>

<p>The center of the axis-parallel bounding box is also a Cartesian triangle center, again computed coordinatewise as the average of the minimum and maximum coordinates.</p>

<p style="text-align: center;"><img alt="Bounding-box center of a triangle" src="https://11011110.github.io/blog/assets/2020/bbcenter.svg"/></p>

<p>But a Cartesian triangle center does not have to be determined coordinatewise in this way. As an example, denote the three triangle vertices by  and consider the point  with the property that the axis-parallel bounding boxes of the three line segments  all have equal area. For two points  and , the locus of points for which the two bounding boxes have equal area is a line through the other two corners of the bounding box of segment . (To see this, consider a linear transformation that takes this bounding box to a square, and apply symmetry.) The three lines defined in this way from the three pairs of vertices of a non-degenerate triangle always meet in a point, the center we are seeking. (This follows from the shared equality of the three rectangles, but it is also an instance of the dual of <a href="https://en.wikipedia.org/wiki/Pappus%27s_hexagon_theorem">Pappusâs theorem</a>.) And this point is equivariant under Cartesian transformations because these transformations preserve the ratios of areas of bounding rectangles.</p>

<p style="text-align: center;"><img alt="Point of equal bounding boxes of a triangle" src="https://11011110.github.io/blog/assets/2020/equalbb.svg"/></p>

<p>You can tell itâs not a coordinatewise center because, in the figure above, the triangle vertices have equally spaced -coordinates, from which it follows that all coordinatewise centers lie on the horizontal line with median -coordinate, but this center doesnât.</p>

<p>In general, the geometry of the plane with Cartesian instead of Euclidean transformations does not seem to have been very thoroughly explored. These examples show, I think, that there are interesting things to find there.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104079992540248342">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-04-28T21:24:00Z</updated>
    <published>2020-04-28T21:24:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-04-29T07:50:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4369</id>
    <link href="https://lucatrevisan.wordpress.com/2020/04/28/phase-2-ready-or-not-here-it-comes/" rel="alternate" type="text/html"/>
    <title>Phase 2, ready or not, here it comes</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Yesterday the Italian prime minister announced the timeline of the loosening of the lockdown. Some manufacturing restarted yesterday, and some customer-facing businesses will gradually reopen between next Monday and the beginning of June. Since the start of the lockdown 51 â¦ <a href="https://lucatrevisan.wordpress.com/2020/04/28/phase-2-ready-or-not-here-it-comes/">Continue reading <span class="meta-nav">â</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Yesterday the Italian prime minister announced the timeline of the loosening of the lockdown. Some manufacturing restarted yesterday, and some customer-facing businesses will gradually reopen between next Monday and the beginning of June.</p>
<p><span id="more-4369"/></p>
<p>Since the start of the lockdown 51 days ago, it was clear that the condition to âreopenâ was to have in place a âtest-trace-isolateâ plan to find infected people as soon as possible after their contagion, trace their contacts, and isolate them. For this, one needs an infrastructure for large-scale testing with quick turnaround, a well-staffed agency to do manual tracing or an app to do it automatically, and facilities to isolate people who are infected and not in need of hospitalization.</p>
<p>None of this has been done. There hasnât been a sufficient ramp-up of testing capacity; as far as I know no additional people have been hired and trained for manual contact-tracing; there is an app for digital contact-tracing, but the plan to adopt it appears to have been shelved; if people test positive and are well they are asked to stay home, potentially with their family members, who are free to leave as they please.</p>
<p>All our eggs are in the basket of social distancing. The humor site Kotiomkin posted âBasically, phase 2 will rely on everybodyâs common sense. We are fuckedâ.</p>
<p>The problem is that social distancing requires a common-sense avoidance of close contacts with other people, and the government can give guidelines on how to achieve it, but eventually it has to rely on everybodyâs sense of responsibility. Unfortunately, the national mood around regulations is to immediately look for loopholes. </p>
<p>For example the initial lockdown measures stipulated that one could leave home to go buy groceries. Then when the police would stop people tens of miles away from their home, people would say âI drove here to buy groceriesâ, âbut we are thirty miles away from where you liveâ, âyes but here the groceries are betterâ. So a subsequent amendment stipulated that one could buy groceries only in the town of residence, making it hard for people living next to a town border, for whom the closest grocery store was across the town line. In fact, every time I have encountered a crazy Italian law or regulation, and asked around for the likely reason it was instituted, it was usually to close a loophole in a previous regulation, which in turn had been put in place to close a loophole in a third regulation, and basically itâs loophole-closing all the way down to <a href="https://en.wikipedia.org/wiki/Roman_law">Roman law</a>.</p>
<p>I think that, from this point on, the story of the Italian covid-19 epidemic will not show the future of the rest of the Western world, but will evolve in its own timeline. Meanwhile, there are a couple of lessons that are still relevant, particularly in the comparison between Lombardy and NYC, which continue to track each other remarkably well.</p>
<p><img alt="2020-05-28-nyc-daily" class="alignnone size-full wp-image-4375" src="https://lucatrevisan.files.wordpress.com/2020/04/2020-05-28-nyc-daily.png?w=584"/><img alt="2020-05-28-nyc" class="alignnone size-full wp-image-4376" src="https://lucatrevisan.files.wordpress.com/2020/04/2020-05-28-nyc.png?w=584"/></p>
<p>One is that, at one point, it was decided to move older people with mild cases of covid-19 from hospital to nursing homes, to open up beds in hospitals. Since the personnel of nursing homes are not trained in the safety procedures for infectious diseases, and since nursing homes host older, frail people who are the highest-risk category for this illness, the result was a huge number of deaths in these nursing homes. Now nursing homes in New York are <a href="https://www.nytimes.com/2020/04/24/us/nursing-homes-coronavirus.html">being asked to take covid-19 patients from hospitals</a>.</p>
<p>The other is that an analysis of all-cause mortality shows a spike in March such that the difference between the typical March all-cause mortality and the March 2020 all-cause mortality is much bigger than the number of confirmed covid-19 deaths. Now the same phenomenon is being <a href="https://www.nytimes.com/interactive/2020/04/27/upshot/coronavirus-deaths-new-york-city.html"> observed in New York City</a>, with numbers similar to Lombardyâs. Notably, the baseline all-case mortality rate in Lombardy is much higher than in New York City (because  population growth has stalled and the demographic skews older), so while the absolute number of additional deaths is similar, the relative increase is a much more dramatic 6x in NYC versus roughly 4x in Lombardy. </p></div>
    </content>
    <updated>2020-04-28T16:40:10Z</updated>
    <published>2020-04-28T16:40:10Z</published>
    <category term="Milan"/>
    <category term="New York"/>
    <category term="covid-19"/>
    <category term="phase 2"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2020-04-29T23:20:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/061</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/061" rel="alternate" type="text/html"/>
    <title>TR20-061 |  Tree-depth and the Formula Complexity of Subgraph Isomorphism | 

	Benjamin Rossman, 

	Deepanshu Kush</title>
    <summary>For a fixed "pattern" graph $G$, the $\textit{colored}$ $G\textit{-subgraph isomorphism problem}$ (denoted $\mathrm{SUB}(G)$) asks, given an $n$-vertex graph $H$ and a coloring $V(H) \to V(G)$, whether $H$ contains a properly colored copy of $G$. The complexity of this problem is tied to parameterized versions of $\mathit{P}$ ${=}?$ $\mathit{NP}$ and $\mathit{L}$ ${=}?$ $\mathit{NL}$, among other questions. An overarching goal is to understand the complexity of $\mathrm{SUB}(G)$, under different computational models, in terms of natural invariants of the pattern graph $G$.

In this paper, we establish a close relationship between the $\textit{formula complexity}$ of $\mathrm{SUB}$ and an invariant known as $\textit{tree-depth}$ (denoted $\mathrm{td}(G)$). $\mathrm{SUB}(G)$ is known to be solvable by monotone $\mathit{AC^0}$ formulas of size $O(n^{\mathrm{td}(G)})$. Our main result is an $n^{\tilde\Omega(\mathrm{td}(G)^{1/3})}$ lower bound for formulas that are monotone $\textit{or}$ have sub-logarithmic depth. This complements a lower bound of Li, Razborov and Rossman (SICOMP 2017) relating tree-width and $\mathit{AC^0}$ circuit size. As a corollary, it implies a stronger homomorphism preservation theorem for first-order logic on finite structures (Rossman, ITCS 2017).

The technical core of this result is an $n^{\Omega(k)}$ lower bound in the special case where $G$ is a complete binary tree of height $k$, which we establish using the $\textit{pathset framework}$ introduced in (Rossman, SICOMP 2018). (The lower bound for general patterns follows via a recent excluded-minor characterization of tree-depth (Czerwi\'nski et al, arXiv:1904.13077).) Additional results of this paper extend the pathset framework and improve upon both, the best known upper and lower bounds on the average-case formula size of $\mathrm{SUB}(G)$ when $G$ is a path.</summary>
    <updated>2020-04-28T11:49:13Z</updated>
    <published>2020-04-28T11:49:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-29T23:20:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/04/28/tenure-track-assistant-associate-or-full-professor-theory-of-computation-at-university-of-groningen-the-netherlands-apply-by-may-5-2020/</id>
    <link href="https://cstheory-jobs.org/2020/04/28/tenure-track-assistant-associate-or-full-professor-theory-of-computation-at-university-of-groningen-the-netherlands-apply-by-may-5-2020/" rel="alternate" type="text/html"/>
    <title>Tenure Track Assistant, Associate or Full Professor Theory of Computation at University of Groningen, the Netherlands  (apply by May 5, 2020)</title>
    <summary>The University of Groningen seeks for an outward looking researcher in Computer Science who will perform research on theory of computation, broadly construed, in relation to new (neuromorphic) computing systems and architectures. We offer a challenging position in a unique world-class research environment, where close collaborations between research groups with different expertise are encouraged. Website: [â¦]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The University of Groningen seeks for an outward looking researcher in Computer Science who will perform research on theory of computation, broadly construed, in relation to new (neuromorphic) computing systems and architectures. We offer a challenging position in a unique world-class research environment, where close collaborations between research groups with different expertise are encouraged.</p>
<p>Website: <a href="https://www.rug.nl/about-ug/work-with-us/job-opportunities/?details=00347-02S0007KLP">https://www.rug.nl/about-ug/work-with-us/job-opportunities/?details=00347-02S0007KLP</a><br/>
Email: b.noheda@rug.nl, j.b.t.m.roerdink@rug.nl and/or j.h.m.van.der.velde@rug.nl</p></div>
    </content>
    <updated>2020-04-28T08:50:14Z</updated>
    <published>2020-04-28T08:50:14Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-04-29T23:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7716</id>
    <link href="https://windowsontheory.org/2020/04/27/lessons-from-covid-19-what-works-online-and-what-doesnt/" rel="alternate" type="text/html"/>
    <title>Lessons from COVID-19: What works online and what doesnât</title>
    <summary>(I am now on Twitter , so you can follow this blog there too if you prefer it. âBoaz) Between Zoom meetings and deadlines, I thought Iâd jot down a few of my impressions so far on what lessons we can draw from this period on how well research and education can work online. Iâve [â¦]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>(I am now on <a href="https://twitter.com/boazbaraktcs">Twitter</a> ,  so you can follow this blog there too if you prefer it. âBoaz)</p>



<p>Between Zoom meetings and deadlines, I thought Iâd jot down a few of my impressions so far on what lessons we can draw from this period on how well research and education can work online.  Iâve had a few surprises in both directions â things that worked better than I would have expected, and aspects that were more problematic than I realized. These are personal impressions â please do comment on your own experiences.</p>



<p>As a rule of thumb, the interactions that most successfully replicate online are those that are relatively short and focused (an hour or so â e.g., a focused research meeting, seminar talk, or a lecture in a course).  Other interactions (e.g., faculty meetings) are also fairly easily to port online, perhaps because the original wasnât that great to begin with.</p>



<p>The things that are harder to replicate are sustained interactions over longer periods. These include more extended and less directed research collaborations, informal workshops, as well as support for students outside lectures in education.</p>



<p><strong>Works well: Research seminars</strong></p>



<p>Iâve been pleasantly surprised by how effective research seminars such as our <a href="https://mltheory.org/">machine learning theory seminar</a> are over Zoom. In particular these were no less interactive than physical seminars â in fact people are offten <em>more</em> comfortable asking questions on chat than they would during in-person seminars. I hope such seminars become common practice even after this period ends- flying a speaker across the country or the world to give an hour talk doesnât makes much sense given that there is a perfectly satisfactory alternative. </p>



<p><strong>Works well: Lectures</strong></p>



<p>This term I am teaching <a href="https://cs127.boazbarak.org/schedule/">cryptography</a>, and online lectures on Zoom have gone surprisingly well (after  working out some <a href="https://windowsontheory.org/2020/03/26/technology-for-theory-covid-19-edition/">technical issues</a>). Students participate on chat and ask questions, and seem to be following the lecture quite well. The important caveat is that lectures only work well for the students that attend and can follow them. For students who need extra support, itâs become much harder to access it.  Itâs also much easier for students to (literally) âfall off the screenâ and fall behind in a course, which brings me to the next point.</p>



<p><strong>Works less well: Support outside lectures</strong></p>



<p>Lectures are just one component of a course. Most of studentsâ learning occurs outside the classroom, where students meet together and work on problem sets, or discuss course material. These interactions between students (both related and unrelated to course) are where much of their intellectual growth happens. </p>



<p>All these interactions are greatly diminished online, and I did not yet see a good alternative. Iâve seen reduced attendance in office hours and sections, and reports are that students find it much harder to have the sort of chance discussions and opportunities to find study partners that they value so much.  If anything, this experience had made me <em>less</em> positive about the possibility of online education replacing physical colleges (though there are interesting <a href="https://en.wikipedia.org/wiki/Minerva_Schools_at_KGI">hybrid models</a>, where the students are co-located but lecturers are online).</p>



<p><strong>Works less well: unstructured research collaborations</strong></p>



<p>A focused meeting reporting on results or deciding on work allocation works pretty well over Zoom. So far it seems that extended brainstorming meetings, such as talking to someone over several hours in a coffeeshop, are much harder to replicate. In particular, a good part of such meetings is often spent with people staring in silence into their notebooks. As I <a href="https://twitter.com/boazbaraktcs/status/1253330145789673473">wrote</a>,  mutual silence seems to be very hard to do over Zoom.</p>



<p>Generally, informal week-long workshops, where much time is devoted to unstructured discussions, are ones that are most important to hold in person, and are hard (or maybe impossible) to replicate online. I have still not attended an online conference, but I suspect that these aspects of the conference would also be the ones hardest to replicate.</p>



<p><strong>Works well: faculty meetings</strong></p>



<p>Iâve always found it hard to bring a laptop to a faculty meeting and get work done, while listening with one ear to whatâs going on. This is so much easier over Zoom <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/></p></div>
    </content>
    <updated>2020-04-27T21:01:00Z</updated>
    <published>2020-04-27T21:01:00Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-04-29T23:20:53Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1676</id>
    <link href="https://theorydish.blog/2020/04/27/whats-your-story/" rel="alternate" type="text/html"/>
    <title>Whatâs Your Story?</title>
    <summary>Last quarter, I taught a course on research methods in TOC, which gave me an opportunity to think through many aspects of research. I was promoting a human-centric perspective on research: how to facilitate better research by addressing the conditions needed for an individual researcher and groups of researchers to succeed. As science is a communal effort, the communication of science is critical, and thus one of the topics we covered is oral presentations. There are plenty of resources about research talks, and mostly they emphasize form over matter. How many words in a slide? How many slides in a talk? how to and how not to use font colors? How to and how not to use animation? and so on. While all of these are important, I find that the failing of many research talks is on a much more basic level. Think back to a research talk you heard recently, or to one you heard a few months ago. You may remember how you felt and what you thought of the talk but what do you remember of this talk in terms of content? Most of us will find that we donât remember much, I rarely do. Yet [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Last quarter, I taught <a href="https://omereingold.wordpress.com/cs-353-the-practice-of-theory-research/">a course on research methods</a> in TOC, which gave me an opportunity to think through many aspects of research. I was promoting a human-centric perspective on research: how to facilitate better research by addressing the conditions needed for an individual researcher and groups of researchers to succeed. As science is a communal effort, the communication of science is critical, and thus one of the topics we covered is oral presentations.</p>
<p>There are plenty of resources about research talks, and mostly they emphasize form over matter. How many words in a slide? How many slides in a talk? how to and how not to use font colors? How to and how not to use animation? and so on. While all of these are important, I find that the failing of many research talks is on a much more basic level.</p>
<p>Think back to a research talk you heard recently, or to one you heard a few months ago. You may remember how you felt and what you thought of the talk but what do you remember of this talk in terms of content? Most of us will find that we donât remember much, I rarely do. Yet in our presentations, we often follow a research-paper-like mold and squeeze in many little details that are somehow important to us, forgetting that they will all vanish in our audienceâs memory soon after (or completely missed in the first place). Giving a talk (writing a paper, writing a blog post etc.) is about communication: who is your audience? what are the limitation of the medium? what is the message you want to convey? Since so little stays with the audience long term, it makes sense to make sure that this little will be what seems most important for you to convey.</p>
<p>The idea I am promoting here is not new, and there are various techniques towards this goal. One (which I think Oded Goldreich shared with me), is to think of audienceâs attention as a limited currency. Whenever you share a big idea you spend a big token and other ideas cost a smaller token. Imagine you have one or two big tokens and a few smaller tokens. <a href="https://www.youtube.com/watch?v=5OFAhBw0OXs">Another approach</a>, emphasizes the notion of <strong>a premise</strong>. The idea promoted here is that a talk needs a premise and this should be the title of the talk. Furthermore, every slide needs a premise and it should be the title of the slide. A premise is a main idea and is a complete sentence. It is not unusual to find a slide titled âAnalysisâ or âEfficiencyâ but neither of these is a premise. âProblem X has an efficient algorithmâ could be. The talkâs premise could help you distill what you want the audience to take out of your talk. It also helps shape the talk, as everything that doesnât serve the premise shouldnât be there. Note that each paper can provoke many different premises and thus many different talks.</p>
<p>Here I want to play with a different idea, that I find intriguing, even if it may seem a bit extreme. It will not be controversial that a good talk (and paper) tells a story. After all, humans understand and remember narratives. But could we take inspiration from the form of storytelling in fiction writing? A vast literature, classifies different kinds of stories and explores their templates (see for example <a href="http://storybistro.com/7-story-frameworks/">this short discussion</a>).Â  Can we find analogues to these types in scientific research talks?</p>
<p>The type of story that is easiest to relate to is the <strong>Quest/Heroâs Journey</strong> (think Lord of the Rings). These have several distinct ingredients: a call to adventure, tests, allies, enemies, ordeal, reward, victorious return. Some research talks that follow this template do it well and preserve a sense of suspense and excitement, others seem like a long list of problems and the tricks that the work uses to handle them.</p>
<p>I believe that many other story templates can find analogues is research talks as well. Here are my initial attempts:</p>
<ul>
<li><strong>Coming of age</strong> stories â this area of research previously only had naive ideas but this works brings significant depth.</li>
<li><strong>The Under<span style="color: #000000;">dog</span></strong><span style="color: #000000;"> (think David and Goliath): a modest technique that concurred a great challenge.</span></li>
<li><strong>Rags to Riches</strong> (think the Ugly Duckling): an area or technique that were not successful prove powerful.
<ul>
<li>Similarly: <strong>Rebirth</strong> (reinvention, renewal).</li>
</ul>
</li>
<li><strong>Comedy</strong> (or the Clarity Tale) â conceptual works shedding a new perspective.</li>
<li><strong>Tragedy</strong> (or the Cautionary Tale) â Some impossibility results come to mind (couldnât we view Arrowâs impossibility theorem as being tragic?)</li>
<li><strong>Redemption stories</strong>: the field so far has missed the point, was misleading or harmful, but this work makes amends.</li>
</ul>
<p>Can you suggest papers and a story type that could fit them?</p></div>
    </content>
    <updated>2020-04-27T16:26:33Z</updated>
    <published>2020-04-27T16:26:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-04-29T23:21:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/060</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/060" rel="alternate" type="text/html"/>
    <title>TR20-060 |  Leakage-Resilient Extractors and Secret-Sharing against Bounded Collusion Protocols | 

	Eshan Chattopadhyay, 

	Xin Li, 

	Vipul Goyal, 

	Jesse Goodman</title>
    <summary>In a recent work, Kumar, Meka, and Sahai (FOCS 2019) introduced the notion of bounded collusion protocols (BCPs), in which $N$ parties wish to compute some joint function $f:(\{0,1\}^n)^N\to\{0,1\}$ using a public blackboard, but such that only $p$ parties may collude at a time. This generalizes well studied models in multiparty communication complexity, such as the number-in-hand (NIH) and number-on-forehead (NOF) models, which are just endpoints on this rich spectrum. We construct explicit hard functions against this spectrum, and achieve a tradeoff between collusion and complexity. Using this, we obtain improved leakage-resilient secret sharing schemes against bounded collusion protocols. 

Our main tool in obtaining hard functions against BCPs are explicit constructions of leakage resilient extractors against BCPs for a wide range of parameters. Kumar et al. (FOCS 2019) studied  such extractors and called them cylinder intersection extractors. In fact, such extractors directly yield correlation bounds against BCPs. We focus on the following setting: the input to the extractor consists of $N$ independent sources of length $n$, and the leakage function Leak $:(\{0,1\}^n)^N\to\{0,1\}^\mu\in\mathcal{F}$ is a BCP with some collusion bound $p$ and leakage (output length) $\mu$. While our extractor constructions are very general, we highlight some interesting parameter settings:

1. In the case when the input sources are uniform, and $p=0.99N$ parties collude, our extractor can handle $n^{\Omega(1)}$ bits of leakage, regardless of the dependence between $N,n$. The best NOF lower bound (i.e., $p=N-1$) on the other hand requires $N&lt;\log n$ even to handle $1$ bit of leakage.

2. Next, we show that for the same setting as above, we can drop the entropy requirement to $k=$ polylog $n$, while still handling polynomial leakage for $p=0.99N$.  This resolves an open question about cylinder intersection extractors raised by Kumar et al. (FOCS 2019), and we find an application of such low entropy extractors in a new type of secret sharing.

We also provide an explicit compiler that transforms any function with high NOF (distributional) communication complexity into a leakage-resilient extractor that can handle polylogarithmic entropy and substantially more leakage against BCPs. Thus any improvement of NOF lower bounds will immediately yield better leakage-resilient extractors.

Using our extractors against BCPs, we obtain improved $N$-out-of-$N$ leakage-resilient secret sharing schemes. The previous best scheme from Kumar et al. (FOCS 2019) required share size to grow exponentially in the collusion bound, and thus cannot efficiently handle $p=\omega(\log N)$. Our schemes have no dependence of this form, and can thus handle collusion size $p=0.99N$.</summary>
    <updated>2020-04-27T06:12:53Z</updated>
    <published>2020-04-27T06:12:53Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-29T23:20:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/059</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/059" rel="alternate" type="text/html"/>
    <title>TR20-059 |  Pr-ZSUBEXP is not contained in Pr-RP | 

	Gonen Krak, 

	Noam Parzanchevski, 

	Amnon Ta-Shma</title>
    <summary>We unconditionally prove there exists a promise problem in promise ZSUBEXP that cannot be solved in promise RP. 
The proof technique builds upon Kabanets' easy witness method [Kab01] as implemented by Impagliazzo et. al [IKW02], with a separate diagonalization carried out on each of the two alternatives in the win-win argument. We remark that even though the easy witness method is a key component in many celebrated results in derandomization, we are not aware of any previous unconditional separation like the one we show.

We remark that the result relativizes. We could not prove a similar result for total functions, nor for functions in ZTime(T(n)) for T(n) below a half-exponential function (i.e., T such that T(T(n)) &lt; 2^n).</summary>
    <updated>2020-04-27T05:27:15Z</updated>
    <published>2020-04-27T05:27:15Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-29T23:20:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/058</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/058" rel="alternate" type="text/html"/>
    <title>TR20-058 |  Interactive Proofs for Verifying Machine Learning | 

	Jonathan Shafer, 

	Amir Yehudayoff, 

	Shafi Goldwasser, 

	Guy Rothblum</title>
    <summary>We consider the following question: using a source of labeled data and interaction with an untrusted prover, what is the complexity of verifying that a given hypothesis is "approximately correct"? We study interactive proof systems for PAC verification, where a verifier that interacts with a prover is required to accept good hypotheses, and reject bad hypotheses. Both the verifier and the prover are efficient and have access to data samples from an unknown distribution. We are interested in cases where the verifier can use significantly less data than is required for (agnostic) PAC learning, or use a substantially cheaper data source (e.g., using only random samples for verification, even though learning requires membership queries). We believe that today, when data and data-driven algorithms are quickly gaining prominence, the question of verifying purported outcomes of data analyses is very well-motivated.
		
We show three main results. First, we prove that for a specific hypothesis class, verification is significantly cheaper than learning in terms of the number of random samples required, even if the verifier engages with the prover only in a single-round (NP-like) protocol. Moreover, for this class we prove that single-round verification is also significantly cheaper than testing closeness to the class. Second, for the broad class of Fourier-sparse boolean functions, we show a multi-round (IP-like) verification protocol, where the prover uses membership queries, and the verifier is able to assess the result while only using random samples. Third, we show that verification is not always more efficient. Namely, we show a class of functions where verification requires as many samples as learning does, up to a logarithmic factor.</summary>
    <updated>2020-04-27T01:42:43Z</updated>
    <published>2020-04-27T01:42:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-29T23:20:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16982</id>
    <link href="https://rjlipton.wordpress.com/2020/04/26/time-for-some-jokes/" rel="alternate" type="text/html"/>
    <title>Time For Some Jokes</title>
    <summary>Can we still smile? [ Hardy and Littlewood] John Littlewood lived through the 1918â1919 flu pandemic, yet he appears not to have remarked on it in print. Nor can we find mention of it by Godfrey Hardy in A Mathematicianâs Apologyâthough Hardy did write about the ravages of WW I. Today, Ken and I thought [â¦]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Can we still smile?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/04/26/time-for-some-jokes/unknown-139/" rel="attachment wp-att-16991"><img alt="" class="alignright size-full wp-image-16991" src="https://rjlipton.files.wordpress.com/2020/04/unknown-2.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Hardy and Littlewood]</font></td>
</tr>
</tbody>
</table>
<p>
John Littlewood lived through the 1918â1919 flu pandemic, yet he appears not to have remarked on it in print. Nor can we find mention of it by Godfrey Hardy in <em>A Mathematicianâs Apology</em>âthough Hardy did write about the ravages of WW I.</p>
<p>
Today, Ken and I thought you might like some fun comments that are not about the current pandemic. </p>
<p>
This is not to say we are ignoring it. We are all fighting the virus in one way or another. Our hearts go out to those of you fighting it directly. We are all worried about ourselves and others. We are stuck at home, at least most of us. We are all in this terrible time together. We hope you all are safe and well. </p>
<p>
We thought we would list a few jokes and stories that you might enjoy. We wrote recently about one kind of mathematical <a href="https://rjlipton.wordpress.com/2020/02/28/reductions-and-jokes/">joke</a> that can be given various proportions of pure levity and mathematical content. Our friends Lance Fortnow and Bill Gasarch, plus commenters in their <a href="https://blog.computationalcomplexity.org/2006/06/funniest-computer-science-joke-ever.html">item</a>, collected some jokes on the computer science side.</p>
<p>
Littlewoodâs notion of âmathematical jokeâ leaned more on mathematical content, though his <a href="https://en.wikipedia.org/wiki/A_Mathematician's_Miscellany">memoir</a> <em>A Mathematicianâs Miscellany</em> includes many funny stories as well. At the end of his introduction to the book, he wrote:</p>
<blockquote><p><b> </b> <em> A good mathematical joke is better, and better mathematics, than a dozen mediocre papers. </em>
</p></blockquote>
<p/><p>
We will start at the levity end. This is almost a math <a href="http://web.sonoma.edu/Math/faculty/falbo/jokes.html">joke</a>:</p>
<blockquote><p><b> </b> <em> The Daily News published a story saying that one-half of the MP (Members of Parliament) were crooks.<br/>
The Government took great exception to that and demanded a retraction and an apology.<br/>
The newspaper responded the next day with an apology and reported that one-half of the MPs were not crooks. </em>
</p></blockquote>
<p/><p>
We like this one, even if it is not really a hardcore math one. It does rely on the fact that <img alt="{\frac{1}{2} + \frac{1}{2} = 1.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B1%7D%7B2%7D+%3D+1.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{1}{2} + \frac{1}{2} = 1.}"/></p>
<p>
</p><p/><h2> Jokes and More </h2><p/>
<p/><p>
The following are some examples that we hope you all like. They are from a variety of sources: </p>
<ul>
<li>
Jokes that mathematicians think are <a href="https://www.businessinsider.com/13-math-jokes-that-every-mathematician-finds-absolutely-hilarious-2013-5">funny</a>. <p/>
</li><li>
Some are from <a href="https://cstheory.stackexchange.com/questions/3111/funny-tcs-related-papers-etc">StackExchange</a>. <p/>
</li><li>
Others are from Andrej Cherkaevâs <a href="https://www.math.utah.edu/~cherk/mathjokes.html">page</a>.
</li></ul>
<p>We have lightly edited a few.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> âMy age is two billion years old,â said Paul ErdÃ¶s. The point is: </p>
<blockquote><p><b> </b> <em> When I was seventeen years old it was said the earth was two billion years old. Now they say it is four billion years old. So my age is about two billion years old. </em>
</p></blockquote>
<p/><p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> There was a statistician that drowned crossing a river <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/> It was 3 feet deep on average. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> An infinite number of mathematicians walk into a bar. The first one orders a beer. The second orders half a beer. The third orders a third of a beer. The bartender bellows, âGet the heck out of here, are you trying to ruin me?â</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> An chemist, a physicist, and a mathematician are stranded on an island when a can of food rolls ashore. The chemist and the physicist comes up with many ingenious ways to open the can. Then suddenly the mathematician gets a bright idea: âAssume we have a can opener <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/>â </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> A theorist decides she wants to learn more about practical problems. She sees a seminar with the title: âThe Theory of Gears.â So she goes. The speaker stands up and begins, âThe theory of gears with a finite number of teeth is well known <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/></p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The reason that every major university maintains a department of mathematics is that it is cheaper to do this than to institutionalize all those people.</p>
<p>
Regarding the last one, Littlewood did after all write in his book:</p>
<blockquote><p><b> </b> <em> Mathematics is a dangerous profession; an appreciable proportion of us go mad. </em>
</p></blockquote>
<p/><p>
This appears to have been a playful swipe at Hardyâs decision to leave Cambridge for Oxford. It was couched in a discussion of events that would seem to have had tiny probabilities before they happened. </p>
<p>
The last two weâve picked out from the above sites verge into philosophy:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The cherry theorem: Question: What is a small, red, round thing that has a cherry pit inside? <br/>
Answer: A cherry.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> RenÃ© Descartes went into his favorite bar and the bartender asked, âwould you like your usual drink tonight, Monsieur Descartes?â Descartes replied âI think not.â Then he promptly ceased to exist.</p>
<p>
</p><p/><h2> Wrong Derivations, Right Results </h2><p/>
<p/><p>
Littlewoodâs standards for a âmathematical jokeâ were higher than ours, but we will start by adapting an example from this MathOverflow <a href="https://mathoverflow.net/questions/38856/jokes-in-the-sense-of-littlewood-examples">discussion</a> of Littlewood-style jokes. Sometimes we can play a joke on ourselves by deriving a result we know is right but with an incorrect proof. Here is the example:</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <a href="https://www.reddit.com/r/math/comments/1bntfg/are_there_or_can_there_be_jokes_or_puns_in/">Casting out 6âs</a>. Suppose we want to simplify the fraction <img alt="{\frac{166}{664}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B166%7D%7B664%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{166}{664}}"/>. We can use the rule of casting out 6âs to get </p>
<p align="center"><img alt="\displaystyle  \frac{166}{664} = \frac{16}{64} = \frac{1}{4}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B166%7D%7B664%7D+%3D+%5Cfrac%7B16%7D%7B64%7D+%3D+%5Cfrac%7B1%7D%7B4%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{166}{664} = \frac{16}{64} = \frac{1}{4}. "/></p>
<p>
The rule works quite generally:</p>
<p align="center"><img alt="\displaystyle  \frac{1666}{6664} = \frac{16666}{66664} = \frac{166666}{666664} = \cdots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B1666%7D%7B6664%7D+%3D+%5Cfrac%7B16666%7D%7B66664%7D+%3D+%5Cfrac%7B166666%7D%7B666664%7D+%3D+%5Ccdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{1666}{6664} = \frac{16666}{66664} = \frac{166666}{666664} = \cdots "/></p>
<p/><p/>
<p align="center"><img alt="\displaystyle  \frac{26}{65} = \frac{266}{665} = \frac{2666}{6665} = \frac{26666}{66665} = \cdots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B26%7D%7B65%7D+%3D+%5Cfrac%7B266%7D%7B665%7D+%3D+%5Cfrac%7B2666%7D%7B6665%7D+%3D+%5Cfrac%7B26666%7D%7B66665%7D+%3D+%5Ccdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{26}{65} = \frac{266}{665} = \frac{2666}{6665} = \frac{26666}{66665} = \cdots "/></p>
<p>You can even turn the paper upside down and cast out the <img alt="{6}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{6}"/>âs that you see then:</p>
<p/><p align="center"><img alt="\displaystyle  \frac{19}{95} = \frac{199}{995} = \frac{1999}{9995} = \frac{19999}{99995} = \cdots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B19%7D%7B95%7D+%3D+%5Cfrac%7B199%7D%7B995%7D+%3D+%5Cfrac%7B1999%7D%7B9995%7D+%3D+%5Cfrac%7B19999%7D%7B99995%7D+%3D+%5Ccdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{19}{95} = \frac{199}{995} = \frac{1999}{9995} = \frac{19999}{99995} = \cdots "/></p>
<p/><p/>
<p align="center"><img alt="\displaystyle  \frac{49}{98} = \frac{499}{998} = \frac{4999}{9998} = \frac{49999}{99998} = \cdots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B49%7D%7B98%7D+%3D+%5Cfrac%7B499%7D%7B998%7D+%3D+%5Cfrac%7B4999%7D%7B9998%7D+%3D+%5Cfrac%7B49999%7D%7B99998%7D+%3D+%5Ccdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{49}{98} = \frac{499}{998} = \frac{4999}{9998} = \frac{49999}{99998} = \cdots "/></p>
<p>
Note, this is a joke: The rule of course does not actually work all the time: 	</p>
<p align="center"><img alt="\displaystyle  \frac{56}{65} = \frac{5}{5} = 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B56%7D%7B65%7D+%3D+%5Cfrac%7B5%7D%7B5%7D+%3D+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{56}{65} = \frac{5}{5} = 1. "/></p>
<p/><p><br/>
We thought to try to come up with our own examples, or at least blend in other sources. It once struck me (Ken), on reading a column by Martin Gardner on difference equations, that they give a âconvincing proofâ of <img alt="{0^0 = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%5E0+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0^0 = 1}"/>. Consider the powers of a natural number <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>, say <img alt="{k = 5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k = 5}"/>. Take differences like so: </p>
<p align="center"><img alt="\displaystyle  \begin{array}{ccccccccccc} 1 &amp; &amp; 5 &amp; &amp; 25 &amp; &amp; 125 &amp; &amp; 625 &amp; &amp; \dots\\ &amp; 4 &amp; &amp; 20 &amp; &amp; 100 &amp; &amp; 500 &amp; &amp; \dots\\ &amp; &amp; 16 &amp; &amp; 80 &amp; &amp; 400 &amp; &amp; \dots &amp; &amp; \\ &amp; &amp; &amp; 64 &amp; &amp; 320 &amp; &amp; \dots &amp; &amp; &amp;\\ &amp; &amp; &amp; &amp; 256 &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \ddots &amp; &amp; &amp; \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Bccccccccccc%7D+1+%26+%26+5+%26+%26+25+%26+%26+125+%26+%26+625+%26+%26+%5Cdots%5C%5C+%26+4+%26+%26+20+%26+%26+100+%26+%26+500+%26+%26+%5Cdots%5C%5C+%26+%26+16+%26+%26+80+%26+%26+400+%26+%26+%5Cdots+%26+%26+%5C%5C+%26+%26+%26+64+%26+%26+320+%26+%26+%5Cdots+%26+%26+%26%5C%5C+%26+%26+%26+%26+256+%26+%26+%26+%26+%5C%5C+%26+%26+%26+%26+%26+%5Cddots+%26+%26+%26+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{ccccccccccc} 1 &amp; &amp; 5 &amp; &amp; 25 &amp; &amp; 125 &amp; &amp; 625 &amp; &amp; \dots\\ &amp; 4 &amp; &amp; 20 &amp; &amp; 100 &amp; &amp; 500 &amp; &amp; \dots\\ &amp; &amp; 16 &amp; &amp; 80 &amp; &amp; 400 &amp; &amp; \dots &amp; &amp; \\ &amp; &amp; &amp; 64 &amp; &amp; 320 &amp; &amp; \dots &amp; &amp; &amp;\\ &amp; &amp; &amp; &amp; 256 &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \ddots &amp; &amp; &amp; \end{array} "/></p>
<p>
The powers of <img alt="{k-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k-1}"/> always appear on the bottom diagonal. Thus we have: <img alt="{(k-1)^0 = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28k-1%29%5E0+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(k-1)^0 = 1}"/>, <img alt="{(k-1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28k-1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(k-1)}"/>, <img alt="{(k-1)^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28k-1%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(k-1)^2}"/>, and so on. Now do this for <img alt="{k = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k = 1}"/>:</p>
<p align="center"><img alt="\displaystyle \begin{array}{ccccccccccc} 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; \dots\\ &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots\\ &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots &amp; &amp; \\ &amp; &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots &amp; &amp; &amp;\\ &amp; &amp; &amp; &amp; 0 &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \ddots &amp; &amp; &amp; \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Bccccccccccc%7D+1+%26+%26+1+%26+%26+1+%26+%26+1+%26+%26+1+%26+%26+%5Cdots%5C%5C+%26+0+%26+%26+0+%26+%26+0+%26+%26+0+%26+%26+%5Cdots%5C%5C+%26+%26+0+%26+%26+0+%26+%26+0+%26+%26+%5Cdots+%26+%26+%5C%5C+%26+%26+%26+0+%26+%26+0+%26+%26+%5Cdots+%26+%26+%26%5C%5C+%26+%26+%26+%26+0+%26+%26+%26+%26+%5C%5C+%26+%26+%26+%26+%26+%5Cddots+%26+%26+%26+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \begin{array}{ccccccccccc} 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; \dots\\ &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots\\ &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots &amp; &amp; \\ &amp; &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots &amp; &amp; &amp;\\ &amp; &amp; &amp; &amp; 0 &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \ddots &amp; &amp; &amp; \end{array} "/></p>
<p>The diagonal now holds the powers of <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>. It thus follows that <img alt="{0^0 = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%5E0+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0^0 = 1}"/>.</p>
<p/><h2> Open Problems </h2><p/>
<p>What are your favorite mathematical jokes? Please send them to us. Be safe. Be well.</p>
<p><a href="https://rjlipton.wordpress.com/2020/04/26/time-for-some-jokes/sign-2/" rel="attachment wp-att-16987"><img alt="" class="aligncenter size-medium wp-image-16987" height="111" src="https://rjlipton.files.wordpress.com/2020/04/sign-1.png?w=300&amp;h=111" width="300"/></a></p>
<p>
[fixed equations in last main section]</p></font></font></div>
    </content>
    <updated>2020-04-27T00:37:51Z</updated>
    <published>2020-04-27T00:37:51Z</published>
    <category term="Oldies"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="jokes"/>
    <category term="math jokes"/>
    <category term="stories"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>GÃ¶delâs Lost Letter and P=NP</title>
      <updated>2020-04-29T23:20:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-32902056.post-3346245643417184590</id>
    <link href="http://paulwgoldberg.blogspot.com/feeds/3346245643417184590/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=32902056&amp;postID=3346245643417184590" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/32902056/posts/default/3346245643417184590" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/32902056/posts/default/3346245643417184590" rel="self" type="application/atom+xml"/>
    <link href="http://paulwgoldberg.blogspot.com/2020/04/surge-pricing-anyone.html" rel="alternate" type="text/html"/>
    <title>Surge pricing, anyone?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div dir="ltr" style="text-align: left;">One social contribution that I tentatively attribute to Uber is popularisation of the concept of surge pricing. That is, we try to call an Uber and all-too-frequently get told that we have to pay a premium at this particular point in time, due to high demand. On the other hand, recent shortages of toilet paper, paracetamol, and certain foods were not accompanied by any kind of surge pricing, and the limits imposed on how much stuff you can buy, were not so effective in keeping these goods available. At this point, things have improved, although I have not been able to buy flour recently: the shortage of flour in the supermarkets I visit seems to be chronic.<br/><br/>Now I appreciate the objection to charging to charging a premium to allcomers, rich and poor alike, in the context of vital food and medicine. (Although, limits on purchases can also be criticised as being unfair to a single purchaser buying for a large family, or a key worker who is short of time and doesn't want to search excessively for a desired item.) In trying to advocate surge pricing, let me turn instead to possible examples less controversial, such as hairdressers and garden centres. When these establishments are allowed to reopen, it seems reasonable that they should charge a premium (temporarily). Not only do they need the money, but it would help to control a flood of customers all causing long queues and infecting each other at close quarters. To be honest, Iâm not optimistic that this will happen, since they will still worry about accusations of price-gouging, plus thereâs the question of how big a premium is appropriate.<br/><br/><a href="https://www.economist.com/britain/2020/04/25/the-impossibility-of-measuring-inflation-in-a-pandemic">An article in the Economist</a> highlights a related problem, which is the difficulty of measuring the rate of inflation, at a time when various goods and services (whose prices get used to measure inflation) are unavailable. Coming back to flour, it may be felt that some of it (not all!) should be sold at market price, meaning one that some people will pay, but where it stays on the shelves for a few days, at least. There is a moral case against selling goods too cheaply, which is that it becomes an attempt to hide a problem â a successful attempt, if inflation cannot be measured.<br/><br/>Finally, the problem discussed here touches on a defect at the heart of traditional economic theory, which is the <a href="https://en.wikipedia.org/wiki/Arrow%E2%80%93Debreu_model">celebrated existence</a> of âcorrectâ prices, unaccompanied by a means of arriving at those prices. The Algorithmic Game Theory community has quite rightly worried about price discovery and its computational obstacles. But the obstacles are also social, and status quo bias plays a big part.</div></div>
    </content>
    <updated>2020-04-26T14:43:00Z</updated>
    <published>2020-04-26T14:43:00Z</published>
    <category scheme="http://www.blogger.com/atom/ns#" term="aggregator"/>
    <category scheme="http://www.blogger.com/atom/ns#" term="economics"/>
    <author>
      <name>Paul Goldberg</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/10952445127830395305</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-32902056</id>
      <category term="aggregator"/>
      <category term="UK academia"/>
      <category term="politics"/>
      <category term="meetings"/>
      <category term="research"/>
      <category term="research directions"/>
      <category term="conferences"/>
      <category term="funding"/>
      <category term="economics"/>
      <category term="people"/>
      <category term="rant"/>
      <category term="academia"/>
      <category term="forecasts"/>
      <category term="internet"/>
      <category term="advertisement"/>
      <category term="game theory"/>
      <category term="trips"/>
      <category term="University of Liverpool"/>
      <category term="editorial"/>
      <category term="technical"/>
      <category term="times higher"/>
      <category term="announcements"/>
      <category term="publications"/>
      <category term="teaching"/>
      <category term="work"/>
      <category term="postgraduate research"/>
      <category term="technology"/>
      <category term="books"/>
      <category term="social choice"/>
      <category term="talks"/>
      <category term="CACM"/>
      <category term="games"/>
      <category term="liverpool"/>
      <category term="open problems"/>
      <category term="problems"/>
      <category term="research assessment"/>
      <category term="tongue in cheek"/>
      <category term="administration"/>
      <category term="architecture"/>
      <category term="email"/>
      <category term="environment"/>
      <category term="higher education"/>
      <category term="mechanism design"/>
      <category term="puzzles"/>
      <category term="web sites"/>
      <category term="URLs"/>
      <category term="USS"/>
      <category term="education"/>
      <category term="oxford"/>
      <category term="schools"/>
      <category term="UCU"/>
      <category term="UK"/>
      <category term="go"/>
      <category term="intellectual property"/>
      <category term="jobs"/>
      <category term="league table"/>
      <category term="math education"/>
      <category term="money"/>
      <category term="products"/>
      <category term="science"/>
      <category term="students"/>
      <category term="Liberal democrats"/>
      <category term="XJTLU"/>
      <category term="behavioural economics"/>
      <category term="china"/>
      <category term="current affairs"/>
      <category term="diversity"/>
      <category term="epsrc"/>
      <category term="family"/>
      <category term="geography"/>
      <category term="holidays"/>
      <category term="joke"/>
      <category term="misc"/>
      <category term="nerd humour"/>
      <category term="pensions"/>
      <category term="predictions"/>
      <category term="proposals"/>
      <category term="psephology"/>
      <category term="region"/>
      <category term="student finance"/>
      <category term="visits"/>
      <category term="warwick"/>
      <category term="web"/>
      <category term="weekends"/>
      <category term="wikipedia"/>
      <category term="writing"/>
      <author>
        <name>Paul Goldberg</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/10952445127830395305</uri>
      </author>
      <link href="http://paulwgoldberg.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/32902056/posts/default/-/aggregator" rel="self" type="application/atom+xml"/>
      <link href="http://paulwgoldberg.blogspot.com/search/label/aggregator" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/32902056/posts/default/-/aggregator/-/aggregator?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>theoretical computer science, economics, and academic life in general. Writing in personal capacity, not representing my employer or other colleagues</subtitle>
      <title>Paul Goldberg</title>
      <updated>2020-04-26T14:43:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-21129445.post-1422354062966011246</id>
    <link href="http://mysliceofpizza.blogspot.com/feeds/1422354062966011246/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=21129445&amp;postID=1422354062966011246" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/21129445/posts/default/1422354062966011246" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/21129445/posts/default/1422354062966011246" rel="self" type="application/atom+xml"/>
    <link href="http://mysliceofpizza.blogspot.com/2020/04/john-conway.html" rel="alternate" type="text/html"/>
    <title>John Conway</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div dir="ltr" style="text-align: left;">I managed to join a zoom meeting yesterday to honor John Conway. Peter Winkler paid tribute with a story about the brick-stacking puzzle (was interesting to hear "skintle" in context of puzzles). Roger Penrose paid tribute with tilings but also an old classic,Â  Morley's Trisector Theorem. Others like Don Knuth appeared in the pre-meeting chat room, but I could not stay for the entire 3 hrs+ homage. Thanks to everyone!Â  JHC, RIP.Â  I was reminded that we are the math, friends and puzzles we leave behind.<br/><br/>Friends Ada and Phillip have created a short hardware tribute to JHC, video embedded below. <a href="https://blog.adafruit.com/category/adafruitchronicles/" target="_blank">Ada and Phillip,</a> thanks for repurposing your NYC manufacturing line to produce face shields and PPEs.Â  Loved the <a href="https://blog.adafruit.com/2020/04/27/the-woman-who-discovered-the-first-coronavirus/" target="_blank">blog on the scientist who discovered the first coronavirus</a>Â and the handsanitizer made in Detroit.<br/><br/><div class="separator" style="clear: both; text-align: center;"/><br/></div></div>
    </content>
    <updated>2020-04-26T14:11:00Z</updated>
    <published>2020-04-26T14:11:00Z</published>
    <category scheme="http://www.blogger.com/atom/ns#" term="aggregator"/>
    <author>
      <name>metoo</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/07192519900962182610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-21129445</id>
      <category term="aggregator"/>
      <category term="Non-CS"/>
      <author>
        <name>metoo</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/07192519900962182610</uri>
      </author>
      <link href="http://mysliceofpizza.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/21129445/posts/default/-/aggregator" rel="self" type="application/atom+xml"/>
      <link href="http://mysliceofpizza.blogspot.com/search/label/aggregator" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/21129445/posts/default/-/aggregator/-/aggregator?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>books, stories, poems, algorithms, math and computer science. 

some art and anecdotes too.</subtitle>
      <title>my slice of pizza</title>
      <updated>2020-04-27T15:43:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/057</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/057" rel="alternate" type="text/html"/>
    <title>TR20-057 |  Polynomial Data Structure Lower Bounds in the Group Model | 

	Omri Weinstein, 

	Gleb Posobin, 

	Oded Regev, 

	Alexander Golovnev</title>
    <summary>Proving super-logarithmic data structure lower bounds in the static \emph{group model} has been a fundamental challenge in computational geometry since the early 80's. We prove a polynomial ($n^{\Omega(1)}$) lower bound for an explicit range counting problem of $n^3$ convex polygons in $\R^2$ (each with $n^{\tilde{O}(1)}$ facets/semialgebraic-complexity), against linear storage arithmetic data structures in the group model. Our construction and analysis are based on a combination of techniques in Diophantine approximation, pseudorandomness, and compressed sensing---in particular, on the existence and partial derandomization of optimal \emph{binary} compressed sensing matrices in the polynomial sparsity regime ($k = n^{1-\delta}$). As a byproduct, this establishes a (logarithmic) separation between compressed sensing matrices and the stronger RIP property.</summary>
    <updated>2020-04-26T11:44:42Z</updated>
    <published>2020-04-26T11:44:42Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-29T23:20:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/056</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/056" rel="alternate" type="text/html"/>
    <title>TR20-056 |  Catalytic Approaches to the Tree Evaluation Problem | 

	Ian Mertz, 

	James  Cook</title>
    <summary>The study of branching programs for the Tree Evaluation Problem, introduced by S. Cook et al. (TOCT 2012), remains one of the most promising approaches to separating L from P. Given a label in $[k]$ at each leaf of a complete binary tree and an explicit function  in $[k]^2 \to [k]$ for recursively computing the value of each internal node from its children, the problem is to compute the value at the root node. The problem is parameterized by the alphabet size $k$ and the height $h$ of the tree. A branching program implementing the straightforward recursive algorithm uses $\Theta((k + 1)^h)$ states, organized into $2^h-1$ layers of width up to $k^h$. Until now no better deterministic algorithm was known.

We present a series of three new algorithms solving the Tree Evaluation Problem. They are inspired by the work of Buhrman et al. on catalytic space (STOC 2012), applied outside the catalytic-space setting. First we give a novel branching program with $2^{4h} poly(k)$ layers of width $2^{3k}$, which beats the straightforward algorithm when $h = \omega(k / \log k)$. Next we give a branching program with $k^{2h} poly(k)$ layers of width $k^3$.  This has total size comparable to the straightforward algorithm, but is implemented using the catalytic framework. Finally we interpolate between the two algorithms to give a branching program with $(O(k/h))^{2h} poly(k)$ layers of width $(O(k/h))^{\epsilon h}$ for any constant $\epsilon &gt; 0$, which beats the straightforward algorithm for all $h \geq k^{1/2 + poly(\epsilon)}$. These are the first deterministic branching programs to beat the straightforward algorithm, but more importantly this is the first non-trivial approach to proving deterministic upper bounds for Tree Evaluation.

We also contribute new machinery to the catalytic computing program, which may be of independent interest to some readers.</summary>
    <updated>2020-04-26T06:11:13Z</updated>
    <published>2020-04-26T06:11:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-29T23:20:22Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2020/04/24/ExpLR1/</id>
    <link href="http://offconvex.github.io/2020/04/24/ExpLR1/" rel="alternate" type="text/html"/>
    <title>Exponential Learning Rate Schedules for Deep Learning (Part 1)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This blog post concerns our <a href="https://arxiv.org/pdf/1910.07454.pdf">ICLR20 paper</a> on a surprising discovery about learning rate (LR), the most basic hyperparameter in deep learning.</p>

<p>As illustrated in many online blogs, setting LR too small  might slow down the optimization, and setting it too large  might make the network overshoot the area of low losses. The standard mathematical analysis for  the right choice of LR relates it to <a href="https://en.wikipedia.org/wiki/Smoothness">smoothness</a> of the loss function.</p>

<p>Many practitioners use a âstep decayâ LR schedule, which systematically drops the LR after specific training epochs. One often hears the intuitionâwith some mathematical justification if one treats SGD as a random walk in the  loss landscapeâ that large learning rates are useful in the initial (âexplorationâ) phase of training whereas lower rates  in later epochs allow a slow settling down to a local minimum in the landscape. Intriguingly, this intuition is called into  question by the success of exotic learning rate schedules such as <a href="https://arxiv.org/abs/1608.03983">cosine</a> (Loshchilov&amp;Hutter, 2016), and <a href="https://arxiv.org/abs/1506.01186">triangular</a> (Smith, 2015), featuring an oscillatory LR.  These divergent approaches suggest that LR, the most basic and intuitive hyperparameter in deep learning, has not revealed all its mysteries yet.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/lr_schedules.png" style="width: 450px;"/>
<br/>
<b>Figure 1.</b> Examples of Step Decay, Triangular and Cosine LR schedules.
</div>
<p><br/></p>

<h1 id="surprise-exponentially-increasing-lr">Surprise: Exponentially increasing LR</h1>

<p>We report experiments that state-of-the-art networks for image recognition tasks can be trained with an exponentially increasing LR (ExpLR): in each iteration it increases by $(1+\alpha)$ for some $\alpha &gt; 0$.  (The $\alpha$ can be varied over epochs.) Here $\alpha$ is not too small in our experiments, so as you would imagine, the LR hits astronomical values in no time.  To the best of our knowledge, this is the first time such a rate schedule has been successfully used, let alone for highly successful architectures. In fact, as we will see below, the reason we even did this bizarre experiment  was that we already had a mathematical proof that it would work. Specifically, we could show that such ExpLR schedules are at least as powerful as the standard step-decay ones, by which we mean that ExpLR can let us achieve (in function space) all the nets obtainable via the currently popular step-decay schedules.</p>

<h2 id="so-why-does-this-work">So why does this work?</h2>

<p>One key property of state-of-the-art nets we rely on is that they all use some normalization of parameters within layers, usually Batch Norm (BN), which has been shown to give benefits in optimization and generalization across architectures. Our result also holds for other normalizations, including Group Normalization (Wu &amp; He, 2018), Layer Normalization (Ba et al., 2016), Instance Norm (Ulyanov et al., 2016), etc.</p>

<p>The second key property of current training is that they use weight decay (aka $\ell_2$ regularizer). When combined with BN, this implies strange dynamics in parameter space, and the experimental papers (<a href="https://arxiv.org/abs/1706.05350">van Laarhoven, 2017</a>, <a href="https://arxiv.org/abs/1803.01814">Hoffer et al., 2018a</a> and <a href="https://openreview.net/forum?id=B1lz-3Rct7">Zhang et al., 2019</a>),  noticed that combining BN and weight decay can  be viewed as increasing the LR.</p>

<p>Our paper gives a rigorous proof of the power of ExpLR by showing the following about the end-to-end function  being computed (see Main Thm in the paper):</p>

<blockquote>
  <p>(Informal Theorem) For commonly  used values of the paremeters, every net produced by <em>Weight Decay + Constant LR + BN + Momentum</em> can also be produced (in function space) via <em>ExpLR + BN + Momentum</em></p>
</blockquote>

<p>*NB: If the LR is not fixed but decaying in discrete steps, then the equivalent ExpLR training decays the exponent. (See our paper for details.)</p>

<p>At first sight such a claim may seem difficult (if not impossible) to prove given that we lack any mathematical characterization of nets produced by training (note that the theorem makes no mention of the dataset!).  The  equivalence is shown by reasoning about <em>trajectory</em> of optimization, instead of the usual âlandscape viewâ of stationary points, gradient norms, Hessian norms, smoothness, etc.. This is an example of the importance of trajectory analysis, as argued in <a href="http://www.offconvex.org/2019/06/03/trajectories/">earlier blog post of Sanjeevâs</a> because optimization and generalization are deeply intertwined for deep learning. Conventional wisdom says LR controls optimization, and the regularizer controls generalization. Our result shows that the effect of weight decay can  under fairly normal conditions be * exactly*  realized by the ExpLR rate schedule.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/exp_lr.png" style="width: 550px;"/>
</div>
<p><strong>Figure 2.</strong> Training PreResNet32 on CIFAR10 with fixed LR $0.1$, momentum $0.9$ and other standard hyperparameters. Trajectory was unchanged when WD was turned off  and LR at iteration $t$ was $\tilde{\eta}_ t = 0.1\times1.481^t$. (The constant $1.481$ is predicted by our theory given the original hyperparameters.) Plot on right shows  weight norm $\pmb{w}$ of the first convolutional layer in the second residual block. It grows exponentially as one would expect, satisfying $|\pmb{w}_ t|_ 2^2/\tilde{\eta}_ t = $ constant.</p>

<p><a href="http://www.offconvex.org/feed.xml# (We first want to clarify that the exponential LR schedules work for normalized networks only and will lead parameter and output explosion for networks without normalization. )">comment</a>:# (In the rest of the post, we will first explain how does this equivalence result arises from various types of normalization schemes and then sketch the proof. We will also present a more general exponential growing learning schedule called â'âTapered Exponential Learning Rate Scheduleâ, or TEXP, which is both experimentally and theoretically equivalent to the standard Step Decay schedule + Weight Decay. )</p>

<h2 id="scale-invariance-and-equivalence">Scale Invariance and Equivalence</h2>

<p>The formal proof holds for any training loss satisfying 
what we call <em>Scale Invariance</em>:</p>



<p>BN and other normalization schemes result in a Scale-Invariant Loss for the popular deep architectures (Convnet, Resnet, DenseNet etc.) if the output layer âwhere normally no normalization is usedâ is fixed throughout training. Empirically, <a href="https://openreview.net/forum?id=S1Dh8Tg0-">Hoffer et al. (2018b)</a>  found that randomly fixing the output layer at the start does not harm the final accuracy. 
(Appendix C of our paper demonstrates scale invariance for  various architectures; it is somewhat nontrivial.)</p>

<p>For batch ${\mathcal{B}} = \{ x_ i \} _ {i=1}^B$, network parameter ${\pmb{\theta}}$, we  denote the network by $f_ {\pmb{\theta}}$ and the loss function at iteration $t$ by $L_ t(f_ {\pmb{\theta}}) = L(f_ {\pmb{\theta}}, {\mathcal{B}}_ t)$ . We also use $L_ t({\pmb{\theta}})$ for convenience. We say the network $f_ {\pmb{\theta}}$ is <em>scale invariant</em> if $\forall c&gt;0$, $f_ {c{\pmb{\theta}}} = f_ {\pmb{\theta}}$, which implies the loss $L_ t$ is also scale invariant, i.e., $L_  t(c{\pmb{\theta}}_ t)=L_ t({\pmb{\theta}}_ t)$, $\forall c&gt;0$. A key source of intuition is the following lemma provable via chain rule:</p>

<blockquote>
  <p><strong>Lemma 1</strong>. A scale-invariant loss $L$ satisfies
(1). $\langle\nabla_ {\pmb{\theta}} L, {\pmb{\theta}} \rangle=0$ ;<br/>
(2). $\left.\nabla_ {\pmb{\theta}} L \right|_ {\pmb{\theta} = \pmb{\theta}_ 0} = c \left.\nabla_ {\pmb{\theta}} L\right|_  {\pmb{\theta} = c\pmb{\theta}_ 0}$, for any $c&gt;0$.</p>
</blockquote>

<p>The first property immediately implies that $|{\pmb{\theta}}_ t|$ is monotone increasing for SGD if WD is turned off by Pythagoren Theorem. And based on this, <a href="https://arxiv.org/pdf/1812.03981.pdf">our previous work</a> with Kaifeng Lyu shows that GD with any fixed learning rate can reach $\varepsilon$ approximate stationary point for scale invariant objectives in $O(1/\varepsilon^2)$ iterations.</p>
<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/inv_lemma.png" style="width: 360px;"/>
<br/>
<b>Figure 3.</b> Illustration of Lemma 1. 
</div>
<p><br/></p>

<p>Below is the main result of the paper. We will explain the proof idea (using scale-invariance) in a later post.</p>
<blockquote>
  <p><strong>Theorem 1(Main, Informal).</strong> SGD on a scale-invariant objective with initial learning rate $\eta$, weight decay factor $\lambda$, and momentum factor $\gamma$ is equivalent to SGD with momentum factor $\gamma$ where at iteration $t$, the ExpLR $\tilde{\eta}_ t$  is defined as $\tilde{\eta}_ t = \alpha^{-2t-1} \eta$ without weight decay($\tilde{\lambda} = 0$) where $\alpha$ is a non-zero root of equation 
     </p>
</blockquote>

<blockquote>
  <p>Specifically, when momentum $\gamma=0$,  the above schedule can be simplified as $\tilde{\eta}_ t = (1-\lambda\eta)^{-2t-1} \eta$.</p>
</blockquote>

<h3 id="sota-performance-with-exponential-lr">SOTA performance with exponential LR</h3>

<p>As mentioned, reaching state-of-the-art accuracy  requires reducing the learning rate a few times. Suppose the training has $K$ phases, and the learning rate is divided by some constant $C_I&gt;1$ when entering phase $I$. To realize the same effect with an exponentially increasing LR, we have:</p>

<blockquote>
  <p><strong>Theorem 2:</strong> ExpLR with the below modification generates the same network sequence as Step Decay with momentum factor $\gamma$ and WD $\lambda$ does. We call it <em>Tapered Exponential LR schedule</em> (TEXP).<br/>
<strong>Modification when entering a new phase $I$</strong>: (1). switching to some smaller exponential growing rate; (2). divinding the current LR by $C_I$.</p>
</blockquote>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/texp_lr.png" style="width: 235px;"/>
<img src="http://www.offconvex.org/assets/TEXP.png" style="width: 500px;"/>
</div>
<p><strong>Figure 5.</strong> PreResNet32 trained with Step Decay (as in Figure 1) and its corresponding TEXP schedule. As predicted by Theorem 2, they have similar trajectories and performances.</p>

<h2 id="conclusion">Conclusion</h2>

<p>We hope that this bit of theory and supporting experiments have changed your outlook on learning rates for deep learning.</p>

<p>A follow-up post will present the proof idea and give more insight into why ExpLR suggests a rethinking of the âlandscape viewâ of optimization in deep learning.</p></div>
    </summary>
    <updated>2020-04-24T10:00:00Z</updated>
    <published>2020-04-24T10:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2020-04-29T22:39:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4772</id>
    <link href="https://www.scottaaronson.com/blog/?p=4772" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4772#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4772" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Martinis, The Plot Against America, Kill Chain</title>
    <summary xml:lang="en-US">As if we didnât have enough to worry us, this week brought the sad news that John Martinis, who for five years was the leader and public face of Googleâs experimental quantum computing effort, has quit Google and returned to his earlier post at UC Santa Barbara. Iâve spoken about what happened both with John [â¦]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>As if we didnât have enough to worry us, this week brought the <a href="https://www.wired.com/story/googles-head-quantum-computing-hardware-resigns/">sad news</a> that John Martinis, who for five years was the leader and public face of Googleâs experimental quantum computing effort, has quit Google and returned to his earlier post at UC Santa Barbara.  Iâve spoken about what happened both with John and with Hartmut Neven, the head of Googleâs Quantum AI Lab.  Without betraying confidences, or asserting anything that either side would disagree with, I think I can say that it came down to a difference in management philosophies.  Google tends to be consensus-driven, whereas John is of the view that building a million-qubit, error-corrected quantum computer will take more decisive leadership.  I can add: Iâd often wondered how John had time to travel the world, giving talks about quantum supremacy, while also managing the labâs decisions on a day-to-day basis.  It looks now like I was right to wonder!  Potential analogies flood the mind: is this like a rock band that breaks up right after its breakout hit?  Is it like Steve Jobs leaving Apple?  Anyway, I wish the Google team the best in Johnâs absence, and I also wish John the best with whatever he does next.</p>



<p>I was never big on HBO (e.g., I still havenât seen a single minute of <em>Game of Thrones</em>), but in the last couple of weeks, Dana and I found ourselves watching two absolutely compelling HBO showsâone a fictional miniseries and the other a documentary, but both on the theme of the fragility of American democracy.</p>



<p><a href="https://www.hbo.com/the-plot-against-america"><em>The Plot Against America</em></a>, based on the <a href="https://en.wikipedia.org/wiki/The_Plot_Against_America">2004 Philip Roth novel</a> of the same name (which Dana read and which I now plan to read), is about an alternate history where the aviator Charles Lindbergh defeats FDR in the 1940 presidential election, on a fascist and isolationist platform, in events thatâas countless people have pointed outâare eerily, terrifyingly prescient of what would actualy befall the US in 2016.  The series follows a Jewish insurance salesman and his family in Newark, NJâisnât that what it always is with Philip Roth?âas they try to cope with the countryâs gradual, all-too-plausible slide downward, from the genteel antisemitism that already existed in <em>our</em> timelineâs 1940 all the way to riots, assassinations, and pogroms (although never to an American Holocaust).  One of the seriesâ final images is of paper ballots, in a rematch presidential election, being carted away and burned, underscoring just how much depends here on the mundane machinery of democracy.</p>



<p>Which brings me to <a href="https://www.hbo.com/documentaries/kill-chain-the-cyber-war-on-americas-elections"><em>Kill Chain: The Cyber War on Americaâs Elections</em></a>, a documentary about the jaw-droppingly hackable electronic voting machines used in US elections and the fight to do something about them.  The show mostly follows the journey of <a href="https://en.wikipedia.org/wiki/Harri_Hursti">Harri Hursti</a>, a Finnish-born programmer whoâs made this issue his lifeâs work, but it also extensively features my childhood best friend <a href="https://en.wikipedia.org/wiki/Alex_Halderman">Alex Halderman</a>.  OK, but isnât this a theoretical issue, one that (perhaps rightly) exercises security nerds like Alex, but surely hasnât changed the outcomes of actual elections?</p>



<p>Yeah, so about that.  You know Brian Kemp, the doofus governor of Georgia, whoâs infamously announced plans to reopen the state right away, ignoring the pleading of public health expertsâa  act that will fill Georgiaâs ICUs and morgues as surely as night follows day?  And you know how Kemp defeated the Democrat, Stacey Abrams, by a razor-thin margin, in a 2018 election of which Kemp himself was the overseer?  It turns out that Kempâs office distributed defective memory cards to African-American and Democratic precincts, though not to white and Republican ones.  Thereâs also striking statistical evidence that at least some voting machines were hacked, although because there was no paper trail it can never be proved.</p>



<p>In short, what <em>The Plot Against America</em> and <em>Kill Chain</em> have in common is that they <em>would be</em> desperately needed warnings about the ease with which democracy could collapse in the US, except for the detail that much of what they warn about has already happened, and now itâs not clear how we get back.</p></div>
    </content>
    <updated>2020-04-23T18:00:30Z</updated>
    <published>2020-04-23T18:00:30Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-04-23T18:03:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=426</id>
    <link href="https://tcsplus.wordpress.com/2020/04/23/tcs-talk-wednesday-april-29-sepideh-mahabadi-ttic/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, April 29 â Sepideh Mahabadi, TTIC</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, April 29th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Sepideh Mahabadi from TTIC will speak about âNon-Adaptive Adaptive Sampling in Turnstile Streamsâ (abstract below). You can reserve a spot as an individual or a group to join [â¦]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, April 29th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Sepideh Mahabadi</strong> from TTIC will speak about â<em>Non-Adaptive Adaptive Sampling in Turnstile Streams</em>â (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a>the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a>on our website</a> on the day of the talk, so people who did not sign up will still be able to watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a>suggest</a> a possible topic or speaker, please see <a>the website</a>.</p>
<blockquote><p>Abstract: Adaptive sampling is a useful algorithmic tool for data summarization problems in the classical centralized setting, where the entire dataset is available to the single processor performing the computation. Adaptive sampling repeatedly selects rows of an underlying <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0" title="n"/> by <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=fff&amp;fg=444444&amp;s=0" title="d"/> matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=fff&amp;fg=444444&amp;s=0" title="A"/>, where <img alt="n \gg d" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cgg+d&amp;bg=fff&amp;fg=444444&amp;s=0" title="n \gg d"/>, with probabilities proportional to their distances to the subspace of the previously selected rows. Intuitively, adaptive sampling seems to be limited to trivial multi-pass algorithms in the streaming model of computation due to its inherently sequential nature of assigning sampling probabilities to each row only after the previous iteration is completed. Surprisingly, we show this is not the case by giving the first one-pass algorithms for adaptive sampling on turnstile streams and using space <img alt="\text{poly}(d,k,\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bpoly%7D%28d%2Ck%2C%5Clog+n%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\text{poly}(d,k,\log n)"/>, where <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0" title="k"/> is the number of adaptive sampling rounds to be performed.</p>
<p>Our adaptive sampling procedure has a number of applications to various data summarization problems on turnstile streams that either improve state-of-the-art or have only been previously studied in the more relaxed row-arrival model. This includes column subset selection, subspace approximation, projective clustering, and volume maximization. We complement our volume maximization algorithmic results with lower bounds that are tight up to lower order terms, even for multi-pass algorithms. By a similar construction, we also obtain lower bounds for volume maximization in the row-arrival model, which we match with competitive upper bounds.</p>
<p>This is a joint work with Ilya Razenshteyn, David Woodruff, and Samson Zhou.</p></blockquote></div>
    </content>
    <updated>2020-04-23T16:59:09Z</updated>
    <published>2020-04-23T16:59:09Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-04-29T23:21:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/055</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/055" rel="alternate" type="text/html"/>
    <title>TR20-055 |  Bounded Collusion Protocols, Cylinder-Intersection Extractors and Leakage-Resilient Secret Sharing | 

	Ashutosh Kumar, 

	Raghu Meka, 

	David Zuckerman</title>
    <summary>In this work we study bounded collusion protocols (BCPs) recently introduced in the context of secret sharing by Kumar, Meka, and Sahai (FOCS 2019). These are multi-party communication protocols on $n$ parties where in each round a subset of $p$-parties (the collusion bound) collude together and write a function of their inputs on a public blackboard. 

BCPs interpolate elegantly between the well-studied number-in-hand (NIH) model ($p=1$) and the number-on-forehead (NOF) model ($p=n-1$). Motivated by questions in communication complexity, secret sharing, and pseudorandomness we investigate BCPs more thoroughly answering several questions about them. 

* We prove a polynomial (in the input-length) lower bound for an explicit function against BCPs where any constant fraction of players can collude. Previously, non-trivial lower bounds were only known when the collusion bound was at most logarithmic in the input-length (owing to bottlenecks in NOF lower bounds). 

* For all $t \leq n$, we construct efficient $t$-out-of-$n$ secret sharing schemes where the secret remains hidden even given the transcript of a BCP with collusion bound $O(t/\log t)$. Prior work could only handle collusions of size $O(\log n)$. Along the way, we construct leakage-resilient schemes against disjoint and adaptive leakage,  resolving a question asked by Goyal and Kumar (STOC 2018).

* An explicit $n$-source cylinder intersection extractor whose output is close to uniform even when given the transcript of a BCP with a constant fraction of parties colluding. The min-entropy rate we require is $0.3$ (independent of collusion bound $p \ll n$). 

Our results rely on a new class of exponential sums that interpolate between the ones considered in additive combinatorics by Bourgain (Geometric and Functional Analysis 2009) and Petridis and Shparlinski (Journal d'Analyse MathÃ©matique 2019).</summary>
    <updated>2020-04-23T09:54:31Z</updated>
    <published>2020-04-23T09:54:31Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-29T23:20:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/054</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/054" rel="alternate" type="text/html"/>
    <title>TR20-054 |  Communication Complexity with Defective Randomness  | 

	Marshall Ball, 

	Oded Goldreich, 

	Tal Malkin</title>
    <summary>Starting with the two standard model of randomized communication complexity, we study the communication complexity of functions when the protocol has access to a defective source of randomness. 
Specifically, we consider both the public-randomness and private-randomness cases, while replacing the commonly postulated perfect randomness with distributions over $\ell$ bit strings that have min-entropy at least $k\leq\ell$. 
We present general upper and lower bounds on the communication complexity in these cases, where the bounds are typically linear in $\ell-k$ and also depend on the size of the fooling set for the function being computed and on its standard randomized complexity.</summary>
    <updated>2020-04-22T19:02:32Z</updated>
    <published>2020-04-22T19:02:32Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-29T23:20:22Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8100403263538580223</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8100403263538580223/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/complexity-vidcast-future-edition.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8100403263538580223" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8100403263538580223" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/complexity-vidcast-future-edition.html" rel="alternate" type="text/html"/>
    <title>Complexity Vidcast - Future Edition</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Bill and Lance aim to <a href="https://www.youtube.com/watch?v=4G2cxVRe0X8">talk about the future</a> but can't escape the present.<br/>
<br/>
<br/></div>
    </content>
    <updated>2020-04-22T18:28:00Z</updated>
    <published>2020-04-22T18:28:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-04-29T17:05:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1650</id>
    <link href="https://theorydish.blog/2020/04/22/private-libraries/" rel="alternate" type="text/html"/>
    <title>Reading in Private</title>
    <summary>(This blog post is based on joint work with Dima Kogan.) One of the great unsung perks of being a college student is having access to the university library. There is something thrilling about hunting down exactly the right reference deep in the stacks, or reading through the archived papers of a public figure from years back. The pandemic has closed all of our libraries for the time being. Even so, through the fruits of computer scienceâdatabases, the Internet, e-readers, and so onâwe can get access to much of the same information even when we are cooped up at home. But for me, one of the true pleasures of using a library is the fact that I can browse through any book I want in complete privacy. If I want to go up to the stacks and read about tulip gardening, or road-bike maintenance, or strategies for managing anxiety, I can do that pretty much without anyone else knowing. In contrast, if I go online today and search for âtulip gardening,â Google will take careful note of my interest in tulips and I will be seeing ads about gardening tools for months. An ideal digital library would let us download [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i>(This blog post is based on joint work with </i><a href="https://cs.stanford.edu/~dkogan/"><i>Dima Kogan</i></a><i>.)</i></p>
<p>One of the great unsung perks of being a college student is having access to the university library. There is something thrilling about hunting down exactly the right reference deep in the stacks, or reading through the archived papers of a public figure from years back.</p>
<p>The pandemic has closed all of our libraries for the time being. Even so, through the fruits of computer scienceâdatabases, the Internet, e-readers, and so onâwe can get access to much of the same information even when we are cooped up at home.</p>
<p>But for me, one of the true pleasures of using a library is the fact that I can browse through any book I want in complete privacy. If I want to go up to the stacks and read about tulip gardening, or road-bike maintenance, or strategies for managing anxiety, I can do that pretty much without anyone else knowing.</p>
<p>In contrast, if I go online today and search for âtulip gardening,â Google will take careful note of my interest in tulips and I will be seeing ads about gardening tools for months.</p>
<p>An ideal digital library would let us download and read books without anyoneânot even the library itselfâlearning which books we are reading. How could we build such a privacy-respecting digital library?</p>
<p>In this post, we will discuss the private-library problem and how <a href="https://eprint.iacr.org/2019/1075">our recent work on private information retrieval</a> might be able to help solve it.</p>
<h3><b>The Private-Library Problem</b></h3>
<p>Let us define the problem a little more precisely. We will imagine a protocol running between a library, which holds the books, and a student, who wants to download a particular book.</p>
<p>Say that the library has <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/> booksâletâs call the books <img alt="x=(x_1, \dots, x_N)" class="latex" src="https://s0.wp.com/latex.php?latex=x%3D%28x_1%2C+%5Cdots%2C+x_N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x=(x_1, \dots, x_N)"/>. To keep things simple, letâs pretend that each book consists of just a single bit of information, so <img alt="x_i \in \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=x_i+%5Cin+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_i \in \{0,1\}"/> for all <img alt="i \in \{1, \dots, N\}" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i \in \{1, \dots, N\}"/>.</p>
<p>The student starts out holding the index <img alt="i \in \{1, \dots, N\}" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i \in \{1, \dots, N\}"/> of her desired book. To fetch the digital book from the library, the student and library exchange some messages. At the end of the interaction, we want the following two properties to hold:</p>
<ul>
<li><b>Correctness.</b> The student should have her desired book (i.e., the bit <img alt="x_i" class="latex" src="https://s0.wp.com/latex.php?latex=x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_i"/>).</li>
<li><b>Privacy. </b>The library should have not learned any information, in a cryptographic sense, about which book the student downloaded.</li>
</ul>
<p>Of course, we have grossly simplified the problem: a real book is more than a single bit in length, book titles are not consecutive integers, maybe the student would like to find a book using a keyword search, etc. But even this simplified private-information-retrieval problem, which <a href="http://www.tau.ac.il/~bchor/PIR.pdf">Chor, Goldreich, Kushilevitz, and Sudan introduced</a> in the 90s, is already interesting enough.</p>
<h3><b>A simple but inefficient solution</b></h3>
<p>There is a simple solution to this problem: the student can just ask the library to send her the contents of all <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/> books. This solution achieves both correctness and privacy, so whatâs the problem? Are we done?</p>
<p>Well, there are two problems:</p>
<ol>
<li>The amount of <b>communication</b> is large: Just to read a single book, the client must download the contents of the entire library! So this is terribly inefficient.</li>
<li>The amount of <b>computation</b> is large: Just to fetch a single book, the library must do work proportional to the size of the entire library. So âchecking outâ a book from this digital library will take a long time.</li>
</ol>
<p>Research on private information retrieval typically focuses on the first problem: how can we reduce the <i>communication</i> cost? Using a <a href="https://dl.acm.org/doi/abs/10.1145/2968443">variety</a> of <a href="https://ieeexplore.ieee.org/abstract/document/646125">clever</a> <a href="https://dl.acm.org/doi/abs/10.1145/2976749.2978429">techniques</a>, it is possible to drive down the communication cost to something very smallâsub-polynomial or even logarithmic in the library size <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/>.</p>
<p>But today we are interested in the <i>computational</i> burden on the library. Is there any way that the student can privately download a book from the library while requiring the library to do only <img alt="o(N)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="o(N)"/> work in the process?</p>
<h3><b>Doing the hard work in advance</b></h3>
<p>To have both correctness and privacy, it seems that the library needs to touch each of the <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/> books in the process of responding to each studentâs request. And, in some sense, <a href="http://groups.csail.mit.edu/cis/pubs/malkin/BIM.ps">this is true</a>. So, to allow the library to run in time sublinear in <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/>, we will have to tweak the problem slightly.</p>
<p>Our idea is to have the library do the <img alt="O(N)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(N)"/>-time computation in an <b>offline phase</b>, which takes place <i>before</i> the student decides which book she wants to read. For example, this offline phase might happen overnight while the libraryâs servers would otherwise be idle.</p>
<p>Later on, once the student decides which book in the library she wants to read, the student and library can run a <img alt="o(N)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="o(N)"/>-time <b>online phase</b> in which the student is able to retrieve her desired book. The total communication cost, in both offline and online phases, will be <img alt="o(N)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="o(N)"/>.</p>
<p>So, by pushing the libraryâs expensive linear scan to an offline phase, the library can service the studentâs request for a book in sublinear online time.</p>
<h3><b>Our offline/online private information retrieval scheme</b></h3>
<p>Letâs see how to construct such an offline/online scheme. To make things simple for the purposes of this post, letâs assume that the student has access to two non-colluding libraries that hold the same set of books. To be concrete, letâs call the two libraries âStanfordâ and âBerkeley.â</p>
<p>The privacy property will hold as long as the librarians at Stanford and Berkeley donât get together and share the information that they learned while running the protocol with the student. So Stanford and Berkeley here are ânon-colluding.â (Equivalently, our scheme that protects privacy against an adversary that controls one of the two librariesâbut not both.)</p>
<div class="wp-caption aligncenter" id="attachment_1670" style="width: 571px;"><img alt="Offline-online PIR" class=" wp-image-1670" height="365" src="https://theorydish.files.wordpress.com/2020/04/offlineonline.png?w=561&amp;h=365" width="561"/><p class="wp-caption-text" id="caption-attachment-1670">In the offline phase, which happens before the student knows which book she wants to read, the Stanford library does linear work. In the online phase, which runs once the student has the index of her desired book, the Berkeley library runs in sublinear time. (We are suppressing log factors here.)</p></div>
<p>Now, letâs describe an offline/online protocol by which the student can privately fetch a book from the digital library:</p>
<p><b>Offline Phase.</b></p>
<ul>
<li>The student partitions the integers <img alt="\{1, .., N\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C+..%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{1, .., N\}"/> into <img alt="\sqrt{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\sqrt{N}"/> non-overlapping sets chosen at random, where each set has size <img alt="\sqrt{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\sqrt{N}"/>. Call these sets <img alt="S_1, \dots, S_{\sqrt{N}}" class="latex" src="https://s0.wp.com/latex.php?latex=S_1%2C+%5Cdots%2C+S_%7B%5Csqrt%7BN%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_1, \dots, S_{\sqrt{N}}"/>.</li>
<li>The student sends these sets <img alt="S_1, \dots, S_{\sqrt{N}}" class="latex" src="https://s0.wp.com/latex.php?latex=S_1%2C+%5Cdots%2C+S_%7B%5Csqrt%7BN%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_1, \dots, S_{\sqrt{N}}"/> to Stanford (the first library). To reduce the communication cost here, the student can compress these sets using pseudorandomness.</li>
<li>For each set <img alt="S_j" class="latex" src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_j"/>, the Stanford library computes the <i>parity</i> of all of the books indexed by set <img alt="S_j" class="latex" src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_j"/> and returns the parity bits <img alt="(b_1, \dots, b_{\sqrt{N}})" class="latex" src="https://s0.wp.com/latex.php?latex=%28b_1%2C+%5Cdots%2C+b_%7B%5Csqrt%7BN%7D%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(b_1, \dots, b_{\sqrt{N}})"/> to the student. In other words, if the books are <img alt="x=(x_1, \dots, x_N) \in \{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%3D%28x_1%2C+%5Cdots%2C+x_N%29+%5Cin+%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x=(x_1, \dots, x_N) \in \{0,1\}^n"/>, then <img alt="b_j = \sum_{k \in S_j} x_k \bmod 2" class="latex" src="https://s0.wp.com/latex.php?latex=b_j+%3D+%5Csum_%7Bk+%5Cin+S_j%7D+x_k+%5Cbmod+2&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="b_j = \sum_{k \in S_j} x_k \bmod 2"/>.</li>
</ul>
<p>The total communication in this phase is only <img alt="O(\sqrt{N})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(\sqrt{N})"/> bits and the student and the Stanford library can run this step <i>before</i> the student decides which book she wants to read.</p>
<p><b>Online Phase.</b> Once the student decides that she wants to read book <img alt="i \in \{1, \dots, N\}" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i \in \{1, \dots, N\}"/>, the student and Berkeley (the second library) run the following steps:</p>
<ul>
<li>The student finds the set <img alt="S_j" class="latex" src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_j"/> that contains the index <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/> of her desired book.</li>
<li>The student flips a coin that is weighted to come up heads with some probability <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p"/>, to be fixed later.</li>
<li>If the coin lands <span style="text-decoration: underline;">heads</span>:
<ul>
<li>The student sends <img alt="S \gets S_j \setminus \{i\}" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Cgets+S_j+%5Csetminus+%5C%7Bi%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S \gets S_j \setminus \{i\}"/> to the Berkeley library.</li>
</ul>
</li>
<li>If the coin lands <span style="text-decoration: underline;">tails</span>:
<ul>
<li>The student samples <img alt="i' \gets_R S_j \setminus \{i\}" class="latex" src="https://s0.wp.com/latex.php?latex=i%27+%5Cgets_R+S_j+%5Csetminus+%5C%7Bi%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i' \gets_R S_j \setminus \{i\}"/>.</li>
<li>The student sends <img alt="S \gets S_j \setminus \{i'\}" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Cgets+S_j+%5Csetminus+%5C%7Bi%27%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S \gets S_j \setminus \{i'\}"/> to the Berkeley library.</li>
</ul>
</li>
<li>The Berkeley library receives the set <img alt="S \subseteq \{1, \dots, N\}" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Csubseteq+%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S \subseteq \{1, \dots, N\}"/> from the student. The Berkeley library returns the contents of all books whose indices appear in set <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S"/> to the student.</li>
<li>Now, the student can recover its desired book as follows:
<ul>
<li>If <span style="text-decoration: underline;">heads</span>: the student now has the parity of the books in <img alt="S_j" class="latex" src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_j"/> (from the offline phase) and the value of all books in <img alt="S_j" class="latex" src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_j"/> that are not book <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/>. This is enough to recover the contents of book <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/>.</li>
<li>If <span style="text-decoration: underline;">tails</span>: <img alt="i \in S" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+S&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i \in S"/>. In this case the Berkeley library has sent the contents of book <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/> to the student in the online phase.</li>
</ul>
</li>
</ul>
<p>Even before we fix the weight <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p"/> of the coin, we see that the protocol satisfies <b>correctness</b>, since no matter how the coin lands the client recovers its desired book. Also, the total communication cost is <img alt="O(\sqrt{N} \log N)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%7D+%5Clog+N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(\sqrt{N} \log N)"/> bits, which is sublinear as we had hoped. Finally, the <b>online computation cost</b> is also sublinear: the Berkeley library just needs to return <img alt="\sqrt{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\sqrt{N}"/> books to the client, which it can do in time roughly <img alt="O(\sqrt{N})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(\sqrt{N})"/>.</p>
<p>The last matter to address is <b>privacy</b>. Again, we are assuming that the adversary controls only one of the two libraries.</p>
<ul>
<li>In the offline phase, the studentâs message to the Stanford library is independent of <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/>, so the protocol is perfectly private with respect to Stanford.</li>
<li>In the online phase, we must be more careful. It turns out that if we choose the weight <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p"/> of the coin as <img alt="p = 1 - (\sqrt{N} - 1)/N" class="latex" src="https://s0.wp.com/latex.php?latex=p+%3D+1+-+%28%5Csqrt%7BN%7D+-+1%29%2FN&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p = 1 - (\sqrt{N} - 1)/N"/>, then the set <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S"/> that the student sends to UC Berkeley in the online phase is just a uniformly random size-<img alt="(\sqrt{N}-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Csqrt%7BN%7D-1%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(\sqrt{N}-1)"/> subset of <img alt="\{1, \dots, N\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{1, \dots, N\}"/>.</li>
</ul>
<h3><b>Open problems</b></h3>
<p>So, the student can privately fetch a book from our digital libraries in sublinear online time. What else is left to do?</p>
<ul>
<li>Getting rid of the need for two non-colluding libraries is a clear next step. <a href="https://eprint.iacr.org/2019/1075">Our work</a> has some results along these lines, but they pay a price either in (a) asymptotic efficiency or in (b) the strength of the cryptographic assumptions required.</li>
<li>A beautiful paper of <a href="https://www.cs.bgu.ac.il/~beimel/Papers/BIM.pdf">Beimel, Ishai, and Malkin</a> shows that if the library can store its collection of books using a special type of error-correcting encoding, the <b>total</b> computational time at the libraries (not just the online time) can be sublinear in <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/>. As far as we know, these schemes are not concretely efficient enough to use in practice. Could they be made so?</li>
<li>Privacy is just one of the many pleasures of using a physical library. During this period of confinement, I also miss the smell of the books, the beauty of light filtering through the stacks, and the peacefulness of thinking in a study carrel. Can a digital library ever give us these things too?</li>
</ul>
<p>If any of these questions catch your fancy, please check out <a href="https://eprint.iacr.org/2019/1075">our Eurocrypt paper</a> for more background, pointers, and results.</p>
<p>Don Knuth <a href="http://jmlr.csail.mit.edu/reviewing-papers/knuth_mathematical_writing.pdf">has reportedly said</a> âUsing a great library to solve a specific problemâ¦ Now <i>that</i> [â¦] is real living.â With better digital libraries, maybe we could all live a little bit more during these challenging days.</p></div>
    </content>
    <updated>2020-04-22T07:07:04Z</updated>
    <published>2020-04-22T07:07:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Henry Corrigan-Gibbs</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-04-29T23:21:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3472</id>
    <link href="https://agtb.wordpress.com/2020/04/21/ec-2020-will-be-virtual/" rel="alternate" type="text/html"/>
    <title>SIGecom Announcement: EC 2020 will be virtual</title>
    <summary>As many of you have probably anticipated, due to concerns regarding the novel coronavirus COVID-19, the 2020 ACM Conference on Economics and Computation (EC 2020) will be held virtually. This change of format will of course present us with difficult challenges, but we believe it will offer exciting new opportunities as well. Â (And not to [â¦]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>As many of you have probably anticipated, due to concerns regarding the novel coronavirus COVID-19, the <a href="http://ec20.sigecom.org/">2020 ACM Conference on Economics and Computation (EC 2020)</a> will be held virtually.</p>
<p>This change of format will of course present us with difficult challenges, but we believe it will offer exciting new opportunities as well. Â (And not to worry, your opportunity to attend EC in Budapest is just deferred to 2021.)</p>
<p>The <a href="http://sigecom.org/officers.html">SIGecom Executive Committee</a> has appointed and will serve on a Virtual Transition Team that additionally includes the following new conference officers:</p>
<ul>
<li>Virtual General Chair: <a href="https://sites.northwestern.edu/hartline/">Jason Hartline</a></li>
<li>Virtual Local Chair: <a href="https://yannai.gonch.name/">Yannai Gonczarowski</a></li>
<li>Virtual Global Outreach Chairs: <a href="https://www.cs.cornell.edu/~red/">Rediet Abebe</a> and <a href="https://research.fb.com/people/sodomka-eric/">Eric Sodomka</a></li>
</ul>
<p>This team is working with the <a href="http://ec20.sigecom.org/committees-acm/organizing-committee/">EC 2020 organizing committee</a>Â and <a href="http://ec20.sigecom.org/committees-acm/program-committee/">EC 2020 PC chairs</a> to put together a plan that leverages the opportunities of the virtual format to the fullest extent. Though these plans are still in the works, we have identified the following âminimal commitmentâ for authors of accepted papers to the main EC conference: at least one author will need to</p>
<ul>
<li>register for the conference;</li>
<li>be available virtually on the conference dates (July 14-16);</li>
<li>provide a camera-ready paper or abstract by the camera-ready deadline;</li>
<li>provide a pre-recorded talk presenting the paper two weeks in advance (by June 28).</li>
</ul>
<p>We are optimistic that, while a virtual EC may lack some of the positive features of a classical conference, the format will also provide opportunities that improve on the classical experience.Â  As with any conference there will be opportunities to participate beyond the âminimal commitment.â Â We hope that speakers and participants will join in other activities, which may include preview sessions for talks before the conference proper, watch parties for speakers and attendees, and mechanisms for reaching a wider audience with the technical program. With many academic interactions moving virtual, the barriers to collaboration with distant colleagues have lowered, and we hope that EC 2020 will kindle and rekindle global collaborations.</p>
<div>
<p>Further details about these activities as well as the minimal requirements will be circulated by June 1.</p>
<p>Tutorial speakers and workshop organizers will receive separate emails from the Tutorial and Workshop Chairs about plans for moving these events online.</p>
</div></div>
    </content>
    <updated>2020-04-21T14:05:08Z</updated>
    <published>2020-04-21T14:05:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Jason Hartline</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2020-04-29T23:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=118</id>
    <link href="https://kamathematics.wordpress.com/2020/04/21/a-primer-on-private-statistics-part-ii/" rel="alternate" type="text/html"/>
    <title>A Primer on Private Statistics â Part II</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">ByÂ Gautam KamathÂ andÂ Jonathan Ullman The second part of our brief survey of differentially private statistics. This time, we show how to privately estimate the CDF of a distribution (i.e., estimate the distribution in Kolmogorov distance), and conclude with pointers to some other work in the space. The first part of this series is here, and you â¦ <a class="more-link" href="https://kamathematics.wordpress.com/2020/04/21/a-primer-on-private-statistics-part-ii/">Continue reading<span class="screen-reader-text"> "A Primer on Private Statistics â PartÂ II"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>ByÂ <a href="http://www.gautamkamath.com/">Gautam Kamath</a>Â andÂ <a href="http://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a></p>
<p>The second part of our brief survey of differentially private statistics. This time, we show how to privately estimate the CDF of a distribution (i.e., estimate the distribution in Kolmogorov distance), and conclude with pointers to some other work in the space.</p>
<p>The first part of this series is <a href="https://kamathematics.wordpress.com/2020/04/14/a-primer-on-private-statistics-part-i/">here</a>, and you can download both parts in PDF form <a href="http://www.gautamkamath.com/writings/primer.pdf">here</a>.</p>
<p><b>1. CDF Estimation for Discrete, Univariate Distributions </b></p>
<p>Suppose we have a distribution <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P}"/> over the ordered, discrete domain <img alt="{\{1,\dots,D\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2CD%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,\dots,D\}}"/> and let <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/> be the family of all such distributions. The CDF of the distribution is the function <img alt="{\Phi_{P} : \{1,\dots,D\} \rightarrow [0,1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi_%7BP%7D+%3A+%5C%7B1%2C%5Cdots%2CD%5C%7D+%5Crightarrow+%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi_{P} : \{1,\dots,D\} \rightarrow [0,1]}"/> given by</p>
<p align="center"><img alt="\displaystyle \Phi_{P}(j) = \mathop{\mathbb P}(P \leq j). \ \ \ \ \ (1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPhi_%7BP%7D%28j%29+%3D+%5Cmathop%7B%5Cmathbb+P%7D%28P+%5Cleq+j%29.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Phi_{P}(j) = \mathop{\mathbb P}(P \leq j). \ \ \ \ \ (1)"/></p>
<p>A natural measure of distance between CDFs is the <img alt="{\ell_\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_\infty}"/> distance, as this is the sort of convergence guarantee that the empirical CDF satisfies. That is, in the non-private setting, the empirical CDF will achieve the minimax rate, which it known by [<a href="https://kamathematics.wordpress.com/feed/#DKW56">DKW56</a>, <a href="https://kamathematics.wordpress.com/feed/#Mas90">Mas90</a>] to be <a name="eqdkw"/></p>
<p><a name="eqdkw"/></p>
<p><a name="eqdkw"/></p>
<p align="center"><img alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \Phi_{X} - \Phi_{P} \|_{\infty}) = O\left(\sqrt{\frac{1}{n}} \right). \ \ \ \ \ (2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+%5CPhi_%7BX%7D+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D%29+%3D+O%5Cleft%28%5Csqrt%7B%5Cfrac%7B1%7D%7Bn%7D%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \Phi_{X} - \Phi_{P} \|_{\infty}) = O\left(\sqrt{\frac{1}{n}} \right). \ \ \ \ \ (2)"/></p>
<p><a name="eqdkw"/><a name="eqdkw"/><a name="eqdkw"/></p>
<p><b> 1.1. Private CDF Estimation </b></p>
<blockquote><p><b>Theorem 1</b> <em> <a name="thmcdf-ub"/> For every <img alt="{n \in {\mathbb N}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cin+%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n \in {\mathbb N}}"/> and every <img alt="{\epsilon,\delta &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%2C%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\epsilon,\delta &gt; 0}"/>, there exists an <img alt="{(\epsilon,\delta)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(\epsilon,\delta)}"/>-differentially private mechanism <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> such that </em></p>
<p align="center"><img alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}) = O\left(\sqrt{\frac{1}{n}} + \frac{\log^{3/2}(D) \log^{1/2}(1/\delta)}{\epsilon n} \right). \ \ \ \ \ (3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D%29+%3D+O%5Cleft%28%5Csqrt%7B%5Cfrac%7B1%7D%7Bn%7D%7D+%2B+%5Cfrac%7B%5Clog%5E%7B3%2F2%7D%28D%29+%5Clog%5E%7B1%2F2%7D%281%2F%5Cdelta%29%7D%7B%5Cepsilon+n%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}) = O\left(\sqrt{\frac{1}{n}} + \frac{\log^{3/2}(D) \log^{1/2}(1/\delta)}{\epsilon n} \right). \ \ \ \ \ (3)"/></p>
</blockquote>
<p><em>Proof:</em> Assume without loss of generality that <img alt="{D = 2^{d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD+%3D+2%5E%7Bd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D = 2^{d}}"/> for an integer <img alt="{d \geq 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d \geq 1}"/>. Let <img alt="{X_{1 \cdots n} \sim P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_{1 \cdots n} \sim P}"/> be a sample. By the triangle inequality, we have</p>
<p align="center"><img alt="\displaystyle \begin{array}{rll} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}{\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}} &amp;\leq{} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \Phi_{X} - \Phi_{P} \|_{\infty} + \| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}) \\ &amp;\leq{} O(\sqrt{1/n}) + \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}), \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%7B%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D%7D+%26%5Cleq%7B%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+%5CPhi_%7BX%7D+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D+%2B+%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BX%7D+%5C%7C_%7B%5Cinfty%7D%29+%5C%5C+%26%5Cleq%7B%7D+O%28%5Csqrt%7B1%2Fn%7D%29+%2B+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BX%7D+%5C%7C_%7B%5Cinfty%7D%29%2C+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \begin{array}{rll} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}{\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}} &amp;\leq{} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \Phi_{X} - \Phi_{P} \|_{\infty} + \| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}) \\ &amp;\leq{} O(\sqrt{1/n}) + \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}), \end{array} "/></p>
<p>so we will focus on constructing <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> to approximate <img alt="{\Phi_{X}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi_%7BX%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi_{X}}"/>.</p>
<p>For any <img alt="{\ell = 0,\dots,d-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%3D+0%2C%5Cdots%2Cd-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell = 0,\dots,d-1}"/> and <img alt="{j = 1,\dots,2^{d - \ell}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj+%3D+1%2C%5Cdots%2C2%5E%7Bd+-+%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j = 1,\dots,2^{d - \ell}}"/>, consider the statistics</p>
<p align="center"><img alt="\displaystyle f_{\ell,j}(X_{1 \cdots n}) = \frac{1}{n} \sum_{i=1}^{n} {\bf 1}\{ (j-1)2^{\ell} + 1 \leq X_i \leq j 2^{\ell} \}. \ \ \ \ \ (4)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f_%7B%5Cell%2Cj%7D%28X_%7B1+%5Ccdots+n%7D%29+%3D+%5Cfrac%7B1%7D%7Bn%7D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%7B%5Cbf+1%7D%5C%7B+%28j-1%292%5E%7B%5Cell%7D+%2B+1+%5Cleq+X_i+%5Cleq+j+2%5E%7B%5Cell%7D+%5C%7D.+%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle f_{\ell,j}(X_{1 \cdots n}) = \frac{1}{n} \sum_{i=1}^{n} {\bf 1}\{ (j-1)2^{\ell} + 1 \leq X_i \leq j 2^{\ell} \}. \ \ \ \ \ (4)"/></p>
<p>Let <img alt="{f : \{1,\dots,D\}^n \rightarrow [0,1]^{2D - 2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%3A+%5C%7B1%2C%5Cdots%2CD%5C%7D%5En+%5Crightarrow+%5B0%2C1%5D%5E%7B2D+-+2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f : \{1,\dots,D\}^n \rightarrow [0,1]^{2D - 2}}"/> be the function whose output consists of all <img alt="{2D-2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2D-2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2D-2}"/> such counts. To decipher this notation, for a given <img alt="{\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell}"/>, the counts <img alt="{f_{\ell,\cdot}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Cell%2C%5Ccdot%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\ell,\cdot}}"/> form a histogram of <img alt="{X_{1 \cdots n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_%7B1+%5Ccdots+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X_{1 \cdots n}}"/> using consecutive bins of width <img alt="{2^{\ell}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{\ell}}"/>, and we consider the <img alt="{\log(D)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log(D)}"/> histograms of geometrically increasing width <img alt="{1,2,4,\dots,D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2C2%2C4%2C%5Cdots%2CD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1,2,4,\dots,D}"/>. First, we claim that the function <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> has low sensitivityâfor adjacent samples <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> and <img alt="{X'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X'}"/>,</p>
<p align="center"><img alt="\displaystyle \| f(X) - f(X') \|_2^2 \leq \frac{2 \log(D)}{n^2}. \ \ \ \ \ (5)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C+f%28X%29+-+f%28X%27%29+%5C%7C_2%5E2+%5Cleq+%5Cfrac%7B2+%5Clog%28D%29%7D%7Bn%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \| f(X) - f(X') \|_2^2 \leq \frac{2 \log(D)}{n^2}. \ \ \ \ \ (5)"/></p>
<p>Thus, we can use the Gaussian mechanism:</p>
<p align="center"><img alt="\displaystyle M'(X_{1 \cdots n}) = f(X_{1 \cdots n}) + \mathcal{N}\left(0, \frac{2 \log(D) \log(1/\delta)}{\epsilon^2 n^2} \cdot \mathbb{I}_{2D \times 2D}\right). \ \ \ \ \ (6)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+M%27%28X_%7B1+%5Ccdots+n%7D%29+%3D+f%28X_%7B1+%5Ccdots+n%7D%29+%2B+%5Cmathcal%7BN%7D%5Cleft%280%2C+%5Cfrac%7B2+%5Clog%28D%29+%5Clog%281%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D+%5Ccdot+%5Cmathbb%7BI%7D_%7B2D+%5Ctimes+2D%7D%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle M'(X_{1 \cdots n}) = f(X_{1 \cdots n}) + \mathcal{N}\left(0, \frac{2 \log(D) \log(1/\delta)}{\epsilon^2 n^2} \cdot \mathbb{I}_{2D \times 2D}\right). \ \ \ \ \ (6)"/></p>
<p>As we will argue, there exists a matrix <img alt="{A \in {\mathbb R}^{2D \times 2D}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Cin+%7B%5Cmathbb+R%7D%5E%7B2D+%5Ctimes+2D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \in {\mathbb R}^{2D \times 2D}}"/> such that <img alt="{\Phi_{X} = A \cdot f(X_{1 \cdots n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi_%7BX%7D+%3D+A+%5Ccdot+f%28X_%7B1+%5Ccdots+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi_{X} = A \cdot f(X_{1 \cdots n})}"/>. We will let <img alt="{M(X_{1 \cdots n}) = A \cdot M'(X_{1 \cdots n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B1+%5Ccdots+n%7D%29+%3D+A+%5Ccdot+M%27%28X_%7B1+%5Ccdots+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M(X_{1 \cdots n}) = A \cdot M'(X_{1 \cdots n})}"/>. Since differential privacy is closed under post-processing, <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/> inherits the privacy of <img alt="{M'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M'}"/>.</p>
<p>We will now show how to construct the matrix <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> and analyze the error of <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M}"/>. For any <img alt="{j = 1,\dots,D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj+%3D+1%2C%5Cdots%2CD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j = 1,\dots,D}"/>, we can form the interval <img alt="{\{1,\dots,j\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2Cj%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,\dots,j\}}"/> as the union of at most <img alt="{\log D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log D}"/> disjoint intervals of the form weâve computed, and therefore we can obtain <img alt="{\Phi_{X}(j)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CPhi_%7BX%7D%28j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Phi_{X}(j)}"/> as the sum of at most <img alt="{\log D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log D}"/> of the entries of <img alt="{f(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X)}"/>. For example, if <img alt="{j = 5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj+%3D+5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j = 5}"/> then we can write</p>
<p align="center"><img alt="\displaystyle \{1,\dots,7\} = \{1,\dots,4\} \cup \{5,6\} \cup \{7\} \ \ \ \ \ (7)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7B1%2C%5Cdots%2C7%5C%7D+%3D+%5C%7B1%2C%5Cdots%2C4%5C%7D+%5Ccup+%5C%7B5%2C6%5C%7D+%5Ccup+%5C%7B7%5C%7D+%5C+%5C+%5C+%5C+%5C+%287%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \{1,\dots,7\} = \{1,\dots,4\} \cup \{5,6\} \cup \{7\} \ \ \ \ \ (7)"/></p>
<p>and</p>
<p align="center"><img alt="\displaystyle \Phi_{X}(5) = f_{2,1} + f_{1,3} + f_{0,7}. \ \ \ \ \ (8)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPhi_%7BX%7D%285%29+%3D+f_%7B2%2C1%7D+%2B+f_%7B1%2C3%7D+%2B+f_%7B0%2C7%7D.+%5C+%5C+%5C+%5C+%5C+%288%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Phi_{X}(5) = f_{2,1} + f_{1,3} + f_{0,7}. \ \ \ \ \ (8)"/></p>
<p>See the following diagram for a visual representation of the decomposition.</p>
<p><img alt="bin-tree-mech" class=" wp-image-142 aligncenter" height="300" src="https://kamathematics.files.wordpress.com/2020/04/bin-tree-mech.png?w=547&amp;h=300" width="547"/></p>
<p>This shows hierarchical decomposition of the domain <img alt="{\{1,\dots,8\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2C8%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,\dots,8\}}"/> using 14 intervals. The highlighted squares represent the interval <img alt="{\{1,\dots,7\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2C7%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,\dots,7\}}"/> and the highlighted circles show the decomposition of this interval into a union of <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/> intervals in the tree.</p>
<p>Thus we can construct the matrix <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> using this information. Note that each entry of <img alt="{A f(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+f%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A f(X)}"/> is the sum of at most <img alt="{\log(D)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log(D)}"/> entries of <img alt="{f(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X)}"/>. Thus, if we use the output of <img alt="{M'(X_{1 \cdots n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%27%28X_%7B1+%5Ccdots+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M'(X_{1 \cdots n})}"/> in place of <img alt="{f(X_{1 \cdots n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28X_%7B1+%5Ccdots+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(X_{1 \cdots n})}"/>, for every <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> we obtain</p>
<p align="center"><img alt="\displaystyle \Phi_{X}(j) + \mathcal{N}(0, \sigma^2) \quad \textrm{for} \quad \sigma^2 = \frac{ 2 \log^2(D) \log(1/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (9)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPhi_%7BX%7D%28j%29+%2B+%5Cmathcal%7BN%7D%280%2C+%5Csigma%5E2%29+%5Cquad+%5Ctextrm%7Bfor%7D+%5Cquad+%5Csigma%5E2+%3D+%5Cfrac%7B+2+%5Clog%5E2%28D%29+%5Clog%281%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%289%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Phi_{X}(j) + \mathcal{N}(0, \sigma^2) \quad \textrm{for} \quad \sigma^2 = \frac{ 2 \log^2(D) \log(1/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (9)"/></p>
<p>Applying standard bounds on the expected supremum of a Gaussian process, we have</p>
<p align="center"><img alt="\displaystyle \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}) = O( \sigma \sqrt{\log D}) = O\left(\frac{\log^{3/2}(D) \log^{1/2}(1/\delta)}{\epsilon n} \right). \ \ \ \ \ (10)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BX%7D+%5C%7C_%7B%5Cinfty%7D%29+%3D+O%28+%5Csigma+%5Csqrt%7B%5Clog+D%7D%29+%3D+O%5Cleft%28%5Cfrac%7B%5Clog%5E%7B3%2F2%7D%28D%29+%5Clog%5E%7B1%2F2%7D%281%2F%5Cdelta%29%7D%7B%5Cepsilon+n%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%2810%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}) = O( \sigma \sqrt{\log D}) = O\left(\frac{\log^{3/2}(D) \log^{1/2}(1/\delta)}{\epsilon n} \right). \ \ \ \ \ (10)"/></p>
<p><img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p><b> 1.2. Why Restrict the Domain? </b></p>
<p>A drawback of the estimator we constructed is that it only applies to distributions of finite support <img alt="{\{1,2,\dots,D\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C2%2C%5Cdots%2CD%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,2,\dots,D\}}"/>, albeit with a relatively mild dependence on the support size. If privacy isnât a concern, then no such restriction is necessary, as the bound <a href="https://kamathematics.wordpress.com/feed/#eqdkw">(2)</a> applies equally well to any distribution over <img alt="{{\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb R}}"/>. Can we construct a differentially private estimator for distributions with infinite support?</p>
<p>Perhaps surprisingly, the answer to this question is no! Any differentially private estimator for the CDF of the distribution has to have a rate that depends on the support size, and cannot give non-trivial rates for distributions with infinite support.</p>
<blockquote><p><b>Theorem 2 ([<a href="https://kamathematics.wordpress.com/feed/#BNSV15">BNSV15</a>])</b> <em> <a name="thmcdf-lb"/> If <img alt="{\mathcal{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{P}}"/> consists of all distributions on <img alt="{\{1,\dots,D\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2CD%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{1,\dots,D\}}"/>, then </em></p>
<p align="center"><img alt="\displaystyle \min_{M \in \mathcal{M}_{1, \frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}) = \Omega\left(\frac{\log^* D}{n} \right). \ \ \ \ \ (11)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D_%7B1%2C+%5Cfrac%7B1%7D%7Bn%7D%7D%7D+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D%29+%3D+%5COmega%5Cleft%28%5Cfrac%7B%5Clog%5E%2A+D%7D%7Bn%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%2811%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \min_{M \in \mathcal{M}_{1, \frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}) = \Omega\left(\frac{\log^* D}{n} \right). \ \ \ \ \ (11)"/></p>
</blockquote>
<p>The notation <img alt="{\log^* D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%5E%2A+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log^* D}"/> refers to the <a href="https://en.wikipedia.org/wiki/Iterated_logarithm">iterated logarithm</a>.</p>
<p>We emphasize that this theorem shouldnât meet with too much alarm, as <img alt="{\log^* D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%5E%2A+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log^* D}"/> grows remarkably slowly with <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/>. There are differentially private CDF estimators that achieve very mild dependence on <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> [<a href="https://kamathematics.wordpress.com/feed/#BNS13">BNS13</a>, <a href="https://kamathematics.wordpress.com/feed/#BNSV15">BNSV15</a>], including one nearly matching the lower bound in Theorem <a href="https://kamathematics.wordpress.com/feed/#thmcdf-lb">2</a>. Moreover, if we want to estimate a distribution over <img alt="{{\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb R}}"/>, and are willing to make some mild regularity conditions on the distribution, then we can approximate it by a distribution with finite support and only increase the rate slightly. However, what Theorem <a href="https://kamathematics.wordpress.com/feed/#thmcdf-lb">2</a> shows is that there is no âone-size-fits-allâ solution to private CDF estimation that achieves similar guarantees to the empirical CDF. That is, the right algorithm has to be tailored somewhat to the application and the assumptions we can make about the distribution.</p>
<p><b>2. More Private Statistics </b></p>
<p>Of course, the story doesnât end here! Thereâs a whole wide world of differentially private statistics beyond what weâve mentioned already. We proceed to survey just a few other directions of study in private statistics.</p>
<p><b> 2.1. Parameter and Distribution Estimation </b></p>
<p>A number of the early works in differential privacy give methods for differentially private statistical estimation for i.i.d. data. The earliest works [<a href="https://kamathematics.wordpress.com/feed/#DN03">DN03</a>, <a href="https://kamathematics.wordpress.com/feed/#DN04">DN04</a>, <a href="https://kamathematics.wordpress.com/feed/#BDMN05">BDMN05</a>, <a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>], which introduced the Gaussian mechanism, among other foundational results, can be thought of as methods for estimating the mean of a distribution over the hypercube <img alt="{\{0,1\}^d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{0,1\}^d}"/> in the <img alt="{\ell_\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_\infty}"/> norm. Tight lower bounds for this problem follow from the tracing attacks introduced in [<a href="https://kamathematics.wordpress.com/feed/#BUV14">BUV14</a>, <a href="https://kamathematics.wordpress.com/feed/#DSSUV15">DSSUV15</a>, <a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>]. A very recent work of Acharya, Sun, and Zhang [<a href="https://kamathematics.wordpress.com/feed/#ASZ20">ASZ20</a>] adapts classical tools for proving estimation and testing lower bounds (lemmata of Assouad, Fano, and Le Cam) to the differentially private setting. Steinke and Ullman [<a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>] give tight minimax lower bounds for the weaker guarantee of selecting the largest coordinates of the mean, which were refined by Cai, Wang, and Zhang [<a href="https://kamathematics.wordpress.com/feed/#CWZ19">CWZ19</a>] to give lower bounds for sparse mean-estimation problems.</p>
<p>Nissim, Raskhodnikova, and Smith introduced the highly general sample-and-aggregate paradigm, which they apply to several learning problems (e.g., learning mixtures of Gaussians) [<a href="https://kamathematics.wordpress.com/feed/#NRS07">NRS07</a>]. Later, Smith [<a href="https://kamathematics.wordpress.com/feed/#Smi11">Smi11</a>] showed that this paradigm can be used to transform any estimator for any asymptotically normal, univariate statistic over a bounded data domain into a differentially private one with the same asymptotic convergence rate.</p>
<p>Subsequent work has focused on both relaxing the assumptions in [<a href="https://kamathematics.wordpress.com/feed/#Smi11">Smi11</a>], particularly boundedness, and on giving finite-sample guarantees. Karwa and Vadhan investigated the problem of Gaussian mean estimation, proving the first near-optimal bounds for this setting [<a href="https://kamathematics.wordpress.com/feed/#KV18">KV18</a>]. In particular, exploiting concentration properties of Gaussian data allows us to achieve non-trivial results even with unbounded data, which is impossible in general. Following this, Kamath, Li, Singhal, and Ullman moved to the multivariate setting, investigating the estimation of Gaussians and binary product distributions in total variation distance [<a href="https://kamathematics.wordpress.com/feed/#KLSU19">KLSU19</a>]. In certain cases (i.e., Gaussians with identity covariance), this is equivalent to mean estimation in <img alt="{\ell_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell_2}"/>-distance, though not always. For example, for binary product distribution, one must estimate the mean in a type of <img alt="{\chi^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi^2}"/>-distance instead. The perspective of distribution estimation rather than parameter estimation can be valuable. Bun, Kamath, Steinke, and Wu [<a href="https://kamathematics.wordpress.com/feed/#BKSW19">BKSW19</a>] develop a primitive for private hypothesis selection, which they apply to learn any coverable class of distributions under pure differential privacy. Through the lens of distribution estimation, their work implies an upper bound for mean estimation of binary product distributions that bypasses lower bounds for the same problem in the empirical setting. In addition to work on mean estimation in the sub-Gaussian setting, such as the results discussed earlier, mean estimation has also been studied under weaker moment conditions [<a href="https://kamathematics.wordpress.com/feed/#BS19">BS19</a>, <a href="https://kamathematics.wordpress.com/feed/#KSU20">KSU20</a>]. Beyond these settings, there has also been study of estimation of discrete multinomials, including estimation in Kolmogorov distance [<a href="https://kamathematics.wordpress.com/feed/#BNSV15">BNSV15</a>] and in total variation distance for structured distributions [<a href="https://kamathematics.wordpress.com/feed/#DHS15">DHS15</a>], and parameter estimation of Markov Random Fields [<a href="https://kamathematics.wordpress.com/feed/#ZKKW20">ZKKW20</a>].</p>
<p>A different approach to constructing differentially private estimators is based on robust statistics. This approah begins with the influential work of Dwork and Lei [<a href="https://kamathematics.wordpress.com/feed/#DL09">DL09</a>], which introduced the propose-test-release framework, and applied to estimating robust statistics such as the median and interquartile range. While the definitions in robust statistics and differential privacy are semantically similar, formal connections between the two remain relatively scant, which suggests a productive area for future study.</p>
<p><b> 2.2. Hypothesis Testing </b></p>
<p>An influential work of Homer et al. [<a href="https://kamathematics.wordpress.com/feed/#HSRDTMPSNC08">HSRDTMPSNC08</a>] demonstrated the vulnerability of classical statistics in a genomic setting, showing that certain <img alt="{\chi^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cchi%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\chi^2}"/>-statistics on many different variables could allow an attacker to determine the presence of an individual in a genome-wide association study (GWAS). Motivated by these concerns, an early line of work from the statistics community focused on addressing these issues [<a href="https://kamathematics.wordpress.com/feed/#VS09">VS09</a>, <a href="https://kamathematics.wordpress.com/feed/#USF13">USF13</a>, <a href="https://kamathematics.wordpress.com/feed/#YFSU14">YFSU14</a>].</p>
<p>More recently, work on private hypothesis testing can be divided roughly into two lines. The first focuses on the minimax sample complexity, in a line initiated by Cai, Daskalakis, and Kamath [<a href="https://kamathematics.wordpress.com/feed/#CDK17">CDK17</a>], who give an algorithm for privately testing goodness-of-fit (more precisely, a statistician might refer to this problem as one-sample testing of multinomial data). A number of subsequent works have essentially settled the complexity of this problem [<a href="https://kamathematics.wordpress.com/feed/#ASZ18">ASZ18</a>, <a href="https://kamathematics.wordpress.com/feed/#ADR18">ADR18</a>], giving tight upper and lower bounds. Other papers in this line study related problems, including the two-sample version of the problem, independence testing, and goodness-of-fit testing for multivariate product distributions [<a href="https://kamathematics.wordpress.com/feed/#ASZ18">ASZ18</a>, <a href="https://kamathematics.wordpress.com/feed/#ADR18">ADR18</a>, <a href="https://kamathematics.wordpress.com/feed/#ADKR19">ADKR19</a>, <a href="https://kamathematics.wordpress.com/feed/#CKMUZ19">CKMUZ19</a>]. A related paper studies the minimax sample complexity of property <em>estimation</em>, rather than testing of discrete distributions, including support size and entropy [<a href="https://kamathematics.wordpress.com/feed/#AKSZ18">AKSZ18</a>]. Other recent works in this vein focus on testing of simple hypotheses [<a href="https://kamathematics.wordpress.com/feed/#CKMTZ18">CKMTZ18</a>, <a href="https://kamathematics.wordpress.com/feed/#CKMSU19">CKMSU19</a>]. In particular [<a href="https://kamathematics.wordpress.com/feed/#CKMSU19">CKMSU19</a>] proves an analogue of the Neyman-Pearson Lemma for differentially private testing of simple hypotheses. A paper of Awan and Slavkovic [<a href="https://kamathematics.wordpress.com/feed/#AS18">AS18</a>] gives a universally optimal test when the domain size is two, however Brenner and Nissim [<a href="https://kamathematics.wordpress.com/feed/#BN14">BN14</a>] shows that such universally optimal tests cannot exist when the domain has more than two elements. A related problem in this space is private change-point detection [<a href="https://kamathematics.wordpress.com/feed/#CKMTZ18">CKMTZ18</a>, <a href="https://kamathematics.wordpress.com/feed/#CKMSU19">CKMSU19</a>, <a href="https://kamathematics.wordpress.com/feed/#CKLZ19">CKLZ19</a>] â in this setting, we are given a time series of datapoints which are sampled from a distribution, which at some point, changes to a different distribution. The goal is to (privately) determine when this point occurs.</p>
<p>Complementary to minimax hypothesis testing, a line of work [<a href="https://kamathematics.wordpress.com/feed/#WLK15">WLK15</a>, <a href="https://kamathematics.wordpress.com/feed/#GLRV16">GLRV16</a>, <a href="https://kamathematics.wordpress.com/feed/#KR17">KR17</a>, <a href="https://kamathematics.wordpress.com/feed/#KSF17">KSF17</a>, <a href="https://kamathematics.wordpress.com/feed/#CBRG18">CBRG18</a>, <a href="https://kamathematics.wordpress.com/feed/#SGGRGB19">SGGRGB19</a>, <a href="https://kamathematics.wordpress.com/feed/#CKSBG19">CKSBG19</a>] designs differentially private versions of popular test statistics for testing goodness-of-fit, closeness, and independence, as well as private ANOVA, focusing on the performance at small sample sizes. Work by Wang et al. [<a href="https://kamathematics.wordpress.com/feed/#WKLK18">WKLK18</a>] focuses on generating statistical approximating distributions for differentially private statistics, which they apply to hypothesis testing problems.</p>
<p><b> 2.3. Differential Privacy on Graphs </b></p>
<p>There is a significant amount of work on differentially private analysis of graphs. We remark that these algorithms can satisfy either edge or node differential privacy. The former (easier) guarantee defines a neighboring graph to be one obtained by adding or removing a single edge, while in the latter (harder) setting, a neighboring graph is one that can be obtained by modifying the set of edges connected to a single node. The main challenge in this area is that most graph statistics can have high sensitivity in the worst-case.</p>
<p>The initial works in this area focused on the empirical setting, and goals range from counting subgraphs [<a href="https://kamathematics.wordpress.com/feed/#KRSY11">KRSY11</a>, <a href="https://kamathematics.wordpress.com/feed/#BBDS13">BBDS13</a>, <a href="https://kamathematics.wordpress.com/feed/#KNRS13">KNRS13</a>, <a href="https://kamathematics.wordpress.com/feed/#CZ13">CZ13</a>, <a href="https://kamathematics.wordpress.com/feed/#RS16">RS16</a>] to outputting a privatized graph which approximates the original [<a href="https://kamathematics.wordpress.com/feed/#GRU12">GRU12</a>, <a href="https://kamathematics.wordpress.com/feed/#BBDS12">BBDS12</a>, <a href="https://kamathematics.wordpress.com/feed/#Upa13">Upa13</a>, <a href="https://kamathematics.wordpress.com/feed/#AU19">AU19</a>, <a href="https://kamathematics.wordpress.com/feed/#EKKL20">EKKL20</a>]. In contrast to the setting discussed in most of this series, it seems that there are larger qualitative differences between the study of empirical and population statistics due to the fact that many graph statistics have high worst-case sensitivity, but may have smaller sensitivity on typical graphs from many natural models.</p>
<p>In the population statistics setting, recent work has focused on parameter estimation of the underlying random graph model. So far this work has given estimators for the <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/>-model [<a href="https://kamathematics.wordpress.com/feed/#KS16">KS16</a>] and graphons [<a href="https://kamathematics.wordpress.com/feed/#BCS15">BCS15</a>,<a href="https://kamathematics.wordpress.com/feed/#BCSZ18">BCSZ18</a>]. Graphons are a generalization of the stochastic block model, which is, in turn, a generalization of the ErdÃ¶s-RÃ©nyi model. Interestingly, the methods of Lipschitz-extensions introduced in the empirical setting by [<a href="https://kamathematics.wordpress.com/feed/#BBDS13">BBDS13</a>, <a href="https://kamathematics.wordpress.com/feed/#KNRS13">KNRS13</a>] are the main tool used in the statistical setting as well. While the first works on private graphon estimation were not computationally efficient, a recent focus has been on obviating these issues for certain important cases, such as the ErdÃ¶s-RÃ©nyi setting [<a href="https://kamathematics.wordpress.com/feed/#SU19">SU19</a>].</p>
<p><b>Bibliography</b></p>
<p><a name="ADKR19"/>[ADKR19] Maryam Aliakbarpour, Ilias Diakonikolas, Daniel M. Kane, and Ronitt Rubinfeld. Private testing of distributions via sample permutations. NeurIPS â19.</p>
<p><a name="ADR18"/>[ADR18] Maryam Aliakbarpour, Ilias Diakonikolas, and Ronitt Rubinfeld. Differentially private identity and closeness testing of discrete distributions. ICML â18.</p>
<p><a name="AKSZ18"/>[AKSZ18] Jayadev Acharya, Gautam Kamath, Ziteng Sun, and Huanyu Zhang. Inspectre: Privately estimating the unseen. ICML â18.</p>
<p><a name="AS18"/>[AS18] Jordan Awan and Aleksandra SlavkoviÄ. Differentially private uniformly most powerful tests for binomial data. NeurIPS â18.</p>
<p><a name="ASZ18"/>[ASZ18] Jayadev Acharya, Ziteng Sun, and Huanyu Zhang. Differentially private testing of identity and closeness of discrete distributions. NeurIPS â18.</p>
<p><a name="ASZ20"/>[ASZ20] Jayadev Acharya, Ziteng Sun, and Huanyu Zhang. Differentially private Assouad, Fano, and Le Cam. arXiv, 2004.06830, 2020.</p>
<p><a name="AU19"/>[AU19] Raman Arora and Jalaj Upadhyay. On differentially private graph sparsification and applications. NeurIPS â19.</p>
<p><a name="BBDS12"/>[BBDS12] Jeremiah Blocki, Avrim Blum, Anupam Datta, and Or Sheffet. The Johnson-Lindenstrauss transform itself preserves differential privacy. FOCS â12.</p>
<p><a name="BBDS13"/>[BBDS13] Jeremiah Blocki, Avrim Blum, Anupam Datta, and Or Sheffet. Differentially private data analysis of social networks via restricted sensitivity. ITCS â13.</p>
<p><a name="BCS15"/>[BCS15] Christian Borgs, Jennifer Chayes, and Adam Smith. Private graphon estimation for sparse graphs. NIPS â15.</p>
<p><a name="BCSZ18"/>[BCSZ18] Christian Borgs, Jennifer Chayes, Adam Smith, and Ilias Zadik. Revealing network structure, confidentially: Improved rates for node-private graphon estimation. FOCS â18.</p>
<p><a name="BDMN05"/>[BDMN05] Avrim Blum, Cynthia Dwork, Frank McSherry, and Kobbi Nissim. Practical privacy: The SuLQ framework. PODS â05.</p>
<p><a name="BKSW19"/>[BKSW19] Mark Bun, Gautam Kamath, Thomas Steinke, and Zhiwei Steven Wu. Private hypothesis selection. NeurIPS â19.</p>
<p><a name="BN14"/>[BN14] Hai Brenner and Kobbi Nissim. Impossibility of differentially private universally optimal mechanisms. SIAM Journal on Computing, 43(5), 2014.</p>
<p><a name="BNS13"/>[BNS13] Amos Beimel, Kobbi Nissim, and Uri Stemmer. Private learning and sanitization: Pure vs. approximate differential privacy. APPROX-RANDOM â13.</p>
<p><a name="BNSV15"/>[BNSV15] Mark Bun, Kobbi Nissim, Uri Stemmer, and Salil Vadhan. Differentially private release and learning of threshold functions. FOCS â15.</p>
<p><a name="BS19"/>[BS19] Mark Bun and Thomas Steinke. Average-case averages: Private algorithms for smooth sensitivity and mean estimation. NeurIPS â19.</p>
<p><a name="BSU17"/>[BSU17] Mark Bun, Thomas Steinke, and Jonathan Ullman. Make up your mind: The price of online queries in differential privacy. SODA â17.</p>
<p><a name="BUV14"/>[BUV14] Mark Bun, Jonathan Ullman, and Salil Vadhan. Fingerprinting codes and the price of approximate differential privacy. STOC â14.</p>
<p><a name="CBRG18"/>[CBRG18] Zachary Campbell, Andrew Bray, Anna Ritz, and Adam Groce. Differentially private ANOVA testing. ICDIS â18.</p>
<p><a name="CDK17"/>[CDK17] Bryan Cai, Constantinos Daskalakis, and Gautam Kamath. Privâit: Private and sample efficient identity testing. ICML â17.</p>
<p><a name="CKLZ19"/>[CKLZ19] Rachel Cummings, Sara Krehbiel, Yuliia Lut, and Wanrong Zhang. Privately detecting changes in unknown distributions. arXiv, 1910.01327, 2019.</p>
<p><a name="CKMSU19"/>[CKMSU19] ClÃ©ment L. Canonne, Gautam Kamath, Audra McMillan, Adam Smith, and Jonathan Ullman. The structure of optimal private tests for simple hypotheses. STOC â19.</p>
<p><a name="CKMTZ18"/>[CKMTZ18] Rachel Cummings, Sara Krehbiel, Yajun Mei, Rui Tuo, and Wanrong Zhang. Differentially private change-point detection. NeurIPS â18.</p>
<p><a name="CKMUZ19"/>[CKMUZ19] ClÃ©ment L. Canonne, Gautam Kamath, Audra McMillan, Jonathan Ullman, and Lydia Zakynthinou. Private identity testing for high-dimensional distributions. arXiv, 1905.11947, 2019.</p>
<p><a name="CKSBG19"/>[CKSBG19] Simon Couch, Zeki Kazan, Kaiyan Shi, Andrew Bray, and Adam Groce. Differentially private nonparametric hypothesis testing. CCS â19.</p>
<p><a name="CWZ19"/>[CWZ19] T. Tony Cai, Yichen Wang, and Linjun Zhang. The cost of privacy: Optimal rates of convergence for parameter estimation with differential privacy. arXiv, 1902.04495, 2019.</p>
<p><a name="CZ13"/>[CZ13] Shixi Chen and Shuigeng Zhou. Recursive mechanism: Towards node differential privacy and unrestricted joins. SIGMOD â13.</p>
<p><a name="DHS15"/>[DHS15] Ilias Diakonikolas, Moritz Hardt, and Ludwig Schmidt. Differentially private learning of structured discrete distributions. NIPS â15.</p>
<p><a name="DKW56"/>[DKW56] Aryeh Dvoretzky, Jack Kiefer, and Jacob Wolfowitz. Asymptotic minimax character of the sample distribution function and of the classical multinomial estimator. The Annals of Mathematical Statistics, 27(3), 1956.</p>
<p><a name="DL09"/>[DL09] Cynthia Dwork and Jing Lei. Differential privacy and robust statistics. STOC â09.</p>
<p><a name="DMNS06"/>[DMNS06] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. TCC â06.</p>
<p><a name="DN03"/>[DN03] Irit Dinur and Kobbi Nissim. Revealing information while preserving privacy. PODS â03.</p>
<p><a name="DN04"/>[DN04] Cynthia Dwork and Kobbi Nissim. Privacy-preserving datamining on vertically partitioned databases. CRYPTO â04.</p>
<p><a name="DSSUV15"/>[DSSUV15] Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman, and Salil Vadhan. Robust traceability from trace amounts. FOCS â15.</p>
<p><a name="EKKL20"/>[EKKL20] Marek EliÃ¡Å¡, Michael Kapralov, Janardhan Kulkarni, and Yin Tat Lee. Differentially private release of synthetic graphs. SODA â20.</p>
<p><a name="GLRV16"/>[GLRV16] Marco Gaboardi, Hyun-Woo Lim, Ryan M. Rogers, and Salil P. Vadhan. Differentially private chi-squared hypothesis testing: Goodness of fit and independence testing. ICML â16.</p>
<p><a name="GRU12"/>[GRU12] Anupam Gupta, Aaron Roth, and Jonathan Ullman. Iterative constructions and private data release. TCC â12.</p>
<p><a name="HSRDTMPSNC08"/>[HSRDTMPSNC08] Nils Homer, Szabolcs Szelinger, Margot Redman, David Duggan, Waibhav Tembe, Jill Muehling, John V. Pearson, Dietrich A. Stephan, Stanley F. Nelson, and David W. Craig. PLoS Genetics, 4(8), 2008.</p>
<p><a name="KLSU19"/>[KLSU19] Gautam Kamath, Jerry Li, Vikrant Singhal, and Jonathan Ullman. Privately learning high-dimensional distributions. COLT â19.</p>
<p><a name="KNRS13"/>[KNRS13] Shiva Prasad Kasiviswanathan, Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Analyzing graphs with node differential privacy. TCC â13.</p>
<p><a name="KR17"/>[KR17] Daniel Kifer and Ryan M. Rogers. A new class of private chi-square tests. AISTATS â17.</p>
<p><a name="KRSY11"/>[KRSY11] Vishesh Karwa, Sofya Raskhodnikova, Adam Smith, and Grigory Yaroslavtsev. Private analysis of graph structure. VLDB â11.</p>
<p><a name="KS16"/>[KS16] Vishesh Karwa and Aleksandra SlavkoviÄ. Inference using noisy degrees: Differentially private Î²-model and synthetic graphs. The Annals of Statistics, 44(1), 2016.</p>
<p><a name="KSF17"/>[KSF17] Kazuya Kakizaki, Jun Sakuma, and Kazuto Fukuchi. Differentially private chi-squared test by unit circle mechanism. ICML â17.</p>
<p><a name="KSU20"/>[KSU20] Gautam Kamath, Vikrant Singhal, and Jonathan Ullman. Private mean estimation of heavy-tailed distributions. arXiv, 2002.09464, 2020.</p>
<p><a name="KV18"/>[KV18] Vishesh Karwa and Salil Vadhan. Finite sample differentially private confidence intervals. ITCS â18.</p>
<p><a name="Mas90"/>[Mas90] Pascal Massart. The tight constant in the Dvoretzky-Kiefer-Wolfowitz inequality. The Annals of Probability, 18(3), 1990.</p>
<p><a name="NRS07"/>[NRS07] Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Smooth sensitivity and sampling in private data analysis. STOC â07.</p>
<p><a name="RS16"/>[RS16] Sofya Raskhodnikova and Adam D. Smith. Lipschitz extensions for node-private graph statistics and the generalized exponential mechanism. FOCS â16.</p>
<p><a name="Smi11"/>[Smi11] Adam Smith. Privacy-preserving statistical estimation with optimal convergence rates. STOC â11.</p>
<p><a name="SGGRGB19"/>[SGGRGB19] Marika Swanberg, Ira Globus-Harris, Iris Griffith, Anna Ritz, Adam Groce, and Andrew Bray. Improved differentially private analysis of variance. PETS â19.</p>
<p><a name="SU17a"/>[SU17a] Thomas Steinke and Jonathan Ullman. Between pure and approximate differential privacy. Journal of Privacy and Confidentiality, 7(2), 2017.</p>
<p><a name="SU17b"/>[SU17b] Thomas Steinke and Jonathan Ullman. Tight lower bounds for differentially private selection. FOCS â17.</p>
<p><a name="SU19"/>[SU19] Adam Sealfon and Jonathan Ullman. Efficiently estimating Erdos-Renyi graphs with node differential privacy. NeurIPS â19.</p>
<p><a name="Upa13"/>[Upa13] Jalaj Upadhyay. Random projections, graph sparsification, and differential privacy. ASIACRYPT â13.</p>
<p><a name="USF13"/>[USF13] Caroline Uhler, Aleksandra SlavkoviÄ, and Stephen E. Fienberg. Privacy-preserving data sharing for genome-wide association studies. The Journal of Privacy and Confidentiality, 5(1), 2013.</p>
<p><a name="VS09"/>[VS09] Duy Vu and Aleksandra SlavkoviÄ. Differential privacy for clinical trial data: Preliminary evaluations. ICDMW â09.</p>
<p><a name="WKLK18"/>[WKLK18] Yue Wang, Daniel Kifer, Jaewoo Lee, and Vishesh Karwa. Statistical approximating distributions under differential privacy. The Journal of Privacy and Confidentiality, 8(1), 2018.</p>
<p><a name="WLK15"/>[WLK15] Yue Wang, Jaewoo Lee, and Daniel Kifer. Revisiting differentially private hypothesis tests for categorical data. arXiv, 1511.03376, 2015.</p>
<p><a name="YFSU14"/>[YFSU14] Fei Yu, Stephen E. Fienberg, Aleksandra B. SlavkoviÄ, and Caroline Uhler. Scalable privacy-preserving data sharing methodology for genome-wide association studies. Journal of Biomedical Informatics, 50, 2014.</p>
<p><a name="ZKKW20"/>[ZKKW20] Huanyu Zhang, Gautam Kamath, Janardhan Kulkarni, and Zhiwei Steven Wu. Privately learning Markov random fields. arXiv, 2002.09463, 2020.</p></div>
    </content>
    <updated>2020-04-21T13:36:53Z</updated>
    <published>2020-04-21T13:36:53Z</published>
    <category term="Technical"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2020-04-29T23:21:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4768</id>
    <link href="https://www.scottaaronson.com/blog/?p=4768" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4768#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4768" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">AirToAll: Another guest post by Steve Ebin</title>
    <summary xml:lang="en-US">Scottâs foreword: Today Iâm honored to host another guest post by friend-of-the-blog Steve Ebin, who not only published a beautiful essay here a month ago (the one that I titled âFirst it came from Wuhanâ), but also posted an extremely informative timeline of what he understood when about the severity of the covid crisis, from [â¦]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong><span class="has-inline-color has-vivid-red-color">Scottâs foreword:</span></strong> Today Iâm honored to host another guest post by friend-of-the-blog Steve Ebin, who not only published a <a href="https://www.scottaaronson.com/blog/?p=4675">beautiful essay</a> here a month ago (the one that I titled âFirst it came from Wuhanâ), but also posted an extremely informative <a href="https://www.scottaaronson.com/blog/?p=4695#comment-1834991">timeline</a> of what he understood when about the severity of the covid crisis, from early January until March 31st.  By the latter date, Steve had quit his job, having made a hefty sum shorting airline stocks, and was devoting his full time to a new nonprofit to manufacture low-cost ventilators, called AirToAll.  A couple weeks ago, Steve was kind enough to include me in one of AirToAllâs regular Zoom meetings; I learned more about pistons than I had in my entire previous life (admittedly, still not much).  Which brings me to what Steve wants to talk about today: what he and others are doing and how <em>you</em> can help.</p>



<p><strong><span class="has-inline-color has-vivid-red-color">Without further ado, Steveâs guest post:</span></strong></p>



<p>In my <a href="https://www.scottaaronson.com/blog/?p=4675">last essay</a> on Coronavirus, I argued that Coronavirus will radically change society.  In this blog post, Iâd like to propose a structure for how we can organize to fight the virus.  I will also make a call to action for readers of this blog to help a non-profit I co-founded, <a href="http://airtoall.org">AirToAll</a>, build safe, low-cost ventilators and other medical devices and distribute them across the world at scale.</p>



<p>There are four ways we can help fight coronavirus:</p>



<ol><li><strong>Reduce exposure to the virus. </strong>Examples: learn where the virus is through better testing; attempt to be where the virus isnât through social distancing, quarantining, and other means.</li><li><strong>Reduce the chance of exposure leading to infection.</strong> Examples: Wash your hands; avoid touching your face; wear personal protective equipment.</li><li><strong>Reduce the chance of infection leading to serious illness. </strong>Examples: improve your aerobic and pulmonary health; make it more difficult for coronavirusâs spike protein to bind to ACE-2 receptors; scale antibody therapies; consume adequate vitamin D; get more sleep; develop a vaccine.</li><li><strong>Reduce the chance of serious illness leading to death. </strong>Examples: ramp up the production and distribution of certain drugs; develop better drugs; build more ventilators; help healthcare workers.</li></ol>



<p>Obviously, not every example I listed is practical, advisable, or will work, and some options, like producing a vaccine, may be better solutions than others. But we must pursue all approaches.</p>



<p>Iâve been devoting my own time to pursuing the fourth approach, reducing the chance that the illness will lead to death.  Specifically, along with Neil Thanedar, I co-founded AirToAll, a nonprofit that helps bring low-cost, reliable, and clinically tested ventilators to market.  I know lots of groups are working on this problem, so I thought Iâd talk about it briefly.</p>



<p>First, like many groups, weâre designing our own ventilators.  Although designing ventilators and bringing them to market at scale poses unique challenges, particularly in an environment where supply chains are strained, this is <em>much </em>easier than it must have been to build iron lungs in the early part of the 20th century, when Zoom conferencing wasnât yet invented.  When it comes to the ventilators weâre producing, weâre focused on safety and clinical validation rather than speed to market.  We are not the farthest along here, but weâve made good progress.</p>



<p>Second, our nonprofit is helping other groups produce safe and reliable ventilators by doing direct consultations with them and also by producing <a href="https://591654b2-a393-4da6-9d87-f168fb514898.filesusr.com/ugd/9fa1d3_9f8fa025b877468e91b8ba575c054815.pdf">whitepapers</a> to help them think through the issues at hand (h/t to Harvey Hawes, Abdullah Saleh, and our friends at <a href="https://icchange.ca/">ICChange</a>).</p>



<p>Third, weâre working to increase the manufacturing capacity for currently approved ventilators.</p>



<p>The current shortage of ventilators is a symptom of a greater underlying problem: namely, the world is not good at recognizing healthcare crises early and responding to them quickly.  While our nonprofit helps bring more ventilators to market, we are also trying to solve this greater underlying problem.  I look at our work in ventilator-land as a first step towards our ultimate goal of making medical devices cheaper and more available through an open-source nonprofit model.</p>



<p>I am writing this post as a call to action to you, dear <em>Shtetl-Optimized</em> reader, to get involved.</p>



<p>You donât have to be an engineer, pulmonologist, virologist, or epidemiologist to help us, although those skillsets are of course helpful and if you are weâd love to have you.  If you have experience in data science and modeling, supply chain and manufacturing, public health, finance, operations, community management, or anything else a rapidly scaling organization needs, you can help us too.Â </p>



<p>We are a group of 700+ volunteers and growing rapidly.  If youâd like to help, weâd love to have you.  If you might be interested in volunteering, click <a href="https://airtoall.org/community/">here</a>.  Donors click <a href="https://airtoall.org/donate/">here</a>.  Everyone else, please email me at <a href="mailto:steven@airtoall.org">steven@airtoall.org</a> and include a clear subject line so I can direct you to the right person.</p></div>
    </content>
    <updated>2020-04-20T22:41:43Z</updated>
    <published>2020-04-20T22:41:43Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-04-23T18:03:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/04/20/workshop-on-local-algorithms/</id>
    <link href="https://cstheory-events.org/2020/04/20/workshop-on-local-algorithms/" rel="alternate" type="text/html"/>
    <title>Workshop on Local Algorithms</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 20-21, 2020 Virtual (8am â 12pm Pacific Time) https://www.mit.edu/~mahabadi/workshops/WOLA-2020.html Submission deadline: May 15, 2020 Registration deadline: June 30, 2020 Due to the current situation with COVID-19, we have decided to hold a virtual and shorter version of WOLA this year. WOLA 2020 will run for two days between 8am â 12pm PT to maximize â¦ <a class="more-link" href="https://cstheory-events.org/2020/04/20/workshop-on-local-algorithms/">Continue reading <span class="screen-reader-text">Workshop on LocalÂ Algorithms</span></a></div>
    </summary>
    <updated>2020-04-20T20:26:48Z</updated>
    <published>2020-04-20T20:26:48Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-04-29T23:21:12Z</updated>
    </source>
  </entry>
</feed>
