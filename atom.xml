<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-09-19T03:22:17Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.08608</id>
    <link href="http://arxiv.org/abs/1909.08608" rel="alternate" type="text/html"/>
    <title>Assignment and Pricing of Shared Rides in Ride-Sourcing using Combinatorial Double Auctions</title>
    <feedworld_mtime>1568851200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karamanis:Renos.html">Renos Karamanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Anastasiadis:Eleftherios.html">Eleftherios Anastasiadis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Angeloudis:Panagiotis.html">Panagiotis Angeloudis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stettler:Marc.html">Marc Stettler</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.08608">PDF</a><br/><b>Abstract: </b>Transportation Network Companies employ dynamic pricing methods at periods of
peak travel to incentivise driver participation and balance supply and demand
for rides. Surge pricing multipliers are commonly used and are applied
following demand and estimates of customer and driver trip valuations.
Combinatorial double auctions have been identified as a suitable alternative,
as they can achieve maximum social welfare in the allocation by relying on
customers and drivers stating their valuations. A shortcoming of current
models, however, is that they fail to account for the effects of trip detours
that take place in shared trips and their impact on the accuracy of pricing
estimates. To resolve this, we formulate a new shared-ride assignment and
pricing algorithm using combinatorial double auctions. We demonstrate that this
model is reduced to a maximum weighted independent set model, which is known to
be APX-hard. A fast local search heuristic is also presented, which is capable
of producing results that lie within 1% of the exact approach. Our proposed
algorithm could be used as a fast and reliable assignment and pricing mechanism
of ride-sharing requests to vehicles during peak travel times.
</p></div>
    </summary>
    <updated>2019-09-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.08544</id>
    <link href="http://arxiv.org/abs/1909.08544" rel="alternate" type="text/html"/>
    <title>Distance Geometry and Data Science</title>
    <feedworld_mtime>1568851200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liberti:Leo.html">Leo Liberti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.08544">PDF</a><br/><b>Abstract: </b>Data are often represented as graphs. Many common tasks in data science are
based on distances between entities. While some data science methodologies
natively take graphs as their input, there are many more that take their input
in vectorial form. In this survey we discuss the fundamental problem of mapping
graphs to vectors, and its relation with mathematical programming. We discuss
applications, solution methods, dimensional reduction techniques and some of
their limits. We then present an application of some of these ideas to neural
networks, showing that distance geometry techniques can give competitive
performance with respect to more traditional graph-to-vector mappings.
</p></div>
    </summary>
    <updated>2019-09-19T01:30:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-09-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.08519</id>
    <link href="http://arxiv.org/abs/1909.08519" rel="alternate" type="text/html"/>
    <title>Efficient Computation of Multi-Modal Public Transit Traffic Assignments using ULTRA</title>
    <feedworld_mtime>1568851200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sauer:Jonas.html">Jonas Sauer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wagner:Dorothea.html">Dorothea Wagner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Z=uuml=ndorf:Tobias.html">Tobias ZÃ¼ndorf</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.08519">PDF</a><br/><b>Abstract: </b>We study the problem of computing public transit traffic assignments in a
multi-modal setting: Given a public transit timetable, an additional
unrestricted transfer mode (in our case walking), and a set of
origin-destination pairs, we aim to compute the utilization of every vehicle in
the network. While it has been shown that considering unrestricted transfers
can significantly improve journeys, computing such journeys efficiently remains
algorithmically challenging. Since traffic assignments require the computation
of millions of shortest paths, using a multi-modal network has previously not
been feasible. A recently proposed approach (ULTRA) enables efficient
algorithms with UnLimited TRAnsfers at the cost of a short preprocessing phase.
In this work we combine the ULTRA approach with a state-of-the-art assignment
algorithm, making multi-modal assignments practical. Careful algorithm
engineering results in a new public transit traffic assignment algorithm that
even outperforms the algorithm it builds upon, while enabling unlimited walking
which has not been considered previously. We conclude our work with an
extensive evaluation of the algorithm, showing its versatility and efficiency.
On our real world instance, the algorithm computes over 15 million unique
journeys in less than 17 seconds.
</p></div>
    </summary>
    <updated>2019-09-19T01:26:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.08435</id>
    <link href="http://arxiv.org/abs/1909.08435" rel="alternate" type="text/html"/>
    <title>A polynomial time approximation schema for maximum k-vertex cover in bipartite graphs</title>
    <feedworld_mtime>1568851200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paschos:Vangelis_Th=.html">Vangelis Th. Paschos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.08435">PDF</a><br/><b>Abstract: </b>The paper presents a polynomial time approximation schema for the
edge-weighted version of maximum k-vertex cover problem in bipartite graphs.
</p></div>
    </summary>
    <updated>2019-09-19T01:20:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.08426</id>
    <link href="http://arxiv.org/abs/1909.08426" rel="alternate" type="text/html"/>
    <title>When Maximum Stable Set can be solved in FPT time</title>
    <feedworld_mtime>1568851200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonnet:=Eacute=douard.html">Ãdouard Bonnet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bousquet:Nicolas.html">Nicolas Bousquet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thomass=eacute=:St=eacute=phan.html">StÃ©phan ThomassÃ©</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Watrigant:R=eacute=mi.html">RÃ©mi Watrigant</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.08426">PDF</a><br/><b>Abstract: </b>Maximum Independent Set (MIS for short) is in general graphs the paradigmatic
$W[1]$-hard problem. In stark contrast, polynomial-time algorithms are known
when the inputs are restricted to structured graph classes such as, for
instance, perfect graphs (which includes bipartite graphs, chordal graphs,
co-graphs, etc.) or claw-free graphs. In this paper, we introduce some variants
of co-graphs with parameterized noise, that is, graphs that can be made into
disjoint unions or complete sums by the removal of a certain number of vertices
and the addition/deletion of a certain number of edges per incident vertex,
both controlled by the parameter. We give a series of FPT Turing-reductions on
these classes and use them to make some progress on the parameterized
complexity of MIS in $H$-free graphs. We show that for every fixed $t \geqslant
1$, MIS is FPT in $P(1,t,t,t)$-free graphs, where $P(1,t,t,t)$ is the graph
obtained by substituting all the vertices of a four-vertex path but one end of
the path by cliques of size $t$. We also provide randomized FPT algorithms in
dart-free graphs and in cricket-free graphs. This settles the FPT/W[1]-hard
dichotomy for five-vertex graphs $H$.
</p></div>
    </summary>
    <updated>2019-09-19T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.08417</id>
    <link href="http://arxiv.org/abs/1909.08417" rel="alternate" type="text/html"/>
    <title>Persistence B-Spline Grids: Stable Vector Representation of Persistence Diagrams Based on Data Fitting</title>
    <feedworld_mtime>1568851200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Zhetong Dong, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Hongwei.html">Hongwei Lin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Chi.html">Chi Zhou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.08417">PDF</a><br/><b>Abstract: </b>Over the last decades, many attempts have been made to optimally integrate
machine learning (ML) and topological data analysis. A prominent problem in
applying persistent homology to ML tasks is finding a vector representation of
a persistence diagram (PD), which is a summary diagram for representing
topological features. From the perspective of data fitting, a stable vector
representation, persistence B-spline grid (PB), is proposed based on the
efficient technique of progressive-iterative approximation for least-squares
B-spline surface fitting. Meanwhile, we theoretically prove that the PB method
is stable with respect to the metrics defined on the PD space, i.e., the
$p$-Wasserstein distance and the bottleneck distance. The proposed method was
tested on a synthetic dataset, datasets of randomly generated PDs, data of a
dynamical system, and 3D CAD models.
</p></div>
    </summary>
    <updated>2019-09-19T01:31:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-09-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.08369</id>
    <link href="http://arxiv.org/abs/1909.08369" rel="alternate" type="text/html"/>
    <title>Message Reduction in the Local Model is a Free Lunch</title>
    <feedworld_mtime>1568851200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bitton:Shimon.html">Shimon Bitton</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Emek:Yuval.html">Yuval Emek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Izumi:Taisuke.html">Taisuke Izumi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kutten:Shay.html">Shay Kutten</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.08369">PDF</a><br/><b>Abstract: </b>A new \emph{spanner} construction algorithm is presented, working under the
\emph{LOCAL} model with unique edge IDs. Given an $n$-node communication graph,
a spanner with a constant stretch and $O (n^{1 + \varepsilon})$ edges (for an
arbitrarily small constant $\varepsilon &gt; 0$) is constructed in a constant
number of rounds sending $O (n^{1 + \varepsilon})$ messages whp. Consequently,
we conclude that every $t$-round LOCAL algorithm can be transformed into an $O
(t)$-round LOCAL algorithm that sends $O (t \cdot n^{1 + \varepsilon})$
messages whp. This improves upon all previous message-reduction schemes for
LOCAL algorithms that incur a $\log^{\Omega (1)} n$ blow-up of the round
complexity.
</p></div>
    </summary>
    <updated>2019-09-19T01:25:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.08307</id>
    <link href="http://arxiv.org/abs/1909.08307" rel="alternate" type="text/html"/>
    <title>Hypergraph partitions</title>
    <feedworld_mtime>1568851200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mishchenko:Alexander.html">Alexander Mishchenko</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manuilov:Vladimir.html">Vladimir Manuilov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/You:Chao.html">Chao You</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Han.html">Han Yang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.08307">PDF</a><br/><b>Abstract: </b>We suggest a reduction of the combinatorial problem of hypergraph
partitioning to a continuous optimization problem.
</p></div>
    </summary>
    <updated>2019-09-19T01:23:13Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.08263</id>
    <link href="http://arxiv.org/abs/1909.08263" rel="alternate" type="text/html"/>
    <title>Distributed Answer Set Coloring: Stable Models Computation via Graph Coloring</title>
    <feedworld_mtime>1568851200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bortoli:Marco_De.html">Marco De Bortoli</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.08263">PDF</a><br/><b>Abstract: </b>Answer Set Programming (ASP) is a famous logic language for knowledge
representation, which has been really successful in the last years, as
witnessed by the great interest into the development of efficient solvers for
ASP. Yet, the great request of resources for certain types of problems, as the
planning ones, still constitutes a big limitation for problem solving.
Particularly, in the case the program is grounded before the resolving phase,
an exponential blow up of the grounding can generate a huge ground file,
infeasible for single machines with limited resources, thus preventing even the
discovering of a single non-optimal solution. To address this problem, in this
paper we present a distributed approach to ASP solving, exploiting distributed
computation benefits in order to overcome the just explained limitations. The
here presented tool, which is called Distributed Answer Set Coloring (DASC), is
a pure solver based on the well-known Graph Coloring algorithm. DASC is part of
a bigger project aiming to bring logic programming into a distributed system,
started in 2017 by Federico Igne with mASPreduce and continued in 2018 by
Pietro Totis with a distributed grounder. In this paper we present a low level
implementation of the Graph Coloring algorithm, via the Boost and MPI libraries
for C++. Finally, we provide a few results of the very first working version of
our tool, at the moment without any strong optimization or heuristic.
</p></div>
    </summary>
    <updated>2019-09-19T01:22:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.08233</id>
    <link href="http://arxiv.org/abs/1909.08233" rel="alternate" type="text/html"/>
    <title>Epistemic Logic Programs: A Different World View</title>
    <feedworld_mtime>1568851200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Morak:Michael.html">Michael Morak</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.08233">PDF</a><br/><b>Abstract: </b>Epistemic Logic Programs (ELPs), an extension of Answer Set Programming (ASP)
with epistemic operators, have received renewed attention from the research
community in recent years. Classically, evaluating an ELP yields a set of world
views, with each being a set of answer sets. In this paper, we propose an
alternative definition of world views that represents them as three-valued
assignments, where each atom can be either always true, always false, or
neither. Based on several examples, we show that this definition is natural and
intuitive. We also investigate relevant computational properties of these new
semantics, and explore how other notions, like strong equivalence, are
affected.
</p></div>
    </summary>
    <updated>2019-09-19T01:21:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.08065</id>
    <link href="http://arxiv.org/abs/1909.08065" rel="alternate" type="text/html"/>
    <title>Deterministic algorithms for the Lovasz Local Lemma: simpler, more general, and more parallel</title>
    <feedworld_mtime>1568851200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harris:David_G=.html">David G. Harris</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.08065">PDF</a><br/><b>Abstract: </b>The Lovasz Local Lemma (LLL) is a keystone principle in probability theory,
guaranteeing the existence of configurations which avoid a collection $\mathcal
B$ of "bad" events which are mostly independent and have low probability. In
its simplest "symmetric" form, it asserts that whenever a bad-event has
probability $p$ and affects at most $d$ bad-events, and $e p d &lt; 1$, then a
configuration avoiding all $\mathcal B$ exists.
</p>
<p>A seminal algorithm of Moser &amp; Tardos (2010) gives nearly-automatic
randomized algorithms for most constructions based on the LLL. However,
deterministic algorithms have lagged behind. We address three specific
shortcomings of the prior deterministic algorithms. First, our algorithm
applies to the LLL criterion of Shearer (1985); this is more powerful than
alternate LLL criteria and also removes a number of nuisance parameters and
leads to cleaner and more legible bounds. Second, we provide parallel
algorithms with much greater flexibility in the functional form of of the
bad-events. Third, we provide a derandomized version of the MT-distribution,
that is, the distribution of the variables at the termination of the MT
algorithm.
</p>
<p>We show applications to non-repetitive vertex coloring, independent
transversals, strong coloring, and other problems. These give deterministic
algorithms which essentially match the best previous randomized sequential and
parallel algorithms.
</p></div>
    </summary>
    <updated>2019-09-19T01:23:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.08006</id>
    <link href="http://arxiv.org/abs/1909.08006" rel="alternate" type="text/html"/>
    <title>Leyenda: An Adaptive, Hybrid Sorting Algorithm for Large Scale Data with Limited Memory</title>
    <feedworld_mtime>1568851200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shi:Yuanjing.html">Yuanjing Shi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Zhaoxing.html">Zhaoxing Li</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.08006">PDF</a><br/><b>Abstract: </b>Sorting is the one of the fundamental tasks of modern data management
systems. With Disk I/O being the most-accused performance bottleneck and more
computation-intensive workloads, it has come to our attention that in
heterogeneous environment, performance bottleneck may vary among different
infrastructure. As a result, sort kernels need to be adaptive to changing
hardware conditions. In this paper, we propose Leyenda, a hybrid, parallel and
efficient Radix Most-Significant-Bit (MSB) MergeSort algorithm, with
utilization of local thread-level CPU cache and efficient disk/memory I/O.
Leyenda is capable of performing either internal or external sort efficiently,
based on different I/O and processing conditions. We benchmarked Leyenda with
three different workloads from Sort Benchmark, targeting three unique use
cases, including internal, partially in-memory and external sort, and we found
Leyenda to outperform GNU's parallel in-memory quick/merge sort implementations
by up to three times. Leyenda is also ranked the second best external sort
algorithm on ACM 2019 SIGMOD programming contest and forth overall.
</p></div>
    </summary>
    <updated>2019-09-19T01:25:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-19T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=367</id>
    <link href="https://tcsplus.wordpress.com/2019/09/18/tcs-talk-wednesday-september-25-mark-sellke-stanford/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, September 25 â Mark Sellke, Stanford</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, September 25th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Mark Sellke from Stanford will speak about âChasing Convex Bodiesâ (abstract below). Please make sure you reserve a spot for your group to join us live by signing [â¦]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, September 25th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Mark Sellke</strong> from Stanford will speak about â<em>Chasing Convex Bodies</em>â (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: I will explain our recent understanding of the chasing convex bodies problem posed by Friedman and Linial in 1991. In this problem, an online player receives a request sequence <img alt="K_1,\dots,K_T" class="latex" src="https://s0.wp.com/latex.php?latex=K_1%2C%5Cdots%2CK_T&amp;bg=fff&amp;fg=444444&amp;s=0" title="K_1,\dots,K_T"/> of convex sets in <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=fff&amp;fg=444444&amp;s=0" title="d"/> dimensional space and moves his position online into each requested set. The playerâs movement cost is the length of the resulting path. Chasing convex bodies asks if there an online algorithm with cost competitive against the offline optimal path. This is both an challenging metrical task system and (equivalent to) a competitive analysis view on online convex optimization.</p>
<p>This problem was open for <img alt="d&gt;2" class="latex" src="https://s0.wp.com/latex.php?latex=d%3E2&amp;bg=fff&amp;fg=444444&amp;s=0" title="d&gt;2"/> until last year but has recently been solved twice. The first solution gives a <img alt="2^{O(d)}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BO%28d%29%7D&amp;bg=fff&amp;fg=444444&amp;s=0" title="2^{O(d)}"/> competitive algorithm while the second gives a nearly optimal <img alt="\min(d,\sqrt(d\log(T)))" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmin%28d%2C%5Csqrt%28d%5Clog%28T%29%29%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\min(d,\sqrt(d\log(T)))"/> competitive algorithm for <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=fff&amp;fg=444444&amp;s=0" title="T"/> requests. The latter result is based on the Steiner point, which is the exact optimal solution to a related geometric problem called Lipschitz selection and dates from 1840. In the talk, I will briefly outline the first solution and fully explain the second.</p>
<p>Partially based on joint works with SÃ©bastien Bubeck, Boâaz Klartag, Yin Tat Lee, and Yuanzhi Li.</p></blockquote>
<p>Â </p></div>
    </content>
    <updated>2019-09-18T19:57:34Z</updated>
    <published>2019-09-18T19:57:34Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2019-09-19T03:21:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7551</id>
    <link href="https://windowsontheory.org/2019/09/18/swiss-tcs-winter-school-guest-post-by-david-steurer/" rel="alternate" type="text/html"/>
    <title>Swiss TCS winter school (guest post by David Steurer)</title>
    <summary>[Guest post by David Steurer â seems like a great opportunity! âBoaz] The Swiss Winter School on Lower Bounds and Communication Complexity (10-14 February 2020, https://theory.epfl.ch/WinterSchool2020/ ) is the first in a series of annual winter schools in Theoretical Computer Science jointly organized by EPFL and ETH Zurich. The goal of the school is to [â¦]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>[Guest post by David Steurer â seems like a great opportunity! âBoaz]</em></p>



<p>The <a href="https://theory.epfl.ch/WinterSchool2020/">Swiss Winter School on Lower Bounds and Communication Complexity</a> (10-14 February 2020, <a href="https://theory.epfl.ch/WinterSchool2020/" rel="nofollow">https://theory.epfl.ch/WinterSchool2020/</a> ) is the first in a series of annual winter schools in Theoretical Computer Science jointly organized by EPFL and ETH Zurich. The goal of the school is to educate top international theory PhD students about exciting recent developments in the field. The winter school will be held in Zinal, a mountain village in the Swiss Alps that has a long tradition of hosting academic workshops and that allows for nice excursions and stimulating discussions in a relaxed atmosphere.</p>



<p>This yearâs installment features an exciting trinity of speakers: Kasper Green Larsen (Data Structure Lower Bounds), Raghu Meka (Communication Complexity) and Amir Shpilka (Algebraic complexity). </p>



<p>The application deadline is November 15th 2019, and acceptance notifications will be sent by December 1st 2019. The application form is available at <a href="https://theory.epfl.ch/WinterSchool2020/" rel="nofollow">https://theory.epfl.ch/WinterSchool2020/</a>. Attendance of the winter school is free of charge and includes room and board (shared rooms).</p>



<p>Organizers: Michael Kapralov (EPFL),  David Steurer  (ETH) ,   Ola Svennson (EPFL) </p></div>
    </content>
    <updated>2019-09-18T12:36:54Z</updated>
    <published>2019-09-18T12:36:54Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2019-09-19T03:21:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07919</id>
    <link href="http://arxiv.org/abs/1909.07919" rel="alternate" type="text/html"/>
    <title>Combinatorial Algorithms for Edge-Disjoint $T$-Paths and Integer Free Multiflow</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iwata:Satoru.html">Satoru Iwata</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yokoi:Yu.html">Yu Yokoi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07919">PDF</a><br/><b>Abstract: </b>Let $G=(V,E)$ be a multigraph with a set $T\subseteq V$ of terminals. A path
in $G$ is called a $T$-path if its ends are distinct vertices in $T$ and no
internal vertices belong to $T$. In 1978, Mader showed a characterization of
the maximum number of edge-disjoint $T$-paths. The original proof was not
constructive, and hence it did not suggest an efficient algorithm.
</p>
<p>In this paper, we provide a combinatorial, deterministic algorithm for
finding the maximum number of edge-disjoint $T$-paths. The algorithm adopts an
augmenting path approach. More specifically, we introduce a novel concept of
augmenting walks in auxiliary labeled graphs to capture a possible augmentation
of the number of edge-disjoint $T$-paths. To design a search procedure for an
augmenting walk, we introduce blossoms analogously to the matching algorithm of
Edmonds (1965), while it is neither a special case nor a generalization of the
present problem. When the search procedure terminates without finding an
augmenting walk, the algorithm provides a certificate for the optimality of the
current edge-disjoint $T$-paths. Thus the correctness argument of the algorithm
serves as an alternative direct proof of Mader's theorem on edge-disjoint
$T$-paths. The algorithm runs in $O(|V|\cdot |E|^2)$ time, which is much faster
than the best known deterministic algorithm based on a reduction to the linear
matroid parity problem.
</p>
<p>We also present a strongly polynomial algorithm for solving the integer free
multiflow problem, which asks for a nonnegative integer combination of
$T$-paths maximizing the sum of the coefficients subject to capacity
constraints on the edges.
</p></div>
    </summary>
    <updated>2019-09-18T23:28:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07854</id>
    <link href="http://arxiv.org/abs/1909.07854" rel="alternate" type="text/html"/>
    <title>Dynamic coloring for Bipartite and General Graphs</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kashyop:Manas_Jyoti.html">Manas Jyoti Kashyop</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narayanaswamy:N=_S=.html">N. S. Narayanaswamy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nasre:Meghana.html">Meghana Nasre</a>, Sai Mohith Potluri <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07854">PDF</a><br/><b>Abstract: </b>We consider the dynamic coloring problem on bipartite and general graphs in
the incremental as well as fully-dynamic settings. In this work, we are
interested in the following parameters : the update time and query time, the
number of colors used, and the number of vertex recolorings per update. Our
results reveal the following trade-off for a bipartite graph with $n$ vertices:
</p>
<p>In the fully dynamic setting, if we restrict the number of colors to $2$ then
the maximum of update and query time is at least $\log n$. In the incremental
setting, using $2$ colors we achieve the maximum of update and query time to be
$O(\alpha(n))$, where $\alpha(n)$ is the inverse Ackermann function.
</p>
<p>We show that by allowing more than two colors we can reduce the query time to
$O(1)$ without changing the update time. Our incremental algorithm uses $1+2
\log{n}$ colors.
</p>
<p>To the best of our knowledge, there are no known theoretical guarantees for
dynamic coloring specific to bipartite graphs. For general graphs we provide a
deterministic fully-dynamic algorithm with constant number of recolorings per
update.
</p>
<p>We use $\Delta+1$ colors and achieve $O(\sqrt{m})$ worst case update time
with at most one recoloring per update. Here $\Delta$ is the maximum degree of
a vertex and $m$ denotes the maximum number of edges throughout the update
sequence.
</p>
<p>For graphs of arboricity bounded by $\gamma$ we maintain a $\Delta+1$
coloring with at most one recoloring per update, an amortized update time of
$O(\gamma + \log{n})$, and an $O(1)$ query time.
</p></div>
    </summary>
    <updated>2019-09-18T23:24:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07816</id>
    <link href="http://arxiv.org/abs/1909.07816" rel="alternate" type="text/html"/>
    <title>The Computational Complexity of Fire Emblem Series and similar Tactical Role-Playing Games</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Jiawei.html">Jiawei Gao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07816">PDF</a><br/><b>Abstract: </b>Fire Emblem (FE) is a popular turn-based tactical role-playing game (TRPG)
series on the Nintendo gaming consoles. This paper studies the computational
complexity of FE, and proves that: 1. General FE is PSPACE-complete. 2.
Poly-round FE is NP-complete, even when the map is cycle-free. Poly-round FE is
to decide whether the player can win the game in a certain number of rounds
that is polynomial to the map size. A map is called cycle-free if its
corresponding planar graph is cycle-free. These hardness results also hold for
other similar TRPG series, such as Final Fantasy Tactics, Tactics Ogre and
Disgaea.
</p></div>
    </summary>
    <updated>2019-09-18T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07780</id>
    <link href="http://arxiv.org/abs/1909.07780" rel="alternate" type="text/html"/>
    <title>Preprocessing and Cutting Planes with Conflict Graphs</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brito:Samuel_S=.html">Samuel S. Brito</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santos:Haroldo_G=.html">Haroldo G. Santos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07780">PDF</a><br/><b>Abstract: </b>This paper addresses the implementation of conflict graph-based routines into
the COIN-OR Branch-and-Cut (CBC) solver, including: $(i)$ a conflict graph
infrastructure with an improved version of a state-of-the-art conflict
detection algorithm to quickly build conflict graphs; this version detects
additional conflicts and has the same worst-case complexity of the original
algorithm; $(ii)$ a preprocessing routine based on a clique-strengthening
scheme that can both reduce the number of nonzeros in the constraint matrix and
also produce stronger formulations; $(iii)$ a clique cut separator capable of
obtaining dual bounds at the root node that are $26\%$ stronger than the ones
provided by the equivalent cut generator of a state-of-the-art commercial
solver, $467\%$ stronger than those attained by the clique cut separator of the
GLPK solver and $500\%$ stronger than the dual bounds obtained by the clique
separation routine of the COIN-OR Cut Generation Library; $(iv)$ an odd-cycle
cut separator with a lifting module to produce valid odd-wheel inequalities.
This new version of CBC obtained an average gap closed that is $26\%$ better
than the previous one and solved $27\%$ more instances.
</p></div>
    </summary>
    <updated>2019-09-18T23:21:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07703</id>
    <link href="http://arxiv.org/abs/1909.07703" rel="alternate" type="text/html"/>
    <title>Multi-robot persistent surveillance with connectivity constraints</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scherer:J=uuml=rgen.html">JÃ¼rgen Scherer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rinner:Bernhard.html">Bernhard Rinner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07703">PDF</a><br/><b>Abstract: </b>Mobile robots, especially unmanned aerial vehicles (UAVs), are of increasing
interest for surveillance and disaster response scenarios. We consider the
problem of multi-robot persistent surveillance with connectivity constraints
where robots have to visit sensing locations periodically and maintain a
multi-hop connection to a base station. We formally define several problem
instances closely related to multi-robot persistent surveillance with
connectivity constraints, i.e., connectivity-constrained multi-robot persistent
surveillance (CMPS), connectivity-constrained multi-robot reachability (CMR),
and connectivity-constrained multi-robot reachability with relay dropping
(CMRD), and show that they are all NP-hard on general graph. We introduce three
heuristics with different planning horizons for convex grid graphs and combine
these with a tree traversal approach which can be applied to a partitioning of
non-convex grid graphs (CMPS with tree traversal, CMPSTT). In simulation
studies we show that a short horizon greedy approach, which requires parameters
to be optimized beforehand, can outperform a full horizon approach, which
requires a tour through all sensing locations, if the number of robots is
larger than the minimum number of robots required to reach all sensing
locations. The minimum number required is the number of robots necessary for
building a chain to the farthest sensing location from the base station.
Furthermore, we show that partitioning the area and applying the tree traversal
approach can achieve a performance similar to the unpartitioned case up to a
certain number of robots but requires less optimization time.
</p></div>
    </summary>
    <updated>2019-09-18T23:27:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07647</id>
    <link href="http://arxiv.org/abs/1909.07647" rel="alternate" type="text/html"/>
    <title>A heuristic use of dynamic programming to upperbound treewidth</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tamaki:Hisao.html">Hisao Tamaki</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07647">PDF</a><br/><b>Abstract: </b>For a graph $G$, let $\Omega(G)$ denote the set of all potential maximal
cliques of $G$. For each subset $\Omega$ of $\Omega(G)$, let $\tw(G, \Omega)$
denote the smallest $k$ such that there is a tree-decomposition of $G$ of width
$k$ whose bags all belong to $\Omega$. Bouchitt\'{e} and Todinca observed in
2001 that $\tw(G, \Omega(G))$ is exactly the treewidth of $G$ and developed a
dynamic programming algorithm to compute it. Indeed, their algorithm can
readily be applied to an arbitrary non-empty subset $\Omega$ of $\Omega(G)$ and
computes $\tw(G, \Omega)$, or reports that it is undefined, in time
$|\Omega||V(G)|^{O(1)}$. This efficient tool for computing $\tw(G, \Omega)$
allows us to conceive of an iterative improvement procedure for treewidth upper
bounds which maintains, as the current solution, a set of potential maximal
cliques rather than a tree-decomposition.
</p>
<p>We design and implement an algorithm along this approach. Experiments show
that our algorithm vastly outperforms previously implemented heuristic
algorithms for treewidth.
</p></div>
    </summary>
    <updated>2019-09-18T23:25:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07633</id>
    <link href="http://arxiv.org/abs/1909.07633" rel="alternate" type="text/html"/>
    <title>Communication-Efficient Weighted Sampling and Quantile Summary for GBDT</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Ziyue.html">Ziyue Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yi:Ke.html">Ke Yi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07633">PDF</a><br/><b>Abstract: </b>Gradient boosting decision tree (GBDT) is a powerful and widely-used machine
learning model, which has achieved state-of-the-art performance in many
academic areas and production environment. However, communication overhead is
the main bottleneck in distributed training which can handle the massive data
nowadays. In this paper, we propose two novel communication-efficient methods
over distributed dataset to mitigate this problem, a weighted sampling approach
by which we can estimate the information gain over a small subset efficiently,
and distributed protocols for weighted quantile problem used in approximate
tree learning.
</p></div>
    </summary>
    <updated>2019-09-18T23:27:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07557</id>
    <link href="http://arxiv.org/abs/1909.07557" rel="alternate" type="text/html"/>
    <title>Object Reachability via Swaps under Strict and Weak Preferences</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Sen.html">Sen Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xiao:Mingyu.html">Mingyu Xiao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07557">PDF</a><br/><b>Abstract: </b>The \textsc{Housing Market} problem is a widely studied resource allocation
problem. In this problem, each agent can only receive a single object and has
preferences over all objects. Starting from an initial endowment, we want to
reach a certain assignment via a sequence of rational trades. We first consider
whether an object is reachable for a given agent under a social network, where
a trade between two agents is allowed if they are neighbors in the network and
no participant has a deficit from the trade. Assume that the preferences of the
agents are strict (no tie among objects is allowed). This problem is
polynomially solvable in a star-network and NP-complete in a tree-network. It
is left as a challenging open problem whether the problem is polynomially
solvable when the network is a path. We answer this open problem positively by
giving a polynomial-time algorithm. Then we show that when the preferences of
the agents are weak (ties among objects are allowed), the problem becomes
NP-hard even when the network is a path. In addition, we consider the
computational complexity of finding different optimal assignments for the
problem under the network being a path or a star.
</p></div>
    </summary>
    <updated>2019-09-18T23:27:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07538</id>
    <link href="http://arxiv.org/abs/1909.07538" rel="alternate" type="text/html"/>
    <title>Generalized Dictionary Matching under Substring Consistent Equivalence Relations</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hendrian:Diptarama.html">Diptarama Hendrian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07538">PDF</a><br/><b>Abstract: </b>Given a set of patterns called a dictionary and a text, the dictionary
matching problem is a task to find all occurrence positions of all patterns in
the text. The dictionary matching problem can be solved efficiently by using
the Aho-Corasick algorithm. Recently, Matsuoka et al. [TCS, 2016] proposed a
generalization of pattern matching problem under substring consistent
equivalence relations and presented a generalization of the Knuth-Morris-Pratt
algorithm to solve this problem. An equivalence relation $\approx$ is a
substring consistent equivalence relation (SCER) if for two strings $X,Y$, $X
\approx Y$ implies $|X| = |Y|$ and $X[i:j] \approx Y[i:j]$ for all $1 \le i \le
j \le |X|$. In this paper, we propose a generalization of the dictionary
matching problem and present a generalization of the Aho-Corasick algorithm for
the dictionary matching under SCER. We present an algorithm that constructs
SCER automata and an algorithm that performs dictionary matching under SCER by
using the automata. Moreover, we show the time and space complexity of our
algorithms with respect to the size of input strings.
</p></div>
    </summary>
    <updated>2019-09-18T23:26:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07515</id>
    <link href="http://arxiv.org/abs/1909.07515" rel="alternate" type="text/html"/>
    <title>Multiplicative Rank-1 Approximation using Length-Squared Sampling</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaiswal:Ragesh.html">Ragesh Jaiswal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Amit.html">Amit Kumar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07515">PDF</a><br/><b>Abstract: </b>We show that the span of $\Omega(\frac{1}{\varepsilon^4})$ rows of any matrix
$A \subset \mathbb{R}^{n \times d}$ sampled according to the length-squared
distribution contains a rank-$1$ matrix $\tilde{A}$ such that $||A -
\tilde{A}||_F^2 \leq (1 + \varepsilon) \cdot ||A - \pi_1(A)||_F^2$, where
$\pi_1(A)$ denotes the best rank-$1$ approximation of $A$ under the Frobenius
norm. Length-squared sampling has previously been used in the context of
rank-$k$ approximation. However, the approximation obtained was additive in
nature. We obtain a multiplicative approximation albeit only for rank-$1$
approximation.
</p></div>
    </summary>
    <updated>2019-09-18T23:26:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07511</id>
    <link href="http://arxiv.org/abs/1909.07511" rel="alternate" type="text/html"/>
    <title>Streaming PTAS for Constrained k-Means</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goyal:Dishant.html">Dishant Goyal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaiswal:Ragesh.html">Ragesh Jaiswal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Amit.html">Amit Kumar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07511">PDF</a><br/><b>Abstract: </b>We generalise the results of Bhattacharya et al. (Journal of Computing
Systems, 62(1):93-115, 2018) for the list-$k$-means problem defined as -- for a
(unknown) partition $X_1, ..., X_k$ of the dataset $X \subseteq \mathbb{R}^d$,
find a list of $k$-center sets (each element in the list is a set of $k$
centers) such that at least one of $k$-center sets $\{c_1, ..., c_k\}$ in the
list gives an $(1+\varepsilon)$-approximation with respect to the cost function
$\min_{\textrm{permutation } \pi} \left[ \sum_{i=1}^{k} \sum_{x \in X_i} ||x -
c_{\pi(i)}||^2 \right]$. The list-$k$-means problem is important for the
constrained $k$-means problem since algorithms for the former can be converted
to PTAS for various versions of the latter. Following are the consequences of
our generalisations:
</p>
<p>- Streaming algorithm: Our $D^2$-sampling based algorithm running in a single
iteration allows us to design a 2-pass, logspace streaming algorithm for the
list-$k$-means problem. This can be converted to a 4-pass, logspace streaming
PTAS for various constrained versions of the $k$-means problem. To the best of
our knowledge, these are the first constant pass, logspace streaming PTASs for
constrained versions of the $k$-means problem.
</p>
<p>- Faster PTAS under stability: Our generalisation is also useful in $k$-means
clustering scenarios where finding good centers becomes easy once good centers
for a few "bad" clusters have been chosen. One such scenario is clustering
under stability where the number of such bad clusters is a constant. Using the
above idea, we significantly improve the running time of the known algorithm
from $O(dn^3) (k \log{n})^{poly(\frac{1}{\beta}, \frac{1}{\varepsilon})}$ to $O
\left(dn^3 k^{\tilde{O}_{\beta \varepsilon}(\frac{1}{\beta \varepsilon})}
\right)$.
</p></div>
    </summary>
    <updated>2019-09-18T23:25:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07498</id>
    <link href="http://arxiv.org/abs/1909.07498" rel="alternate" type="text/html"/>
    <title>Vanishing-Error Approximate Degree and QMA Complexity</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sherstov:Alexander_A=.html">Alexander A. Sherstov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thaler:Justin.html">Justin Thaler</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07498">PDF</a><br/><b>Abstract: </b>The $\epsilon$-approximate degree of a function $f\colon X \to \{0, 1\}$ is
the least degree of a multivariate real polynomial $p$ such that $|p(x)-f(x)|
\leq \epsilon$ for all $x \in X$. We determine the $\epsilon$-approximate
degree of the element distinctness function, the surjectivity function, and the
permutation testing problem, showing they are $\Theta(n^{2/3}
\log^{1/3}(1/\epsilon))$, $\tilde\Theta(n^{3/4} \log^{1/4}(1/\epsilon))$, and
$\Theta(n^{1/3} \log^{2/3}(1/\epsilon))$, respectively. Previously, these
bounds were known only for constant $\epsilon.$
</p>
<p>We also derive a connection between vanishing-error approximate degree and
quantum Merlin--Arthur (QMA) query complexity. We use this connection to show
that the QMA complexity of permutation testing is $\Omega(n^{1/4})$. This
improves on the previous best lower bound of $\Omega(n^{1/6})$ due to Aaronson
(Quantum Information &amp; Computation, 2012), and comes somewhat close to matching
a known upper bound of $O(n^{1/3})$.
</p></div>
    </summary>
    <updated>2019-09-18T23:21:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07446</id>
    <link href="http://arxiv.org/abs/1909.07446" rel="alternate" type="text/html"/>
    <title>Three-in-a-Tree in Near Linear Time</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Kai-Yuan Lai, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Hsueh=I.html">Hsueh-I Lu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thorup:Mikkel.html">Mikkel Thorup</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07446">PDF</a><br/><b>Abstract: </b>The three-in-a-tree problem is to determine if a simple undirected graph
contains an induced subgraph which is a tree connecting three given vertices.
Based on a beautiful characterization that is proved in more than twenty pages,
Chudnovsky and Seymour [Com-binatorica 2010] gave the previously only known
polynomial-time algorithm, running in $O(mn^2)$ time, to solve the
three-in-a-tree problem on an $n$-vertex $m$-edge graph. Their three-in-a-tree
algorithm has become a critical subroutine in several state-of-the-art graph
recognition and detection algorithms.
</p>
<p>In this paper we solve the three-in-a-tree problem in $\tilde{O}(m)$ time,
leading to improved algorithms for recognizing perfect graphs and detecting
thetas, pyramids, beetles, and odd and even holes. Our result is based on a new
and more constructive characterization than that of Chudnovsky and Seymour. Our
new characterization is stronger than the original, and our proof implies a new
simpler proof for the original characterization. The improved characterization
gains the first factor $n$ in speed. The remaining improvement is based on
dynamic graph algorithms.
</p></div>
    </summary>
    <updated>2019-09-18T23:22:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07420</id>
    <link href="http://arxiv.org/abs/1909.07420" rel="alternate" type="text/html"/>
    <title>Regular Partitions and Their Use in Structural Pattern Recognition</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fiorucci:Marco.html">Marco Fiorucci</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07420">PDF</a><br/><b>Abstract: </b>Recent years are characterized by an unprecedented quantity of available
network data which are produced at an astonishing rate by an heterogeneous
variety of interconnected sensors and devices. This high-throughput generation
calls for the development of new effective methods to store, retrieve,
understand and process massive network data. In this thesis, we tackle this
challenge by introducing a framework to summarize large graphs based on
Szemer\'edi's Regularity Remma (RL), which roughly states that any sufficiently
large graph can almost entirely be partitioned into a bounded number of
random-like bipartite graphs. The partition resulting from the RL gives rise to
a summary, which inherits many of the essential structural properties of the
original graph. We first extend an heuristic version of the RL to improve its
efficiency and its robustness. We use the proposed algorithm to address
graph-based clustering and image segmentation tasks. In the second part of the
thesis, we introduce a new heuristic algorithm which is characterized by an
improvement of the summary quality both in terms of reconstruction error and of
noise filtering. We use the proposed heuristic to address the graph search
problem defined under a similarity measure. Finally, we study the linkage among
the regularity lemma, the stochastic block model and the minimum description
length. This study provide us a principled way to develop a graph decomposition
algorithm based on stochastic block model which is fitted using likelihood
maximization.
</p></div>
    </summary>
    <updated>2019-09-18T23:27:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1909.07413</id>
    <link href="http://arxiv.org/abs/1909.07413" rel="alternate" type="text/html"/>
    <title>On Decoding Cohen-Haeupler-Schulman Tree Codes</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narayanan:Anand_Kumar.html">Anand Kumar Narayanan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weidner:Matthew.html">Matthew Weidner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1909.07413">PDF</a><br/><b>Abstract: </b>Tree codes, introduced by Schulman, are combinatorial structures essential to
coding for interactive communication. An infinite family of tree codes with
both rate and distance bounded by positive constants is called asymptotically
good. Rate being constant is equivalent to the alphabet size being constant.
Schulman proved that there are asymptotically good tree code families using the
Lovasz local lemma, yet their explicit construction remains an outstanding open
problem. In a major breakthrough, Cohen, Haeupler and Schulman constructed
explicit tree code families with constant distance, but over an alphabet
polylogarithmic in the length. Our main result is a randomized polynomial time
decoding algorithm for these codes making novel use of the polynomial method.
The number of errors corrected scales roughly as the block length to the
three-fourths power, falling short of the constant fraction error correction
guaranteed by the constant distance. We further present number theoretic
variants of Cohen-Haeupler-Schulman codes, all correcting a constant fraction
of errors with polylogarithmic alphabet size. Towards efficiently correcting
close to a constant fraction of errors, we propose a speculative convex
optimization approach inspired by compressed sensing.
</p></div>
    </summary>
    <updated>2019-09-18T23:20:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.09527</id>
    <link href="http://arxiv.org/abs/1901.09527" rel="alternate" type="text/html"/>
    <title>Envy-free Matchings in Bipartite Graphs and their Applications to Fair Division</title>
    <feedworld_mtime>1568764800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aigner=Horev:Elad.html">Elad Aigner-Horev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Segal=Halevi:Erel.html">Erel Segal-Halevi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.09527">PDF</a><br/><b>Abstract: </b>A matching in a bipartite graph $G:=(X + Y,E)$ is said to be envy-free if no
unmatched vertex in $X$ is adjacent to a mathced vertex in $Y$. Every perfect
matching is envy-free, but envy-free matchings may exist even when perfect
matchings do not.
</p>
<p>We provide a polynomial-time algorithm for finding an envy-free matching of
maximum cardinality. For edge-weighted bipartite graphs, we provide a
polynomial-time algorithm for finding a maximum-cardinality envy-free matching
of minimum weight.
</p>
<p>We show how envy-free matchings can be used in various fair division problems
with either continuous resources (``cakes'') or discrete ones. In particular,
we show a symmetric algorithm for proportional cake-cutting, and an algorithm
for $1$-out-of-$(2n-2)$ maximin-share allocation of discrete objects among $n$
agents.
</p></div>
    </summary>
    <updated>2019-09-18T23:24:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-09-18T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/125</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/125" rel="alternate" type="text/html"/>
    <title>TR19-125 |  Hardness Amplification of Optimization Problems 	 | 

	Elazar Goldenberg, 

	Karthik  C. S.</title>
    <summary>In this paper, we prove a general hardness amplification scheme for optimization problems based on the technique of direct products.
  
We say that an optimization problem $\Pi$ is direct product feasible if it is possible to efficiently aggregate any $k$ instances of $\Pi$ and form one large instance of $\Pi$ such that given an optimal feasible solution to the larger instance, we can efficiently find optimal feasible solutions to all the $k$ smaller instances. Given a direct product feasible optimization problem $\Pi$, our hardness amplification theorem may be informally stated as follows:
  
If there is a distribution $\mathcal{D}$ over instances of $\Pi$ of size $n$ such that every randomized algorithm running in time $t(n)$ fails to solve $\Pi$ on $\frac{1}{\alpha(n)}$ fraction of inputs sampled from $\mathcal{D}$, then, assuming some relationships on $\alpha(n)$ and $t(n)$, there is a distribution $\mathcal{D}'$ over instances of $\Pi$ of size $O(n\cdot \alpha(n))$ such that every randomized algorithm running in time $\frac{t(n)}{poly(\alpha(n))}$ fails to solve $\Pi$ on $\frac{99}{100}$ fraction of inputs sampled from $\mathcal{D}'$.
  
As a consequence of the above theorem, we show hardness amplification of problems in various classes such as NP-hard problems like Max-Clique, Knapsack, and Max-SAT, problems in P such as Longest Common Subsequence, Edit Distance, Matrix Multiplication, and even problems in TFNP such as Factoring and computing Nash equilibrium.</summary>
    <updated>2019-09-17T23:59:55Z</updated>
    <published>2019-09-17T23:59:55Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-19T03:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/124</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/124" rel="alternate" type="text/html"/>
    <title>TR19-124 |  Testing Odd Direct Sums Using High Dimensional Expanders | 

	Roy Gotlib, 

	Tali Kaufman</title>
    <summary>In this work, using methods from high dimensional expansion, we show that the property of $k$-direct-sum is testable for odd values of $k$ . Previous work of Kaufman and Lubotzky could inherently deal only with the case that $k$ is even, using a reduction to linearity testing.
Interestingly, our work is the first to combine the topological notion of high dimensional expansion (called co-systolic expansion) with the combinatorial/spectral notion of high dimensional expansion (called colorful expansion) to obtain the result.

The classical $k$-direct-sum problem applies to the complete complex; Namely it considers a function defined over all $k$-subsets of some $n$ sized universe. Our result here applies to any collection of $k$-subsets of an $n$-universe, assuming this collection of subsets forms a high dimensional expander.</summary>
    <updated>2019-09-17T00:04:22Z</updated>
    <published>2019-09-17T00:04:22Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-19T03:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/123</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/123" rel="alternate" type="text/html"/>
    <title>TR19-123 |  On the Hardness of Robust Classification | 

	Pascale Gourdeau, 

	Varun Kanade, 

	Marta Kwiatkowska, 

	James Worrell</title>
    <summary>It is becoming increasingly important to understand the vulnerability of machine learning models to adversarial attacks. In this paper we study the feasibility of robust learning from the perspective of computational learning theory, considering both sample and computational complexity. In particular, our definition of robust learnability requires polynomial sample complexity. We start with two negative results. We show that no non-trivial concept class can be robustly learned in the distribution-free setting against an adversary who can perturb just a single input bit. We show moreover that the class of monotone conjunctions cannot be robustly learned under the uniform distribution against an adversary who can perturb $\omega(\log n)$ input bits. However if the adversary is restricted to perturbing $O(\log n)$ bits, then the class of monotone conjunctions can be robustly learned with respect to a general class of distributions (that includes the uniform distribution). Finally, we provide a simple proof of the computational hardness of robust learning on the boolean hypercube. Unlike previous results of this nature, our result does not rely on another computational model (e.g. the statistical query model) nor on any hardness assumption other than the existence of a hard learning problem in the PAC framework.</summary>
    <updated>2019-09-17T00:00:40Z</updated>
    <published>2019-09-17T00:00:40Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-19T03:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/122</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/122" rel="alternate" type="text/html"/>
    <title>TR19-122 |  LDPC Codes Achieve List-Decoding Capacity | 

	Jonathan Mosheiff, 

	Nicolas Resch, 

	Noga Ron-Zewi, 

	Shashwat Silas, 

	Mary Wootters</title>
    <summary>We show that Gallager's ensemble of Low-Density Parity Check (LDPC) codes achieve list-decoding capacity. These are the first graph-based codes shown to have this property. Previously, the only codes known to achieve list-decoding capacity were completely random codes, random linear codes, and codes constructed by algebraic (rather than combinatorial) techniques. This result opens up a potential avenue towards truly linear-time list-decodable codes which achieve list-decoding capacity.

Our result on list decoding follows from a much more general result: any local property satisfied with high probability by a random linear code is also satisfied with high probability by a random LDPC code from Gallager's distribution. Local properties are properties characterized by the exclusion of small sets of codewords, and include list-decoding, list-recovery and average-radius list-decoding. Along the way, we give a characterization of sets of codewords that are likely to appear in a random linear code, which may be of independent interest.</summary>
    <updated>2019-09-16T23:58:26Z</updated>
    <published>2019-09-16T23:58:26Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-19T03:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/121</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/121" rel="alternate" type="text/html"/>
    <title>TR19-121 |  Vanishing-Error Approximate Degree and QMA Complexity | 

	Justin Thaler, 

	Alexander A. Sherstov</title>
    <summary>The $\epsilon$-approximate degree of a function $f\colon X \to \{0, 1\}$ is the least degree of a multivariate real polynomial $p$ such that $|p(x)-f(x)| \leq \epsilon$ for all $x \in X$. We determine the $\epsilon$-approximate degree of the element distinctness function, the surjectivity function, and the permutation testing problem, showing they are $\Theta(n^{2/3} \log^{1/3}(1/\epsilon))$, $\tilde\Theta(n^{3/4} \log^{1/4}(1/\epsilon))$, and  $\Theta(n^{1/3} \log^{2/3}(1/\epsilon))$, respectively. Previously, these bounds were known only for constant $\epsilon.$ 

We also derive a connection between vanishing-error approximate degree and quantum Merlin--Arthur (QMA) query complexity. We use this connection to show that the QMA complexity of permutation testing is $\Omega(n^{1/4})$. This improves on the previous best lower bound of $\Omega(n^{1/6})$ due to Aaronson (Quantum Information &amp; Computation, 2012), and comes somewhat close to matching a known upper bound of $O(n^{1/3})$.</summary>
    <updated>2019-09-16T23:55:59Z</updated>
    <published>2019-09-16T23:55:59Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-09-19T03:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16239</id>
    <link href="https://rjlipton.wordpress.com/2019/09/16/separating-words-decoding-a-paper/" rel="alternate" type="text/html"/>
    <title>Separating Words: Decoding a Paper</title>
    <summary>A clever trick on combining automata John Robson has worked on various problems including what is still the best result on separating wordsâthe topic we discussed the other day. Ken first knew him for his proof than checkers is -complete and similar hardness results for chess and Go. Today I want to talk about his [â¦]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>A clever trick on combining automata</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/09/16/separating-words-decoding-a-paper/unknown-128/" rel="attachment wp-att-16242"><img alt="" class="alignright  wp-image-16242" src="https://rjlipton.files.wordpress.com/2019/09/unknown-2.jpeg?w=190" width="190"/></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p>
John Robson has worked on various problems including what is still the best result on separating wordsâthe topic we discussed the other <a href="https://rjlipton.wordpress.com/2019/09/08/separating-words-by-automata/">day</a>. Ken first knew him for his <a href="https://epubs.siam.org/doi/10.1137/0213018">proof</a> than <img alt="{N \times N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%5Ctimes+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N \times N}"/> checkers is <img alt="{\mathsf{EXPTIME}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BEXPTIME%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{EXPTIME}}"/>-complete and similar hardness results for chess and Go.</p>
<p>
Today I want to talk about his theorem that any two words can be separated by an automaton with relataivley few states.</p>
<p>
In his famous paper from 1989, he proved an upper bound on the <i>Separating Word Problem</i>. This is the question: Given two strings <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>, how many states does a deterministic automaton need to be able to accept <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> and reject <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/>? His theorem is:</p>
<blockquote><p><b>Theorem 1 (Robsonâs Theorem)</b> <em> Suppose that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T}"/> are distinct strings of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>. Then there is an automaton with at most <img alt="{O(n^{0.4}\log^{0.6} n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%7B0.4%7D%5Clog%5E%7B0.6%7D+n%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{O(n^{0.4}\log^{0.6} n)}"/> states that accepts <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> and rejects <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T}"/>. </em>
</p></blockquote>
<p/><p>
The story of his result is involved. For starters, it is still the best upper bound after almost three decades. Impressive. Another issue is that a web search does not quickly, at least for for me, find a PDF of the original paper. I tried to find it and could not. More recent papers on the separating word problem reference his 1989 paper, but they do not explain how he proves it. </p>
<p>
Recall the problem of separating words is: Given two distinct words of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, is there a deterministic finite automaton that accepts one and rejects the other? And the machine has as few states as possible. Thus his theorem shows that roughly the number of states grows at most like the square root of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. </p>
<p>
I did finally track the paper down. The trouble for me is the paper is encrypted. Well not exactly, but the version I did find is a poor copy of the original. Here is an example to show what I mean:</p>
<p/><p/>
<p>&lt;/tr</p><table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/09/16/separating-words-decoding-a-paper/r/" rel="attachment wp-att-16248"><img alt="" class="aligncenter size-medium wp-image-16248" height="137" src="https://rjlipton.files.wordpress.com/2019/09/r.png?w=300&amp;h=137" width="300"/></a>
</td>

</tr><tr>
<td class="caption alignright"><font size="-2">[ An Example ]</font>
</td>
</tr>
</tbody></table>
<p>
So the task of decoding the proof is a challenge. A challenge, but a rewarding one.</p>
<p>
</p><p/><h2> A Cool Trick </h2><p/>
<p/><p>
Robsonâs proof uses two insights. The first is he uses some basic <a href="http://www.stringology.org">string-ology</a>. That is he uses some basic facts about strings. For example he uses that a non-periodic string cannot overlap itself too much.</p>
<p>
He also uses a clever trick on how to simulate two deterministic machines for the price of one. This in general is not possible, and is related to deep questions about automata that we have discussed before <a href="https://rjlipton.wordpress.com/2012/11/08/the-power-of-guessing/">here</a>. Robson shows that it can be done in a special but important case.</p>
<p>
Let me explain. Suppose that <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is a string. We can easily design an automaton that accepts <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> if and only if <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> is the string <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. The machine will have order the length of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> states. So far quite simple. </p>
<p>
Now suppose that we have a string <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and wish to find a particular occurrence of the pattern <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. We assume that there are <img alt="{\#(S,\alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%23%28S%2C%5Calpha%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\#(S,\alpha)}"/> occurrences of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. The task is to construct an automaton that accepts at the end of the <img alt="{k^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k^{th}}"/> copy of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. Robson shows that this can be done by a automaton that has order 	</p>
<p align="center"><img alt="\displaystyle  \#(S,\alpha) + |\alpha| " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%23%28S%2C%5Calpha%29+%2B+%7C%5Calpha%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \#(S,\alpha) + |\alpha| "/></p>
<p>Here <img alt="{|\alpha|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C%5Calpha%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|\alpha|}"/> is the length of the string <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>.</p>
<p>
This is a simple, clever, and quite useful observation. Clever indeed. The obvious automaton that can do this would seem to require a cartesian product of two machines. This would imply that it would require 	</p>
<p align="center"><img alt="\displaystyle  \#(S,\alpha) \times |\alpha| " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%23%28S%2C%5Calpha%29+%5Ctimes+%7C%5Calpha%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \#(S,\alpha) \times |\alpha| "/></p>
<p>number of states: Note the times operator <img alt="{\times}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctimes%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\times}"/> rather than addition. Thus Robsonâs trick is a huge improvement.</p>
<p>
Here is how he does this.</p>
<p>
</p><p/><h2> His Trick </h2><p/>
<p/><p>
Robsonâs uses a clever trick in his proof of the main lemma. Letâs work through an example with the string <img alt="{100}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B100%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{100}"/>. The goal is to see if there is a copy of this string starting at a position that is a multiple of <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/>.</p>
<p>
The machine starts in state <img alt="{(0,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%280%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(0,Y)}"/> and tries to find the correct string <img alt="{100}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B100%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{100}"/> as input. If it does, then it reaches the accepting state <img alt="{(3,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,Y)}"/>. If while doing this it gets a wrong input, then it switches to states that have stopped looking for the input <img alt="{100}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B100%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{100}"/>. After seeing three inputs the machine reaches <img alt="{(3,N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2CN%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3,N)}"/> and then moves back to the start state. </p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/09/16/separating-words-decoding-a-paper/rfig/" rel="attachment wp-att-16249"><img alt="" class="aligncenter  wp-image-16249" src="https://rjlipton.files.wordpress.com/2019/09/rfig.png?w=500" width="500"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ The automaton  ]</font>
</td>
</tr>
</tbody></table>
<p/><h2> The Lemmas </h2><p/>
<p>We will now outline the proof in some detail.</p>
<p>
</p><p/><h3> Hashing </h3><p/>
<p/><p>
The first lemma is a simple fact about hashing.</p>
<blockquote><p><b>Lemma 2</b> <em> Suppose <img alt="{1 \le r \le m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%5Cle+r+%5Cle+m%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{1 \le r \le m}"/> and 	</em></p><em>
<p align="center"><img alt="\displaystyle  1 \le k_{1} &lt; \cdots &lt; k_{m} \le n. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%5Cle+k_%7B1%7D+%3C+%5Ccdots+%3C+k_%7Bm%7D+%5Cle+n.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  1 \le k_{1} &lt; \cdots &lt; k_{m} \le n. "/></p>
<p>Then all but <img alt="{{O}(m \log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7BO%7D%28m+%5Clog+n%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{O}(m \log n)}"/> primes satisfy 	</p>
<p align="center"><img alt="\displaystyle  k_{i} \equiv k_{r} \bmod p \text{ if and only if } i =r. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++k_%7Bi%7D+%5Cequiv+k_%7Br%7D+%5Cbmod+p+%5Ctext%7B+if+and+only+if+%7D+i+%3Dr.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  k_{i} \equiv k_{r} \bmod p \text{ if and only if } i =r. "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Consider the quantity <img alt="{|k_{r} - k_{i}|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Ck_%7Br%7D+-+k_%7Bi%7D%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|k_{r} - k_{i}|}"/> for <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> not equal to <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/>. Call a prime <i>bad</i> if it divides this quantity. This quantity can be divisible by at most <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/> primes. So there are at most <img alt="{{O}(m\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7BO%7D%28m%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{O}(m\log n)}"/> bad primes in total. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
</p><p/><h3> Strings </h3><p/>
<p/><p>
We need some definitions about strings. Let <img alt="{| \alpha |}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Calpha+%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{| \alpha |}"/> be the length of the string <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. Also let <img alt="{\#(S,\alpha)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%23%28S%2C%5Calpha%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\#(S,\alpha)}"/> be the number of occurrences of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. </p>
<p>
A string <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> has the <i>period</i> <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> provided 	</p>
<p align="center"><img alt="\displaystyle  \alpha_{i} = \alpha_{i+p}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Calpha_%7Bi%7D+%3D+%5Calpha_%7Bi%2Bp%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \alpha_{i} = \alpha_{i+p}, "/></p>
<p>for all <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> so that <img alt="{i+p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%2Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i+p}"/> is defined. A string <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is <i>periodic</i> provided it has a period <img alt="{p&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p&gt;0}"/> that is less than half its length. Note, the shorter the period the more the string is really âperiodicâ: for example, the string 	</p>
<p align="center"><img alt="\displaystyle  10101010101010 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++10101010101010+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  10101010101010 "/></p>
<p>is more âperiodicâ than 	</p>
<p align="center"><img alt="\displaystyle  10000001000000. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++10000001000000.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  10000001000000. "/></p>
<blockquote><p><b>Lemma 3</b> <em> For any string <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{u}"/> either <img alt="{u0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{u0}"/> or <img alt="{u1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{u1}"/> is not periodic. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Suppose that <img alt="{\beta=u\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%3Du%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta=u\sigma}"/> is periodic with period <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> where <img alt="{\sigma}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sigma}"/> is a single character. Let the length of <img alt="{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\beta}"/> equal <img alt="{l}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l}"/>. So by definition, <img alt="{1 \le p \le l/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%5Cle+p+%5Cle+l%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1 \le p \le l/2}"/>. Then 	</p>
<p align="center"><img alt="\displaystyle  \beta_{i} = \beta_{i+p}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbeta_%7Bi%7D+%3D+%5Cbeta_%7Bi%2Bp%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \beta_{i} = \beta_{i+p}, "/></p>
<p>for <img alt="{1 \le i \le l-p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%5Cle+i+%5Cle+l-p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1 \le i \le l-p}"/>. So it follows that 	</p>
<p align="center"><img alt="\displaystyle  \beta_{l-p} = \beta_{l} = \sigma. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbeta_%7Bl-p%7D+%3D+%5Cbeta_%7Bl%7D+%3D+%5Csigma.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \beta_{l-p} = \beta_{l} = \sigma. "/></p>
<p>This shows that <img alt="{u1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u1}"/> and <img alt="{u0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u0}"/> cannot both be periodic, since 	</p>
<p align="center"><img alt="\displaystyle  1 \le l-p \le l/2 &lt; l. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%5Cle+l-p+%5Cle+l%2F2+%3C+l.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  1 \le l-p \le l/2 &lt; l. "/></p>
<p><img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<blockquote><p><b>Lemma 4</b> <em> Suppose that <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> is not a periodic string. Then the number of copies of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> in a string <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> is upper bounded by <img alt="{{O}(M)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7BO%7D%28M%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{O}(M)}"/> where 	</em></p><em>
<p align="center"><img alt="\displaystyle  M = \frac{|S|}{|\alpha|}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M+%3D+%5Cfrac%7B%7CS%7C%7D%7B%7C%5Calpha%7C%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  M = \frac{|S|}{|\alpha|}. "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
<em>Proof:</em>  The claim follows once we prove that no two copies of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> can overlap more than <img alt="{l/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l/2}"/> where <img alt="{l}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l}"/> is the length of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. This will immediately imply the lemma.</p>
<p>
If <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> has two copies in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> that overlap then clearly 	</p>
<p align="center"><img alt="\displaystyle  \alpha_{i} = \alpha_{i+d}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Calpha_%7Bi%7D+%3D+%5Calpha_%7Bi%2Bd%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \alpha_{i} = \alpha_{i+d}, "/></p>
<p>for some <img alt="{d&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d&gt;0}"/> and all <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> in the range <img alt="{1,\dots,l-d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2C%5Cdots%2Cl-d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1,\dots,l-d}"/>. This says that <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> has the period <img alt="{l-d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl-d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l-d}"/>. Since <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is not periodic it follows that <img alt="{d &gt; l/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd+%3E+l%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d &gt; l/2}"/>. This implies that the overlap of the two copies of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> are at most length <img alt="{l/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l/2}"/>. Thus we have shown that they cannot overlap too much. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
</p><p/><h3> Main Lemma </h3><p/>
<p/><p>
Say an automaton <i>finds</i> the <img alt="{k^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k^{th}}"/> occurrence of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> provided it enters a special state after scanning the last bit of this occurrence.</p>
<blockquote><p><b>Lemma 5</b> <em> Let <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> be a string of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> and let <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> be a non-periodic string.Then, there is an automaton with at most <img alt="{\widetilde{O}(M)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28M%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\widetilde{O}(M)}"/> states that can find the <img alt="{k^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%5E%7Bth%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k^{th}}"/> occurrence of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\alpha}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> where 	</em></p><em>
<p align="center"><img alt="\displaystyle  M = \#(S,\alpha) + |\alpha|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M+%3D+%5C%23%28S%2C%5Calpha%29+%2B+%7C%5Calpha%7C.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  M = \#(S,\alpha) + |\alpha|. "/></p>
</em><p><em/>
</p></blockquote>
<p>Here <img alt="{\widetilde{O}(M)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28M%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\widetilde{O}(M)}"/> allows factors that are fixed powers of <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/>. This lemma is the main insight of Robson and will be proved later.</p>
<p>
</p><p/><h2> The Main Theorem </h2><p/>
<p/><p>
The following is a slightly weaker version of Robsonâs theorem. I am still confused a bit about his stronger theorem, to be honest. </p>
<blockquote><p><b>Theorem 6 (Robsonâs Theorem)</b> <em> Suppose that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T}"/> are distinct strings of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>. Then there is an automaton with at most <img alt="{\widetilde{O}(\sqrt {n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28%5Csqrt+%7Bn%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\widetilde{O}(\sqrt {n})}"/> states that accepts <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> and rejects <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Since <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> are distinct we can assume that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> starts with the prefix <img alt="{u1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u1}"/> and <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> starts with the prefix <img alt="{u0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u0}"/> for some string <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/>. If the length of <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> is less than order <img alt="{\widetilde{O}(\sqrt {n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28%5Csqrt+%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\widetilde{O}(\sqrt {n})}"/> the theorem is trivial. Just construct an automaton that accepts <img alt="{u1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u1}"/> and rejects <img alt="{u0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u0}"/>.</p>
<p>
So we can assume that <img alt="{u = w\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu+%3D+w%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u = w\alpha}"/> for some strings <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> and <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> where the latter is order <img alt="{\widetilde{O}(\sqrt {n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28%5Csqrt+%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\widetilde{O}(\sqrt {n})}"/> in length. By lemma we can assume that <img alt="{\alpha1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha1}"/> is not periodic. So by lemma we get that 	</p>
<p align="center"><img alt="\displaystyle  \#(S,\alpha1) = \widetilde{O}(\sqrt{n}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%23%28S%2C%5Calpha1%29+%3D+%5Cwidetilde%7BO%7D%28%5Csqrt%7Bn%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \#(S,\alpha1) = \widetilde{O}(\sqrt{n}). "/></p>
<p>Then by lemma we are done. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
</p><p/><h2> Proof of Main Lemma </h2><p/>
<p/><p>
<em>Proof:</em>  Let <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> have length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and let <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> be a non-periodic string in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> of length <img alt="{l}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bl%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{l}"/>. Also let <img alt="{\#(S,\alpha) = m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%23%28S%2C%5Calpha%29+%3D+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\#(S,\alpha) = m}"/>. By the overlap lemma it follows that <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> is bounded by <img alt="{\widetilde{O}(|S|/|\alpha|)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28%7CS%7C%2F%7C%5Calpha%7C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\widetilde{O}(|S|/|\alpha|)}"/>. </p>
<p>
Let <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> occur at locations 	</p>
<p align="center"><img alt="\displaystyle  1 \le k_{1} &lt; \cdots &lt; k_{m} \le n. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%5Cle+k_%7B1%7D+%3C+%5Ccdots+%3C+k_%7Bm%7D+%5Cle+n.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  1 \le k_{1} &lt; \cdots &lt; k_{m} \le n. "/></p>
<p>Suppose that we are to construct a machine that finds the <img alt="{r^{th}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r^{th}}"/> copy of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. By the hashing lemma there is a prime <img alt="{p=\widetilde{O}(m)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%3D%5Cwidetilde%7BO%7D%28m%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p=\widetilde{O}(m)}"/> so that 	</p>
<p align="center"><img alt="\displaystyle  k_{i} \equiv k_{r} \bmod p " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++k_%7Bi%7D+%5Cequiv+k_%7Br%7D+%5Cbmod+p+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  k_{i} \equiv k_{r} \bmod p "/></p>
<p>if and only if <img alt="{i=r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%3Dr%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i=r}"/>. Note we can also assume that <img alt="{p &gt; l}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3E+l%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p &gt; l}"/>. </p>
<p>
Letâs argue the special case where <img alt="{k_{r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk_%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k_{r}}"/> is <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> modulo <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/>. If it is congruent to another value the same argument can be used. This follows by having the machine initially skip a fixed amount of the input and then do the same as in the congruent to <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> case.</p>
<p>
The automaton has states <img alt="{(i,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,Y)}"/> and <img alt="{(i,N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2CN%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,N)}"/> for <img alt="{i=0,\dots,p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%3D0%2C%5Cdots%2Cp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i=0,\dots,p}"/>. The machine starts in state <img alt="{(0,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%280%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(0,Y)}"/> and tries to get to the accepting state <img alt="{(l,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28l%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(l,Y)}"/>. The transitions include: 	</p>
<p align="center"><img alt="\displaystyle  (0,Y) \underset{\alpha_{1}}{\rightarrow} (1,Y) \underset{\alpha_{2}}{\rightarrow} (2,Y) \underset{\alpha_{3}}{\rightarrow} \cdots \underset{\alpha_{l}}{\rightarrow} (l,Y). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%280%2CY%29+%5Cunderset%7B%5Calpha_%7B1%7D%7D%7B%5Crightarrow%7D+%281%2CY%29+%5Cunderset%7B%5Calpha_%7B2%7D%7D%7B%5Crightarrow%7D+%282%2CY%29+%5Cunderset%7B%5Calpha_%7B3%7D%7D%7B%5Crightarrow%7D+%5Ccdots+%5Cunderset%7B%5Calpha_%7Bl%7D%7D%7B%5Crightarrow%7D+%28l%2CY%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (0,Y) \underset{\alpha_{1}}{\rightarrow} (1,Y) \underset{\alpha_{2}}{\rightarrow} (2,Y) \underset{\alpha_{3}}{\rightarrow} \cdots \underset{\alpha_{l}}{\rightarrow} (l,Y). "/></p>
<p>This means that the machine keeps checking the input to see if it is scanning a copy of <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>. If it gets all the way to the accepting state <img alt="{(l,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28l%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(l,Y)}"/>, then it stops.</p>
<p>
Further transitions are: 	</p>
<p align="center"><img alt="\displaystyle  (1,N) \rightarrow (2,N) \rightarrow \cdots \rightarrow (p,N), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%281%2CN%29+%5Crightarrow+%282%2CN%29+%5Crightarrow+%5Ccdots+%5Crightarrow+%28p%2CN%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (1,N) \rightarrow (2,N) \rightarrow \cdots \rightarrow (p,N), "/></p>
<p>and 	</p>
<p align="center"><img alt="\displaystyle  (0,Y) \underset{\neg \alpha_{1}}{\rightarrow} (1,N), (1,Y) \underset{\neg \alpha_{2}}{\rightarrow} (2,N), \dots, (l-1,Y) \underset{\neg \alpha_{l}}{\rightarrow} (l,N). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%280%2CY%29+%5Cunderset%7B%5Cneg+%5Calpha_%7B1%7D%7D%7B%5Crightarrow%7D+%281%2CN%29%2C+%281%2CY%29+%5Cunderset%7B%5Cneg+%5Calpha_%7B2%7D%7D%7B%5Crightarrow%7D+%282%2CN%29%2C+%5Cdots%2C+%28l-1%2CY%29+%5Cunderset%7B%5Cneg+%5Calpha_%7Bl%7D%7D%7B%5Crightarrow%7D+%28l%2CN%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  (0,Y) \underset{\neg \alpha_{1}}{\rightarrow} (1,N), (1,Y) \underset{\neg \alpha_{2}}{\rightarrow} (2,N), \dots, (l-1,Y) \underset{\neg \alpha_{l}}{\rightarrow} (l,N). "/></p>
<p>The second group means that if a wrong input happens, then <img alt="{(i,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i,Y)}"/> moves to <img alt="{(i+1,N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28i%2B1%2CN%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(i+1,N)}"/>. Finally, the state <img alt="{(p,N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28p%2CN%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(p,N)}"/> resets and starts the search again by going to the start state <img alt="{(0,Y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%280%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(0,Y)}"/> with an epsilon move.</p>
<p>
Clearly this has the required number of states and it operates correctly. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
The open problem is: Can the SWP be solved with a better bound? The lower bound is still order <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/>. So the gap is exponential. </p></font></font></div>
    </content>
    <updated>2019-09-16T21:26:18Z</updated>
    <published>2019-09-16T21:26:18Z</published>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="automaton"/>
    <category term="deterministic"/>
    <category term="separating words"/>
    <category term="strings"/>
    <category term="trick"/>
    <category term="words"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>GÃ¶delâs Lost Letter and P=NP</title>
      <updated>2019-09-19T03:20:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=18035</id>
    <link href="https://gilkalai.wordpress.com/2019/09/17/alefs-corner-bicycles-and-the-art-of-planar-random-maps/" rel="alternate" type="text/html"/>
    <title>Alefâs corner: Bicycles and the Art of  Planar Random Maps</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The artist behind Alefâs corner has a few mathematical designs and here are two new ones. (See Alefâs Â website offering over 100 T-shirt designs.) Â  which was used for the official T-shirt for Jean-FranÃ§ois Le Gallâs birthday conference. See also â¦ <a href="https://gilkalai.wordpress.com/2019/09/17/alefs-corner-bicycles-and-the-art-of-planar-random-maps/">Continue reading <span class="meta-nav">â</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The artist behind <a href="https://gilkalai.wordpress.com/?s=alef">Alefâs corner</a> has a few mathematical designs and here are two new ones. (See Alefâs Â <a href="https://tembelone.com/?fbclid=IwAR27VIu9gIgfgTWSYu88Xz1H9GneVoZsLZb1sw6jQ6IiE9w7cFo0jlISUas">website offering over 100 T-shirt designs</a>.)</p>
<p>Â </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/legal.png"><img alt="" class="alignnone size-full wp-image-18040" height="529" src="https://gilkalai.files.wordpress.com/2019/09/legal.png?w=640&amp;h=529" width="640"/></a></p>
<p>which was used for the official T-shirt for Jean-FranÃ§ois Le Gallâs <a href="https://www.math.u-psud.fr/~jf60/">birthday conference</a>.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/image-principale2.jpg"><img alt="" class="alignnone size-full wp-image-18041" src="https://gilkalai.files.wordpress.com/2019/09/image-principale2.jpg?w=640"/></a></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/curien.png"><img alt="" class="alignnone size-full wp-image-18036" src="https://gilkalai.files.wordpress.com/2019/09/curien.png?w=640"/></a></p>
<p>See also <a href="https://www.quantamagazine.org/random-surfaces-hide-an-intricate-order-20190702/">this quanta magazine article</a> by Kevin Hartness.</p></div>
    </content>
    <updated>2019-09-16T21:23:03Z</updated>
    <published>2019-09-16T21:23:03Z</published>
    <category term="Art"/>
    <category term="Combinatorics"/>
    <category term="Geometry"/>
    <category term="Probability"/>
    <category term="Alef's corner"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-09-19T03:20:49Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6037506695705789893</id>
    <link href="https://blog.computationalcomplexity.org/feeds/6037506695705789893/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/09/this-paper-from-2015-cracks-diffie.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6037506695705789893" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6037506695705789893" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/09/this-paper-from-2015-cracks-diffie.html" rel="alternate" type="text/html"/>
    <title>this paper from 2015 cracks Diffie-Hellman. What to tell the students?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I am teaching cryptography this semester for the second time (I taught it in Fall 2019) and will soon tell the students about the paper from 2015:<br/>
<a href="https://weakdh.org/imperfect-forward-secrecy.pdf">Imperfect Forward Secrecy: How Diffie-Hellman Fails in Practice</a>. There are 14 authors.<br/>
<br/>
The upshot is that as Diffie-Hellman was implemented in 2015, many cases were crackable. In summary (and probably too simple):<br/>
<br/>
DH in a 512-bit group can be cracked by the authors<br/>
<br/>
DH in a 1024-bit group they speculate can be cracked with nation-state resources. <br/>
<br/>
<br/>
<br/>
Is this a big deal? If YES then what is being done, and if NOT then why not?<br/>
<br/>
I have come up with some statements that I DO NOT KNOW if they are true, but I am ASKING you, to shed some light on the BIG DEAL or NO BIG DEAL question. (Note- Idea for a game show: BIG DEAL or NO BIG DEAL where contestants are asked if a news story is a BIG DEAL or not.)<br/>
<br/>
So, please comment on the following question:<br/>
<br/>
1) Since 2015 the people who use DH have upped their game and are now using bigger parameters. (I doubt this is true)<br/>
<br/>
2) DH is mostly not used on things that hackers are not interested in, so this is not a big deal.<br/>
<br/>
3) The expertise required to crack DH via this paper is rather difficult, so hackers don't have the skills.<br/>
<br/>
4) This paper is not a problem for a bad reason: Hackers don't need to  use the number field sieve DL algorithm when all they need to do is (1) guess that the pin numer is 1234 or the year the user was born (or close to it), (2) put on a uniform from Geek-Squad or some such organization and claim they are here to help, (3) exploit a known security flaw that the company has not bothered fixing.  <br/>
<br/>
5) The 14 authors have mysteriously disappeared. (I doubt this is true.)<br/>
<br/>
<br/>
(Misc: My spell checker thinks that Diffie and crackable are not words, but Hellman is.)</div>
    </content>
    <updated>2019-09-16T13:10:00Z</updated>
    <published>2019-09-16T13:10:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-09-18T23:54:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/09/16/faculty-at-university-of-sydney-apply-by-november-15-2019/</id>
    <link href="https://cstheory-jobs.org/2019/09/16/faculty-at-university-of-sydney-apply-by-november-15-2019/" rel="alternate" type="text/html"/>
    <title>faculty at University of Sydney (apply by November 15, 2019)</title>
    <summary>Multiple continuing positions in the School Computer Science at the University of Sydney Website: https://sydney.nga.net.au/cp/index.cfm?event=jobs.jati&amp;returnToEvent=jobs.home&amp;jobID=899915FC-E820-42ED-8D7F-AABE00DC48B2&amp;audienceTypeCode=EXT&amp;UseAudienceTypeLanguage=1 Email: joachim.gudmundsson@sydney.edu.au</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Multiple continuing positions in the School Computer Science at the University of Sydney</p>
<p>Website: <a href="https://sydney.nga.net.au/cp/index.cfm?event=jobs.jati&amp;returnToEvent=jobs.home&amp;jobID=899915FC-E820-42ED-8D7F-AABE00DC48B2&amp;audienceTypeCode=EXT&amp;UseAudienceTypeLanguage=1">https://sydney.nga.net.au/cp/index.cfm?event=jobs.jati&amp;returnToEvent=jobs.home&amp;jobID=899915FC-E820-42ED-8D7F-AABE00DC48B2&amp;audienceTypeCode=EXT&amp;UseAudienceTypeLanguage=1</a><br/>
Email: joachim.gudmundsson@sydney.edu.au</p></div>
    </content>
    <updated>2019-09-16T11:34:31Z</updated>
    <published>2019-09-16T11:34:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-09-19T03:20:58Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/09/15/linkage</id>
    <link href="https://11011110.github.io/blog/2019/09/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Lee Bollinger, president of Columbia University: âNo, I wonât start spying on my foreign-born studentsâ ().</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.washingtonpost.com/opinions/no-i-wont-start-spying-on-my-foreign-born-students/2019/08/29/01c80e84-c9b2-11e9-a1fe-ca46e8d573c0_story.html">Lee Bollinger, president of Columbia University: âNo, I wonât start spying on my foreign-born studentsâ</a> (<a href="https://mathstodon.xyz/@11011110/102718751083310854"/>).</p>
  </li>
  <li>
    <p><a href="https://windowsontheory.org/2019/08/30/update-on-the-safe-toc-initiative-guest-post-by-sandy-irani/">Update on the Safe ToC initiative</a> (<a href="https://mathstodon.xyz/@11011110/102725927728134229"/>). Sandy Irani describes progress in combatting harassment and discrimination at theoretical computer science conferences, and calls for volunteer advocates to serve as contact points at conferences.</p>
  </li>
  <li>
    <p><a href="http://isohedral.ca/escher-like-spiral-tilings/">Escher-like spiral tilings, by Craig Kaplan</a> (<a href="https://mathstodon.xyz/@11011110/102732614495435403"/>, <a href="https://news.ycombinator.com/item?id=20854644">via</a>). Sadly with no angels, devils, fish, or geese, but maybe some talented artist will take up that challenge.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1909.00263">How to peel self-intersecting onions</a> (<a href="https://mathstodon.xyz/@jeffgerickson/102734672335961160"/>). Gabriel Nivasch extends the <a href="https://11011110.github.io/blog/2017/10/11/peeling-vs-shortening.html">conjectured equivalence</a> between <a href="https://en.wikipedia.org/wiki/Convex_layers">convex layers</a> and the <a href="https://en.wikipedia.org/wiki/Curve-shortening_flow#Related_flows">affine curve-shortening flow</a> to non-convex and self-intersecting curves. The generalized onion-peeling process alternates between steps that jump over grid points and steps that shrink curves to the shortest curve that passes between the same grid points. See also Gabrielâs animations of this process for <a href="https://mathstodon.xyz/@gnivasch/102741204463574303">grid points</a> and for <a href="https://mathstodon.xyz/@gnivasch/102753301344471044">random points</a>.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1909.00917">New stick number bounds from random sampling of confined polygons</a> (<a href="https://mathstodon.xyz/@shonk/102742716819892997"/>). Tom Eddy and Clayton Shonkwiler do knot theory on large numbers of random 3d polygons, in the process finding polygonal representations of many knots with fewer segments than were known before.</p>
  </li>
  <li>
    <p><a href="https://aperiodical.com/2019/09/42-is-the-answer-to-the-question-what-is-80538738812075974%c2%b3-80435758145817515%c2%b3-12602123297335631%c2%b3/">42 is the answer</a>. The question is: What is ?</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1177/2378023118823946">Who Counts as a Notable Sociologist on Wikipedia? Gender, Race, and the âProfessor Testâ</a> (<a href="https://mathstodon.xyz/@11011110/102755324164533099"/>, <a href="https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2019-08-30/Recent_research">via</a>). After authors Adams, BrÃ¼ckner, and Naslund factored out seniority and impact of sociologists, white men remained more likely than others to have Wikipedia articles. Surprisingly to me, the disparity happens at article creation, not deletion. So we should create more articles about women! Or be less quick to create them on borderline-notable menâ¦</p>
  </li>
  <li>
    <p><a href="https://www.flickr.com/photos/132410114@N04/24230683269/">Permutations in the real world: 12784563</a> (<a href="https://mathstodon.xyz/@11011110/102763393307640430"/>). Actually I have sentimental reasons to prefer 15426378, but I couldnât find a nice photo of that one.</p>
  </li>
  <li>
    <p><a href="https://simon.lc/the-history-of-tetris-randomizers">The history of Tetris randomizers</a> (<a href="https://mathstodon.xyz/@11011110/102766825773116819"/>, <a href="https://www.metafilter.com/182935/let-piece-I-J-L-TMathfloorMathrandom-4">via</a>). Truly uniformly random distributions tend to be more clustered than people expect (having runs of the same piece or of mostly the same piece). So later versions took measures to make the piece distribution less random and more non-clustered.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1908.07097">An  lower bound for random universal sets for planar graphs</a> (<a href="https://mathstodon.xyz/@11011110/102771230722757397"/>). Random subsets of a square act like grids in lots of ways. Hereâs one, from the linked preprint: to draw all -vertex planar graphs with chosen points as vertices, you need either a grid or a random point set of  points. The reason is that drawings of the nested triangles graph contain a sequence of  points (corners of bounding boxes of triangles) thatâs monotone in both coordinate directions, and smaller random sets (or grids) donât have such sequences.</p>
  </li>
  <li>
    <p><a href="https://codepen.io/collection/eErLu/">CSS polyhedra</a> (<a href="https://mathstodon.xyz/web/statuses/102775320989084287"/>). Visualizations of 3d rotating polyhedra, coded entirely in html/css and embeddable in other web pages.</p>
  </li>
  <li>
    <p><a href="https://www.maths.ox.ac.uk/node/30217">Random minimum spanning trees</a> (<a href="https://mathstodon.xyz/@11011110/102786143581334329"/>). Did you know that in random graphs with edge probability  (just below the appearance of the giant component) there are lots of components of size  that all look nearly the same as uniformly random spanning trees of a complete graph? And that the minimum spanning tree of a randomly-weighted complete graph, instead, looks like one of these components with a lot of others all glued onto it? Christina Goldschmidt describes her work in this area.</p>
  </li>
  <li>
    <p><a href="https://www.gwern.net/Turing-complete">A big list of unlikely or surprising Turing-complete systems</a> (<a href="https://mathstodon.xyz/@11011110/102789724968251958"/>, <a href="https://www.metafilter.com/183095/On-having-sufficient-complexity-to-allow-for-arbitrary-computation">via</a>). My favorite: <a href="https://github.com/tom-p-reichel/svg-is-turing-complete">SVG is Turing-complete</a> because it can be used to (slowly) simulate Rule 110 (and one hopes also simulate the weird boundary conditions needed to make Rule 110 Turing complete).</p>
  </li>
  <li>
    <p><a href="https://www.english.cam.ac.uk/cmt/?p=5751">Miltonâs hand-annotated volume of Shakespeareâs plays discovered sitting on a library shelf in Philly</a> (<a href="https://mathstodon.xyz/@11011110/102791968928048975"/>, <a href="https://www.metafilter.com/183100/Miltons-Shakespeare">via</a>).</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Vojt%C4%9Bch_Jarn%C3%ADk">VojtÄch JarnÃ­k, now a good article on Wikipedia</a> (<a href="https://mathstodon.xyz/@11011110/102798710399112671"/>). I teach his algorithm for minimum spanning trees in my classes, but lately in my research Iâve been citing him more for his work on the number of integer grid points on convex curves. He also did important work on Diophantine approximation and nowhere-differentiable functions.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-09-15T17:51:00Z</updated>
    <published>2019-09-15T17:51:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-09-16T01:18:08Z</updated>
    </source>
  </entry>
</feed>
