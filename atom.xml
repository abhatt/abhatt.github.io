<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-11-16T18:21:35Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1802</id>
    <link href="https://theorydish.blog/2020/11/16/hiring-postdocs/" rel="alternate" type="text/html"/>
    <title>Hiring Postdocs</title>
    <summary>I am looking to hire postdocs in the coming years on topics of algorithmic fairness with relation to a Simons Collaboration and on the meaning of individual probabilities with relation to a Sloan Foundation project. Please contact me for details and please forward to any relevant individual. Some comments: The Simons Collaboration will offer additional postdoc opportunities across the participating institutions. To be advertised soon. The perspective taken in both these projects is of TOC but the research will gain from collaborations with other fields within and outside of CS (Statistics, Economics, Philosophy, Law, Social Sciences at large). I will therefore be open to postdocs with various backgrounds (and would consider co-hosting with colleagues in other fields). Candidates from under-represented populations are encouraged to apply and I promise to give those applications my close attention.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am looking to hire postdocs in the coming years on topics of algorithmic fairness with relation to a <a href="https://www.simonsfoundation.org/2020/06/18/foundation-announces-simons-collaboration-on-the-theory-of-algorithmic-fairness/">Simons Collaboration</a> and on the meaning of individual probabilities with relation to a <a href="https://sloan.org/">Sloan Foundation</a> project. Please contact me for details and please forward to any relevant individual. Some comments:</p>



<ol type="1"><li>The Simons Collaboration will offer additional postdoc opportunities across the participating institutions. To be advertised soon.</li></ol>



<ul><li>The perspective taken in both these projects is of TOC but the research will gain from collaborations with other fields within and outside of CS (Statistics, Economics, Philosophy, Law, Social Sciences at large). I will therefore be open to postdocs with various backgrounds (and would consider co-hosting with colleagues in other fields).</li></ul>



<ul><li>Candidates from under-represented populations are encouraged to apply and I promise to give those applications my close attention.</li></ul></div>
    </content>
    <updated>2020-11-16T17:39:07Z</updated>
    <published>2020-11-16T17:39:07Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-11-16T18:21:11Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/11/15/linkage</id>
    <link href="https://11011110.github.io/blog/2020/11/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>The early history of continued fractions (\(\mathbb{M}\)). Includes the equivalences of infinitude with irrationality and periodicity with quadraticness, and the work of Euler and Gauss on continued fractions for values with nice series expansions.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://golem.ph.utexas.edu/category/2020/09/five_levels_of_continued_fract.html">The early history of continued fractions</a> (<a href="https://mathstodon.xyz/@11011110/105139147272940535">\(\mathbb{M}\)</a>). Includes the equivalences of infinitude with irrationality and periodicity with quadraticness, and the work of Euler and Gauss on continued fractions for values with nice series expansions.</p>
  </li>
  <li>
    <p>According to <a href="http://cams.ehess.fr/">EHESS</a>, <a href="https://en.wikipedia.org/wiki/Pierre_Rosenstiehl">Pierre Rosenstiehl</a> has died (<a href="https://mathstodon.xyz/@11011110/105147747900598849">\(\mathbb{M}\)</a>). I don’t think I met or interacted with Rosenstiehl, but I definitely interacted with his works: he was one of the founders of the International Symposium on Graph Drawing and co-editor in chief of the European Journal of Combinatorics, with important publications in topological and algorithmic graph theory on <a href="https://en.wikipedia.org/wiki/Bipolar_orientation">bipolar orientations</a> and the <a href="https://en.wikipedia.org/wiki/Left-right_planarity_test">left-right planarity test</a>.</p>
  </li>
  <li>
    <p><a href="https://www.aerialphotoawards.com/aerial-photos-of-the-year-2020-man-made-category">Aerial photos of the year, 2020</a> (<a href="https://mathstodon.xyz/@11011110/105155256595043126">\(\mathbb{M}\)</a>, <a href="https://www.metafilter.com/189287/A-Different-Perspective">via</a>). The link shows only the “man-made” category; be sure to click on all the others as well.</p>
  </li>
  <li>
    <p><a href="https://www.slac.stanford.edu/~kaehler/homepage/visualizations/dark-matter.html">Simulation and visualization of the large-scale structure of the universe</a> (<a href="https://mathstodon.xyz/@11011110/105161855079392754">\(\mathbb{M}\)</a>, <a href="https://apod.nasa.gov/apod/ap201025.html">via</a>), including webs of dark matter and the transition from an opaque early universe to its present mostly-transparent state.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2007.06838">The cocked hat</a> (<a href="https://mathstodon.xyz/@11011110/105167862476053808">\(\mathbb{M}\)</a>). This interestingly-titled recent preprint by Bárány, Steiger, and Toledo concerns locating yourself by measuring angles to three landmarks. Usually, random error causes rays from the landmarks to form a triangle rather than meeting at a point. Supposedly this triangle contains your position with probability 1/4, but the preprint shows that this can be proven only for distributions that force the rays to form a triangle. See also Toledo’s new book, <em><a href="http://www.cs.tau.ac.il/~stoledo/LocationEstimationFromTheGroundUp/">Location Estimation from the Ground Up</a></em>.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/w/index.php?title=User_talk:DMacks&amp;diff=prev&amp;oldid=987454393">MDPI is asking its authors to spam Wikipedia with their work</a> (<a href="https://mathstodon.xyz/@11011110/105176559718608713">\(\mathbb{M}\)</a>), and <a href="https://www.elsevier.com/__data/assets/pdf_file/0013/201325/Get-Noticed_Brochure_2018.pdf">so is Elsevier</a>. I’m not surprised by MDPI doing this but, despite my low opinion of them, I thought Elsevier were better than that.</p>
  </li>
  <li>
    <p><a href="https://drawingmachines.org/">Drawing machines</a> (<a href="https://mathstodon.xyz/@11011110/105181738042763529">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=25033793">via</a>). An archive of optical/mechanical/automated drawing machines/devices/aids.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=LdnvxN4UUfs">Origami Fibonacci torus and knotted torus</a> (<a href="https://mathstodon.xyz/@11011110/105184956163150834">\(\mathbb{M}\)</a>). I have the impression that the Fibonacci part just gives it a nice organic look, <a href="http://www.starcage.org/englishindex.html">visible in much of Akio Hizume’s other architecture</a>, but what interests me is the way it rotates smoothly. That’s not something unfolded paper can do, because the inner parts of a torus have negative curvature, the outer parts are positive, and unfolded paper can’t change curvature.</p>
  </li>
  <li>
    <p>The floorplan below is of the <a href="https://en.wikipedia.org/wiki/K%C3%B6lntriangle">KölnTriangle</a>, a building in Cologne which has been claimed to be a Reuleaux triangle in cross-section (<a href="https://mathstodon.xyz/@11011110/105195769927037078">\(\mathbb{M}\)</a>). Obviously it’s not. The <a href="https://en.wikipedia.org/wiki/Torre_de_Collserola">Torre de Collserola in Barcelona</a> looks <a href="https://commons.wikimedia.org/wiki/File:Barcelona_Torre_de_Collserola_Planol_Evacuacio.jpg">much more promising</a> but a published description of its specific architecture would help make that more clear.</p>

    <p style="text-align: center;"><img alt="K&#xF6;lntriangle floor plan from CC-BY-SA image https://commons.wikimedia.org/wiki/File:Fluchtwegeplan_K%C3%B6ln_Trangle.JPG by Bin im Garten, with overlaid Reuleaux triangle" src="https://11011110.github.io/blog/assets/2020/KoelnTriangle-not-Reuleaux.jpg"/></p>
  </li>
  <li>
    <p><a href="https://www.scottaaronson.com/blog/?p=5094">The <em>Complexity Zoo</em> needs a new home</a> (<a href="https://mathstodon.xyz/@11011110/105199077818825073">\(\mathbb{M}\)</a>). Scott Aaronson’s collection of complexity classes and their relations had been at the U. Waterloo Institute for Quantum Computing, but their bureaucrats have decided that they cannot accept the liability of it possibly being out of compliance with accessibility rules, without allowing him to fix any issues or even tell him what issues it might have. As Scott writes, “Do you find it ironic that a central effect of these accessibility policies seems to be to make free academic content less accessible than before?”</p>
  </li>
  <li>
    <p>Two more recent deaths in discrete mathematics and theoretical computer science (<a href="https://mathstodon.xyz/@11011110/105205573414576460">\(\mathbb{M}\)</a>): <a href="http://emps.exeter.ac.uk/mathematics/news-events/news/articles/robinchapmanobituary.html">Robin J. Chapman, problem-solver extraordinaire</a> (and scarily almost exactly the same age as me), and
<a href="https://en.wikipedia.org/wiki/Chung_Laung_Liu">Dave (C. L.) Liu</a>, early researcher in scheduling algorithms and VLSI layout and later president of National Tsing Hua University (<a href="https://news.ltn.com.tw/amp/news/life/breakingnews/3346060">Chinese-language obituary</a>).</p>
  </li>
  <li>
    <p><a href="http://www.the-sandpit.com/contortions/contort.htm">Contortion engineering</a> (<a href="https://mathstodon.xyz/@11011110/105217523608810155">\(\mathbb{M}\)</a>). Engineering-style drawings of Escher-like impossible objects. An old link from my old Geometry Junkyard site — its old earthlink url went dead some time after 2016, when archive.org last captured it, but now it has a new home.</p>
  </li>
</ul></div>
    </content>
    <updated>2020-11-15T21:05:00Z</updated>
    <published>2020-11-15T21:05:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-11-16T05:34:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=797</id>
    <link href="https://emanueleviola.wordpress.com/2020/11/15/marijuana-brings-good-to-your-community/" rel="alternate" type="text/html"/>
    <title>Marijuana brings good to your community</title>
    <summary>Subsequence of official communication from Newton: […] recently reviewed applications from […] marijuana retailers who have submitted proposals […]. […] has a diverse management team with experience in the cannabis industry, equity, community relations and public health. […] certified by the Cannabis Control Commission as an Economic Empowerment Applicant, signifying that the applicant demonstrates experience […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Subsequence of official communication from Newton:</p>



<figure class="wp-block-table"><table><tbody><tr><td><br/>[…] recently reviewed applications from […] marijuana retailers who have submitted proposals […].<br/><br/>[…] has a diverse management team with experience in the cannabis industry, equity, community relations and public health. […] certified by the Cannabis Control Commission as an Economic Empowerment Applicant, signifying that the applicant demonstrates experience in or business practices that promote economic empowerment in disproportionately impacted communities. Their plan involves […] additional parking on-site.<br/><br/>[…] also signing […] is a family owned and operated business. The company is certified by the Massachusetts Supplier Diversity Office as both a Minority Business and a Women Business Enterprise. […] will renovate the building and create surface parking. It has indicated it is willing to make transportation infrastructure improvements to the intersection […].<br/><br/>I am also signing […]. […] brings experience in the cannabis industry along with commitments to equity, public health, and community relations. […] will be constructing a new building and parking on what is currently a vacant parcel. <br/><br/>[…] with a revised plan to […] include more parking.<br/><br/></td></tr></tbody></table></figure>



<figure class="wp-block-table"><table><tbody><tr><td>Et cetera.</td></tr></tbody></table></figure>



<p/></div>
    </content>
    <updated>2020-11-15T12:40:43Z</updated>
    <published>2020-11-15T12:40:43Z</published>
    <category term="Uncategorized"/>
    <category term="marijuana"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-11-16T18:21:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06585</id>
    <link href="http://arxiv.org/abs/2011.06585" rel="alternate" type="text/html"/>
    <title>Sparse PCA: Algorithms, Adversarial Perturbations and Certificates</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Tommaso d'Orsi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kothari:Pravesh_K=.html">Pravesh K. Kothari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Novikov:Gleb.html">Gleb Novikov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Steurer:David.html">David Steurer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06585">PDF</a><br/><b>Abstract: </b>We study efficient algorithms for Sparse PCA in standard statistical models
(spiked covariance in its Wishart form). Our goal is to achieve optimal
recovery guarantees while being resilient to small perturbations. Despite a
long history of prior works, including explicit studies of perturbation
resilience, the best known algorithmic guarantees for Sparse PCA are fragile
and break down under small adversarial perturbations.
</p>
<p>We observe a basic connection between perturbation resilience and
\emph{certifying algorithms} that are based on certificates of upper bounds on
sparse eigenvalues of random matrices. In contrast to other techniques, such
certifying algorithms, including the brute-force maximum likelihood estimator,
are automatically robust against small adversarial perturbation.
</p>
<p>We use this connection to obtain the first polynomial-time algorithms for
this problem that are resilient against additive adversarial perturbations by
obtaining new efficient certificates for upper bounds on sparse eigenvalues of
random matrices. Our algorithms are based either on basic semidefinite
programming or on its low-degree sum-of-squares strengthening depending on the
parameter regimes. Their guarantees either match or approach the best known
guarantees of \emph{fragile} algorithms in terms of sparsity of the unknown
vector, number of samples and the ambient dimension.
</p>
<p>To complement our algorithmic results, we prove rigorous lower bounds
matching the gap between fragile and robust polynomial-time algorithms in a
natural computational model based on low-degree polynomials (closely related to
the pseudo-calibration technique for sum-of-squares lower bounds) that is known
to capture the best known guarantees for related statistical estimation
problems. The combination of these results provides formal evidence of an
inherent price to pay to achieve robustness.
</p></div>
    </summary>
    <updated>2020-11-15T23:03:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06572</id>
    <link href="http://arxiv.org/abs/2011.06572" rel="alternate" type="text/html"/>
    <title>Relative Lipschitzness in Extragradient Methods and a Direct Recipe for Acceleration</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen:Michael_B=.html">Michael B. Cohen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidford:Aaron.html">Aaron Sidford</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tian:Kevin.html">Kevin Tian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06572">PDF</a><br/><b>Abstract: </b>We show that standard extragradient methods (i.e. mirror prox and dual
extrapolation) recover optimal accelerated rates for first-order minimization
of smooth convex functions. To obtain this result we provide fine-grained
characterization of the convergence rates of extragradient methods for solving
monotone variational inequalities in terms of a natural condition we call
relative Lipschitzness. We further generalize this framework to handle local
and randomized notions of relative Lipschitzness and thereby recover rates for
box-constrained $\ell_\infty$ regression based on area convexity and complexity
bounds achieved by accelerated (randomized) coordinate descent for smooth
convex function minimization.
</p></div>
    </summary>
    <updated>2020-11-15T23:10:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06551</id>
    <link href="http://arxiv.org/abs/2011.06551" rel="alternate" type="text/html"/>
    <title>Efficient Solution of Boolean Satisfiability Problems with Digital MemComputing</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>S. R. B. Bearden, Y. R. Pei, M. Di Ventra <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06551">PDF</a><br/><b>Abstract: </b>Boolean satisfiability is a propositional logic problem of interest in
multiple fields, e.g., physics, mathematics, and computer science. Beyond a
field of research, instances of the SAT problem, as it is known, require
efficient solution methods in a variety of applications. It is the decision
problem of determining whether a Boolean formula has a satisfying assignment,
believed to require exponentially growing time for an algorithm to solve for
the worst-case instances. Yet, the efficient solution of many classes of
Boolean formulae eludes even the most successful algorithms, not only for the
worst-case scenarios, but also for typical-case instances. Here, we introduce a
memory-assisted physical system (a digital memcomputing machine) that, when its
non-linear ordinary differential equations are integrated numerically, shows
evidence for polynomially-bounded scalability while solving "hard"
planted-solution instances of SAT, known to require exponential time to solve
in the typical case for both complete and incomplete algorithms. Furthermore,
we analytically demonstrate that the physical system can efficiently solve the
SAT problem in continuous time, without the need to introduce chaos or an
exponentially growing energy. The efficiency of the simulations is related to
the collective dynamical properties of the original physical system that
persist in the numerical integration to robustly guide the solution search even
in the presence of numerical errors. We anticipate our results to broaden
research directions in physics-inspired computing paradigms ranging from theory
to application, from simulation to hardware implementation.
</p></div>
    </summary>
    <updated>2020-11-15T22:43:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06545</id>
    <link href="http://arxiv.org/abs/2011.06545" rel="alternate" type="text/html"/>
    <title>Towards Better Approximation of Graph Crossing Number</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chuzhoy:Julia.html">Julia Chuzhoy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahabadi:Sepideh.html">Sepideh Mahabadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tan:Zihan.html">Zihan Tan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06545">PDF</a><br/><b>Abstract: </b>Graph Crossing Number is a fundamental problem with various applications. In
this problem, the goal is to draw an input graph $G$ in the plane so as to
minimize the number of crossings between the images of its edges. Despite
extensive work, non-trivial approximation algorithms are only known for
bounded-degree graphs. Even for this special case, the best current algorithm
achieves a $\tilde O(\sqrt n)$-approximation, while the best current negative
result is APX-hardness. All current approximation algorithms for the problem
build on the same paradigm: compute a set $E'$ of edges (called a
\emph{planarizing set}) such that $G\setminus E'$ is planar; compute a planar
drawing of $G\setminus E'$; then add the drawings of the edges of $E'$ to the
resulting drawing. Unfortunately, there are examples of graphs, in which any
implementation of this method must incur $\Omega (\text{OPT}^2)$ crossings,
where $\text{OPT}$ is the value of the optimal solution. This barrier seems to
doom the only known approach to designing approximation algorithms for the
problem, and to prevent it from yielding a better than $O(\sqrt
n)$-approximation.
</p>
<p>In this paper we propose a new paradigm that allows us to overcome this
barrier. We show an algorithm that, given a bounded-degree graph $G$ and a
planarizing set $E'$ of its edges, computes another set $E''$ with $E'\subseteq
E''$, such that $|E''|$ is relatively small, and there exists a near-optimal
drawing of $G$ in which only edges of $E''$ participate in crossings. This
allows us to reduce the Crossing Number problem to \emph{Crossing Number with
Rotation System} -- a variant in which the ordering of the edges incident to
every vertex is fixed as part of input. We show a randomized algorithm for this
new problem, that allows us to obtain an $O(n^{1/2-\epsilon})$-approximation
for Crossing Number on bounded-degree graphs, for some constant $\epsilon&gt;0$.
</p></div>
    </summary>
    <updated>2020-11-15T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06535</id>
    <link href="http://arxiv.org/abs/2011.06535" rel="alternate" type="text/html"/>
    <title>Quantum Random Access Codes for Boolean Functions</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Doriguello:Jo=atilde=o_F=.html">João F. Doriguello</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Montanaro:Ashley.html">Ashley Montanaro</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06535">PDF</a><br/><b>Abstract: </b>An $n\overset{p}{\mapsto}m$ random access code (RAC) is an encoding of $n$
bits into $m$ bits such that any initial bit can be recovered with probability
at least $p$, while in a quantum RAC (QRAC), the $n$ bits are encoded into $m$
qubits. Since its proposal, the idea of RACs was generalized in many different
ways, e.g. allowing the use of shared entanglement (called
entanglement-assisted random access code, or simply EARAC) or recovering
multiple bits instead of one. In this paper we generalize the idea of RACs to
recovering the value of a given Boolean function $f$ on any subset of fixed
size of the initial bits, which we call $f$-random access codes. We study and
give protocols for $f$-random access codes with classical ($f$-RAC) and quantum
($f$-QRAC) encoding, together with many different resources, e.g. private or
shared randomness, shared entanglement ($f$-EARAC) and Popescu-Rohrlich boxes
($f$-PRRAC). The success probability of our protocols is characterized by the
\emph{noise stability} of the Boolean function $f$. Moreover, we give an
\emph{upper bound} on the success probability of any $f$-QRAC with shared
randomness that matches its success probability up to a multiplicative constant
(and $f$-RACs by extension), meaning that quantum protocols can only achieve a
limited advantage over their classical counterparts.
</p></div>
    </summary>
    <updated>2020-11-15T22:39:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06530</id>
    <link href="http://arxiv.org/abs/2011.06530" rel="alternate" type="text/html"/>
    <title>Towards Tight Bounds for Spectral Sparsification of Hypergraphs</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kapralov:Michael.html">Michael Kapralov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krauthgamer:Robert.html">Robert Krauthgamer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tardos:Jakab.html">Jakab Tardos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yoshida:Yuichi.html">Yuichi Yoshida</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06530">PDF</a><br/><b>Abstract: </b>Cut and spectral sparsification of graphs have numerous applications,
including e.g. speeding up algorithms for cuts and Laplacian solvers. These
powerful notions have recently been extended to hypergraphs, which are much
richer and may offer new applications. However, the current bounds on the size
of hypergraph sparsifiers are not as tight as the corresponding bounds for
graphs.
</p>
<p>Our first result is a polynomial-time algorithm that, given a hypergraph on
$n$ vertices with maximum hyperedge size $r$, outputs an $\epsilon$-spectral
sparsifier with $O^*(nr)$ hyperedges, where $O^*$ suppresses $(\epsilon^{-1}
\log n)^{O(1)}$ factors. This size bound improves the two previous bounds:
$O^*(n^3)$ [Soma and Yoshida, SODA'19] and $O^*(nr^3)$ [Bansal, Svensson and
Trevisan, FOCS'19]. Our main technical tool is a new method for proving
concentration of the nonlinear analogue of the quadratic form of the Laplacians
for hypergraph expanders.
</p>
<p>We complement this with lower bounds on the bit complexity of any compression
scheme that $(1+\epsilon)$-approximates all the cuts in a given hypergraph, and
hence also on the bit complexity of every $\epsilon$-cut/spectral sparsifier.
These lower bounds are based on Ruzsa-Szemer\'edi graphs, and a particular
instantiation yields an $\Omega(nr)$ lower bound on the bit complexity even for
fixed constant $\epsilon$. This is tight up to polylogarithmic factors in $n$,
due to recent hypergraph cut sparsifiers of [Chen, Khanna and Nagda, FOCS'20].
</p>
<p>Finally, for directed hypergraphs, we present an algorithm that computes an
$\epsilon$-spectral sparsifier with $O^*(n^2r^3)$ hyperarcs, where $r$ is the
maximum size of a hyperarc. For small $r$, this improves over $O^*(n^3)$ known
from [Soma and Yoshida, SODA'19], and is getting close to the trivial lower
bound of $\Omega(n^2)$ hyperarcs.
</p></div>
    </summary>
    <updated>2020-11-15T23:03:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06516</id>
    <link href="http://arxiv.org/abs/2011.06516" rel="alternate" type="text/html"/>
    <title>Sample-driven optimal stopping: From the secretary problem to the i.i.d. prophet inequality</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Correa:Jos=eacute=.html">José Correa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cristi:Andr=eacute=s.html">Andrés Cristi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Epstein:Boris.html">Boris Epstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Soto:Jos=eacute=.html">José Soto</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06516">PDF</a><br/><b>Abstract: </b>Two fundamental models in online decision making are that of competitive
analysis and that of optimal stopping. In the former the input is produced by
an adversary, while in the latter the algorithm has full distributional
knowledge of the input. In recent years, there has been a lot of interest in
bridging these two models by considering data-driven or sample-based versions
of optimal stopping problems. In this paper, we study such a version of the
classic single selection optimal stopping problem, as introduced by Kaplan et
al. [2020]. In this problem a collection of arbitrary non-negative numbers is
shuffled in uniform random order. A decision maker gets to observe a fraction
$p\in [0,1)$ of the numbers and the remaining are revealed sequentially. Upon
seeing a number, she must decide whether to take that number and stop the
sequence, or to drop it and continue with the next number. Her goal is to
maximize the expected value with which she stops.
</p>
<p>On one end of the spectrum, when $p=0$, the problem is essentially equivalent
to the secretary problem and thus the optimal algorithm guarantees a reward
within a factor $1/e$ of the expected maximum value. We develop an approach,
based on the continuous limit of a factor revealing LP, that allows us to
obtain the best possible rank-based (ordinal) algorithm for any value of $p$.
Notably, we prove that as $p$ approaches 1, our guarantee approaches 0.745,
matching the best possible guarantee for the i.i.d. prophet inequality. This
implies that there is no loss by considering this more general combinatorial
version without full distributional knowledge. Furthermore, we prove that this
convergence is very fast. Along the way we show that the optimal rank-based
algorithm takes the form of a sequence of thresholds $t_1,t_2,\ldots$ such that
at time $t_i$ the algorithm starts accepting values which are among the top $i$
values seen so far.
</p></div>
    </summary>
    <updated>2020-11-15T22:45:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06481</id>
    <link href="http://arxiv.org/abs/2011.06481" rel="alternate" type="text/html"/>
    <title>Communication Efficient Coresets for Maximum Matching</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kapralov:Michael.html">Michael Kapralov</a>, Gilbert Maystre, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tardos:Jakab.html">Jakab Tardos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06481">PDF</a><br/><b>Abstract: </b>In this paper we revisit the problem of constructing randomized composable
coresets for bipartite matching. In this problem the input graph is randomly
partitioned across $k$ players, each of which sends a single message to a
coordinator, who then must output a good approximation to the maximum matching
in the input graph. Assadi and Khanna gave the first such coreset, achieving a
$1/9$-approximation by having every player send a maximum matching, i.e. at
most $n/2$ words per player. The approximation factor was improved to $1/3$ by
Bernstein et al.
</p>
<p>In this paper, we show that the matching skeleton construction of Goel,
Kapralov and Khanna, which is a carefully chosen (fractional) matching, is a
randomized composable coreset that achieves a $1/2-o(1)$ approximation using at
most $n-1$ words of communication per player. We also show an upper bound of
$2/3+o(1)$ on the approximation ratio achieved by this coreset.
</p></div>
    </summary>
    <updated>2020-11-15T22:46:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06475</id>
    <link href="http://arxiv.org/abs/2011.06475" rel="alternate" type="text/html"/>
    <title>Quantum algorithms for spectral sums</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Luongo:Alessandro.html">Alessandro Luongo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shao:Changpeng.html">Changpeng Shao</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06475">PDF</a><br/><b>Abstract: </b>We propose and analyze new quantum algorithms for estimating the most common
spectral sums of symmetric positive definite (SPD) matrices. For a function $f$
and a matrix $A \in \mathbb{R}^{n\times n}$, the spectral sum is defined as
$S_f(A) :=\text{Tr}[f(A)] = \sum_j f(\lambda_j)$, where $\lambda_j$ are the
eigenvalues. Examples of spectral sums are the von Neumann entropy, the trace
of inverse, the log-determinant, and the Schatten-$p$ norm, where the latter
does not require the matrix to be SPD. The fastest classical randomized
algorithms estimate these quantities have a runtime that depends at least
linearly on the number of nonzero components of the matrix. Assuming quantum
access to the matrix, our algorithms are sub-linear in the matrix size, and
depend at most quadratically on other quantities, like the condition number and
the approximation error, and thus can compete with most of the randomized and
distributed classical algorithms proposed in recent literature. These
algorithms can be used as subroutines for solving many practical problems, for
which the estimation of a spectral sum often represents a computational
bottleneck.
</p></div>
    </summary>
    <updated>2020-11-15T23:11:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06268</id>
    <link href="http://arxiv.org/abs/2011.06268" rel="alternate" type="text/html"/>
    <title>FPT-Algorithms for the l-Matchoid Problem with Linear and Submodular Objectives</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Chien=Chung.html">Chien-Chung Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Ward:Justin.html">Justin Ward</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06268">PDF</a><br/><b>Abstract: </b>We design a fixed-parameter deterministic algorithm for computing a maximum
weight feasible set under a $\ell$-matchoid of rank $k$, parameterized by
$\ell$ and $k$. Unlike previous work that presumes linear representativity of
matroids, we consider the general oracle model. Our result, combined with the
lower bounds of Lovasz, and Jensen and Korte, demonstrates a separation between
the $\ell$-matchoid and the matroid $\ell$-parity problems in the setting of
fixed-parameter tractability.
</p>
<p>Our algorithms are obtained by means of kernelization: we construct a small
representative set which contains an optimal solution. Such a set gives us much
flexibility in adapting to other settings, allowing us to optimize not only a
linear function, but also several important submodular functions. It also helps
to transform our algorithms into streaming algorithms.
</p>
<p>In the streaming setting, we show that we can find a feasible solution of
value $z$ and the number of elements to be stored in memory depends only on $z$
and $\ell$ but totally independent of $n$. This shows that it is possible to
circumvent the recent space lower bound of Feldman et al., by parameterizing
the solution value. This result, combined with existing lower bounds, also
provides a new separation between the space and time complexity of maximizing
an arbitrary submodular function and a coverage function in the value oracle
model.
</p></div>
    </summary>
    <updated>2020-11-15T22:45:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06250</id>
    <link href="http://arxiv.org/abs/2011.06250" rel="alternate" type="text/html"/>
    <title>Online Virtual Machine Allocation with Predictions</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Buchbinder:Niv.html">Niv Buchbinder</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fairstein:Yaron.html">Yaron Fairstein</a>, Konstantina Mellou, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Menache:Ishai.html">Ishai Menache</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Naor:Joseph.html">Joseph Naor</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06250">PDF</a><br/><b>Abstract: </b>The cloud computing industry has grown rapidly over the last decade, and with
this growth there is a significant increase in demand for compute resources.
Demand is manifested in the form of Virtual Machine (VM) requests, which need
to be assigned to physical machines in a way that minimizes resource
fragmentation and efficiently utilizes the available machines. This problem can
be modeled as a dynamic version of the bin packing problem with the objective
of minimizing the total usage time of the bins (physical machines). Earlier
works on dynamic bin packing assumed that no knowledge is available to the
scheduler and later works studied models in which lifetime/duration of each
"item" (VM in our context) is available to the scheduler. This extra
information was shown to improve exponentially the achievable competitive
ratio.
</p>
<p>Motivated by advances in Machine Learning that provide good estimates of
workload characteristics, this paper studies the effect of having extra
information regarding future (total) demand. In the cloud context, since demand
is an aggregate over many VM requests, it can be predicted with high accuracy
(e.g., using historical data). We show that the competitive factor can be
dramatically improved by using this additional information; in some cases, we
achieve constant competitiveness, or even a competitive factor that approaches
1. Along the way, we design new offline algorithms with improved approximation
ratios for the dynamic bin-packing problem.
</p></div>
    </summary>
    <updated>2020-11-15T23:06:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06204</id>
    <link href="http://arxiv.org/abs/2011.06204" rel="alternate" type="text/html"/>
    <title>Approximating the Weighted Minimum Label $s$-$t$ Cut Problem</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Peng.html">Peng Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06204">PDF</a><br/><b>Abstract: </b>In the weighted (minimum) {\sf Label $s$-$t$ Cut} problem, we are given a
(directed or undirected) graph $G=(V,E)$, a label set $L = \{\ell_1, \ell_2,
\dots, \ell_q \}$ with positive label weights $\{w_\ell\}$, a source $s \in V$
and a sink $t \in V$. Each edge edge $e$ of $G$ has a label $\ell(e)$ from $L$.
Different edges may have the same label. The problem asks to find a minimum
weight label subset $L'$ such that the removal of all edges with labels in $L'$
disconnects $s$ and $t$.
</p>
<p>The unweighted {\sf Label $s$-$t$ Cut} problem (i.e., every label has a unit
weight) can be approximated within $O(n^{2/3})$, where $n$ is the number of
vertices of graph $G$. However, it is unknown for a long time how to
approximate the weighted {\sf Label $s$-$t$ Cut} problem within $o(n)$. In this
paper, we provide an approximation algorithm for the weighted {\sf Label
$s$-$t$ Cut} problem with ratio $O(n^{2/3})$. The key point of the algorithm is
a mechanism to interpret label weight on an edge as both its length and
capacity.
</p></div>
    </summary>
    <updated>2020-11-15T22:48:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06202</id>
    <link href="http://arxiv.org/abs/2011.06202" rel="alternate" type="text/html"/>
    <title>Optimal Private Median Estimation under Minimal Distributional Assumptions</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tzamos:Christos.html">Christos Tzamos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vlatakis=Gkaragkounis:Emmanouil=Vasileios.html">Emmanouil-Vasileios Vlatakis-Gkaragkounis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zadik:Ilias.html">Ilias Zadik</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06202">PDF</a><br/><b>Abstract: </b>We study the fundamental task of estimating the median of an underlying
distribution from a finite number of samples, under pure differential privacy
constraints. We focus on distributions satisfying the minimal assumption that
they have a positive density at a small neighborhood around the median. In
particular, the distribution is allowed to output unbounded values and is not
required to have finite moments. We compute the exact, up-to-constant terms,
statistical rate of estimation for the median by providing nearly-tight upper
and lower bounds. Furthermore, we design a polynomial-time differentially
private algorithm which provably achieves the optimal performance. At a
technical level, our results leverage a Lipschitz Extension Lemma which allows
us to design and analyze differentially private algorithms solely on
appropriately defined "typical" instances of the samples.
</p></div>
    </summary>
    <updated>2020-11-15T22:47:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06173</id>
    <link href="http://arxiv.org/abs/2011.06173" rel="alternate" type="text/html"/>
    <title>Note on 3-Coloring of $(2P_4,C_5)$-Free Graphs</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jel=iacute=nek:V=iacute=t.html">Vít Jelínek</a>, Tereza Klimošová, Tomáš Masařík, Jana Novotná, Aneta Pokorná <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06173">PDF</a><br/><b>Abstract: </b>We show that the 3-coloring problem is polynomial-time solvable on
$(2P_4,C_5)$-free graphs.
</p></div>
    </summary>
    <updated>2020-11-15T22:46:13Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06166</id>
    <link href="http://arxiv.org/abs/2011.06166" rel="alternate" type="text/html"/>
    <title>Comparing computational entropies below majority (or: When is the dense model theorem false?)</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Impagliazzo:Russell.html">Russell Impagliazzo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/McGuire:Sam.html">Sam McGuire</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06166">PDF</a><br/><b>Abstract: </b>Computational pseudorandomness studies the extent to which a random variable
$\bf{Z}$ looks like the uniform distribution according to a class of tests
$\cal{F}$. Computational entropy generalizes computational pseudorandomness by
studying the extent which a random variable looks like a \emph{high entropy}
distribution. There are different formal definitions of computational entropy
with different advantages for different applications. Because of this, it is of
interest to understand when these definitions are equivalent.
</p>
<p>We consider three notions of computational entropy which are known to be
equivalent when the test class $\cal{F}$ is closed under taking majorities.
This equivalence constitutes (essentially) the so-called \emph{dense model
theorem} of Green and Tao (and later made explicit by Tao-Zeigler, Reingold et
al., and Gowers). The dense model theorem plays a key role in Green and Tao's
proof that the primes contain arbitrarily long arithmetic progressions and has
since been connected to a surprisingly wide range of topics in mathematics and
computer science, including cryptography, computational complexity,
combinatorics and machine learning. We show that, in different situations where
$\cal{F}$ is \emph{not} closed under majority, this equivalence fails. This in
turn provides examples where the dense model theorem is \emph{false}.
</p></div>
    </summary>
    <updated>2020-11-15T22:37:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06150</id>
    <link href="http://arxiv.org/abs/2011.06150" rel="alternate" type="text/html"/>
    <title>Total Completion Time Minimization for Scheduling with Incompatibility Cliques</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jansen:Klaus.html">Klaus Jansen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lassota:Alexandra.html">Alexandra Lassota</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maack:Marten.html">Marten Maack</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pikies:Tytus.html">Tytus Pikies</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06150">PDF</a><br/><b>Abstract: </b>This paper considers parallel machine scheduling with incompatibilities
between jobs. The jobs form a graph and no two jobs connected by an edge are
allowed to be assigned to the same machine. In particular, we study the case
where the graph is a collection of disjoint cliques. Scheduling with
incompatibilities between jobs represents a well-established line of research
in scheduling theory and the case of disjoint cliques has received increasing
attention in recent years. While the research up to this point has been focused
on the makespan objective, we broaden the scope and study the classical total
completion time criterion. In the setting without incompatibilities, this
objective is well known to admit polynomial time algorithms even for unrelated
machines via matching techniques. We show that the introduction of
incompatibility cliques results in a richer, more interesting picture.
Scheduling on identical machines remains solvable in polynomial time, while
scheduling on unrelated machines becomes APX-hard. Furthermore, we study the
problem under the paradigm of fixed-parameter tractable algorithms (FPT). In
particular, we consider a problem variant with assignment restrictions for the
cliques rather than the jobs. We prove that it is NP-hard and can be solved in
FPT time with respect to the number of cliques. Moreover, we show that the
problem on unrelated machines can be solved in FPT time for reasonable
parameters, e.g., the parameter pair: number of machines and maximum processing
time. The latter result is a natural extension of known results for the case
without incompatibilities and can even be extended to the case of total
weighted completion time. All of the FPT results make use of n-fold Integer
Programs that recently have received great attention by proving their
usefulness for scheduling problems.
</p></div>
    </summary>
    <updated>2020-11-15T22:39:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06135</id>
    <link href="http://arxiv.org/abs/2011.06135" rel="alternate" type="text/html"/>
    <title>Hardness of Approximate Nearest Neighbor Search under L-infinity</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Ko:Young_Kun.html">Young Kun Ko</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Song:Min_Jae.html">Min Jae Song</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06135">PDF</a><br/><b>Abstract: </b>We show conditional hardness of Approximate Nearest Neighbor Search (ANN)
under the $\ell_\infty$ norm with two simple reductions. Our first reduction
shows that hardness of a special case of the Shortest Vector Problem (SVP),
which captures many provably hard instances of SVP, implies a lower bound for
ANN with polynomial preprocessing time under the same norm. Combined with a
recent quantitative hardness result on SVP under $\ell_\infty$ (Bennett et al.,
FOCS 2017), our reduction implies that finding a $(1+\varepsilon)$-approximate
nearest neighbor under $\ell_\infty$ with polynomial preprocessing requires
near-linear query time, unless the Strong Exponential Time Hypothesis (SETH) is
false. This complements the results of Rubinstein (STOC 2018), who showed
hardness of ANN under $\ell_1$, $\ell_2$, and edit distance.
</p>
<p>Further improving the approximation factor for hardness, we show that,
assuming SETH, near-linear query time is required for any approximation factor
less than $3$ under $\ell_\infty$. This shows a conditional separation between
ANN under the $\ell_1/ \ell_2$ norm and the $\ell_\infty$ norm since there are
sublinear time algorithms achieving better than $3$-approximation for the
$\ell_1$ and $\ell_2$ norm. Lastly, we show that the approximation factor of
$3$ is a barrier for any naive gadget reduction from the Orthogonal Vectors
problem.
</p></div>
    </summary>
    <updated>2020-11-15T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06112</id>
    <link href="http://arxiv.org/abs/2011.06112" rel="alternate" type="text/html"/>
    <title>Tree Embeddings for Hop-Constrained Network Design</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haeupler:Bernhard.html">Bernhard Haeupler</a>, D Ellis Hershkowitz, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zuzic:Goran.html">Goran Zuzic</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06112">PDF</a><br/><b>Abstract: </b>Network design problems aim to compute low-cost structures such as routes,
trees and subgraphs. Often, it is natural and desirable to require that these
structures have small hop length or hop diameter. Unfortunately, optimization
problems with hop constraints are much harder and less well understood than
their hop-unconstrained counterparts. A significant algorithmic barrier in this
setting is the fact that hop-constrained distances in graphs are very far from
being a metric.
</p>
<p>We show that, nonetheless, hop-constrained distances can be approximated by
distributions over "partial tree metrics." We build this result into a powerful
and versatile algorithmic tool which, similarly to classic probabilistic tree
embeddings, reduces hop-constrained problems in general graphs to
hop-unconstrained problems on trees. We then use this tool to give the first
poly-logarithmic bicriteria approximations for the hop-constrained variants of
many classic network design problems. These include Steiner forest, group
Steiner tree, group Steiner forest, buy-at-bulk network design as well as
online and oblivious versions of many of these problems.
</p></div>
    </summary>
    <updated>2020-11-15T22:44:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2011.06108</id>
    <link href="http://arxiv.org/abs/2011.06108" rel="alternate" type="text/html"/>
    <title>An Optimal Rounding for Half-Integral Weighted Minimum Strongly Connected Spanning Subgraph</title>
    <feedworld_mtime>1605398400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>D Ellis Hershkowitz, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kehne:Gregory.html">Gregory Kehne</a>, R. Ravi <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2011.06108">PDF</a><br/><b>Abstract: </b>In the weighted minimum strongly connected spanning subgraph (WMSCSS) problem
we must purchase a minimum-cost strongly connected spanning subgraph of a
digraph. We show that half-integral linear program (LP) solutions for WMSCSS
can be efficiently rounded to integral solutions at a multiplicative $1.5$
cost. This rounding matches a known $1.5$ integrality gap lower bound for a
half-integral instance. More generally, we show that LP solutions whose
non-zero entries are at least a value $f &gt; 0$ can be rounded at a
multiplicative cost of $2 - f$.
</p></div>
    </summary>
    <updated>2020-11-15T23:10:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-11-13T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3746629932537659579</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3746629932537659579/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/11/alex-trebekwhat-is-todays-post-about.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3746629932537659579" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3746629932537659579" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/11/alex-trebekwhat-is-todays-post-about.html" rel="alternate" type="text/html"/>
    <title>Alex Trebek/What is today's post about?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p> Alex Trebek, long time host of the TV show Jeopardy! (the exclamation point is part of the name, though I will omit it for the rest of the post), passed away in November of 2020 at the age of 80. He announced he had pancreatic cancer in March 2019.</p><p>0) <a href="https://blog.computationalcomplexity.org/search?q=Jeopardy">Here</a> is a pointer to a page that has all of our posts with the word <i>Jeopardy </i>in them. Some are about the show and others mention the show in passing. All of the posts relate to the TV show. That is because Lance and I lead fairly safe lives.</p><p>1) On April Fools day of 1997 Pat Sajak hosted <i>Jeopardy</i> and Alex Trebek hosted <i>Wheel of Fortune</i>. Both are on You tube: <a href="https://www.youtube.com/watch?v=dtIT-jr1hmQ">Trebek hosts wheel</a>, <a href="https://www.youtube.com/watch?v=LwVNmYjClXE">Pat hosts Jeopardy</a> Alex's hosting was more fun because- well, you can see for yourself. </p><p>2) Aside from that one day, Alex Trebek hosted <i>Jeopardy</i> every night since he began in 1984. </p><p>3) My favorite pangram (sentence that has all 26 letters) is</p><p>Watch <i>Jeopardy!</i>, Alex Trebek's fun TV quiz game show. </p><p>(See my post on natural pangrams <a href="https://blog.computationalcomplexity.org/2017/11/can-you-measure-which-panagrams-are.html">here</a> for... more natural pangrams and a discussion of what natural means.) </p><p>It's my favorite since I can really imagine someone saying it. The show should have used it for its tagline. And now they can't :-(</p><p>4) From Alex's comments he seems to like high scoring games that are not run-a-ways. He also likes when people bet big on the daily doubles and on<i> final Jeopardy</i>.  I think he liked having long win streaks like Ken Jenning's  and James Holzhauer, but see point 7 below.  I think he didn't like it when people go for the high scoring questions first (perhaps looking for the Daily Double) since sometimes the category name is not quite clear (e.g., <i>Country Groups</i> could be things like<i> NATO </i>or things like <i>The Charlie Daniels Band</i>) so you want to do a cheap question to get your feet wet, and also easier for the audience to see what the category means.  IMHO they should really make the Daily Double Uniformly distributed on all the squares instead of having it tend to be the bigger-money questions. </p><p>5) When the final <i>Jeopardy</i> category is  revealed he sometimes says <i>that's a  good category!</i> or <i>that sounds hard. </i> Makes me wonder that if he makes no comment he is thinking<i> that's a stupid categor</i>y  or <i>Gee that's easy.</i></p><p>6) Because of the pandemic they could not, for a while, make new shows. Hence  they aired old shows including the  first ever Alex-Trebek-<i>Jeopardy</i> (the show had been hosted by Art Fleming and the Trebek-version was really a reboot). From that show I found out WHY it's called<i> Jeopardy</i> (a question I had never thought about). It's because if you get an answer WRONG you can LOSE money- that's the Jeopardy. Not really a good name, but by now everyone knows the show by that name.</p><p>7) Art Fleming also died of pancreatic cancer, back in 1995 (he was 70). Coincidence? Well, yes, though two game show hosts of the same show dying of the same disease 25 years apart could be the premise of a really bad murder mystery. </p><p>8) Alex makes some small talk with the contestants  (though some is edited for time). Things like <i>I hear you have a book on muffins that is not a cookbook-- what's that all about?</i>' I wonder if during Ken Jenning's 74-long winning streak, towards the end,  Alex ran out of things to ask him. I can imagine <i>I hear you're pretty good at Jeopardy.</i></p><p>9) I wonder how good Alex would be playing <i>Jeopardy</i>. When he hosted <i>Wheel of Fortune</i> he said in passing that he would NEVER go on <i>Jeopardy</i> as a contestant, so he doesn't think he would do well. He could be wrong about that since over time they ask questions that are not quite repeats but draw on the same knowledge- and he's heard all of them. However, it could be that he is too busy concentrating on other things to really absorb all of this knowledge. </p><p>10) The <i>we give the answers you give the questions </i>is a bit odd. However, in my classes I  sometimes say  <i>We'll Trebek this - we know what the answer is, we have to find the question</i>.</p><p>11) <a href="https://www.youtube.com/watch?v=A7UgxCayfV0">This</a> youtube video is of a contestant singing WORDS to the <i>Jeopardy</i> theme song that he wrote.The contestant  refers to Jon Stewart as having also written words to the <i>Jeopardy</i> theme, but I can't find that anywhere- if you can, let me know. </p><p>12) Weird Al did a novelty song about <i>Jeopardy</i> using Art Fleming in the video (see  <a href="https://www.youtube.com/watch?v=BvUZijEuNDQ">here</a>)  I always hoped he would update it and use Alex Trebek. He never did and now he can't :-( OR-with todays technology maybe he can. Here's hoping!</p><p>13) Alex Trebek was in a category by himself!</p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2020-11-14T20:26:00Z</updated>
    <published>2020-11-14T20:26:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-11-15T09:47:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/11/14/pathbreaking-for-intervals</id>
    <link href="https://11011110.github.io/blog/2020/11/14/pathbreaking-for-intervals.html" rel="alternate" type="text/html"/>
    <title>Pathbreaking for intervals</title>
    <summary>The use of Nash’s Hex lemma in my previous post, according to which any 2-coloring of a triangular grid has a long monochromatic path, naturally raises the question: for which graphs other than the triangular grid is this true? In that post I mentioned that it is also true for certain outerplanar graphs, but false for bipartite graphs and for subcubic graphs. Here’s another class of graphs for which it is false: the graphs of bounded pathwidth. These graphs can always be 2-colored in a way that breaks up all long paths, leaving the remaining monochromatic paths of bounded size.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The use of Nash’s Hex lemma in <a href="https://11011110.github.io/blog/2020/11/10/hex-books-queues.html">my previous post</a>, according to which any 2-coloring of a triangular grid has a long monochromatic path, naturally raises the question: for which graphs other than the triangular grid is this true? In that post I mentioned that it is also true for certain outerplanar graphs, but false for bipartite graphs and for subcubic graphs. Here’s another class of graphs for which it is false: the graphs of bounded <a href="https://en.wikipedia.org/wiki/Pathwidth">pathwidth</a>. These graphs can always be 2-colored in a way that breaks up all long paths, leaving the remaining monochromatic paths of bounded size.</p>

<p>Rather than dealing with pathwidth directly, I want to formulate it geometrically in terms of interval graphs. Every graph can be completed (by adding extra edges) to form an <a href="https://en.wikipedia.org/wiki/Interval_graph">interval graph</a> of the same pathwidth; an interval graph has one-dimensional closed intervals as its vertices, connected by an edge whenever they intersect. The pathwidth of an interval graph is always one less than the maximum number of intervals that overlap at the same point (their ply). So rather than looking at graphs of bounded pathwidth I’ll be considering sets of intervals of bounded ply. For example in the illustration below which I drew a few years ago for Wikipedia, the intervals shown have ply 3, and their interval graph has pathwidth 2.</p>

<p style="text-align: center;"><img alt="A set of intervals and their associated interval graph" src="https://11011110.github.io/blog/assets/2020/interval-graph.svg"/></p>

<p>Intervals with low ply that are all either nested or disjoint can have no long paths in their intersection graph regardless of coloring. In any set of intervals forming a path, the path can pass through the outermost level of nesting at most once, subdividing it into two smaller paths with lower ply. It follows by induction the number of intervals in the path can be at most \(2^{\operatorname{ply}}-1\). (This is the standard argument behind an equivalence in graphs between longest path length and <a href="https://en.wikipedia.org/wiki/Tree-depth">tree-depth</a>.) So if we could partition an arbitrary set of intervals into two subsets within which all intervals are nested or disjoint, we’d be done. For instance, in the example above, the partition into \(\{A,B,F\}\) and \(\{C,D,E,G\}\) works. Not every set of intervals can be partitioned in this way, but I’ll show below that it’s always possible to lengthen some intervals, keeping the ply small, so that the lengthened intervals can be partitioned (colored) into two nested subsets.</p>

<p>As a subroutine in the construction, let’s find a set of points with the following properties:</p>

<ul>
  <li>
    <p>Each interval lies strictly between the leftmost and rightmost selected points.</p>
  </li>
  <li>
    <p>No interval covers more than one selected point.</p>
  </li>
  <li>
    <p>The union of the intervals that cover selected points equals the union of all the intervals.</p>
  </li>
</ul>

<p>This can be done by a greedy algorithm that repeatedly selects an uncovered interval endpoint until the intervals that cover selected points also cover all other interval endpoints. Finish by selecting any two points to the left and right of all the intervals, and then number the selected points as \(x_0,x_1,\dots\) in left-to-right order. For example, one possible choice for our example would have \(x_0\) to the left of the intervals, \(x_1\) at the left endpoint of \(D\), \(x_2\) at the left endpoint of \(F\), and \(x_3\) to the right of the intervals. For this choice, \(B\) and \(E\) do not cover any selected points, but that’s not a problem. It’s not necessary to optimize how many points are selected.</p>

<p>Call an interval “odd” if it covers an odd-numbered point \(x_i\) and “even” if it covers an even-numbered point. In our example, \(A\), \(C\), and \(D\) are odd, and \(F\), and \(G\) are even, but \(B\) and \(E\) are neither odd nor even. We will color the odd intervals blue and the even intervals red. Because they are different colors, we don’t have to worry about nesting between odd and even intervals. However, the intervals that contain any single point \(x_i\) will have the same color and need to be lengthened to nesting intervals. To do so, we extend all these intervals to a single longer interval, from just after \(x_{i-1}\) to just before \(x_{i+1}\). Because of the way the points \(x_i\) were chosen, this does not create new intersections between intervals of the same color, and it makes all colored intervals nest with all uncolored ones (not just with each other). However, it can also increase the ply. If the ply was \(p\) previously, it can increase by as much as \(2p-1\), when a point that was previously covered by only one odd or even interval becomes covered by \(2p-1\) more of them.</p>

<p>Finally, we apply the same coloring and lengthening process recursively, to the remaining subsets of uncolored intervals between each pair of selected points.
To make sure the intervals stay nested after lengthening, we take care in each recursive subproblem to select its first and last points to be inside all intervals of the outer problem that contain the subproblem. Because every point in an interval of a recursive subproblem is also in at least one of the outer colored intervals, the recursive subproblem has smaller ply than the initial ply of the outer problem. The recursion stops at ply 2; for this ply the intersection graph is a tree (more precisely a caterpillar) and it is possible to 2-color the intervals without any lengthening so that no two intervals of the same color intersect, by 2-coloring the tree.</p>

<p>So if we start with intervals of ply 2, we produce a lengthened, 2-colored, and monochromatically nested set of intervals of ply 2 again (no change to the ply). If we start with intervals of ply 3, we produce a lengthened, 2-colored, and monochromatically nested set of intervals of ply at most 8, because the ply-3 interval-lengthening process added at most 5 to the existing ply. More generally for any starting ply \(p\) the new ply will be at most \(p^2+p-4\). And since the interval graph for the lengthened intervals has no monochromatic path with more than \(2^{p^2+p-4}-1\) intervals in it, neither does the interval graph for the original intervals, with the same 2-coloring.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/105211974100055236">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-11-14T17:59:00Z</updated>
    <published>2020-11-14T17:59:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-11-16T05:34:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=20366</id>
    <link href="https://gilkalai.wordpress.com/2020/11/14/to-cheer-you-up-in-difficult-times-13-triangulating-real-projective-spaces-with-subexponentially-many-vertices/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 13: Triangulating real projective spaces with subexponentially many vertices</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Wolfgang Kühnel Today I want to talk about a new result in a newly arXived paper: A subexponential size by Karim Adiprasito, Sergey Avvakumov, and Roman Karasev. Sergey Avvakumov gave about it a great zoom seminar talk about the result … <a href="https://gilkalai.wordpress.com/2020/11/14/to-cheer-you-up-in-difficult-times-13-triangulating-real-projective-spaces-with-subexponentially-many-vertices/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2020/11/wk.jpg"><img alt="" class="alignnone size-full wp-image-20381" src="https://gilkalai.files.wordpress.com/2020/11/wk.jpg?w=640"/></a></p>
<p><span style="color: #ff0000;">Wolfgang Kühnel</span></p>
<p>Today I want to talk about a new result in a newly arXived paper: <a href="https://arxiv.org/abs/2009.02703">A subexponential size <img alt="\mathbb RP^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+RP%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\mathbb RP^n"/> by Karim Adiprasito, Sergey Avvakumov, and Roman Karasev</a>. Sergey Avvakumov gave about it a <strong>great</strong> zoom seminar talk about the result in our combinatorics seminar. <a href="https://huji.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=602454e6-d104-42fe-849c-ac6000b7517b">Here is the link</a>.</p>
<p>The question is very simple: <strong>W<span style="color: #0000ff;">hat is the smallest number of vertices required to triangulate the <em>n</em>-dimensional real projective space?</span></strong></p>
<p>The short paper exhibits a triangulation with <img alt="\exp (\frac {1}{2} \sqrt n \log n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cexp+%28%5Cfrac+%7B1%7D%7B2%7D+%5Csqrt+n+%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\exp (\frac {1}{2} \sqrt n \log n)"/> vertices.  This is the first construction that requires subexponential number of vertices in the dimension. The best lower bound by Pierre Arnoux and Alexis Marin (from 1999) are quadratic, so there is quite a way to go with the problem. I am thankful to Ryan Alweiss who was the first to tell me about the new result.</p>
<h2>Reasons to care</h2>
<p>Representing a topological space using simplicial complexes arose in the early days of algebraic topology, but there are certainly more “efficient” representations. What is the reason to to care specifically about representations via simplicial complexes? Here are my answers</p>
<ol>
<li>Constructions of triangulated manifolds with few vertices are occasionally amazing mathematical objects.</li>
<li>Simplicial complexes arise in many combinatorial and algebraic contexts,</li>
<li>The study of face numbers of simplicial complexes with various topological properties is often related to deep questions in algebra, geometry, and topology,</li>
<li>We care also about other types of representation.</li>
</ol>
<h2>Kühnel and Lassmann’s complex projective plane with nine vertices and other miracles</h2>
<p>You may all be familiar with the 6-vertex triangulation of the projective space. It is obtained by identifying opposite faces of the icosahedron. It is 2-neighborly, namely every pair of vertices span an edge of the triangulation. (It also played a role in my high dimensional extension of Cayley’s counting trees formula.) The existence of 2-neighborly triangulations of other closed surfaces is essentially the <a href="https://en.wikipedia.org/wiki/Heawood_conjecture">Heawood 1890 conjecture</a> solved by Ringel and Young in the 1960s.</p>
<p>In 1980 Wolfgang Kühnel set out to construct a 3-neighborly triangulation of the complex projective plane with 9 vertices. The construction, achieved in <a href="https://www.sciencedirect.com/science/article/pii/0097316583900055?via%3Dihub">a paper by Kühnel and Lassmann</a> (who also proved uniqueness), and discussed in <a href="http://www.math.brown.edu/~banchoff/howison/newbanchoff/publications/pdfs/9Vertex.pdf">a paper of the same year by Kühnel and Banchof</a>, is, in my view, among the most beautiful constructions in mathematics with additional hidden structures and many connections. Some motivation to the work came from the study of tight embeddings of smooth manifolds and Morse theory.</p>
<p>Ulrich Brehm and Kühnel <a href="https://www.sciencedirect.com/science/article/pii/0040938387900425?via%3Dihub">proved</a> that if a <span class="MathJax" id="MathJax-Element-1-Frame"><span class="math" id="MathJax-Span-1"><span class="mrow" id="MathJax-Span-2"><span class="mi" id="MathJax-Span-3">d</span></span></span></span>-manifold has fewer than <span class="MathJax" id="MathJax-Element-2-Frame"><span class="math" id="MathJax-Span-4"><span class="mrow" id="MathJax-Span-5"><span class="mn" id="MathJax-Span-6">3</span><span class="mo" id="MathJax-Span-7">⌈</span><span class="mi" id="MathJax-Span-8">d</span><span class="texatom" id="MathJax-Span-9"><span class="mrow" id="MathJax-Span-10"><span class="mo" id="MathJax-Span-11">/</span></span></span><span class="mn" id="MathJax-Span-12">2</span><span class="mo" id="MathJax-Span-13">⌉</span><span class="mo" id="MathJax-Span-14">+</span><span class="mn" id="MathJax-Span-15">3</span></span></span></span> vertices then it is homeomorphic to a sphere, and if it has exactly <span class="MathJax" id="MathJax-Element-3-Frame"><span class="math" id="MathJax-Span-16"><span class="mrow" id="MathJax-Span-17"><span class="mn" id="MathJax-Span-18">3</span><span class="mo" id="MathJax-Span-19">(</span><span class="mi" id="MathJax-Span-20">d</span><span class="texatom" id="MathJax-Span-21"><span class="mrow" id="MathJax-Span-22"><span class="mo" id="MathJax-Span-23">/</span></span></span><span class="mn" id="MathJax-Span-24">2</span><span class="mo" id="MathJax-Span-25">)</span><span class="mo" id="MathJax-Span-26">+</span><span class="mn" id="MathJax-Span-27">3</span></span></span></span> vertices and is not a sphere, then <span class="MathJax" id="MathJax-Element-4-Frame"><span class="math" id="MathJax-Span-28"><span class="mrow" id="MathJax-Span-29"><span class="mi" id="MathJax-Span-30">d</span><span class="mo" id="MathJax-Span-31">=</span><span class="mn" id="MathJax-Span-32">2</span><span class="mo" id="MathJax-Span-33">,</span><span class="mn" id="MathJax-Span-34">4</span><span class="mo" id="MathJax-Span-35">,</span><span class="mn" id="MathJax-Span-36">8</span></span></span></span> or <span class="MathJax" id="MathJax-Element-5-Frame"><span class="math" id="MathJax-Span-37"><span class="mrow" id="MathJax-Span-38"><span class="mn" id="MathJax-Span-39">16</span></span></span></span> and the manifold has a nondegenerate height function with exactly three critical points. The 6-vertex <img alt="\mathbb RP^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+RP%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\mathbb RP^2"/> and the 9-vertex $\mathbbCP^2$ are examples for dimensions 2 and 4. We can expect further such examples for projective planes over the quaternions and octonions. <a href="https://link.springer.com/article/10.1007%2FBF01934320">Brehm and Kühnel</a> constructed three 8-dimensional 5-neighborly “manifolds” which are not combinatorially isomorphic. It is conjectured but not known that they all triangulate the quaternionic projective plane.</p>
<h2>The result of <a href="https://arxiv.org/abs/2009.02703">Adiprasito, Avvakumov, and Karasev</a> as <a href="https://huji.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=602454e6-d104-42fe-849c-ac6000b7517b">told by Sergey Avvakumov</a>.</h2>
<p>Here is a brief description of Sergey Avvakumov’s lecture. (As far as I could see the proof of their result is fully presented along with  3 other proofs for basic related results.)</p>
<p><span style="color: #0000ff;"><strong>06:00</strong></span>  The lecture starts. A simple inductive constructions of  a triangulation of <img alt="\mathbb R P^n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R+P%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\mathbb R P^n"/>.</p>
<p><span style="color: #0000ff;"><strong>08:00</strong></span>  Equivalent statement: we seek a centrally symmetric triangulation of the n-sphere with diameter 3.</p>
<p><strong><span style="color: #0000ff;">09:00</span></strong> 6-vertex triangulation of  <img alt="\mathbb R P^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R+P%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" title="\mathbb R P^2"/></p>
<p><strong><span style="color: #0000ff;">11:00</span></strong> The construction: triangulate the positive facets of the cross polytope and symmetrically the negative facet. Follow a recipe to triangulate the side facets. Crucial question: what is needed from the triangulation T of the positive facet. Answer: <span style="color: #0000ff;"><strong>No edge between two disjoint faces</strong></span>.</p>
<p><span style="color: #0000ff;"><strong>23:00</strong> </span>Spherical interpretation and Delaunay triangulations of a certain configuration V</p>
<p><strong><span style="color: #0000ff;">31:00</span></strong>   A sufficient combinatorial condition</p>
<p><strong><span style="color: #0000ff;">39:00</span></strong> Proof of sufficiency</p>
<p><strong><span style="color: #0000ff;">54:00</span></strong> The construction!</p>
<p><strong><span style="color: #0000ff;">1:09:00</span></strong> Counting the number of vertices completes the proof of the theorem.</p>
<p>Additional matters</p>
<p><strong><span style="color: #0000ff;">1:11:00</span></strong> A proof of a quadratic lower bound by Kuhnel.</p>
<p><strong><span style="color: #0000ff;">1:21:00</span></strong> Proof of the facet lower bound (Barany and Lovasz) via Borsuk-Ulam</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/11/semtri7.png"><img alt="" class="alignnone size-full wp-image-20397" height="306" src="https://gilkalai.files.wordpress.com/2020/11/semtri7.png?w=640&amp;h=306" width="640"/></a></p>
<h2>Open problems and Low dimensions</h2>
<p>Of course a main question is what is the minimum number of vertices required for a triangulation of n dimensional real projective space. What about the n-dimensional complex projective space? What is the situation for low dimensions? See also the paper by Sonia Balagopalan, <a href="https://arxiv.org/abs/1409.6149">On a vertex-minimal triangulation of RP^4</a>.</p></div>
    </content>
    <updated>2020-11-14T17:52:54Z</updated>
    <published>2020-11-14T17:52:54Z</published>
    <category term="Algebra"/>
    <category term="Combinatorics"/>
    <category term="Geometry"/>
    <category term="Karim Adiprasito"/>
    <category term="Roman Karasev"/>
    <category term="Sergey Avvakumov"/>
    <category term="Wolfgang Kuhnel"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-11-16T18:20:33Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/11/14/postdoc-positions-at-foundations-of-data-science-institute-fodsi-apply-by-december-1-2020/</id>
    <link href="https://cstheory-jobs.org/2020/11/14/postdoc-positions-at-foundations-of-data-science-institute-fodsi-apply-by-december-1-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc positions at Foundations of Data Science Institute (FODSI) (apply by December 1, 2020)</title>
    <summary>The Foundations of Data Science Institute (FODSI), funded by the National Science Foundation TRIPODS program, is announcing a competitive postdoctoral fellowship. Multiple positions are available. FODSI is a collaboration between UC Berkeley and MIT, partnering with Boston University, Northeastern University, Harvard University, Howard University and Bryn Mawr College. Website: https://academicjobsonline.org/ajo/jobs/17305 Email: see the URL</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Foundations of Data Science Institute (FODSI), funded by the National Science Foundation TRIPODS program, is announcing a competitive postdoctoral fellowship. Multiple positions are available. FODSI is a collaboration between UC Berkeley and MIT, partnering with Boston University, Northeastern University, Harvard University, Howard University and Bryn Mawr College.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/17305">https://academicjobsonline.org/ajo/jobs/17305</a><br/>
Email: see the URL</p></div>
    </content>
    <updated>2020-11-14T17:52:02Z</updated>
    <published>2020-11-14T17:52:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-11-16T18:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/172</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/172" rel="alternate" type="text/html"/>
    <title>TR20-172 |  Optimal rate list decoding over bounded alphabets using algebraic-geometric codes | 

	Venkatesan Guruswami, 

	Chaoping Xing</title>
    <summary>We construct two classes of algebraic code families which are efficiently list decodable with small output list size from a fraction $1-R-\epsilon$ of adversarial errors where $R$ is the rate of the code, for any desired positive constant $\epsilon$. The alphabet size depends only on $\epsilon$ and is nearly-optimal.

The first class of codes are obtained by folding algebraic-geometric codes using automorphisms of the underlying function field. The second class of codes are obtained by restricting evaluation points of an algebraic-geometric code to rational points from a subfield. In both cases, we develop a linear-algebraic approach to perform list decoding, which pins down the candidate messages to a subspace with a nice "periodic" structure.

To prune this subspace and obtain a good bound on the list-size, we pick subcodes of these codes by pre-coding into certain subspace-evasive sets which are guaranteed to have small intersection with the sort of periodic subspaces that arise in our list decoding. We develop two approaches for constructing such subspace-evasive sets. The first is a Monte Carlo construction of hierearchical subspace-evasive (h.s.e) sets which leads to excellent list-size but is not explicit. The second approach exploits a further ultra-periodicity of our subspaces and uses a novel construct called subspace designs, which were subsequently constructed explicitly and also found further applications in pseudorandomness.

To get a family of codes over a fixed alphabet size, we instantiate our approach with algebraic-geometric codes based on the Garcia-Stichtenoth tower of function fields. Combining this with pruning via h.s.e sets yields codes list-decodable up to a $1-R-\epsilon$ error fraction with list size bounded by $O(1/\epsilon)$, matching the existential bound for random codes up to constant factors. Further, the alphabet size can be made $\exp(\tilde{O}(1/\epsilon^2))$ which is not much worse than the lower bound of $\exp(\Omega(1/\epsilon))$. The parameters we achieve are thus quite close to the  existential bounds in all three aspects---error-correction radius, alphabet size, and list-size---simultaneously. This construction is, however, Monte Carlo and the claimed list decoding property only holds with high probability. Once the code is (efficiently) sampled, the encoding/decoding algorithms are deterministic with a running time $O_\epsilon(N^c)$ for an absolute constant $c$, where $N$ is the code's block length.

Using subspace designs instead for the pruning, our approach yields a deterministic construction of an algebraic code family of rate $R$ with efficient list decoding from $1-R-\epsilon$ fraction of errors over an alphabet of constant size $\exp(\tilde{O}(1/\epsilon^2))$.  The list size bound is upper bounded by a very slowly growing function of the block length $N$; in particular, it is at most $O(\log^{(r)} N)$ (the $r$'th iterated logarithm) for any fixed integer $r$. The explicit construction avoids the shortcoming of the Monte Carlo sampling at the expense of a worse list size.</summary>
    <updated>2020-11-13T15:16:25Z</updated>
    <published>2020-11-13T15:16:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-11-16T18:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/11/12/postdoc-position-at-boston-college-apply-by-december-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/11/12/postdoc-position-at-boston-college-apply-by-december-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc Position at Boston College (apply by December 15, 2020)</title>
    <summary>Applications are invited for a postdoc position hosted by Hsin-Hao Su at Boston College. Areas of specific interests include but not limited to distributed graph algorithms, local algorithms, dynamic graph algorithms, gossip algorithms, and massively parallel computation algorithms. Website: https://sites.google.com/site/distributedhsinhao/postdoc Email: suhx@bc.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a postdoc position hosted by Hsin-Hao Su at Boston College. Areas of specific interests include but not limited to distributed graph algorithms, local algorithms, dynamic graph algorithms, gossip algorithms, and massively parallel computation algorithms.</p>
<p>Website: <a href="https://sites.google.com/site/distributedhsinhao/postdoc">https://sites.google.com/site/distributedhsinhao/postdoc</a><br/>
Email: suhx@bc.edu</p></div>
    </content>
    <updated>2020-11-12T22:58:17Z</updated>
    <published>2020-11-12T22:58:17Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-11-16T18:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17747</id>
    <link href="https://rjlipton.wordpress.com/2020/11/12/the-art-of-math/" rel="alternate" type="text/html"/>
    <title>The Art of Math</title>
    <summary>Art, history, and controversy Jemma Lorenat is an assistant professor at Pitzer College in Los Angeles. She teaches and does research on the history of mathematics. Today I thought we’d look at some of her work. History of math is one topic that we have focused on many times before. More on that in a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Art, history, and controversy</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p>
Jemma Lorenat is an assistant professor at <a href="https://www.pitzer.edu">Pitzer College</a> in Los Angeles. She teaches and does research on the history of mathematics.<br/>
<a href="https://rjlipton.wordpress.com/2020/11/12/the-art-of-math/jemma/" rel="attachment wp-att-17751"><img alt="" class="alignright size-full wp-image-17751" src="https://rjlipton.files.wordpress.com/2020/10/jemma.png?w=600"/></a></p>
<p>
Today I thought we’d look at some of her work. </p>
<p>
History of math is one topic that we have focused on many times before. More on that in a moment. </p>
<p>
</p><p/><h2> Her Art </h2><p/>
<p/><p>
But before we do that I wish to present Lorenat’s art work. My late father, Jack Lipton, was an artist and so perhaps I have a genetic interest in art. Lorenat is an artist besides being a mathematician. You can see some of her drawings of famous mathematicians <a href="https://www.maa.org/press/periodicals/convergence/portrait-gallery">here</a>. Her elegant style I find appealing. See if you like it as much as I do. My dad taught me: </p>
<blockquote><p><b> </b> <em> A clean drawing is more difficult to execute than a busy one. It is hard to hide flaws when your art is clean. </em>
</p></blockquote>
<p>Her drawings are clean indeed. </p>
<p>
Here are three of Lorenat’s drawings of the following three famous mathematicians in some order: Which is which? Prizes will not be given to those with correct answers.</p>
<ol>
<li>
Eric Temple Bell <p/>
</li><li>
Jacques Hadamard <p/>
</li><li>
Henri Lebesgue
</li></ol>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/11/12/the-art-of-math/group-2/" rel="attachment wp-att-17753"><img alt="" class="aligncenter size-full wp-image-17753" height="274" src="https://rjlipton.files.wordpress.com/2020/10/group.png?w=600&amp;h=274" width="600"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
</p><p/><h2> Her Research </h2><p/>
<p/><p>
Lorenat’s research is on the history of mathematics. My first choice is to create math, but I am intrigued by the history of who did what, when, and why. We must understand history—at least in broad strokes—if we are to continue to make progress. History helps us understand how progress was made and how it was not. History teaches us much about our field, about mathematics. </p>
<p>
<a href="http://archives.math.utk.edu/topics/history.html">Several</a> online <a href="https://www.math.tamu.edu/~dallen/masters/hist_frame.htm">sources</a> show the field’s breadth and scope. Among issues and <a href="https://en.wikipedia.org/wiki/List_of_mathematics_history_topics">topics</a>, we note:</p>
<ul>
<li>
Who is a result named for? <p/>
</li><li>
Who gets the credit for a result? <p/>
</li><li>
What is the strongest result known? <p/>
</li><li>
Is this result correct?
</li></ul>
<p>
It is fun to see the process in action. One example I have been involved in for a long time is the study of vector addition systems and reachability problems. There continues to be exciting news, for instance, a <a href="https://arxiv.org/pdf/1809.07115.pdf">paper</a> last year showing that a central reachability problem is vastly harder than had been conjectured. I will discuss, however, an issue from two centuries ago that Lorenat has illuminated.</p>
<p>
</p><p/><h2> The Duality Controversy </h2><p/>
<p/><p>
Lorenat has a <a href="https://rjlipton.files.wordpress.com/2020/11/78167-culturalcontextconference2015.pdf">talk</a> on the geometric theory of duality. It was a prime example of a controversy in the discover of a basic math idea. Here duality means: Given a statement from projective geometry we can flip points and lines and still leave its correctness invariant. This is the duality: 	</p>
<p align="center"><img alt="\displaystyle  points \iff lines. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++points+%5Ciff+lines.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  points \iff lines. "/></p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/11/12/the-art-of-math/dual/" rel="attachment wp-att-17754"><img alt="" class="aligncenter size-full wp-image-17754" src="https://rjlipton.files.wordpress.com/2020/10/dual.png?w=600"/></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
In complexity theory we have our own duality. Instead of flipping points and lines we can exchange boolean operations 	</p>
<p align="center"><img alt="\displaystyle  AND \iff OR, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++AND+%5Ciff+OR%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  AND \iff OR, "/></p>
<p>and also exchange 	</p>
<p align="center"><img alt="\displaystyle  0 \iff 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++0+%5Ciff+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  0 \iff 1. "/></p>
<p>	 Thus 	</p>
<p align="center"><img alt="\displaystyle  (x \wedge y) \vee (x \wedge z) \iff (x \vee y) \wedge (x \vee z). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28x+%5Cwedge+y%29+%5Cvee+%28x+%5Cwedge+z%29+%5Ciff+%28x+%5Cvee+y%29+%5Cwedge+%28x+%5Cvee+z%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" title="\displaystyle  (x \wedge y) \vee (x \wedge z) \iff (x \vee y) \wedge (x \vee z). "/></p>
<p>		 Lorenat’s talk highlights a controversy between: Joseph Diaz Gergonne, Jean-Victor Poncelet, and Julius Plucker. Her work is <a href="https://www.cambridge.org/core/journals/science-in-context/article/polemics-in-public-poncelet-gergonne-plucker-and-the-duality-controversy/C305E6B9326F2AC4C8AC31D4194FEDC6">here</a>. </p>
<blockquote><p><b> </b> <em> A plagiarism charge in 1827 sparked a public controversy centered between Jean-Victor Poncelet (1788-1867) and Joseph-Diez Gergonne (1771-1859) over the origin and applications of the principle of duality in geometry. Over the next three years and through the pages of various journals, monographs, letters, reviews, reports, and footnotes, vitriol between the antagonists increased as their potential publicity grew. While the historical literature offers valuable resources toward understanding the development, content, and applications of geometric duality, the hostile nature of the exchange seems to have deterred an in-depth textual study of the explicitly polemical writings. We argue that the necessary collective endeavor of beginning and ending this controversy constitutes a case study in the circulation of geometry. In particular, we consider how the duality controversy functioned as a medium of communicating new fundamental principles to a wider audience of practitioners. </em>
</p></blockquote>
<p/><p>
A further comment is <a href="https://en.wikipedia.org/wiki/Duality_(projective_geometry)">here</a>:</p>
<blockquote><p><b> </b> <em> Of this feud, Pierre Samuel has quipped that since both men were in the French army and Poncelet was a general while Gergonne a mere captain, Poncelet’s view prevailed, at least among their French contemporaries. </em>
</p></blockquote>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Did you see which drawing was which? </p>
<p><a href="https://rjlipton.wordpress.com/2020/11/12/the-art-of-math/answer-3/" rel="attachment wp-att-17763"><img alt="" class="aligncenter size-full wp-image-17763" src="https://rjlipton.files.wordpress.com/2020/10/answer-1.png?w=600"/></a></p>
<p/></font></font></div>
    </content>
    <updated>2020-11-12T19:14:31Z</updated>
    <published>2020-11-12T19:14:31Z</published>
    <category term="History"/>
    <category term="People"/>
    <category term="Results"/>
    <category term="controversy"/>
    <category term="duality"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-11-16T18:20:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5094</id>
    <link href="https://www.scottaaronson.com/blog/?p=5094" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5094#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5094" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">The Complexity Zoo needs a new home</title>
    <summary xml:lang="en-US">Update (Nov. 14): I now have a deluge of serious hosting offers—thank you so much, everyone! No need for more. Since I’m now feeling better that the first authoritarian coup attempt in US history will probably sort itself out OK, here’s a real problem: Nearly a score years ago, I created the Complexity Zoo, a […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong><span class="has-inline-color has-vivid-red-color">Update (Nov. 14):</span></strong> I now have a deluge of serious hosting offers—thank you so much, everyone!  No need for more.</p>



<p/><hr/><p/>



<p>Since I’m now feeling better that the first authoritarian coup attempt in US history will probably sort itself out OK, here’s a <em>real</em> problem:</p>



<p>Nearly a score years ago, I created the <a href="https://complexityzoo.uwaterloo.ca/Complexity_Zoo">Complexity Zoo</a>, a procrastination project turned encyclopedia of complexity classes.  Nearly half a score years ago, the Zoo moved to my former employer, the <a href="https://uwaterloo.ca/institute-for-quantum-computing/">Institute for Quantum Computing</a> in Waterloo, Canada, which graciously hosted it ever since.  Alas, IQC has decided that it can no longer do so.  The reason is new regulations in Ontario about the accessibility of websites, which the Zoo might be out of compliance with.  My students and I were willing to look into what was needed—like, does the <a href="https://complexityzoo.uwaterloo.ca/Complexity_Zoo:P#ph">polynomial hierarchy</a> need ramps between its levels or something?  The best would be if we heard from actual blind or other disabled complexity enthusiasts about how we could improve their experience, rather than trying to parse bureaucratese from the Ontario government.  But IQC informed us that in any case, they can’t deal with the potential liability and their decision is final.  I thank them for hosting the Zoo for eight years.</p>



<p>Now I’m looking for a volunteer for a new host.  The Zoo runs on the <a href="https://www.mediawiki.org/wiki/MediaWiki">MediaWiki</a> platform, which doesn’t work with my own hosting provider (Bluehost) but is apparently easy to set up if you, unlike me, are the kind of person who can do such things.  The IQC folks kindly offered to help with the transfer; I and my students can help as well.  It’s a small site with modest traffic.  The main things I need are just assurances that you can host the site for a long time (“forever” or thereabouts), and that you or someone else in your organization will be reachable if the site goes down or if there are other problems.  I own the complexityzoo.com domain and can redirect from there.</p>



<p>In return, you’ll get the immense prestige of hosting such a storied resource for theoretical computer science … plus free publicity for your cause or organization on <em>Shtetl-Optimized</em>, and the eternal gratitude of thousands of my readers.</p>



<p>Of course, if you’re <em>into</em> complexity theory, and you want to update or improve the Zoo while you’re at it, then so much the awesomer!  It could use some updates, badly.  But you don’t even <em>need</em> to know P from NP.</p>



<p>If you’re interested, leave a comment or shoot me an email.  Thanks!!</p>



<p><strong><span class="has-inline-color has-vivid-red-color">Unrelated Announcement:</span></strong> I’ll once again be doing an Ask-Me-Anything session at the <a href="https://q2b.qcware.com/">Q2B (“Quantum to Business”)</a> conference, December 8-10.  Other speakers include Umesh Vazirani, John Preskill, Jennifer Ouellette, Eric Schmidt, and many others.  Since the conference will of course be virtual this year, registration is a lot cheaper than in previous years.  Check it out!  (Full disclosure: Q2B is organized by <a href="https://qcware.com/">QC Ware, Inc.</a>, for which I’m a scientific advisor.)</p></div>
    </content>
    <updated>2020-11-12T19:10:44Z</updated>
    <published>2020-11-12T19:10:44Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Self-Referential"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-11-14T22:20:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/11/12/tenured-tenured-track-faculty-positions-at-cispa-saarbrucken-apply-by-november-30-2020/</id>
    <link href="https://cstheory-jobs.org/2020/11/12/tenured-tenured-track-faculty-positions-at-cispa-saarbrucken-apply-by-november-30-2020/" rel="alternate" type="text/html"/>
    <title>Tenured/tenured track faculty positions at CISPA, Saarbrücken (apply by November 30, 2020)</title>
    <summary>CISPA Helmholtz Center for Information Security (Saarbrücken, Germany) is inviting applications for tenured/tenure track faculty positions. The positions come with generous support including research staff positions. We have 4 separate calls: – Efficient Algorithms &amp; TCS Foundations – ML &amp; Data Science – Information Security &amp; Privacy – Software Engineering, Program Analysis &amp; Formal Methods. […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>CISPA Helmholtz Center for Information Security (Saarbrücken, Germany) is inviting applications for tenured/tenure track faculty positions. The positions come with generous support including research staff positions. We have 4 separate calls:</p>
<p>– Efficient Algorithms &amp; TCS Foundations<br/>
– ML &amp; Data Science<br/>
– Information Security &amp; Privacy<br/>
– Software Engineering, Program Analysis &amp; Formal Methods.</p>
<p>Website: <a href="https://jobs.cispa.saarland/de_DE/jobs/detail/tenure-track-faculty-positions-in-all-areas-related-to-efficient-algorithms-and-the-foundations-of-theoretical-computer-science-f-m-d-69">https://jobs.cispa.saarland/de_DE/jobs/detail/tenure-track-faculty-positions-in-all-areas-related-to-efficient-algorithms-and-the-foundations-of-theoretical-computer-science-f-m-d-69</a><br/>
Email: marx@cispa.de</p></div>
    </content>
    <updated>2020-11-12T16:35:34Z</updated>
    <published>2020-11-12T16:35:34Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-11-16T18:20:40Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7166344296310393734</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7166344296310393734/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/11/recovery.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7166344296310393734" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7166344296310393734" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/11/recovery.html" rel="alternate" type="text/html"/>
    <title>Recovery</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Lance</b>: Perhaps we should do a post-election vidcast--what does it mean for complexity!</p><p><b>Bill</b>: Not sure if you are serious- but I doubt a Biden presidency will either speed up or slow down the proof that P NE NP or anything else in complexity. Did Trump give LESS money to the NSF and other funding agencies, and will Biden give more? I doubt it. </p><p><b>Lance: </b>Trump's budget did call for a massive cut for the NSF but luckily he doesn't control the purse strings. It's the immigration policy that worried me--both that it keeps good students from coming to the US and that it cuts off a revenue source that will cause many good schools to close down.</p><p><b>Bill: </b>Excellent point- but sounds more like a post you could write since you... know stuff, as opposed to a vidcast with me who... doesn't know stuff. </p><hr/><p>Bill sells himself short and me long but here is my post.</p><p>After Trump was elected in 2016 I thought maybe Trump with all his bluster will just be a typical conservative politician that we can live through until the next election. That didn't last long with his travel ban for Iranians just a few weeks after his inauguration <a href="https://blog.computationalcomplexity.org/2017/02/we-are-all-iranians.html">when I said</a> "This is not the America I believe in."</p><p>Judges have stopped the worst of Trump's travel bans but he has continued to whittle down the number of available visas, made it harder to get visas and get visas after they graduate. New students can't come to America if they take only on-line courses at a time many universities are online. Now students will have to get their visas renewed after two or four years. Few get a PhD in four years and would students come here and take the risk that their visas won't get renewed before they can finish? The <a href="https://cra.org/govaffairs/blog/2020/10/three-new-immigration-rule-changes/">CRA has some details</a> on the newest rules. Not to mention Trump's handling of COVID--would you send your kid to America now?</p><p>Trump hasn't hidden his disdain for higher education and had he won a second term his policies would greatly diminish the country's academic strength. Biden can and certainly will undo much of these changes and I hope it is not too late. </p><p>More from <a href="https://www.chronicle.com/article/bidens-victory-has-elated-international-students-but-the-road-to-lasting-reform-is-long">The Chronicle</a>.</p><p/></div>
    </content>
    <updated>2020-11-12T15:07:00Z</updated>
    <published>2020-11-12T15:07:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-11-15T09:47:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7892</id>
    <link href="https://windowsontheory.org/2020/11/12/mops-and-junior-senior-meeting-disc-2020/" rel="alternate" type="text/html"/>
    <title>MoPS and Junior-Senior Meeting (DISC 2020)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">(Guest post by Shir Cohen and Mouna Safir) The 34th International Symposium on Distributed Computing (DISC 2020) was held on October 12-16, 2020, as a virtual conference. As such, the opportunity for community members to get to know each other in an informal environment was lacking. To address this need, we arranged two types of … <a class="more-link" href="https://windowsontheory.org/2020/11/12/mops-and-junior-senior-meeting-disc-2020/">Continue reading <span class="screen-reader-text">MoPS and Junior-Senior Meeting (DISC 2020)</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><br/>(Guest post by Shir Cohen and Mouna Safir)</p>



<p><br/>The 34th International Symposium on Distributed Computing (DISC 2020) was held on October 12-16, 2020, as a virtual conference. As such, the opportunity for community members to get to know each other in an informal environment was lacking. To address this need, we arranged two types of virtual networking events. We hope that these events planted the seeds for many future collaborations and that there will be an opportunity for those involved to meet in person next time.</p>



<p><strong>MoPS (Meet other Postdoc and Students) Sessions<br/></strong>Webpage: <a href="https://sites.google.com/view/disc2020mops/home" rel="noreferrer noopener" target="_blank">https://sites.google.com/view/disc2020mops/home</a></p>



<p>To allow junior members of the community to get to know one another, we arranged MoPS sessions, which we have not seen done before. There were more than 50 participants who took part in the sessions, with representation from a host of countries throughout the world. Sessions were held in 10-time slots before, during, and after DISC. In each session, there would typically be 5 members representing a mixture of Bachelor’s students, Masters students, PhDs, postdocs, and others. Care was taken to include at least one postdoc or Ph.D. in each session so that Bachelors and Masters students might benefit from their experience. Groups were formed with the goal of allowing participants from different countries and institutions to share their experiences and research journeys with one another. Based on the feedback for this event, it would appear that that goal was met and the participants came away with more of a sense of community.</p>



<p><strong>Junior-Senior Meetings<br/></strong>Webpage: <a href="https://sites.google.com/view/disc2020junior-seniormeeting/home" rel="noreferrer noopener" target="_blank">https://sites.google.com/view/disc2020junior-seniormeeting/home</a></p>



<p>The Junior-Senior meetings were organized to provide an opportunity for junior researchers to meet with senior researchers. Fourteen sessions were conducted, where each one brought together one senior and 3-5 juniors. In these sessions,  the juniors got a chance to interact with seniors in the field and profit from their experience. Discussions covered a variety of topics such as how to approach research, how to deal with the job market, or perhaps more personal concerns like work-life balance. We collected amazing feedback from the participants, who claimed that this was a fruitful and interesting experience.</p></div>
    </content>
    <updated>2020-11-12T13:53:04Z</updated>
    <published>2020-11-12T13:53:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-11-16T18:20:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/171</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/171" rel="alternate" type="text/html"/>
    <title>TR20-171 |  Comparing computational entropies below majority (or: When is the dense model theorem false?) | 

	Sam McGuire, 

	Russell Impagliazzo</title>
    <summary>Computational pseudorandomness studies the extent to which a random variable $\bf{Z}$ looks like the uniform distribution according to a class of tests $\cal{F}$. Computational entropy generalizes computational pseudorandomness by studying the extent which a random variable looks like a \emph{high entropy} distribution. There are different formal definitions of computational entropy with different advantages for different applications. Because of this, it is of interest to understand when these definitions are equivalent.
  We consider three notions of computational entropy which are known to be equivalent when the test class $\cal{F}$ is closed under taking majorities. This equivalence constitutes (essentially) the so-called \emph{dense model theorem} of Green and Tao (and later made explicit by Tao-Zeigler, Reingold et al., and Gowers). The dense model theorem plays a key role in Green and Tao's proof that the primes contain arbitrarily long arithmetic progressions and has since been connected to a surprisingly wide range of topics in mathematics and computer science, including cryptography, computational complexity, combinatorics and machine learning. We show that, in different situations where $\cal{F}$ is \emph{not} closed under majority, this equivalence fails. This in turn provides examples where the dense model theorem is \emph{false}.</summary>
    <updated>2020-11-12T02:49:07Z</updated>
    <published>2020-11-12T02:49:07Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-11-16T18:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=75</id>
    <link href="https://dstheory.wordpress.com/2020/11/11/friday-nov-20-himanshu-tyagi-for-the-indian-institute-of-science-iisc/" rel="alternate" type="text/html"/>
    <title>Friday Nov 20 — Himanshu Tyagi from the Indian Institute of Science (IISc)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The next Foundations of Data Science virtual talk will take place on Friday, Nov 20th at 10:00 AM Pacific Time (13:00 Eastern Time, 18:00 Central European Time, 17:00 UTC, 23:30 Indian Time).  Himanshu Tyagi from IISc will speak about “General lower bounds for estimation under information constraints”. Abstract:  We present very general lower bounds for parametric<a class="more-link" href="https://dstheory.wordpress.com/2020/11/11/friday-nov-20-himanshu-tyagi-for-the-indian-institute-of-science-iisc/">Continue reading <span class="screen-reader-text">"Friday Nov 20 — Himanshu Tyagi from the Indian Institute of Science (IISc)"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next Foundations of Data Science virtual talk will take place on Friday, Nov 20th at 10:00 AM Pacific Time (13:00 Eastern Time, 18:00 Central European Time, 17:00 UTC, 23:30 Indian Time).  <strong>Himanshu Tyagi </strong>from IISc will speak about “<strong>General lower bounds for estimation under information constraints</strong>”.</p>



<p><strong>Abstract</strong>:  We present very general lower bounds for parametric estimation when only limited information per sample is allowed. These limitations can arise, for example, in form of communication constraints, privacy constraints, or linear measurements. Our lower bounds hold for discrete distributions with large alphabet as well as continuous distributions with high-dimensional parameters, apply for any information constraint, and are valid for any $\ell_p$ loss function. Our bounds recover both strong data processing inequality based bounds and Cramér-Rao based bound as special cases.</p>



<p>This talk is based on joint work with Jayadev Acharya and Clément Canonne.</p>



<p><a href="https://sites.google.com/view/dstheory" rel="noreferrer noopener" target="_blank">Please register here to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>
    </content>
    <updated>2020-11-11T21:47:20Z</updated>
    <published>2020-11-11T21:47:20Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2020-11-16T18:21:31Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/11/11/faculty-any-rank-at-penn-state-at-penn-state-apply-by-january-31-2021/</id>
    <link href="https://cstheory-jobs.org/2020/11/11/faculty-any-rank-at-penn-state-at-penn-state-apply-by-january-31-2021/" rel="alternate" type="text/html"/>
    <title>FACULTY (ANY RANK) AT PENN STATE at Penn State (apply by January 31, 2021)</title>
    <summary>Applications are invited for tenure-track positions at all levels across all areas of theoretical computer science. Website: https://apptrkr.com/2036821 Email: ablanca@cse.psu.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for tenure-track positions at all levels across all areas of theoretical computer science.</p>
<p>Website: <a href="https://apptrkr.com/2036821">https://apptrkr.com/2036821</a><br/>
Email: ablanca@cse.psu.edu</p></div>
    </content>
    <updated>2020-11-11T21:17:02Z</updated>
    <published>2020-11-11T21:17:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-11-16T18:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/170</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/170" rel="alternate" type="text/html"/>
    <title>TR20-170 |  High Dimensional Expanders: Random Walks, Pseudorandomness, and Unique Games | 

	Max Hopkins, 

	Tali Kaufman, 

	Shachar Lovett</title>
    <summary>Higher order random walks (HD-walks) on high dimensional expanders have played a crucial role in a number of recent breakthroughs in theoretical computer science, perhaps most famously in the recent resolution of the Mihail-Vazirani conjecture (Anari et al. STOC 2019), which focuses on HD-walks on one-sided local-spectral expanders. In this work we study the spectral structure of walks on the stronger two-sided variant, which capture wide generalizations of important objects like the Johnson and Grassmann graphs. We prove that the spectra of these walks are tightly concentrated in a small number of strips, each of which corresponds combinatorially to a level in the underlying complex. Moreover, the eigenvalues corresponding to these strips decay exponentially with a measure we term the depth of the walk.
    
    Using this spectral machinery, we characterize the edge-expansion of small sets based upon the interplay of their local combinatorial structure and the global decay of the walk's eigenvalues across strips. Variants of this result for the special cases of the Johnson and Grassmann graphs were recently crucial both for the resolution of the 2-2 Games Conjecture (Khot et al. FOCS 2018), and for efficient algorithms for affine unique games over the Johnson graphs (Bafna et al. Arxiv 2020). For the complete complex, our characterization admits a low-degree Sum of Squares proof. Building on the work of Bafna et al., we provide the first polynomial time algorithm for affine unique games over the Johnson scheme. The soundness and runtime of our algorithm depend upon the number of strips with large eigenvalues, a measure we call High-Dimensional Threshold Rank that calls back to the seminal work of Barak, Raghavendra, and Steurer (FOCS 2011) on unique games and threshold rank.</summary>
    <updated>2020-11-11T17:13:41Z</updated>
    <published>2020-11-11T17:13:41Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-11-16T18:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/169</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/169" rel="alternate" type="text/html"/>
    <title>TR20-169 |  Efficient List-Decoding with Constant Alphabet and List Sizes | 

	Zeyu Guo, 

	Noga Ron-Zewi</title>
    <summary>We present an explicit and efficient algebraic construction of capacity-achieving list decodable codes with both constant alphabet and constant list sizes. More specifically, for any $R \in (0,1)$ and $\epsilon&gt;0$, we give an algebraic construction of an infinite family of error-correcting codes of rate $R$, over an alphabet of size $(1/\epsilon)^{O(1/\epsilon^2)}$, that can be list decoded from a $(1-R-\epsilon)$-fraction of errors with list size at most $\exp(\mathrm{poly}(1/\epsilon))$. Moreover, the codes can be encoded in time $\mathrm{poly}(1/\epsilon, n)$, the output list is contained in a linear subspace of dimension at most $\mathrm{poly}(1/\epsilon)$, and a basis for this subspace can be found in time $\mathrm{poly}(1/\epsilon, n)$. Thus, both encoding and list decoding can be performed in \emph{fully polynomial-time} $\mathrm{poly}(1/\epsilon, n)$, except for pruning the subspace and outputting the final list which takes time $\exp(\mathrm{poly}(1/\epsilon)) \cdot \mathrm{poly}(n)$. In contrast, prior explicit and efficient constructions of capacity-achieving list decodable codes either required a much higher complexity in terms of $1/\epsilon$ (and were additionally much less structured), or had super-constant alphabet or list sizes.

Our codes are quite natural and structured. Specifically, we use algebraic-geometric (AG) codes with evaluation points restricted to a subfield, and with the message space restricted to a (carefully chosen) linear subspace. Our main observation is that the output list of AG codes with subfield evaluation points is contained in an affine shift of the image of a \emph{block-triangular-Toeplitz (BTT) matrix}, and that the list size can potentially be reduced to a constant by restricting the message space to a \emph{BTT evasive subspace}, which is a large subspace that intersects the image of any BTT matrix in a constant number of points. We further show how to explicitly construct such BTT evasive subspaces, based on the explicit subspace designs of Guruswami and Kopparty (\emph{Combinatorica}, 2016), and composition.</summary>
    <updated>2020-11-11T17:07:44Z</updated>
    <published>2020-11-11T17:07:44Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-11-16T18:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/168</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/168" rel="alternate" type="text/html"/>
    <title>TR20-168 |  Improved List-Decodability of Reed–Solomon Codes via Tree Packings | 

	Zeyu Guo, 

	Ray Li, 

	Itzhak Tamo, 

	Mary Wootters, 

	Chong Shangguan</title>
    <summary>This paper shows that there exist Reed--Solomon (RS) codes, over large finite fields, that are combinatorially list-decodable well beyond the Johnson radius, in fact almost achieving list-decoding capacity. In particular, we show that for any $\epsilon\in (0,1]$ there exist RS codes with rate $\Omega(\frac{\epsilon}{\log(1/\epsilon)+1})$ that are list-decodable from radius of $1-\epsilon$. We generalize this result to obtain a similar result on list-recoverability of RS codes. Along the way we use our techniques to give a new proof of a result of Blackburn on optimal linear perfect hash matrices, and strengthen it to obtain a construction of strongly perfect hash matrices. 

To derive the results in this paper we show a surprising connection of the above problems to graph theory, and in particular to the tree packing theorem of Nash-Williams and Tutte. En route to our results on RS codes, we prove a generalization of the tree packing theorem to hypergraphs (and we conjecture that an even stronger generalization holds). We hope that this generalization to hypergraphs will be of independent interest.</summary>
    <updated>2020-11-11T17:06:16Z</updated>
    <published>2020-11-11T17:06:16Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-11-16T18:20:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://mycqstate.wordpress.com/?p=1262</id>
    <link href="https://mycqstate.wordpress.com/2020/11/11/lecture-notes-on-the-mahadev-verification-protocol/" rel="alternate" type="text/html"/>
    <title>Lecture notes on the Mahadev verification protocol</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">As announced earlier I am currently teaching a course on “interactive proofs with quantum devices” in Paris. The course is proceeding apace, even though the recent lockdown order in France means that we had to abandon our beautiful auditorium at … <a href="https://mycqstate.wordpress.com/2020/11/11/lecture-notes-on-the-mahadev-verification-protocol/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-image"><figure class="alignright size-large is-resized"><a href="https://mycqstate.files.wordpress.com/2020/11/index-1.jpg"><img alt="" class="wp-image-1266" height="206" src="https://mycqstate.files.wordpress.com/2020/11/index-1.jpg?w=1024" width="367"/></a>My street in lockdown </figure></div>



<p>As announced <a href="https://mycqstate.wordpress.com/2020/09/20/announcing-a-short-course-in-paris/">earlier</a> I am currently teaching a course on “interactive proofs with quantum devices” in Paris. The course is proceeding apace, even though the recent lockdown order in France means that we had to abandon our beautiful auditorium at the Institut Henri Poincaré and retreat behind the fanciful Zoom backgrounds whose pretension is a sad reminder of what our summers used to be (Banff, anyone?). A possible upshot is that more may be able to attend the now-online course; if you are interested see the <a href="http://users.cms.caltech.edu/~vidick/teaching/fsmp/">course page</a> for info. (Things are actually fairly good here–in spite of the apparently strict restrictions on daily outings (max 1h, 1km) you can count on the French to bend things their way; most shops are closed but the streets remain quite busy.)</p>



<p>We just finished a sequence of four lectures on the Mahadev “classical verification of quantum computation” protocol. In the process of preparing the lectures I arrived at a presentation of the protocol that is fairly self-contained, so I decided to compile the associated lecture notes as a stand-alone group of 4 lectures that is available <a href="http://users.cms.caltech.edu/~vidick/teaching/fsmp/fsmp_verification.pdf">here</a>. The notes are aimed at beginning graduate students with a first course in quantum computing and in complexity desiring to gain a concrete understanding of the inner workings of the result; the notes are a bit lengthy but this in part because they take the time to introduce related concepts and slowly build up to the main result. Overall, my hope is that these should be relatively easily readable and provide a good technical introduction to the Mahadev result on classical verification, including an almost complete analysis of her protocol (there are a few explicitly declared shortcuts that help simplify the presentation without hiding any important aspects). For additional background you can also consult the full <a href="http://users.cms.caltech.edu/~vidick/teaching/fsmp/fsmp.pdf">10-week notes</a>. Comments on the notes are welcome; I’m afraid they most likely contain numerous typos so if you find any please feel free to correct them directly on the associated <a href="https://www.overleaf.com/9892211158zrwmqnxtvcxm">overleaf document</a>.</p>



<p>The last three lectures of the course will be devoted to the problem of testing under spatial assumptions, building up to an introduction to the proof of MIP* = RE. If all goes well I’ll aim to prepare some stand-alone notes for that part as well.</p></div>
    </content>
    <updated>2020-11-11T15:43:12Z</updated>
    <published>2020-11-11T15:43:12Z</published>
    <category term="Quantum"/>
    <category term="Science"/>
    <category term="teaching"/>
    <category term="Uncategorized"/>
    <category term="lecture notes"/>
    <category term="quantum verification"/>
    <author>
      <name>Thomas</name>
    </author>
    <source>
      <id>https://mycqstate.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://mycqstate.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://mycqstate.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://mycqstate.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://mycqstate.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>In superposition</subtitle>
      <title>MyCQstate</title>
      <updated>2020-11-16T18:21:22Z</updated>
    </source>
  </entry>
</feed>
