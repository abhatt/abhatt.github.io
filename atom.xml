<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2022-02-07T12:39:07Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.01757</id>
    <link href="http://arxiv.org/abs/2202.01757" rel="alternate" type="text/html"/>
    <title>$k$-Transmitter Watchman Routes</title>
    <feedworld_mtime>1644192000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nilsson:Bengt_J=.html">Bengt J. Nilsson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Christiane.html">Christiane Schmidt</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.01757">PDF</a><br/><b>Abstract: </b>We consider the watchman route problem for a $k$-transmitter watchman:
standing at point $p$ in a polygon $P$, the watchman can see $q\in P$ if
$\overline{pq}$ intersects $P$'s boundary at most $k$ times -- $q$ is
$k$-visible to $p$. Traveling along the $k$-transmitter watchman route, either
all points in $P$ or a discrete set of points $S\subset P$ must be $k$-visible
to the watchman. We aim for minimizing the length of the $k$-transmitter
watchman route.
</p>
<p>We show that even in simple polygons the shortest $k$-transmitter watchman
route problem for a discrete set of points $S\subset P$ is NP-complete and
cannot be approximated to within a logarithmic factor (unless P=NP), both with
and without a given starting point. Moreover, we present a polylogarithmic
approximation for the $k$-transmitter watchman route problem for a given
starting point and $S\subset P$ with approximation ratio $O(\log^2(|S|\cdot n)
\log\log (|S|\cdot n) \log(|S|+1))$ (with $|P|=n$).
</p></div>
    </summary>
    <updated>2022-02-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6817129401606575319</id>
    <link href="http://blog.computationalcomplexity.org/feeds/6817129401606575319/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/pspace-is-contained-in-zero-knowledge.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6817129401606575319" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6817129401606575319" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/pspace-is-contained-in-zero-knowledge.html" rel="alternate" type="text/html"/>
    <title>PSPACE is contained in Zero Knowledge!! How come nobody seems to care?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>(This post was inspired by Lance's post on Zero Knowledge, <a href="https://blog.computationalcomplexity.org/2022/02/the-beginnings-of-zero-knowledge.html">here</a>, which was inspired by a video he has in the post which was inspired by... (I think this ordering is well founded.))</p><p> ZK= Zero Knowledge.</p><p>When it was shown that NP \subseteq ZK this was a big deal. This was by Goldreich-Micali-Wigderson  (see <a href="https://dl.acm.org/doi/10.1145/116825.116852">her</a>e (FOCS-1986, JACM-1991). In the JACM paper they have the following passage:</p><div><blockquote>Our result that all languages in NP have zero-knowledge proof systems, has been extended to IP, assuming the same assumptions. (The result was first proved by Impagliazzo and Yung, but since their paper [53] contains only a claim of the result, the interested reader is directed to [11] where a (different proof) appears.) In other words, whatever can be efficiently proven can be efficiently proven in a zero-knowledge manner. This may be viewed as the best result possible, since only languages having interactive proof systems can have zero-knowledge interactive proof systems.<br/><br/>11. BEN-OR, M., GOLDREICH, O., GOLDWASSER, S., HASTAD, J., KILLIAN, J., MICALI, S,,  AND ROGAWAY, P. Everything provable is provable in zero-knowledge. In Proceedings of Advances in Cryptology— Crypto88. Lecture Notes in Computer Science, vol. 403. Springer-Verlag, New York, 1990, pp. 37-56.<br/><br/>53.IMPAGLIAZZO. R., AND YUNG, M. Direct minimum-knowledge computations. In C. Pomerance, ed., Proceedings of Advances in Cryptology— Crypto87. Lecture Notes in Computer Science, vol. 293. Springer-Verlag, New York, 1987, pp. 40-51.</blockquote>Later the papers of Lund-Fortnow-Karloff-Nisan and Shamir showed IP=PSPACE. Hence<br/><br/><div style="text-align: center;">PSPACE \subseteq ZK</div><p>When I realized this I thought OH, that's interesting! I then looked around the web and could not find any mention of it. I asked Lance and some people in crypto and yeah, they all knew it was true, but nobody seemed to care.</p><p>Why the apathy? Speculation:</p><p>1) ZK is a notion people actually want to use in real crypto (and there has been some progress on that lately). The prover for ZK in PSPACE has to be way to powerful to be practical. I don't really like this explanation since we are talking about theorists. Even in crypto, which has more of a connection to the real works then, say, Ramsey Theory, there are still plenty of non-useful results. </p><p>2) IP=PSPACE was the big news and  had interesting proof with nice ideas. Nothing crypto-ish about it. So the corollary that PSPACE \subseteq ZK is an afterthought. </p><p>3) SAT in ZK was big news. IP in ZK is nice, but uses mostly the same ideas.</p><p>4) I am WRONG- it is a celebrated result and I somehow missed the celebration.</p><p>5) The proof that ZK is in PSPACE USES two interesting results, but adds NOTHING to the mix. In short, the proof is to easy.</p><p>Any other ideas?</p></div></div>
    </content>
    <updated>2022-02-06T20:19:00Z</updated>
    <published>2022-02-06T20:19:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-07T10:26:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6288</id>
    <link href="https://scottaaronson.blog/?p=6288" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6288#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6288" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">AlphaCode as a dog speaking mediocre English</title>
    <summary xml:lang="en-US">Tonight, I took the time actually to read DeepMind’s AlphaCode paper, and to work through the example contest problems provided, and understand how I would’ve solved those problems, and how AlphaCode solved them. It is absolutely astounding. Consider, for example, the “n singers” challenge (pages 59-60). To solve this well, you first need to parse […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Tonight, I took the time actually to read DeepMind’s <a href="https://storage.googleapis.com/deepmind-media/AlphaCode/competition_level_code_generation_with_alphacode.pdf">AlphaCode paper</a>, and to work through the example contest problems provided, and understand how I would’ve solved those problems, and how AlphaCode solved them.</p>



<p>It is absolutely astounding.</p>



<p>Consider, for example, the “n singers” challenge (pages 59-60). To solve this well, you first need to parse a somewhat convoluted English description, discarding the irrelevant fluff about singers, in order to figure out that you’re being asked to find a positive integer solution (if it exists) to a linear system whose matrix looks like<br/>1 2 3 4<br/>4 1 2 3<br/>3 4 1 2<br/>2 3 4 1.<br/>Next you need to find a trick for solving such a system without Gaussian elimination or the like (I’ll leave that as an exercise…). Finally, you need to generate code that implements that trick, correctly handling the wraparound at the edges of the matrix, and breaking and returning “NO” for any of multiple possible reasons why a positive integer solution won’t exist.   Oh, and also correctly parse the input.</p>



<p>Yes, I realize that AlphaCode generates a million candidate programs for each challenge, then discards the vast majority by checking that they don’t work on the example data provided, then <em>still</em> has to use clever tricks to choose from among the thousands of candidates remaining. I realize that it was trained on tens of thousands of contest problems and millions of solutions to those problems. I realize that it “only” solves about a third of the contest problems, making it similar to a mediocre human programmer on these problems. I realize that it works only in the artificial domain of programming contests, where a complete English problem specification and example inputs and outputs are always provided.</p>



<p>Forget all that. Judged against where AI was 20-25 years ago, when I was a student, a dog is now holding meaningful conversations in English. And people are complaining that the dog isn’t a very eloquent orator, that it often makes grammatical errors and has to start again, that it took heroic effort to train it, and that it’s unclear how much the dog really understands.</p>



<p>It’s not obvious how you go from solving programming contest problems to conquering the human race or whatever, but I feel pretty confident that we’ve now entered a world where “programming” will look different.</p>



<p><strong>Update:</strong> A colleague of mine points out that one million, the number of candidate programs that AlphaCode needs to generate, could be seen as roughly exponential in the number of lines of the generated programs.  If so, this suggests a perspective according to which DeepMind has created almost the exact equivalent, in AI code generation, of a non-fault-tolerant quantum computer that’s nevertheless competitive on some task (as in the quantum supremacy experiments). I.e., it clearly does something highly nontrivial, but the “signal” is still decreasing exponentially with the number of instructions, necessitating an exponential number of repetitions to extract the signal and imposing a limit on the size of the programs you can scale to.</p></div>
    </content>
    <updated>2022-02-06T09:12:13Z</updated>
    <published>2022-02-06T09:12:13Z</published>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <category scheme="https://scottaaronson.blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-02-07T01:34:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.01746</id>
    <link href="http://arxiv.org/abs/2202.01746" rel="alternate" type="text/html"/>
    <title>Pivot Gray Codes for the Spanning Trees of a Graph ft. the Fan</title>
    <feedworld_mtime>1644105600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cameron:Ben.html">Ben Cameron</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grubb:Aaron.html">Aaron Grubb</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sawada:Joe.html">Joe Sawada</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.01746">PDF</a><br/><b>Abstract: </b>We consider the problem of listing all spanning trees of a graph $G$ such
that successive trees differ by pivoting a single edge around a vertex. Such a
listing is called a "pivot Gray code", and it has more stringent conditions
than known "revolving-door" Gray codes for spanning trees. Most revolving-door
algorithms employ a standard edge-deletion/edge-contraction recursive approach
which we demonstrate presents natural challenges when requiring the "pivot"
property. Our main result is the discovery of a greedy strategy to list the
spanning trees of the fan graph in a pivot Gray code order. It is the first
greedy algorithm for exhaustively generating spanning trees using such a
minimal change operation. The resulting listing is then studied to find a
recursive algorithm that produces the same listing in $O(1)$-amortized time
using $O(n)$ space. Additionally, we present $O(n)$-time algorithms for ranking
and unranking the spanning trees for our listing; an improvement over the
generic $O(n^3)$-time algorithm for ranking and unranking spanning trees of an
arbitrary graph. Finally, we discuss how our listing can be applied to find a
pivot Gray code for the wheel graph.
</p></div>
    </summary>
    <updated>2022-02-06T22:38:51Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.01725</id>
    <link href="http://arxiv.org/abs/2202.01725" rel="alternate" type="text/html"/>
    <title>RipsNet: a general architecture for fast and robust estimation of the persistent homology of point clouds</title>
    <feedworld_mtime>1644105600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Thibault de Surrel, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hensel:Felix.html">Felix Hensel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carri=egrave=re:Mathieu.html">Mathieu Carrière</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lacombe:Th=eacute=o.html">Théo Lacombe</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ike:Yuichi.html">Yuichi Ike</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kurihara:Hiroaki.html">Hiroaki Kurihara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Glisse:Marc.html">Marc Glisse</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chazal:Fr=eacute=d=eacute=ric.html">Frédéric Chazal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.01725">PDF</a><br/><b>Abstract: </b>The use of topological descriptors in modern machine learning applications,
such as Persistence Diagrams (PDs) arising from Topological Data Analysis
(TDA), has shown great potential in various domains. However, their practical
use in applications is often hindered by two major limitations: the
computational complexity required to compute such descriptors exactly, and
their sensitivity to even low-level proportions of outliers. In this work, we
propose to bypass these two burdens in a data-driven setting by entrusting the
estimation of (vectorization of) PDs built on top of point clouds to a neural
network architecture that we call RipsNet. Once trained on a given data set,
RipsNet can estimate topological descriptors on test data very efficiently with
generalization capacity. Furthermore, we prove that RipsNet is robust to input
perturbations in terms of the 1-Wasserstein distance, a major improvement over
the standard computation of PDs that only enjoys Hausdorff stability, yielding
RipsNet to substantially outperform exactly-computed PDs in noisy settings. We
showcase the use of RipsNet on both synthetic and real-world data. Our
open-source implementation is publicly available at
https://github.com/hensel-f/ripsnet and will be included in the Gudhi library.
</p></div>
    </summary>
    <updated>2022-02-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.01716</id>
    <link href="http://arxiv.org/abs/2202.01716" rel="alternate" type="text/html"/>
    <title>Multivariate Algorithmics for Eliminating Envy by Donating Goods</title>
    <feedworld_mtime>1644105600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Boehmer:Niclas.html">Niclas Boehmer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bredereck:Robert.html">Robert Bredereck</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heeger:Klaus.html">Klaus Heeger</a>, Dušan Knop, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Luo:Junjie.html">Junjie Luo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.01716">PDF</a><br/><b>Abstract: </b>Fairly dividing a set of indivisible resources to a set of agents is of
utmost importance in some applications. However, after an allocation has been
implemented the preferences of agents might change and envy might arise. We
study the following problem to cope with such situations: Given an allocation
of indivisible resources to agents with additive utility-based preferences, is
it possible to socially donate some of the resources (which means removing
these resources from the allocation instance) such that the resulting modified
allocation is envy-free (up to one good). We require that the number of deleted
resources and/or the caused utilitarian welfare loss of the allocation are
bounded. We conduct a thorough study of the (parameterized) computational
complexity of this problem considering various natural and problem-specific
parameters (e.g., the number of agents, the number of deleted resources, or the
maximum number of resources assigned to an agent in the initial allocation) and
different preference models, including unary and 0/1-valuations. In our
studies, we obtain a rich set of (parameterized) tractability and
intractability results and discover several surprising contrasts, for instance,
between the two closely related fairness concepts envy-freeness and
envy-freeness up to one good and between the influence of the parameters
maximum number and welfare of the deleted resources.
</p></div>
    </summary>
    <updated>2022-02-06T22:37:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.01678</id>
    <link href="http://arxiv.org/abs/2202.01678" rel="alternate" type="text/html"/>
    <title>Recognising the overlap graphs of subtrees of restricted trees is hard</title>
    <feedworld_mtime>1644105600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jessica Enright, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pergel:Martin.html">Martin Pergel</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.01678">PDF</a><br/><b>Abstract: </b>The overlap graphs of subtrees in a tree (SOGs) generalise many other graphs
classes with set representation characterisations. The complexity of
recognising SOGs in open. The complexities of recognising many subclasses of
SOGs are known. We consider several subclasses of SOGs by restricting the
underlying tree. For a fixed integer $k \geq 3$, we consider:
\begin{my_itemize}
</p>
<p>\item The overlap graphs of subtrees in a tree where that tree has $k$ leaves
</p>
<p>\item The overlap graphs of subtrees in trees that can be derived from a
given input tree by subdivision and have at least 3 leaves
</p>
<p>\item The overlap and intersection graphs of paths in a tree where that tree
has maximum degree $k$ \end{my_itemize}
</p>
<p>We show that the recognition problems of these classes are NP-complete. For
all other parameters we get circle graphs, well known to be polynomially
recognizable.
</p></div>
    </summary>
    <updated>2022-02-06T22:37:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.01636</id>
    <link href="http://arxiv.org/abs/2202.01636" rel="alternate" type="text/html"/>
    <title>On constant-time quantum annealing and guaranteed approximations for graph optimization problems</title>
    <feedworld_mtime>1644105600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Braida:Arthur.html">Arthur Braida</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Martiel:Simon.html">Simon Martiel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Todinca:Ioan.html">Ioan Todinca</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.01636">PDF</a><br/><b>Abstract: </b>Quantum Annealing (QA) is a computational framework where a quantum system's
continuous evolution is used to find the global minimum of an objective
function over an unstructured search space. It can be seen as a general
metaheuristic for optimization problems, including NP-hard ones if we allow an
exponentially large running time. While QA is widely studied from a heuristic
point of view, little is known about theoretical guarantees on the quality of
the solutions obtained in polynomial time.
</p>
<p>In this paper we use a technique borrowed from theoretical physics, the
Lieb-Robinson (LR) bound, and develop new tools proving that short, constant
time quantum annealing guarantees constant factor approximations ratios for
some optimization problems when restricted to bounded degree graphs.
Informally, on bounded degree graphs the LR bound allows us to retrieve a
(relaxed) locality argument, through which the approximation ratio can be
deduced by studying subgraphs of bounded radius.
</p>
<p>We illustrate our tools on problems MaxCut and Maximum Independent Set for
cubic graphs, providing explicit approximation ratios and the runtimes needed
to obtain them. Our results are of similar flavor to the well-known ones
obtained in the different but related QAOA (quantum optimization algorithms)
framework.
</p>
<p>Eventually, we discuss theoretical and experimental arguments for further
improvements.
</p></div>
    </summary>
    <updated>2022-02-06T22:44:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.01567</id>
    <link href="http://arxiv.org/abs/2202.01567" rel="alternate" type="text/html"/>
    <title>Perpetual maintenance of machines with different urgency requirements</title>
    <feedworld_mtime>1644105600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Leszek Gąsieniec, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klasing:Ralf.html">Ralf Klasing</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levcopoulos:Christos.html">Christos Levcopoulos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lingas:Andrzej.html">Andrzej Lingas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Min:Jie.html">Jie Min</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Radzik:Tomasz.html">Tomasz Radzik</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.01567">PDF</a><br/><b>Abstract: </b>A garden $G$ is populated by $n\ge 1$ bamboos $b_1, b_2, ..., b_n$ with the
respective daily growth rates $h_1 \ge h_2 \ge \dots \ge h_n$. It is assumed
that the initial heights of bamboos are zero. The robotic gardener maintaining
the garden regularly attends bamboos and trims them to height zero according to
some schedule. The Bamboo Garden Trimming Problem (BGT) is to design a
perpetual schedule of cuts to maintain the elevation of the bamboo garden as
low as possible. The bamboo garden is a metaphor for a collection of machines
which have to be serviced, with different frequencies, by a robot which can
service only one machine at a time. The objective is to design a perpetual
schedule of servicing which minimizes the maximum (weighted) waiting time for
servicing.
</p>
<p>We consider two variants of BGT. In discrete BGT the robot trims only one
bamboo at the end of each day. In continuous BGT the bamboos can be cut at any
time, however, the robot needs time to move from one bamboo to the next.
</p>
<p>For discrete BGT, we show a simple $4$-approximation algorithm and, by
exploiting relationship between BGT and the classical Pinwheel scheduling
problem, we derive a $2$-approximation algorithm for the general case and a
tighter approximation when the growth rates are balanced. A by-product of this
last approximation algorithm is that it settles one of the conjectures about
the Pinwheel problem. For continuous BGT, we propose approximation algorithms
which achieve approximation ratios $O(\log (h_1/h_n))$ and $O(\log n)$.
</p></div>
    </summary>
    <updated>2022-02-06T22:39:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.01537</id>
    <link href="http://arxiv.org/abs/2202.01537" rel="alternate" type="text/html"/>
    <title>Bending Graphs: Hierarchical Shape Matching using Gated Optimal Transport</title>
    <feedworld_mtime>1644105600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saleh:Mahdi.html">Mahdi Saleh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Shun=Cheng.html">Shun-Cheng Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cosmo:Luca.html">Luca Cosmo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Navab:Nassir.html">Nassir Navab</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Busam:Benjamin.html">Benjamin Busam</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tombari:Federico.html">Federico Tombari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.01537">PDF</a><br/><b>Abstract: </b>Shape matching has been a long-studied problem for the computer graphics and
vision community. The objective is to predict a dense correspondence between
meshes that have a certain degree of deformation. Existing methods either
consider the local description of sampled points or discover correspondences
based on global shape information. In this work, we investigate a hierarchical
learning design, to which we incorporate local patch-level information and
global shape-level structures. This flexible representation enables
correspondence prediction and provides rich features for the matching stage.
Finally, we propose a novel optimal transport solver by recurrently updating
features on non-confident nodes to learn globally consistent correspondences
between the shapes. Our results on publicly available datasets suggest robust
performance in presence of severe deformations without the need for extensive
training or refinement.
</p></div>
    </summary>
    <updated>2022-02-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.01456</id>
    <link href="http://arxiv.org/abs/2202.01456" rel="alternate" type="text/html"/>
    <title>Fast and explainable clustering based on sorting</title>
    <feedworld_mtime>1644105600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Xinye.html">Xinye Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=uuml=ttel:Stefan.html">Stefan Güttel</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.01456">PDF</a><br/><b>Abstract: </b>We introduce a fast and explainable clustering method called CLASSIX. It
consists of two phases, namely a greedy aggregation phase of the sorted data
into groups of nearby data points, followed by the merging of groups into
clusters. The algorithm is controlled by two scalar parameters, namely a
distance parameter for the aggregation and another parameter controlling the
minimal cluster size. Extensive experiments are conducted to give a
comprehensive evaluation of the clustering performance on synthetic and
real-world datasets, with various cluster shapes and low to high feature
dimensionality. Our experiments demonstrate that CLASSIX competes with
state-of-the-art clustering algorithms. The algorithm has linear space
complexity and achieves near linear time complexity on a wide range of
problems. Its inherent simplicity allows for the generation of intuitive
explanations of the computed clusters.
</p></div>
    </summary>
    <updated>2022-02-06T22:43:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.01428</id>
    <link href="http://arxiv.org/abs/2202.01428" rel="alternate" type="text/html"/>
    <title>Multi-Criteria Assessment of Shape Quality in CAD Systems of the Future</title>
    <feedworld_mtime>1644105600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Valerijan Muftejev, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Ziatdinov:Rushan.html">Rushan Ziatdinov</a>, Rifkat Nabiyev <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.01428">PDF</a><br/><b>Abstract: </b>Unlike many other works, where authors are usually focused on one or two
quality criteria, the current manuscript, which is a generalization of the
article [35] published in Russian, offers a multi-criteria approach to the
assessment of the shape quality of curves that constitute component parts of
the surfaces used for the computer modelling of object shapes in various types
of design. Based on the analysis of point particle motion along a curved path,
requirements for the quality of functional curves are proposed: a high order of
smoothness, a minimum number of curvature extrema, minimization of the maximum
value of curvature and its variation rate, minimization of the potential energy
of the curve, and aesthetic analysis from the standpoint of the laws of
technical aesthetics. The authors do not set themselves the task of giving a
simple and precise mathematical definition of such curves. On the contrary,
this category can include various curves that meet certain quality criteria,
the refinement and addition of which is possible in the near future.
Engineering practice shows that quality criteria can change over time, which
does not diminish the need to develop multi-criteria methods for assessing the
quality of geometric shapes. Technical issues faced during edge rounding in 3D
models that affect the quality of industrial design product shape have been
reviewed as an example of the imperfection of existing CAD systems.
</p></div>
    </summary>
    <updated>2022-02-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.01391</id>
    <link href="http://arxiv.org/abs/2202.01391" rel="alternate" type="text/html"/>
    <title>Fair Representation Clustering with Several Protected Classes</title>
    <feedworld_mtime>1644105600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dai:Zhen.html">Zhen Dai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Makarychev:Yury.html">Yury Makarychev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vakilian:Ali.html">Ali Vakilian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.01391">PDF</a><br/><b>Abstract: </b>We study the problem of fair $k$-median where each cluster is required to
have a fair representation of individuals from different groups. In the fair
representation $k$-median problem, we are given a set of points $X$ in a metric
space. Each point $x\in X$ belongs to one of $\ell$ groups. Further, we are
given fair representation parameters $\alpha_j$ and $\beta_j$ for each group
$j\in [\ell]$. We say that a $k$-clustering $C_1, \cdots, C_k$ fairly
represents all groups if the number of points from group $j$ in cluster $C_i$
is between $\alpha_j |C_i|$ and $\beta_j |C_i|$ for every $j\in[\ell]$ and
$i\in [k]$. The goal is to find a set $\mathcal{C}$ of $k$ centers and an
assignment $\phi: X\rightarrow \mathcal{C}$ such that the clustering defined by
$(\mathcal{C}, \phi)$ fairly represents all groups and minimizes the
$\ell_1$-objective $\sum_{x\in X} d(x, \phi(x))$.
</p>
<p>We present an $O(\log k)$-approximation algorithm that runs in time
$n^{O(\ell)}$. Note that the known algorithms for the problem either (i)
violate the fairness constraints by an additive term or (ii) run in time that
is exponential in both $k$ and $\ell$. We also consider an important special
case of the problem where $\alpha_j = \beta_j = \frac{f_j}{f}$ and $f_j, f \in
\mathbb{N}$ for all $j\in [\ell]$. For this special case, we present an $O(\log
k)$-approximation algorithm that runs in $(kf)^{O(\ell)}\log n + poly(n)$ time.
</p></div>
    </summary>
    <updated>2022-02-06T22:43:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.01293</id>
    <link href="http://arxiv.org/abs/2202.01293" rel="alternate" type="text/html"/>
    <title>Orthogonal Fold &amp; Cut</title>
    <feedworld_mtime>1644105600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ani:Joshua.html">Joshua Ani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brunner:Josh.html">Josh Brunner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Erik_D=.html">Erik D. Demaine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Martin_L=.html">Martin L. Demaine</a>, Dylan Hendrickson, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Luo:Victor.html">Victor Luo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Madhukara:Rachana.html">Rachana Madhukara</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.01293">PDF</a><br/><b>Abstract: </b>We characterize the shapes that can be produced by "orthogonal fold &amp; cut":
folding a rectangular sheet of paper along horizontal and vertical creases, and
then making a single straight cut (at any angle). Along the way, we solve a
handful of related problems: orthogonal fold &amp; punch, 1D fold &amp; cut, signed 1D
fold &amp; cut, and 1D interval fold &amp; cut.
</p></div>
    </summary>
    <updated>2022-02-06T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.01274</id>
    <link href="http://arxiv.org/abs/2202.01274" rel="alternate" type="text/html"/>
    <title>Principled Graph Management</title>
    <feedworld_mtime>1644105600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yarkony:Julian.html">Julian Yarkony</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Regan:Amelia.html">Amelia Regan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.01274">PDF</a><br/><b>Abstract: </b>Graph Generation is a recently introduced enhanced Column Generation
algorithm for solving expanded Linear Programming relaxations of mixed integer
linear programs without weakening the expanded relaxations which characterize
these methods. To apply Graph Generation we must be able to map any given
column generated during pricing to a small directed acyclic graph for which any
path from source to sink describes a feasible column. This structure is easily
satisfied for vehicle routing, crew scheduling and various logistics problems
where pricing is a constrained shortest path problem. The construction of such
graphs trades off the size/diversity of a subset of columns modeled by the
graphs versus the additional computational time required to solve the problems
induced by larger graphs.
</p>
<p>Graph Generation (GG) has two computational bottlenecks. The first is
pricing. Pricing in GG and Column Generation (CG) is identical because of the
structure of the problems solved. The second bottleneck is the restricted
master problem (RMP), which is more computationally intensive in GG than in CG
given the same number of columns generated. By design GG converges in fewer
iterations than CG, and hence requires fewer calls to pricing. Therefore, when
the computation time of GG is dominated by pricing, as opposed to solving the
RMP, GG converges much faster than CG in terms of time. However GG need not
converge faster than CG when the GG RMP, rather than pricing, dominates
computation.
</p>
<p>In this paper we introduce Principled Graph Management (PGM), which is an
algorithm to solve the GG RMP rapidly by exploiting its special structure. We
demonstrate the effectiveness of PGM inside a GG solution to the classical
Capacitated Vehicle Routing Problem. We demonstrate that PGM solves the GG RMP
hundreds of times faster than the baseline solver and that the improvement in
speed increases with problem size.
</p></div>
    </summary>
    <updated>2022-02-06T22:43:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2202.01248</id>
    <link href="http://arxiv.org/abs/2202.01248" rel="alternate" type="text/html"/>
    <title>Passing the Limits of Pure Local Search for the Maximum Weight Independent Set Problem in d-Claw Free Graphs</title>
    <feedworld_mtime>1644105600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Neuwohner:Meike.html">Meike Neuwohner</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2202.01248">PDF</a><br/><b>Abstract: </b>In this paper, we consider the task of computing an independent set of
maximum weight in a given $d$-claw free graph $G=(V,E)$ equipped with a
positive weight function $w:V\rightarrow\mathbb{R}_{&gt;0}$. Recently, Neuwohner
has shown how to obtain approximation ratios of $\frac{d-1+\epsilon_d}{2}$ in
quasi-polynomial time, where $0\leq \epsilon_d\leq 1$ and
$\lim_{d\rightarrow\infty}\epsilon_d = 0$. For the special case of the
$d-1$-Set Packing Problem, she showed how to get down to a polynomial running
time. On the other hand, she provided examples showing that no local
improvement algorithm considering local improvements of logarithmic size can
yield an approximation guarantee better than $\frac{d-1}{2}$. However, it turns
out that if one considers local improvements that arise by dropping vertex
weights and running an algorithm devised for the unweighted setting on certain
sub-instances of the given one, one can get beyond the
$\frac{d-1}{2}$-threshold and obtain approximation guarantees of
$\frac{d}{2}-\Omega(d)$ in quasi-polynomial time. For $d-1$-Set Packing
instances, we can guarantee a polynomial running time.
</p>
<p>We also conduct a more general investigation of the relation between
approximation guarantees for the unweighted and weighted variants of both the
Maximum Weight Independent Set Problem in $d$-claw free graphs and the
$d-1$-Set Packing problem. In doing so, we can show that for any constant
$\sigma &gt; 0$, there exists a constant $\tau &gt; 0$ such that a (quasi-)polynomial
time $1+\tau\cdot (d-2)$-approximation for the unweighted $d-1$-Set Packing
Problem (the Maximum Cardinality Independent Set problem in $d$-claw free
graphs) implies a (quasi-)-polynomial time $1+\sigma\cdot (d-2)$-approximation
for the weighted $d-1$-Set Packing Problem (the Maximum Weight Independent Set
problem in $d$-claw free graphs).
</p></div>
    </summary>
    <updated>2022-02-06T22:43:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-02-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/013</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/013" rel="alternate" type="text/html"/>
    <title>TR22-013 |  On properties that are non-trivial to test | 

	Nader Bshouty, 

	Oded Goldreich</title>
    <summary>In this note we show that all sets that are neither finite nor too dense are non-trivial to test in the sense that, for every $\epsilon&gt;0$, distinguishing between strings in the set and strings that are $\epsilon$-far from the set requires $\Omega(1/\epsilon)$ queries. 
Specifically, we show that if, for infinitely many $n$'s, the set contains at least one $n$-bit long string and at most $2^{n-\Omega(n)}$ many $n$-bit strings, then it is non-trivial to test.</summary>
    <updated>2022-02-05T16:37:06Z</updated>
    <published>2022-02-05T16:37:06Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-07T12:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/05/assistant-professor-at-linkoping-university-at-department-of-computer-and-information-science-apply-by-march-1-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/05/assistant-professor-at-linkoping-university-at-department-of-computer-and-information-science-apply-by-march-1-2022/" rel="alternate" type="text/html"/>
    <title>Assistant professor at Linköping University at Department of Computer and Information Science (apply by March 1 , 2022)</title>
    <summary>Linköping University announces an assistant professor position in computer science that focuses on the borderland between theoretical computer science, mathematics, and artificial intelligence. Website: https://liu.se/en/work-at-liu/vacancies?rmpage=job&amp;rmjob=18113&amp;rmlang=UK Email: peter.jonsson@liu.se</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Linköping University announces an assistant professor position in computer science<br/>
that focuses on the borderland between theoretical computer science, mathematics, and artificial intelligence.</p>
<p>Website: <a href="https://liu.se/en/work-at-liu/vacancies?rmpage=job&amp;rmjob=18113&amp;rmlang=UK">https://liu.se/en/work-at-liu/vacancies?rmpage=job&amp;rmjob=18113&amp;rmlang=UK</a><br/>
Email: peter.jonsson@liu.se</p></div>
    </content>
    <updated>2022-02-05T15:39:01Z</updated>
    <published>2022-02-05T15:39:01Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-07T12:37:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://scottaaronson.blog/?p=6256</id>
    <link href="https://scottaaronson.blog/?p=6256" rel="alternate" type="text/html"/>
    <link href="https://scottaaronson.blog/?p=6256#comments" rel="replies" type="text/html"/>
    <link href="https://scottaaronson.blog/?feed=atom&amp;p=6256" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Scott Aaronson Speculation Grant WINNERS!</title>
    <summary xml:lang="en-US">Two weeks ago, I announced on this blog that, thanks to the remarkable generosity of Jaan Tallinn, and the Speculation Grants program of the Survival and Flourishing Fund that Jaan founded, I had $200,000 to give away to charitable organizations of my choice. So, inspired by what Scott Alexander had done, I invited the readers […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Two weeks ago, I <a href="https://scottaaronson.blog/?p=6232">announced</a> on this blog that, thanks to the remarkable generosity of Jaan Tallinn, and the Speculation Grants program of the <a href="https://survivalandflourishing.fund/">Survival and Flourishing Fund</a> that Jaan founded, I had $200,000 to give away to charitable organizations of my choice.  So, inspired by what Scott Alexander had <a href="https://astralcodexten.substack.com/p/acx-grants-results">done</a>, I invited the readers of <em>Shtetl-Optimized</em> to pitch their charities, mentioning only some general areas of interest to me (e.g., advanced math education at the precollege level, climate change mitigation, pandemic preparedness, endangered species conservation, and any good causes that would enrage the people who attack me on Twitter).</p>



<p>I’m grateful to have gotten more than twenty well-thought-out pitches; you can read a subset of them in the <a href="https://scottaaronson.blog/?p=6232#comments">comment thread</a>.  Now, having studied them all, I’ve decided—as I hadn’t at the start—to use my entire allotment to make as strong a statement as I can about a single cause: namely, <strong>subject-matter passion and excellence in precollege STEM education</strong>.</p>



<p>I’ll be directing funds to some shockingly cash-starved math camps, math circles, coding outreach programs, magnet schools, and enrichment programs, in Maine and Oregon and England and Ghana and Ethiopia and Jamaica.  The programs I’ve chosen target a variety of ability levels, not merely the “mathematical elite.”  Several explicitly focus on minority and other underserved populations.  But they share a goal of raising every student they work with as high as possible, rather than pushing the students down to fit some standardized curriculum.</p>



<p>Language like that ought to be meaningless boilerplate, but alas, it no longer is.  We live in a time when the state of California, in a misguided pursuit of “modernization” and “equity,” is <a href="https://sites.google.com/view/k12mathmatters/home">poised</a> to eliminate 8th-grade algebra, make it nearly impossible for high-school seniors to take AP Calculus, and shunt as many students as possible from serious mathematical engagement into a “data science pathway” that in practice might teach little more than how to fill in spreadsheets.  (This watering-down effort now <em>itself</em> looks liable to be watered down—but only because of a furious pushback from parents and STEM professionals, pushback in which I’m proud that this blog <a href="https://scottaaronson.blog/?p=6146">played a small role</a>.)  We live in a time when elite universities are racing to eliminate the SAT—thus, for all their highminded rhetoric, effectively slamming the door on thousands of nerdy kids from poor or immigrant backgrounds who know how to think, but not how to shine in a college admissions popularity pageant.  We live in a time when America’s legendary STEM magnet high schools, from Thomas Jefferson in Virginia to Bronx Science to Lowell in San Francisco, rather than being celebrated as the national treasures that they are, or better yet replicated, are bitterly attacked as “elitist” (even while competitive sports and music programs are not similarly attacked)—and are now being forcibly “demagnetized” by bureaucrats, made all but indistinguishable from other high schools, over the desperate pleas of their students, parents, and alumni.</p>



<p>And—alright, fine, on a global scale, arresting climate change is surely a higher-priority issue than protecting the intellectual horizons of a few teenage STEM nerds.  The survival of liberal democracy is a higher-priority issue.  Pandemic preparedness, poverty, malnutrition are higher-priority issues.  Some of my friends strongly believe that <em>the danger of AI becoming super-powerful and taking over the world</em> is the highest-priority issue … and truthfully, with this week’s announcements of <a href="https://deepmind.com/blog/article/Competitive-programming-with-AlphaCode">AlphaCode</a> and <a href="https://openai.com/blog/formal-math/">OpenAI’s theorem prover</a>, which achieve human-competitive performance in elite programming and math competitions respectively, I can’t confidently declare that they’re wrong.</p>



<p>On the other hand, when you think about the astronomical returns on every penny that was invested in setting a teenage Ramanujan or Einstein or Turing or Sofya Kovalevskaya or Norman Borlaug or Mario Molina onto their trajectories in life … and the comically tiny budgets of the world-leading programs that aim to nurture the <em>next</em> Ramanujans, to the point where $10,000 often seems like a windfall to those programs … well, you might come to the conclusion that the “protecting nerds” thing actually isn’t <em>that</em> far down the global priority list!  Like, it probably cracks the top ten.</p>



<p>And there’s more to it than that.  There’s a reason beyond parochialism, it dawned on me, why individual charities tend to specialize in wildlife conservation in Ecuador or deworming in Swaziland or some other little domain, rather than simply casting around for the highest-priority cause on earth.  <em>Expertise matters</em>—since one wants to make, not only good judgments about which stuff to support, but good judgments that most others can’t or haven’t made.  In my case, it would seem sensible to leverage the fact that I’m Scott Aaronson.  I’ve spent much of my career in math/CS education and outreach—mostly, of course, at the university level, but <em>by god</em> did I personally experience the good and the bad in nearly every form of precollege STEM education!  I’m pretty confident in my ability to distinguish the two, and for whatever I don’t know, I have close friends in the area who I trust.</p>



<p>There’s also a practical issue: in order for me to fund something, the recipient has to fill out a somewhat time-consuming application to SFF.  If I’d added, say, another $20,000 drop into the bucket of global health or sustainability or whatever, there’s no guarantee that the intended recipients of my largesse would even notice, or care enough to go through the application process if they did.  With STEM education, by contrast, holy crap!  I’ve got an inbox full of <em>Shtetl-Optimized</em> readers explaining how their little math program is an intellectual oasis that’s changed the lives of hundreds of middle-schoolers in their region, and how $20,000 would mean the difference between their program continuing or not.  <em>That’s</em> someone who I trust to fill out the form.</p>



<p>Without further ado, then, here are the first-ever Scott Aaronson Speculation Grants:</p>



<ul><li>$57,000 for <a href="https://www.mathcamp.org/">Canada/USA Mathcamp</a>, which changed my life when I attended it as a 15-year-old in 1996, and which I returned to as a lecturer in 2008.  The funds will be used for COVID testing to allow Mathcamp to resume in-person this summer, and perhaps scholarships and off-season events as well.</li><li>$30,000 for <a href="https://www.addiscoder.com/">AddisCoder</a>, which has had spectacular success teaching computer science to high-school students in Ethiopia, placing some of its alumni at elite universities in the US, to help them expand to a new “JamCoders” program in Jamaica.  These programs were founded by UC Berkeley’s amazing <a href="https://en.wikipedia.org/wiki/Jelani_Nelson">Jelani Nelson</a>, also with involvement from friend and <em>Shtetl-Optimized</em> semi-regular <a href="https://en.wikipedia.org/wiki/Boaz_Barak">Boaz Barak</a>.</li><li>$30,000 for the <a href="https://www.mssm.org/">Maine School of Science and Mathematics</a>, which seems to offer a curriculum comparable to those of Thomas Jefferson, Bronx Science, or the nation’s other elite magnet high schools, but (1) on a shoestring budget and (2) in rural Maine.  I hadn’t even heard of MSSM before Alex Altair, an alum and <em>Shtetl-Optimized</em> reader, told me about it, but now I couldn’t be prouder to support it.</li><li>$30,000 for the <a href="https://pages.uoregon.edu/nemirovm/emc.html">Eugene Math Circle</a>, which provides a math enrichment lifeline to kids in Oregon, and whose funding was just cut.  This donation will keep the program alive for another year.</li><li>$13,000 for the <a href="https://summerscience.org/">Summer Science Program</a>, which this summer will offer research experiences to high-school juniors in astrophysics, biochemistry, and genomics.</li><li>$10,000 for the <a href="https://misemaths.wordpress.com/">MISE Foundation</a>, which provides math enrichment for the top middle- and high-school students in Ghana.</li><li>$10,000 for <a href="https://www.numberchampions.org.uk/">Number Champions</a>, which provides one-on-one coaching to kids in the UK who struggle with math.</li><li>$10,000 for <a href="https://www.beammath.org/">Bridge to Enter Advanced Mathematics (BEAM)</a>, which runs math summer programs in New York, Los Angeles, and elsewhere for underserved populations.</li><li>$10,000 for <a href="https://powderhouse.org/">Powderhouse</a>, an innovative lab school being founded in Somerville, MA.</li></ul>



<p>While working on this, it crossed my mind that, on my deathbed, I might be at least as happy about having directed funds to efforts like these as about any of my research or teaching.</p>



<p>To the applicants who weren’t chosen: I’m sorry, as many of you had wonderful projects too!  As I said in the earlier post, you remain warmly invited to apply to SFF, and to make your pitch to the other Speculators and/or the main SFF committee.</p>



<p>Needless to say, anyone who feels inspired should add to my (or rather, SFF’s) modest contributions to these STEM programs.  My sense is that, while $200k can go eye-poppingly far in this area, it still hasn’t come <em>close</em> to exhausting even the lowest-hanging fruit.</p>



<p>Also needless to say, the opinions in this post are my own and are not necessarily shared by SFF or by the organizations I’m supporting.  The latter are welcome to disagree with me as long as they keep up their great work!</p>



<p>Huge thanks again to Jaan, to SFF, to my SFF contact Andrew Critch, to everyone (whether chosen or not) who participated in this contest, and to everyone who’s putting in work to broaden kids’ intellectual horizons or otherwise make the world a little less horrible.</p></div>
    </content>
    <updated>2022-02-04T17:26:02Z</updated>
    <published>2022-02-04T17:26:02Z</published>
    <category scheme="https://scottaaronson.blog" term="Announcements"/>
    <category scheme="https://scottaaronson.blog" term="Nerd Interest"/>
    <category scheme="https://scottaaronson.blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://scottaaronson.blog/?feed=atom</id>
      <icon>https://scottaaronson.blog/wp-content/uploads/2021/10/cropped-Jacket-32x32.gif</icon>
      <link href="https://scottaaronson.blog" rel="alternate" type="text/html"/>
      <link href="https://scottaaronson.blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2022-02-07T01:34:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/04/postdoc-at-lip-ens-lyon-apply-by-march-1-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/04/postdoc-at-lip-ens-lyon-apply-by-march-1-2022/" rel="alternate" type="text/html"/>
    <title>postdoc at LIP, ENS Lyon (apply by March 1, 2022)</title>
    <summary>A postdoctoral position in Computer Science is available at LIP, ENS Lyon. Details on the website. Website: http://perso.ens-lyon.fr/edouard.bonnet/postdocOffer.html Email: edouard.bonnet@ens-lyon.fr</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A postdoctoral position in Computer Science is available at LIP, ENS Lyon. Details on the website.</p>
<p>Website: <a href="http://perso.ens-lyon.fr/edouard.bonnet/postdocOffer.html">http://perso.ens-lyon.fr/edouard.bonnet/postdocOffer.html</a><br/>
Email: edouard.bonnet@ens-lyon.fr</p></div>
    </content>
    <updated>2022-02-04T16:59:38Z</updated>
    <published>2022-02-04T16:59:38Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-07T12:37:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/04/phd-privacy-by-design-computing-for-iot-data-at-graduate-school-of-technical-sciences-aarhus-university-denmark-apply-by-march-15-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/04/phd-privacy-by-design-computing-for-iot-data-at-graduate-school-of-technical-sciences-aarhus-university-denmark-apply-by-march-15-2022/" rel="alternate" type="text/html"/>
    <title>Phd – Privacy-by-design Computing for IoT data at Graduate School of Technical Sciences, Aarhus University, Denmark (apply by March 15, 2022)</title>
    <summary>Applications are invited for a PhD fellowship/scholarship at Graduate School of Technical Sciences, Aarhus University, Denmark, within the Electrical and Computer Engineering programme. The position is available from 1 May 2022 or later. Website: https://phd.tech.au.dk/for-applicants/apply-here/saeropslag/privacy-by-design-computing-for-iot-data/ Email: daniel.lucani@ece.au.dk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Applications are invited for a PhD fellowship/scholarship at Graduate School of Technical Sciences, Aarhus University, Denmark, within the Electrical and Computer Engineering programme. The position is available from 1 May 2022 or later.</p>
<p>Website: <a href="https://phd.tech.au.dk/for-applicants/apply-here/saeropslag/privacy-by-design-computing-for-iot-data/">https://phd.tech.au.dk/for-applicants/apply-here/saeropslag/privacy-by-design-computing-for-iot-data/</a><br/>
Email: daniel.lucani@ece.au.dk</p></div>
    </content>
    <updated>2022-02-04T09:17:46Z</updated>
    <published>2022-02-04T09:17:46Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-07T12:37:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19620</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/02/03/next-big-thing/" rel="alternate" type="text/html"/>
    <title>Next Big Thing?</title>
    <summary>Big ideas we tend to like are the ones that seem impossible or crazy—Bill Maris UW History page Margaret O’Mara is a historian at the University of Washington. She specializes in the history of Silicon Valley. Of course we are most interested in the future of Silicon Valley. Today—between history and the future—we channel her […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Big ideas we tend to like are the ones that seem impossible or crazy—Bill Maris</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/03/next-big-thing/mo/" rel="attachment wp-att-19622"><img alt="" class="alignright wp-image-19622" height="175" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/mo.png?resize=140%2C175&amp;ssl=1" width="140"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">UW History <a href="https://history.washington.edu/people/margaret-omara">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Margaret O’Mara is a <a href="https://www.margaretomara.com/">historian</a> at the University of Washington. She specializes in the history of Silicon Valley. Of course we are most interested in the future of Silicon Valley. </p>
<p>
Today—between history and the future—we channel her insights to ask what next-big-things may intersect our fields.</p>
<p>
An <a href="https://www.nytimes.com/2022/01/24/technology/silicon-valley-next-big-thing.html">article</a> last week in the New York Times quotes her on recent developments:</p>
<ol>
<li>
“The age of mobile and cloud computing has created so many new business opportunities,” O’Mara said. “But now there are trickier problems.” <p/>
</li><li>
“Imagine the economic impact of the pandemic had there not been the infrastructure— the hardware and the software— that allowed so many white-collar workers to work from home and so many other parts of the economy to be conducted in a digitally mediated way”, she added.
</li></ol>
<p>
But what’s next?</p>
<p>
</p><p/><h2> The Next Big Idea? </h2><p/>
<p/><p>
The NYT article talks about the future of Silicon Valley as seen by O’Mara and other experts. The main issue is: what are the next big ideas that will come out of Silicon Valley? Big ideas are defined by ones that will change the future and generate billions if not trillions in dollars. Some possible ones are:</p>
<ol>
<li>
Self-driving cars; <p/>
</li><li>
Advanced artificial intelligence; <p/>
</li><li>
Brain implants—to control devices with only thoughts; <p/>
</li><li>
Quantum computing; <p/>
</li><li>
<img alt="{\dots ?}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots+%3F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>
</li></ol>
<p>
The article quotes Jake Taylor, the chief science officer at the quantum start-up <a href="https://www.riverlane.com">Riverlane</a>, as saying that “building a quantum computer might may be the most difficult task ever undertaken, [one that] defies the physics of everyday life.” </p>
<p/><h2> Next Big Theory Ideas? </h2><p/>
<p/><p>
I am quite interested in hearing what role complexity theory might play in creating the next big thing. If the area is quantum based then perhaps theory could play a major role. It helped start the explosion in interest in quantum computing. The famous results of Peter Shor on <a href="https://en.wikipedia.org/wiki/Shor%27s_algorithm">factoring</a> could no doubt play a major role. But the paradox is that theory does not seem to be central to thoughts on what the next big idea will be? Even if the idea is quantum based. </p>
<p>
What goal, result, breakthrough will make theory play a major role in the next <b>big idea</b>? </p>
<p>
One answer is to search the Internet. We find that Kurt Mehlhorn has had a course on the main ideas of theory. Perhaps we could imagine a direction for the next big idea based on one of these <a href="http://resources.mpi-inf.mpg.de/departments/d1/teaching/ss14/gitcs/syllabus.pdf">ideas</a> from his course:</p>
<ol>
<li>
Time vs. Space, P vs. NP, and More. <p/>
</li><li>
Interactive System, Zero Knowledge Proofs, the PCP Theorem. <p/>
</li><li>
Expander Graphs. <p/>
</li><li>
Learning Theory. <p/>
</li><li>
Streaming Algorithms. <p/>
</li><li>
Public-Key Cryptography. <p/>
</li><li>
Linear Programming. <p/>
</li><li>
Randomness in Computation. <p/>
</li><li>
Introduction to Approximation Algorithms. <p/>
</li><li>
Algorithms for Big Data. <p/>
</li><li>
Algebraic Techniques in Algorithm Design
</li></ol>
<p>
Here are the opening <a href="https://www.anilada.com/courses/15251f18/www/slides/lec1.pdf">slides</a> from a related course at CMU by Anil Ada and Bernhard Haeupler.</p>
<p>
</p><p/><h2> The Next is <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>? </h2><p/>
<p/><p>
Another idea is to search for other groups that have more directly looked at possible next ideas. For example: in 2014, a team of technical leaders from the IEEE Computer Society joined forces to write a technical report, entitled <a href="https://www.computer.org/publications/tech-news/trends/2022-report">IEEE CS 2022</a>, surveying 23 technologies that could potentially change the landscape of computer science and industry by the year 2022. By the way, 23 is special: <i>The famous Hilbert Problems are 23 in number.</i> See <a href="https://en.wikipedia.org/wiki/Hilbert%27s_problems">here</a>.</p>
<p>
Here are some of the top few that we might consider. Note we left out some that seem less special for computer science.  That leaves 14 problems.  OK, 14 is the number of Steve Smale’s problems that are fully or partly unresolved according to <a href="https://en.wikipedia.org/wiki/Smale%27s_problems">this</a>.</p>
<ol>
<li>
Security Cross-Cutting Issues The growth of large data repositories and emergence of data analytics have combined with intrusions by bad actors, governments, and corporations to open a Pandora’s box of issues. How can we balance security and privacy in this environment? <p/>
</li><li>
Sustainability Can electronic cars, LED lighting, new types of batteries and chips, and increasing use of renewables combat rising energy use and an explosion in the uptake of computing? <p/>
</li><li>
Device and Nanotechnology It is clear that MEMS devices, nanoparticles, and their use in applications are here to stay. Nanotechnology has already been useful in manufacturing sunscreen, tires, and medical devices that can be swallowed. <p/>
</li><li>
3D Integrated Circuits The transition from printed circuit boards to 3D-ICs is already underway in the mobile arena, and will eventually spread across the entire spectrum of IT products. <p/>
</li><li>
Photonics Silicon photonics will be a fundamental technology to address the bandwidth, latency, and energy challenges in the fabric of high-end systems. <p/>
</li><li>
Networking and Interconnectivity Developments at all levels of the network stack will continue to drive research and the Internet economy. <p/>
</li><li>
Software-Defined Networks OpenFlow and SDN will make networks more secure, transparent, flexible, and functional. <p/>
</li><li>
High-Performance Computing While some governments are focused on reaching exascale, some researchers are intent on moving HPC to the cloud. <p/>
</li><li>
The Internet of Things From clothes that monitor our movements to smart homes and cities, the Internet of Things knows no bounds, except for our concerns about ensuring privacy amid such convenience. <p/>
</li><li>
Natural User Interfaces The long-held dreams of computers that can interface with us through touch, gesture, and speech are finally coming true, with more radical interfaces on the horizon. <p/>
</li><li>
3D Printing 3D printing promises a revolution in fabrication, with many opportunities to produce designs that would have been prohibitively expensive. <p/>
</li><li>
Big Data and Analytics The growing availability of data and demand for its insights holds great potential to improve many data-driven decisions. <p/>
</li><li>
Machine Learning and Intelligent Systems Machine learning plays an increasingly important role in our lives, whether it’s ranking search results, recommending products, or building better models of the environment. <p/>
</li><li>
Computer Vision and Pattern Recognition Unlocking information in pictures and videos has had a major impact on consumers and more significant advances are in the pipeline.
</li></ol>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Any thoughts? Can theory play a main role in the future? </p>
<p/></font></font></div>
    </content>
    <updated>2022-02-04T04:47:33Z</updated>
    <published>2022-02-04T04:47:33Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="ideas"/>
    <category term="Margaret O'Mara"/>
    <category term="Next Big Thing"/>
    <category term="predictions"/>
    <category term="Theory"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-02-07T12:37:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1841700560229331052</id>
    <link href="http://blog.computationalcomplexity.org/feeds/1841700560229331052/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/the-beginnings-of-zero-knowledge.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/1841700560229331052" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/1841700560229331052" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/02/the-beginnings-of-zero-knowledge.html" rel="alternate" type="text/html"/>
    <title>The Beginnings of Zero-Knowledge</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Wired runs this <a href="https://www.youtube.com/playlist?list=PLibNZv5Zd0dyCoQ6f4pdXUFnpAIlKgm3N">video series</a> where topic expert explain concepts to five levels of difficulty, typically a child, teen, undergrad, grad student and expert. UCLA professor Amit Sahai <a href="https://www.youtube.com/watch?v=fOGdb1CTu5c">took this on</a> for zero-knowledge. </p><p>I'd recommend the whole thing but I'd like to focus on the last segment with USC Professor Shanghua Teng (<a href="https://youtu.be/fOGdb1CTu5c?t=1025">starts at 17:05</a>). Amit nicely summed up the importance of the paper.</p><blockquote><p>What was such a beautiful insight is that the idea of zero-knowledge being something that you can already predict. If you can already predict the answer, then you must not be gaining any knowledge by that interaction. This insight of being able to predict the future accurately, and that being an evidence of a lack of new knowledge.</p></blockquote><p>Like Shanghua I was also assigned the seminal zero-knowledge paper by Goldwasser-Micali-Rackoff from my advisor. In many ways the <a href="https://dl.acm.org/doi/10.1145/22145.22178">original STOC paper</a> was rough. The definitions were buggy, the examples uninspiring. Supposedly the paper didn't even get accepted into a conference in its first try. And yet as you read the paper you realize the potential, the beauty of not one but two new models that would go on to change both cryptography and complexity forever.</p><p>In the fall of 1985 when I started graduate school I took a cryptography class from Manuel Blum. Much of that class was spent on protocols that would convince you that, for example, a number was the product of three primes. By the spring of 1986, Goldreich, Micali and Wigderson distributed <a href="https://dl.acm.org/doi/abs/10.1145/116825.116852">their paper</a> showing, among other things, all NP problems has zero-knowledge proofs, making many of the protocols discussed in Blum's course a few months earlier trivial corollaries.</p><p>But it wasn't just zero-knowledge. Goldwasser, Micali and Rackoff (and independently <a href="https://doi.org/10.1016/0022-0000(88)90028-1">Babai and Moran</a>) developed the notion of interactive proof, a proof system with statistical confidence, a model that would lead to probabilistically checkable proofs and helping us understand the limits of approximation.</p><p>I owe most of my early research to the models developed in the GMR paper and glad that Amit has found a way to share these ideas so well.</p></div>
    </content>
    <updated>2022-02-02T21:46:00Z</updated>
    <published>2022-02-02T21:46:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-07T10:26:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4607</id>
    <link href="https://lucatrevisan.wordpress.com/2022/02/02/%e6%81%ad%e5%96%9c%e5%8f%91%e8%b4%a2-13/" rel="alternate" type="text/html"/>
    <title>恭喜发财!</title>
    <summary>新年快乐！</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><figure class="wp-block-image size-full"><a href="https://lucatrevisan.files.wordpress.com/2010/02/calvin-and-hobbes.jpg"><img alt="" class="wp-image-1680" src="https://lucatrevisan.files.wordpress.com/2010/02/calvin-and-hobbes.jpg"/></a></figure>



<p>新年快乐！</p></div>
    </content>
    <updated>2022-02-02T20:15:12Z</updated>
    <published>2022-02-02T20:15:12Z</published>
    <category term="&#x65B0;&#x5E74;"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2022-02-07T12:37:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/02/tenure-track-faculty-at-university-of-haifa-at-oranim-campus-apply-by-february-28-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/02/tenure-track-faculty-at-university-of-haifa-at-oranim-campus-apply-by-february-28-2022/" rel="alternate" type="text/html"/>
    <title>Tenure-Track Faculty at University of Haifa at Oranim Campus (apply by February 28, 2022)</title>
    <summary>The Department of Mathematics-Physics-Computer Science of the University of Haifa at Oranim College invites applications for a tenure-track faculty position in all areas of Computer Science, to begin October 1st 2022. More details on our website. Applications will be considered until the position is filled. Website: https://mathphys.haifa.ac.il/en/announcements/ Email: ackerman@math.haifa.ac.il</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Mathematics-Physics-Computer Science of the University of Haifa at Oranim College invites applications for a tenure-track faculty position in all areas of Computer Science, to begin October 1st 2022. More details on our website.<br/>
Applications will be considered until the position is filled.</p>
<p>Website: <a href="https://mathphys.haifa.ac.il/en/announcements/">https://mathphys.haifa.ac.il/en/announcements/</a><br/>
Email: ackerman@math.haifa.ac.il</p></div>
    </content>
    <updated>2022-02-02T14:47:55Z</updated>
    <published>2022-02-02T14:47:55Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-07T12:37:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/02/postdoc-at-university-of-bergen-apply-by-february-11-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/02/postdoc-at-university-of-bergen-apply-by-february-11-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at University of Bergen (apply by February 11, 2022)</title>
    <summary>Two postdoctoral positions in Algorithmic foundations of data science (in a very broad sense), funded by ERC Consolidator grant of Saket Saurabh. Competitive salary, solid travel funds, and friendly research environment. Website: https://www.jobbnorge.no/en/available-jobs/job/218932/researcher-in-informatics-algorithmic-foundations-of-data-science Email: fedor.fomin@uib.no</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Two postdoctoral positions in Algorithmic foundations of data science (in a very broad sense), funded by ERC Consolidator grant of Saket Saurabh. Competitive salary, solid travel funds, and friendly research environment.</p>
<p>Website: <a href="https://www.jobbnorge.no/en/available-jobs/job/218932/researcher-in-informatics-algorithmic-foundations-of-data-science">https://www.jobbnorge.no/en/available-jobs/job/218932/researcher-in-informatics-algorithmic-foundations-of-data-science</a><br/>
Email: fedor.fomin@uib.no</p></div>
    </content>
    <updated>2022-02-02T12:06:04Z</updated>
    <published>2022-02-02T12:06:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-07T12:37:43Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://gradientscience.org/datamodels-1/</id>
    <link href="https://gradientscience.org/datamodels-1/" rel="alternate" type="text/html"/>
    <title>Predicting Predictions with Datamodels</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="bbutton" href="https://arxiv.org/abs/2202.00622" style="float: left; width: 45%;">
<i class="fas fa-file-pdf"/>
    Paper
</a>
<a class="bbutton" href="https://github.com/MadryLab/datamodels-data" style="float: left; width: 45%;">
<i class="fab fa-github"/>
   Data
</a>
<br/>
<em>What drives machine learning (ML) models’ predictions?</em></p>

<p>This question is rarely an easy one to answer. On one hand, we know that predictions are a product of <em>training data</em> and <em>learning algorithms</em>. On the other hand, it is often hard to characterize exactly how these two elements interact.</p>

<p>In our <a href="https://arxiv.org/abs/2202.00622">latest work</a>, we introduce <em>datamodels</em>—a step towards acquiring a more fine-grained understanding of how learning algorithms use training data to make predictions. This post introduces the datamodeling framework, describes its simplest, <em>linear</em> instantiation, and illustrates its success in modeling data-to-prediction mapping for deep neural networks. Our future posts will tour through some of the applications of the datamodeling framework that we are most excited about.</p>

<h2 id="what-is-a-datamodel">What is a datamodel?</h2>

<p>In the standard machine learning setup, we have both a learning algorithm (say, stochastic gradient descent applied to a deep neural network) and a training set to learn from (say, the CIFAR-10 training set).</p>

<p>Now, suppose that we want to evaluate model behavior on a specific input \(x\). For example, \(x\) might be one of the following input-label pairs from the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a> test set:</p>



<div class="row">
     <div class="img_holder">
         <img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse7.png"/>
         <span>"horse"</span>
     </div>
     <div class="img_holder">
         <img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog7.png"/>
         <span>"dog"</span>
     </div>
     <div class="img_holder">
         <img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship5.png"/>
         <span>"boat"</span>
     </div>
     <div class="img_holder">
         <img src="https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck5.png"/>
         <span>"firetruck"</span>
     </div>
 </div>

<p>A natural question that might arise in this context is: <em>for such an example \(x\), how does the learning algorithm use the training data to arrive at its prediction?</em> Answering this question is difficult—think of the underlying complexity stemming from training  a deep neural network using thousands of stochastic gradient descent (SGD) steps.</p>

<p>Our <em>datamodeling</em> framework is motivated exactly by this challenge. Specifically, the goal of datamodeling is to bypass that complexity of model training entirely, and instead find a <em>simple</em> function that <em>directly</em> maps training data to predictions. So, roughly speaking, a <em>datamodel</em> for a specific example of interest \(x\) is a function \(g(S’)\) that takes as input any subset \(S’\) of the original training \(S\), and as output predicts the outcome of training a model on \(S’\) and then evaluating on \(x\).</p>
<div class="footnote">
Note that “evaluating” is left intentionally vague here as we expect the specific form to be task dependent: one might be interested in, for instance, the predicted label (e.g., in classification tasks), squared error (e.g., in regression tasks), or log-likelihood (e.g., in language modeling tasks).
</div>

<p>For the visual learners out there, datamodels have the following interface:</p>

<p><img src="https://gradientscience.org/images/datamodels/flow.png" style="width: 75%;"/></p>

<p>The hope is to find datamodels that are <em>simple</em> enough to analyze directly, yet <em>accurate</em> enough to faithfully capture model behavior. We then can use such datamodels to gain insight into how the algorithm and data combine <em>through</em> the lens of the training dynamics (but without having to analyze that dynamics directly).</p>

<p>At first glance, this of task of <em>predicting</em> the output of a learning algorithm trained on different subsets of the original training set does not appear any easier than <em>analyzing</em> the learning algorithm on that original training set—in fact, it might seem even harder. At the very least, one would expect that any function approximating such a learning algorithm would need to be rather complicated. It turns out, however, that a (very) simple instantiation of datamodels—as linear functions—is already expressive enough to accurately capture the intended mapping, even for real-world deep neural networks!</p>

<h2 id="linear-datamodels-for-deep-classifiers">Linear datamodels for deep classifiers</h2>

<p>How exactly do we formulate <em>linear datamodels</em>? We represent each subset \(S’\) of the training set as an <em>indicator vector</em> \(\mathbf{1}_{S’}\), and then have our datamodel \(g_\theta\) map such indicator vectors to scalars. Specifically, we parameterize linear datamodels as:</p>

\[g_\theta(S’) = \mathbf{1}_{S’}^\top \theta + \theta_0,\]

<p>where \(\theta\) are our model’s parameters.</p>

<div class="footnote">
An <a href="https://en.wikipedia.org/wiki/Indicator_vector">indicator vector</a>
is a binary vector of dimension equal to the size of the training set, whose
\(i\)-th index is equal to \(1\) if and only if the \(i\)-th training example is present in \(S’\). 
</div>

<h2 id="estimating-linear-datamodels">Estimating linear datamodels</h2>

<p>Now, how do we actually select parameters \(\theta\) for such a linear datamodel? Recall that our goal is to find a \(\theta\) such that our linear datamodel satisfies:</p>

<center>
$$
g_\theta(S’) \approx \mbox{the output on \(x\) of a model trained on \(S’\).}
$$
</center>

<p>Our idea is to frame this task as a <em>supervised learning problem</em> in which we infer \(g_\theta\) from “input-label pairs.” Here, each of these pairs consists of a specific training subset \(S’\) (“input”) and the corresponding model output on \(x\) (“label”). Indeed, obtaining such pairs is rather easy—for a given choice of \(S’\), we retrieve corresponding outputs by just executing the learning algorithm on \(S’\) and evaluating on \(x\).</p>

<p>From this perspective, estimating \(g_\theta\) for a given \(x\) becomes a two-step process:</p>

<ul>
  <li><strong>Collecting our datamodel train set</strong>:  Sample a training subset \(S_i\), train
 a model on \(S_i\), and, finally, add the corresponding “input-label pair”
 \((S_i, \text{trained model output on }x)\) to our datamodel training set. 
 Rinse and repeat (until that training set becomes sufficiently large).</li>
  <li><strong>Datamodel training</strong>: Solve for \(\theta\) by regressing from our “training subsets” \(S_i\) to their corresponding model outputs on \(x\).</li>
</ul>

<p>Now: how many such input-label pairs do we need to be able to solve the corresponding (very high-dimensional) regression problem? (Note that the dimension here is 50k, the size of the training set!) The answer is: a lot. Specifically, to fit CIFAR-10 datamodels we trained a few <em>hundred thousand</em> CIFAR-10 models. (Moreover, looking across all our paper’s experiments, we train more than 4 million such models in total.) To make this task feasible, we designed (and released!) a <a href="https://ffcv.io/">fast fast model training library</a>—you might find this library helpful for your training tasks, however big or small. With our library, we were able to bring CIFAR training down to <em>seconds</em> on a single (A100) GPU, meaning that training hundreds of thousands of models takes (only) a few days (on a single machine).</p>

<div class="footnote">
Use our <i>data release</i>! Both pre-computed datamodels and the predictions of 4 million trained CIFAR models are available for download at <a href="https://github.com/MadryLab/datamodels-data">https://github.com/MadryLab/datamodels-data</a>.
</div>

<h2 id="evaluating-datamodels">Evaluating datamodels</h2>

<p>Now, after all this setup, the key question is: how accurately do such linear datamodels predict model behavior? Following our supervised learning perspective, the gold standard is to evaluate via a held-out test set: a set of (held-out) input-label (or rather, in our case, subset-model output) pairs.</p>

<p>Specifically, we make a <em>datamodel “test set”</em> using the same sampling process employed to generate the datamodel train set. We then compare <em>datamodel-predicted</em> outputs for these (previously unseen) collected subsets to the <em>true outputs</em> (i.e., the output of training a model on the subset and evaluating on the relevant example). It turns out that datamodels predictions predict the result of model training rather well!</p>

<p>
    <img src="https://gradientscience.org/images/datamodels/blog_xy.svg" style="width: 50%;"/>
</p>

<div class="footnote">
    The plotted points range across both choice of training set and target example \(x\). The magnified clusters of the same color each correspond to the same \(x\) for different sampled training sets \(S’\). The output here that we measure is correct-label margin, i.e., the difference between the logit for the correct class and the largest incorrect logit.
</div>

<p>The predicted and actual margins here—even conditioned on a specific \(x\)—correspond nearly one-to-one, despite that our predicted margins come from a linear model, and the actual margins stem from thousands of SGD steps on a ResNet-9!</p>

<h2 id="how-can-we-use-datamodels">How can we use datamodels?</h2>

<p>We’ve already seen that a simple linear model can predict the output of end-to-end model training (for a single target example) relatively well. We found this phenomenon surprising on its own, and hope that studying it further might yield theoretical or empirical insights into the generalization of deep networks (and when applied to new settings, other classes of machine learning models).</p>

<p>That said, in a series of follow up posts we’ll also highlight some of the other direct datamodel applications:</p>

<ul>
  <li>In Part 2, we’ll take a deeper dive into datamodels’ ability to predict outcomes of model training, and find that this ability extends beyond just the subsets sampled from the distribution they were fitted to. We’ll then use this capability to identify <em>brittle predictions</em>, test examples for which model predictions can be flipped by removing just a small number of examples from the training set.</li>
  <li>In Part 3, we’ll discuss how to use datamodels to identify training examples that are similar to any given test example, and will then employ this capability to find (non-trivial) train-test leakage in both CIFAR-10 and FMoW datasets. (FMoW is the other dataset that we investigate in our paper.)</li>
  <li>In Part 4, we’ll explore leveraging linear datamodels as <em>feature representation</em>. Specifically, we find that datamodels yield a natural way to embed every example into a well-behaved representation space. We use the corresponding embeddings to perform clustering and identify <em>model-driven</em> data subpopulations.</li>
</ul>

<p>All of these applications are fully detailed in <a href="https://arxiv.org/abs/2202.00622">our paper</a>, along with more experiments, a more formal introduction to datamodels, and an extensive discussion of the related and future work in this area. Also, check out our <a href="https://github.com/MadryLab/datamodels-data">data release</a> with both pre-computed datamodels and predictions corresponding to million CIFAR-10 models. Stay tuned for more!</p></div>
    </summary>
    <updated>2022-02-02T00:00:00Z</updated>
    <published>2022-02-02T00:00:00Z</published>
    <source>
      <id>https://gradientscience.org/</id>
      <author>
        <name>Gradient Science</name>
      </author>
      <link href="https://gradientscience.org/" rel="alternate" type="text/html"/>
      <link href="https://gradientscience.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Research highlights and perspectives on machine learning and optimization from MadryLab.</subtitle>
      <title>gradient science</title>
      <updated>2022-02-07T00:45:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/012</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/012" rel="alternate" type="text/html"/>
    <title>TR22-012 |  On List Decoding Transitive Codes From Random Errors | 

	Anup Rao, 

	Oscar Sprumont</title>
    <summary>We study the error resilience of transitive linear codes over $F_2$. We give tight bounds on the weight distribution of every such code $C$, and we show how these bounds can be used to infer bounds on the error rates that $C$ can tolerate on the binary symmetric channel. Using this connection, we show that every transitive code can be list-decoded from random errors. As an application, our results imply list-decoding bounds for Reed-Muller codes even when the rate exceeds the channel capacity.</summary>
    <updated>2022-02-01T22:26:33Z</updated>
    <published>2022-02-01T22:26:33Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-07T12:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/02/01/postdoc-at-boston-college-apply-by-february-21-2022/</id>
    <link href="https://cstheory-jobs.org/2022/02/01/postdoc-at-boston-college-apply-by-february-21-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc at Boston College (apply by February 21, 2022)</title>
    <summary>The Computer Science department at Boston College invites applications for a postdoctoral position in the area of graph algorithms (broadly defined, e.g. distributed graph algorithms, local algorithms, dynamic graph algorithms, streaming algorithms, MPC algorithms, and etc) under the supervision of Hsin-Hao Su. Website: https://sites.google.com/site/distributedhsinhao/postdoc-position-on-distributed-graph-algorithms Email: suhx@bc.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Computer Science department at Boston College invites applications for a postdoctoral position in the area of graph algorithms (broadly defined, e.g. distributed graph algorithms, local algorithms, dynamic graph algorithms, streaming algorithms, MPC algorithms, and etc) under the supervision of Hsin-Hao Su.</p>
<p>Website: <a href="https://sites.google.com/site/distributedhsinhao/postdoc-position-on-distributed-graph-algorithms">https://sites.google.com/site/distributedhsinhao/postdoc-position-on-distributed-graph-algorithms</a><br/>
Email: suhx@bc.edu</p></div>
    </content>
    <updated>2022-02-01T19:10:53Z</updated>
    <published>2022-02-01T19:10:53Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-07T12:37:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://nisheethvishnoi.wordpress.com/?p=131</id>
    <link href="https://nisheethvishnoi.wordpress.com/2022/01/31/focs-2021-is-virtually-here/" rel="alternate" type="text/html"/>
    <title>FOCS 2021 is (Virtually) Here!</title>
    <summary>The 62nd Annual IEEE Foundations of Computer Science (FOCS) will be held (virtually) February 7-10, 2022 — this coming Monday! Thanks to the effort of the progam committee, the FOCS 2021 program consists of 118 amazing papers in three parallel sessions. All talks will be live and of the usual length of 20 minutes. The […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The <a href="https://focs2021.cs.colorado.edu/">62nd Annual IEEE Foundations of Computer Science (FOCS)</a> will be held (virtually) February 7-10,  2022 — this coming Monday!</p>



<p>Thanks to the effort of the <a href="https://focs2021.cs.colorado.edu/cfp/">progam committee</a>, the <a href="https://focs2021.cs.colorado.edu/program/">FOCS 2021 program</a> consists of 118 amazing papers in three parallel sessions. All talks will be <strong>live </strong>and of the usual length of 20 minutes. The program has also set aside ample time for breaks to enable the participants to socialize and connect on gather and slack. </p>



<p>FOCS 2021 also has <strong>three exciting workshops</strong> as a part of the main program:<br/><br/>1) <a href="https://sites.google.com/view/focs2021ml/home">Recent directions in Machine Learning</a>: co-organized by <a href="https://www.cs.columbia.edu/~djhsu/">Daniel Hsu</a>, <a href="https://people.csail.mit.edu/madry/">Aleksander Madry</a>, and <a href="http://users.eecs.northwestern.edu/~aravindv/">Aravindan Vijayaraghavan</a>, and and featuring <a href="http://tensorlab.cms.caltech.edu/users/anima/">Anima Anandkumar</a>, <a href="https://causalai.net/">Elias Bareinboim</a>, <a href="http://people.cs.uchicago.edu/~risi/">Risi Kondor</a>, <a href="https://profiles.stanford.edu/chris-manning">Christopher Manning</a>, <a href="https://www.andrew.cmu.edu/user/aristesk/">Andrej Risteski</a>, <a href="http://www.columbia.edu/~cgr2130/">Cynthia Rush</a>, <a href="https://jsteinhardt.stat.berkeley.edu/">Jacob Steinhardt</a>.<br/><br/>2) <a href="https://derezende.github.io/focs21proofcomplexity/index.html">Reflections on Propositional Proofs in Algorithms and Complexity</a>: co-organized by <a href="https://www.cs.toronto.edu/~toni/" rel="noreferrer noopener" target="_blank">Toni Pitassi</a>, <a href="https://derezende.github.io/">Susanna de Rezende</a>, and <a href="https://www.cs.mcgill.ca/~robere/" rel="noreferrer noopener" target="_blank">Robert Robere</a>, and featuring <a href="https://www.math.ucsd.edu/~sbuss/" rel="noreferrer noopener" target="_blank">Sam Buss</a>, <a href="https://home.cs.colorado.edu/~jgrochow/index.html" rel="noreferrer noopener" target="_blank">Joshua Grochow</a>, <a href="https://www.cs.cmu.edu/~praveshk/" rel="noreferrer noopener" target="_blank">Pravesh K. Kothari</a>, <a href="https://www2.karlin.mff.cuni.cz/~krajicek/" rel="noreferrer noopener" target="_blank">Jan Krajíček</a>, <a href="https://www.cs.toronto.edu/~toni/" rel="noreferrer noopener" target="_blank">Toni Pitassi</a>, <a href="https://derezende.github.io/">Susanna de Rezende</a>, <a href="https://www.cs.mcgill.ca/~robere/" rel="noreferrer noopener" target="_blank">Robert Robere</a>, <a href="https://www.cs.ox.ac.uk/people/rahul.santhanam/" rel="noreferrer noopener" target="_blank">Rahul Santhanam</a>, <a href="https://users.math.cas.cz/~thapen/" rel="noreferrer noopener" target="_blank">Neil Thapen</a>.<br/><br/>3) <a href="https://focs2021.cs.colorado.edu/workshop-on-cryptography/">Workshop on Cryptography</a>: co-organized by <a href="https://crypto.stanford.edu/~dabo/">Dan Boneh</a> and <a href="http://web.cs.ucla.edu/~sahai/">Amit Sahai</a>, and featuring <a href="https://cs.idc.ac.il/~elette/">Elette Boyle</a>, <a href="https://sites.google.com/view/aayushjain/home">Aayush Jain</a>, <a href="https://www.cs.technion.ac.il/~yuvali/">Yuval Ishai</a>, <a href="https://homes.cs.washington.edu/~rachel/">Rachel Lin</a>, <a href="https://c.rypto.systems/">Wilson Nguyen</a>, <a href="https://www.cs.cornell.edu/~rafael/">Rafael Pass</a>, <a href="https://simons.berkeley.edu/people/hoeteck-wee">Hoeteck Wee</a>.</p>



<p><a href="https://focs2021.cs.colorado.edu/registration/">Registration </a>is still open and available at a reduced rate of $100-150 for participants. </p>



<p>Thanks to generous support from the National Science Foundation, there will be a total of $15,000 in <a href="https://focs2021.cs.colorado.edu/nsf-awards-for-focs-2021/">support for FOCS 2021</a> for eligible students and postdoctoral fellows towards registration fee. </p>



<p>Looking forward to seeing many of you next week!</p>



<p/>



<p><strong>Update: Junior/Senior Lunches by <a href="https://ccanonne.github.io/">Clement Cannone</a> and <a href="http://www.gautamkamath.com/">Gautam Kamath</a>:<br/></strong></p>



<p>Back by popular demand! As part of FOCS 2021, and in view of the success of similar events in the past, a “junior/senior lunch” will take place on Tuesday February 8, 1:30PM-2:30pm ET. Importantly, this is <strong>not</strong> limited to FOCS attendees! As in previous years, this virtual lunch will be the occasion for senior researchers in the field, broadly construed, to have an informal chat with students, postdocs, and junior faculty, answer their questions, discuss their research, and generally have a nice conversation.</p>



<p>To participate as either a senior or junior researcher, please write your name in <a href="https://docs.google.com/spreadsheets/d/1nrL8I0l2OF1kbMFTKlaBdK1L2LXkOMjR1PKBjEUSA4E/edit?usp=sharing">this spreadsheet</a>. Further instructions will be sent to people who sign up.  If you are on the “senior” side of the lunch, you will be responsible for contacting the corresponding juniors, and provide a Zoom link.</p>



<p/>



<p><br/></p></div>
    </content>
    <updated>2022-01-31T21:33:22Z</updated>
    <published>2022-01-31T21:33:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>nisheethvishnoi</name>
    </author>
    <source>
      <id>https://nisheethvishnoi.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://nisheethvishnoi.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://nisheethvishnoi.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Algorithms, Nature, and Society</title>
      <updated>2022-02-07T12:38:48Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/01/31/linkage</id>
    <link href="https://11011110.github.io/blog/2022/01/31/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>A happy 75th birthday to Dick Lipton and 1000th post on his blog with Ken Regan, Gödel’s Lost Letter and \(\mathsf{P}=\mathsf{NP}\) (\(\mathbb{M}\)).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://rjlipton.wpcomstaging.com/2022/01/14/happy-1000th-post-and-75th-birthday-dick/">A happy 75th birthday to Dick Lipton and 1000th post on his blog with Ken Regan, <em>Gödel’s Lost Letter and \(\mathsf{P}=\mathsf{NP}\)</em></a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107634279991786612">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p>A quick round-up of three recent Wikipedia Good Articles <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107640833016660096">\(\mathbb{M}\)</a>):</span></p>

    <ul>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Factorial">Factorial</a> – you know, <span style="white-space: nowrap;">\(n!\).</span></p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Jessen%27s_icosahedron">Jessen’s icosahedron</a> – polyhedron with all-right dihedrals despite not having axis-parallel sides; the shape of the “Skwish” tensegrity.</p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Straus_conjecture">Erdős–Straus conjecture</a> – the question of whether \(\tfrac4n=\tfrac1x+\tfrac1y+\tfrac1z\) has positive integer solutions for <span style="white-space: nowrap;">all \(n\gt 1\).</span></p>
      </li>
    </ul>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2201.06475">Infinite Hex is a draw</a>, Joel David Hamkins and Davide Leonessi <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107646776817088370">\(\mathbb{M}\)</a>,</span> <a href="http://jdh.hamkins.org/infinite-hex-is-a-draw/">via</a>). The paper uses a winning condition for the infinite game that seems pretty technical: you need a bidirectional infinite path of your pieces, whose two ends eventually stay inside all translations of  two opposite quadrants (NE-SW or NW-SE depending on the player). They give a simple mirroring strategy for drawing, and explain why other winning conditions aren’t as nice.</p>
  </li>
  <li>
    <p><a href="https://fractalkitty.com/2022/01/19/string-art-presentation/">String art from Fractal Kitty</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@fractalkitty/107649797432442304">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://cs.stanford.edu/~knuth/fasc12a+.pdf">The Art of Computer Programming, Volume 4, Pre-Fascicle 12A: Components and Traversal</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107659396275070620">\(\mathbb{M}\)</a>).</span> It’s labeled as “ridiculously preliminary”, but includes interesting material on <a href="https://en.wikipedia.org/wiki/Weak_component">weak components of directed graphs</a>. Strong components are the finest partially ordered vertex sets under reachability; analogously, weak components are the finest total order. Every vertex can reach all vertices in later sets, and none in earlier ones.</p>
  </li>
  <li>
    <p><a href="https://mirtitles.org/2022/01/16/some-applications-of-mechanics-to-mathematics-popular-lectures-in-mathematics-vol-3-uspenskii/"><em>Some Applications Of Mechanics To Mathematics</em> by V. A. Uspenskii</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@jarban/107634117912496403">\(\mathbb{M}\)</a>).</span> Usually it goes the other way around. One of the Mir free book series, translated from Russian into English.</p>
  </li>
  <li>
    <p><a href="https://somethingorotherwhatever.com/jiggraph/">JIGGRAPH</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@christianp/107671629340668489">\(\mathbb{M}\)</a>).</span> A game of holding hands or, if you prefer something more abstract, fitting vertices with known local geometries together into a graph.</p>
  </li>
  <li>
    <p><a href="https://history-of-mathematics.org/">History of Mathematics Project</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107676446199538323">\(\mathbb{M}\)</a>,</span> <a href="https://www.sciencenews.org/article/history-math-online-exhibit-journey">via</a>, <a href="https://www.metafilter.com/194098/Math-History">via2</a>), an online exhibit for MOMATH. I’m not convinced of the soundness of a project whose timeline of prime numbers starts with Eratosthenes instead of Euclid, skips from Greeks to enlightenment Europe completely bypassing Ibn al-Haytham (using an ordinal time scale to hide the gap), and doesn’t mention the prime number theorem, but still this looks interesting or at least entertaining.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2107.13460">Asymptotics of the number of \(n\)-queens placements</a>, Michael Simkin <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107681952236743192">\(\mathbb{M}\)</a>,</span> <a href="https://news.harvard.edu/gazette/story/2022/01/harvard-mathematician-answers-150-year-old-chess-problem/">via</a>, <a href="https://news.ycombinator.com/item?id=30068680">via2</a>). “The chief innovation is the introduction of limit objects for \(n\)-queens configurations, which we call queenons.”</p>
  </li>
  <li>
    <p><a href="https://theconversation.com/more-women-in-a-stem-field-leads-people-to-label-it-as-a-soft-science-according-to-new-research-173724">More women in a STEM field leads people to label it as a “soft science”</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107687670599777394">\(\mathbb{M}\)</a>).</span> Alysson Light provides a general-audience explanation of <a href="https://doi.org/10.1016/j.jesp.2021.104234">her research with Tessa Benson-Greenwald and Amanda Diekman in <em>J. Experimental Social Psych.</em></a>.</p>
  </li>
  <li>
    <p>Today’s observation on overlooked history of mathematics <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107693041325431974">\(\mathbb{M}\)</a>):</span> The <a href="https://en.wikipedia.org/wiki/Binary_tiling">binary tiling of the hyperbolic plane</a>, generally attributed to a 1974 paper by Károly Böröczky, was already used by M. C. Escher in a 1957 print, <em><a href="https://www.escherinhetpaleis.nl/escher-today/woodblocks-and-the-regular-division-of-the-plane/?lang=en">Regular Division of the Plane VI</a></em>.</p>
  </li>
  <li>
    <p>If the pigeonhole principle is the idea that more than \(n\) items distributed into  containers lead to a container with more than one item <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107706939046931942">\(\mathbb{M}\)</a>),</span> what is the name for the principle that fewer than \(n\) items distributed into  containers lead to an empty container?</p>
  </li>
  <li>
    <p><a href="https://3quarksdaily.com/3quarksdaily/2022/01/do-androids-dream-of-mathematics.html">Do androids dream of mathematics</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107710557994842340">\(\mathbb{M}\)</a>)?</span> A popular-audience essay by algebraic combinatorist Jonathan Kujawa on data vs insight in mathematics, and the use of computers in sifting through piles of data on mathematical objects and their invariants in order to focus on potential relations between them.</p>
  </li>
  <li>
    <p>I upgraded from MacOS 11 to 12.2 recently <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107718968183366763">\(\mathbb{M}\)</a>).</span> Today was our first day of in-person classes. I could not get my laptop working with the lecture hall display. Fortunately I was broadcasting the lecture over Zoom and everyone in the classroom had a laptop so we did it that way. But <a href="https://www.youtube.com/watch?v=C6FyXNfGY0k">this video</a> looks like it describes the problem, and a fix (in System Preferences : Battery : Battery, uncheck “Automatic graphics switching”) — I’m hopeful this will work and I can lecture from the big screen next time.</p>
  </li>
</ul></div>
    </content>
    <updated>2022-01-31T17:14:00Z</updated>
    <published>2022-01-31T17:14:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-02-05T20:49:19Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6013534385390898908</id>
    <link href="http://blog.computationalcomplexity.org/feeds/6013534385390898908/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/01/regan-lipton-celebrates-my-1000th-blog.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6013534385390898908" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6013534385390898908" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/01/regan-lipton-celebrates-my-1000th-blog.html" rel="alternate" type="text/html"/>
    <title>Regan Lipton celebrates my 1000th blog post and random thoughts this inspires</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Ken Regan emailed me recently asking if our software could tell how many blogs I had done (not how many Lance+Bill had done). We didn't know how to do that but he managed it anyway. Apparently he was more interested in this question than either Lance or I was. </p><p>But the answer was interesting: My1000th post of Complexityblog was about Betty White dying at just the wrong time to be in those <i>those we say goodbye to</i> articles that appear CLOSE to the end of the year. (I don't know why, but I think the fact that my 1000th post was on Betty White is just awesome!) The post is <a href="https://blog.computationalcomplexity.org/2022/01/did-betty-white-die-in-2021why-do.html">here</a>. He was asking this because he thought (correctly) that I was around 1000 and wanted to do a tribute blog to me (actually it was done by Lipton and Regan- more on that later). And indeed they did do the post, its <a href="https://rjlipton.wpcomstaging.com/2022/01/29/bill-gasarch-also-1000/">here</a>.</p><p>RANDOM THOUGHT ONE</p><p>While preparing it Ken asked me about my papers.  This brings up the more general question: When looking at your old work what do you think? Common reactions are</p><p>1) Gee, I was smarter then. That was very clever. OH, now I remember, my co-author did it. </p><p>2) Gee, I was dumber then. I could do that argument so much better now. </p><p>3) Why did I care about Muffins so much to write a book about it? (Replace <i>Muffins</i> with <i>whatever you</i> <i>worked on</i> and <i>book</i> with the<i> venue it appeared in</i>.) </p><p>Item 3 is probably the most common: As a graduate student one works on things without really have a vision of the field (though the advisor can mitigate this) so what you work on may seem odd later on. And ones tastes can change as well. </p><p>RANDOM THOUGHT TWO</p><p>Ken and Dick write actual posts together. I find that amazing! By contrast, the extent of Lance and my interactions about the blog are: </p><p>a) Someone died. Which of us should do the blog obit? or get a guest blogger.?(Whenever Lance phones me on the telephone I answer <i>who died</i> and usually someone did.) </p><p>b) Which of us does the April Fools Day post this year (we usually alternate, or <a href="https://blog.computationalcomplexity.org/2014/04/i-am-bill-gasarch.html">do we</a>)?</p><p>c) I plan on doing 2 posts close together- a question and an answer, so when do you NOT plan on blogging so I can do that.</p><p>d) Someone proved X. Which of us should blog? Or should we get a guest blogger?</p><p>e) Establish a general rule for the year like <i>Bill will post Sunday's, Lance Thursdays.</i></p><p>f) I ask Lance for technical help on the blog. How do you get rid of the white background when I cut and paste?</p><p>g) Sometimes one of us wants commentary on a blog we are working no- but that is rare. Though I asked Lance for this post and he added a few things to this list.</p><p>h) Sometimes I look at one of his posts before it goes out and offer commentary, or vice versa. Also rare.</p><p>i) Lance writes the end of year posts, but always with my input. We jointly choose the theorem of the year.</p><p>j) The very <a href="https://blog.computationalcomplexity.org/2015/03/leonard-nimoy-1931-2015_2.html">rare</a> <a href="https://blog.computationalcomplexity.org/2017/08/the-crystal-blogaversity.html">joint</a> <a href="https://blog.computationalcomplexity.org/2008/02/wseas-greek-tragedy.html">posts</a>.</p><p>k) If we happen to be in the same place at the same time, like Dagsthul, we'll do a <a href="https://blog.computationalcomplexity.org/search?q=typecast">typecast</a> capturing our conversations. In the past we've also had <a href="https://lance.fortnow.com/blogpodcasts/podcast.xml">podcasts</a> and <a href="https://www.youtube.com/user/fortnow">vidcasts</a> together.</p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2022-01-30T19:50:00Z</updated>
    <published>2022-01-30T19:50:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-07T10:26:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/01/30/fast-iterated-exchange</id>
    <link href="https://11011110.github.io/blog/2022/01/30/fast-iterated-exchange.html" rel="alternate" type="text/html"/>
    <title>Fast iterated exchange transformations via normal curves</title>
    <summary>Soon after I posted my preprint “The Complexity of Iterated Reversible Computation” (arXiv:2112.11607) last month (see previous post “Raytracing diamonds”), Mark Bell emailed me to observe that one of the problems I mentioned in it, iterated integer interval exchange transformations, could be solved in polynomial time by reinterpreting it as a problem on normal curves in triangulated surfaces and plugging in known results from computational topology. Here is a more detailed expansion of that observation.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Soon after I posted my preprint <a href="https://arxiv.org/abs/2112.11607">“The Complexity of Iterated Reversible Computation” (arXiv:2112.11607)</a> last month (see <a href="https://11011110.github.io/blog/2021/12/23/raytracing-diamonds.html">previous post “Raytracing diamonds”</a>), Mark Bell emailed me to observe that one of the problems I mentioned in it, iterated integer interval exchange transformations, could be solved in polynomial time by reinterpreting it as a problem on normal curves in triangulated surfaces and plugging in known results from computational topology. Here is a more detailed expansion of that observation.</p>

<p>First, some terminology, with a picture to help make sense of it:</p>

<p style="text-align: center;"><img alt="Integer interval exchange transformation represented as a normal curve on a triangulated surface" src="https://11011110.github.io/blog/assets/2022/normal-interval-exchange.svg"/></p>

<dl>
  <dt>Interval exchange transformation</dt>
  <dd>An <a href="https://en.wikipedia.org/wiki/Interval_exchange_transformation">interval exchange transformation</a> is a transformation of an interval, obtained by dividing it up into subintervals, permuting the subintervals, and concatenating them back together in the permuted order to obtain the starting interval. They have been widely studied in the theory of dynamical systems. The picture above is derived from an interval exchange transformation on four subintervals \(a\), \(b\), \(c\), and \(d\) (top edge of the rectangle), permuted into the new order \(b\), \(d\), \(c\), \(a\) (bottom edge of the rectangle).</dd>
  <dt>Integer interval exchange transformation</dt>
  <dd>In order to obtain a transformation on a discrete set rather than a continuous interval, we restrict our attention to intervals of the number line, interval exchange transformations that map integers to integers on the number line, and the action of those transformations on the integers. More specifically, we can consider the \(N\) integers from \(0\) to \(N-1\), for some \(N\). The one in the picture has \(N=15\), with the integer positions on the number line shown as vertical blue line segments.</dd>
  <dd>
    <p>An integer interval exchange transformation can be specified by listing the largest integer in each interval, in permuted order: here, this permuted list is \(5, 14, 6, 3\). If there are \(k\) intervals, this specification has bit-length \(O(k\log N)\) and so to achieve polynomial time we will want a time bound that is polynomial in \(k\) and \(\log N\).</p>
  </dd>
  <dt>Iterated interval exchange transformation</dt>
  <dd>Given a number \(n\), a starting value \(x\), and a specified integer interval exchange transformation \(f\), repeatedly apply \(f\), \(n\) times. What is the value \(f^{(n)}(x)\) that results? For instance, the transformation shown takes \(0\to 11\to 6\to 8\to\cdots\), so \(f^3(0)=8\).</dd>
  <dt>Surface</dt>
  <dd>The surfaces I have in mind are compact two-dimensional <a href="https://en.wikipedia.org/wiki/Orientability">oriented manifolds</a> without boundary: topologically like a plane at every point, but globally having a different topology. They can be classified as the sphere, torus, two-handled torus, etc., but we won’t need this classification. The rectangle in the figure can be interpreted as a surface if we glue the pairs of labeled edges together. The left and right sides of the rectangle, when glued together, make a cylinder. The top and bottom edges of the rectangle are glued according to the labeling shown, rather than just wrapping directly from top to bottom.</dd>
  <dt>Triangulated surface</dt>
  <dd>Subdivide the surface into triangles, meeting edge-to-edge, as in the figure. For topological purposes the geometry of the surface is unimportant: all you need to know is the triangles and how they meet edge-to-edge.</dd>
  <dt>Normal curve</dt>
  <dd>A normal curve, on a triangulated surface, is a curve that does not cross itself, does not pass through any triangle vertices, and when entering a triangle on one edge always leaves on a different edge. After gluing the rectangle to form a surface, the blue lines link up to form a normal curve.</dd>
  <dt>Normal arc</dt>
  <dd>A normal curve can have more than one connected component; when it does, a single component is called an arc. The blue normal curve turns out to be an arc: it has only one component.</dd>
  <dt>Normal coordinates</dt>
  <dd>The normal coordinates of a normal curve describe the curve by specifying, for each edge of a topological triangulation, how many times the normal curve crosses each edge. The normal coordinates on the labeled horizontal edges are \(N_a=4\), \(N_b=2\), \(N_c=1\), and \(N_d=8\). The normal coordinates on the vertical edges are all zero; the other edges interior to the rectangle have nonzero normal coordinates, which are just the numbers of times each edge is crossed by the blue curve.</dd>
  <dd>
    <p>Not all assignments of numbers to triangulation edges work. For a triangle with edges \(x\), \(y\), and \(z\), the normal coordinates \(N_x\), \(N_y\), and \(N_z\) must obey the <a href="https://en.wikipedia.org/wiki/Triangle_inequality">triangle inequality</a>. You can read off how the curve crosses the triangle from these numbers: it has \((N_x+N_y-N_z)/2\) segments that cross from edge \(x\) to edge \(y\), etc. The triangle inequality ensures that these numbers of segments are all non-negative; additionally, each triangle must have an even sum of coordinates, to make these numbers of segments be integers. A curve topologically equivalent to the given curve can be obtained by placing the given number of tick-marks on each edge and connecting them by non-crossing segments according to this formula.</p>
  </dd>
  <dt>Edge coordinates</dt>
  <dd>The edge coordinate of a point where a normal curve crosses an edge is just its position along the crossings on that edge.</dd>
  <dt>Arc coordinates</dt>
  <dd>The arc coordinate of a point where a normal curve crosses an edge is its position among all of the crossings along the normal curve, in the order they are reached by that curve, after choosing an arbitrary starting point to have coordinate zero.</dd>
</dl>

<p>With all of this as setup, and with the algorithms on normal curves from a paper by Jeff Erickson and Amir Nayyeri, <a href="https://doi.org/10.1007/s00454-013-9515-z">“Tracing Compressed Curves in Triangulated Surfaces”, <em>DCG</em> 2013</a>, the rest is easy:</p>

<ul>
  <li>
    <p>Given an interval exchange transformation, construct a surface in the form depicted: a triangulated rectangle, divided into some number \(s\) of horizontal stripes, with the input intervals to the transformation subdividing the top of the rectangle and the outputs subdividing the bottom. Triangulate it as shown in the figure, so that each vertical line through the rectangle crosses exactly one diagonal per slice, and so that the central horizontal line across the rectangle forms an unsubdivided edge. Each step up or down from this central line allows the number of horizontal subdivisions to double, so it suffices to let \(s=2\lceil\log_2 k\rceil\), producing a triangulation with \(O(k)\) triangles. Glue the left and right sides of the rectangle together, and glue top and bottom according to the labeling from the transformation.</p>
  </li>
  <li>
    <p>Compute the normal coordinates of the normal curve formed by the vertical integer lines in the rectangle. The normal coordinate of any edge is how far apart horizontally its endpoints are within the rectangle.</p>
  </li>
  <li>
    <p>Given the number \(x\) whose iterates we want to compute, let \(p_x\) be the point of the central horizontal line, \(x\) steps from the left. Each iteration of the exchange transformation can be obtained by advancing \(2s\) units upward along the curve, starting from \(p_x\), and wrapping around halfway through from the top of the rectangle to the bottom.</p>
  </li>
  <li>
    <p>Find the normal arc containing \(p_x\) and its normal coordinates (Erickson and Nayyeri, Theorem 6.2). Its length \(X\) (measured as a number of crossings) is just the sum of these normal coordinates.</p>
  </li>
  <li>
    <p>Convert the known edge coordinate of \(p_x\) to an arc coordinate (Erickson and Nayyeri, Theorem 6.3), add \(2ns\) (modulo \(X\)) to this arc coordinate, convert the resulting arc coordinate back into an edge coordinate in its arc (Erickson and Nayyeri, Theorem 6.4), and then back into an edge coordinate in the whole curve. This edge coordinate is the number we want to compute, \(f^{(n)}(x)\).</p>
  </li>
</ul>

<p>The topological subroutines used by this algorithm all take time quadratic in the size of the triangulation and logarithic in the number of crossings of the normal curve, so for the triangulation and normal curve constructed above this time bound is \(O(k^2\log N)\).</p>

<p>(<a href="https://mathstodon.xyz/@11011110/107714613861230488">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2022-01-30T17:34:00Z</updated>
    <published>2022-01-30T17:34:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-02-05T20:49:19Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/011</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/011" rel="alternate" type="text/html"/>
    <title>TR22-011 |  Public-Key Encryption from Continuous LWE | 

	Andrej Bogdanov, 

	Miguel Cueto Noval, 

	Charlotte Hoffmann, 

	Alon Rosen</title>
    <summary>The continuous learning with errors (CLWE) problem was recently introduced by Bruna
et al. (STOC 2021). They showed that its hardness implies infeasibility of learning Gaussian
mixture models, while its tractability implies efficient Discrete Gaussian Sampling and thus
asymptotic improvements in worst-case lattice algorithms. No reduction between CLWE and
LWE is currently known, in either direction.
We propose four public-key encryption schemes based on the hardness of CLWE, with varying
tradeoffs between decryption and security errors, and different discretization techniques. Some
of our schemes are based on hCLWE, a homogeneous variant, which is no easier than CLWE.
Our schemes yield a polynomial-time algorithm for solving hCLWE, and hence also CLWE,
using a Statistical Zero-Knowledge oracle.</summary>
    <updated>2022-01-30T04:10:37Z</updated>
    <published>2022-01-30T04:10:37Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-02-07T12:37:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=19594</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/01/29/bill-gasarch-also-1000/" rel="alternate" type="text/html"/>
    <title>Bill Gasarch Also 1,000</title>
    <summary>Another theory of computing blogging milestone 2016 Gathering For Gardner lecture William Gasarch turned 1,000 earlier this month. Or in October, depending on how you count. That is, he has made 1,000 posts on a theory blog all by himself. Bill is a professor at the University of Maryland Department of Computer Science and is […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Another theory of computing blogging milestone</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p/>
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/01/29/bill-gasarch-also-1000/billgsnip/" rel="attachment wp-att-19596"><img alt="" class="alignright wp-image-19596" height="200" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/01/BillGsnip.jpg?resize=162%2C200&amp;ssl=1" width="162"/>
</a></td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">2016 Gathering For Gardner <a href="https://rjlipton.wpcomstaging.com/feed/www.youtube.com/watch?v=TXJ6fYF9em8">lecture</a></font></td>
</tr>
</tbody>
</table>
<p>
William Gasarch turned 1,000 earlier this month. Or in October, depending on how you count. That is, he has made 1,000 posts on a theory blog all by himself. Bill is a professor at the University of Maryland Department of Computer Science and is one of the leaders in computational complexity theory, computability theory, computational learning theory, and Ramsey theory. </p>
<p>
Today we congratulate Bill on this milestone and convey some of his other work and activities.<br/>
<span id="more-19594"/></p>
<p>
Bill joined as Lance Fortnow’s official partner on the <i>Computational Complexity</i> <a href="https://blog.computationalcomplexity.org">blog</a> in March 2007. His 1,000th from that point was his Jan. 2 <a href="https://blog.computationalcomplexity.org/2022/01/did-betty-white-die-in-2021why-do.html">post</a> about Betty White and boundaries of time. If we count seven posts from two earlier guest-blogger stints when Lance was on vacation, then his 1,000th <i>Computational Complexity</i> post was <a href="https://blog.computationalcomplexity.org/2021/10/squaring-circle-is-mentioned-in-gilbert.html">this</a> last October 24th about some appearances of mathematics in Gilbert and Sullivan operettas.</p>
<p>
As noted <a href="https://www.meersworld.net/2019/02/how-to-filter-blogger-posts-by-authors.html">here</a>, the <em>Blogger</em> platform does not break down post counts by author, only by label, so I (Ken) resorted to grabbing all the text and counting all the “Posted by” lines. By the same count, Lance has 1,850 posts, and there are blocks by other guest posters. </p>
<p>
Other metrics might be interesting: Shall we count equations? theorems? open problems? proofs given in full? conjectures? How about a raw count of numbers used in the posts, apart from words? Anyway, Bill has done a lot more in the public eye than the blog.</p>
<p>
</p><p/><h2> Book Reviews </h2><p/>
<p/><p>
Bill was the book review editor for ACM SIGACT NEWS from 1997 to 2015 before turning the job over to Fred Green, a professor of computer science at Clark University. See Bill’s reviews <a href="https://www.cs.umd.edu/users/gasarch/bookrev/bookrev.html">here</a>. The reviews are wonderful and there are lots of them. He should be thanked many times for the terrific work he did there.</p>
<p>
I (Dick) am happy to say that Bill reviewed three of my books: </p>
<ol>
<li>
People, Problems, and Proofs, by Richard Lipton and Ken Regan. <p/>
</li><li>
The P=NP Question and Gödel’s Lost Letter, by Richard Lipton. <p/>
</li><li>
Ideas that Created the Future: Classic Papers of Computer Science, the <a href="https://www.yumpu.com/en/document/view/65334324/pdf-ideas-that-created-the-future-classic-papers-of-computer-science-full">book</a> edited by Harry Lewis.
</li></ol>
<p>
The last one includes one of my strangest papers: “Social Processes and Proofs of Theorems and Programs,” with Rich DeMillo and Alan Perlis in 1977. Rich and I cherish it because it included Perlis as a co-author. He was special to many of us—especially those from <a href="https://www.cmu.edu">CMU</a>. We always will miss him. </p>
<p>
</p><p/><h2> New Book and Numbers </h2><p/>
<p/><p>
Let’s look at Bill’s <a href="https://www.cs.umd.edu/users/gasarch/">personal</a> page. He highlights his wonderful newest <a href="https://www.amazon.com/Mathematical-Muffin-Morsels-Problem-Mathematics/dp/9811215170">book</a> <i>Mathematical Muffin Morsels: Nobody Wants a Small Piece</i>. It is joint with Erik Metz, Jacob Prinz, and Daniel Smolyak, who were undergraduate students in Bill’s group, and features contributions by numerous others.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/01/29/bill-gasarch-also-1000/book-7/" rel="attachment wp-att-19598"><img alt="" class="aligncenter size-full wp-image-19598" height="283" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/01/book.png?resize=178%2C283&amp;ssl=1" width="178"/></a></p>
<p>
A summary: </p>
<blockquote><p><b> </b> <em> Suppose you have five muffins that you want to divide and give to Alice, Bob, and Carol. You want each of them to get <img alt="{5/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%2F3%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>. You could cut each muffin into <img alt="{1/3-1/3-1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3-1%2F3-1%2F3%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/> and give each student five <img alt="{1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>-sized pieces. But Alice objects! She has large hands! She wants everyone to have pieces larger than <img alt="{1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</em></p><em>
<p>
Is there a way to divide five muffins for three students so that everyone gets <img alt="{5/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%2F3%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>, and all pieces are larger than <img alt="{1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>? Spoiler alert: Yes! In fact, there is a division where the smallest piece is <img alt="{5/12}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%2F12%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Is there a better division? Spoiler alert: No.</p>
</em><p><em>
This problem takes us through much mathematics of interest, for example, combinatorics and optimization theory. However, the math is elementary enough for an advanced high school student. </em>
</p></blockquote>
<p/><p>
What supplements the math is the use of accessibly simple computer programs to do numerical experiments. Some can be found on Bill’s <a href="https://www.cs.umd.edu/~gasarch/MUFFINS/muffins.html">Muffin Website</a>. Among news after our June 2018 <a href="https://rjlipton.wpcomstaging.com/2018/06/21/muffins-and-integers/">post</a> on the muffin problem, Richard Chatwin <a href="https://arxiv.org/pdf/1907.08726.pdf">proved</a> that the value <img alt="{f(s,m) =}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28s%2Cm%29+%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> the largest size of the smallest piece—when <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> muffins are divided equally among <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> people—depends only on the ratio <img alt="{m/s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%2Fs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The value <img alt="{f(61,27)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%2861%2C27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> left wide open in the post has been proved to equal <img alt="{41/90}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B41%2F90%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and other bounds have been closed.</p>
<p>
All these sources have tables of what we might—to channel the title of Bill’s other <a href="https://rjlipton.wpcomstaging.com/2019/03/10/problems-with-a-point/">recent</a> <a href="https://www.worldscientific.com/worldscibooks/10.1142/11261">book</a> with Clyde Kruskal—call <em>Numbers With a Point</em>. The point is the insight they give about asymptotic growth and likelihood of conjectures. We note in particular a 2020 <a href="https://www.cs.umd.edu/~gasarch/MUFFINS/MuffinsAnalysis/MuffinsAnalysis.pdf">paper</a> by Smolyak on “The Muffin Problem – Data Analysis of Exceptions” to patterns in the values <img alt="{f(s,m)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28s%2Cm%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. </p>
<p>
</p><p/><h2> More Numbers </h2><p/>
<p/><p>
Bill gave a <a href="https://www.cs.umd.edu/~gasarch/COURSES/858/S20/notes/liptonbday.pdf">talk</a> in our January 17 workshop on “Seeking an Easier Proof of a Weaker Result in Multiparty Communication Complexity.” The topic is a classic setting in which <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> people each have an <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>-bit number on their foreheads, so that all can see everyone else’s number but not their own. The problem is to compute some function or predicate <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of the numbers, such as their whether their sum exceeds or equals a given value <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, while minimizing the total number <img alt="{d_{f,k}(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7Bf%2Ck%7D%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of bits communicated. </p>
<p>
Ashok Chandra, Merrick Furst, and I (Dick) raised these problems in a 1983 <a href="http://www.cs.umd.edu/~gasarch/TOPICS/ramsey/mpp.pdf">paper</a>, which Bill preserves on his site for papers related to Ramsey theory. The trivial way of having one person reveal another’s hidden number giving bound <img alt="{d_{f,k}(n) \leq n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7Bf%2Ck%7D%28n%29+%5Cleq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (plus one or more bits needed for that person to speak the result of <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to all parties). The basic surprising fact is that, as a function of <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> and for the above and other natural predicates <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>, one can do asymptotically much better than <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.</p>
<p>
Bill talked about his own <a href="https://www.cs.umd.edu/~gasarch/papers/multicomm.pdf">paper</a> with Richard Beigel and James Glenn on the exact-<img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> case. It appeared at the MFCS 2006 conference. This paper is really neat because it shows the problem has depth and difficulty and ramifications beyond what I imagined back then. It gives connections to groups and regular expressions, besides refining our original application to branching programs. See also the <a href="https://www.cs.umd.edu/~gasarch/BLOGBOOK/foreheadserious.pdf">update</a> that went with Bill’s talk.</p>
<p>
Even the case of <img alt="{k=3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> people is highly nontrivial. The paper gives a chart tracking the constant in the <img alt="{O}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> for the result giving <img alt="{d_{f,k}(n) = O(\sqrt{n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7Bf%2Ck%7D%28n%29+%3D+O%28%5Csqrt%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> with <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> of order <img alt="{2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. The constant on the closest-known bounding formula seems to stay in the vicinity of <img alt="{\pi}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> (the chart gives its reciprocal), going from <img alt="{47/15 = 3.13...}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B47%2F15+%3D+3.13...%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to <img alt="{48/15 = 3.2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B48%2F15+%3D+3.2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> in the last lines. Is that a coincidence? It relates to the density of sets of integers with no arithmetic progression of length 3, for which see this StackExchange <a href="https://math.stackexchange.com/questions/1250622/largest-subset-with-no-arithmetic-progression">item</a> from last year, and this older <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/3apsurvey.pdf">survey</a> by Bill with Glenn and Kruskal.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Bill is one of the top writers on theory. We owe him some props. Thank you, Bill.</p>
<p/></font></font></div>
    </content>
    <updated>2022-01-29T23:04:04Z</updated>
    <published>2022-01-29T23:04:04Z</published>
    <category term="All Posts"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Teaching"/>
    <category term="1000th post"/>
    <category term="Bill Gasarch"/>
    <category term="blog milestone"/>
    <category term="book reviews"/>
    <category term="muffin puzzle"/>
    <category term="multiparty protocols"/>
    <category term="numbers"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2022-02-07T12:37:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/01/27/open-algorithmic-problems</id>
    <link href="https://11011110.github.io/blog/2022/01/27/open-algorithmic-problems.html" rel="alternate" type="text/html"/>
    <title>Open algorithmic problems from a talk by Alon</title>
    <summary>The UCI mathematics department had a departmental colloquium today given by Noga Alon, titled “The Polynomial Method and its Algorithmic Aspects”. One part of his talk that I found very interesting was a collection of easy-to-state combinatorial problems where the existence of a solution can be proved, but there is no known efficient (polynomial time) algorithm for finding the solution:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The UCI mathematics department had a departmental colloquium today given by Noga Alon, titled “The Polynomial Method and its Algorithmic Aspects”. One part of his talk that I found very interesting was a collection of easy-to-state combinatorial problems where the existence of a solution can be proved, but there is no known efficient (polynomial time) algorithm for finding the solution:</p>

<ul>
  <li>
    <p>Let \(p\) be a prime number, and suppose that we are given two inputs: a sequence \(A=a_1,a_2,\dots a_k\) of elements of \(\mathbb{Z}_p\), of length \(k\lt p\), not necessarily distinct from each other, and a set \(B\), also consisting of \(k\) elements of \(\mathbb{Z}_p\), distinct but not ordered. Can we pair them up by assigning an ordering \(b_1,b_2,\dots\) to the elements of \(B\) so that all of the sums \(a_i+b_i\) are distinct? For instance, if all of the \(A\)’s are equal, then any ordering of the \(B\)’s will work.</p>
  </li>
  <li>
    <p>Let \(G\) be a bipartite graph that has a perfect matching. Assign “non-degrees” to the vertices on one side of the bipartition, numbers that should not be the degree of the vertex. Can we delete some subset of the vertices on the other side, so that in the remaining graph each vertex’s degree is different from its non-degree? For instance, if the non-degrees are all zero, then \(G\) itself will work (it has nonzero degree because it has a perfect matching). If the non-degrees are all non-zero, then we can delete all of the vertices on the other side of the bipartition.</p>
  </li>
  <li>
    <p>Let \(G\) be a planar graph with degree three at every vertex, and suppose also that each edge of \(G\) has a list of three colors available to it. Can we assign colors from these lists to the edges so that each vertex touches edges of three different colors?</p>
  </li>
  <li>
    <p>Let \(C_1\) and \(C_2\) be proper colorings of a large \(d\)-dimensional grid, using \(q\ge d+2\) colors, and let \(S_1\) and \(S_2\) be subsets of the vertices of the grid that are far apart from each other (I am not sure how far this needs to be but it seems to be \(d\pm O(1)\) or maybe \(q\pm O(1)\)). Can we find a proper coloring of the whole grid that blends between the two colorings, agreeing with each \(C_i\) on \(S_i\)? This one comes from a new paper by Alon, Raimundo Briceño, Nishant Chandgotia, Alexander Magazinov, and Yinon Spinka, <a href="https://doi.org/10.1017/S0963548320000395">“Mixing properties of colourings of the \(\mathbb{Z}^d\) lattice”, <em>Combinatorics, Probability and Computing</em> 2021</a>. Fewer colors will not always work.</p>
  </li>
</ul>

<p>In all of these cases, the answer to the existence problem is yes, but we don’t know of an efficient algorithm for finding the structure that is supposed to exist. Instead, Alon proves the existence non-constructively, through a combinatorial <a href="https://en.wikipedia.org/wiki/Hilbert%27s_Nullstellensatz">Nullstellensatz</a> encoding the principle that low-degree polynomials don’t have many roots. For one-variable polynomials of degree \(d\), for instance, there cannot be more than \(d\) values at which the polynomial is zero. But the degree really has to be \(d\), and not merely at most \(d\), because the degree-zero constant-zero polynomial is zero everywhere.</p>

<p>The analogous principle Alon uses for higher numbers of variables is the following: Let \(p\) be a polynomial of degree \(d\) in the variables \(x_1,x_2,\dots x_n\), over some field, and let \(t_i\) be the exponents of a nonzero monomial \(\prod_i x_i^{t_i}\) of degree \(d\) in \(p\). Additionally, let \(S_i\) be (not necessarily distinct) sets of \(t_i+1\) elements. Then we can choose an element \(s_i\) in each \(S_i\) such that \(p(s_1,s_2,\dots)\) is non-zero. Alon surveys this principle and its applications in his paper <a href="https://doi.org/10.1017/S0963548398003411">“Combinatorial Nullstellensatz”, <em>Combinatorics, Probability and Computing</em> 1999</a>.</p>

<p>The hard parts about using this method to prove existence in combinatorial problems such as the ones above are finding the right polynomial and proving that it has a nonzero coefficient at the right monomial. The problem on reordering with distinct pairwise sums, for instance, comes from Alon’s paper <a href="https://doi.org/10.1007/BF02773567">“Additive Latin transversals”, <em>Israel J. Math.</em> 2000</a> and uses the polynomial</p>

\[\prod_{i\lt j}(x_i-x_j)(a_i+x_i-a_j-x_j)\]

<p>where each \(S_i=B\), the first terms in the product can only be nonzero if each \(x_i\) is chosen to be a distinct member of \(B\), and the second terms in the product can only be nonzero if the pairwise sums are different from each other. The coefficient of the monomial \(\prod x_i^{k-1}\) turns out to be (up to sign) exactly \(k!\), which is nonzero modulo \(p\) by the assumptions that \(p\) is prime and \(k\lt p\). The nonzero coefficients for the other two problems are not so easy to compute: they are the <a href="https://en.wikipedia.org/wiki/Permanent_(mathematics)">permanent</a> (number of perfect matchings) and the number of 3-edge-colorings of the given graphs. For the case of 3-edge-colorings, the fact that this number is nonzero is one of the equivalent forms of the 4-color theorem.</p>

<p>The general problem of constructing a nonzero solution to an instance of the combinatorial Nullstellensatz whose polynomial is described by an arithmetic circuit is (according to Alon) as hard as inverting arbitrary one-way permutations, a standard cryptographic primitive. This suggests that a polynomial-time construction algorithm does not exist; if it did exist, it would break a lot of modern cryptography. On the other hand, proving that it does not exist would also prove \(\mathsf{P}\ne\mathsf{NP}\). Despite this relation to standard hard problems, there’s no strong reason for believing that any of the combinatorial problems outlined above is as hard as the general case, so maybe they might still have an efficient algorithm. If so, it would probably translate into an existence proof that is substantially different than the ones we already have for these problems.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/107698894668333119">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2022-01-27T23:08:00Z</updated>
    <published>2022-01-27T23:08:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-02-05T20:49:19Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/synth-data-1/</id>
    <link href="https://differentialprivacy.org/synth-data-1/" rel="alternate" type="text/html"/>
    <title>A simple recipe for private synthetic data generation</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In the <a href="https://differentialprivacy.org/synth-data-0/">last blog post</a>, we covered the potential pitfalls of synthetic data without formal privacy guarantees, and motivated the need for differentially private synthetic data mechanisms.  In this blog post, we will describe the <strong>select-measure-generate</strong> paradigm, which is a simple and effective template for designing synthetic data mechanisms.  The three steps underlying the select-measure-generate paradigm are illustrated and explained below.</p>

<p><img alt="" src="https://differentialprivacy.org/images/select-measure-reconstruct.png"/></p>

<ol>
  <li><strong>Select</strong> a collection of queries to measure — typically low-dimensional marginals.</li>
  <li><strong>Measure</strong> the selected queries privately using a noise-addition mechanism.</li>
  <li><strong>Generate</strong> synthetic data that best explains the noisy measurements.<sup id="fnref:0"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:0" rel="footnote">1</a></sup></li>
</ol>

<p>Mechanisms in this class differ primarily in their methodology for selecting queries and their algorithm for generating synthetic data from noisy measurements.  The focus of this blog post is the final <strong>Generate</strong> step.  Specifically, we will explore different ways in which one can model data distributions for the purpose of generating synthetic data, outlining the qualitative pros and cons of each method. We will then introduce the <strong><a href="https://github.com/ryan112358/private-pgm" target="_blank">Marginal-Based Inference (MBI)</a></strong> repository that provides methods that, given some set of noisy measurements, enables users to generate synthetic data in a generic and scalable way.</p>

<p>Separating the Generate subroutine from the existing synthetic data generation mechanisms greatly simplifies the design space of new differentially private mechanisms.  It allows the mechanism designer to focus on <em>selecting the queries</em> to maximize utility of the synthetic data, rather than <em>how to generate synthetic data</em> that explain the noisy measurements well.  Both are challenging technical problems that require different techniques to solve, and MBI provides principled solutions to the latter problem, while exposing an interface that can be readily adopted by mechanism designers.</p>

<h1 id="the-generate-subproblem-a-unifying-view">The Generate Subproblem: A Unifying View</h1>

<p>In this section we will introduce the main optimization problem that underlies several methods for the Generate subproblem, and provide a high-level overview of how each method attempts to solve this optimization problem. Let \( y = \mathcal{M}(D) \) be the noisy measurements obtained from running a privacy mechanism on a discrete dataset \( D \).  Our goal is to post-process these noise measurements to obtain synthetic data that explains them well.  In particular, we wish to minimize over the space of all <em>datasets</em> for one that maximizes the likelihood of the observations \( y \).<sup id="fnref:1"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:1" rel="footnote">2</a></sup></p>

<p>\[ \hat{D} \in \text{arg} \max_{D \in \mathcal{D}} \log \mathbb{P}[\mathcal{M}(D) = y] \]</p>

<p>This is a high-dimensional discrete optimization problem, and is generally intractable to solve in practice, even in low-dimensional settings.  It is common to consider the relaxed problem that instead optimizes over the set of <em>probability distributions</em> \( \mathcal{S} \):</p>

<p>\[ \hat{P} \in \text{arg} \max_{P \in \mathcal{S}} \log \mathbb{P}[\mathcal{M}(P) = y] \label{eq1} \tag{1} \]</p>

<p>More generally, we can consider any objective function that measures how well \( P \) explains \( y \).  The log-likelihood is a natural choice, although other choices are also possible and used in practice.  In the special-but-common case where the mechanism is an instance of the Gaussian mechanism, we have \( \mathcal{M}(D) = f(D) + \mathcal{N}(0, \sigma^2)^k \) and \( \log \mathbb{P}[\mathcal{M}(P) = y] \propto - || f(P) - y ||_2^2 \).  If \( f \) is a linear function of \( P \), then Problem \ref{eq1} is simply a quadratic program.  In the subsequent subsections, we will describe different approaches to solve or approximately solve Problem \ref{eq1}.</p>

<blockquote>
  <p><strong>Remark 1</strong>: The distribution learned from solving Problem \ref{eq1} will resemble the true data with respect to the statistics measured by \( \mathcal{M} \).  It may or may not accurately preserve other statistics — that is data dependent.</p>
</blockquote>

<blockquote>
  <p><strong>Remark 2</strong>: The most common statistics to measure are <strong>low-dimensional marginals</strong>.  A marginal for a subset of attributes counts the number of records in the dataset that match each setting of possible values. They are appealing statistics to measure because:</p>
  <ul>
    <li>They capture low-dimensional structure common in real world data distributions.</li>
    <li>Each cell in a marginal is a count, a statistic that is fairly robust to noise.</li>
    <li>One individual can only contribute to a single cell of a marginal, so all cells have low sensitivity and can be measured simultaneously with low privacy cost.</li>
  </ul>
</blockquote>

<h3 id="direct">Direct</h3>

<p>We can attempt to solve Problem \ref{eq1} directly by utilizing any algorithm for convex optimization over the probability simplex, such as multiplicative weights.  This method works well in low-dimensional regimes, although quickly becomes intractable for higher-dimensional domains, where it is generally intractable to even enumerate all the entries of a single distribution \( P \), let alone optimize over the space of all distributions.</p>

<p>Until recently, variants of the direct method were the only general-purpose solutions available for this problem, and as a result, many mechanisms struggled to scale to high-dimensional domains.  Recently, several methods have been proposed that attempt to overcome the curse of dimensionality inherent in the direct approach, which scale by imposing additional assumptions on the mechanism \( \mathcal{M} \) and/or by relaxing the optimization problem.  A common theme is to restrict attention to a subset of joint distributions which have tractable representations.     The sections below describe these more scalable methods, including the different (implicit) assumptions each method makes, as well as the consequences of those assumptions.</p>

<h3 id="probabilistic-graphical-models-pgm">Probabilistic Graphical Models (PGM)</h3>

<p>The first method we describe is <a href="https://arxiv.org/abs/1901.09136" target="\_blank">PGM</a>, which was a key component of the first-place solution in the 2018 NIST Differential Privacy <a href="https://www.nist.gov/ctl/pscr/open-innovation-prize-challenges/past-prize-challenges/2018-differential-privacy-synthetic" target="\_blank">Synthetic Data Competition</a> and in both the first and second-place solutions in the follow-up <a href="https://www.nist.gov/ctl/pscr/open-innovation-prize-challenges/current-and-upcoming-prize-challenges/2020-differential" target="\_blank">Temporal Map Competition</a>.</p>

<p>PGM scales by restricting attention to distributions that can be represented as a graphical model \( P_{\theta} \).  The key observation of PGM is that when \( \mathcal{M} \) only depends on \( P \) through its low-dimensional marginals, then one of the optimizers of Problem \ref{eq1} is a graphical model with parameters \( \theta \).  In this case, Problem \ref{eq1} is under-determined and typically has infinitely many solutions.  It turns out that the solution found by PGM has maximum entropy among all solutions to the problem — a very natural way to break ties among equally good solutions. Remarkably, these facts are true for any dataset — they do not require the underlying data to be generated from a graphical model with the same structure <a href="https://arxiv.org/abs/2108.04978" target="\_blank">[MMS21]</a>.</p>

<p>The parameter vector \( \theta \) is often much smaller than \( P \), and we can efficiently optimize it, bypassing the curse of dimensionality in this special case.  The size of \( \theta \) and in turn the complexity of PGM depends on the mechanism \( \mathcal{M} \), and in the worst case is the same as the Direct method.<sup id="fnref:6"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:6" rel="footnote">3</a></sup>  However, in many common cases of practical interest, the complexity of PGM is exponentially better than that of Direct, in which case we can efficiently solve the optimization problem above, finding \( \theta \) and thus a tractable representation of \( \hat{P} \).  The complexity ultimately depends on the size of the junction tree derived from the mechanism \( \mathcal{M} \), and understanding this relationship requires some expertise in graphical models.  However, if we utilize this understanding to design \( \mathcal{M} \), we can avoid this worst-case behavior, as <a href="https://arxiv.org/abs/2108.04978" target="\_blank">MST</a> and <a href="http://vldb.org/pvldb/vol14/p2190-cai.pdf" target="\_blank">PrivMRF</a> do.</p>

<h3 id="relaxed-tabular">Relaxed Tabular</h3>

<p>An alternative approach was proposed in the recent <a href="https://arxiv.org/abs/2103.06641" target="\_blank">RAP</a> paper.  The key idea is to restrict attention to “pseudo-distributions” that can be represented in a relaxed tabular format.  The format is similar to the one-hot encoding of a discrete dataset, although the entries need not be \( 0 \) or \( 1 \), which enables gradient-based optimization to be performed on the cells in this table.  The number of rows is a tunable knob that can be set to trade off expressive capacity with computational efficiency.  With a sufficiently large knob size, the true minimizer of the original problem can be expressed in this way, but there is no guarantee that gradient-based optimization will converge to it because this representation introduces non-convexity.  Moreover, the search space of this method includes “spurious” distributions, so even the global optimum of relaxed problem would not necessarily solve the original problem.<sup id="fnref:9"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:9" rel="footnote">4</a></sup>  Despite these drawbacks, this method appears to work well in practice.</p>

<h3 id="generative-networks">Generative Networks</h3>

<p>Among the iterative methods introduced by <a href="https://arxiv.org/abs/2106.07153" target="\_blank">[LVW21]</a> is GEM (Generative networks with the exponential mechanism), an approach inspired by generative adversarial networks. They propose representing any dataset as mixture of product distributions over attributes in the data domain. They implicitly encode such distributions using a generative neural network with a softmax layer. In concrete terms, given some Gaussian noise \( \mathbf{z} \sim \mathcal{N}(0, I) \), their <strong>Generate</strong> step outputs \( f_\theta(\mathbf{z}) \) where \( f \) is some feedforward neural network parametrized by \( \theta \). \( f_\theta(\mathbf{z}) \) represents a collection of marginal distributions for each individual attribute in the domain, which can be used to directly answer any k-way marginal query. Alternatively, one can sample directly from \( f_\theta(\mathbf{z}) \) if the goal is generate synthetic tabular data.</p>

<p>Note that the size of \( \mathbf{z} \) can be arbitrarily large, meaning that this generative network approach can theoretically be scaled up to capture any distribution \( P \). Moreover, <a href="https://arxiv.org/abs/2106.07153">[LVW21]</a> show that one can achieve strong performance in practical settings even when \( \mathbf{z} \) is small, making such generative network approaches to scale in terms of both computation and memory. Howevever, as is commonly found in deep learning methods, this optimization problem is nonconvex.</p>

<h3 id="local-consistency">Local Consistency</h3>

<p>Finally, <a href="https://arxiv.org/abs/2106.07153" target="\_blank">GUM</a> and <a href="https://arxiv.org/abs/2109.06153" target="\_blank">APPGM</a> do not search over any space of distributions, but instead impose <em>local consistency</em> constraints on the noisy measurements.  These methods relax Problem \ref{eq1} to optimize over the space of pseudo-marginals, rather than distributions.  The pseudo-marginals are required to be internally consistent, but there is no guarantee that there is a distribution which realizes those pseudo-marginals.  As a result, the solution found by these methods need not be feasible in Problem \ref{eq1}.  Nevertheless, we can attempt to generate synthetic data using heuristics to translate these locally consistent pseudo-marginals into synthetic tabular data.  This approach was used by team DPSyn in both NIST competitions.</p>

<h3 id="summary">Summary</h3>

<p>A qualitative comparison between the discussed methods is given in the table below.<sup id="fnref:7"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:7" rel="footnote">5</a></sup></p>

<blockquote>
  <p><strong>Remark 3</strong>: Among the alternatives discussed here, only Direct and PGM can be expected to solve Problem \ref{eq1}.    The alternatives fail to solve Problem \ref{eq1} in general, either from non-convexity, or from introducing spurious distributions to the search space.  This distinguishing feature of PGM comes at a cost: the complexity can be much higher than the alternatives, and in the worst-case, will not be feasible to run.  In such cases, one of the approximations must be used instead.</p>
</blockquote>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td><strong>Direct</strong></td>
      <td><strong>PGM</strong></td>
      <td><strong>Relaxed Tabular</strong></td>
      <td><strong>Generative Networks</strong></td>
      <td><strong>Local Consistency</strong></td>
    </tr>
    <tr>
      <td>Search space includes optimum</td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: green;">Yes</span></td>
    </tr>
    <tr>
      <td>Search space excludes spurious distributions</td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: red;">No</span></td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: red;">No</span></td>
    </tr>
    <tr>
      <td>Convexity preserving</td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: red;">No</span></td>
      <td><span style="color: red;">No</span></td>
      <td><span style="color: green;">Yes</span></td>
    </tr>
    <tr>
      <td>Solves Problem \ref{eq1}</td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: green;">Yes</span></td>
      <td><span style="color: red;">No</span></td>
      <td><span style="color: red;">No</span></td>
      <td><span style="color: red;">No</span></td>
    </tr>
    <tr>
      <td>Factors influencing scalability</td>
      <td><span style="color: red;">Size of Entire Domain</span></td>
      <td><span style="color: orange;">Size of Junction Tree</span></td>
      <td><span style="color: green;">Size of Largest Marginal</span></td>
      <td><span style="color: green;">Size of Largest Marginal</span></td>
      <td><span style="color: green;">Size of Largest Marginal</span></td>
    </tr>
  </tbody>
</table>

<h1 id="generating-synthetic-data-with-mbi">Generating Synthetic Data with MBI</h1>

<p>Now that we have introduced the techniques underlying the Generate step, we will show how to utilize the implementations in the MBI repository to develop end-to-end mechanisms for differentially private synthetic data.</p>

<h2 id="preparing-noisy-measurements">Preparing Noisy Measurements</h2>

<p>The input to any method for Generate is a collection of noisy measurements.  We show below how to prepare these measurements in a format compatible with the methods for Generate implemented in the MBI repository.  The measurements are represented as a list, where each element of the list is a noisy marginal (represented as a numpy array), along with relevant metadata including the attributes in the marginal and the amount of noise used to answer it.  In the code snippet below, the selected marginals are hard-coded, but in general this list can be modified to tailor the synthetic data towards a different set of marginals.</p>

<figure class="highlight"><pre><code class="language-python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">sparse</span>
<span class="kn">from</span> <span class="nn">mbi</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'adult.csv'</span><span class="p">,</span> <span class="s">'adult-domain.json'</span><span class="p">)</span>

<span class="c1"># SELECT the marginals we'd like to measure
</span><span class="n">marginals</span> <span class="o">=</span> <span class="p">[(</span><span class="s">'marital-status'</span><span class="p">,</span> <span class="s">'sex'</span><span class="p">),</span>
             <span class="p">(</span><span class="s">'education-num'</span><span class="p">,</span> <span class="s">'race'</span><span class="p">),</span>
             <span class="p">(</span><span class="s">'sex'</span><span class="p">,</span> <span class="s">'hours-per-week'</span><span class="p">),</span>
             <span class="p">(</span><span class="s">'workclass'</span><span class="p">,),</span>
             <span class="p">(</span><span class="s">'marital-status'</span><span class="p">,</span> <span class="s">'occupation'</span><span class="p">,</span> <span class="s">'income&gt;50K'</span><span class="p">)]</span>

<span class="c1"># MEASURE the marginals and log the noisy answers
</span><span class="n">sigma</span> <span class="o">=</span> <span class="mi">50</span> 
<span class="n">measurements</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">M</span> <span class="ow">in</span> <span class="n">marginals</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">project</span><span class="p">(</span><span class="n">M</span><span class="p">).</span><span class="n">datavector</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">I</span> <span class="o">=</span> <span class="n">sparse</span><span class="p">.</span><span class="n">eye</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
    <span class="n">measurements</span><span class="p">.</span><span class="n">append</span><span class="p">(</span> <span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span> <span class="p">)</span></code></pre></figure>

<p>The above code snippet is a 5-fold composition of Gaussian mechanisms with \( \sigma = 50 \), and hence the entire mechanism is \( \frac{5}{2 \sigma^2} = \frac{1}{1000} \)-zCDP.</p>

<h2 id="generating-synthetic-data-from-measurements">Generating Synthetic Data from Measurements</h2>

<p>Given measurements represented in the format above, we can readily generate synthetic data using one of several methods.  For example, the code snippet below generates synthetic data that approximately matches the noisy measurements:</p>

<figure class="highlight"><pre><code class="language-python"><span class="kn">from</span> <span class="nn">mbi</span> <span class="kn">import</span> <span class="n">FactoredInference</span> <span class="c1"># PGM
</span><span class="kn">from</span> <span class="nn">mbi</span> <span class="kn">import</span> <span class="n">MixtureInference</span>  <span class="c1"># Relaxed Tabular + Softmax
</span><span class="kn">from</span> <span class="nn">mbi</span> <span class="kn">import</span> <span class="n">LocalInference</span>    <span class="c1"># Local Consistency
</span><span class="kn">from</span> <span class="nn">mbi</span> <span class="kn">import</span> <span class="n">PublicInference</span>   <span class="c1"># Not Discussed
</span>
<span class="c1"># GENERATE synthetic data using PGM 
</span><span class="n">engine</span> <span class="o">=</span> <span class="n">FactoredInference</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">domain</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">2500</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">engine</span><span class="p">.</span><span class="n">estimate</span><span class="p">(</span><span class="n">measurements</span><span class="p">)</span>
<span class="n">synth</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">synthetic_data</span><span class="p">()</span></code></pre></figure>

<p>To generate synthetic data, we have to simply instantiate one of the inference engines imported.  In the code snippet above, we use the FactoredInference engine, which corresponds to the PGM method.  The other inference engines share the same interface, and can be used instead if desired.</p>

<blockquote>
  <p><strong>Remark 4</strong>: By utilizing the inference engines implemented in MBI, end-to-end synthetic data mechanisms can be written with remarkably little code.  This simple example required less than 25 lines of code, and <a href="https://github.com/ryan112358/private-pgm/tree/master/mechanisms" target="\_blank">more complex mechanisms</a> can usually be written in a single file with less than 200 lines of code.  As a result, future research can focus on the measurement selection subproblem, and new ideas can more rapidly be evaluated and iterated on.</p>
</blockquote>

<p>We evaluated the quality of the synthetic data generated by measuring the error of the measured marginals.  Interestingly, the synthetic data has lower error than the noisy marginals, with reductions in error up to 30% for the larger marginals, and around 3% for the smaller ones.</p>

<p><img alt="" src="https://differentialprivacy.org/images/smr1.png"/></p>

<blockquote>
  <p><strong>Remark 5:</strong> It is not surprising that the synthetic data enjoys lower error than the noisy marginals.  Problem \ref{eq1} can be seen as a <em>projection problem</em>, and there is substantial theoretical <a href="https://arxiv.org/abs/1212.0297" target="\_blank">[NTZ12]</a> and empirical [<a href="https://dl.acm.org/doi/abs/10.1145/2783258.2783366" target="\_blank">LWK15</a>, <a href="https://systems.cs.columbia.edu/private-systems-class/papers/Abowd2019Census.pdf" target="\_blank">AAGK+19</a>] evidence that solving this problem reduces error.  Intuitively, the benefit arises due to the inconsistencies in the noisy observations that are resolved through the optimization procedure.</p>
</blockquote>

<p>We can also use the synthetic data to estimate marginals we didn’t measure with the Gaussian mechanism.  These estimates may or may not be accurate, it depends on the data and the marginal being estimated.  For example, the error on the (sex, income&gt;50K) marginal is around 0.02, while the error on the (education-num, occupation) marginal is about 0.5.</p>

<p><img alt="" src="https://differentialprivacy.org/images/smr2.png"/></p>
<blockquote>
  <p><strong>Remark 6:</strong> The fact that the synthetic data is not accurate for some marginals is not a limitation of the method used for Generate, but rather an artifact of what marginals were selected.  Thus, it is clear that selecting the right marginals to measure plays a crucial role in the quality of the synthetic data. This is an important open problem that will be the topic of a future blog post.</p>
</blockquote>

<h1 id="coming-up-next">Coming up Next</h1>

<p>In this blog post, we focused on the <strong>Generate</strong> step of the select-measure-generate paradigm.  For the next blog post in this series, we will focus on state-of-the-art approaches to the <strong>Select</strong> sub-problem.  If you have any comments, questions, or remarks, please feel free to share them in the comments section below.  If you would like to try generating synthetic data with MBI, check out this <a href="https://colab.research.google.com/drive/1c8gT5m_GWfQoa_mx8eXh4sPD48Y0z3ML?usp=sharing">jupyter notebook</a> on Google Colab!</p>

<hr/>
<div class="footnotes">
  <ol>
    <li id="fn:0">
      <p>The Generate step is a post-processing of already privatized noisy marginals, and therefore the privacy analysis only needs to reason about the first two steps. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:0">↩</a></p>
    </li>
    <li id="fn:1">
      <p>Here we assume that \( \mathcal{M} \) is a mechanism with a discrete output space.  In practice, this is always the case because any mechanism implemented on a finite computer must have a discrete output space.  For continuous output spaces, interpret the objective function as a log density rather than a log probability. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:1">↩</a></p>
    </li>
    <li id="fn:6">
      <p>For example, this worst-case behavior is realized if <strong>all</strong> 2-way marginals are measured.  While this can be seen as a limitation of PGM, <a href="http://people.seas.harvard.edu/~salil/research/synthetic-Feb2010.pdf">it is known</a> that generating synthetic data that preserves all 2-way marginals is computationally hard in the worst-case. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:6">↩</a></p>
    </li>
    <li id="fn:9">
      <p>This idea was refined into <a href="https://arxiv.org/abs/2106.07153" target="\_blank">RAP<sup>softmax</sup></a> in follow-up-work, which overcomes the latter issue, but does not resolve the non-convexity issue. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:9">↩</a></p>
    </li>
    <li id="fn:7">
      <p>These approximations were all developed concurrently, and systematic empirical comparisons between them (and PGM) have not been done to date.  Some experimental comparisons can be found in <a href="https://arxiv.org/abs/2106.07153" target="\_blank">[LVW21]</a> and <a href="https://arxiv.org/abs/2109.06153">[MPSM21]</a>. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:7">↩</a></p>
    </li>
  </ol>
</div></div>
    </summary>
    <updated>2022-01-27T17:00:00Z</updated>
    <published>2022-01-27T17:00:00Z</published>
    <author>
      <name>Terrance Liu</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2022-02-07T00:47:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/01/27/research-fellow-postdoc-at-national-university-of-singapore-apply-by-july-31-2022/</id>
    <link href="https://cstheory-jobs.org/2022/01/27/research-fellow-postdoc-at-national-university-of-singapore-apply-by-july-31-2022/" rel="alternate" type="text/html"/>
    <title>Research Fellow (Postdoc) at National University of Singapore (apply by July 31, 2022)</title>
    <summary>I (Prashant Nalini Vasudevan) have a postdoctoral position available at the Department of Computer Science at NUS. I am looking for someone who works on the foundations of cryptography, information-theoretic cryptography, and/or related areas of theoretical computer science. See the website below for details, and feel free to email me if you have questions. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I (Prashant Nalini Vasudevan) have a postdoctoral position available at the Department of Computer Science at NUS. I am looking for someone who works on the foundations of cryptography, information-theoretic cryptography, and/or related areas of theoretical computer science. See the website below for details, and feel free to email me if you have questions.</p>
<p>Website: <a href="https://careers.nus.edu.sg/NUS/job/Kent-Ridge-Research-Fellow%2C-Theory-of-Cryptography-Kent/7003544/">https://careers.nus.edu.sg/NUS/job/Kent-Ridge-Research-Fellow%2C-Theory-of-Cryptography-Kent/7003544/</a><br/>
Email: prashant@comp.nus.edu.sg</p></div>
    </content>
    <updated>2022-01-27T09:35:49Z</updated>
    <published>2022-01-27T09:35:49Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-02-07T12:37:43Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://thmatters.wordpress.com/?p=1348</id>
    <link href="https://thmatters.wordpress.com/2022/01/26/theory-fest22-call-for-workshop-proposals/" rel="alternate" type="text/html"/>
    <title>STOC’22: Call for Workshop Proposals</title>
    <summary>The Theory Fest workshops committee is soliciting proposals for workshops. Workshops will be held during the STOC conference week, June 20-24, 2022. The (updated) deadline for submitting proposals is Feb 15, 2022. Details on how to submit a proposal can be found at http://acm-stoc.org/stoc2022/callforworkshops.html.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Theory Fest workshops committee is soliciting proposals for workshops. Workshops will be held during the STOC conference week, June 20-24, 2022. The (updated) deadline for submitting proposals is <strong>Feb 15, 2022</strong>. Details on how to submit a proposal can be found at <a href="http://acm-stoc.org/stoc2022/callforworkshops.html" rel="nofollow">http://acm-stoc.org/stoc2022/callforworkshops.html</a>.</p></div>
    </content>
    <updated>2022-01-26T23:43:17Z</updated>
    <published>2022-01-26T23:43:17Z</published>
    <category term="Deadlines"/>
    <author>
      <name>shuchic</name>
    </author>
    <source>
      <id>https://thmatters.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://thmatters.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://thmatters.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://thmatters.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://thmatters.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theory Matters</title>
      <updated>2022-02-07T12:37:54Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8274979502456032700</id>
    <link href="http://blog.computationalcomplexity.org/feeds/8274979502456032700/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/01/a-failure-to-communicate.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8274979502456032700" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8274979502456032700" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/01/a-failure-to-communicate.html" rel="alternate" type="text/html"/>
    <title>A Failure to Communicate</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The screenwriter Aaron Sorkin wrote an <a href="https://ew.com/movies/aaron-sorkin-column-biopics-being-the-ricardos/">article</a> on prioritizing "Truth over Accuracy". He tells stories from his movies The Social Network and Being the Ricardos, of where he moves away from accuracy to get to the truth of a situation.</p><blockquote><p>My friend and teacher, the late William Goldman, said of his Academy Award-winning screenplay for All the President's Men, "If I'm telling the true story of the fall of the President of the United States, the last thing I'm going to do is make anything up." I understand what he meant in context, but the fact is, as soon as he wrote "FADE IN," he'd committed to making things up. People don't speak in dialogue, and their lives don't play out in a series of scenes that form a narrative. Dramatists do that. They prioritize truth over accuracy. Paintings over photographs.</p></blockquote><p>As scientists we focus on accuracy, as we should in our scientific publications. However being fully accurate can distract from the "truth", the underlying message you want to say, particularly in the title, abstract and introduction of our papers </p><p>Even more so when we promote our research to the public. A science writer once <a href="https://blog.computationalcomplexity.org/2004/04/view-of-science-writer.html">lamented to me</a> that scientists would focus too much on the full accuracy of the science and the names behind it, even though neither serves the reader well.</p><p>Reminds me of the recent Netflix movie <a href="https://www.netflix.com/title/81252357">Don't Look Up</a> satirizes scientists trying to communicate an end-of-the-world event to an untrusting society. I wish it was a better movie but still worth watching just to see Leo DiCaprio and Jennifer Lawrence play scientists frustrated with their ability to communicate a true existential crisis to the government and the general public. </p><p>So how should we as scientists try to frame our messaging to get people onboard, particularly when we say things they don't want to hear? Most importantly, how do scientists regain trust in a world where trust is in short supply. Perhaps we should paint more and photograph less.</p></div>
    </content>
    <updated>2022-01-26T17:49:00Z</updated>
    <published>2022-01-26T17:49:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-02-07T10:26:42Z</updated>
    </source>
  </entry>
</feed>
