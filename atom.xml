<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-05-05T05:40:17Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3524</id>
    <link href="https://agtb.wordpress.com/2021/05/05/netecon-2021/" rel="alternate" type="text/html"/>
    <title>NetEcon 2021</title>
    <summary>NetEcon’21, the 16th Workshop on the Economics of Networks, Systems and Computation, will take place on July 23, 2021. NetEcon’21 is a workshop of EC’21, the 22nd ACM Conference on Economics and Computation, which will be held on July 19-23, 2021, co-located with the 6th World Congress of the Game Theory Society. The aim of NetEcon […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>NetEcon’21,</strong> the 16th Workshop on the Economics of Networks, Systems and Computation, will take place on July 23, 2021. NetEcon’21 is a workshop of EC’21, the 22nd ACM Conference on Economics and Computation, which will be held on July 19-23, 2021, co-located with the 6th World Congress of the Game Theory Society. The aim of NetEcon is to foster discussions on the application of economic and game-theoretic models and principles to address challenges in the development of networks and network-based applications and services.</p>



<p>Details regarding submission rules and dates can be found at <a href="https://netecon21.gametheory.online/" rel="noreferrer noopener" target="_blank">https://netecon21.gametheory.online/</a>. A novelty compared with prior editions of the workshop is that papers that were already formatted for and submitted to EC’21 or SIGMETRICS’21 may retain this format (for submission) if submitted together with all the reviews (see submission guidelines for details).</p></div>
    </content>
    <updated>2021-05-05T01:12:21Z</updated>
    <published>2021-05-05T01:12:21Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Kevin Leyton-Brown</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2021-05-05T05:37:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/064</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/064" rel="alternate" type="text/html"/>
    <title>TR21-064 |  Streaming approximation resistance of every ordering CSP | 

	Santhoshini Velusamy, 

	Noah Singer, 

	Madhu Sudan</title>
    <summary>An ordering constraint satisfaction problem (OCSP) is given by a positive integer $k$ and a constraint predicate $\Pi$ mapping permutations on $\{1,\ldots,k\}$ to $\{0,1\}$. Given an instance of OCSP$(\Pi)$ on $n$ variables and $m$ constraints, the goal is to find an ordering of the $n$ variables that maximizes the number of constraints that are satisfied, where a constraint specifies a sequence of $k$ distinct variables and the constraint is satisfied by an ordering on the $n$ variables if the ordering induced on the $k$ variables in the constraint satisfies $\Pi$. Ordering constraint satisfaction problems capture natural problems including ''Maximum acyclic subgraph (MAS)'' and ''Betweenness''. 

In this work we consider the task of approximating the maximum number of satisfiable constraints in the (single-pass) streaming setting, where an instance is presented as a stream of constraints. We show that for every $\Pi$, OCSP$(\Pi)$ is approximation-resistant to $o(\sqrt{n})$-space streaming algorithms, i.e., algorithms using $o(\sqrt{n})$ space cannot distinguish streams where almost every constraint is satisfiable from streams where no ordering beats the random ordering by a noticeable amount. In the case of MAS our result shows that for every $\epsilon&gt;0$, MAS is not $1/2+\epsilon$-approximable. The previous best inapproximability result only ruled out a $3/4$ approximation.

Our results build on a recent work of Chou, Golovnev, Sudan, and Velusamy who show tight inapproximability results for some constraint satisfaction problems over arbitrary (finite) alphabets. We show that the hard instances from this earlier work have the following ''small-set expansion'' property: in every partition of the hypergraph formed by the constraints into small blocks, most of the hyperedges are incident on vertices from distinct blocks. By exploiting this combinatorial property, in combination with a natural reduction from CSPs over large finite alphabets to OCSPs, we give optimal inapproximability results for all OCSPs.</summary>
    <updated>2021-05-04T21:39:50Z</updated>
    <published>2021-05-04T21:39:50Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-05-05T05:37:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.let-all.com/blog/?p=55</id>
    <link href="https://www.let-all.com/blog/2021/05/04/alt-highlights-an-interview-with-the-pc-chairs-of-alt-2021/" rel="alternate" type="text/html"/>
    <title>ALT Highlights – An Interview with the PC Chairs of ALT 2021</title>
    <summary>Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference ALT 2021, including plenary talks, tutorials, trends in learning theory, and more! To reach a broad audience, the series will be disseminated as guest posts on different blogs in machine learning and theoretical computer science. This initiative is organized by […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference <a href="http://algorithmiclearningtheory.org/alt2021/">ALT 2021</a>, including plenary talks, tutorials, trends in learning theory, and more! To reach a broad audience, the series will be disseminated as guest posts on different blogs in machine learning and theoretical computer science. This initiative is organized by the <a href="https://www.let-all.com/">Learning Theory Alliance</a>, and overseen by <a href="http://www.gautamkamath.com/">Gautam Kamath</a>. All posts in ALT Highlights are indexed on the official <a href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/">Learning Theory Alliance blog</a>.</p>



<p>This is the fourth post in the series, an interview with ALT 2021 PC Chairs <a href="http://vtaly.net/">Vitaly Feldman</a> and <a href="http://people.csail.mit.edu/costis/">Katrina Ligett</a>, written by <a href="https://www.comp.nus.edu.sg/~sutanu/">Sutanu Gayen</a> and <a href="https://sites.google.com/view/michal-moshkovitz">Michal Moshkovitz</a>.</p>



<hr class="wp-block-separator"/>



<p>We had the great opportunity to attend <em>The 32nd International Conference on Algorithmic Learning Theory</em>, held online between March 16-19, 2021, and co-chaired by Vitaly Feldman and Katrina Ligett. Vitaly is a research scientist at Apple AI Research and has done foundational works in machine learning and privacy-preserving data analysis. Katrina is an Associate Professor of Computer Science at the Hebrew University of Jerusalem and has done pivotal works in data privacy, algorithmic fairness, algorithmic game theory, and online algorithms. We asked for an interview with them about their experiences and perspectives as co-chairs, to which they kindly agreed. We are happy to share with the readers the excerpts of this interview.</p>



<p class="has-text-align-center"><img src="https://lh4.googleusercontent.com/7RUOfC-v06amphwIhfCYsQNH4jUg82AVsePZcbWO0D40DhSRk-Cf_wnXx9y5RI-qVYz6D-IRAxRzsQ9lWBpraofuggrTYC_sG40GehOCvSrQyZfj1khlMTVqK23NKOZueGcbK_xa" style="width: 225px;"/>           <img height="252" src="https://lh4.googleusercontent.com/lUMmpb6Bcfq3bPljS7jYaF2TFaXRks64--IeslcdR3WzqnCtUETu-ymoOSxm7ys_6eyRFb2mGmd1mCe1boNHdxii0d1_UCthAEJy_eTsWsGQsFKpsV5snZe3Nm9g-QDy0JTnzPKx" width="194"/></p>



<p><strong>How it started</strong></p>



<p>How are chairs and program committees chosen? </p>



<p class="has-text-color" style="color: #0000ff;">Katrina: The chairs are selected by the Association for Algorithmic Learning Theory (AALT) Steering Committee (<a href="http://algorithmiclearningtheory.org/alt-steering-committee/">http://algorithmiclearningtheory.org/alt-steering-committee/</a>), and the chairs then select the program committee members. Vitaly and I brainstormed potential PC member names, solicited additional suggestions, and also considered the lists of people who have served on recent ALT and COLT PCs. In building the PC, we had many considerations in mind, including coverage of research areas, and various metrics of diversity.</p>



<p><strong>The chairs’ role</strong></p>



<p>What are the different tasks a chair has? What is the most difficult task?</p>



<p class="has-text-color" style="color: #0000ff;">Katrina: At a high level, the roles of the PC chairs are to build the PC, oversee the reviewing process and create the conference program. Practically, though, there are a lot of decisions that need to be discussed, emails to be sent, and a lot of organizational aspects to tend to—configuring the reviewing platform, sending reminders, chasing down late reviews, and so on. Vitaly and I have a very, very long joint “to do” list—and luckily, it’s now almost all crossed off! We also had additional responsibilities this year because of the move to the virtual conference format, including selecting the technologies, overseeing the pre-recording process, and much more.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: I think the hardest and probably the most time-consuming is making the accept/reject decisions on papers.  For a large fraction of the papers arriving at the decision requires getting a sense of the results; understanding the main points in reviews, author responses and discussion (while calibrating them to the PC members and reviewers); ensuring that each paper is properly discussed by chasing reviewers, asking questions and often soliciting additional opinions. We also needed to come up with a set of criteria for deciding on borderline cases and make sure that these criteria are applied as consistently as possible. At the end it is a rather long and iterative process that luckily for us has converged to a program we are happy with.</p>



<p>How much time do you spend doing chair tasks? How do you balance chairing a conference (a massive amount of work) with all your other commitments? Do you turn down other service items you would generally accept, etc.?</p>



<p class="has-text-color" style="color: #0000ff;">Katrina: It’s difficult to estimate the number of hours, but I think we have been meeting regularly since early June 2020, and we’re only wrapping up our work now, in late March 2021. It’s a much longer-timeframe commitment than serving as a PC member. I actually am chairing a second conference this year, FORC, and together it makes for a pretty serious load. As a result, I have been declining all other conference-related service. I also have a couple of other pretty substantial service commitments, as well, so I just don’t have bandwidth this year for additional PC and Area Chair-type roles.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: I agree that it’s hard to tell how much time we spent in total. My rough estimate is that it’s about a month of full-time work. I also had to decline most other service commitments during that period some of which I’d normally accept. Naturally, it also slows down other work so I definitely had to lean more on my collaborators in some of the ongoing projects <img alt="&#x1F642;" class="wp-smiley" src="https://s.w.org/images/core/emoji/13.0.1/72x72/1f642.png" style="height: 1em;"/></p>



<p>Can chairs bring their own personality into the conference? How? </p>



<p class="has-text-color" style="color: #0000ff;">Katrina: One area where the chairs enjoy freedom is in selecting the keynote and tutorial speakers. I’m biased, of course, but I think we chose very well, and all of these speakers (Joelle Pineau, Shay Moran, and Costis Daskalakis) gave excellent talks (they were recorded—check them out if you missed them)! We also were fortunate to be able to work with amazing partners who organized the mentoring workshop (Surbhi Goel, Nika Hagtalab, and Ellen Vitercik) and the Women in ML Theory event (Tosca Lechner and Ruth Urner). These aspects of the conference beyond the papers are a way for the chairs to express their priorities.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: The chairs have a lot of freedom in choosing how to run the review process, design the conference program and who else will be involved. So, inevitably, the chairs’ personalities and tastes end up being reflected in the final results. </p>



<p>Does the online conference impact the chair job? How? </p>



<p class="has-text-color" style="color: #0000ff;">Katrina: Typically, the PC chairs build the program, and then many details of organizing and running the conference get handed off to local organization chairs. But this year, since ALT was held virtually, there were many unusual tasks that fell to the PC chairs—not just the obvious ones like choosing the technologies and format and negotiating those contracts, but smaller things like chasing down authors who failed to upload their recordings, and developing instructions for people in various roles to interact with the conference platform.</p>



<p class="has-text-color" style="color: #0000ff;">In addition, COVID times placed strains on many people, which made it more challenging to recruit PC members, and resulted in a higher than usual rate of late reviews and PC drop-outs, which of course left us scrambling.</p>



<p>What motivates you to spend time on a conference service?</p>



<p class="has-text-color" style="color: #0000ff;">Katrina: We all rely on the conference system for our personal professional advancement, and for the advancement of our field as a whole. So we all owe that system our service, of course, according to our abilities, availability, and seniority. Also, it’s fun to get this different perspective on the conference review process and on the field. And it’s an honor to be entrusted with shepherding a conference for a year and hopefully nurturing its growth.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: I agree that it’s a mix of (1) contribution to the community I’m a member of and, perhaps, an opportunity to improve some of its processes (2) a learning experience that gives one a higher-level view of the research that is happening and people who do it (3) honor and recognition that come with the job.</p>



<p><strong>Awards </strong></p>



<p>How do you decide which papers were chosen as awards? </p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: A necessary condition for a paper to receive an award is that at least one of the PC members/reviewers assigned to the paper is excited about the results.  So we start by looking at papers with the highest scores (typically all papers that received at least one “strong accept”) and reading their reviews. This allowed us to narrow down the list to a set of 5-6 candidates. From those we selected the winners by learning more about the results and selecting those, we found the most significant and interesting for the community.</p>



<p><strong>The review process</strong></p>



<p>What are your thoughts about the current peer review process in ALT? What are the downsides and advantages? Do you have suggestions for improvement?</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: It is common that confidence in correctness of the results in a conference submission is based on higher-level sanity checks and general intuition of the reviewers. Naturally, the more interesting and important result the more likely it is to be scrutinized. At this ALT we did not run into a situation where the authors’ reputation affected our confidence in the correctness of the results. In case of concerns about correctness of an interesting result we would ask either an expert on the PC or an external expert to try to verify the result.</p>



<p class="has-luminous-vivid-orange-color has-text-color">ALT currently relies on a traditional theory conference model of reviewing and for a typical submission has several PC members who are experts in the subarea. The reviewing load is also relatively light (8 papers per PC member). So I think that the overall reviewing quality is pretty much as good as it gets in ML (and is similar to COLT). Naturally, the model is not perfect and there is still variation in the quality of individual reviews. This year many more reviewers and PC members were under unusual time pressure due to the pandemic so perhaps the variation was higher than usual.</p>



<p><strong>The future</strong></p>



<p>What are your suggestions for the next chair? </p>



<p class="has-text-color" style="color: #0000ff;">Katrina: Make sure you have a good co-chair. <img alt="&#x1F642;" class="wp-smiley" src="https://s.w.org/images/core/emoji/13.0.1/72x72/1f642.png" style="height: 1em;"/> Vitaly has been a great partner for this process—fun to work with, reliable, always willing to pitch in even on the less-fun tasks, and I have great respect for his technical perspective.</p>



<p class="has-luminous-vivid-orange-color has-text-color">Vitaly: I agree that diversity of perspectives and expertise is useful in several ways. Most notably, it gives the chairs a wider network of people to select the PC from. But I completely agree with Katrina, that the most important thing is the ability of co-chairs to work well together: after all, it’s a lot of work and complicated decisions that need to be made jointly. Here, I couldn’t have asked for more: Katrina is amazing both professionally and personally. Working with her was definitely the highlight of being the ALT co-chair and learned a lot from her in the process as well.</p></div>
    </content>
    <updated>2021-05-04T16:40:08Z</updated>
    <published>2021-05-04T16:40:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Gautam Kamath</name>
    </author>
    <source>
      <id>https://www.let-all.com/blog</id>
      <logo>https://i1.wp.com/www.let-all.com/blog/wp-content/uploads/2021/04/logo.png?fit=32%2C32&amp;ssl=1</logo>
      <link href="https://www.let-all.com/blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://www.let-all.com/blog" rel="alternate" type="text/html"/>
      <title>The Learning Theory Alliance Blog</title>
      <updated>2021-05-05T05:40:17Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=559</id>
    <link href="https://tcsplus.wordpress.com/2021/05/04/tcs-talk-wednesday-may-12-santhoshini-velusamy-harvard-university/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, May 12 — Santhoshini Velusamy, Harvard University</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, May 12th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Santhoshini Velusamy from Harvard University will speak about “Classification of the approximability of all finite Max-CSPs in the dynamic streaming setting” (abstract below). You can reserve a spot […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, May 12th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <a href="https://scholar.harvard.edu/santhoshiniv/home"><strong>Santhoshini Velusamy</strong></a> from Harvard University will speak about “<em>Classification of the approximability of all finite Max-CSPs in the dynamic streaming setting</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards, so people who did not sign up will still be able to watch the talk)</p>
<p>As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: A maximum constraint satisfaction problem, Max-CSP(F), is specified by a finite family of constraints F, where each constraint is of arity k. An instance of the problem on n variables is given by m applications of constraints from F to length-k subsequences of the n variables, and the goal is to find an assignment to the n variables that satisfies the maximum number of constraints. The class of Max-CSP(F) includes optimization problems such as Max-CUT, Max-DICUT, Max-3SAT, Max-q-Coloring, Unique Games, etc.</p>
<p>In this talk, I will present our recent dichotomy theorem on the approximability of Max-CSP(F) for every finite family F, in the single-pass dynamic streaming setting. In this setting, at each time step, a constraint is either added to or deleted from the stream. In the end, the streaming algorithm must estimate the maximum number of constraints that can be satisfied using space that is only polylogarithmic in n. No background in streaming algorithms or constraint satisfaction problems will be needed to enjoy this talk!</p>
<p>The talk will be based on <a href="https://eccc.weizmann.ac.il/report/2021/011/">this paper</a>, and <a href="https://eccc.weizmann.ac.il/report/2021/063/">this paper</a> with Chi-Ning Chou, Alexander Golovnev, and Madhu Sudan.</p></blockquote></div>
    </content>
    <updated>2021-05-04T06:48:59Z</updated>
    <published>2021-05-04T06:48:59Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2021-05-05T05:39:25Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00689</id>
    <link href="http://arxiv.org/abs/2105.00689" rel="alternate" type="text/html"/>
    <title>CSAT and CEQV for nilpotent Maltsev algebras of Fitting length &gt; 2</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kompatscher:Michael.html">Michael Kompatscher</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00689">PDF</a><br/><b>Abstract: </b>The circuit satisfaction problem CSAT(A) of an algebra A is the problem of
deciding whether an equation over A (encoded by two circuits) has a solution or
not. While solving systems of equations over finite algebras is either in P or
NP-complete, no such dichotomy result is known for CSAT(A). In fact, Idziak,
Kawalek and Krzaczkowski constructed examples of nilpotent Maltsev algebras A,
for which, under the assumption of ETH and an open conjecture in circuit
theory, CSAT(A) can be solved in quasipolynomial, but not polynomial time. The
same is true for the circuit equivalence problem CEQV(A).
</p>
<p>In this paper we generalize their result to all nilpotent Maltsev algebras of
Fitting length &gt;2. This not only advances the project of classifying the
complexity of CSAT (and CEQV) for algebras from congruence modular varieties,
but we also believe that the tools we developed are of independent interest in
the study of nilpotent algebras.
</p></div>
    </summary>
    <updated>2021-05-04T22:40:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00656</id>
    <link href="http://arxiv.org/abs/2105.00656" rel="alternate" type="text/html"/>
    <title>A 3D Advancing-Front Delaunay Mesh Refinement Algorithm</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Shankar P Sastry <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00656">PDF</a><br/><b>Abstract: </b>I present a 3D advancing-front mesh refinement algorithm that generates a
constrained Delaunay mesh for any piecewise linear complex (PLC) and extend
this algorithm to produce truly Delaunay meshes for any PLC. First, as in my
recently published 2D algorithm, I split the input line segments such that the
length of the subsegments is asymptotically proportional to the local feature
size (LFS). For each facet, I refine the mesh such that the edge lengths and
the radius of the circumcircle of every triangular element are asymptotically
proportional to the LFS. Finally, I refine the volume mesh to produce a
constrained Delaunay mesh whose tetrahedral elements are well graded and have a
radius-edge ratio less than some $\omega^* &gt; 2/\sqrt{3}$ (except ``near'' small
input angles). I extend this algorithm to generate truly Delaunay meshes by
ensuring that every triangular element on a facet satisfies Gabriel's
condition, i.e., its diametral sphere is empty. On an ``apex'' vertex where
multiple facets intersect, Gabriel's condition is satisfied by a modified
split-on-a-sphere (SOS) technique. On a line where multiple facets intersect,
Gabriel's condition is satisfied by mirroring meshes near the line of
intersection. The SOS technique ensures that the triangles on a facet near the
apex vertex have angles that are proportional to the angular feature size
(AFS), a term I define in the paper. All tetrahedra (except ``near'' small
input angles) are well graded and have a radius-edge ratio less than $\omega^*
&gt; \sqrt{2}$ for a truly Delaunay mesh. The upper bounds for the radius-edge
ratio are an improvement by a factor of $\sqrt{2}$ over current
state-of-the-art algorithms.
</p></div>
    </summary>
    <updated>2021-05-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00639</id>
    <link href="http://arxiv.org/abs/2105.00639" rel="alternate" type="text/html"/>
    <title>Model Counting meets F0 Estimation</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>A. Pavan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vinodchandran:N=_V=.html">N. V. Vinodchandran</a>, Arnab Bhattacharyya, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meel:Kuldeep_S=.html">Kuldeep S. Meel</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00639">PDF</a><br/><b>Abstract: </b>Constraint satisfaction problems (CSP's) and data stream models are two
powerful abstractions to capture a wide variety of problems arising in
different domains of computer science. Developments in the two communities have
mostly occurred independently and with little interaction between them. In this
work, we seek to investigate whether bridging the seeming communication gap
between the two communities may pave the way to richer fundamental insights. To
this end, we focus on two foundational problems: model counting for CSP's and
computation of zeroth frequency moments ($F_0$) for data streams.
</p>
<p>Our investigations lead us to observe striking similarity in the core
techniques employed in the algorithmic frameworks that have evolved separately
for model counting and $F_0$ computation. We design a recipe for translation of
algorithms developed for $F_0$ estimation to that of model counting, resulting
in new algorithms for model counting. We then observe that algorithms in the
context of distributed streaming can be transformed to distributed algorithms
for model counting. We next turn our attention to viewing streaming from the
lens of counting and show that framing $F_0$ estimation as a special case of
#DNF counting allows us to obtain a general recipe for a rich class of
streaming problems, which had been subjected to case-specific analysis in prior
works. In particular, our view yields a state-of-the art algorithm for
multidimensional range efficient $F_0$ estimation with a simpler analysis.
</p></div>
    </summary>
    <updated>2021-05-04T22:47:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00603</id>
    <link href="http://arxiv.org/abs/2105.00603" rel="alternate" type="text/html"/>
    <title>Quantum Advantage with Shallow Circuitsunder Arbitrary Corruption</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Atsuya Hasegawa, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gall:Fran=ccedil=ois_Le.html">François Le Gall</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00603">PDF</a><br/><b>Abstract: </b>Recent works by Bravyi, Gosset and K\"onig (Science 2018), Bene Watts et al.
(STOC 2019), Coudron, Stark and Vidick (QIP 2019) and Le Gall (CCC 2019) have
shown unconditional separations between the computational powers of shallow
(i.e., small-depth) quantum and classical circuits: quantum circuits can solve
in constant depth computational problems that require logarithmic depth to
solve with classical circuits. Using quantum error correction, Bravyi, Gosset,
K\"onig and Tomamichel (Nature Physics 2020) further proved that a similar
separation still persists even if quantum circuits are subject to local
stochastic noise.
</p>
<p>We prove that this quantum advantage persists even if the quantum circuits
can be subject to arbitrary corruption: in this paper we assume that any
constant fraction of the qubits (for instance, huge blocks of qubits) may be
arbitrarily corrupted at the end of the computation. We show that even in this
model, quantum circuits can still solve in constant depth computational
problems that require logarithmic depth to solve with bounded fan-in classical
circuits. This gives another compelling evidence of the computational power of
quantum shallow circuits.
</p>
<p>In order to show our result, we consider the Graph State Sampling problem
(which was also used in prior works) on expander graphs. We exploit the
"robustness" of expander graphs against vertex corruption to show that a
subproblem hard for small-depth classical circuits can still be extracted from
the output of the corrupted quantum circuit.
</p></div>
    </summary>
    <updated>2021-05-04T22:40:20Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00524</id>
    <link href="http://arxiv.org/abs/2105.00524" rel="alternate" type="text/html"/>
    <title>Fast mixing via polymers for random graphs with unbounded degree</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galanis:Andreas.html">Andreas Galanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldberg:Leslie_Ann.html">Leslie Ann Goldberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stewart:James.html">James Stewart</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00524">PDF</a><br/><b>Abstract: </b>The polymer model framework is a classical tool from statistical mechanics
that has recently been used to obtain approximation algorithms for spin systems
on classes of bounded-degree graphs; examples include the ferromagnetic Potts
model on expanders and on the grid. One of the key ingredients in the analysis
of polymer models is controlling the growth rate of the number of polymers,
which has been typically achieved so far by invoking the bounded-degree
assumption. Nevertheless, this assumption is often restrictive and obstructs
the applicability of the method to more general graphs. For example, sparse
random graphs typically have bounded average degree and good expansion
properties, but they include vertices with unbounded degree, and therefore are
excluded from the current polymer model framework.
</p>
<p>We develop a less restrictive framework for polymer models that relaxes the
standard bounded-degree assumption, by reworking the relevant polymer models
from the edge perspective. The edge perspective allows us to bound the growth
rate of the number of polymers in terms of the total degree of polymers, which
in turn can be related more easily to the expansion properties of the
underlying graph. To apply our methods, we consider random graphs with
unbounded degrees from a fixed degree sequence and obtain approximation
algorithms for the ferromagnetic Potts model, which is a standard benchmark for
polymer models. Our techniques also extend to more general spin systems.
</p></div>
    </summary>
    <updated>2021-05-04T22:44:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00518</id>
    <link href="http://arxiv.org/abs/2105.00518" rel="alternate" type="text/html"/>
    <title>Computing Optimal Persistent Cycles for Levelset Zigzag on Manifold-like Complexes</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dey:Tamal_K=.html">Tamal K. Dey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hou:Tao.html">Tao Hou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00518">PDF</a><br/><b>Abstract: </b>In standard persistent homology, a persistent cycle born and dying with a
persistence interval (bar) associates the bar with a concrete topological
representative, which provides means to effectively navigate back from the
barcode to the topological space. Among the possibly many, optimal persistent
cycles bring forth further information due to having guaranteed quality.
However, topological features usually go through variations in the lifecycle of
a bar which a single persistent cycle may not capture. Hence, for persistent
homology induced from PL functions, we propose levelset persistent cycles
consisting of a sequence of cycles that depict the evolution of homological
features from birth to death. Our definition is based on levelset zigzag
persistence which involves four types of persistence intervals as opposed to
the two types in standard persistence. For each of the four types, we present a
polynomial-time algorithm computing an optimal sequence of levelset persistent
$p$-cycles for the so-called weak $(p+1)$-pseudomanifolds. Given that optimal
cycle problems for homology are NP-hard in general, our results are useful in
practice because weak pseudomanifolds do appear in applications. Our algorithms
draw upon an idea of relating optimal cycles to min-cuts in a graph that we
exploited earlier for standard persistent cycles. Note that levelset zigzag
poses non-trivial challenges for the approach because a sequence of optimal
cycles instead of a single one needs to be computed in this case.
</p></div>
    </summary>
    <updated>2021-05-04T22:52:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00443</id>
    <link href="http://arxiv.org/abs/2105.00443" rel="alternate" type="text/html"/>
    <title>Fixed Point Constructions in Tilings and Cellular Automata</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/T=ouml=rm=auml=:Ilkka.html">Ilkka Törmä</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00443">PDF</a><br/><b>Abstract: </b>The fixed point construction is a method for designing tile sets and cellular
automata with highly nontrivial dynamical and computational properties. It
produces an infinite hierarchy of systems where each layer simulates the next
one. The simulations are implemented entirely by computations of Turing
machines embedded in the tilings or spacetime diagrams. We present an overview
of the construction and list its applications in the literature.
</p></div>
    </summary>
    <updated>2021-05-04T22:41:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00419</id>
    <link href="http://arxiv.org/abs/2105.00419" rel="alternate" type="text/html"/>
    <title>Graph Vulnerability and Robustness: A Survey</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Freitas:Scott.html">Scott Freitas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Diyi.html">Diyi Yang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Srijan.html">Srijan Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tong:Hanghang.html">Hanghang Tong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chau:Duen_Horng.html">Duen Horng Chau</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00419">PDF</a><br/><b>Abstract: </b>The study of network robustness is a critical tool in the characterization
and sense making of complex interconnected systems such as infrastructure,
communication and social networks. While significant research has been
conducted in all of these areas, gaps in the surveying literature still exist.
Answers to key questions are currently scattered across multiple scientific
fields and numerous papers. In this survey, we distill key findings across
numerous domains and provide researchers crucial access to important
information by--(1) summarizing and comparing recent and classical graph
robustness measures; (2) exploring which robustness measures are most
applicable to different categories of networks (e.g., social, infrastructure;
(3) reviewing common network attack strategies, and summarizing which attacks
are most effective across different network topologies; and (4) extensive
discussion on selecting defense techniques to mitigate attacks across a variety
of networks. This survey guides researchers and practitioners in navigating the
expansive field of network robustness, while summarizing answers to key
questions. We conclude by highlighting current research directions and open
problems.
</p></div>
    </summary>
    <updated>2021-05-04T22:48:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00299</id>
    <link href="http://arxiv.org/abs/2105.00299" rel="alternate" type="text/html"/>
    <title>Online Domination: The Value of Getting to Know All your Neighbors</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Hovhannes Harutyunyan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pankratov:Denis.html">Denis Pankratov</a>, Jesse Racicot <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00299">PDF</a><br/><b>Abstract: </b>We study the dominating set problem in an online setting. An algorithm is
required to guarantee competitiveness against an adversary that reveals the
input graph one node at a time. When a node is revealed, the algorithm learns
about the entire neighborhood of the node (including those nodes that have not
yet been revealed). Furthermore, the adversary is required to keep the revealed
portion of the graph connected at all times. We present an algorithm that
achieves 2-competitiveness on trees and prove that this competitive ratio
cannot be improved by any other algorithm. We also present algorithms that
achieve 2.5-competitiveness on cactus graphs, $(t-1)$-competitiveness on
$K_{1,t}$-free graphs, and $\Theta(\sqrt{\Delta})$ for maximum degree $\Delta$
graphs. We show that all of those competitive ratios are tight. Then, we study
several more general classes of graphs, such as threshold, bipartite planar,
and series-parallel graphs, and show that they do not admit competitive
algorithms (that is, when competitive ratio is independent of the input size).
Previously, the dominating set problem was considered in a slightly different
input model, where a vertex is revealed alongside its restricted neighborhood:
those neighbors that are among already revealed vertices. Thus, conceptually,
our results quantify the value of knowing the entire neighborhood at the time a
vertex is revealed as compared to the restricted neighborhood. For instance, it
was known in the restricted neighborhood model that 3-competitiveness is
optimal for trees, whereas knowing the neighbors allows us to improve it to
2-competitiveness.
</p></div>
    </summary>
    <updated>2021-05-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00287</id>
    <link href="http://arxiv.org/abs/2105.00287" rel="alternate" type="text/html"/>
    <title>The complexity of approximating the complex-valued Ising model on bounded degree graphs</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galanis:Andreas.html">Andreas Galanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldberg:Leslie_Ann.html">Leslie Ann Goldberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Herrera=Poyatos:Andr=eacute=s.html">Andrés Herrera-Poyatos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00287">PDF</a><br/><b>Abstract: </b>We study the complexity of approximating the partition function
$Z_{\mathrm{Ising}}(G; \beta)$ of the Ising model in terms of the relation
between the edge interaction~$\beta$ and a parameter~$\Delta$ which is an upper
bound on the maximum degree of the input graph~$G$. Following recent trends in
both statistical physics and algorithmic research, we allow the edge
interaction~$\beta$ to be any complex number. Many recent partition function
results focus on complex parameters, both because of physical relevance and
because of the key role of the complex case in delineating the
tractability/intractability phase transition of the approximation problem.
</p>
<p>In this work we establish both new tractability results and new
intractability results. Our tractability results show that
$Z_{\mathrm{Ising}}(-; \beta)$ has an FPTAS when $\lvert \beta - 1 \rvert /
\lvert \beta + 1 \rvert &lt; \tan(\pi / (4 \Delta - 4))$. The core of the proof is
showing that there are no inputs~$G$ that make the partition function~$0$ when
$\beta$ is in this range. Our result significantly extends the known zero-free
region of the Ising model (and hence the known approximation results).
</p>
<p>Our intractability results show that it is $\mathrm{\#P}$-hard to
multiplicatively approximate the norm and to additively approximate the
argument of $Z_{\mathrm{Ising}}(-; \beta)$ when $\lvert \beta - 1 \rvert /
\lvert \beta + 1 \rvert &gt; 1/ \sqrt{\Delta - 1}$. These are the first results to
show intractability of approximating $Z_{\mathrm{Ising}}(-, \beta)$ on bounded
degree graphs with complex~$\beta$. Moreover, we demonstrate situations in
which zeros imply hardness of approximation in the Ising model.
</p></div>
    </summary>
    <updated>2021-05-04T22:37:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00254</id>
    <link href="http://arxiv.org/abs/2105.00254" rel="alternate" type="text/html"/>
    <title>Perfect Forests in Graphs and Their Extensions</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Gregory Gutin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yeo:Anders.html">Anders Yeo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00254">PDF</a><br/><b>Abstract: </b>Let $G$ be a graph on $n$ vertices. For $i\in \{0,1\}$ and a connected graph
$G$, a spanning forest $F$ of $G$ is called an $i$-perfect forest if every tree
in $F$ is an induced subgraph of $G$ and exactly $i$ vertices of $F$ have even
degree (including zero). A $i$-perfect forest of $G$ is proper if it has no
vertices of degree zero. Scott (2001) showed that every connected graph with
even number of vertices contains a (proper) 0-perfect forest. We prove that one
can find a 0-perfect forest with minimum number of edges in polynomial time,
but it is NP-hard to obtain a 0-perfect forest with maximum number of edges. We
also prove that for a prescribed edge $e$ of $G,$ it is NP-hard to obtain a
0-perfect forest containing $e,$ but we can find a 0-perfect forest not
containing $e$ in polynomial time. It is easy to see that every graph with odd
number of vertices has a 1-perfect forest. It is not the case for proper
1-perfect forests. We give a characterization of when a connected graph has a
proper 1-perfect forest.
</p></div>
    </summary>
    <updated>2021-05-04T22:42:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00111</id>
    <link href="http://arxiv.org/abs/2105.00111" rel="alternate" type="text/html"/>
    <title>On the Hardness of Scheduling With Non-Uniform Communication Delays</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Davies:Sami.html">Sami Davies</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kulkarni:Janardhan.html">Janardhan Kulkarni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rothvoss:Thomas.html">Thomas Rothvoss</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sandeep:Sai.html">Sai Sandeep</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tarnawski:Jakub.html">Jakub Tarnawski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Yihao.html">Yihao Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00111">PDF</a><br/><b>Abstract: </b>In the scheduling with non-uniform communication delay problem, the input is
a set of jobs with precedence constraints. Associated with every precedence
constraint between a pair of jobs is a communication delay, the time duration
the scheduler has to wait between the two jobs if they are scheduled on
different machines. The objective is to assign the jobs to machines to minimize
the makespan of the schedule. Despite being a fundamental problem in theory and
a consequential problem in practice, the approximability of scheduling problems
with communication delays is not very well understood. One of the top ten open
problems in scheduling theory, in the influential list by Schuurman and
Woeginger and its latest update by Bansal, asks if the problem admits a
constant factor approximation algorithm. In this paper, we answer the question
in negative by proving that there is a logarithmic hardness for the problem
under the standard complexity theory assumption that NP-complete problems do
not admit quasi-polynomial time algorithms.
</p>
<p>Our hardness result is obtained using a surprisingly simple reduction from a
problem that we call Unique Machine Precedence constraints Scheduling (UMPS).
We believe that this problem is of central importance in understanding the
hardness of many scheduling problems and conjecture that it is very hard to
approximate. Among other things, our conjecture implies a logarithmic hardness
of related machine scheduling with precedences, a long-standing open problem in
scheduling theory and approximation algorithms.
</p></div>
    </summary>
    <updated>2021-05-04T22:41:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00110</id>
    <link href="http://arxiv.org/abs/2105.00110" rel="alternate" type="text/html"/>
    <title>Triangle Centrality</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Burkhardt:Paul.html">Paul Burkhardt</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00110">PDF</a><br/><b>Abstract: </b>Triangle centrality is introduced for finding important vertices in a graph
based on the concentration of triangles surrounding each vertex. An important
vertex in triangle centrality is at the center of many triangles, and therefore
it may be in many triangles or none at all.
</p>
<p>We give optimal algorithms that compute triangle centrality in $O(m^{3/2})$
time and $O(m+n)$ space. Using fast matrix multiplication it takes
$n^{\omega+o(1)}$ time where $\omega$ is the matrix product exponent.
</p>
<p>On a Concurrent Read Exclusive Write (CREW) Parallel Random Access Memory
(PRAM) machine, we give a near work-optimal algorithm that takes $O(\log n)$
time using $O(m\sqrt{m})$ CREW PRAM processors. In MapReduce, we show it takes
four rounds using $O(m\sqrt{m})$ communication bits, and is therefore optimal.
</p>
<p>We also give a deterministic algorithm to find the triangle neighborhood and
triangle count of each vertex in $O(m\sqrt{m})$ time and $O(m+n)$ space. It can
be also easily be computed in $O(m\bar\delta(G))$ expected time, where
$\bar\delta(G)$ is the average graph degeneracy and is related to the
arboricity. We leave it as an open problem to deterministically compute
triangle neighbors in $O(m\bar\delta(G))$ time and $O(m+n)$ space.
</p>
<p>Our empirical results demonstrate that triangle centrality uniquely
identified central vertices thirty-percent of the time in comparison to five
other well-known centrality measures, while being asymptotically faster to
compute on sparse graphs than all but the most trivial of these other measures.
</p></div>
    </summary>
    <updated>2021-05-04T22:42:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00057</id>
    <link href="http://arxiv.org/abs/2105.00057" rel="alternate" type="text/html"/>
    <title>Speeding up Python-based Lagrangian Fluid-Flow Particle Simulations via Dynamic Collection Data Structures</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kehl:Christian.html">Christian Kehl</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sebille:Erik_van.html">Erik van Sebille</a>, Angus Gibson <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00057">PDF</a><br/><b>Abstract: </b>Array-like collection data structures are widely established in Python's
scientific computing-ecosystem for high-performance computations. The structure
maps well to regular, gridded lattice structures that are common to
computational problems in physics and geosciences. High performance is,
however, only guaranteed for static computations with a fixed computational
domain. We show that for dynamic computations within an actively changing
computational domain, the array-like collections provided by NumPy and its
derivatives are a bottleneck for large computations. In response, we describe
the integration of naturally-dynamic collection data structures (e.g.
double-linked lists) into NumPy simulations and \textit{ctypes}-based
C-bindings. Our benchmarks verify and quantify the performance increase
attributed to the change of the collection data structure. Our application
scenario, a Lagrangian (oceanic) fluid-flow particle simulation within the
\textit{Parcels} framework, demonstrates the speed-up yield in a realistic
setting and demonstrates the novel capabilities that are facilitated by
optimised collection data structures.
</p></div>
    </summary>
    <updated>2021-05-04T22:42:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2105.00017</id>
    <link href="http://arxiv.org/abs/2105.00017" rel="alternate" type="text/html"/>
    <title>Negative 3D gadgets in origami extrusions with a supporting triangle on the back side</title>
    <feedworld_mtime>1620086400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Doi:Mamoru.html">Mamoru Doi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2105.00017">PDF</a><br/><b>Abstract: </b>In our previous two papers, we studied (positive) 3D gadgets in origami
extrusions which create a top face parallel to the ambient paper and two side
faces sharing a ridge with two simple outgoing pleats. Then a natural problem
comes up whether it is possible to construct a `negative' 3D gadget from any
positive one having the same net without changing the outgoing pleats, that is,
to sink the top and two side faces of any positive 3D gadget to the reverse
side without changing the outgoing pleats. Of course, simply sinking the faces
causes a tear of the paper, and thus we have to modify the crease pattern.
There are two known constructions of negative 3D gadgets before ours, but they
do not solve this problem because their outgoing pleats are different from
positive ones. In the present paper we give an affirmative solution to the
above problem. For this purpose, we present three constructions of negative 3D
gadgets with a supporting triangle on the back side, which are based on our
previous ones of positive 3D gadgets. The first two are an extension of those
presented in our previous paper, and the third is new. We prove that our first
and third constructions solve the problem. Our solutions enable us to deal with
positive and negative 3D gadgets on the same basis, so that we can construct
from an origami extrusion constructed with 3D gadgets its negative using the
same pleats if there are no interferences among the 3D gadgets. We also treat
repetition/division of negative 3D gadgets under certain conditions, which
reduces their interferences with others.
</p></div>
    </summary>
    <updated>2021-05-04T22:52:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-05-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2021/05/03/postdoc-at-uc-irvine-apply-by-june-4-2021/</id>
    <link href="https://cstheory-jobs.org/2021/05/03/postdoc-at-uc-irvine-apply-by-june-4-2021/" rel="alternate" type="text/html"/>
    <title>Postdoc at UC Irvine (apply by June 4, 2021)</title>
    <summary>One Post-doctoral position is available under the guidance of Ioannis Panageas. The appointment is for one year and may be renewable if funding permits. Requirement is a Ph.D. in TCS/Theory of ML, or related field. Expertise can be demonstrated by 3 top-tier publications in venues like ICML, NeurIPS, AISTATS, STOC, FOCS, SODA, ICALP, EC. Anticipated […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>One Post-doctoral position is available under the guidance of Ioannis Panageas. The appointment is for one year and may be renewable if funding permits. Requirement is a Ph.D. in TCS/Theory of ML, or related field. Expertise can be demonstrated by 3 top-tier publications in venues like ICML, NeurIPS, AISTATS, STOC, FOCS, SODA, ICALP, EC. Anticipated starting date is October 1 2021 (negotiable).</p>
<p>Website: <a href="https://recruit.ap.uci.edu/JPF06615">https://recruit.ap.uci.edu/JPF06615</a><br/>
Email: ipanagea@ics.uci.edu</p></div>
    </content>
    <updated>2021-05-03T22:59:14Z</updated>
    <published>2021-05-03T22:59:14Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2021-05-05T05:37:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/063</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/063" rel="alternate" type="text/html"/>
    <title>TR21-063 |  Approximability of all finite CSPs in the dynamic streaming setting | 

	Chi-Ning  Chou, 

	Alexander Golovnev, 

	Madhu Sudan, 

	Santhoshini Velusamy</title>
    <summary>A constraint satisfaction problem (CSP), Max-CSP$({\cal F})$, is specified by a finite set of constraints ${\cal F} \subseteq \{[q]^k \to \{0,1\}\}$ for positive integers $q$ and $k$. An instance of the problem on $n$ variables is given by $m$ applications of constraints from ${\cal F}$ to subsequences of the $n$ variables, and the goal is to find an assignment to the variables that satisfies the maximum number of constraints. In the $(\gamma,\beta)$-approximation version of the problem for parameters $0 \leq \beta &lt; \gamma \leq 1$, the goal is to distinguish instances where at least $\gamma$ fraction of the constraints can be satisfied from instances where at most $\beta$ fraction of the constraints can be satisfied. 

In this work we consider the approximability of this problem in the context of streaming algorithms and give a dichotomy result in the dynamic setting, where constraints can be inserted or deleted. Specifically,  for every family ${\cal F}$ and every $\beta &lt; \gamma$,  we show that either the approximation problem is solvable with polylogarithmic space in the dynamic setting, or not solvable with $o(\sqrt{n})$ space. We also establish tight inapproximability results for a broad subclass in the streaming insertion-only setting. Our work builds on, and significantly extends previous work by the authors who consider the special case of Boolean variables ($q=2$), singleton families ($|{\cal F}| = 1$) and where constraints may be placed on variables or their negations. Our framework extends non-trivially the previous work allowing us to appeal to richer norm estimation algorithms to get our algorithmic results. For our negative results we introduce new variants of the communication problems studied in the previous work, build new reductions for these problems, and extend the technical parts of previous works. In particular, previous works used Fourier analysis over the Boolean cube to prove their results and the results seemed particularly tailored to functions on Boolean literals (i.e., with negations). Our techniques surprisingly allow us to get to general $q$-ary CSPs without negations by appealing to the same Fourier analytic starting point over Boolean hypercubes.</summary>
    <updated>2021-05-03T20:10:43Z</updated>
    <published>2021-05-03T20:10:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-05-05T05:37:28Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7474459772601125760</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7474459772601125760/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/05/the-mythical-man-month-hen-day-and-cat.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7474459772601125760" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7474459772601125760" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/05/the-mythical-man-month-hen-day-and-cat.html" rel="alternate" type="text/html"/>
    <title>The Mythical Man-Month, Hen-Day, and Cat-Minute (Fred Brooks Turned 90)</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i> The Mythical Man-Month </i>is a great book which talks about the (obvious in retrospect) fact that putting more people on a project may slow it down. It was by Fred Brooks who turned 90 in April (he is still alive). It's a good read. I actually read it many years ago when I exchanged books with a Software Engineer I was dating- She lent me <i>The Mythical Man Month </i>which I found interesting, and I lent her <i>What is the name of this book by Smullyan </i>which she found amusing. Did this exchange of books help our relationship? We have now been married for many years, though its not clear if we can trace this to the exchange of books OR to the fact that she had KNUTH Volumes 1 and 3, and I had KNUTH Volume 2. </p><p> Fred Brooks: You have my thanks and of course Happy Birthday!</p><p>When I read The Mythical Man-Month  I was reminded of a math problem I heard as a kid: </p><p>If a hen-and-half lays an egg-and-a-half in a day-and-a-half then how many eggs can seven hen lay in seven days? </p><p>My answer: if (3/2) hens lay (3/2) eggs in (3/2) days then that's 2/3 of an egg per hen-day, so the answer is </p><p>49* 2/3 = 32 and 2/3 eggs.</p><p>It did not bother me one whit that (1) you can't have 2/3 of an egg, and (2) Just like adding more people might slow down a project, adding more hens might end up being a bad idea-- especially if they are all crowded into the same chicken-coop and hence don't feel much like laying eggs.</p><p>Who was the first person to note that adding <i>more</i> people or hens might be a bad idea? I do not know, but here is an amusing, yet realistic, article by Mark Twain on what I would call <i>The mythical</i> <i>cat-minute. </i>My advisor Harry Lewis send it to me in the midst of an email exchange about <i>The Mythical</i> <i>Man-Month.</i> He got it from a student of his, Larry Denenberg. Here it is: </p><p><br/></p><p>CATS AND RATS</p><pre>The following piece first appeared in ``The Monthly Packet'' of February
1880 and is reprinted in _The_Magic_of_Lewis_Carroll_, edited by John
Fisher, Bramhall House, 1973.


   If 6 cats kill 6 rats in 6 minutes, how many will be needed to kill
   100 rats in 50 minutes?

   This is a good example of a phenomenon that often occurs in working
   problems in double proportion; the answer looks all right at first, but,
   when we come to test it, we find that, owing to peculiar circumstances in
   the case, the solution is either impossible or else indefinite, and needing
   further data.  The 'peculiar circumstance' here is that fractional cats or
   rats are excluded from consideration, and in consequence of this the
   solution is, as we shall see, indefinite.

   The solution, by the ordinary rules of Double Proportion, is 12 cats.
   [Steps of Carroll's solution, in the notation of his time, omitted.]

   But when we come to trace the history of this sanguinary scene through all
   its horrid details, we find that at the end of 48 minutes 96 rats are dead,
   and that there remain 4 live rats and 2 minutes to kill them in: the
   question is, can this be done?

   Now there are at least *four* different ways in which the original feat,
   of 6 cats killing 6 rats in 6 minutes, may be achieved.  For the sake of
   clearness let us tabulate them:
      A.  All 6 cats are needed to kill a rat; and this they do in one minute,
          the other rats standing meekly by, waiting for their turn.
      B.  3 cats are needed to kill a rat, and they do it in 2 minutes.
      C.  2 cats are needed, and do it in 3 minutes.
      D.  Each cat kills a rat all by itself, and takes 6 minutes to do it.

   In cases A and B it is clear that the 12 cats (who are assumed to come
   quite fresh from their 48 minutes of slaughter) can finish the affair in
   the required time; but, in case C, it can only be done by supposing that 2
   cats could kill two-thirds of a rat in 2 minutes; and in case D, by
   supposing that a cat could kill one-third of a rat in two minutes.  Neither
   supposition is warranted by the data; nor could the fractional rats (even
   if endowed with equal vitality) be fairly assigned to the different cats.
   For my part, if I were a cat in case D, and did not find my claws in good
   working order, I should certainly prefer to have my one-third-rat cut off
   from the tail end.

   In cases C and D, then, it is clear that we must provide extra cat-power.
   In case C *less* than 2 extra cats would be of no use.  If 2 were supplied,
   and if they began killing their 4 rats at the beginning of the time, they
   would finish them in 12 minutes, and have 36 minutes to spare, during which
   they might weep, like Alexander, because there were not 12 more rats to
   kill.  In case D, one extra cat would suffice; it would kill its 4 rats in
   24 minutes, and have 26 minutes to spare, during which it could have killed
   another 4.  But in neither case could any use be made of the last 2
   minutes, except to half-kill rats---a barbarity we need not take into
   consideration.

   To sum up our results.  If the 6 cats kill the 6 rats by method A or B,
   the answer is 12; if by method C, 14; if by method D, 13.

   This, then, is an instance of a solution made `indefinite' by the
   circumstances of the case.  If an instance of the `impossible' be desired,
   take the following: `If a cat can kill a rat in a minute, how many would be
   needed to kill it in the thousandth part of a second?'  The *mathematical*
   answer, of course, is `60,000,' and no doubt less than this would *not*
   suffice; but would 60,000 suffice?  I doubt it very much.  I fancy that at
   least 50,000 of the cats would never even see the rat, or have any idea of
   what was going on.

   Or take this: `If a cat can kill a rat in a minute, how long would it be
   killing 60,000 rats?'  Ah, how long, indeed!  My private opinion is that
   the rats would kill the cat.
</pre><div><br/></div><p><br/></p></div>
    </content>
    <updated>2021-05-02T19:33:00Z</updated>
    <published>2021-05-02T19:33:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-05-03T19:20:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/062</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/062" rel="alternate" type="text/html"/>
    <title>TR21-062 |  Improved Hitting Set for Orbit of ROABPs | 

	Vishwas Bhargava, 

	Sumanta Ghosh</title>
    <summary>The orbit of an $n$-variate polynomial $f(\mathbf{x})$ over a field $\mathbb{F}$ is the set $\{f(A \mathbf{x} +  b)\,\mid\, A\in \mathrm{GL}({n,\mathbb{F}})\mbox{ and }\mathbf{b} \in \mathbb{F}^n\}$, and the orbit of a polynomial class is the union of orbits of all the polynomials in it. In this paper, we give improved constructions of hitting-sets for the orbit of read-once oblivious algebraic branching programs (ROABPs) and a related model. Over field with characteristic zero or greater than $d$, we construct a hitting set of size  $(ndw)^{O(w^2\log n\cdot \min\{w^2, d\log w\})}$  for the orbit of ROABPs in unknown variable order where $d$ is the individual degree and $w$ is the width of ROABPs. We also give hitting set of size $(ndw)^{O(\min\{w^2,d\log w\})}$ for the orbit of polynomials  computed by $w$-width ROABPs in any variable order. Our hitting sets improve upon the results of Saha and Thankey \cite{Saha-Thankey'21} who gave an $(ndw)^{O(d\log w)}$ size hitting set for the orbit of commutative ROABPs (a subclass of \textit{any-order} ROABPs) and $(nw)^{O(w^6\log n)}$ size hitting set for the orbit of multilinear ROABPs. Designing better hitting sets in large individual degree regime, for instance $d&gt;n$, was asked as an open problem by \cite{Saha-Thankey'21} and this work solves it in  small width setting. 

We prove some new rank concentration results by establishing \emph{low-cone concentration} for the polynomials over vector spaces, and they strengthen some previously known \emph{low-support} based rank concentrations shown in \cite{FSS14}. These new low-cone concentration results are crucial in our hitting set construction, and may be of independent interest. To the best of our knowledge, this is the first time when low-cone rank concentration has been used for designing hitting sets.</summary>
    <updated>2021-05-02T07:04:05Z</updated>
    <published>2021-05-02T07:04:05Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-05-05T05:37:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=18674</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/" rel="alternate" type="text/html"/>
    <title>Test of Time</title>
    <summary>Time is the ultimate critic. What future generations think of us and our work ultimately determines our standing or lack of it— Stewart Stafford Bobby Kleinberg just reached out to those of us who post from time to time. He wanted some help in announcing a new STOC Test of Time Award. So today, Ken […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Time is the ultimate critic. What future generations think of us and our work ultimately determines our standing or lack of it— Stewart Stafford</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/bk/" rel="attachment wp-att-18676"><img alt="" class="alignright size-thumbnail wp-image-18676" height="150" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/bk-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
Bobby Kleinberg just reached out to those of us who post from time to time. He wanted some help in announcing a new STOC Test of Time Award. </p>
<p>
So today, Ken and I put this together. </p>
<p>Bobby said: </p>
<blockquote><p><b> </b> <em> As with FOCS, three awards will be given: one for papers from approximately 10 years ago, one for approximately 20 years ago, and one for approximately 30 years ago. The selection committee for this year’s award will be Joe Halpern, Mihalis Yannakakis, and Salil Vadhan. </em>
</p></blockquote>
<p/><p>
I would suggest that one of Bobby’s papers could fit this award: </p>
<p>Group-theoretic algorithms for matrix multiplication <br/>
Henry Cohn, Robert Kleinberg, Balazs Szegedy, Christopher Umans </p>
<p>
Well, I can say that without being out of order <em>here</em> because that paper was in FOCS, not STOC.</p>
<p>
</p><p/><h2> Criteria </h2><p/>
<p>
</p><li>
<i>Area</i>: Opening up a new area of research <p/>
</li><li>
<i>Proof</i>: Introducing new proof techniques <p/>
</li><li>
<i>Use</i>: Solving a problem of lasting importance <p/>
</li><li>
<i>Else</i>: Stimulating advances in other areas of computer science or in other disciplines. <p/>
<p>
Go here for details on how to <a href="https://sigact.org/prizes/stoc_tot.html">nominate</a>. By the way: Another test of Time is that the nominations are due relatively soon—May 24. So if you wish to nominate some paper please act soon. </p>
<p>
Ken notes that the first criterion could also be called <i>Leadership</i>, the second always comes with an element of <i>Surprise</i>, and the last two have aspects of <i>Applicability</i> and <i>Practicality</i>.  Adding those to my terms makes a double acronym <i>APPLAUSE</i>.</p>
<p>
</p><p/><h2> Early Early Years </h2><p/>
<p/><p>
I have been around long enough to fit the a 30++ years category, and Ken almost <a href="https://rjlipton.wpcomstaging.com/2021/04/22/ken-turns-40/">ditto</a>. Here are some opinions on the early days. Those papers with<br/>
<a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/ll/" rel="attachment wp-att-18682"><img alt="" class="alignleft  wp-image-18682" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ll-150x150.png?w=40&amp;ssl=1"/></a><br/>
are an absolute must include—I hope you agree.</p>
<p>
<a href="https://dblp.org/db/conf/stoc/stoc81.html">1981</a>:</p>
<p>
Space-Bounded Probabilistic Turing Machine Complexity Classes Are Closed under Complement <br/>
<i>Use</i>.</p>
<p>
<a href="https://dblp.org/db/conf/stoc/stoc82.html">1982</a>:</p>
<p>
Shafi Goldwasser, Silvio Micali <br/>
Probabilistic Encryption and How to Play Mental Poker Keeping Secret All Partial Information <br/>
<i>Area</i>.</p>
<p>
<a href="https://dl.acm.org/doi/proceedings/10.1145/800061">1983</a>:</p>
<p>
Miklós Ajtai, Janos Komlós, and Endre Szemerédi <br/>
<a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/ll/" rel="attachment wp-att-18682"><img alt="" class="alignleft  wp-image-18682" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ll-150x150.png?w=40&amp;ssl=1"/></a>An <img alt="{0(n \log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%28n+%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> sorting network <br/>
<i>Use</i> and <i>Proof</i>.</p>
<p>
Larry Stockmeyer <br/>
The complexity of approximate counting <br/>
<i>Use</i>.</p>
<p>
<a href="https://dl.acm.org/doi/proceedings/10.1145/800057">1984</a>:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/ll/" rel="attachment wp-att-18682"><img alt="" class="alignleft  wp-image-18682" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ll-150x150.png?w=40&amp;ssl=1"/></a>Les Valiant <br/>
A theory of the learnable <br/>
<i>Area</i> and <i>Else</i>.</p>
<p>
Narendra Karmarkar <br/>
<a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/ll/" rel="attachment wp-att-18682"><img alt="" class="alignleft  wp-image-18682" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ll-150x150.png?w=40&amp;ssl=1"/></a>A new polynomial-time algorithm for linear programming <br/>
<i>Use</i> and <i>Proof</i>.</p>
<p>
Of course, these are my own opinions (with concurrence from Ken) and do not reflect those of organizations we belong to.</p>
<p/><h2> Open Problems </h2><p/>
<p/><p>
Ken thinks that one way not to be asked here about my own papers is to mention one, so here goes:</p>
<p>
<a href="https://dblp.org/db/conf/stoc/stoc80.html">1980</a></p>
<p>
Ravindran Kannan, Richard Lipton <br/>
The Orbit Problem is Decidable <br/>
<i>Proof</i>.  Ken adds: Could also be <i>Surprise</i> because we not only showed decidable but in polynomial time.  But the real test of time here may be whether (despite some technical limitations) it proves useful to the great recent interest in adjacent kinds of orbit problems in <a href="https://rjlipton.wpcomstaging.com/2018/06/06/princeton-is-invariant/">invariant</a> and <a href="https://rjlipton.wpcomstaging.com/2015/07/12/the-long-reach-of-reachability/">reachability</a> theory.</p></li></font></font></div>
    </content>
    <updated>2021-04-30T22:53:16Z</updated>
    <published>2021-04-30T22:53:16Z</published>
    <category term="All Posts"/>
    <category term="News"/>
    <category term="People"/>
    <category term="award"/>
    <category term="Bobby Kleinberg"/>
    <category term="Prize"/>
    <category term="STOC"/>
    <category term="Test of Time"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-05-05T05:37:38Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-27705661.post-3713824207379370168</id>
    <link href="http://processalgebra.blogspot.com/feeds/3713824207379370168/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=27705661&amp;postID=3713824207379370168" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/3713824207379370168" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/27705661/posts/default/3713824207379370168" rel="self" type="application/atom+xml"/>
    <link href="http://processalgebra.blogspot.com/2021/04/polyconc-online-collaboration-to.html" rel="alternate" type="text/html"/>
    <title>PolyConc: Online collaboration to improve on a result on the equational theory of CCS modulo bisimilarity</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The aim of this post is to try and start an online collaboration to improve the solution to a problem in the equational logic of processes that I posed in a <a href="https://www.brics.dk/NS/03/2/BRICS-NS-03-2.pdf" target="_blank">survey paper in 2003</a>, namely    </p><blockquote>  Can one obtain a finite axiomatisation of the parallel composition operator in bisimulation semantics by adding only one binary operator to the signature of (recursion, restriction, and relabelling free) CCS? </blockquote><p>     Valentina Castiglioni, Wan Fokkink, Anna Ingólfsdóttir, Bas Luttik and I published a partial, negative answer to the above question in a <a href="https://doi.org/10.4230/LIPIcs.CSL.2021.8" target="_blank">paper at CSL 2021</a>. (See the <a href="https://arxiv.org/pdf/2010.01943.pdf" target="_blank">arXiv version</a> for details and for the historical context for the above question.) Our solution is based on three simplifying assumptions that are described in detail in Section 3 of the <a href="https://arxiv.org/pdf/2010.01943.pdf" target="_blank">above-mentioned paper</a>. We'd be very interested in hearing whether any member of the research community in process algebra, universal algebra and equational logic can relax or remove any of our simplifying assumptions. In particular, one can start with assumptions 3 and 2. </p><p>We would also welcome any comments and suggestions on whether some version of that problem can be solved using existing results from equational logic and universal algebra. In particular, are there any general results guaranteeing that, under certain conditions, the reduct of a finitely based algebra is also finitely based? Or, conversely, that if some algebra is not finitely based, then so its expansion with a new operator?</p><p>To start with, add any contributions you might have as comments to this post. If ever we make substantial enough progress on the above question, anyone who has played a positive role in extending our results will be a co-author of the resulting paper. </p><p>Let PolyConc begin!<br/></p><p/></div>
    </content>
    <updated>2021-04-30T20:41:00Z</updated>
    <published>2021-04-30T20:41:00Z</published>
    <author>
      <name>Luca Aceto</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/01092671728833265127</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-27705661</id>
      <author>
        <name>Luca Aceto</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/01092671728833265127</uri>
      </author>
      <link href="http://processalgebra.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://processalgebra.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/27705661/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Papers I find interesting---mostly, but not solely, in Process Algebra---, and some fun stuff in Mathematics and Computer Science at large and on general issues related to research, teaching and academic life.</subtitle>
      <title>Process Algebra Diary</title>
      <updated>2021-05-03T15:28:29Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/04/30/linkage</id>
    <link href="https://11011110.github.io/blog/2021/04/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>The EFF on FLoC (\(\mathbb{M}\)), Google’s plan for browsers to aggregate your browsing habits and make them public for ad-personalization. Short summary: it’s a bad idea and if you care about privacy you should switch to a non-Chrome browser. Technical summary: it’s based on k-anonymity, known as inadequate at protecting individual privacy in social networks. If you use Chrome, assume all bad guys on the web can see all your browsing.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.eff.org/deeplinks/2021/03/googles-floc-terrible-idea">The EFF on FLoC</a> (<a href="https://mathstodon.xyz/@11011110/106079326968515725">\(\mathbb{M}\)</a>), Google’s plan for browsers to aggregate your browsing habits and make them public for ad-personalization. Short summary: it’s a bad idea and if you care about privacy you should switch to a non-Chrome browser. Technical summary: it’s based on <a href="https://en.wikipedia.org/wiki/K-anonymity">k-anonymity</a>, known as <a href="https://doi.org/10.1109/CASoN.2010.139">inadequate at protecting individual privacy in social networks</a>. If you use Chrome, assume all bad guys on the web can see all your browsing.</p>
  </li>
  <li>
    <p>Relevant to my recent post on Pick’s theorem: <a href="https://www.youtube.com/watch?v=osF2JhrVHxc">Chris Staecker on the dot planimeter</a> (<a href="https://mathstodon.xyz/@11011110/106090366361151274">\(\mathbb{M}\)</a>), a device for <a href="https://en.wikipedia.org/wiki/Dot_planimeter">approximating area by counting grid points</a>.</p>
  </li>
  <li>
    <p><a href="https://www.peeta.net/">Anamorphic street art by Peeta transforms building shapes into 3d geometric abstractions</a> (<a href="https://mathstodon.xyz/@11011110/106100758800338449">\(\mathbb{M}\)</a>, <a href="https://weburbanist.com/2019/07/12/anamorphic-street-art-new-abstract-murals-by-peeta-pop-off-the-wall/">via</a>).</p>
  </li>
  <li>
    <p><a href="https://lore.kernel.org/linux-nfs/YH+zwQgBBGUJdiVK@unreal/">Students of University of Minnesota assistant professor Kangjie Lu caught allegedly deliberately sending buggy patches to Linux kernel as some kind of breaching experiment</a>, resulting in <a href="https://lore.kernel.org/linux-nfs/YH%2FfM%2FTsbmcZzwnX@kroah.com/">the whole university being banned from Linux kernel development</a> (<a href="https://mathstodon.xyz/@11011110/106104208447478044">\(\mathbb{M}\)</a>, <a href="https://lobste.rs/s/3qgyzp/they_introduce_kernel_bugs_on_purpose">via</a>). They claim to have been declared IRB-exempt but this appears to be a mistake by the IRB. See also <a href="https://cse.umn.edu/cs/statement-cse-linux-kernel-research-april-21-2021">department reaction</a> and <a href="https://www.metafilter.com/191207/How-to-get-your-University-banned-in-1-easy-step">metafilter discussion</a>.</p>
  </li>
  <li>
    <p><a href="https://mastodon.social/@joshmillard/106109652170356976">Josh Millard plays with algorithmically-generated pen-plotter art</a>; <a href="https://www.patreon.com/posts/50677186">more</a>.</p>
  </li>
  <li>
    <p><a href="https://www.flyingcoloursmaths.co.uk/a-pretty-puzzle/">You could prove that the number of integer solutions to \(x^2+xy+y^2=a\) is a multiple of six for positive \(a\) by finding a hidden group structure</a> (<a href="https://mathstodon.xyz/@11011110/106113101236984677">\(\mathbb{M}\)</a>). Or, you could recognize that it’s the norm of the Eisenstein integers under a small change of basis from the usual one and that they have six-fold rotational symmetry.</p>
  </li>
  <li>
    <p><a href="https://www.origamitessellations.com/2018/03/paper-engineering-from-the-bauhaus-josef-albers-to-the-modern-day/">Paper engineering from the Bauhaus</a> and <a href="https://www.origamitessellations.com/2018/04/reverse-engineering-bauhaus-paper-designs-part-two/">reverse-engineering Bauhaus paper designs</a> (<a href="https://mathstodon.xyz/@11011110/106118829181433597">\(\mathbb{M}\)</a>). These designs are more curved kirigami than origami, producing smooth-looking 3d shapes from cut sheets of flat paper.</p>
  </li>
  <li>
    <p><a href="https://www.scientificamerican.com/article/the-art-of-mathematics-in-chalk/">The art of mathematics in chalk</a> (<a href="https://mathstodon.xyz/@11011110/106124866673951925">\(\mathbb{M}\)</a>, <a href="https://whatsonmyblackboard.wordpress.com/">see also</a>). Teaser for the forthcoming book <em>Do Not Erase: Mathematicians and Their Chalkboards</em>, featuring several photographic spreads of chalkboard illustrations and formulas and their explanations. They appear to be mostly set-ups rather than captured from active research, but still pretty and interesting. <a href="https://11011110.github.io/blog/2019/09/30/linkage.html">I linked an earlier post on this in 2019</a> but with fewer photos and no explanations.</p>
  </li>
  <li>
    <p><a href="https://coq.discourse.group/t/renaming-coq/1264">The Coq theorem prover brainstorms a name change</a> (<a href="https://mathstodon.xyz/@11011110/106127971601789143">\(\mathbb{M}\)</a>, <a href="https://www.metafilter.com/191240/Not-every-woman-is-offended-by-this-name-but-enough-people-are">via</a>), after too many women get harrassed for saying they work on Coq.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Tetrad_(geometry_puzzle)">Tetrad puzzle</a> (<a href="https://mathstodon.xyz/@11011110/106136227486814000">\(\mathbb{M}\)</a>). It’s possible to arrange four congruent hexagons so they tile a disk with each pair sharing a length of boundary, but the known pentagons with four pairwise-touching copies leave a hole in the region they tile. Is the hole necessary?</p>
  </li>
  <li>
    <p><a href="https://github.andrewt.net/mercator-rotator/">Mercator Rotator</a> (<a href="https://mastodon.social/@andrewt/105950778379233419">\(\mathbb{M}\)</a>), a tool for drawing Mercator-projection world maps with different viewpoints than the usual one. Set the pole on a place you don’t like to see the map of a world without it.</p>
  </li>
  <li>
    <p><a href="https://mathoverflow.net/q/138752/440">Tetrahedra passing through a hole</a> (<a href="https://mathstodon.xyz/@11011110/106152970915208525">\(\mathbb{M}\)</a>). This is from eight years ago, but was active again recently. The question is: what’s the smallest-area hole in a plane through which you can push a unit tetrahedron? DPKR has a very pretty animated answer, but sadly it’s not optimal: there’s a triangular hole with smaller area \(1/\sqrt{8}\), known <a href="https://doi.org/10.1016/j.comgeo.2011.07.004">minimal for translational motion</a>. The problem for more general motion seems to be still open.</p>
  </li>
  <li>
    <p><a href="http://arxiv.org/abs/1112.4205v2">Lagarias’s survey on the Takagi Function</a> and <a href="https://www.jstor.org/stable/2324028">Mallows’ survey on Conway’s $10,000 sequence</a> (<a href="https://mathstodon.xyz/@11011110/106153079186577081">\(\mathbb{M}\)</a>, <a href="https://mathstodon.xyz/@esoterica/106152848486538030">via</a>, <a href="https://en.wikipedia.org/wiki/Blancmange_curve">see also</a>) have very similar-looking figures, but little or no overlap in references. Maybe someone knows of an explanation for the similarity?</p>
  </li>
</ul></div>
    </content>
    <updated>2021-04-30T17:00:00Z</updated>
    <published>2021-04-30T17:00:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-05-01T00:37:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8108</id>
    <link href="https://windowsontheory.org/2021/04/30/alt-highlights-equilibrium-computation-and-the-foundations-of-deep-learning/" rel="alternate" type="text/html"/>
    <title>ALT Highlights – Equilibrium Computation and the Foundations of Deep Learning</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">[Guest post by Kush Bhatia and Cyrus Rashtchian, foreword by Gautam Kamath] Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference ALT 2021, including plenary talks, tutorials, trends in learning theory, and more! To reach a broad audience, the series will be disseminated as guest posts on different blogs … <a class="more-link" href="https://windowsontheory.org/2021/04/30/alt-highlights-equilibrium-computation-and-the-foundations-of-deep-learning/">Continue reading <span class="screen-reader-text">ALT Highlights – Equilibrium Computation and the Foundations of Deep Learning</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>[Guest post by Kush Bhatia and Cyrus Rashtchian, foreword by Gautam Kamath]</p>



<p>Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference <a href="http://algorithmiclearningtheory.org/alt2021/">ALT 2021</a>, including plenary talks, tutorials, trends in learning theory, and more! To reach a broad audience, the series will be disseminated as guest posts on different blogs in machine learning and theoretical computer science. Boaz has kindly agreed to host a post in this series. This initiative is organized by the <a href="https://www.let-all.com/">Learning Theory Alliance</a>, and overseen by <a href="http://www.gautamkamath.com/">Gautam Kamath</a>. All posts in ALT Highlights are indexed on the official <a href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/">Learning Theory Alliance blog</a>.</p>



<p>This is the third post in the series, an interview with <a href="http://people.csail.mit.edu/costis/">Constantinos Daskalakis</a> and coverage of his ALT 2021 <a href="https://www.youtube.com/watch?v=GpaCWKlOMig">keynote talk</a>, written by <a href="https://people.eecs.berkeley.edu/~kush/">Kush Bhatia</a> and <a href="https://sites.google.com/site/cyrusrashtchian/">Cyrus Rashtchian</a>.</p>



<hr class="wp-block-separator"/>



<p>To make a decision for ourselves, we need to think about the impact of our actions to our objectives. But, when our actions affect other people and their actions affect our objectives, we also need to consider their incentives, and choose our actions in anticipation of theirs. This increase in complexity also occurs in situations involving multiple decision-making machines (e.g., self-driving cars), automated systems (e.g., algorithmic stock trading), or living organisms (e.g., groups of cells).</p>



<p>Studying decision-making in so-called multi-agent environments has been a question of interest to mathematicians and economists for centuries. In the 1830s, Antoine Augustin Cournot developed a theory of competition to model oligopolies, inspired by observing competition in a spring water duopoly. Jumping forward to the 20th century, researchers converged that a fruitful approach to analyzing multi-agent systems is studying them at “equilibrium”, that is, in situations where the system is stable in the sense that all parties are satisfied with their actions. A fundamental concept of equilibrium, studied by John von Neumann, and later by von Neumann and Oskar Morgenstern is a collection of actions, one per agent, such that no agent has an incentive to deviate from their choice given the actions of the other agents. While a nice proposal, they could only show that such equilibrium is guaranteed to exist in situations conforming to what is called a “two-player zero-sum game”. In such games, two agents are in exact competition with each other; whatever one player wins the other loses.<sup><a href="https://windowsontheory.org/feed/#fn1">1</a></sup> In 1950, John F. Nash showed that this notion of equilibrium, named Nash equilibrium in his honor, indeed exists for most naturally occurring multi-agent problems.<sup><a href="https://windowsontheory.org/feed/#fn2">2</a></sup></p>



<p>While Nash established the existence of equilibrium, one question bothered economists and computer scientists alike: “<em>Is it possible to efficiently find the Nash equilibrium of a game</em>?”</p>



<p>Throughout the rest of the 20th century, many people proposed algorithms for computing Nash equilibrium, but none of them succeeded in showing that it can be done efficiently (i.e., in polynomial time in the size of the game). During his early graduate school days at UC Berkeley, Constantinos (a.k.a. Costis) Daskalakis obsessed over this question. Then, in 2006, Costis, along with co-authors Paul Goldberg and Christos Papadimitriou, who was also his PhD advisor, showed a surprising result: finding a Nash equilibrium is computationally intractable!</p>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-311" src="https://kamathematics.files.wordpress.com/2021/04/fig1-1.png?w=643"/><strong>Figure 1.</strong> Utility functions encode the value an agent gets from a particular decision. (a) In classical Economics and Game Theory literature, these trade off benefits and costs of actions. For e.g., consider an agent deciding on the quantity <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> of basic material to procure while the other agent sets the price <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> per unit of this material. If we let <img alt="g(x)" class="latex" src="https://s0.wp.com/latex.php?latex=g%28x%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> denote the revenue from selling the product produced using <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> units of basic material, where <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a concave function of <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> (capturing diminishing returns), then the overall utility of the agent choosing <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> is <img alt="f(x,y) = g(x) - x \cdot y" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29+%3D+g%28x%29+-+x+%5Ccdot+y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, an overall concave function. (b) Modern multi-agent problems involve agents choosing parameters of deep neural networks. This quickly leads to non-concave agent utilities.</figure>



<p>A central concept in analyzing multi-agent systems is the <em>utility function</em> of each interacting agent. This is  a function that captures the value that the agent derives as a function of their own action as well as those of the other agents. A common assumption is that the utility function of each agent is a concave function of their own action for any collection of actions committed by the others. Concavity often arises when agents trade off benefits and costs from their actions taking into account properties like diminishing returns and risk-aversion (see Figure 1 for an illustration). It is also crucial in guaranteeing that equilibria exist.</p>



<h3>From Game Theory and Economics to Deep Learning</h3>



<p>Recently, Costis has shifted his attention to the more general setting where the underlying utilities can be arbitrary non-concave functions of the agents’ actions. “Earlier, I was interested in the problem of equilibrium computation for its fundamental applications in Game Theory and Economics and its intimate connections to duality theory, topology and complexity theory. As Machine Learning is now moving towards multi-agent learning, studying more general setups arising from nonconcave agent utilities becomes increasingly relevant,” says Costis. He elaborates that the recent success of deep learning methods has largely been in single-agent setups and that the next frontier is to replicate this success in multi-agent settings. It is at this intersection of deep learning and multi-agent learning that non-concave utility functions arise — when actions correspond to setting the parameters of deep neural networks, agent utilities quickly become non-concave in the space of these parameters(see Figure 1).</p>



<p>The focus of Costis’ <a href="https://www.youtube.com/watch?v=GpaCWKlOMig" rel="noreferrer noopener" target="_blank">keynote talk</a>, on joint work with Stratis Skoulakis and Manolis Zampetakis [<a href="https://windowsontheory.org/feed/#DSZ21">DSZ21</a>] was on the simplest multi-agent problem: two-player zero-sum games. In these games, two players, the <em>min</em> and the <em>max</em> player, choose actions <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> respectively, which are constrained to lie in some compact and convex set <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, i.e., <img alt="(x,y) \in S" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29+%5Cin+S&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. The agents share some objective function <img alt="f(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> that <em>min</em> wants to minimize and <em>max</em> wants to maximize. Classical studies, going back to von Neumann’s celebrated work [<a href="https://windowsontheory.org/feed/#vN28">vN28</a>] focus on when this objective is a convex function of the <em>min</em> player’s action and a concave function of the <em>max</em> player’s action, the so-called “convex-concave setting”. For any function <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> which is convex-concave, there exists a Nash equilibrium, i.e., a point <img alt="(x^*, y^*)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%5E%2A%2C+y%5E%2A%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> satisfying</p>



<p class="has-text-align-center" id="eq-nash"><img alt="f(x^*, y) \leq f(x^*, y^*) \leq f(x, y^*) \quad \text{for all}\; x, y \text{ such that } (x, y^*), (x^*, y) \in S.\qquad (1)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%5E%2A%2C+y%29+%5Cleq+f%28x%5E%2A%2C+y%5E%2A%29+%5Cleq+f%28x%2C+y%5E%2A%29+%5Cquad+%5Ctext%7Bfor+all%7D%5C%3B+x%2C+y+%5Ctext%7B+such+that+%7D+%28x%2C+y%5E%2A%29%2C+%28x%5E%2A%2C+y%29+%5Cin+S.%5Cqquad+%281%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Thus the <em>min</em> (<em>max</em>) player has no incentive to deviate from <img alt="x^* (y^*)" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%2A+%28y%5E%2A%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> as long as the other player remains fixed. The existence of such <img alt="(x^*, y^*)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%5E%2A%2C+y%5E%2A%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> follows from von Neumann’s minimax theorem and Rosen’s generalization of this theorem to the case that agents actions are jointly constrained [<a href="https://windowsontheory.org/feed/#Ros65">Ros65</a>]. However, when <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> is not convex-concave, the minimax theorem fails, and we lose the existence of Nash equilibrium. For a simple example, consider <img alt="f(x,y) = (x-y)^2" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29+%3D+%28x-y%29%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> over the space <img alt="S=[0,1]^2" class="latex" src="https://s0.wp.com/latex.php?latex=S%3D%5B0%2C1%5D%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Given any decision choice <img alt="(x, y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2C+y%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> if <img alt="x\neq y" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cneq+y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the <em>min</em> player should move <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> towards <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Otherwise, if <img alt="x = y" class="latex" src="https://s0.wp.com/latex.php?latex=x+%3D+y&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the <em>max</em> player wants to move away from <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Thus, no pair <img alt="(x^*, y^*)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%5E%2A%2C+y%5E%2A%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> satisfies equation <a href="https://windowsontheory.org/feed/#eq-nash">(1)</a>.</p>



<p>Nonconvex-nonconcave utility functions naturally arise in adversarial training applications, such as Generative Adversarial Network (GAN) training, where the goal is to learn how to generate new data, such as images, from the same distribution that generated a collection of given data. Specifically, GANs are trained by trying to identify the equilibrium of a two-player zero-sum game between a generator model (the <em>min</em> player) and a discriminator model (the <em>max</em> player). Each of these models are viewed as agents, choosing parameters in deep neural networks, and the objective, capturing how close the generated distribution is to the target distribution, amounts to a nonconvex-nonconcave function of the underlying network parameters, which the <em>min</em> player aims to minimize and the <em>max</em> player aims to maximize.</p>



<p>Given that Nash equilibria may not exist when the objective is not convex-concave, what type of solutions should we target when studying two player zero-sum games with such objectives? “One property that we would like our target solutions to possess is that they are universal, i.e. they are guaranteed to exist for any objective function. We can take them to a practitioner and tell them that they are always plausible targets for their computations,” says Costis. With this in mind, Costis and his co-authors consider a relaxed equilibrium concept, called <img alt="(\epsilon, \delta)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C+%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>-Nash equilibrium. This is a pair <img alt="(x^*, y^*)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%5E%2A%2C+y%5E%2A%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> satisfying</p>



<p class="has-text-align-center"><img alt="f(x^*, y^*) &lt; f(x, y^*) + \epsilon \quad \text{for all}\; x \text{ such that } \|x - x^*\| \leq \delta \text{ and } (x,y^*)\in S;" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%5E%2A%2C+y%5E%2A%29+%3C+f%28x%2C+y%5E%2A%29+%2B+%5Cepsilon+%5Cquad+%5Ctext%7Bfor+all%7D%5C%3B+x+%5Ctext%7B+such+that+%7D+%5C%7Cx+-+x%5E%2A%5C%7C+%5Cleq+%5Cdelta+%5Ctext%7B+and+%7D+%28x%2Cy%5E%2A%29%5Cin+S%3B&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/><img alt="f(x^*, y^*) &gt; f(x^*, y) - \epsilon \quad \text{for all}\; y \text{ such that } \|y - y^*\| \leq \delta \text{ and } (x^*,y)\in S." class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%5E%2A%2C+y%5E%2A%29+%3E+f%28x%5E%2A%2C+y%29+-+%5Cepsilon+%5Cquad+%5Ctext%7Bfor+all%7D%5C%3B+y+%5Ctext%7B+such+that+%7D+%5C%7Cy+-+y%5E%2A%5C%7C+%5Cleq+%5Cdelta+%5Ctext%7B+and+%7D+%28x%5E%2A%2Cy%29%5Cin+S.&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>This relaxes Nash equilibrium: given strategy <img alt="y^*" class="latex" src="https://s0.wp.com/latex.php?latex=y%5E%2A&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> for the <em>max</em> player, the <em>min</em> player can improve by at most <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> by changing their action in a ball of radius <img alt="\delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> around <img alt="x^*" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%2A&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and a symmetric condition holds for the <em>max</em> player, given strategy <img alt="x^*" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%2A&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> for the <em>min</em> player. One of the main insights of their paper is that such local Nash equilibria <em>are guaranteed to</em> exist as long as <img alt="\delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a small enough function of <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>’s smoothness, namely whenever <img alt="\delta \le \sqrt{2\epsilon \over L}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cle+%5Csqrt%7B2%5Cepsilon+%5Cover+L%7D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> where <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> is <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>’s smoothness. This non-trivial result is established via an application of Brouwer’s fixed point theorem.</p>



<h3>Can algorithms find a local Nash equilibrium?</h3>



<p>The next question, pertaining to computational complexity, is to determine whether finding an <img alt="(\epsilon, \delta)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C+%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>-Nash equilibrium is algorithmically tractable in the regime of parameters (small enough <img alt="\delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>) where it is guaranteed to exist. As a first step, Costis and his co-authors focus on first-order algorithms, which have access to the gradient of the objective function. Examples include gradient descent and variants thereof, which have been the main computational engine behind the success of deep learning in single-agent problems. A classical result known for these methods in minimization settings is that they are efficient in computing <img alt="(\epsilon,\delta)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>-minima of non-convex, smooth objectives <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. These are points <img alt="x^*" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%2A&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that <img alt="f(x^*) &lt; f(x) + \epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%5E%2A%29+%3C+f%28x%29+%2B+%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> for all feasible <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that <img alt="\|x - x^*\| \leq \delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Cx+-+x%5E%2A%5C%7C+%5Cleq+%5Cdelta&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Namely, given query access to the gradient <img alt="\nabla f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cnabla+f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> of some <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>-smooth objective <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> with values normalized to <img alt="[0,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, it is possible to compute <img alt="(\epsilon,\delta)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>-minima in polynomially many, in <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="1/\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, steps and queries to <img alt="\nabla f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cnabla+f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, as long as <img alt="\delta \le \sqrt{2\epsilon \over L}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cle+%5Csqrt%7B2%5Cepsilon+%5Cover+L%7D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. In contrast to minimization, a main contribution of Costis’ work is to establish an intractability result for min-maximization, showing that the number of gradient queries for any first-order algorithm to compute <img alt="(\epsilon,\delta)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>-Nash equilibria must be exponential in at least one of <img alt="1/\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the dimension <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, or the smoothness <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> of the objective.</p>



<div class="wp-block-group"><div class="wp-block-group__inner-container">
<blockquote class="wp-block-quote"><p>Theorem 1 (informal). First-order methods need a number of queries to <img alt="\nabla f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cnabla+f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> that is exponential in at least one of <img alt="1 /\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=1+%2F%5Cepsilon&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, or the dimension to find <img alt="(\epsilon,\delta)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cepsilon%2C%5Cdelta%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>-Nash equilibria, even when <img alt="\delta \le \sqrt{2\epsilon \over L}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cle+%5Csqrt%7B2%5Cepsilon+%5Cover+L%7D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, i.e. in the regime in which they are guaranteed to exist.</p></blockquote>



<p>This theorem tells us that there exist objective functions for which the min-maximization problem can be computationally intractable for any first-order algorithm. Requiring many queries is one way to say that the problem is hard in practice. Indeed, practitioners have found it notoriously hard to get the discriminator-generator neural networks to converge to good solutions for generative modelling problems using gradient-based methods.</p>



<p>From a technical perspective, this work represents a new approach for proving lower bounds in optimization. Classical lower bounds in the optimization literature, going back to Nemirovsky and Yudin [<a href="https://windowsontheory.org/feed/#NY83">NY83</a>] target the black-box setting: an algorithm is given access to an oracle which outputs some desired information about a function when presented with a query. For example, a first-order oracle outputs the gradient of a function <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> at a given input. Costis shared that he and his co-authors first tried to construct a black-box lower bound for local Nash equilibria directly. However, they were unsuccessful. Any direct construction they tried ended up introducing spurious local Nash equilibria, which first-order algorithms might find in polynomial time. Their direct attempts at a lower bound failed to capture the computational hardness of the problem. They quickly realized that they needed a deeper understanding of the problem at hand, better insight on what made it harder than minimization.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img alt="" class="wp-image-310" height="331" src="https://kamathematics.files.wordpress.com/2021/04/fig2.png?w=1011" width="581"/><strong>Figure 2. </strong>(a) Black-box models work with an oracle which an algorithm queries to obtain information. White-box models provide algorithms access to functions which can compute the desired information. (b) Architecture of black-box intractability results (focus of the optimization literature): first show computational hardness results in the white-box model (focus of computational complexity); then compose those with black-box lower bounds for any problem in the class for which hardness results were established.</figure></div>



<div class="wp-block-group"><div class="wp-block-group__inner-container">
<p>That insight came when they switched to studying the complexity of the white-box version of the problem, wherein the optimization algorithm can look inside the oracle that computes <img alt="\nabla f(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cnabla+f%28x%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> and possibly <img alt="f(x)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> as well. One might wonder why one would want to consider such white-box models over black-box ones if their goal is to prove intractability results for methods that have limited access to <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Indeed, proving an intractability result in the white-box model is much harder because the set of algorithms that use white-box access to the objective is strictly bigger than those using only black-box access. However, the key difference is that we are not looking for the same kind of hardness in the two models. In the black-box model, we are looking for unconditional computational hardness, that is, showing that any algorithm will require exponentially many queries to the gradient oracle. On the other hand, in the white-box model, we would like to show complexity-theoretic hardness, i.e., show that solving the problem at hand is at least as hard (or exactly as hard) as solving the hardest problems in some complexity class. Such a complexity-theoretic hardness result is conditional; it says that solving this problem will be computationally intractable as long as some computational complexity conjecture, such as P <img alt="\neq" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cneq&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> NP, holds. Importantly, showing hardness (or completeness) of a problem in some complexity class typically entails a fine-grained understanding of the nature of the problem and how that enables it to encode other problems in the target complexity class.</p>
</div></div>



<p>In the white-box model, the authors show that the problem of computing local Nash equilibria is PPAD-complete. In other words, computing this local equilibrium concept in zero-sum games with nonconvex-nonconcave objectives is exactly as hard as computing Nash equilibria in general-sum games with concave agent utilities.<sup><a href="https://windowsontheory.org/feed/#fn3">3</a></sup> This result is established by exhibiting a reduction from a variant of the Sperner coloring problem,<sup><a href="https://windowsontheory.org/feed/#fn4">4</a></sup> which is a PPAD-complete problem, to a discrete nonconvex-nonconcave min-maximization problem, where the two agents choose points on a hypergrid.</p>



<h3>Unexpected challenges in high dimensions</h3>



<p>Having established this result, Costis and his coauthors presumed that the hardest part of the problem was behind them. However, another challenge awaited them. They still had to construct a continuous interpolation of their discrete function to satisfy the desired Lipschitz and smoothness properties in a computationally efficient manner. To understand the challenge with this, consider a simple two-dimensional example with two actions per agent. Suppose we are given prescribed values for <img alt="f(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> on all four vertices of <img alt="\{0,1\}^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> and our goal is to construct a continuous and smooth function on <img alt="[0,1]^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>, which matches the prescribed function values at the corners. A simple approach is to define <img alt="f(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> at any point <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> using a smooth interpolation of all four corners of <img alt="\{0,1\}^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>. This works, but does not scale to high dimensions. An approach that would scale computationally in high dimensions is to first triangulate <img alt="[0,1]^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D%5E2&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> by chopping it along its main diagonal and then interpolate the function on each triangle separately. However, this simple approach fails since the gradient of the interpolated function can be discontinuous when crossing the diagonal. “This part turned out to be more technically challenging than we had thought in high dimensions,” says Costis. He and his coauthors overcame the issue by proposing a new <em>smooth and computationally efficient interpolation</em> scheme, which they expect will have more applications in transferring hardness results from discrete problems to continuous problems.</p>



<p>To obtain Theorem 1, the authors show that one can translate their complexity-theoretic hardness in the white-box model to an unconditional intractability result in the black-box model. This follows immediately from their reduction from Sperner to local Nash equilibrium. Indeed, finding local Nash equilibria in the min-max instance at the output of their reduction provides solutions to the Sperner instance at its input. Moreover, a single query (function value or gradient value) to the min-max objective requires <img alt="O(d)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28d%29&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> queries to the Sperner coloring circuit in order to be computed. Finally, it is known that, with black-box queries to the Sperner coloring circuit, exponentially many queries are necessary to compute a solution [<a href="https://windowsontheory.org/feed/#HPV89">HPV89</a>, <a href="https://windowsontheory.org/feed/#Pap94">Pap94</a>]. An exponential black-box lower bound for local Nash equilibrium thus follows.</p>



<p>This proof architecture can be used more generally to prove intractability results for optimization problems involving smooth objectives. First, ignore the black-box model and focus on identifying the complexity class that captures the complexity of the problem in the white-box model. Then, focus on obtaining a hardness result for a discrete version of the problem. Once this is established, one can use the techniques presented in this work to lift this intractability from the discrete to the continuous problem. If there are black-box lower bounds for any problem residing in the complexity class for which the white-box version of the problem is hard, then these lower bounds can be composed with hardness reductions to establish lower bounds for the black-box version of the problem. As an aside, Costis mentions that it would be interesting if one could establish the lower bound of Theorem 1 in the black-box model directly, i.e., without going through the PPAD machinery.</p>



<h3>Looking forward</h3>



<p>Costis ends on an optimistic note: “While this might appear as a negative result, it really is a positive one.” Explaining further, he says that a philosophical consequence of his intractability results is that the multi-agent future of deep learning is going to have a lot of interesting “texture” — it will involve a large breadth of communities and motivate a plethora of problems at the interface of theoretical computer science, game theory, economics and machine learning. Costis envisions a change in balance in the multi-agent world: while recent successes of deep learning in single-agent problems capitalize on access to large data, unprecedented computational power, and effective inductive biases, multi-agent problems will demand much stronger inductive biases, invoking domain expertise in order to develop effective models and useful learning targets, as well as to discover algorithms that attain those targets.</p>



<p>Indeed, domain expertise has been crucial in some recent high-profile machine learning achievements in multi-agent settings: the AlphaGo agent for playing the game of Go and the Libratus agent for playing Texas Hold’em. For these, a game-theoretic understanding has been infused into the structure and training of the learning algorithm. In addition to using deep neural networks, AlphaGo uses a Monte Carlo tree search procedure to determine the best next move as well as to collect data for the training of the neural networks during self play, while Libratus uses counterfactual regret minimization to approximate the equilibrium of the game. The success of both algorithms required combining machine learning expertise with game-theoretic expertise about how to solve the games at hand.</p>



<p>More broadly, Costis urges young researchers to move beyond the classical statistical paradigm which assumes independent and identically distributed observations, and embrace learning challenges that are motivated from learning problems with state, incomplete or biased data, data with dependencies, and multi-agent learning applications. In particular, he would like to see more activity in obtaining new models and algorithms for reinforcement and multi-agent learning, better tools for high-dimensional learning problems with data bias and dependencies, as well as deeper connections to causal inference and econometrics. <em>“There is a lot of beautiful mathematics to be done and new continents to explore motivated by these challenges.”</em></p>



<h4>Acknowledgements </h4>



<p>We are thankful to Margalit Glasgow, Gautam Kamath, Praneeth Netrapalli, Arun Sai Suggala, and Manolis Zampetakis for providing valuable feedback on the blog. We would like to especially thank Costis Daskalakis for helpful conversations related to the technical and philosophical aspects of this work, and valuable comments throughout the writing of this article.</p>
</div></div>



<p><strong>Notes</strong></p>



<p id="fn1"><sup>1 </sup> As we discuss later, this existence only holds when the gains of each player are a concave function of their own actions.</p>



<p id="fn2"><sup>2</sup> This led to Nash winning the Nobel prize in Economics in 1994 with John Harsanyi and Reinhard Selten.</p>



<p id="fn3"><sup>3</sup> PPAD is the complexity class that exactly captures the complexity of computing Nash equilibria in general-sum games, computing fixed points of Lipschitz functions in convex and compact domains, and many other equilibrium and fixed point computation problems.</p>



<p id="fn4"><sup>4</sup> In Sperner, we are given white-box access to a circuit that computes colors for the vertices of some canonical simplicization of the <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/>-dimensional simplex. Each vertex receives one of the colors in <img alt="\{1,\ldots,d+1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C%5Cldots%2Cd%2B1%5C%7D&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> and each color <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> does not appear on any vertex of the triangulation lying on facet <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=eeeeee&amp;fg=666666&amp;s=0&amp;c=20201002"/> of the simplex. The goal is to find a simplex of the triangulation with all vertices colored differently.</p>



<p><strong>Bibliography</strong></p>



<p id="DSZ21">[DSZ21] Constantinos Daskalakis, Stratis Skoulakis, and Manolis Zampetakis. The complexity of constrained min-max optimization. Symposium on Theory of Computing, 2021</p>



<p id="HPV89">[HPV89] Michael D Hirsch, Christos H Papadimitriou, and Stephen A Vavasis. Exponential lower bounds for finding brouwer fixed points. Journal of Complexity, 1989.</p>



<p id="NY83">[NY83] Arkadi S. Nemirovsky and David B. Yudin. Problem complexity and method efficiency in optimization. Wiley, 1983.</p>



<p id="Pap94">[Pap94] Christos H. Papadimitriou. On the complexity of the parity argument and other inefficient proofs of existence. Journal of Computer and System Sciences, 1994.</p>



<p id="Ros65">[Ros65] J. Ben Rosen. Existence and uniqueness of equilibrium points for concave n-person games. Econometrica, 1965.</p>



<p id="vN28">[vN28] John von Neumann. Zur Theorie der Gesellschaftsspiele. In Mathematische annalen, 1928.</p></div>
    </content>
    <updated>2021-04-30T14:05:03Z</updated>
    <published>2021-04-30T14:05:03Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-05-05T05:38:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://dstheory.wordpress.com/?p=94</id>
    <link href="https://dstheory.wordpress.com/2021/04/29/thursday-may-6th-hamed-hassani-from-university-of-pennsylvania/" rel="alternate" type="text/html"/>
    <title>Thursday May 6th — Hamed Hassani  from University of Pennsylvania</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The next Foundations of Data Science virtual talk will take place on Thursday, May 6th at 11:00 AM Pacific Time (14:00 Eastern Time, 19:00 Central European Time, 18:00 UTC).  Hamed Hassani from Univeristy of Pennsylvania will speak about “Learning Robust Models: How does the Geometry of Perturbations Play a Role?” Please register here to join the<a class="more-link" href="https://dstheory.wordpress.com/2021/04/29/thursday-may-6th-hamed-hassani-from-university-of-pennsylvania/">Continue reading <span class="screen-reader-text">"Thursday May 6th — Hamed Hassani  from University of Pennsylvania"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p class="has-text-align-justify">The next <a href="https://sites.google.com/view/dstheory/home" rel="noreferrer noopener" target="_blank">Foundations of Data Science</a> virtual talk will take place on <strong>Thursday, May 6</strong>th at <strong>11:00 AM Pacific Time</strong> (14:00 Eastern Time, 19:00 Central European Time, 18:00 UTC).  <strong><a href="https://www.seas.upenn.edu/~hassani/index.html" rel="noreferrer noopener" target="_blank">Hamed Hassani</a></strong> from<strong> Univeristy of Pennsylvania</strong> will speak about “Learning Robust Models: How does the Geometry of Perturbations Play a Role?”</p>



<p><a href="https://sites.google.com/view/dstheory" rel="noreferrer noopener" target="_blank">Please register here to join the virtual talk.</a></p>



<p class="has-text-align-justify"><strong>Abstract</strong>: In this talk, we will focus on the emerging field of (adversarially) robust machine learning. The talk will be self-contained and no particular background on robust learning will be needed. Recent progress in this field has been accelerated by the observation that despite unprecedented performance on clean data, modern learning models remain fragile to seemingly innocuous changes such as small, norm-bounded additive perturbations.  Moreover, recent work in this field has looked beyond norm-bounded perturbations and has revealed that various other types of distributional shifts in the data can significantly degrade performance.  However, in general our understanding of such shifts is in its infancy and several key questions remain unaddressed.</p>



<p class="has-text-align-justify">The goal of this talk is to explain why robust learning paradigms have to be designed — and sometimes rethought — based on the geometry of the input perturbations.  We will cover a wide range of perturbation geometries from simple norm-bounded perturbations, to sparse, natural, and more general distribution shifts.  As we will show, the geometry of the perturbations necessitates fundamental modifications to the learning procedure as well as the architecture in order to ensure robustness. In the first part of the talk, we will discuss our recent theoretical results on robust learning with respect to various geometries, along with fundamental tradeoffs between robustness and accuracy, phase transitions, etc.  The remaining portion of the talk will be about developing practical robust training algorithms and evaluating the resulting (robust) deep networks against state-of-the-art methods on naturally-varying, real-world datasets.</p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>
    </content>
    <updated>2021-04-29T21:14:05Z</updated>
    <published>2021-04-29T21:14:05Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>dstheory</name>
    </author>
    <source>
      <id>https://dstheory.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://dstheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://dstheory.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://dstheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://dstheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Foundation of Data Science – Virtual Talk Series</title>
      <updated>2021-05-05T05:40:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/061</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/061" rel="alternate" type="text/html"/>
    <title>TR21-061 |  Reflections on Proof Complexity and Counting Principles | 

	Noah Fleming, 

	Toniann Pitassi</title>
    <summary>This paper surveys the development of propositional proof complexity and the seminal contributions of Alasdair Urquhart. We focus on the central role of counting principles, and in particular Tseitin's graph tautologies, to most of the key advances in lower bounds in proof complexity. We reflect on a couple of key ideas that Urquhart pioneered: (i) graph expansion as a tool for distinguishing between easy and hard principles, and (ii) ``reductive" lower bound arguments, proving via a simulation theorem that an optimal proof cannot bypass the obvious (inefficient) one.</summary>
    <updated>2021-04-29T20:10:17Z</updated>
    <published>2021-04-29T20:10:17Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-05-05T05:37:28Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2021/04/28/how-good-greed</id>
    <link href="https://11011110.github.io/blog/2021/04/28/how-good-greed.html" rel="alternate" type="text/html"/>
    <title>How good is greed for the no-three-in-line problem?</title>
    <summary>The 37th European Workshop on Computational Geometry (EuroCG 2021) was earlier this month, but its book of abstracts remains online. This has an odd position in the world of academic publishing: the “abstracts” are really short papers, so it looks a lot like a published conference proceedings. However, it declares that you should really pretend that it’s not a proceedings, in order to allow the same work to go on to another conference with a published proceedings, getting around the usual prohibitions on double publication. Instead, its papers “should be considered a preprint rather than a formally reviewed paper”. But I think that doesn’t preclude citing them, with care, just as you might occasionally cite arXiv preprints. The workshop’s lack of peer review and selectivity is actually a useful feature, allowing it to act as an outlet for works that are too small or preliminary for publication elsewhere. In North America, the Canadian Conference on Computational Geometry performs much the same role, but does publish a proceedings; its submission deadline is rapidly approaching.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The <a href="http://eurocg21.spbu.ru/">37th European Workshop on Computational Geometry (EuroCG 2021)</a> was earlier this month, but its <a href="http://eurocg21.spbu.ru/wp-content/uploads/2021/04/proceedings.pdf">book of abstracts</a> remains online. This has an odd position in the world of academic publishing: the “abstracts” are really short papers, so it looks a lot like a published conference proceedings. However, it declares that you should really pretend that it’s not a proceedings, in order to allow the same work to go on to another conference with a published proceedings, getting around the usual prohibitions on double publication. Instead, its papers “should be considered a preprint rather than a formally reviewed paper”. But I think that doesn’t preclude citing them, with care, just as you might occasionally cite arXiv preprints. The workshop’s lack of peer review and selectivity is actually a useful feature, allowing it to act as an outlet for works that are too small or preliminary for publication elsewhere. In North America, the <a href="http://cccg.ca/">Canadian Conference on Computational Geometry</a> performs much the same role, but does publish a proceedings; its <a href="https://projects.cs.dal.ca/cccg2021/the-call-for-papers-is-out/">submission deadline</a> is rapidly approaching.</p>

<p>Anyway, one of the EuroCG not-really-a-published-paper things is mine: “Geometric dominating sets – A minimum version of the no-three-in-line problem”, with Oswin Aichholzer and Eva-Maria Hainzl. As the title suggests, it’s related to the <a href="https://en.wikipedia.org/wiki/No-three-in-line_problem">no-three-in-line problem</a>, in which one must place as many points as possible in a grid so that no three are collinear. I’ve written about the same problem here <a href="https://11011110.github.io/blog/2018/11/10/random-no-three.html">several</a> <a href="https://11011110.github.io/blog/2018/11/12/gurobi-vs-no.html">times</a> <a href="https://11011110.github.io/blog/2018/12/08/general-position-hypercube.html">already</a>. On an \(n\times n\) grid, there’s an easy upper bound of \(2n\) on the number of points, but it’s widely conjectured that the actual number is a smaller linear function of \(n\). It was a big step forward when Erdős showed that \(n\bigl(1-o(1)\bigr)\) points can be placed, and this was later improved to \(\tfrac{3}{2}n\bigl(1-o(1)\bigr)\).</p>

<p>These big no-three-in-line sets are constructed algebraically, but what if we try something simpler, a greedy algorithm that just adds points one by one (in a random or systematic order) until getting stuck? This question was already asked in the 1970s by Martin Gardner, and studied by several other authors since. But it is, if anything, even more frustratingly unknown than the no-three-in-line problem itself. We don’t know whether, in general, it’s possible to get stuck with fewer points than the maximum solution to the no-three-in-line problem, or even whether it’s possible to get stuck with fewer than \(2n\) points for infinitely many values of \(n\). For some values of \(n\) we do know smaller stuck solutions, though: for instance, here’s one with \(28\) points on a \(36\times 36\) grid.</p>

<p style="text-align: center;"><img alt="A 28-point greedy solution to the no-three-in-line problem on a 36x36 grid" src="https://11011110.github.io/blog/assets/2021/greedy-no3-36x36.svg"/></p>

<p>It was known that greedy solutions always have \(\Omega(\sqrt{n})\) points, and one of our main results is to improve this bound to \(\Omega(n^{2/3})\). The known \(\Omega(\sqrt{n})\) lower bound is easy to see: A single line through two selected points can cover at most \(n\) other grid points, so you need \(n\) lines to cover the whole grid, and you need \(\Omega(\sqrt{n})\) points to determine this many lines. With fewer points, there won’t be enough lines through your points to cover the whole grid, and your greedy solution won’t be stuck. Our new \(\Omega(n^{2/3})\) bound looks more carefully at the tradeoff between numbers of lines and numbers of points per line. It can be divided into two cases:</p>

<ul>
  <li>
    <p>Suppose, first, that the selected point set has the property that, for any selected point \(p\), the lines through \(p\) cover fewer than \(n^{4/3}\) grid points. Because each selected point covers few grid points, we need to select many points to cover the whole grid: at least \(\Omega(n^{2/3})\) points.</p>
  </li>
  <li>
    <p>Suppose on the other hand that the lines through some point \(p\) cover at least  \(n^{4/3}\) grid points. Parameterize these lines by the \(L_\infty\) distance to the closest grid point (regardless of whether that point is one of the selected ones). Then there are \(O(k)\) lines with parameter \(k\), each of which covers \(O(n/k)\) grid points. Summing over small values of \(k\) shows that, even if we use lines that cover as many grid points as possible, we need  \(\Omega(n^{2/3})\) lines through \(p\) to cover this many grid points. Each of these lines is determined by another selected point, so we need \(\Omega(n^{2/3})\) selected points.</p>
  </li>
</ul>

<p>The actual proof in the paper takes into account that not all the grid points near \(p\) are the nearest on their line, and does the summation over small values of \(k\) more carefully, to get more precise constant factors in the bounds. Our paper also includes another variation of the problem in which we allow our selected points to be collinear but require the lines through them to cover all unselected points. There, we can make a little progress: we show that \(n\) points, or in some cases slightly fewer than \(n\) points, are sufficient. The same \(\Omega(n^{2/3})\) lower bound is still valid for this case, but there’s still a big gap between the lower bound and the upper bound.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/106146843522019241">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2021-04-28T18:23:00Z</updated>
    <published>2021-04-28T18:23:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2021-05-01T00:37:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=18647</id>
    <link href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/" rel="alternate" type="text/html"/>
    <title>Congrats to the New Members</title>
    <summary>If you know you are on the right track, if you have this inner knowledge, then nobody can turn you off no matter what they say—Barbara McClintock David Oxtoby is the president of AAAS. He just announced the 2021 new members. See the press release. Today I thought I would explain which choices are correct […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>If you know you are on the right track, if you have this inner knowledge, then nobody can turn you off <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> no matter what they say—Barbara McClintock</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/oxtobycropped/" rel="attachment wp-att-18671"><img alt="" class="alignright size-full wp-image-18671" height="150" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/oxtobyCropped.png?resize=121%2C150&amp;ssl=1" width="121"/></a></p>
<p>
David Oxtoby is the president of <a href="https://www.amacad.org/new-members-2021">AAAS</a>. He just announced the 2021 new members. See the <a href="https://www.amacad.org/news/2021-member-announcement">press release</a>.</p>
<p>
Today I thought I would explain which choices are correct and which are <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/><br/>
<span id="more-18647"/></p>
<p>
Just kidding. Of course they all are terrific choices. Here are some choices in previous years—going back a little while: </p>
<blockquote><p><b> </b> <em> The new class joins Academy members elected before them, including Benjamin Franklin (elected 1781) and Alexander Hamilton (1791) in the eighteenth century; Ralph Waldo Emerson (1864), Maria Mitchell (1848), and Charles Darwin (1874) in the nineteenth; Albert Einstein (1924), Robert Frost (1931), Margaret Mead (1948), Groucho Marx (1951), Milton Friedman (1959), Martin Luther King, Jr. (1966), and Anthony Fauci (1991) in the twentieth. </em>
</p></blockquote>
<p>
</p><p/><h2> Computer Science </h2><p/>
<p/><p>
Here they are with some fun facts.</p>
<p>
<a href="https://en.wikipedia.org/wiki/Demis_Hassabis">Demis Hassabis</a> (International Honorary Member), DeepMind <br/>
Child chess prodigy: at the age of 13 had an Elo rating of 2300.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/dh/" rel="attachment wp-att-18657"><img alt="" class="aligncenter size-thumbnail wp-image-18657" height="150" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/dh-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://en.wikipedia.org/wiki/Charles_Lee_Isbell_Jr.">Charles Isbell</a>, Georgia Institute of Technology <br/>
Started the Black History Database. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/ci/" rel="attachment wp-att-18659"><img alt="" class="aligncenter size-thumbnail wp-image-18659" height="150" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ci-150x150.jpg?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://en.wikipedia.org/wiki/Fei-Fei_Li">Fei-Fei Li</a>, Stanford University <br/>
Helped create ImageNet. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/fl/" rel="attachment wp-att-18660"><img alt="" class="aligncenter size-thumbnail wp-image-18660" height="150" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/fl-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://www.linkedin.com/in/murielmedard/">Muriel Medard</a>, Massachusetts Institute of Technology <br/>
Co-founded multiple companies. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/mm-3/" rel="attachment wp-att-18661"><img alt="" class="aligncenter size-thumbnail wp-image-18661" height="150" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/mm-1-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://en.wikipedia.org/wiki/Stefan_Savage">Stefan Savage</a>, University of California, San Diego <br/>
Uses cool names for projects: Jetset, Trufflehunter, <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/ss/" rel="attachment wp-att-18666"><img alt="" class="aligncenter size-thumbnail wp-image-18666" height="150" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ss-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://en.wikipedia.org/wiki/Margo_Seltzer">Margo Seltzer</a>, University of British Columbia <br/>
Very busy: see her <a href="https://www.seltzer.com/margo/calendar/">calendar</a> </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/ms-2/" rel="attachment wp-att-18663"><img alt="" class="aligncenter size-thumbnail wp-image-18663" height="150" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ms-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
<a href="https://en.wikipedia.org/wiki/Daniel_Spielman">Daniel Spielman</a>, Yale University <br/>
Once held a professorship named for “Hank the Deuce” or “HF2”. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/04/28/congrats-to-the-new-members/ds/" rel="attachment wp-att-18664"><img alt="" class="aligncenter size-thumbnail wp-image-18664" height="150" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/04/ds-150x150.png?resize=150%2C150&amp;ssl=1" width="150"/></a></p>
<p>
[re-aligned photo at top]</p>
<p/><h2> Mathematics </h2><p/>
<p/><p>
<a href="https://en.wikipedia.org/wiki/Yakov_Eliashberg">Yakov Eliashberg</a>, Stanford University <br/>
<a href="https://en.wikipedia.org/wiki/Benson_Farb">Benson Farb</a>, University of Chicago <br/>
<a href="https://www.math.nyu.edu/faculty/masmoudi/">Nader Masmoudi</a>, New York University <br/>
<a href="https://en.wikipedia.org/wiki/Kavita_Ramanan">Kavita Ramanan</a>, Brown University <br/>
<a href="https://en.wikipedia.org/wiki/Scott_D._Sheffield">Scott Sheffield</a>, Massachusetts Institute of Technology <br/>
<a href="https://en.wikipedia.org/wiki/Karen_E._Smith">Karen Smith</a>, University of Michigan <br/>
<a href="https://en.wikipedia.org/wiki/Amie_Wilkinson">Amie Wilkinson</a>, University of Chicago </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Do you have better fun facts on the winners? Let us know if you do.</p>
<p/></font></font></div>
    </content>
    <updated>2021-04-28T16:20:07Z</updated>
    <published>2021-04-28T16:20:07Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="AAAS"/>
    <category term="Awards"/>
    <category term="congrats"/>
    <category term="new members"/>
    <category term="who"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel's Lost Letter and P=NP</title>
      <updated>2021-05-05T05:37:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8105</id>
    <link href="https://windowsontheory.org/2021/04/27/google-research-workshop-on-deep-learning-theory/" rel="alternate" type="text/html"/>
    <title>Google Research Workshop on Deep Learning Theory</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">[Guest post from Pranjal Awasthi and Rina Panigrahy – workshop looks great! –Boaz] Please join us for a virtual Google workshop on “Conceptual Understanding of Deep Learning”  When: May 17th 9am-4pm. Where: Live over Youtube, Goal: How does the Brain/Mind (perhaps even an artificial one) work at an algorithmic level? While deep learning has produced tremendous technological … <a class="more-link" href="https://windowsontheory.org/2021/04/27/google-research-workshop-on-deep-learning-theory/">Continue reading <span class="screen-reader-text">Google Research Workshop on Deep Learning Theory</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>[Guest post from Pranjal Awasthi and Rina Panigrahy – workshop looks great! –Boaz]</em><br/></p>



<p>Please join us for a virtual Google workshop on “<a href="https://sites.google.com/view/conceptualdlworkshop/home" rel="noreferrer noopener" target="_blank">Conceptual Understanding of Deep Learning</a>” </p>



<p>When: May 17th 9am-4pm. Where: <a href="https://www.youtube.com/watch?v=g5DGBWjiULQ" rel="noreferrer noopener" target="_blank">Live over Youtube</a>,</p>



<p><strong>Goal: </strong>How does the Brain/Mind (perhaps even an artificial one) work at an algorithmic level? While deep learning has produced tremendous technological strides in recent decades, there is an unsettling feeling of a lack of “conceptual” understanding of why it works and to what extent it will work in the current form. The goal of the workshop is to bring together theorists and practitioners to develop an understanding of the right algorithmic view of deep learning, characterizing the class of functions that can be learned, coming up with the right learning architecture that may (provably) learn multiple functions, concepts and remember them over time as humans do, theoretical understanding of language, logic, RL, meta learning and lifelong learning.</p>



<p>The speakers and panelists include Turing award winners Geoffrey Hinton, Leslie Valiant, and Godel Prize winner Christos Papadimitriou (<a href="https://sites.google.com/corp/view/conceptualdlworkshop/home" rel="noreferrer noopener" target="_blank">full-details</a>).   </p>



<p><strong>Panel Discussion: </strong>There will also be a panel discussion on the fundamental question of “Is there a mathematical model for the Mind?”. We will explore basic questions such as “Is there a provable algorithm that captures the essential capabilities of the mind?”, “How do we remember complex phenomena?”, “How is a knowledge graph created automatically?”, “How do we learn new concepts, function and action hierarchies over time?” and “Why do human decisions seem so interpretable?”<br/><br/>Twitter:<a href="https://twitter.com/search?q=%23ConceptualDLWorkshop&amp;src=recent_search_click" rel="noreferrer noopener" target="_blank"> #ConceptualDLWorkshop</a>. Please help advertise on mailing-lists/blog-posts and <a href="https://twitter.com/rinapy/status/1384311169519788032" rel="noreferrer noopener" target="_blank">Retweet</a>.<br/>Hope to see you there!</p>



<p>Rina Panigrahy<br/>(<a href="http://theory.stanford.edu/~rinap" rel="noreferrer noopener" target="_blank">http://theory.stanford.edu/~rinap</a>)</p></div>
    </content>
    <updated>2021-04-27T18:55:31Z</updated>
    <published>2021-04-27T18:55:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-05-05T05:38:39Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://differentialprivacy.org/alt-highlights/</id>
    <link href="https://differentialprivacy.org/alt-highlights/" rel="alternate" type="text/html"/>
    <title>ALT Highlights - An Equivalence between Private Learning and Online Learning (ALT '21 Tutorial)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Welcome to ALT Highlights, a series of blog posts spotlighting various happenings at the recent conference <a href="http://algorithmiclearningtheory.org/alt2021/">ALT 2021</a>, including plenary talks, tutorials, trends in learning theory, and more! 
To reach a broad audience, the series will be disseminated as guest posts on different blogs in machine learning and theoretical computer science. 
Given the topic of this post, we felt <a href="https://differentialprivacy.org/">DifferentialPrivacy.org</a> was a great fit.
This initiative is organized by the <a href="https://www.let-all.com/">Learning Theory Alliance</a>, and overseen by <a href="http://www.gautamkamath.com/">Gautam Kamath</a>. 
All posts in ALT Highlights are indexed on the official <a href="https://www.let-all.com/blog/2021/04/20/alt-highlights-2021/">Learning Theory Alliance blog</a>.</p>

<p>The second post is coverage of <a href="http://www.cs.technion.ac.il/~shaymrn">Shay Moran</a>’s <a href="https://www.youtube.com/watch?v=wk910Aj559A">tutorial</a>, by <a href="https://people.eecs.berkeley.edu/~kush/">Kush Bhatia</a> and <a href="https://web.stanford.edu/~mglasgow/">Margalit Glasgow</a>.</p>

<hr/>

<p>The tutorial at ALT was given by <a href="http://www.cs.technion.ac.il/~shaymrn/">Shay Moran</a>, an assistant professor at the Technion in Haifa.
His <a href="https://www.youtube.com/watch?v=wk910Aj559A">talk</a> focused on recent results showing a deep connection between two important areas in learning theory: online learning and differentially private learning. 
While online learning is a well-established area that has been studied since the invention of the Perceptron algorithm in 1954, differential privacy (DP) - introduced in the seminal work of Dwork, McSherry, Nissim, and Smith in 2006 <a href="https://journalprivacyconfidentiality.org/index.php/jpc/article/view/405"><strong>[DMNS06]</strong></a> - has received increasing attention in recent years from both theoretical and applied research communities along with industry and the government. 
This recent interest in differential privacy comes from a need to protect the privacy rights of the individuals, while still allowing one to derive useful conclusions from the dataset.
Shay, in a sequence of papers with co-authors Noga Alon, Mark Bun, Roi Livni, and Maryanthe Malliaris, revealed a surprising qualitative connection between these two models of learning: a concept class can be learned in an online fashion if and only if this concept class can be learned in an offline fashion by a differentially private algorithm.</p>

<p>The main objectives of this tutorial were to give an in-depth foray into this recent work, and present an opportunity to young researchers to identify interesting research problems at the intersection of these two fields. This line of work (<a href="https://arxiv.org/abs/1806.00949"><strong>[ALMM19]</strong></a>, <a href="https://arxiv.org/abs/2003.00563"><strong>[BLM20]</strong></a>) - which has been primarily featured in general CS Theory conferences, including recently winning a best paper award at FOCS -  introduced several new techniques which could be of use to the machine learning theory community. The first part of this article focuses on the technical challenges of characterizing DP learnability and the solutions used in Shay’s work, which originate from combinatorics and model theory. In the rest of this article, we highlight some of the exciting open directions Shay sees more broadly in learning theory.</p>

<h2 id="background-pac-learning-online-learning-and-dp-pac-learning">Background: PAC Learning, Online Learning, and DP PAC Learning</h2>

<p>We begin by reviewing the classical setting of PAC learning. 
The goal of PAC learning is to learn some function from a <em>concept class</em> \(\mathcal{H} \), a set of functions from some domain \( \mathcal{X} \) to \( \{0, 1\} \). 
<img align="right" src="https://differentialprivacy.org/images/PACLearning.png" style="width: 300px; height: 300px;"/> 
In the realizable setting of PAC learning, which we will focus on here, the learner is presented with \( n \) labeled training samples \( \{(x_i, y_i)\}_{i=1}^{n} \) where \( x_i \in \mathcal{X} \) and \( y_i = h(x_i) \) for some function \( h \in \mathcal{H} \). While the learner knows the concept class \( \mathcal{H} \), the function \( h \) is unknown, and after seeing the \( n \) samples, the learner algorithm \( A \) must output some function \( \hat{h}: \mathcal{X} \rightarrow \{0, 1\} \). A concept class is <em>PAC-learnable</em> if there exists an algorithm \( A \) such that for any distribution over samples, as the number of labeled training samples goes to infinity, the probability that \( \hat{h} \) incorrectly labels a new random sample goes to 0. We will say that \( A \) is a <em>proper</em> learner if \( A \) outputs a function in \(\mathcal{H}\), while \( A \) is <em>improper</em> if it may output a function outside of \( \mathcal{H} \). More quantitative measures of learnability concern the exact number of samples \( n \) needed for the learner to correctly predict future labels with nontrivial probability.</p>

<p>DP PAC learning imposes an additional restriction on PAC learning: the learner must output a function which does not reveal too much about any one sample in the input. Formally, we say an algorithm \( A \) is \( (\varepsilon, \delta) \)-DP if for any two neighboring inputs \( X = (X_1, \cdots,  X_i, \cdots, X_n) \) and \( X’ = (X_1, \cdots, X_i’,\cdots, X_n) \) which differ at exactly one sample, for any set \( S \), \( \Pr[A(X) \in S] \leq e^\varepsilon Pr[A(X’) \in S] + \delta \) . A concept class is <em>DP PAC learnable</em> if it can be PAC-learned by a \( (0.1, o(1/n)) \)-DP algorithm \( A \). That is, changing any one training sample \( (x_i, y_i) \) should not affect the distribution over concepts output by \( A \) by too much.</p>

<p>Online learning considers a setting where the samples arrive one-by-one, and the learner must make predictions as this process unfolds. <img align="right" src="https://differentialprivacy.org/images/OnlineLearning.png" style="width: 300px; height: 300px;"/>Formally, in realizable online learning, at each round \( i = 1,\dots,T \), the learner is presented with a sample \( x_i\). The learner must predict the label, and then the true label \( y_i \) is revealed to the learner. The sequence of examples \( x_i \) and the labels \( y_i \) may be chosen adversarially, but they must be consistent with some function \( h \in \mathcal{H} \). The goal of the learner is to minimize the total number of mistakes made by round \( T \), also called the <em>mistake bound</em>. If there is a learner such that at \( T \rightarrow \infty \), the number of mistakes is \( o(T) \), we say that the class of functions \( \mathcal{H} \) is <em>online learnable</em>. Because of the adversarial nature of the examples, online learning is well known to be much harder than PAC learning, and is possible precisely when the <em>Littlestone Dimension</em> of the concept class is finite. Figure 1 below illustrates the definition of the Littlestone Dimension. One important PAC-learnable concept class which is not online learnable is the infinite class of thresholds on \( \mathbb{R} \): The set of functions \(\{h_t\}_{t \in \mathbb{R}} \) where \( h_t(x) = \textbf{1}(x &gt; t) \).</p>

<p><img alt="Figure 1: Littlestone Dimension" src="https://differentialprivacy.org/images/LD.png" title="Figure 1: Littlestone Dimension"/></p>

<p><strong>Figure 1</strong>: The Littlestone dimension is the maximum depth of a tree shattered by \( \mathcal{H} \), where each node may contain a unique element from \(\mathcal{X}\). The tree is shattered if each leaf can be labeled by a function in \(\mathcal{H} \) that labels each element on the path to the root according to the value of the edge entering it. In this figure, we show how the set of thresholds on \( [0, 1] \) shatters this tree of depth 3.</p>

<p>It’s worth taking a moment to understand intuitively why learning thresholds might be hard for both an online learner and a DP learner. In an online setting, suppose the adversary chooses the next example to be any value of \( x \) in between all previously 0-labeled examples and all 1-labeled examples. Then no matter what label \( A \) chooses, the adversary can say \( A \) was incorrect. In a DP setting, a simple proper learner that outputs a threshold that makes no errors on the training data will reveal too much information about the samples at the boundary of 0-labeled samples and 1-labeled samples.</p>

<h2 id="a-challenging-question">A Challenging Question</h2>

<p>The journey to characterizing DP PAC learnability started soon after the introduction of DP, in <a href="https://arxiv.org/abs/0803.0924"><strong>[KLNRS08]</strong></a>, where the concept of DP PAC learning was introduced. This work primarily considered the more stringent <em>pure</em> DP-learning, where \( \delta = 0\). This work established that any finite concept class could be learned privately by applying the <em>exponential mechanism</em> (a standard technique in DP) to the empirical error of each candidate concept. Using the exponential mechanism, the learner could output each function \( h \in \mathcal{H}\) with probability proportional to \( \exp(- \varepsilon(\# \text{ of errors h on the training data})) \). This was sufficiently private because the empirical error is not too sensitive to a change of one training sample. Later works <a href="https://arxiv.org/abs/1402.2224"><strong>[BNS14]</strong></a> combinatorially characterized the complexity of pure DP PAC learning in terms of a measure called <em>representation dimension</em>, showing that in some cases where PAC learning was possible, pure DP PAC learning was not. <a href="https://arxiv.org/abs/1504.07553"><strong>[BNSV15]</strong></a> further yielded lower bounds on the limits of proper DP PAC learning.<sup id="fnref:1"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:1" rel="footnote">1</a></sup><br/>
Both pure and proper DP learning though are significantly more stringent than improper DP learning, and proving lower bounds against an improper DP learner posed a serious challenge. Even the following simple-sounding question was unsolved:</p>

<blockquote>
  <p>Can an improper DP algorithm learn the infinite class of thresholds over [0, 1]? (*)</p>
</blockquote>

<p>This question stands at the center of Shay’s work, which unfolded while Shay was residing at the Institute for Advanced Study (IAS) at Princeton from 2017 to 2019.<sup id="fnref:2"><a class="footnote" href="https://differentialprivacy.org/feed.xml#fn:2" rel="footnote">2</a></sup> At the time, Shay was working on understanding the expressivity of limited mutual-information algorithms, that is, algorithms which expose little information about the total input. “If we were to have directly worked on this problem, I believe we wouldn’t have solved it,” Shay says. Instead, they came from the angle of mutual-information, a concept qualitatively similar to DP, but armed with a rich toolkit from 70 years of information theory. One of Shay’s prior works with Raef Bassily, Ido Nachum, Jonathan Shafer, and Amir Yehudayof established lower bounds on the mutual information of any proper algorithm that learns thresholds <a href="https://arxiv.org/abs/1710.05233"><strong>[BMNSY18]</strong></a>, though this didn’t yet address the challenge presented by improper learners.</p>

<p>Unlike most lower bounds in theoretical computer science, proving hardness of learning the infinite class of thresholds on the line against an improper DP algorithm would require coming up with algorithm-specific distributions over samples. That is, instead of showing that one distribution over samples would be impossible to learn for all algorithms — in the way the a uniform distribution over the set in \(\mathcal{X}\) shattered by the concept class is hard to PAC-learn for any algorithm — they would have to come up with a distribution on \(\mathcal{X}\) specific to each candidate learning algorithm. Indeed, if the distribution was known to the learner, it was possible to devise a DP algorithm using the exponential mechanism (again!) which could learn any PAC-learnable concept class. Similar to the case of finite concept classes, here we can apply the exponential mechanism to some finite set of representative functions forming a cover of the concept class.</p>

<h2 id="uncovering-a-solution">Uncovering a Solution</h2>

<p>At the IAS, Shay met his initial team to tackle this obstacle: Noga Alon, a combinatorialist, Roi Livni, a learning theorist, and Maryanthe Malliaris, a model theorist. Shay and Maryanthe would walk together from IAS to their combinatorics class at Princeton taught by Noga and discuss mathematics. While Marayathe studied the abstract mathematical field of model theory, Shay and Maryanthe soon noticed a connection between model theory and machine learning: the Littlestone dimension. “There is applied math, then pure math, and then model theory is way over there,” Shay elaborates. “If theoretical machine learning is between applied math and pure math, model theory is on the other extreme.” This surprising interdisciplinary connection led them to use a result from model theory: a concept class had finite Littlestone Dimension precisely when the concept class had finite threshold dimension (formally, the maximum number of threshold functions that could be embedded in the class). This meant that answering (*) negatively was enough to show that DP PAC learning was as hard as online learning.</p>

<p>The idea for showing a lower bound for improper DP learning of thresholds came from Ramsey Theory, a famous area in combinatorics. Ramsey theory guarantees the existence of structured subsets among large, but arbitrary, combinatorial objects. A toy example of Ramsey Theory is that in any graph on 6 or more nodes, there must be a group of 3 nodes which form either a clique or an independent set. In the case of DP learning thresholds, the learning algorithm \( A \) is the arbitrary (and unstructured) combinatorial object. Ramsey Theory guarantees that for any PAC learner \( A \), there exists some large subset \( \mathcal{X}’ \) of the domain \(\mathcal{X}=[0, 1]\) on which \( A \) is close to behaving “normally”. The next step is to show that behaving normally contradicts differentially privacy. We’ll dig more technically into this argument in the next couple paragraphs. Note that we invent a couple definitions for the sake of exposition (“proper-normal” and “improper-normal”) that don’t appear in <a href="https://arxiv.org/abs/1504.07553"><strong>[BNSV15]</strong></a> or <a href="https://arxiv.org/abs/1806.00949"><strong>[ALMM19]</strong></a>.</p>

<p>Let’s start by seeing how a simpler version of this argument from <a href="https://arxiv.org/abs/1504.07553"><strong>[BNSV15]</strong></a> works to show that proper DP algorithms cannot learn thresholds. Recall that in a proper algorithm, after seeing \( n \) labeled samples, \( A \) must output a threshold. To be a PAC learner, if exactly half of the \( n \) samples are labeled \( 1 \) (which we will call a <em>balanced</em> sample), \( A \) must output a threshold between the smallest and largest sample with constant probability. Indeed, otherwise the empirical error of \( A \) will be too large to even hope to generalize. This implies that for a balanced list of samples \( S = [(x_1, 0), \ldots ,(x_{n/2}, 0), (x_{n/2+1}, 1), \ldots ,(x_n, 1)] \) (ordered by \(x\)-value), there must exist an integer \( k \in [n] \) for which with probability \( \Omega(1/n) \), \(A \) outputs a threshold in between 
\( x_k \) and \( x_{k+1} \). We’ll say that \( A \) is <em>\(k\)-proper-normal</em> on a set \( \mathcal{X}’ \) if for any balanced sample \( S \) of \( n \) points in \( \mathcal{X}’ \), \( A \) outputs a threshold in between the \(k\)th and \(k+1\)th ordered samples with probability \( \Omega(1/n) \). For example, the naive algorithm that always outputs a threshold between the 0-labeled samples and 1-labeled samples is \(n/2\)-normal on the entire domain \([0, 1]\). Ramsey theory guarantees that there is an arbitrary large subset of the domain \([0, 1]\) on which \(A \) is \(k\)-proper-normal for some \(k\). (See Figure 2).</p>

<p><img alt="Figure 2: Ramsey's Theorem" src="https://differentialprivacy.org/images/RamseyTheorem.png" title="Figure 2: Ramsey's Theorem"/>
<strong>Figure 2</strong>: Ramsey’s Theorem guarantees a large subset \( \mathcal{X}’ \) on which \( A \) is \( k \)-proper-normal for some \( k \).</p>

<p>The second part of the argument shows that being \( k \)-proper-normal on a large set is in direct conflict with differential privacy. We show this argument in Figure 3 by constructing a set of \( n \) samples \( S^* \) on which \( A \) must output a threshold in many distinct regions with substantial probability.</p>

<p><img alt="Figure 3: A Hard Distribution" src="https://differentialprivacy.org/images/DP_Construction.png" title="Figure 2: Ramsey's Theorem"/></p>

<p><strong>Figure 3:</strong> A distribution showing the conflict between \(A \) being DP and \(k\)-proper normal. By DP, the behaviour of \(A\) on \(S^* \) must be similar to its behaviour on \(S_i\) for \(i = 1 \ldots \Omega(n).\) Namely, since \(S^* \) and \( S_i \) differ by at most two points, \( A(S^*) \) must output a threshold in \( I_i \) with probability \( p \geq (q - 2\delta)e^{-(2\varepsilon)} \) for each \( i \), where \( q \) is a lower bound on the probability that \( A(S_i) \) outputs a threshold in \( I_i \). Because \( A \) is \(k\)-proper-normal, \( q &gt; c/n \), so \( p = \Omega(1/n) \). This yields a contradiction for \( m &gt;1/p \) because \( A \) cannot simultaneously output a threshold in two of the intervals \( I_i \).</p>

<p>For the case of improper algorithms, Shay and his coauthors considered an alternative notion of normality, which we will term <em>improper-normal</em>. Recall that in this case the output \( A(S) \) of the learner on a sample \( S \) is <em>any function</em> from \( [0, 1] \) to \( \{0, 1\} \) and not necessarly a threshold. We’ll say that \( A \) is \(k\)-improper-normal on a set \( \mathcal{X}’ \) if for any balanced sample \( S = [(x_1, 0), \ldots, (x_{n/2}, 0), (x_{n/2 +1}, 1), \ldots,  (x_n, 1)] \) of \( n \) points in \( \mathcal{X}’, \Pr[A(S)(w) = 1] - \Pr[A(S)(v) = 1] &gt; \Omega(1/n) \) for any \( w \in (x_{k - 1}, x_k) \) and \( v \in  (x_k, x_{k + 1}) \) in \( \mathcal{X}’ \setminus \{x_1, … x_n\} \). To PAC learn, A must be \(k\)-improper-normal for some \(k\) on any set of \(n + 1\) points. Applying the same Ramsey Theorem to a graph with colored hyperedges of size \(n + 1\) shows that there must exist an arbitrarily large set \( \mathcal{X}’ \) on which \( A \) is \(k\)-improper normal for some \( k \). A similar (but more nuanced) argument as before shows that a learner cannot be simultaneously private and \(k\)-improper-normal on some distribution over \( \mathcal{X}’ \).</p>

<p>For the last piece of the puzzle, showing the upper bound converse, Mark Bun, an expert in differential privacy at Princeton at the time, joined in. Beginning in the fall of 2019, Mark, Shay, and Roi worked out an upper bound that showed that any class with finite Littlestone dimension could be learned privately. Their technique introduced a new notion of stability, called <em>global stability</em>, which is a property of algorithms that frequently output the same hypothesis. Given a globally stable PAC learner \( A \), to obtain a DP PAC learner, one can run \( A \) many times and produce a histogram of the output hypotheses, add noise to this histogram for the sake of privacy, and then select the most frequent output hypothesis. The construction for the globally stable learner uses the Standard Optimal Algorithm for online learning as a black box - though the reduction is very computationally intensive and results in a sample complexity depending exponentially on the Littlestone Dimension. This reduction was improved in <a href="https://arxiv.org/abs/2012.03893"><strong>[GGKM20]</strong></a>, where the authors gave a reduction requiring only polynomially many samples in the Littlestone dimension.</p>

<h2 id="outlook">Outlook</h2>

<p>Shay mentions that these results are only a first step towards understanding differentially private PAC learning. This work establishes a deep connection between online learning and DP learning, qualitatively showing that these two problems have similar underlying complexity. Recent works <a href="https://arxiv.org/abs/1905.11311"><strong>[GHM19]</strong></a> have gone a step further and established polynomial time reductions from DP learning to online learning under certain conditions. At the same time, Bun <a href="https://arxiv.org/abs/2007.05665"><strong>[B20]</strong></a> demonstrates a computational gap between the two problems: they exhibit a concept class which is DP PAC learnable in polynomial time, but no algorithm can learn it online in polynomial time and sample complexity.</p>

<p>An interesting question here is whether a polynomial time online learning algorithm implies a polynomial time DP learning algorithm? With regards to sample complexity, tighter quantitative bounds relating the sample complexity of DP learning to the Threshold dimension and the Littlestone Dimension, along with constructive reductions from DP learning to online learning are wide open. An interesting conjecture, also highlighted in the talk, is whether DP PAC learning and PAC learning are actually equivalent up to a \(log*\) factor of the Littlestone dimension? Solving this would mean that for most natural function classes, one need not pay a very high price for private learning as compared to PAC learning.</p>

<p>From a more practical perspective, studying such qualitative equivalences can lay the groundwork allowing one to use the vast existing knowledge in the field of online learning to design better algorithms for DP learning, and vice versa. Despite its abstractness, Shay believes this result still has significance for engineers: “If they want to do something differentially privately, if they already have a good online learning algorithm for this, maybe they can modify it,” Shay says. “It gives some kind of inspiration.”</p>

<p>From a broader perspective, Shay believes that discovering clean, beautiful mathematical models that are more realistic than the PAC learning model and understanding the price one pays for privacy in those models are important directions for future research. One model, highlighted in the tutorial by Shay is that of <em>Universal Learning</em>, introduced in a recent work <a href="https://arxiv.org/abs/2011.04483"><strong>[BHMVY21]</strong></a> with Olivier Bousquet, Steve Hanneke, Ramon van Handel and Amir Yehudayoff. This model considers a learning task with a fixed distribution of samples and studies the hardness of the problem as the number of samples \( n \to \infty \). This setup better captures the practical aspects of modern machine learning and overcomes the limitations of the PAC model, which studies worst-case distributions for each sample size.</p>

<p>And how should one go about identifying such better mathematical models? “Pick the simplest problem that you don’t know how to solve and see where that leads you”, says Shay. One should begin by trying to understand the deficiencies of existing learning models, by identifying simple examples which go beyond these existing models. For example, Livni and Moran <a href="https://arxiv.org/abs/2006.13508"><strong>[LM20]</strong></a> exhibit the limitations of PAC-Bayes framework through a simple 1D linear classification problem. Fixing such limitations can often lead one to discover better learning models.</p>

<hr/>
<p><em>Thanks to Gautam Kamath, Shay Moran, and Keziah Naggita for helpful conversations and comments.</em></p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>For a more complete background on the progress in DP PAC learning, we refer the reader to the excellent survey blog post <a href="https://differentialprivacy.org/private-pac/">here</a>. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:1">↩</a></p>
    </li>
    <li id="fn:2">
      <p>At the time, Shay was additionally affiliated with Princeton University and Google Brain. <a class="reversefootnote" href="https://differentialprivacy.org/feed.xml#fnref:2">↩</a></p>
    </li>
  </ol>
</div></div>
    </summary>
    <updated>2021-04-26T16:00:00Z</updated>
    <published>2021-04-26T16:00:00Z</published>
    <author>
      <name>Margalit Glasgow</name>
    </author>
    <source>
      <id>https://differentialprivacy.org</id>
      <link href="https://differentialprivacy.org" rel="alternate" type="text/html"/>
      <link href="https://differentialprivacy.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Website for the differential privacy research community</subtitle>
      <title>Differential Privacy</title>
      <updated>2021-05-04T22:56:35Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-9152128988613149804</id>
    <link href="https://blog.computationalcomplexity.org/feeds/9152128988613149804/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/04/ferrers-diagrams-can-be-used-to-prove-x.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9152128988613149804" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/9152128988613149804" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/04/ferrers-diagrams-can-be-used-to-prove-x.html" rel="alternate" type="text/html"/>
    <title>Ferrer's Diagrams can be used to prove X theorems about partitions. What is X?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>1978: I took an excellent  ugrad course in combinatorics from James C Frauenthal (he sometimes wrote his name as the biniomial cofficient (J choose F))  and he covered Ferrer's diagrams. They are a nice way to prove equalities about types of partitions.   See <a href="https://www.britannica.com/science/combinatorics/The-Ferrer-diagram">here</a> for a definition and a few examples. I have this (possibly false) memory that there were LOTS of partition theorems proven nicely with Ferrer's diagrams.</p><p>Fast forward to 2021:</p><p>2021: My TA Emily  needs a topic to cover in Honors Discrete Math. I have this memory that there were LOTS of theorems about partitions proven with Ferrer's diagrams. We look at many websites on Ferrer diagrams  and  find only TWO examples:</p><p>The numb of partitions of n into k parts is the numb of partitions of n into parts the largest of which is k.</p><p><br/></p><p>The numb of partitions of n into \le k parts is the numb of partitions of n into parts the largest of which is \le k</p><p>We DO find many theorems about partitions such as this corollary to the Rogers-Ramanujan theorem:</p><p>The numb of partitions of n such that adjacent parts differ by at least 2 is the numb of partitions of n such that each partition is either \equiv 1 mod 5 or \equiv 4 mod 5.</p><p>This is a HARD theorem and there is no Ferrer-diagram or other elementary proof. </p><p>SO, I have one MEMORY but the reality seems different. Possibilities:</p><p>1) My memory is wrong. There really are only 2 examples (or some very small number).</p><p>2) There are other examples but I can't find them on the web. I HOPE this is true--- if someone knows of other ways to use Ferrer diagrams to get partition results, please comment. </p><p><br/></p></div>
    </content>
    <updated>2021-04-26T02:01:00Z</updated>
    <published>2021-04-26T02:01:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-05-03T19:20:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5481</id>
    <link href="https://www.scottaaronson.com/blog/?p=5481" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5481#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5481" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">The easiest exercise in the moral philosophy book</title>
    <summary xml:lang="en-US">Peter Singer, in the parable that came to represent his whole worldview and that of the effective altruism movement more generally, asked us to imagine that we could save a drowning child at the cost of jumping into a lake and ruining an expensive new suit. Assuming we’d do that, he argued that we do […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Peter Singer, in the parable that came to represent his whole worldview and that of the effective altruism movement more generally, asked us to imagine that we could save a drowning child at the cost of jumping into a lake and ruining an expensive new suit.  Assuming we’d do that, he argued that we do in fact face an ethically equivalent choice; if we don’t donate most of our income to save children in the Third World, then we need to answer for why, as surely as the person who walked past the kid thrashing in the water.</p>



<p>In this post, I don’t want to take a position on Singer’s difficult but important hypothetical.  I merely want to say: suppose that to save the child, you didn’t even have to jump in the water.  Suppose you just had to toss a life preserver, one you weren’t using.  Or suppose you just had to assure the child that it was OK to grab your life raft that was already in the water.</p>



<p>That, it seems, is the situation that the US and other rich countries will increasingly face with covid vaccines.  What’s happening in India right now looks on track to become a humanitarian tragedy, if it isn’t already.  Even if, as Indian friends tell me, this was a staggering failure of the Modi government, people shouldn’t pay for it with their lives.  And we in the US now have tens of millions of vaccine doses sitting in warehouses unused, for regulatory and vaccine hesitancy reasons—stupidly, but we do.  We’re past the time, in my opinion, when it’s morally obligatory either to use the doses or to give them away.  Anyone in a position to manufacture more vaccines for distribution to poor countries, should also immediately get the intellectual property rights to do so.</p>



<p>I was glad to read, just this weekend, that the US is finally starting to move in the right direction.  I hope it moves faster.</p>



<p>And I’m sorry that this brief post doesn’t contain any information or insight that you can’t find elsewhere.  It just made me feel better to write it, is all.</p></div>
    </content>
    <updated>2021-04-25T20:04:49Z</updated>
    <published>2021-04-25T20:04:49Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-04-25T20:04:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/060</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/060" rel="alternate" type="text/html"/>
    <title>TR21-060 |  Optimal Error Resilience of Adaptive Message Exchange | 

	Raghuvansh Saxena, 

	Klim Efremenko, 

	Gillat Kol</title>
    <summary>We study the error resilience of the message exchange task: Two parties, each holding a private input, want to exchange their inputs. However, the channel connecting them is governed by an adversary that may corrupt a constant fraction of the transmissions. What is the maximum fraction of corruptions that still allows the parties to exchange their inputs? 

For the non-adaptive channel, where the parties must agree in advance on the order in which they communicate, the maximum error resilience was shown to be $\frac{1}{4}$ (see Braverman and Rao, STOC 2011).
The problem was also studied over the adaptive channel, where the order in which the parties communicate may not be predetermined (Ghaffari, Haeupler, and Sudan, STOC 2014; Efremenko, Kol, and Saxena, STOC 2020). These works show that the adaptive channel admits much richer set of protocols but leave open the question of finding its maximum error resilience.

In this work, we show that the maximum error resilience of a protocol for message exchange over the adaptive channel is $\frac{5}{16}$, thereby settling the above question. Our result requires improving both the known upper bounds and the known lower bounds for the problem.</summary>
    <updated>2021-04-25T13:09:50Z</updated>
    <published>2021-04-25T13:09:50Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-05-05T05:37:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/059</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/059" rel="alternate" type="text/html"/>
    <title>TR21-059 |  On One-way Functions from NP-Complete Problems | 

	Yanyi Liu, 

	Rafael Pass</title>
    <summary>We present the first natural $\NP$-complete problem whose average-case hardness w.r.t. the uniform distribution over instances implies the existence of one-way functions (OWF). In fact, we prove that the existence of OWFs is \emph{equivalent} to mild average-case hardness of this $\NP$-complete problem. The problem, which originated in the 1960s, is the \emph{Conditional Time-Bounded Kolmogorov Complexity Problem}: let $K^t(x \mid z)$ be the length of the shortest ``program'' that, given the ``auxiliary input'' $z$, outputs the string $x$ within time $t(|x|)$, and let $\mcktp[t,\zeta]$ be the set of strings $(x,z,k)$ where $|z| = \zeta(|x|)$, $|k| = \log |x|$ and $K^t(x \mid z)&lt; k$, where, for our purposes, a ``program'' is defined as a RAM machine.

Our main results shows that for every polynomial $t(n)\geq n^2$, there exists some polynomial $\zeta$ such that $\mcktp[t,\zeta]$ is $\NP$-complete. We additionally observe that the result of Liu-Pass (FOCS'20) extends to show that for every polynomial $t(n)\geq 1.1n$, and every polynomial $\zeta(\cdot)$, mild average-case hardness of $\mcktp[t,\zeta]$ is equivalent to the existence of OWFs.</summary>
    <updated>2021-04-25T10:26:23Z</updated>
    <published>2021-04-25T10:26:23Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-05-05T05:37:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/058</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/058" rel="alternate" type="text/html"/>
    <title>TR21-058 |  Average-Case Hardness of NP from Exponential Worst-Case Hardness Assumptions | 

	Shuichi Hirahara</title>
    <summary>A long-standing and central open question in the theory of average-case complexity is to base average-case hardness of NP on worst-case hardness of NP.  A frontier question along this line is to prove that PH is hard on average if UP requires (sub-)exponential worst-case complexity.  The difficulty of resolving this question has been discussed from various perspectives based on technical barrier results, such as the limits of black-box reductions and the non-existence of worst-case hardness amplification procedures in PH.

In this paper, we overcome these barriers and resolve the open question by presenting the following main results:

1.  $UP \not\subseteq DTIME(2^{O(n / \log n)})$ implies $DistNP \not\subseteq AvgP$.

2.  $PH \not\subseteq DTIME(2^{O(n / \log n)})$ implies $DistPH \not\subseteq AvgP$.

3.  $NP \not\subseteq DTIME(2^{O(n / \log n)})$ implies $DistNP \not\subseteq Avg_P P$.
Here, $Avg_P P$ denotes P-computable average-case polynomial time, which interpolates average-case polynomial-time and worst-case polynomial-time.  We complement this result by showing that $DistPH \not\subseteq AvgP$ if and only if $DistPH \not\subseteq Avg_P P$.

At the core of all of our results is a new notion of universal heuristic scheme, whose running time is P-computable average-case polynomial time under every polynomial-time samplable distribution.  Our proofs are based on the meta-complexity of time-bounded Kolmogorov complexity: We analyze average-case complexity through the lens of worst-case meta-complexity using a new "algorithmic" proof of language compression and weak symmetry of information for time-bounded Kolmogorov complexity.</summary>
    <updated>2021-04-25T10:22:37Z</updated>
    <published>2021-04-25T10:22:37Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-05-05T05:37:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8089</id>
    <link href="https://windowsontheory.org/2021/04/24/towards-a-theory-of-generalization-in-reinforcement-learning-guest-lecture-by-sham-kakade/" rel="alternate" type="text/html"/>
    <title>Towards a Theory of Generalization in Reinforcement Learning: guest lecture by Sham Kakade</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Scribe notes by Hamza Chaudhry and Zhaolin Ren Previous post: Natural Language Processing – guest lecture by Sasha Rush Next post: TBD. See also all seminar posts and course webpage. See also video of lecture. Lecture slides: Original form: main / bandit analysis. Annotated: main / bandit analysis. Sham Kakade is a professor in the … <a class="more-link" href="https://windowsontheory.org/2021/04/24/towards-a-theory-of-generalization-in-reinforcement-learning-guest-lecture-by-sham-kakade/">Continue reading <span class="screen-reader-text">Towards a Theory of Generalization in Reinforcement Learning: guest lecture by Sham Kakade</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>Scribe notes by <a href="https://pehlevan.seas.harvard.edu/people/hamza-chaudhry">Hamza Chaudhry</a> and Zhaolin Ren</em></p>



<p><strong>Previous post:</strong> <a href="https://windowsontheory.org/2021/04/03/natural-language-processing-guest-lecture-by-sasha-rush/">Natural Language Processing – guest lecture by Sasha Rush</a> <strong>Next post:</strong> TBD. See also <a href="https://windowsontheory.org/category/ml-theory-seminar/">all seminar posts</a> and <a href="https://boazbk.github.io/mltheoryseminar/cs229br.html#plan">course webpage</a>.</p>



<p>See also <a href="https://harvard.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=5d1a4401-6dee-4e49-881c-ad13017f606c">video of lecture</a>. <strong>Lecture slides:</strong> Original form: <a href="http://files.boazbarak.org/misc/mltheory/sham1.pdf">main</a> / <a href="http://files.boazbarak.org/misc/mltheory/sham2.pdf">bandit analysis</a>. Annotated: <a href="http://files.boazbarak.org/misc/mltheory/sham1_ink.pdf">main</a> / <a href="http://files.boazbarak.org/misc/mltheory/sham2_ink.pdf">bandit analysis</a>.</p>



<p><a href="https://homes.cs.washington.edu/~sham/">Sham Kakade</a> is a professor in the Department of Computer Science and the Department of Statistics at the University of Washington, as well as a senior principal researcher at Microsoft Research New York City. He works on the mathematical foundations of machine learning and AI. He is the recipient of the several awards, including the ICML Test of Time Award (2020), the IBM Pat Goldberg best paper award (in 2007), and the INFORMS Revenue Management and Pricing Prize (2014).</p>



<p>Sham is writing a <a href="https://rltheorybook.github.io/">book on the theory of reinforcement learning</a> with Agarwal, Jiang and Sun.</p>



<h2>Introduction:</h2>



<p>Reinforcement learning has found success in a great number of fields because it is a very “natural framework” for interactive learning. It is based around the notion of experimenting with different behaviors in one’s environment and learning from mistakes to identify the optimal strategy. However, there is a lack of understanding regarding how to best optimize reinforcement learning algorithms when there is uncertainty about the agent’s environment and potential rewards. Therefore, it is important to develop a theoretical foundation about this to study generalization in reinforcement learning. The primary question these notes will address is as follows:</p>



<p><strong>What are necessary representational and distributional conditions that enable provably sample-efficient reinforcement learning?</strong></p>



<p>We will answer this question in the following parts.</p>



<ul><li><strong>Part I: Bandits &amp; Linear Bandits</strong> “Bandit problems” correspond to RL where the environment is reset in each step (horizon H=1). This captures the aspect of having an unknown reward function of RL, but does not capture the aspect of a changing environment based on agent’s actions. This part will be based on the papers <a href="https://homes.cs.washington.edu/~sham/papers/ml/bandit_rates.pdf">Dani-Hayes-Kakade 08</a> and <a href="https://arxiv.org/abs/0912.3995">Srinivas-Kakade-Krause-Seeger 10</a></li><li><strong>Part II: Lower Bounds</strong> RL is very much <em>not</em> a solved problem in neither theory nor practice. Even the RL analog of linear regression, when the expected reward is a linear function of the actions, is not solved. We will see that this is for a good reason: there is an exponential lower bound on the number of steps it takes to find a nearly-optimal policy in this case. This part is based on the recent paper <a href="https://arxiv.org/abs/2010.01374">Weisz-Amortila-Szepesvári 20</a> and the follow-up <a href="https://arxiv.org/abs/2103.12690">Wang-Wang-Kakade 21</a></li><li><strong>Interlude:</strong> Do these lower bounds matter in practice?</li><li><strong>Part III: Upper Bounds</strong> Given the lower bound, we see that to get positive results (aka <em>upper bounds</em> on the number of steps) we need to make strong assumptions on the structure of reqards. There have been a number of incomparable such assumptions used, and we will see that there is a way to unify them. This part is based on the recent paper <a href="https://arxiv.org/abs/2103.10897">Du-Kakade-Lee-Lovett-Mahajan-Sun-Wang 21</a></li></ul>



<p>Before all of these parts, we will start by introducing the general framework of Markov Decision Processes (MDPs) and do a quick tour of generalization for static learning and RL.</p>



<h3>Markov Decision Processes: A Framework for Reinforcement Learning</h3>



<p>We have an agent in an environment at state <img alt="s_t" class="latex" src="https://s0.wp.com/latex.php?latex=s_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> that takes some action <img alt="a_t" class="latex" src="https://s0.wp.com/latex.php?latex=a_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> which will observe some reward <img alt="r_{t}" class="latex" src="https://s0.wp.com/latex.php?latex=r_%7Bt%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and update the environment to state <img alt="s_{t+1}" class="latex" src="https://s0.wp.com/latex.php?latex=s_%7Bt%2B1%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<figure class="wp-block-image"><img alt="" src="https://windowsontheory.files.wordpress.com/2021/04/f7a66-17cuaqjq97x1h_sbieavvzg.png"/></figure>



<p>The following are some key terms that we will need throughout the rest of the notes:</p>



<ol><li><em>State Space, Action Space, Policy</em>: We denote the state space as <img alt="\mathcal{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BS%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and the action space as <img alt="\mathcal{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BA%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. A policy <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a mapping from states to actions: <img alt="\pi: \mathcal{S} \to \mathcal{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi%3A+%5Cmathcal%7BS%7D+%5Cto+%5Cmathcal%7BA%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li><strong>Trajectory</strong>: The sequence of states, actions, rewards an agent sees for a horizon of <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> timesteps. <img alt="(s_1, a_1, r_1, s_2, a_2, r_2, \dots, s_{H}, a_{H}, r_{H})" class="latex" src="https://s0.wp.com/latex.php?latex=%28s_1%2C+a_1%2C+r_1%2C+s_2%2C+a_2%2C+r_2%2C+%5Cdots%2C+s_%7BH%7D%2C+a_%7BH%7D%2C+r_%7BH%7D%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li><em>State Value at time <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></em>: The expected cumulative reward starting from state <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and using policy <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> afterwards.</li><li><img alt="V_h^\pi(s) = \mathbb{E} \left[ \sum_{t=h}^{H} r_t \vert s_h = s \right]" class="latex" src="https://s0.wp.com/latex.php?latex=V_h%5E%5Cpi%28s%29+%3D+%5Cmathbb%7BE%7D+%5Cleft%5B+%5Csum_%7Bt%3Dh%7D%5E%7BH%7D+r_t+%5Cvert+s_h+%3D+s+%5Cright%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li><em>State Action Value at time <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></em>: The expected cumulative reward given a state-action tuple <img alt="(s,a)" class="latex" src="https://s0.wp.com/latex.php?latex=%28s%2Ca%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> starting from time <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and using policy <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> afterwards. <img alt="Q_h^\pi(s,a) = \mathbb{E} \left[ \sum_{t=h}^{H} r_t \vert s_h = s, a_h = a \right]" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cpi%28s%2Ca%29+%3D+%5Cmathbb%7BE%7D+%5Cleft%5B+%5Csum_%7Bt%3Dh%7D%5E%7BH%7D+r_t+%5Cvert+s_h+%3D+s%2C+a_h+%3D+a+%5Cright%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li><em>Optimal value and state-value function</em>: we define an optimal policy by <img alt="\pi^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and the associated optimal <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-function and value function by <img alt="Q^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="V^\star" class="latex" src="https://s0.wp.com/latex.php?latex=V%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> respectively (or equivalently, <img alt="Q^{\pi^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=Q%5E%7B%5Cpi%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, <img alt="V^{\pi^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=V%5E%7B%5Cpi%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>). Note that <img alt="Q^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="V^\star" class="latex" src="https://s0.wp.com/latex.php?latex=V%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> can be defined via the Bellman optimality equation as follows:</li></ol>



<p><img alt="V_h^\star(s) = \max_{a \in \mathcal{A}} Q_h^\star(s,a)" class="latex" src="https://s0.wp.com/latex.php?latex=V_h%5E%5Cstar%28s%29+%3D+%5Cmax_%7Ba+%5Cin+%5Cmathcal%7BA%7D%7D+Q_h%5E%5Cstar%28s%2Ca%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><img alt="Q_h^\star(s,a) = \mathbb{E}\left[R_h(s,a) + V_{h+1}^\star(s_{h+1}) \mid s_h = s, a_h = a \right]" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28s%2Ca%29+%3D+%5Cmathbb%7BE%7D%5Cleft%5BR_h%28s%2Ca%29+%2B+V_%7Bh%2B1%7D%5E%5Cstar%28s_%7Bh%2B1%7D%29+%5Cmid+s_h+%3D+s%2C+a_h+%3D+a+%5Cright%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>where we additionally define <img alt="V_{H+1}(s) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=V_%7BH%2B1%7D%28s%29+%3D+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for all <img alt="s \in \mathcal{S}" class="latex" src="https://s0.wp.com/latex.php?latex=s+%5Cin+%5Cmathcal%7BS%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<ol start="6"><li><strong>Goal:</strong> To find a policy <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> that maximizes the cumulative H-step reward <img alt="V_1^\pi(s)" class="latex" src="https://s0.wp.com/latex.php?latex=V_1%5E%5Cpi%28s%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> starting from an initial state <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> with a horizon <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. In the episodic setting, one starts at state <img alt="s_1" class="latex" src="https://s0.wp.com/latex.php?latex=s_1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, acts for <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> steps, and then repeats.</li></ol>



<h3>Challenges in Reinforcement Learning</h3>



<p>There are three main challenges that we face in reinforcement learning</p>



<ol><li><strong>Exploration:</strong> The total size and states of the environment may be unknown.</li><li><em>Credit Assignment:</em> We need to assign rewards to actions even if the rewards are delayed.</li><li><em>Large State/Action Spaces:</em> We face the curse of dimensionality.<ul><li><a href="https://openai.com/blog/learning-dexterity/">OpenAI 2019 Dexterous Robotic Hand Manipulation</a></li></ul><img alt="" src="https://i.imgur.com/PIIli4L.gif"/></li></ol>



<p><strong>We will deal with these problems by framing them in terms of generalization.</strong></p>



<h2>Part 0: A Whirlwind Tour of Generalization</h2>



<h3>Provable Generalization in Supervised Learning</h3>



<p>As we have seen in <a href="https://windowsontheory.org/2021/01/31/a-blitz-through-classical-statistical-learning-theory/">the first lecture of this course</a>, generalization is possible in the supervised learning setting, when the data follows an i.i.d distribution.<br/>Specifically we have the following bound</p>



<blockquote class="wp-block-quote"><p><strong>Occam’s Razor Bound (Finite Hypothesis Class):</strong> To learn a policy that is <img alt="\epsilon-" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon-&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>close to the best policy in a hypothesis class <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we need a number of samples that is <img alt="\mathcal{O} (\log(|\mathcal{F}|) / \epsilon^2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BO%7D+%28%5Clog%28%7C%5Cmathcal%7BF%7D%7C%29+%2F+%5Cepsilon%5E2%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p></blockquote>



<p>This means we can try lots of things on our data to see which hypotheses are <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-best. To handle infinite hypothesis classes, we can replace <img alt="\log |\mathcal{F}|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog+%7C%5Cmathcal%7BF%7D%7C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> with various other “complexity measures” to obtain generalization bounds such as:</p>



<ul><li>VC Dimension: <img alt="\mathcal{O} (\text{VC}(\mathcal{F}) / \epsilon^2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BO%7D+%28%5Ctext%7BVC%7D%28%5Cmathcal%7BF%7D%29+%2F+%5Cepsilon%5E2%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li>Classification (Margin Bounds): <img alt="\mathcal{O} (\text{margin} / \epsilon^2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BO%7D+%28%5Ctext%7Bmargin%7D+%2F+%5Cepsilon%5E2%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li>Linear Regression: <img alt="\mathcal{O}(\text{dimension}/\epsilon^2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BO%7D%28%5Ctext%7Bdimension%7D%2F%5Cepsilon%5E2%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li>Deep Learning: Algorithm also determines the complexity control</li></ul>



<p>Another way to say this is that in all of these cases, we can bound the generalization gap <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> by a quantity of the form <img alt="O(\sqrt{d/n})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7Bd%2Fn%7D%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> where <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is some “complexity measure” of the class <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the number of samples.</p>



<p>One reference for these generalization results in the supervised learning setting is the following <a href="https://www.cs.princeton.edu/courses/archive/fall19/cos597B/lecnotes/bookdraft.pdf">book</a> by Sanjeev Arora and collaborators.</p>



<p>The key enabler of generalization in supervised learning is <em>data reuse</em>. For a given training set, we can in principle simultaneously evaluate the loss of all hypotheses in our class. For example, given the fixed ImageNet dataset, we can evaluate performance on any classifier. As we will see, this is not a property that will always hold in RL (when it does hold, sample-efficient generalization is likely to follow).</p>



<h3>Sample Efficient RL in the Tabular Case with few states and actions (No Generalization involved):</h3>



<p>Consider a tabular MDP setting where <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> , <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> denote the number of states, number of actions and length of the horizon respectively. Suppose we are operating in a setup where <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are both small. Suppose also that the MDP is <strong>unknown</strong>.</p>



<p>Our goal in such a setting is to find a <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-optimal policy <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that <img alt="V_{1}^{\pi}(s_1) \geq V_1^{\pi^\star}(s_1) - \epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=V_%7B1%7D%5E%7B%5Cpi%7D%28s_1%29+%5Cgeq+V_1%5E%7B%5Cpi%5E%5Cstar%7D%28s_1%29+-+%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, where <img alt="s_1" class="latex" src="https://s0.wp.com/latex.php?latex=s_1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the initial state (for concreteness let’s assume it is deterministic), and <img alt="\pi^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is <strong>truly</strong> an optimal policy for this MDP. Since we assume the number of states and actions to be small, it is possible to explore the entire world, and finding such an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-optimal policy is in principle possible. We thus do not have to consider any hypothesis class here (so no generalization involved), and can instead seek to be optimal under all possible mappings from states to actions.</p>



<p>Think for example of the following maze MDP, where the state of the world is the cell the agent is in and the action it can take at each state is a move to each of say 4 neighboring cells. Then, if we are able to get to every state and try every action there, we would have learned the world.</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/BxUuayQ.png"/></figure>



<p>In this particular scenario, randomly exploring the world will allow us to learn the world. However, if we consider a modified random exploration strategy, where the probability of going left is significantly larger (say 5 times larger) than the probability of going right, then it will take exponential time to hit the goal state. In general, even for MDPs with small state and action spaces, a purely random exploration approach may be insufficient, as we may not be exploring the world enough. What alternative approach might we then adopt in order to achieve a sample-efficient learning algorithm?</p>



<blockquote class="wp-block-quote"><p><a href="https://www.cis.upenn.edu/~mkearns/papers/KearnsSinghE3.pdf"><strong>Theorem: (Kearns &amp; Singh ’98)</strong></a>. In the episodic setting, <img alt="poly(S,A,H,1/\epsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=poly%28S%2CA%2CH%2C1%2F%5Cepsilon%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> samples suffice to find an <img alt="\epsilon-" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon-&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>opt policy, where <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the number of states, <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the number of actions, and <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the length of the horizon.</p></blockquote>



<p>The above breakthrough result was the first to demonstrate that learning an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-opt policy is possible using just polynomially many samples. The key idea behind this is optimism and dynamic programming. In proving the result, the authors designed an algorithm called the E<img alt="^3" class="latex" src="https://s0.wp.com/latex.php?latex=%5E3&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> algorithm (Explicit Explore or Exploit). The E<img alt="^3" class="latex" src="https://s0.wp.com/latex.php?latex=%5E3&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> algorithm adopts a model-based approach, and relies on a “plan-to-explore” mechanism. As we act randomly, we will learn some part of the state space, and having learned this region well, we can thus accurately plan to escape it. This is where optimism comes in, since we give ourselves a bonus for escaping a region we know well.</p>



<p>Based on the Kearns and Singh result, there has been a number of followup works on the tabular MDP setting. One line of work seeks to improve on the precise factors in the sample complexity.</p>



<p><strong>Improvements on the sample complexity:</strong></p>



<ul><li><a href="https://jmlr.org/papers/volume3/brafman02a/brafman02a.pdf">A General Polynomial Time Algorithm for Near-Optimal Reinforcement Learning</a> / Brafman-Tennenholtz 2002</li><li><a href="https://homes.cs.washington.edu/~sham/papers/thesis/sham_thesis.html">On the Sample Complexity of Reinforcement Learning</a> – Kakade 2003 (PhD Thesis).</li><li><a href="https://www.jmlr.org/papers/volume11/jaksch10a/jaksch10a.pdf">Near-Optimal Regret Bounds for Reinforcement Learning</a> – Jaksch, Ortner, Auer 2010</li><li><a href="https://arxiv.org/abs/1705.07041">Posterior sampling for reinforcement learning: worst-case regret bounds</a> – Agrawal Jia 2017</li></ul>



<p>Another line of work seeks to show that <a href="https://en.wikipedia.org/wiki/Q-learning">Q-learning</a>, a model-free approach, can also achieve similar polynomial complexity, if an appropriate optimism bonus is incorporated.</p>



<p><strong>Provable Q-Learning (+Bonus)</strong></p>



<ul><li><a href="https://cseweb.ucsd.edu/~ewiewior/06efficient.pdf">PAC Model-Free Reinforcement Learning</a> – Strehl-Li-Wiewiora-Langford-Littman 2006</li><li><a href="https://castlelab.princeton.edu/html/ORF544/Readings/Szepesvari%20-%20Algorithms%20for%20reinforcement%20learning.pdf">Algorithms for Reinforcement Learning</a> – lecture by Szepesv´ari 2009</li><li><a href="https://arxiv.org/abs/1807.03765">Is Q-learning Provably Efficient?</a> – Jin Allen-ZhuBubeck Jordan 2018</li></ul>



<p>As the range and technical depth of the above results demonstrate, even in the relatively simple tabular case, the problem is already challenging, and a precise sharp characterization of sample complexity is even more difficult. The chief source of difficulty is the unknown nature of the world (if the world was known, then we can just run dynamic programming).</p>



<h3>Provable Generalization in RL:</h3>



<p>Ultimately, we want to move beyond small tabular MDPs, where a polynomial dependence in the sample complexity on <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is acceptable, and achieve sample-efficient learning in big problems where the space space could be massive. Think for instance of the game of Go.</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/DNHJgnJ.jpg"/></figure>



<p>In such a setting, requiring polynomially (in <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>) many samples is clearly unacceptable. This gives rise to the following question.</p>



<p><strong>Question 1: Can we find an <img alt="\epsilon-" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon-&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>opt policy with no <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> dependence?</strong></p>



<p>In order to do so, it is necessary to reutilize data in some way since we will not be able to see all the possible states in the world. How then might we reuse data to estimate the value of all policies in a policy class <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>? A naive approach is the following:</p>



<ul><li>Idea: Trajectory tree algorithm</li><li>Dataset Collection: Choose actions uniformly at random for all H steps in an episode.</li><li>Estimation: Uses importance sampling to evaluate every <img alt="f \in \mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</li></ul>



<blockquote class="wp-block-quote"><p><a href="https://www.cis.upenn.edu/~mkearns/papers/traj.pdf"><strong>Theorem: (Kearns, Mansour, &amp; Ng ’00)</strong></a> To find an <img alt="\epsilon-" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon-&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>best in class policy, the trajectory tree algorithm uses <img alt="O(A^H\log(|\mathcal{F}|)/\epsilon^2)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28A%5EH%5Clog%28%7C%5Cmathcal%7BF%7D%7C%29%2F%5Cepsilon%5E2%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> samples.</p></blockquote>



<p>Observe that when <img alt="H = 1" class="latex" src="https://s0.wp.com/latex.php?latex=H+%3D+1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> (i.e. a contextual bandit) this is exactly the kind of generalization bound we saw in the Occam Razor’s bound for supervised learning. Since there may be stochasticity in the MDP, such that <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> could be infinite or even uncountable, this dependence on <img alt="A^H" class="latex" src="https://s0.wp.com/latex.php?latex=A%5EH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a genuine improvement on the results for the tabular MDP setting which depended polynomially on <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. In this sense, this really is a generalization result, since we are learning an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-best in class policy without having seen the entire world (i.e. all the states in the world).<br/>We note that the result only has <img alt="\log(\mathcal{F}|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog%28%5Cmathcal%7BF%7D%7C%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> dependence on hypothesis class size and similar to the supervised learning setting, there are VC analogues as well. However, we can not avoid the <img alt="A^H" class="latex" src="https://s0.wp.com/latex.php?latex=A%5EH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> dependence to find an <img alt="\epsilon-" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon-&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>best-in-class policy agnostically (without assumptions on the MDP). To see why, consider a binary tree with <img alt="2^H" class="latex" src="https://s0.wp.com/latex.php?latex=2%5EH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-policies and a sparse reward at a leaf node.</p>



<p>This <img alt="A^H" class="latex" src="https://s0.wp.com/latex.php?latex=A%5EH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> dependence, while unavoidable without further assumptions, is clearly undesirable. This brings us to the following question.</p>



<p><strong>Question 2: Can we find an <img alt="\epsilon-" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon-&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>opt policy with no <img alt="S,A" class="latex" src="https://s0.wp.com/latex.php?latex=S%2CA&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> dependence and <img alt="poly(H,1/ \epsilon, \text{&quot;complexity measure&quot;})" class="latex" src="https://s0.wp.com/latex.php?latex=poly%28H%2C1%2F+%5Cepsilon%2C+%5Ctext%7B%22complexity+measure%22%7D%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> samples?</strong></p>



<p>As we just saw, agnostically we cannot learn an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-best-in-class policy without an <img alt="A^H" class="latex" src="https://s0.wp.com/latex.php?latex=A%5EH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> dependence. However, as we will see it is possible when appropriate assumptions are made. But what is the nature of the assumptions under which this kind of sample-efficient RL generalization is possible (when there is no (or mild) dependence on <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>)? What assumptions are necessary? What assumptions are sufficient? We will seek to address these questions.</p>



<p>To do so, we start simple, and first look at the bandits and linear bandits problem, where the horizon <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is just 1. Note that this is still an interactive learning problem, just that we reset the episode after one time-step, and that it is an example of a problem with a potentially large action space.</p>



<h2>Part 1: Bandits and Linear Bandits</h2>



<h3>Multi-Armed Bandits:</h3>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/LHEqOwn.png"/></figure>



<p>The multi-armed bandits algorithm is intimately interwoven with the theory of reinforcement learning. It is based around the question of how to allocate T tokens to A “arms” to maximize one’s return:</p>



<ul><li><a href="https://www.ams.org/journals/bull/1952-58-05/S0002-9904-1952-09620-8/S0002-9904-1952-09620-8.pdf">Some Aspects of the Sequential Design of Experiments</a> – Robbins 1952</li><li><a href="https://people.eecs.berkeley.edu/~russell/classes/cs294/s11/readings/Gittins:1979.pdf">Bandit Processes and Dynamic Allocations Indices</a> – Gittins 1979</li><li><a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.674.1620&amp;rep=rep1&amp;type=pdf">Asymptotically Efficient Adaptive Allocation Rules</a> – Lai and Robbins 1985</li></ul>



<p>It is a very successful algorithm when <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is small. What can we do when <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is large?</p>



<h4>Large-Action Case:</h4>



<p>The bandits have to make a decision regarding which arm to pull. There is a widely used linear formulation of this problem that will assist us in understanding generalization. The <a href="http://phillong.info/publications/peval.pdf">linear bandit model</a> is successful in many applications (scheduling, ads, etc.)</p>



<p><strong>Linear (RKHS) Bandits:</strong></p>



<ul><li>Decision: <img alt="x_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>; Reward: <img alt="r_t" class="latex" src="https://s0.wp.com/latex.php?latex=r_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>; Reward model:<br/><img alt="r_t = f(x_t) + \text{noise}; f(x) = w^\star \cdot \phi(x)" class="latex" src="https://s0.wp.com/latex.php?latex=r_t+%3D+f%28x_t%29+%2B+%5Ctext%7Bnoise%7D%3B+f%28x%29+%3D+w%5E%5Cstar+%5Ccdot+%5Cphi%28x%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li>The hypothesis class <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a set of linear/RKHS functions (an overview of RKHS, which stands for Reproducing Kernel Hilbert Space, can be found <a href="https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space">here</a>).</li></ul>



<h4>Linear/Gaussian Process Upper Confidence Bounds (UCB):</h4>



<p>The principle underlying the Linear Bandits algorithm is <strong>optimism in the face of uncertainty</strong>:<br/>Pick an input that maximizes the upper confidence bound:</p>



<p><img alt="x_t = \text{arg}\max_{x \in D} \mu_{t-1}(x) + \beta_t \sigma_{t-1}(x)." class="latex" src="https://s0.wp.com/latex.php?latex=x_t+%3D+%5Ctext%7Barg%7D%5Cmax_%7Bx+%5Cin+D%7D+%5Cmu_%7Bt-1%7D%28x%29+%2B+%5Cbeta_t+%5Csigma_%7Bt-1%7D%28x%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Note that <img alt="\mu_{t-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu_%7Bt-1%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the best estimate of the ground-truth and <img alt="\sigma_{t-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma_%7Bt-1%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a standard deviation that we have to estimate. In choosing the term <img alt="\beta_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have to navigate a trade-off between exploration and exploitation. As we can see, this algorithm will only pick plausible maximizers.</p>



<h4>Regret of Linear-UCB / Gaussian Process-UCB (Generalization in Action Space)</h4>



<blockquote class="wp-block-quote"><p><strong><a href="http://people.cs.uchicago.edu/~varsha/pubs/stoch_bandit.pdf">Theorem: (Dani, Hayes, &amp; K. ’08)</a>, <a href="https://arxiv.org/pdf/0912.3995.pdf">(Srinivas, Krause, K., &amp; Seeger ’10)</a></strong>. Assuming <img alt="\mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is an RKHS (with bounded norm), if we choose <img alt="\beta_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> “correctly”, then the regret satisfies<br/><img alt="\frac{1}{T} \sum_{t=1}^T[f(x^\star) - f(x_t)] = \tilde{\mathcal{O}} \left( \sqrt{\frac{\gamma_T}{T}} \right)," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7BT%7D+%5Csum_%7Bt%3D1%7D%5ET%5Bf%28x%5E%5Cstar%29+-+f%28x_t%29%5D+%3D+%5Ctilde%7B%5Cmathcal%7BO%7D%7D+%5Cleft%28+%5Csqrt%7B%5Cfrac%7B%5Cgamma_T%7D%7BT%7D%7D+%5Cright%29%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/>where <img alt="\tilde{\mathcal{O}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7B%5Cmathcal%7BO%7D%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> hides logarithmic terms, and </p></blockquote>



<figure class="wp-block-image size-large"><a href="https://windowsontheory.files.wordpress.com/2021/04/image.png"><img alt="" class="wp-image-8095" src="https://windowsontheory.files.wordpress.com/2021/04/image.png?w=1024"/></a></figure>



<p>The key complexity concept here is “Maximum Information Gain”: <img alt="\gamma_T" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma_T&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, which one can think of as the “effective dimension,” determines the regret because <img alt="\gamma_T \approx d \log T" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma_T+%5Capprox+d+%5Clog+T&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> in <img alt="\mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Here are some relevant papers for further understanding regret, which is the difference between the reward of a possible action and the reward of an action that has been taken.</p>



<ul><li><a href="https://homes.di.unimi.it/cesa-bianchi/Pubblicazioni/ml-02.pdf">Finite-time Analysis of the Multiarmed Bandit Problem</a> – Auer Cesa-Bianchi Fischer 2002</li><li><a href="https://papers.nips.cc/paper/2011/file/e1d5be1c7f2f456670de3d53c7b54f4a-Paper.pdf">Improved Algorithms for Linear Stochastic Bandits</a> – Abbasi-yadkori, Pál, Szepesvári 2011</li></ul>



<h3>Linear Upper Confidence Bound Analysis</h3>



<h4>Handling Large Action Spaces</h4>



<p>On each round, we must choose a decision <img alt="x_t \in D \subset R^d" class="latex" src="https://s0.wp.com/latex.php?latex=x_t+%5Cin+D+%5Csubset+R%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. This yields a reward <img alt="r_t \in [-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=r_t+%5Cin+%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, where</p>



<p><img alt="\mathbb{E}[r_t | x_t = x] = \mu^\star \cdot x \in [-1,1]." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D%5Br_t+%7C+x_t+%3D+x%5D+%3D+%5Cmu%5E%5Cstar+%5Ccdot+x+%5Cin+%5B-1%2C1%5D.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Above, <img alt="\mu^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is an unknown weight vector and <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> may be replaced by <img alt="\phi(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28x%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> if we have access to such a representation. Note that this tells us that the conditional expectation of <img alt="r_t" class="latex" src="https://s0.wp.com/latex.php?latex=r_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> upon <img alt="x_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is linear. We have the a corresponding i.i.d. noise sequence <img alt="\eta_t = r_t - \mu^\star \cdot x_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ceta_t+%3D+r_t+-+%5Cmu%5E%5Cstar+%5Ccdot+x_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. If <img alt="(x_0, \dots, x_{T-1})" class="latex" src="https://s0.wp.com/latex.php?latex=%28x_0%2C+%5Cdots%2C+x_%7BT-1%7D%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are our decisions, then our <em>cumulative regret</em> in expectation is</p>



<p><img alt="R_T = T(\mu^\star \cdot x^\star) - \sum_{t=0}^{T - 1} \mu^\star \cdot x_t" class="latex" src="https://s0.wp.com/latex.php?latex=R_T+%3D+T%28%5Cmu%5E%5Cstar+%5Ccdot+x%5E%5Cstar%29+-+%5Csum_%7Bt%3D0%7D%5E%7BT+-+1%7D+%5Cmu%5E%5Cstar+%5Ccdot+x_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>where <img alt="x^\star\in D" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%5Cstar%5Cin+D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is an optimal decision for <img alt="\mu^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, i.e.</p>



<p><img alt="x^\star \in \text{arg}\max_{x \in D} \mu^\star \cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%5Cstar+%5Cin+%5Ctext%7Barg%7D%5Cmax_%7Bx+%5Cin+D%7D+%5Cmu%5E%5Cstar+%5Ccdot+x&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<h4>LinUCB and the Confidence Ball</h4>



<p>After t rounds, we can define our uncertainty region <img alt="\text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> with center <img alt="\hat{\mu_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cmu_t%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and shape <img alt="\Sigma_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> using the <img alt="\lambda-" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda-&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>regularized least squares solution:</p>



<ul><li><img alt="\hat{\mu_t} = \text{arg}\min_\mu \sum_{\tau = 0}^{t-1} \left\| \mu \cdot x_\tau - r_\tau \right\|_2^2 + \lambda \left \| \mu \right\|_2^2," class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cmu_t%7D+%3D+%5Ctext%7Barg%7D%5Cmin_%5Cmu+%5Csum_%7B%5Ctau+%3D+0%7D%5E%7Bt-1%7D+%5Cleft%5C%7C+%5Cmu+%5Ccdot+x_%5Ctau+-+r_%5Ctau+%5Cright%5C%7C_2%5E2+%2B+%5Clambda+%5Cleft+%5C%7C+%5Cmu+%5Cright%5C%7C_2%5E2%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li><img alt="\Sigma_t = \lambda I + \sum_{\tau = 0}^{t-1} x_\tau x_\tau^\top \text{, with } \Sigma_0 = \lambda I," class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma_t+%3D+%5Clambda+I+%2B+%5Csum_%7B%5Ctau+%3D+0%7D%5E%7Bt-1%7D+x_%5Ctau+x_%5Ctau%5E%5Ctop+%5Ctext%7B%2C+with+%7D+%5CSigma_0+%3D+%5Clambda+I%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li><img alt="\text{BALL}_t = \left\{ \mu: (\hat{\mu_t} - \mu)^\top \Sigma_t (\hat{\mu_t} - \mu) \leq \beta_t \right\}," class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BBALL%7D_t+%3D+%5Cleft%5C%7B+%5Cmu%3A+%28%5Chat%7B%5Cmu_t%7D+-+%5Cmu%29%5E%5Ctop+%5CSigma_t+%28%5Chat%7B%5Cmu_t%7D+-+%5Cmu%29+%5Cleq+%5Cbeta_t+%5Cright%5C%7D%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li><img alt="\beta_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a parameter of the algorithm and <img alt="\Sigma_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> determines how accurately we know <img alt="\hat{\mu_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cmu_t%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li></ul>



<p>The LinUCB Algorithm can be understood as follows: For <img alt="t = 0,1,\dots" class="latex" src="https://s0.wp.com/latex.php?latex=t+%3D+0%2C1%2C%5Cdots&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<ol><li>Execute <img alt="x_t = \text{arg}\max_{x \in D} \max_{\mu \in \text{BALL}_t} \mu \cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=x_t+%3D+%5Ctext%7Barg%7D%5Cmax_%7Bx+%5Cin+D%7D+%5Cmax_%7B%5Cmu+%5Cin+%5Ctext%7BBALL%7D_t%7D+%5Cmu+%5Ccdot+x&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li>Observe the reward <img alt="r_t" class="latex" src="https://s0.wp.com/latex.php?latex=r_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and update <img alt="\text{BALL}_{t+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BBALL%7D_%7Bt%2B1%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li></ol>



<h4>LinUCB Regret Bound</h4>



<p>As the following theorem shows, the regret <img alt="R_T \leq \tilde{\mathcal{O} }(d\sqrt T)" class="latex" src="https://s0.wp.com/latex.php?latex=R_T+%5Cleq+%5Ctilde%7B%5Cmathcal%7BO%7D+%7D%28d%5Csqrt+T%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is sublinear with polynomial dependence on <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and no dependence on the cardinality <img alt="|D|" class="latex" src="https://s0.wp.com/latex.php?latex=%7CD%7C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> of the decision space <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<blockquote class="wp-block-quote"><p><a href="https://homes.cs.washington.edu/~sham/papers/ml/bandit_linear_long.pdf"><strong>Theorem (regret): (Dani, Hayes, Kakade 2009)</strong></a>. Suppose we have bounded noise <img alt="|\eta_t|" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Ceta_t%7C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>; <img alt="|| \mu^\star || \leq W" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7C+%5Cmu%5E%5Cstar+%7C%7C+%5Cleq+W&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>; <img alt="||x|| \leq B" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7Cx%7C%7C+%5Cleq+B&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, for <img alt="x\ \in D" class="latex" src="https://s0.wp.com/latex.php?latex=x%5C+%5Cin+D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Set <img alt="\lambda = \sigma^2/W^2, \quad \beta_t := c_1 \sigma^2\left(d \log\left(1 + \frac{TB^2}{d}\right) + \log(1 /\delta)\right)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda+%3D+%5Csigma%5E2%2FW%5E2%2C+%5Cquad+%5Cbeta_t+%3A%3D+c_1+%5Csigma%5E2%5Cleft%28d+%5Clog%5Cleft%281+%2B+%5Cfrac%7BTB%5E2%7D%7Bd%7D%5Cright%29+%2B+%5Clog%281+%2F%5Cdelta%29%5Cright%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> Then, with probability greater than <img alt="1 - \delta" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+%5Cdelta&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, for all <img alt="t \geq 0" class="latex" src="https://s0.wp.com/latex.php?latex=t+%5Cgeq+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>,<br/><img alt="R_T \leq c_2 \sigma \sqrt{T} \left ( d \log\left(1 + \frac{TB^2}{d \sigma^2}\right) + \sqrt{\log(1 /\delta)}\sqrt{d \log\left(1 + \frac{TB^2}{d}\right)} \right)," class="latex" src="https://s0.wp.com/latex.php?latex=R_T+%5Cleq+c_2+%5Csigma+%5Csqrt%7BT%7D+%5Cleft+%28+d+%5Clog%5Cleft%281+%2B+%5Cfrac%7BTB%5E2%7D%7Bd+%5Csigma%5E2%7D%5Cright%29+%2B+%5Csqrt%7B%5Clog%281+%2F%5Cdelta%29%7D%5Csqrt%7Bd+%5Clog%5Cleft%281+%2B+%5Cfrac%7BTB%5E2%7D%7Bd%7D%5Cright%29%7D+%5Cright%29%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/>where <img alt="c_1,c_2" class="latex" src="https://s0.wp.com/latex.php?latex=c_1%2Cc_2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are absolute constants.</p></blockquote>



<p>To prove the regret theorem above, we will require the following two lemmas.</p>



<blockquote class="wp-block-quote"><p><strong>Lemma 1 (Confidence):</strong> Let <img alt="\delta &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We have that <img alt="Pr(\forall t, \mu^\star \in \text{BALL}_t) \geq 1 - \delta." class="latex" src="https://s0.wp.com/latex.php?latex=Pr%28%5Cforall+t%2C+%5Cmu%5E%5Cstar+%5Cin+%5Ctext%7BBALL%7D_t%29+%5Cgeq+1+-+%5Cdelta.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p><p><strong>Lemma 2 (Sum of Squares Regret Bound):</strong> Define <img alt="\text{regret}_t = \mu^\star \cdot x^\star - \mu^\star \cdot x_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bregret%7D_t+%3D+%5Cmu%5E%5Cstar+%5Ccdot+x%5E%5Cstar+-+%5Cmu%5E%5Cstar+%5Ccdot+x_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Suppose <img alt="\beta_t \geq 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_t+%5Cgeq+1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is increasing and that for all <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have <img alt="\mu^\star \in \text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar+%5Cin+%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Then, <img alt="\sum_{t=0}^{T-1} \text{regret}_t^2 \leq 8 \beta_T d \log \left ( 1 + \frac{TB^2}{d\lambda} \right )." class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bt%3D0%7D%5E%7BT-1%7D+%5Ctext%7Bregret%7D_t%5E2+%5Cleq+8+%5Cbeta_T+d+%5Clog+%5Cleft+%28+1+%2B+%5Cfrac%7BTB%5E2%7D%7Bd%5Clambda%7D+%5Cright+%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p>We note that Lemma 2 actually depends on Lemma 1, since it assumes that <img alt="\mu^\star \in \text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar+%5Cin+%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for each <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, a property that Lemma 1 tells us happens with probability at least <img alt="1-\delta" class="latex" src="https://s0.wp.com/latex.php?latex=1-%5Cdelta&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We defer the proofs of the two lemmas to later, and first show why they can be used to prove the regret theorem.</p>



<p><strong>Proof of regret theorem:</strong> Using the two lemmas above along with the Cauchy-Schwarz inequality, we have with probability at least <img alt="1 - \delta" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+%5Cdelta&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> that</p>



<p><img alt="R_T = \sum_{t=0}^{T-1} \text{regret}_t \leq \sqrt{T \sum{t=0}^{T-1} \text{regret}_t^2} \leq \sqrt{8 T \beta_T d \log \left( 1 + \frac{TB^2}{d\lambda} \right)}." class="latex" src="https://s0.wp.com/latex.php?latex=R_T+%3D+%5Csum_%7Bt%3D0%7D%5E%7BT-1%7D+%5Ctext%7Bregret%7D_t+%5Cleq+%5Csqrt%7BT+%5Csum%7Bt%3D0%7D%5E%7BT-1%7D+%5Ctext%7Bregret%7D_t%5E2%7D+%5Cleq+%5Csqrt%7B8+T+%5Cbeta_T+d+%5Clog+%5Cleft%28+1+%2B+%5Cfrac%7BTB%5E2%7D%7Bd%5Clambda%7D+%5Cright%29%7D.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>The rest of the proof follows from our chosen value of <img alt="\beta_T" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_T&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>We now proceed to sketch out the proofs of Lemma 1 (confidence bound) and Lemma 2 (sum of squares regret bound). We begin with showing why Lemma 2 holds.</p>



<h4>Analysis and proof of Lemma 2 (sum of squares regret bound)</h4>



<p>Our first auxilliary result bounds the pointwise width of the confidence ball.</p>



<blockquote class="wp-block-quote"><p><strong>Lemma (pointwise width of confidence ball)</strong>. Let <img alt="x \in D" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Consider any <img alt="\mu \in \text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu+%5Cin+%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Then,<br/><img alt="| (\mu - \hat{\mu}_t)^\top x| \leq \sqrt{\beta_t x^\top \Sigma_t^{-1}x}." class="latex" src="https://s0.wp.com/latex.php?latex=%7C+%28%5Cmu+-+%5Chat%7B%5Cmu%7D_t%29%5E%5Ctop+x%7C+%5Cleq+%5Csqrt%7B%5Cbeta_t+x%5E%5Ctop+%5CSigma_t%5E%7B-1%7Dx%7D.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p><em><strong>Proof</strong></em>. We have</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/ghNhZRo.png"/></figure>



<p>where the first inequality follows from Cauchy-Schwarx and the second (i.e last) inequality holds by the definition of <img alt="\text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and our assumption that <img alt="\mu \in \text{BALL}_t." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu+%5Cin+%5Ctext%7BBALL%7D_t.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Let us now define</p>



<p><img alt="w_t := \sqrt{x_t^\top \Sigma_t^{-1}x_t}," class="latex" src="https://s0.wp.com/latex.php?latex=w_t+%3A%3D+%5Csqrt%7Bx_t%5E%5Ctop+%5CSigma_t%5E%7B-1%7Dx_t%7D%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>which we can think of as the “normalized width” at time <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> in the direction of our decision. We have the following bound on the instantaneous regret <img alt="\text{regret}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bregret%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<blockquote class="wp-block-quote"><p><strong>Lemma (instantaneous regret lemma)</strong>. Fix <img alt="t \leq T" class="latex" src="https://s0.wp.com/latex.php?latex=t+%5Cleq+T&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. If <img alt="\mu^\star \in \text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar+%5Cin+%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, then<br/><img alt="\text{regret}_t \leq 2 \min (\sqrt{\beta_t}w_t, 1) \leq 2 \sqrt{\beta_t} \min(w_t,1)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bregret%7D_t+%5Cleq+2+%5Cmin+%28%5Csqrt%7B%5Cbeta_t%7Dw_t%2C+1%29+%5Cleq+2+%5Csqrt%7B%5Cbeta_t%7D+%5Cmin%28w_t%2C1%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p><em><strong>Proof</strong></em>. The basic idea is to use “optimism”. Let <img alt="\tilde{\mu} \in \text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7B%5Cmu%7D+%5Cin+%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> denote the vector maximizing the dot product <img alt="\hat{\mu}^\top x_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cmu%7D%5E%5Ctop+x_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. By choice of <img alt="x_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, <img alt="\tilde{\mu}^\top x_t = \max{\mu \in \text{BALL}_t} \max_{x \in D}\mu^\top x \geq (\mu^\star)^\top x^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7B%5Cmu%7D%5E%5Ctop+x_t+%3D+%5Cmax%7B%5Cmu+%5Cin+%5Ctext%7BBALL%7D_t%7D+%5Cmax_%7Bx+%5Cin+D%7D%5Cmu%5E%5Ctop+x+%5Cgeq+%28%5Cmu%5E%5Cstar%29%5E%5Ctop+x%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, where the inequality used the hypothesis that <img alt="\mu^\star \in \text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar+%5Cin+%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. This manifestation of “optimism” is crucial, since it tells us that the “ideal” reward we think we can get at time <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> exceeds the optimal expected reward <img alt="(\mu^\star)^\top x^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cmu%5E%5Cstar%29%5E%5Ctop+x%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Hence,</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/CO4lDFc.png"/></figure>



<p>where the last step follows from the pointwise width lemma (note <img alt="\tilde{\mu}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctilde%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is in <img alt="\text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="\mu^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is assumed to be <img alt="\text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> by the hypothesis in Lemma 2). Since in the linear bandits setup we assumed that <img alt="\mu^\star \cdot x \in [-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar+%5Ccdot+x+%5Cin+%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for all <img alt="x \in D" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the simple bound <img alt="\text{regret}_t \leq 2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bregret%7D_t+%5Cleq+2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> holds as well. We may also assume for simplicity that <img alt="\beta_t \geq 1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_t+%5Cgeq+1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. This then yields the bound in the result. <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>In the next two lemmas, we use a geometric potential function argument to bound the sum of widths independently of the choices made by the algorithm (e.g. choice of <img alt="\lambda" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="{\beta_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta_t%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> sequence).</p>



<blockquote class="wp-block-quote"><p><strong>Geometric Lemma 1</strong>. We have <img alt="\det(\Sigma_T) = \det(\Sigma_0) \prod_{t=0}^{T-1} (1+w_t^2)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdet%28%5CSigma_T%29+%3D+%5Cdet%28%5CSigma_0%29+%5Cprod_%7Bt%3D0%7D%5E%7BT-1%7D+%281%2Bw_t%5E2%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p><em><strong>Proof</strong></em>. By definition of <img alt="\Sigma_{t+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma_%7Bt%2B1%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/qX7Q3Ft.png"/></figure>



<p>We complete the proof by noting that <img alt="w_t^2 = x_t^\top \Sigma_t^{-1}x_t = |\Sigma_t^{-1/2}x_t |^2" class="latex" src="https://s0.wp.com/latex.php?latex=w_t%5E2+%3D+x_t%5E%5Ctop+%5CSigma_t%5E%7B-1%7Dx_t+%3D+%7C%5CSigma_t%5E%7B-1%2F2%7Dx_t+%7C%5E2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<blockquote class="wp-block-quote"><p><strong>Geometric Lemma 2</strong>. For any sequence <img alt="x_0,\dots,x_{T-1}" class="latex" src="https://s0.wp.com/latex.php?latex=x_0%2C%5Cdots%2Cx_%7BT-1%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that for <img alt="t &lt; T" class="latex" src="https://s0.wp.com/latex.php?latex=t+%3C+T&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, <img alt="|x_t|_2 \leq B" class="latex" src="https://s0.wp.com/latex.php?latex=%7Cx_t%7C_2+%5Cleq+B&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have<br/><img alt="\log\left(\det(\Sigma_{T-1})/\det(\Sigma_0)\right) = \log \det \left(I + \frac{1}{\gamma} \sum_{t=0}^{T-1} x_tx_t^\top \right) \leq d \log \left(1 + \frac{TB^2}{d\lambda}\right)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog%5Cleft%28%5Cdet%28%5CSigma_%7BT-1%7D%29%2F%5Cdet%28%5CSigma_0%29%5Cright%29+%3D+%5Clog+%5Cdet+%5Cleft%28I+%2B+%5Cfrac%7B1%7D%7B%5Cgamma%7D+%5Csum_%7Bt%3D0%7D%5E%7BT-1%7D+x_tx_t%5E%5Ctop+%5Cright%29+%5Cleq+d+%5Clog+%5Cleft%281+%2B+%5Cfrac%7BTB%5E2%7D%7Bd%5Clambda%7D%5Cright%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p><em><strong>Proof</strong></em>. Denote the eigenvalues of <img alt="\sum_{t=0}^{T-1}x_tx_t^\top" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bt%3D0%7D%5E%7BT-1%7Dx_tx_t%5E%5Ctop&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> as <img alt="\sigma_1,\dots,\sigma_d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma_1%2C%5Cdots%2C%5Csigma_d&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and note<br/><img alt="\sum_{i=1}^d \sigma_i = \text{Trace}\left(\sum_{t=0}^{T-1} x_t x_t^\top \right) = \sum_{t=0}^{T-1} |x_t|^2 \leq TB^2." class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum_%7Bi%3D1%7D%5Ed+%5Csigma_i+%3D+%5Ctext%7BTrace%7D%5Cleft%28%5Csum_%7Bt%3D0%7D%5E%7BT-1%7D+x_t+x_t%5E%5Ctop+%5Cright%29+%3D+%5Csum_%7Bt%3D0%7D%5E%7BT-1%7D+%7Cx_t%7C%5E2+%5Cleq+TB%5E2.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/>Using the AM-GM inequality,</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/jQDxDYm.png"/></figure>



<p>We are now finally ready to prove Lemma 2 (sum of squares regret bound).</p>



<p><strong>Proof of Lemma 2 (sum of squares regret bound)</strong>.<br/>Assume <img alt="\mu^\star \in \text{BALL}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar+%5Cin+%5Ctext%7BBALL%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for all <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We have<br/><img alt="" src="https://i.imgur.com/1rzWWOT.png"/></p>



<p>where the first inequality follows from the instantaneous regret lemma, the second from that <img alt="\beta_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is an increasing function of <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the third uses the fact that for <img alt="0 \leq y \leq 1, \ln(1+y) \geq y/2" class="latex" src="https://s0.wp.com/latex.php?latex=0+%5Cleq+y+%5Cleq+1%2C+%5Cln%281%2By%29+%5Cgeq+y%2F2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the final equality holds by Geometric Lemma 1, and the final inequality follows from Geometric Lemma 2. <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>This wraps up our discussion of Lemma 2.</p>



<h4>Analysis of Lemma 1 (Confidence bound)</h4>



<p>Recall that our goal here is to show that <img alt="\mu^\star \in \text{Ball}_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu%5E%5Cstar+%5Cin+%5Ctext%7BBall%7D_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> with high probability. We begin with the following result, which is a general version of the self-normalized sum argument in <a href="https://homes.cs.washington.edu/~sham/papers/ml/bandit_linear_long.pdf">Dani, Hayes, Kakade 2009</a>.</p>



<blockquote class="wp-block-quote"><p><strong>Lemma (Self-normalized bound for vector-valued Martingalues, <a href="https://arxiv.org/abs/1102.2670">Abbasi et al. 2011</a>)</strong>. Suppose <img alt="{\epsilon_i}_{i=1}^{\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_i%7D_%7Bi%3D1%7D%5E%7B%5Cinfty%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are mean zero random variables (can be generalized to martingalues), and <img alt="\epsilon_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon_i&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is bounded by <img alt="\sigma" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csigma&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Let <img alt="{X_i}_{i=1}^{\infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX_i%7D_%7Bi%3D1%7D%5E%7B%5Cinfty%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> be a stochastic process. Define <img alt="\Sigma_t := \Sigma_0 + \sum_{i=1}^t X_i X_i^\top" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma_t+%3A%3D+%5CSigma_0+%2B+%5Csum_%7Bi%3D1%7D%5Et+X_i+X_i%5E%5Ctop&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. With probability at least <img alt="1 - \delta" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+%5Cdelta&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have for all <img alt="t \geq 1" class="latex" src="https://s0.wp.com/latex.php?latex=t+%5Cgeq+1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>,<br/><img alt="\left|\sum_{t=1}^t X_i \epsilon_i \right|_{\Sigma_t^{-1}}^2 \leq \sigma^2 \log \left(\frac{\det(\Sigma_t)\det(\Sigma_0)^{-1}}{\delta^2} \right)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Csum_%7Bt%3D1%7D%5Et+X_i+%5Cepsilon_i+%5Cright%7C_%7B%5CSigma_t%5E%7B-1%7D%7D%5E2+%5Cleq+%5Csigma%5E2+%5Clog+%5Cleft%28%5Cfrac%7B%5Cdet%28%5CSigma_t%29%5Cdet%28%5CSigma_0%29%5E%7B-1%7D%7D%7B%5Cdelta%5E2%7D+%5Cright%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p>Equipped with the lemma above, we are now ready to prove Lemma 1, which we will restate here again.</p>



<blockquote class="wp-block-quote"><p><strong>Lemma 1 (Confidence):</strong> Let <img alt="\delta &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We have that <img alt="Pr(\forall t, \mu^\star \in \text{BALL}_t) \geq 1 - \delta." class="latex" src="https://s0.wp.com/latex.php?latex=Pr%28%5Cforall+t%2C+%5Cmu%5E%5Cstar+%5Cin+%5Ctext%7BBALL%7D_t%29+%5Cgeq+1+-+%5Cdelta.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p><strong>Proof of Lemma 1</strong>. Since <img alt="r_{\tau} = x_{\tau}\cdot \mu^\star + \eta_{\tau}" class="latex" src="https://s0.wp.com/latex.php?latex=r_%7B%5Ctau%7D+%3D+x_%7B%5Ctau%7D%5Ccdot+%5Cmu%5E%5Cstar+%2B+%5Ceta_%7B%5Ctau%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have<br/><img alt="" src="https://i.imgur.com/fsVT5QQ.png"/></p>



<p>To get the last equality, we recall that <img alt="\Sigma_t = \lambda I + \sum_{\tau=0}^{t-1}\eta_{\tau}x_{\tau}" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma_t+%3D+%5Clambda+I+%2B+%5Csum_%7B%5Ctau%3D0%7D%5E%7Bt-1%7D%5Ceta_%7B%5Ctau%7Dx_%7B%5Ctau%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. By the triangle inequality, it follows that we have</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/8Pr0zPB.png"/></figure>



<p>where the last inequality holds with probability at least <img alt="1 - \delta" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+%5Cdelta&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for every <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, using the self-normalized bound above, as well as the fact that <img alt="\Sigma_t^{-1/2} \leq 1/\sqrt{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%5CSigma_t%5E%7B-1%2F2%7D+%5Cleq+1%2F%5Csqrt%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Since <img alt="(|v_1 | + |v_2|)^2 \leq 2|v_1|^2 + 2|v_2|^2" class="latex" src="https://s0.wp.com/latex.php?latex=%28%7Cv_1+%7C+%2B+%7Cv_2%7C%29%5E2+%5Cleq+2%7Cv_1%7C%5E2+%2B+2%7Cv_2%7C%5E2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for any vectors <img alt="v_1,v_2" class="latex" src="https://s0.wp.com/latex.php?latex=v_1%2Cv_2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, it follows that with probability at least <img alt="1 - \delta" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+%5Cdelta&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, for every <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>,<br/><img alt="" src="https://i.imgur.com/TS18lfK.png"/></p>



<p>where the final inequality is a consequence of the choice <img alt="\lambda = \sigma^2/W^2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda+%3D+%5Csigma%5E2%2FW%5E2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> in the algorithm (where we recall the upper bound <img alt="|\mu^\star| \leq W" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmu%5E%5Cstar%7C+%5Cleq+W&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>), as well as Geometric Lemma 2. The result then follows by our choice of <img alt="\beta_t" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_t&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, which is</p>



<p><img alt="\beta_t := c_1 \sigma^2\left(d \log\left(1 + \frac{TB^2}{d\lambda}\right) + \log(1 /\delta)\right)," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta_t+%3A%3D+c_1+%5Csigma%5E2%5Cleft%28d+%5Clog%5Cleft%281+%2B+%5Cfrac%7BTB%5E2%7D%7Bd%5Clambda%7D%5Cright%29+%2B+%5Clog%281+%2F%5Cdelta%29%5Cright%29%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>where <img alt="c_1" class="latex" src="https://s0.wp.com/latex.php?latex=c_1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is an absolute constant (note in doing so we also subsumed the <img alt="2\sigma^2" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Csigma%5E2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> term, simplifying the exposition). <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>We move on now to more challenging RL problems where the horizon <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is larger than 1, and explore lower bounds in this regime.</p>



<h2>Part 2: What are necessary assumptions for generalization in RL?</h2>



<h3>Approximate dynamic programming with linear function approximation</h3>



<p>We begin by considering generalization with a very natural assumption: suppose that the value function <img alt="Q(s,a)" class="latex" src="https://s0.wp.com/latex.php?latex=Q%28s%2Ca%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> can be approximated by linear basis functions</p>



<p><img alt="\phi(s,a) = (\phi_1(s,a),\dots,\phi_d(s,a)), \quad \phi(s,a) \in \mathbb{R}^d." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28s%2Ca%29+%3D+%28%5Cphi_1%28s%2Ca%29%2C%5Cdots%2C%5Cphi_d%28s%2Ca%29%29%2C+%5Cquad+%5Cphi%28s%2Ca%29+%5Cin+%5Cmathbb%7BR%7D%5Ed.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>We assume that the dimension of the representation, <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, is low compared the state and action dimensions. The idea of using a linear function approximation in RL and dynamic programming is not new, and had been explored in early works by Shannon (<a href="https://vision.unipv.it/IA1/ProgrammingaComputerforPlayingChess.pdf">“Programming a digital computer for playing chess.”, Philosophical Magazine, 1950</a>) as well as Bellman and Dreyfus (<a href="https://www.rand.org/content/dam/rand/pubs/papers/2006/P1176.pdf">“Functional approximations and dynamic programming”, 1959</a>). There has also since been significant work on this approach, see e.g. <a href="https://dl.acm.org/doi/10.1145/203330.203343">Tesauro 1995</a>, <a href="http://www.mit.edu/~pucci/discountedLP.pdf">de Farias and Van Roy 2003</a>, <a href="https://arxiv.org/abs/1307.4847">Wen and Van Roy 2013</a>.</p>



<p>One natural question that arises is this: <strong>what conditions must the representation <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> satisfy in order for this approach to work?</strong></p>



<p>We proceed by studying the simplest possible case: assuming that the optimal <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-function <img alt="Q_h^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is linearly realizable.</p>



<h4>RL with linearly realizable <img alt="Q_h^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> function approximation: does there exist a sample efficient algorithm?</h4>



<p>Suppose we have access to a feature map <img alt="\phi(s,a) \in \mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28s%2Ca%29+%5Cin+%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Concretely, the assumption we consider is the following:</p>



<blockquote class="wp-block-quote"><p><strong>Assumption 1 (Linearly realizable <img alt="Q_h^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>)</strong>: Assume for all <img alt="s,a,h \in [H]" class="latex" src="https://s0.wp.com/latex.php?latex=s%2Ca%2Ch+%5Cin+%5BH%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> that there exists <img alt="w_1^\star,\dots,w_H^\star \in \mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=w_1%5E%5Cstar%2C%5Cdots%2Cw_H%5E%5Cstar+%5Cin+%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that<br/><img alt="Q_h^\star(s,a) = w_h^\star \cdot \phi(s,a)." class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28s%2Ca%29+%3D+w_h%5E%5Cstar+%5Ccdot+%5Cphi%28s%2Ca%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p>As an aside, with Assumption 1, we can consider the problem from a linear programming viewpoint. Note that:</p>



<ul><li>We have an underlying LP with <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> variables and <img alt="O(SA)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28SA%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> constraints.</li><li>The LP is specific to the dynamic programming problem at hand (and hence not general) because it encodes the Bellman optimality constraints.</li><li>We have sampling access (in the episodic setting).</li></ul>



<p>It may be tempting to think that Assumption 1 is sufficient to enable a sample-efficient algorithm for RL (if we assume we already know the representation <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>). However, that is <strong>not</strong> true, as the following theorem from a very recent work demonstrates:</p>



<blockquote class="wp-block-quote"><p><a href="https://arxiv.org/abs/2010.01374"><strong>Theorem 1 (Weisz, Amortila, Szepesvári 2021):</strong></a> There exists an MDP and a representation <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> satisfying Assumption 1, such that any online RL algorithm (with knowledge of <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>) requires <img alt="\Omega(\min(2^d,2^H))" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%28%5Cmin%282%5Ed%2C2%5EH%29%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> samples to output the value <img alt="V_1^\star(s_1)" class="latex" src="https://s0.wp.com/latex.php?latex=V_1%5E%5Cstar%28s_1%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> up to constant additive error, with probability at least 0.9.</p></blockquote>



<p>While linear realizability alone is insufficient for sample efficiency in online RL, one might consider imposing further assumptions that could suffice for sample-efficient RL. One candidate assumption is to assume that at each state, the optimal action yields significantly more value than the next-best action:</p>



<blockquote class="wp-block-quote"><p><strong>Assumption 2 (Large suboptimality gap)</strong>: Assume for all <img alt="a \neq \pi^\star(s)" class="latex" src="https://s0.wp.com/latex.php?latex=a+%5Cneq+%5Cpi%5E%5Cstar%28s%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have<br/><img alt="V_h^\star(s) - Q_h^\star(s,a) \geq \frac{1}{16}." class="latex" src="https://s0.wp.com/latex.php?latex=V_h%5E%5Cstar%28s%29+-+Q_h%5E%5Cstar%28s%2Ca%29+%5Cgeq+%5Cfrac%7B1%7D%7B16%7D.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p>Perhaps surprisingly, the following theorem shows that an exponential lower bound for online RL remains under <strong>both</strong> Assumption 1 and Assumption 2.</p>



<blockquote class="wp-block-quote"><p><a href="https://arxiv.org/abs/2103.12690"><strong>Theorem 2 (Wang, Wang, Kakade 2021):</strong></a> There exists an MDP and a representation <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> satisfying both Assumption 1 and Assumption 2, such that any online RL algorithm (with knowledge of <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>) requires <img alt="\Omega(\min(2^d,2^H))" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%28%5Cmin%282%5Ed%2C2%5EH%29%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> samples to output the value <img alt="V_1^\star(s_1)" class="latex" src="https://s0.wp.com/latex.php?latex=V_1%5E%5Cstar%28s_1%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> up to constant additive error, with probability at least 0.9.</p></blockquote>



<p><em><strong>Remark</strong></em>: We note a subtle distinction between the online RL setting and the simulator access setting. In the online RL setting, during each episode, we start at some state <img alt="s_0" class="latex" src="https://s0.wp.com/latex.php?latex=s_0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and the subsequent states we see are entirely dependent on the policy we choose and the environment dynamics. Meanwhile, in the simulator access setting, at each time-step, we are free to input <strong>any</strong> <img alt="(s,a)" class="latex" src="https://s0.wp.com/latex.php?latex=%28s%2Ca%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> pair, and the simulator will return the next state <img alt="s' \sim P(\cdot \mid s,a)" class="latex" src="https://s0.wp.com/latex.php?latex=s%27+%5Csim+P%28%5Ccdot+%5Cmid+s%2Ca%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, as well as the reward <img alt="r(s,a)" class="latex" src="https://s0.wp.com/latex.php?latex=r%28s%2Ca%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. While Theorem 1 (when only Assumption 1 is satisfied) holds for both online RL and simulator access, Theorem 2 (when both Assumption 1 and Assumption 2 hold) is valid only in the online RL setting. In the simulator access setting, <a href="https://arxiv.org/abs/1910.03016">Du et al. 2019</a> proved that there exists a sample-efficient approach (i.e. polynomial in all relevant problem parameters) to find an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-optimal policy, when both Assumption 1 and Assumption 2 hold. This demonstrates an <em>exponential separation</em> between the online RL and simulator access settings.</p>



<p>We next introduce the counterexample used to prove Theorem 2 in detail.</p>



<h4>Construction sketch for counterexample in Theorem 2</h4>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/ReAcF8x.png"/></figure>



<p>Above, we have a pictorial representation of the MDP family in the counterexample. We first describe its state and action spaces.</p>



<ul><li>The state space is <img alt="{\bar{1},\dots,\bar{m}, f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7B1%7D%2C%5Cdots%2C%5Cbar%7Bm%7D%2C+f%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We use <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> to denote an integer, which we set to be approximately <img alt="2^d" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</li><li>State <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a special state, which we can think of as a “terminal state”.</li><li>At state <img alt="\bar{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbar%7Bi%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the feasible action set is <img alt="[m] \setminus {i}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bm%5D+%5Csetminus+%7Bi%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. At state <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the feasible action set is <img alt="[m-1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bm-1%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Hence, there are <img alt="m-1" class="latex" src="https://s0.wp.com/latex.php?latex=m-1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> feasible actions at each state.</li><li>Each MDP in this “hard” family is specified by an index <img alt="a^\star \in [m]" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar+%5Cin+%5Bm%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and denoted by <img alt="\mathcal{M}_{a^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D_%7Ba%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</li></ul>



<p>Before we proceed, we first recall the Johnson-Lindenstrauss lemma, which states that a set of points in a high-dimensional space can be embedded into a space of much lower dimension in such a way that the distances between the points are nearly preserved.</p>



<blockquote class="wp-block-quote"><p><a href="https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma">Johnson-Lindenstrauss Lemma</a>: Suppose we are given <img alt="0 &lt; \epsilon &lt; 1" class="latex" src="https://s0.wp.com/latex.php?latex=0+%3C+%5Cepsilon+%3C+1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, a set <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> of <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> points in <img alt="\mathbb{R}^N" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5EN&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and a number <img alt="n &gt; 8 \ln m/\epsilon^2" class="latex" src="https://s0.wp.com/latex.php?latex=n+%3E+8+%5Cln+m%2F%5Cepsilon%5E2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Then, there is a linear map <img alt="f \in \mathbb{R}^N \to \mathbb{R}^n" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathbb%7BR%7D%5EN+%5Cto+%5Cmathbb%7BR%7D%5En&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that<br/><img alt="(1-\epsilon)|u-v|^2 \leq |f(u) - f(v)|^2 \leq (1+\epsilon)|u-v|^2." class="latex" src="https://s0.wp.com/latex.php?latex=%281-%5Cepsilon%29%7Cu-v%7C%5E2+%5Cleq+%7Cf%28u%29+-+f%28v%29%7C%5E2+%5Cleq+%281%2B%5Cepsilon%29%7Cu-v%7C%5E2.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p>Consider a collection <img alt="\mathcal{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BX%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> of <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> orthogonal unit vectors in the high-dimensional space <img alt="\mathbb{R}^N" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5EN&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. For any two vectors <img alt="u\neq v \in \mathcal{X}" class="latex" src="https://s0.wp.com/latex.php?latex=u%5Cneq+v+%5Cin+%5Cmathcal%7BX%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, after applying the linear embedding <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we observe by Johnson-Lindenstrauss that</p>



<p><img alt="\pm\left \langle f(u),f(v)\right \rangle= \frac{|f(u) \pm f(v)|^2 - |f(u)|^2 - |f(v)|^2}{2} \leq \frac{2(1+\epsilon) - 2(1-\epsilon)}{2} = 2\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpm%5Cleft+%5Clangle+f%28u%29%2Cf%28v%29%5Cright+%5Crangle%3D+%5Cfrac%7B%7Cf%28u%29+%5Cpm+f%28v%29%7C%5E2+-+%7Cf%28u%29%7C%5E2+-+%7Cf%28v%29%7C%5E2%7D%7B2%7D+%5Cleq+%5Cfrac%7B2%281%2B%5Cepsilon%29+-+2%281-%5Cepsilon%29%7D%7B2%7D+%3D+2%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>where we used the fact that <img alt="(1-\epsilon) \leq |f(u) - 0|^2 = |f(u)|^2\leq (1+\epsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=%281-%5Cepsilon%29+%5Cleq+%7Cf%28u%29+-+0%7C%5E2+%3D+%7Cf%28u%29%7C%5E2%5Cleq+%281%2B%5Cepsilon%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> holds for any unit <img alt="u \in \mathcal{X}" class="latex" src="https://s0.wp.com/latex.php?latex=u+%5Cin+%5Cmathcal%7BX%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> by linearity of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Hence, we can apply Johnson-Lindenstrauss to derive the following lemma, which will be useful in our construction.</p>



<blockquote class="wp-block-quote"><p><a href="https://arxiv.org/pdf/2103.12690.pdf">Lemma 1 (Johnson-Lindenstrauss)</a>: For any <img alt="\gamma &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma+%3E+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, there exists <img alt="m = \left\lfloor\exp\left(\frac{1}{8} \gamma^2 d\right)\right\rfloor" class="latex" src="https://s0.wp.com/latex.php?latex=m+%3D+%5Cleft%5Clfloor%5Cexp%5Cleft%28%5Cfrac%7B1%7D%7B8%7D+%5Cgamma%5E2+d%5Cright%29%5Cright%5Crfloor&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> unit vectors <img alt="{v_1,\dots,v_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_1%2C%5Cdots%2Cv_m%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> in <img alt="\mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that <img alt="\forall i,j \in [m]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+i%2Cj+%5Cin+%5Bm%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="i \neq j" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cneq+j&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, <img alt="|\langle v_i,v_j \rangle| \leq \gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Clangle+v_i%2Cv_j+%5Crangle%7C+%5Cleq+%5Cgamma&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p></blockquote>



<p>Throughout our discussion, we will set <img alt="\gamma := \frac{1}{4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma+%3A%3D+%5Cfrac%7B1%7D%7B4%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<p>Equipped with the lemma above, we can now describe the transitions, features and rewards of the constructed MDP family. In the sequel, <img alt="a_1 \in [m]" class="latex" src="https://s0.wp.com/latex.php?latex=a_1+%5Cin+%5Bm%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="a_2 \in [m]" class="latex" src="https://s0.wp.com/latex.php?latex=a_2+%5Cin+%5Bm%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> represent integers associated with the state and action respectively.</p>



<p><em><strong>Transitions</strong></em>: The initial state <img alt="s_0" class="latex" src="https://s0.wp.com/latex.php?latex=s_0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> follows the uniform distribution <img alt="\mu = \mathrm{Unif}\left({\bar{1},\dots,\bar{m}}\right)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmu+%3D+%5Cmathrm%7BUnif%7D%5Cleft%28%7B%5Cbar%7B1%7D%2C%5Cdots%2C%5Cbar%7Bm%7D%7D%5Cright%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. The transition probabilities are set as follows:</p>



<figure class="wp-block-image size-large"><a href="https://windowsontheory.files.wordpress.com/2021/04/image-1.png"><img alt="" class="wp-image-8096" src="https://windowsontheory.files.wordpress.com/2021/04/image-1.png?w=1024"/></a></figure>



<p>After taking action <img alt="a_2" class="latex" src="https://s0.wp.com/latex.php?latex=a_2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the next state is either <img alt="\overline{a_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Coverline%7Ba_2%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> or <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We might observe then that this MDP resembles a “leaking complete graph”. It is possible to visit any other state (except for <img alt="\overline{a^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Coverline%7Ba%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>). However, importantly, there is at least <img alt="1 - 3\gamma = \frac{1}{4}" class="latex" src="https://s0.wp.com/latex.php?latex=1+-+3%5Cgamma+%3D+%5Cfrac%7B1%7D%7B4%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> probability of going to the terminal state <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Also, observe that the transition probabilities are indeed valid, since by Lemma 1 above, <img alt="0 &lt; \gamma \leq \left\langle v(a_1),v(a_2) \right\rangle + 2\gamma \leq 3\gamma &lt; 1." class="latex" src="https://s0.wp.com/latex.php?latex=0+%3C+%5Cgamma+%5Cleq+%5Cleft%5Clangle+v%28a_1%29%2Cv%28a_2%29+%5Cright%5Crangle+%2B+2%5Cgamma+%5Cleq+3%5Cgamma+%3C+1.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><em><strong>Features</strong></em>: The feature map, which maps state-action pairs to <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-dimensional vectors, is defined as<br/><img alt="\phi(\overline{a_1},a_2) := \left(\left\langle v(a_1),v(a_2) \right\rangle + 2\gamma \right) v(a_2), \; \forall a_1,a_2 \in [m], a_1 \neq a_2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28%5Coverline%7Ba_1%7D%2Ca_2%29+%3A%3D+%5Cleft%28%5Cleft%5Clangle+v%28a_1%29%2Cv%28a_2%29+%5Cright%5Crangle+%2B+2%5Cgamma+%5Cright%29+v%28a_2%29%2C+%5C%3B+%5Cforall+a_1%2Ca_2+%5Cin+%5Bm%5D%2C+a_1+%5Cneq+a_2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/><img alt="\phi(f,\cdot) := 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28f%2C%5Ccdot%29+%3A%3D+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Note that the feature map is independent of <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and is shared across the MDP family.</p>



<p><em><strong>Rewards</strong></em>: For <img alt="1 \leq h \leq H" class="latex" src="https://s0.wp.com/latex.php?latex=1+%5Cleq+h+%5Cleq+H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the rewards are defined as</p>



<p><img alt="R_h(\overline{a_1},a^\star) := \left\langle v(a_1),v(a^\star) \right\rangle + 2 \gamma" class="latex" src="https://s0.wp.com/latex.php?latex=R_h%28%5Coverline%7Ba_1%7D%2Ca%5E%5Cstar%29+%3A%3D+%5Cleft%5Clangle+v%28a_1%29%2Cv%28a%5E%5Cstar%29+%5Cright%5Crangle+%2B+2+%5Cgamma&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><img alt="R_h(\overline{a_1},a_2) := -2\gamma \left[\left\langle v(a_1),v(a_2) \right\rangle + 2\gamma\right], \; (a_2 \neq a^\star, a_2 \neq a_1)" class="latex" src="https://s0.wp.com/latex.php?latex=R_h%28%5Coverline%7Ba_1%7D%2Ca_2%29+%3A%3D+-2%5Cgamma+%5Cleft%5B%5Cleft%5Clangle+v%28a_1%29%2Cv%28a_2%29+%5Cright%5Crangle+%2B+2%5Cgamma%5Cright%5D%2C+%5C%3B+%28a_2+%5Cneq+a%5E%5Cstar%2C+a_2+%5Cneq+a_1%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><img alt="R_h(f,\cdot) := 0" class="latex" src="https://s0.wp.com/latex.php?latex=R_h%28f%2C%5Ccdot%29+%3A%3D+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>For <img alt="h = H" class="latex" src="https://s0.wp.com/latex.php?latex=h+%3D+H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we set <img alt="r_H(s,a) := \langle \phi(s,a), v(a^\star)\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=r_H%28s%2Ca%29+%3A%3D+%5Clangle+%5Cphi%28s%2Ca%29%2C+v%28a%5E%5Cstar%29%5Crangle&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for every state-action pair.</p>



<p>We now verify that our construction satisfies both the linear realizability and large suboptimality gap assumptions (Assumption 1 and Assumption 2).</p>



<blockquote class="wp-block-quote"><p><strong>Lemma (Linear realizability)</strong>. For all <img alt="(s,a)" class="latex" src="https://s0.wp.com/latex.php?latex=%28s%2Ca%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have <img alt="Q_h^\star(s,a) = \langle \phi(s,a), v(a^\star) \rangle" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28s%2Ca%29+%3D+%5Clangle+%5Cphi%28s%2Ca%29%2C+v%28a%5E%5Cstar%29+%5Crangle&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p></blockquote>



<p><em><strong>Proof</strong></em>: Throughout, we assume that <img alt="a_2 \neq a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a_2+%5Cneq+a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We first verify the statement for the terminal state <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. At the state <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, regardless of the action taken, the next state is always <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and the reward is always 0. Hence, <img alt="Q_h^\star(f,\cdot) = V_h^\star(f) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28f%2C%5Ccdot%29+%3D+V_h%5E%5Cstar%28f%29+%3D+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for all <img alt="h \in [H]" class="latex" src="https://s0.wp.com/latex.php?latex=h+%5Cin+%5BH%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Thus, <img alt="Q_h^\star(f,\cdot) = \langle \phi(f,\cdot),v(a^\star)\rangle = 0" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28f%2C%5Ccdot%29+%3D+%5Clangle+%5Cphi%28f%2C%5Ccdot%29%2Cv%28a%5E%5Cstar%29%5Crangle+%3D+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We next verify realizability for other states via backwards induction on <img alt="h = H, H-1,\dots,1" class="latex" src="https://s0.wp.com/latex.php?latex=h+%3D+H%2C+H-1%2C%5Cdots%2C1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. The inductive hypothesis is <img alt="\forall a_1 \in [m], a_2 \neq a_1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+a_1+%5Cin+%5Bm%5D%2C+a_2+%5Cneq+a_1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>,</p>



<p><img alt="Q_h^\star(\overline{a_1},a_2) = \left(\left\langle v(a_1),v(a_2) \right\rangle + 2\gamma \right) \left\langle v(a_1),v(a^\star) \right\rangle. \;(1)" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28%5Coverline%7Ba_1%7D%2Ca_2%29+%3D+%5Cleft%28%5Cleft%5Clangle+v%28a_1%29%2Cv%28a_2%29+%5Cright%5Crangle+%2B+2%5Cgamma+%5Cright%29+%5Cleft%5Clangle+v%28a_1%29%2Cv%28a%5E%5Cstar%29+%5Cright%5Crangle.+%5C%3B%281%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>and that <img alt="\forall a_1 \neq a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+a_1+%5Cneq+a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>,</p>



<p><img alt="V_h^\star(\overline{a_1}) = Q_h^\star(\overline{a_1},a^\star) = \left\langle v(a_1),v(a^\star) \right\rangle + 2\gamma \; (2)" class="latex" src="https://s0.wp.com/latex.php?latex=V_h%5E%5Cstar%28%5Coverline%7Ba_1%7D%29+%3D+Q_h%5E%5Cstar%28%5Coverline%7Ba_1%7D%2Ca%5E%5Cstar%29+%3D+%5Cleft%5Clangle+v%28a_1%29%2Cv%28a%5E%5Cstar%29+%5Cright%5Crangle+%2B+2%5Cgamma+%5C%3B+%282%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>When <img alt="h = H" class="latex" src="https://s0.wp.com/latex.php?latex=h+%3D+H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, (1) holds by the definition of the rewards at that level. Next, note that <img alt="\forall h" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cforall+h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, (2) follows from (1). This is because for <img alt="a_2 \neq a^\star,a_1" class="latex" src="https://s0.wp.com/latex.php?latex=a_2+%5Cneq+a%5E%5Cstar%2Ca_1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>,</p>



<p><img alt="Q_h^\star(\overline{a_1},a_2) = \left(\left\langle v(a_1),v(a_2) \right\rangle + 2\gamma \right) \left\langle v(a_1),v(a^\star) \right\rangle \leq 3\gamma^2," class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28%5Coverline%7Ba_1%7D%2Ca_2%29+%3D+%5Cleft%28%5Cleft%5Clangle+v%28a_1%29%2Cv%28a_2%29+%5Cright%5Crangle+%2B+2%5Cgamma+%5Cright%29+%5Cleft%5Clangle+v%28a_1%29%2Cv%28a%5E%5Cstar%29+%5Cright%5Crangle+%5Cleq+3%5Cgamma%5E2%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>while (recall <img alt="\gamma := 1/4" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgamma+%3A%3D+1%2F4&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>)</p>



<p><img alt="Q_h^\star(\overline{a_1},a^\star) = \left\langle v(a_1),v(a^\star) \right\rangle + 2\gamma \geq \gamma &gt; 3\gamma^2." class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28%5Coverline%7Ba_1%7D%2Ca%5E%5Cstar%29+%3D+%5Cleft%5Clangle+v%28a_1%29%2Cv%28a%5E%5Cstar%29+%5Cright%5Crangle+%2B+2%5Cgamma+%5Cgeq+%5Cgamma+%3E+3%5Cgamma%5E2.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>This means that proving (1) suffices to show that <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is always the optimal action. A simple verification via Bellman’s optimality equation suffices to prove the inductive hypothesis for (1) for every <img alt="h \in [H]" class="latex" src="https://s0.wp.com/latex.php?latex=h+%5Cin+%5BH%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, since the base case <img alt="h = H" class="latex" src="https://s0.wp.com/latex.php?latex=h+%3D+H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> holds. Thus, both (1) and (2) hold for all <img alt="h \in [H]" class="latex" src="https://s0.wp.com/latex.php?latex=h+%5Cin+%5BH%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, concluding our proof. <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>We next show that the constant suboptimality gap (Assumption 2) is also (approximately) satisfied by our constructed MDP family.</p>



<blockquote class="wp-block-quote"><p><strong>Lemma (Suboptimality gap)</strong>. For all state <img alt="\overline{a_1} \neq \overline{a^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Coverline%7Ba_1%7D+%5Cneq+%5Coverline%7Ba%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and <img alt="a_2 \neq a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a_2+%5Cneq+a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the suboptimality gap is<br/><img alt="\Delta_h(\overline{a_1},a_2) := V_h^\star(\overline{a_1}) -Q_h^\star(\overline{a_1},a_2) &gt; \gamma - 3\gamma^2 \geq \frac{1}{4} \gamma." class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta_h%28%5Coverline%7Ba_1%7D%2Ca_2%29+%3A%3D+V_h%5E%5Cstar%28%5Coverline%7Ba_1%7D%29+-Q_h%5E%5Cstar%28%5Coverline%7Ba_1%7D%2Ca_2%29+%3E+%5Cgamma+-+3%5Cgamma%5E2+%5Cgeq+%5Cfrac%7B1%7D%7B4%7D+%5Cgamma.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/>Hence, in this MDP, Assumption 2 is satisfied with <img alt="\Delta_{\min} \geq \frac{1}{4}\gamma = \Omega(1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta_%7B%5Cmin%7D+%5Cgeq+%5Cfrac%7B1%7D%7B4%7D%5Cgamma+%3D+%5COmega%281%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p></blockquote>



<p><em><strong>Remark</strong></em>. Note that that here we ignored the terminal state <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and the essentially unreachable state <img alt="\overline{a^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Coverline%7Ba%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for simplicity. This seems reasonable intuitively, since reaching <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is effectively the end of the episode, and the state <img alt="\overline{a^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Coverline%7Ba%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> can only be reached with negligible probability(recall that <img alt="m \approx 2^d" class="latex" src="https://s0.wp.com/latex.php?latex=m+%5Capprox+2%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is exponentially large). For a more rigorous treatment of this issue, refer to Appendix B in <a href="https://arxiv.org/pdf/2103.12690.pdf">Wang, Wang, Kakade 2021</a>.</p>



<p>We can now state and prove the following key technical lemma, which directly implies Theorem 2 in <a href="https://arxiv.org/pdf/2103.12690.pdf">Wang, Wang, Kakade 2021</a>.</p>



<blockquote class="wp-block-quote"><p><em><strong>Lemma</strong></em>. For any algorithm, there exists <img alt="a^\star \in [m]" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar+%5Cin+%5Bm%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that in order to output <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> with<br/><img alt="\mathbb{E}_{s_1 \sim \mu} V_1^{\pi}(s_0) \geq \mathbb{E}_{s_1 \sim \mu} V_1^\star(s_1) - 0.05" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7Bs_1+%5Csim+%5Cmu%7D+V_1%5E%7B%5Cpi%7D%28s_0%29+%5Cgeq+%5Cmathbb%7BE%7D_%7Bs_1+%5Csim+%5Cmu%7D+V_1%5E%5Cstar%28s_1%29+-+0.05&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/>with probability at least 0.1 for <img alt="\mathcal{M}_{a^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D_%7Ba%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the number of samples required is <img alt="2^{\Omega(\min(d,H))}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B%5COmega%28%5Cmin%28d%2CH%29%29%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p></blockquote>



<p><strong>Proof sketch</strong>. We take an information-theoretic perspective. Observe that the feature map of <img alt="\mathcal{M}_{a^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D_%7Ba%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> does not depend on <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and that for <img alt="h &lt; H" class="latex" src="https://s0.wp.com/latex.php?latex=h+%3C+H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="a_2 \neq a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a_2+%5Cneq+a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the reward <img alt="R_h(\overline{a_1},a_2)" class="latex" src="https://s0.wp.com/latex.php?latex=R_h%28%5Coverline%7Ba_1%7D%2Ca_2%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> also has no information about <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. The transition probabilities are also independent of <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, unless the action <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is taken, and the reward at state <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is always 0. Thus, to receive information about the optimal action <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the agent either needs to take the action <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, or be a non-game-over state at the final time step <img alt="h= H" class="latex" src="https://s0.wp.com/latex.php?latex=h%3D+H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> (i.e <img alt="s_H \neq f" class="latex" src="https://s0.wp.com/latex.php?latex=s_H+%5Cneq+f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.)</p>



<p>However, by the design of the transition probabilities, the probability of remaining at a non-game-over state at the next time step is at most</p>



<p><img alt="\sup_{a_1 \neq a_2} \langle v(a_1),v(a_2)\rangle + 2\gamma \leq 3\gamma \leq \frac{3}{4}." class="latex" src="https://s0.wp.com/latex.php?latex=%5Csup_%7Ba_1+%5Cneq+a_2%7D+%5Clangle+v%28a_1%29%2Cv%28a_2%29%5Crangle+%2B+2%5Cgamma+%5Cleq+3%5Cgamma+%5Cleq+%5Cfrac%7B3%7D%7B4%7D.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Hence, for any algorithm, <img alt="P(s_H \neq f) \leq \left(\frac{3}{4}\right)^H" class="latex" src="https://s0.wp.com/latex.php?latex=P%28s_H+%5Cneq+f%29+%5Cleq+%5Cleft%28%5Cfrac%7B3%7D%7B4%7D%5Cright%29%5EH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, which is exponentially small.</p>



<p>Summarizing, any algorithm that does not know <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> either needs to “get lucky” so that <img alt="s_H = f" class="latex" src="https://s0.wp.com/latex.php?latex=s_H+%3D+f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, or take the optimal action <img alt="a^\star" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. For each episode, the first event happens with probability less than <img alt="\left(\frac{3}{4}\right)^H" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleft%28%5Cfrac%7B3%7D%7B4%7D%5Cright%29%5EH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and the second event happens with probability less than <img alt="\frac{H}{m-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7BH%7D%7Bm-1%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Since the number of actions is <img alt="m-1 = 2^{\Theta(d)}" class="latex" src="https://s0.wp.com/latex.php?latex=m-1+%3D+2%5E%7B%5CTheta%28d%29%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, it follows that neither event can happen with constant probability unless the number of episodes is exponential in <img alt="\min(d,H)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmin%28d%2CH%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. This wraps up the sketch. <img alt="\square" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>We note that our construction is not quite rigorous due to the remark earlier that the suboptimality gap assumption does not hold for the states <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="\overline{a^\star}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Coverline%7Ba%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. A more rigorous construction can be found in Appendix B of <a href="https://arxiv.org/pdf/2103.12690.pdf">Wang, Wang, Kakade 2021</a>. Note that this lower bound is silent on the dependence of the sample complexity on the size of the action space, giving rise to the following question, which appears to be still unsolved.</p>



<blockquote class="wp-block-quote"><p><strong>Open problem</strong>: Could we get a lower bound that also depends on the action space dimension <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, such that the number of samples required to obtain an approximately optimal policy scales with<br/><img alt="\exp(\min(A,d,H))?" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cexp%28%5Cmin%28A%2Cd%2CH%29%29%3F&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<h2>Interlude: do these lower bounds matter in practice?</h2>



<p>A natural question to ask is this: are these exponential lower bounds in Part 2 (when we only assume linear realizability) actually relevant for practice?</p>



<p>To answer this, we take a brief detour into <em>offline RL</em>. In offline RL (see <a href="https://arxiv.org/abs/2005.01643">Levine et al. 2020</a> for a survey), we assume that the agent has no direct access to the MDP, and is instead provided with a static dataset of transitions, <img alt="\mathcal{D} = {{s_h^i,a_h^i,r_h^i,s_{h+1}^i}_{h=1}^{H}}_{i=1}^m" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D+%3D+%7B%7Bs_h%5Ei%2Ca_h%5Ei%2Cr_h%5Ei%2Cs_%7Bh%2B1%7D%5Ei%7D_%7Bh%3D1%7D%5E%7BH%7D%7D_%7Bi%3D1%7D%5Em&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> (<img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> denotes number of independent episodes in the offline data). The goal here could be to learn a policy <img alt="\pi(a\mid s)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi%28a%5Cmid+s%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> (based on the static dataset <img alt="\mathcal{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>) that attains the largest possible cumulative reward when applied to the MDP, or to evaluate the performance of some target policy <img alt="\pi(a \mid s)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi%28a+%5Cmid+s%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> based on the offline data. We use <img alt="\pi_{\beta}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> to denote the distribution over states and actions in <img alt="\mathcal{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, such that we assume the state-action tuples <img alt="(s,a) \in \mathcal{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%28s%2Ca%29+%5Cin+%5Cmathcal%7BD%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> are sampled according to <img alt="s \sim d^{\pi_{\beta}}(s)" class="latex" src="https://s0.wp.com/latex.php?latex=s+%5Csim+d%5E%7B%5Cpi_%7B%5Cbeta%7D%7D%28s%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and the actions are sampled according to the behaviour policy, such that <img alt="a \sim \pi_{\beta}(a \mid s)" class="latex" src="https://s0.wp.com/latex.php?latex=a+%5Csim+%5Cpi_%7B%5Cbeta%7D%28a+%5Cmid+s%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<p>Analogous to the online RL lower bound, the following theorem shows that linear realizability is also insufficient for sample-efficient evaluation of a target policy using offline data.</p>



<blockquote class="wp-block-quote"><p><strong>Theorem (informal, from <a href="https://arxiv.org/pdf/2010.11895.pdf">Wang, Foster, Kakade 2020</a>))</strong>. In the offline RL setting, suppose the data distributions have (polynomially) lower bounded eigenvalues, and the <img alt="Q" class="latex" src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-functions of every policy are linear with respect to a given feature mapping. Then, any algorithm requires an exponential number of samples in the horizon <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> to output a non-trivially accurate estimate of the value of any given policy <img alt="\pi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, with constant probability.</p></blockquote>



<p>Some remarks are in order. First, note that the above hardness result for policy evaluation also holds for finding near-optimal policies using offline data. For a simple reduction, consider an example where at the initial state, one action <img alt="a_1" class="latex" src="https://s0.wp.com/latex.php?latex=a_1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> leads to a fixed reward and another action <img alt="a_2" class="latex" src="https://s0.wp.com/latex.php?latex=a_2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> transits us to an instance which is hard to evaluate using offline data. Then, in order to find a good policy, it is necessary for the agent to approximately evaluate the value of the optimal policy in the hard instance. Second, an appropriate eigenvalue lower bound on the offline data distribution ensures that there is sufficient feature coverage in the dataset, without which linear realizability alone is clearly insufficient for sample-efficient estimation. Third, note that the representation condition in the theorem is significantly stronger than assuming than assuming realizability with regards to only a single target policy, and so the result carries over to the latter setting as well. Fourth, the key idea to prove the result is the error amplification (exponential in the horizon <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>) induced by the <em>distribution shift</em> from the offline policy to the target policy we wish to evaluate.</p>



<p>Empirical work performed in <a href="https://arxiv.org/pdf/2103.04947.pdf">Wang et al. 2021</a> show that the these negative results do manifest themselves in experimental examples. The methology considered by <a href="https://arxiv.org/pdf/2103.04947.pdf">Wang et al. 2021</a> is as follows:</p>



<ol><li>Decide on a target policy to be evaluated, along with a good feature mapping for this policy (could be the last layer of a deep neural network trained to evaluate the policy).</li><li>Collect offline data using trajectories that are a mixture of the target policy and another distribution (perhaps generated by a random policy).</li><li>Run offline RL methods to evaluate the target policy using feature mapping found in Step 1 and the offline data obtained in Step 2.</li></ol>



<p>We note that features extracted from pre-trained deep neural networks should be able to satisfy the linear realizibility assumption approximately (for the target policy). Moreover, the offline dataset is relatively favorable for evaluation of the target policy, since we would not expect realistic offline datasets to have a large number of trajectories from the target policy itself.</p>



<p>However, numerical results show substantial degradation in the accuracy of policy evaluation, even for a relatively mild distribution shift (e.g. where there is a 50/50 split in target policy and random policy in the offline data). As an example, consider the following plot.</p>



<figure class="wp-block-image"><img alt="" src="https://i.imgur.com/WUpg5nW.png"/></figure>



<p>The figure above depicts the performance of Fitted Q-Iteration (FQI) on Walker2d-v2, an environment from the <a href="https://github.com/openai/gym">OpenAI gym benchmark suite</a> which has continuous action space. Here, the <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-axis is the number of rounds of FQI used, and the <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-axis is the square root of the mean squared error of the predicted values (smaller is better). The blue line corresponds to performance when the dataset is generated by the target policy itself with 1 million samples, and other lines correspond to the performance when adding more offline data induced by random trajectories. As we can see, adding more random trajectories lead to significant degradation of FQI. See <a href="https://arxiv.org/pdf/2103.04947.pdf">Wang et al. 2021</a> for more such experiments.</p>



<p>These empirical results seem to affirm the hardness results in <a href="https://arxiv.org/pdf/2103.04947.pdf">Wang et al. 2021</a> (offline RL) and <a href="https://arxiv.org/pdf/2103.12690.pdf">Wang, Wang, Kakade 2021</a> (online RL), in that the definition of a good representation in RL is more subtle than in supervised learning, and certainly goes beyond just linear realizibility.</p>



<h2>Part 3: Sufficient conditions for provable generalization in RL</h2>



<p>We have seen from Part 1 and Part 2 that finding an <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-optimal policy with mild (e.g. logarithmic) dependence on <img alt="S,A" class="latex" src="https://s0.wp.com/latex.php?latex=S%2CA&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="poly(H,1/\epsilon,\mbox{&quot;complexity measure&quot;})" class="latex" src="https://s0.wp.com/latex.php?latex=poly%28H%2C1%2F%5Cepsilon%2C%5Cmbox%7B%22complexity+measure%22%7D%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> samples is <strong>NOT</strong> possible agnostically, or even with linearly realizable <img alt="Q^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. This leads us to the following question.</p>



<p><strong>Q: What kind of assumptions enable provable generalization in RL?</strong></p>



<p>In fact, under various stronger assumptions, sample-efficient generalization <strong>is</strong> possible in many special cases. Amongst others, these include</p>



<ul><li>Linear Bellman Completion [<a href="https://www.aaai.org/Library/AAAI/2005/aaai05-159.php">Munos 2005</a>, <a href="https://arxiv.org/abs/2003.00153">Zanette et al. 2020</a>]<ul><li>Linear MDPs (low-rank transition matrix) [<a href="https://arxiv.org/abs/1902.04779">Wang and Yang 2018</a>; <a href="https://arxiv.org/abs/1907.05388">Jin et al. 2019</a>]</li><li>Linear Quadratic Regulators (LQR): standard control theory model (see e.g. <a href="https://en.wikipedia.org/wiki/Linear%E2%80%93quadratic_regulator">Wikipedia page for LQR</a>)</li></ul></li><li>FLAMBE/Feature Selection: <a href="https://arxiv.org/abs/2006.10814">Agarwal, Kakade, Krishnamurthy, Sun 2020</a></li><li>Linear Mixture MDPs: [<a href="http://proceedings.mlr.press/v108/modi20a/modi20a.pdf">Modi et al. 2020</a>, <a href="http://proceedings.mlr.press/v119/ayoub20a/ayoub20a.pdf">Ayoub et al. 2020</a>]</li><li>Block MDPs <a href="https://arxiv.org/pdf/1901.09018.pdf">Du et al. 2019</a></li><li>Factored MDPs <a href="https://arxiv.org/abs/1811.08540">Sun et al 2019</a></li><li>Kernelized Nonlinear Regulator <a href="https://arxiv.org/abs/2006.12466">Kakade et al. 2020</a></li></ul>



<p>What structural commonalities are shared between these underlying assumptions and models? To answer this question, we go back to the start, and revisit the case of linear bandits (<img alt="H=1" class="latex" src="https://s0.wp.com/latex.php?latex=H%3D1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> RL problem) for intuition.</p>



<h3>Intuition from properties satisfied by linear bandits</h3>



<p>We consider linear contextual bandits, where the context is <img alt="s \in\mathcal{S}" class="latex" src="https://s0.wp.com/latex.php?latex=s+%5Cin%5Cmathcal%7BS%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, the action is <img alt="a \in \mathcal{A}" class="latex" src="https://s0.wp.com/latex.php?latex=a+%5Cin+%5Cmathcal%7BA%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="\mathcal{S}, \mathcal{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BS%7D%2C+%5Cmathcal%7BA%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> denote the state (or context) and action space respectively. We assume as before that associated with each state-action pair is a representation <img alt="\phi(s,a) \in \mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28s%2Ca%29+%5Cin+%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. The observed reward is <img alt="r(s,a) = w^\star \cdot \phi(s,a) + \epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=r%28s%2Ca%29+%3D+w%5E%5Cstar+%5Ccdot+%5Cphi%28s%2Ca%29+%2B+%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, where <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a mean-zero stochastic noise term. The hypothesis class is</p>



<p><img alt="\mathcal{F} = {f(s,a) = w(f) \cdot \phi(s,a), w(f) \in \mathcal{W}}," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BF%7D+%3D+%7Bf%28s%2Ca%29+%3D+w%28f%29+%5Ccdot+%5Cphi%28s%2Ca%29%2C+w%28f%29+%5Cin+%5Cmathcal%7BW%7D%7D%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>where <img alt="\mathcal{W}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BW%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is a subset of <img alt="\mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We let <img alt="\pi_f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> denote the greedy policy for <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, i.e.</p>



<p><img alt="\pi_f(s) = \mathrm{argmax}_{a} f(s,a)." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_f%28s%29+%3D+%5Cmathrm%7Bargmax%7D_%7Ba%7D+f%28s%2Ca%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>An important structural property satisfied by linear contextual bandits is the following: <em>data reuse</em>. Indeed, the difference between any <img alt="f \in \mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and the observed reward <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is estimable when we had in fact played <img alt="\pi_g" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_g&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for some hypothesis <img alt="g \neq f" class="latex" src="https://s0.wp.com/latex.php?latex=g+%5Cneq+f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Via direct calculation, we see that</p>



<p><img alt="\mathbb{E}_{(s,a) \sim \pi_g} [f(s,a) - r(s,a)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7B%28s%2Ca%29+%5Csim+%5Cpi_g%7D+%5Bf%28s%2Ca%29+-+r%28s%2Ca%29%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><img alt="= \mathbb{E}_{(s,a) \sim \pi_g} [w(f) \cdot \phi(s,a) - (w^\star \cdot \phi(s,a) + \epsilon)]" class="latex" src="https://s0.wp.com/latex.php?latex=%3D+%5Cmathbb%7BE%7D_%7B%28s%2Ca%29+%5Csim+%5Cpi_g%7D+%5Bw%28f%29+%5Ccdot+%5Cphi%28s%2Ca%29+-+%28w%5E%5Cstar+%5Ccdot+%5Cphi%28s%2Ca%29+%2B+%5Cepsilon%29%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><img alt="= \left\langle w(f) - w^\star, \mathbb{E}_{(s,a) \sim \pi_g} [\phi(s,a)] \right\rangle." class="latex" src="https://s0.wp.com/latex.php?latex=%3D+%5Cleft%5Clangle+w%28f%29+-+w%5E%5Cstar%2C+%5Cmathbb%7BE%7D_%7B%28s%2Ca%29+%5Csim+%5Cpi_g%7D+%5B%5Cphi%28s%2Ca%29%5D+%5Cright%5Crangle.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Intuitively, assuming that <img alt="\pi_g" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_g&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> induces “sufficient exploration” of the <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-dimensional representation space, this implies that we can evaluate the quality of any policy/hypothesis <img alt="f \in \mathcal{F}" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BF%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> using just the one set of data collected by <img alt="\pi_g" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_g&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. This is <strong>precisely</strong> the kind of data reuse property we saw for supervised learning, which enables sample-efficient generalization there. This suggests that to ensure sample-efficient generalization in general RL, it may be fruitful to look for assumptions that enable data reuse. One special case where such data reuse is possible is the class of linear Bellman complete models.</p>



<h3>Special case: linear Bellman complete class</h3>



<p>Let <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> be the length of each episode as before. We recall that a hypothesis class <img alt="\mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is <strong>realizable</strong> for an MDP <img alt="\mathcal{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> if there exists a hypothesis <img alt="f^\star \in \mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=f%5E%5Cstar+%5Cin+%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that</p>



<p><img alt="Q_h^\star(s,a) = Q_{h}^{f^\star}(s,a) \quad \forall h \in [h]," class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar%28s%2Ca%29+%3D+Q_%7Bh%7D%5E%7Bf%5E%5Cstar%7D%28s%2Ca%29+%5Cquad+%5Cforall+h+%5Cin+%5Bh%5D%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>where <img alt="Q_h^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is the optimal state-action value at time step <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Having defined realizability, we are now ready to define the notion of linear Bellman completeness.</p>



<p>For any <img alt="f = (\theta_1,\dots,\theta_{H}) \in \mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=f+%3D+%28%5Ctheta_1%2C%5Cdots%2C%5Ctheta_%7BH%7D%29+%5Cin+%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, let <img alt="\pi_f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> be the greedy policy associated with <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. By the definition of a linear Bellman complete class, it follows that given some fixed <img alt="g = (\theta_1^g,\dots,\theta_{H}^g) \in \mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=g+%3D+%28%5Ctheta_1%5Eg%2C%5Cdots%2C%5Ctheta_%7BH%7D%5Eg%29+%5Cin+%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, for any <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we have<br/><img alt="\mathbb{E}_{s_h,a_h, s{h+1} \sim \pi_g} \left[Q_{h}^f(s_h,a_h) - r(s_h,a_h) - V_{h+1}^f(s_{h+1}) \right]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7Bs_h%2Ca_h%2C+s%7Bh%2B1%7D+%5Csim+%5Cpi_g%7D+%5Cleft%5BQ_%7Bh%7D%5Ef%28s_h%2Ca_h%29+-+r%28s_h%2Ca_h%29+-+V_%7Bh%2B1%7D%5Ef%28s_%7Bh%2B1%7D%29+%5Cright%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/><img alt="= \mathbb{E}_{s_h, a_h \sim \pi_g} \left[ (\theta_h - \mathcal{T}_h(\theta{h+1}) \cdot \phi(s_h,a_h) \right]" class="latex" src="https://s0.wp.com/latex.php?latex=%3D+%5Cmathbb%7BE%7D_%7Bs_h%2C+a_h+%5Csim+%5Cpi_g%7D+%5Cleft%5B+%28%5Ctheta_h+-+%5Cmathcal%7BT%7D_h%28%5Ctheta%7Bh%2B1%7D%29+%5Ccdot+%5Cphi%28s_h%2Ca_h%29+%5Cright%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/><br/><img alt="= (\theta_h - \mathcal{T}h(\theta{h+1}) \cdot \mathbb{E}_{s_h, a_h \sim \pi_g} \left[ \phi(s_h,a_h) \right]." class="latex" src="https://s0.wp.com/latex.php?latex=%3D+%28%5Ctheta_h+-+%5Cmathcal%7BT%7Dh%28%5Ctheta%7Bh%2B1%7D%29+%5Ccdot+%5Cmathbb%7BE%7D_%7Bs_h%2C+a_h+%5Csim+%5Cpi_g%7D+%5Cleft%5B+%5Cphi%28s_h%2Ca_h%29+%5Cright%5D.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<blockquote class="wp-block-quote"><p><strong>Definition (linear Bellman complete)</strong>. A hypothesis class <img alt="\mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, with respect to some known feature <img alt="\phi:\mathcal{S} \times \mathcal{A} \mapsto \mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%3A%5Cmathcal%7BS%7D+%5Ctimes+%5Cmathcal%7BA%7D+%5Cmapsto+%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, is linear Bellman complete for an MDP <img alt="\mathcal{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> if <img alt="\mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is realizable and there exists <img alt="\mathcal{T}_h: \mathbb{R}^d \to \mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BT%7D_h%3A+%5Cmathbb%7BR%7D%5Ed+%5Cto+%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> such that for all <img alt="(\theta_1,\dots,\theta&lt;_{H}) \in \mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Ctheta_1%2C%5Cdots%2C%5Ctheta%3C_%7BH%7D%29+%5Cin+%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="h \in [H]" class="latex" src="https://s0.wp.com/latex.php?latex=h+%5Cin+%5BH%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>,<br/><img alt="T_h(\theta_{h+1}) \cdot \phi(s,a) = r(s,a) + \mathbb{E}_{s' \sim P_h(s,a)} \left[\max_{a' \in \mathcal{A}} \theta_{h+1}^\top \phi(s',a') \right], \quad \forall (s,a) \in \mathcal{S} \times \mathcal{A}." class="latex" src="https://s0.wp.com/latex.php?latex=T_h%28%5Ctheta_%7Bh%2B1%7D%29+%5Ccdot+%5Cphi%28s%2Ca%29+%3D+r%28s%2Ca%29+%2B+%5Cmathbb%7BE%7D_%7Bs%27+%5Csim+P_h%28s%2Ca%29%7D+%5Cleft%5B%5Cmax_%7Ba%27+%5Cin+%5Cmathcal%7BA%7D%7D+%5Ctheta_%7Bh%2B1%7D%5E%5Ctop+%5Cphi%28s%27%2Ca%27%29+%5Cright%5D%2C+%5Cquad+%5Cforall+%28s%2Ca%29+%5Cin+%5Cmathcal%7BS%7D+%5Ctimes+%5Cmathcal%7BA%7D.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p></blockquote>



<p>This shows that data reuse is possible for any linear Bellman complete class <img alt="\mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, since any <img alt="f \in \mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> can be evaluated using offline data collected by some fixed policy <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>.</p>



<p>As an aside, note that linear Bellman completeness is a very strong condition that can break when new features are added. This is because adding new features expands the hypothesis space (of linear functions), and there is no guarantee that the new hypothesis class will again satisfy linear Bellman completeness.</p>



<p>It turns out that linear Bellman complete classes are just one example of Bilinear Classes (<a href="https://arxiv.org/pdf/2103.10897.pdf">Du et al. 2021</a>), which encompass many RL models in which sample-efficient generalization has been shown to be possible.</p>



<h3>Bilinear Classes: structural properties to enable generalization in RL</h3>



<p>We assume access to a hypothesis class <img alt="\mathcal{H} = \mathcal{H}_1 \times \dots \times \mathcal{H}_{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D+%3D+%5Cmathcal%7BH%7D_1+%5Ctimes+%5Cdots+%5Ctimes+%5Cmathcal%7BH%7D_%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, which can be abstract sets that permit for both model-based and value-based hypotheses. We assume that for all <img alt="f \in \mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, there is an associated state-action value function <img alt="Q_h^f" class="latex" src="https://s0.wp.com/latex.php?latex=Q_h%5Ef&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and a value function <img alt="V_h^f" class="latex" src="https://s0.wp.com/latex.php?latex=V_h%5Ef&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for each <img alt="h \in {1,\dots,H}" class="latex" src="https://s0.wp.com/latex.php?latex=h+%5Cin+%7B1%2C%5Cdots%2CH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. As before, let <img alt="\pi_{h}^{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_%7Bh%7D%5E%7Bf%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> denote the greedy policy with respect to <img alt="Q_{h}^{f}" class="latex" src="https://s0.wp.com/latex.php?latex=Q_%7Bh%7D%5E%7Bf%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, and let <img alt="\pi_f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cpi_f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> denote <img alt="{\pi_{h}^{f}}_{h=1}^{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpi_%7Bh%7D%5E%7Bf%7D%7D_%7Bh%3D1%7D%5E%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. We can now introduce the Bilinear Class.</p>



<p><strong>Definition (Bilinear Class)</strong>. Consider an MDP <img alt="\mathcal{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, a hypothesis class <img alt="\mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, a discrepancy function <img alt="\ell_f: \mathcal{S} \times \mathcal{A} \times \mathcal{S} \times \mathcal{H} \to \mathbb{R}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_f%3A+%5Cmathcal%7BS%7D+%5Ctimes+%5Cmathcal%7BA%7D+%5Ctimes+%5Cmathcal%7BS%7D+%5Ctimes+%5Cmathcal%7BH%7D+%5Cto+%5Cmathbb%7BR%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> (defined for each <img alt="f \in \mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>). Suppose <img alt="\mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> is realizable in <img alt="\mathcal{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and that there exists functions <img alt="W_h: \mathcal{H} \to \mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=W_h%3A+%5Cmathcal%7BH%7D+%5Cto+%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="X_h: \mathcal{H} \to \mathbb{R}^d" class="latex" src="https://s0.wp.com/latex.php?latex=X_h%3A+%5Cmathcal%7BH%7D+%5Cto+%5Cmathbb%7BR%7D%5Ed&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for some <img alt="d \in \mathcal{N}" class="latex" src="https://s0.wp.com/latex.php?latex=d+%5Cin+%5Cmathcal%7BN%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. Then, <img alt="(\mathcal{H},\ell_f)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cmathcal%7BH%7D%2C%5Cell_f%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> forms a Bilinear Class for <img alt="\mathcal{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BM%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> if the following two conditions hold.</p>



<ol><li>Bilinear regret: on-policy difference between claimed reward and true reward satisfies following upper bound,<br/><img alt="|\mathbb{E}_{a{1:h} \sim \pi_f} \left[Q_{h}^{f}(s_h,a_h) - r(s_h,a_h) - V_{h}^{f}(s_{h+1}) \right] | \leq \langle W_h(f)  - W_h(f^\star), X_h(f)\rangle.f" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb%7BE%7D_%7Ba%7B1%3Ah%7D+%5Csim+%5Cpi_f%7D+%5Cleft%5BQ_%7Bh%7D%5E%7Bf%7D%28s_h%2Ca_h%29+-+r%28s_h%2Ca_h%29+-+V_%7Bh%7D%5E%7Bf%7D%28s_%7Bh%2B1%7D%29+%5Cright%5D+%7C+%5Cleq+%5Clangle+W_h%28f%29++-+W_h%28f%5E%5Cstar%29%2C+X_h%28f%29%5Crangle.f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li><li>Data reuse: <img alt="|\mathbb{E}_{a{1:h} \sim \pi_f}\left[\ell_f(s_h,a_h,s_{h+1},g) \right]| = |\langle W_h(g) - W_h(f^\star), X_h(f)\rangle |." class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb%7BE%7D_%7Ba%7B1%3Ah%7D+%5Csim+%5Cpi_f%7D%5Cleft%5B%5Cell_f%28s_h%2Ca_h%2Cs_%7Bh%2B1%7D%2Cg%29+%5Cright%5D%7C+%3D+%7C%5Clangle+W_h%28g%29+-+W_h%28f%5E%5Cstar%29%2C+X_h%28f%29%5Crangle+%7C.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></li></ol>



<p>As an example to demonstrate what the choices of <img alt="\ell_f,W_h" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_f%2CW_h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> and <img alt="X_h" class="latex" src="https://s0.wp.com/latex.php?latex=X_h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> might look like, for a linear Bellman complete class <img alt="\mathcal{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BH%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>, we can choose<br/><img alt="\ell_f(s_h,a_h,s_{h+1},g) = Q_{h}^{g}(s_h,a_h) - r(s_h,a_h) - V_{h+1}^{g}(s_{h+1})," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_f%28s_h%2Ca_h%2Cs_%7Bh%2B1%7D%2Cg%29+%3D+Q_%7Bh%7D%5E%7Bg%7D%28s_h%2Ca_h%29+-+r%28s_h%2Ca_h%29+-+V_%7Bh%2B1%7D%5E%7Bg%7D%28s_%7Bh%2B1%7D%29%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><img alt="W_h(g) = \theta_h - \mathcal{T}_h(\theta_{h+1})" class="latex" src="https://s0.wp.com/latex.php?latex=W_h%28g%29+%3D+%5Ctheta_h+-+%5Cmathcal%7BT%7D_h%28%5Ctheta_%7Bh%2B1%7D%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p><img alt="X_h(f) = \mathbb{E}_{(s_h,a_h) \sim \pi_f}[\phi(s_h,a_h)]" class="latex" src="https://s0.wp.com/latex.php?latex=X_h%28f%29+%3D+%5Cmathbb%7BE%7D_%7B%28s_h%2Ca_h%29+%5Csim+%5Cpi_f%7D%5B%5Cphi%28s_h%2Ca_h%29%5D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/></p>



<p>Above, note that <img alt="W_h(f^\star) = 0" class="latex" src="https://s0.wp.com/latex.php?latex=W_h%28f%5E%5Cstar%29+%3D+0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for all <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> for linear Bellman complete classes, and that the discrepancy function <img alt="\ell_f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> in this case does not depend on <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>. As demonstrated in <a href="https://arxiv.org/pdf/2103.10897.pdf">Du et al. 2021</a>, the following models (in which sample-efficient generalization is known to be possible) can all be shown to be Bilinear Classes for some discrepancy function <img alt="\ell_f" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_f&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>:</p>



<ul><li>Linear Bellman Completion [<a href="https://www.aaai.org/Library/AAAI/2005/aaai05-159.php">Munos 2005</a>, <a href="https://arxiv.org/abs/2003.00153">Zanette et al. 2020</a>]<ul><li>Linear MDPs (low-rank transition matrix) [<a href="https://arxiv.org/abs/1902.04779">Wang and Yang 2018</a>; <a href="https://arxiv.org/abs/1907.05388">Jin et al. 2019</a>]</li><li>Linear Quadratic Regulators (LQR): standard control theory model (see e.g. <a href="https://en.wikipedia.org/wiki/Linear%E2%80%93quadratic_regulator">Wikipedia page for LQR</a>)</li></ul></li><li>FLAMBE/Feature Selection: <a href="https://arxiv.org/abs/2006.10814">Agarwal, Kakade, Krishnamurthy, Sun 2020</a></li><li>Linear Mixture MDPs: [<a href="http://proceedings.mlr.press/v108/modi20a/modi20a.pdf">Modi et al. 2020</a>, <a href="http://proceedings.mlr.press/v119/ayoub20a/ayoub20a.pdf">Ayoub et al. 2020</a>]</li><li>Block MDPs <a href="https://arxiv.org/pdf/1901.09018.pdf">Du et al. 2019</a></li><li>Factored MDPs <a href="https://arxiv.org/abs/1811.08540">Sun et al 2019</a></li><li>Kernelized Nonlinear Regulator <a href="https://arxiv.org/abs/2006.12466">Kakade et al. 2020</a></li><li>and more (see <a href="https://arxiv.org/pdf/2103.10897.pdf">Du et al. 2021</a> for details.)</li></ul>



<p>Bilinear classes can be seen as a generalization of Bellman rank (<a href="https://arxiv.org/abs/1610.09512">Jiang et al. 2017</a>) and Witness rank (<a href="https://arxiv.org/abs/1811.08540">Wen et al. 2019</a>), which were previous works that sought to identify strucural commonalities between different RL models that enable sample-efficient generalization. That being said, there are still models (with known provable generalization) which Bilinear Classes does not cover. Two such exceptions are the deterministic linear <img alt="Q^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/> (<a href="https://arxiv.org/abs/1307.4847">Wen and Van Roy 2013</a>) model and the <img alt="Q^\star" class="latex" src="https://s0.wp.com/latex.php?latex=Q%5E%5Cstar&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002"/>-state aggregation model (<a href="https://arxiv.org/abs/1912.06366">Dong et al. 2020</a>). On a heuristic level, the structural commonalities identified by the Bilinear Classes show that to a large extent, most RL models known to enable sample-efficient generalization resemble linear bandits, in that data reuse is possible. In this sense, understanding why generalization is possible in the linear bandit case gives one intuition for why generalization is possible in these other cases as well. On some level, this may be disappointing since we might hope to capture richer phenomenon than just linear bandits, but promisingly, there is a rich class of RL models which share these structural commonalities that enable generalization in RL (as the examples encompassed by the Bilinear Classes demonstrate).</p>



<h2>Conclusion</h2>



<p>From the discussion above, we see that a generalization theory for RL, while significantly distinct from that for supervised learning, is still possible. However, natural assumptions that might seem adequate, such as linear realizability, are in fact insufficient, and much stronger assumptions are required. One such example of sufficient assumptions is the Bilinear Class, which covers a rich set of models. Moreover, as the empirical results we saw in the interlude show, these representational issues identified by theory are relevant for practice. For more on the theory of RL, see the following <a href="https://rltheorybook.github.io">forthcoming book</a>.</p></div>
    </content>
    <updated>2021-04-24T14:56:43Z</updated>
    <published>2021-04-24T14:56:43Z</published>
    <category term="ML Theory seminar"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-05-05T05:38:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8083</id>
    <link href="https://windowsontheory.org/2021/04/23/tcs-women-rising-star-nominations/" rel="alternate" type="text/html"/>
    <title>TCS Women Rising star nominations</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">(Guest post by Virginia Vassilevska Williams) Dear colleagues We invite you to nominate speakers for our TCS Women Rising Star talks at the TCS Women Spotlight Workshop at STOC 2021. To be eligible, your nominee has to be a theoretical computer science researcher (all topics represented at STOC are welcome) who is female or an … <a class="more-link" href="https://windowsontheory.org/2021/04/23/tcs-women-rising-star-nominations/">Continue reading <span class="screen-reader-text">TCS Women Rising star nominations</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>(Guest post by Virginia Vassilevska Williams) <br/></em><br/></p>



<p>Dear colleagues</p>



<p>We invite you to nominate speakers for our TCS Women Rising Star talks at the TCS Women Spotlight Workshop at STOC 2021. To be eligible, your nominee has to be a theoretical computer science researcher (all topics represented at STOC are welcome) who is female or an underrepresented minority, and is a graduating PhD student or a postdoc. You can make your nomination by filling this form by May 15th:  <a href="https://forms.gle/g4mTS2MJzkenKrry6" rel="noreferrer noopener" target="_blank">https://forms.gle/g4mTS2MJzkenKrry6</a></p>



<p>The TCS Women Spotlight workshop at STOC 2021 will take place virtually between June 21st and June 25th (most likely on Tuesday, June 22<sup>nd</sup>, to be confirmed later on).</p>



<p>You can see the list of speakers from last year here: <a href="https://sigact.org/tcswomen/3rd-tcs-women-meeting/tcs-women-2020/">https://sigact.org/tcswomen/3rd-tcs-women-meeting/tcs-women-2020/</a></p>



<p/>



<p>Looking forward to your nominations and to seeing you at the TCS Women Spotlight Workshop!</p>



<p>Virginia Vassilevska Williams, Barna Saha, Sofya Raskhodnikova, Mary Wootters and Elena Grigorescu</p></div>
    </content>
    <updated>2021-04-23T15:10:25Z</updated>
    <published>2021-04-23T15:10:25Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2021-05-05T05:38:42Z</updated>
    </source>
  </entry>
</feed>
