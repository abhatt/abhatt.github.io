<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2021-06-10T20:22:02Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4522</id>
    <link href="https://lucatrevisan.wordpress.com/2021/06/10/benny-chor/" rel="alternate" type="text/html"/>
    <title>Benny Chor</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I just heard that Benny Chor died this morning. Chor did very important work on computational biology and distributed algorithms, but I (and probably many of my readers) know him primarily for his work on cryptography, for his work on … <a href="https://lucatrevisan.wordpress.com/2021/06/10/benny-chor/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I just heard that Benny Chor died this morning. Chor did very important work on computational biology and distributed algorithms, but I (and probably many of my readers) know him primarily for his work on cryptography, for his work on randomness extraction and for introducing the notion of private information retrieval.</p>



<p>I only met him once, at the event for <a href="https://lucatrevisan.wordpress.com/2017/04/20/fests/">Oded Goldreich’s 60th birthday</a>. On the occasion, he gave a talk on the Chor-Goldreich paper, which introduced the problem of randomness extraction from independent sources, and which introduced min-entropy as the right parameter by which to quantify the randomness content of random sources. He did so using the original slides used for the FOCS 1985 talk.</p>



<figure class="wp-block-image size-large"><a href="https://lucatrevisan.files.wordpress.com/2017/04/img_6726.jpg"><img alt="" class="wp-image-3735" src="https://lucatrevisan.files.wordpress.com/2017/04/img_6726.jpg?w=768"/></a></figure>



<p>I took a picture during the talk, which I posted online, and later he sent me an email asking for the original. Sadly, this was the totality of our correspondence. I heard that besides being a brilliant and generous researchers, he was a very playful, likeable and nice person. My thoughts are with his family and his friends.</p></div>
    </content>
    <updated>2021-06-10T20:18:16Z</updated>
    <published>2021-06-10T20:18:16Z</published>
    <category term="theory"/>
    <category term="Benny Chor"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2021-06-10T20:20:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4515</id>
    <link href="https://lucatrevisan.wordpress.com/2021/06/10/the-simons-institute-reopens/" rel="alternate" type="text/html"/>
    <title>The Simons Institute Reopens</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This coming Fall semester the Simons Institute for the Theory of Computing in Berkeley will have in-person activities, including the really interesting program on the complexity of statistical inference, within which I will co-organize a workshop on cryptography, average-case complexity, … <a href="https://lucatrevisan.wordpress.com/2021/06/10/the-simons-institute-reopens/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This coming Fall semester the Simons Institute for the Theory of Computing in Berkeley will have in-person activities, including the really interesting program on the complexity of statistical inference, within which I will co-organize a <a href="https://simons.berkeley.edu/programs/si2021">workshop</a> on cryptography, average-case complexity, and the complexity of statistical problems.</p>
<p>As it had been the case before the pandemic, all Simons Institute events will be streamed and available remotely. This includes a new series of <a href="https://simons.berkeley.edu/events">Public Lectures</a> called <a href="https://simons.berkeley.edu/news/institute-launches-breakthroughs-lecture-series">“Breakthroughs”</a> that starts next week with a talk by Virginia Williams on matrix multiplication.</p></div>
    </content>
    <updated>2021-06-10T20:00:51Z</updated>
    <published>2021-06-10T20:00:51Z</published>
    <category term="Berkeley"/>
    <category term="theory"/>
    <category term="Simons Institute"/>
    <category term="Virginia Williams"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2021-06-10T20:20:09Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5542</id>
    <link href="https://www.scottaaronson.com/blog/?p=5542" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5542#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5542" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">On Guilt</title>
    <summary xml:lang="en-US">The other night Dana and I watched “The Internet’s Own Boy,” the 2014 documentary about the life and work of Aaron Swartz, which I’d somehow missed when it came out. Swartz, for anyone who doesn’t remember, was the child prodigy who helped create RSS and Reddit, who then became a campaigner for an open Internet, […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>The other night Dana and I watched <a href="https://www.youtube.com/watch?v=9vz06QO3UkQ">“The Internet’s Own Boy,”</a> the 2014 documentary about the life and work of <a href="https://en.wikipedia.org/wiki/Aaron_Swartz">Aaron Swartz</a>, which I’d somehow missed when it came out.  Swartz, for anyone who doesn’t remember, was the child prodigy who helped create RSS and Reddit, who then became a campaigner for an open Internet, who was arrested for using a laptop in an MIT supply closet to download millions of journal articles and threatened with decades in prison, and who then committed suicide at age 26.  I regret that I never knew Swartz, though he did once send me a fan email about <em>Quantum Computing Since Democritus</em>.</p>



<p>Say whatever you want about the tactical wisdom or the legality of Swartz’s actions; it seems inarguable to me that he was <em>morally</em> correct, that certain categories of information (e.g. legal opinions and taxpayer-funded scientific papers) need to be made freely available, and that sooner or later our civilization will catch up to Swartz and regard his position as completely obvious.  The beautifully-made documentary filled me with rage and guilt not only that the world had failed Swartz, but that I personally had failed him.</p>



<p>At the time of Swartz’s arrest, prosecution, and suicide, I was an MIT CS professor who’d previously <a href="https://www.scottaaronson.com/writings/journal.html">written</a> in strong support of open access to scientific literature, and who had the platform of this blog.  Had I understood what was going on with Swartz—had I <em>taken the time to find out</em> what was going on—I could have been in a good position to help organize a grassroots campaign to pressure the MIT administration to urge prosecutors to drop the case (like JSTOR had already done), which could plausibly have made a difference.  As it was, I was preoccupied in those years with BosonSampling, getting married, etc., I didn’t bother to learn whether anything was being done or <em>could</em> be done about the Aaron Swartz matter, and then before I knew it, Swartz had joined Alan Turing in computer science’s pantheon of lost geniuses.</p>



<p>But maybe there was something deeper to my inaction.  If I’d strongly defended the substance of what Swartz had done, it would’ve raised the question: <em>why wasn’t I doing the same?</em>  Why was I merely complaining about paywalled journals from the comfort of my professor’s office, rather than putting my own freedom on the line like Swartz was?  It was as though I <em>had</em> to put some psychological distance between myself and the situation, in order to justify my life choices to myself.</p>



<p>Even though I see the error in that way of “thinking,” it keeps recurring, keeps causing me to make choices that I feel guilt or at least regret about later.  In February 2020, there were a few smart people saying that a new viral pneumonia from Wuhan was about to upend life on earth, but the people around me certainly weren’t <em>acting</em> that way, and <em>I</em> wasn’t acting that way either … and so, “for the sake of internal consistency,” I didn’t spend much time thinking about it or investigating it.  After all, if the fears of a global pandemic had a good chance of being true, I should be dropping everything else and panicking, shouldn’t I?  But I <em>wasn’t</em> dropping everything else and panicking … so how could the fears be true?</p>



<p>Then I <a href="https://www.scottaaronson.com/blog/?p=4695">publicly repented</a>, and resolved not to make such an error again.  And now, 15 months later, I realize that I <em>have</em> made such an error again.</p>



<p>All throughout the pandemic, I’d ask my friends, privately, why the hypothesis that the virus had accidentally leaked from the Wuhan Institute of Virology wasn’t being taken far more seriously, given what seemed like a shockingly strong <em>prima facie</em> case.  But I didn’t discuss the lab leak scenario on this blog, except once in passing.  I could <em>say</em> I didn’t discuss it because I’m not a virologist and I had nothing new to contribute.  But I worry that I also didn’t discuss it because it seemed incompatible with my self-conception as a cautious scientist who’s skeptical of lurid coverups and conspiracies—and because I’d already spent my “weirdness capital” on other issues, and didn’t relish the prospect of being sneered at on social media yet again.  Instead I simply waited for discussion of the lab leak hypothesis to become “safe” and “respectable,” as today it finally has, thanks to writers who were more courageous than I was.  I became, basically, another sheep in one of the conformist herds that we rightly despise when we read about them in history.</p>



<p>(For all that, it’s still plausible to me that the virus had a natural origin after all.  What’s become clear is simply that, <em>even if so</em>, the failure to take the possibility of a lab escape more seriously back when the trail of evidence was fresher will stand as a major intellectual scandal of our time.)</p>



<p>Sometimes people are wracked with guilt, but over completely different things than the world <em>wants</em> them to be wracked with guilt over.  This was one of the great lessons that I learned from reading Richard Rhodes’s <em><a href="https://www.amazon.com/Making-Atomic-Bomb-Richard-Rhodes/dp/1451677618">The Making of the Atomic Bomb</a></em>.  Many of the Manhattan Project physicists felt lifelong guilt, <em>not</em> that they’d participated in building the bomb, but only that they hadn’t <em>finished</em> the bomb by 1943, when it could have ended the war in Europe and the Holocaust.</p>



<p>On a much smaller scale, I suppose some readers would still like me to feel guilt about comment 171, or some of the other stuff I wrote about nerds, dating, and feminism … or if not that, then maybe about my defense of a two-state solution for Israel and Palestine, or of standardized tests and accelerated math programs, or maybe my vehement condemnation of Trump and his failed insurrection.  Or any of the dozens of other times when I stood up and said something I actually believed, or when I recounted my experiences as accurately as I could.  The truth is, though, I don’t.</p>



<p>Looking back—which, now that I’m 40, I confess is an increasingly large fraction of my time—the pattern seems consistent.  I feel guilty, not for having stood up for what I strongly believed in, but for having <em>failed</em> to do so.  This suggests that, if I want fewer regrets, then I should click “Publish” on more potentially controversial posts!  I don’t know how to force myself to do that, but maybe this post itself is a step.</p></div>
    </content>
    <updated>2021-06-10T17:38:24Z</updated>
    <published>2021-06-10T17:38:24Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Embarrassing Myself"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Self-Help"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Self-Referential"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-06-10T17:41:45Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-2554136414226144895</id>
    <link href="https://blog.computationalcomplexity.org/feeds/2554136414226144895/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/06/the-future-of-faculty-hiring.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2554136414226144895" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/2554136414226144895" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2021/06/the-future-of-faculty-hiring.html" rel="alternate" type="text/html"/>
    <title>The Future of Faculty Hiring</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Faculty hiring in computer science is a <a href="https://blog.computationalcomplexity.org/2016/12/fixing-academic-job-market.html">process long due for an overhaul</a>. The pandemic certainly changed some of the dynamics moving most of the interviews online and saving a ton of money and time. Will this be the start of a fresh approach to recruiting?</p><p>A typical search in the past few years had some schools flying in 30-40 candidates, typically costing over a $1000 each and a full-time job for a staff member during the search. We'd justify the expense as small compared to the millions we'd invest in a faculty member throughout their career, but it is generally the largest discretionary expense for a CS department. It also gives advantages to rich departments over others.</p><p>During the pandemic all those interviews moved online and worked reasonably well at virtually no additional cost. Also no need to scrounge around to find faculty willing to skip family meals to have dinner with the candidates. And if a faculty had a conflict with a candidate on the interview day, they could schedule on a different day. There really is no reason to have all the meetings on the same day.</p><p>With the pandemic mostly behind us, will we go back to in-person interviews moving forward. I suspect the <a href="https://www.chronicle.com/article/whiffing-the-airport-interview/">airport interview</a>, where you fly out 20 or so candidates to have hour long interviews in a hotel near an airport with a search committee for an administrative position, will be the first to go completely virtual. </p><p>Even for regular faculty interviews, there will be great pressure to reduce the number of in-person visits, perhaps to just the top candidates, or just the ones who have offers--make the "second visit" the only visit. Richer departments may find the expense worthwhile to make a bigger impression on the candidates and that will only expand the advantage of wealthier universities.</p><p>Times like this are the perfect opportunity for CS leadership to come in and give some sanity to the hiring process but I'm not holding my breath.</p></div>
    </content>
    <updated>2021-06-10T13:10:00Z</updated>
    <published>2021-06-10T13:10:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2021-06-10T13:11:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/080</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/080" rel="alternate" type="text/html"/>
    <title>TR21-080 |  Hardness vs Randomness, Revised: Uniform, Non-Black-Box, and Instance-Wise | 

	Lijie Chen, 

	Roei Tell</title>
    <summary>We propose a new approach to the hardness-to-randomness framework and to the promise-BPP=promise-P conjecture. Classical results rely on non-uniform hardness assumptions to construct derandomization algorithms that work in the worst-case, or rely on uniform hardness assumptions to construct derandomization algorithms that work only in the average-case. In both types of results, the derandomization algorithm is ``black-box'' and uses the standard PRG approach. In this work we present results that closely relate **new and natural uniform hardness assumptions** to **worst-case derandomization** of promise-BPP, where the algorithms underlying the latter derandomization are **non-black-box**.

In our main result, we show that promise-BPP=promise-P if the following holds: There exists a multi-output function computable by logspace-uniform circuits of polynomial size and depth $n^2$ that cannot be computed by uniform probabilistic algorithms in time $n^c$, for some universal constant $c&gt;1$, on **almost all inputs**. The required failure on ``almost all inputs'' is stronger than the standard requirement of failing on one input of each length; however, the same assumption without the depth restriction on $f$ is **necessary** for the conclusion. This suggests a potential equivalence between worst-case derandomization of promise-BPP of any form (i.e., not necessarily by a black-box algorithm) and the existence of efficiently computable functions that are hard for probabilistic algorithms on almost all inputs.

In our second result, we introduce a new and uniform hardness-to-randomness tradeoff for the setting of **superfast average-case derandomization**; prior to this work, superfast average-case derandomization was known only under non-uniform hardness assumptions. In an extreme instantiation of our new tradeoff, under appealing uniform hardness assumptions, we show that for every polynomial $T(n)$ and constant $\epsilon&gt;0$ it holds that $BPTIME[T]\subseteq heur-DTIME[T\cdot n^{\epsilon}]$, where the ``heur'' prefix means that no polynomial-time algorithm can find, with non-negligible probability, an input on which the deterministic simulation errs.

Technically, our approach is to design **targeted PRGs and HSGs**, as introduced by Goldreich (LNCS, 2011). The targeted PRGs/HSGs ``produce randomness from the input'', as suggested by Goldreich and Wigderson (RANDOM 2002); and their analysis relies on non-black-box versions of the reconstruction procedure of Impagliazzo and Wigderson (FOCS 1998). Our main reconstruction procedure crucially relies on the ideas underlying the proof system of Goldwasser, Kalai, and Rothblum (J. ACM 2015).</summary>
    <updated>2021-06-10T07:46:31Z</updated>
    <published>2021-06-10T07:46:31Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-06-10T20:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.05245</id>
    <link href="http://arxiv.org/abs/2106.05245" rel="alternate" type="text/html"/>
    <title>Local Algorithms for Finding Densely Connected Clusters</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Peter Macgregor, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:He.html">He Sun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.05245">PDF</a><br/><b>Abstract: </b>Local graph clustering is an important algorithmic technique for analysing
massive graphs, and has been widely applied in many research fields of data
science. While the objective of most (local) graph clustering algorithms is to
find a vertex set of low conductance, there has been a sequence of recent
studies that highlight the importance of the inter-connection between clusters
when analysing real-world datasets. Following this line of research, in this
work we study local algorithms for finding a pair of vertex sets defined with
respect to their inter-connection and their relationship with the rest of the
graph. The key to our analysis is a new reduction technique that relates the
structure of multiple sets to a single vertex set in the reduced graph. Among
many potential applications, we show that our algorithms successfully recover
densely connected clusters in the Interstate Disputes Dataset and the US
Migration Dataset.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.05161</id>
    <link href="http://arxiv.org/abs/2106.05161" rel="alternate" type="text/html"/>
    <title>Interactive Modelling of Volumetric Musculoskeletal Anatomy</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abdrashitov:Rinat.html">Rinat Abdrashitov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bang:Seungbae.html">Seungbae Bang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levin:David_I=_W=.html">David I. W. Levin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singh:Karan.html">Karan Singh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jacobson:Alec.html">Alec Jacobson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.05161">PDF</a><br/><b>Abstract: </b>We present a new approach for modelling musculoskeletal anatomy. Unlike
previous methods, we do not model individual muscle shapes as geometric
primitives (polygonal meshes, NURBS etc.). Instead, we adopt a volumetric
segmentation approach where every point in our volume is assigned to a muscle,
fat, or bone tissue. We provide an interactive modelling tool where the user
controls the segmentation via muscle curves and we visualize the muscle shapes
using volumetric rendering. Muscle curves enable intuitive yet powerful control
over the muscle shapes. This representation allows us to automatically handle
intersections between different tissues (musclemuscle, muscle-bone, and
muscle-skin) during the modelling and automates computation of muscle fiber
fields. We further introduce a novel algorithm for converting the volumetric
muscle representation into tetrahedral or surface geometry for use in
downstream tasks. Additionally, we introduce an interactive skeleton authoring
tool that allows the users to create skeletal anatomy starting from only a skin
mesh using a library of bone parts.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-06-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.05145</id>
    <link href="http://arxiv.org/abs/2106.05145" rel="alternate" type="text/html"/>
    <title>Relative Clustering Coefficient</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Touli:Elena_Farahbakhsh.html">Elena Farahbakhsh Touli</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lindberg:Oscar.html">Oscar Lindberg</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.05145">PDF</a><br/><b>Abstract: </b>In this paper, we relatively extend the definition of global clustering
coefficient to another clustering, which we call it relative clustering
coefficient. The idea of this definition is to ignore the edges in the network
that the probability of having an edge is 0. Here, we also consider a model as
an example that using relative clustering coefficient is better than global
clustering coefficient for comparing networks and also checking the properties
of the networks.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-06-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.05131</id>
    <link href="http://arxiv.org/abs/2106.05131" rel="alternate" type="text/html"/>
    <title>Prior-Aware Distribution Estimation for Differential Privacy</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tao:Yuchao.html">Yuchao Tao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bater:Johes.html">Johes Bater</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Machanavajjhala:Ashwin.html">Ashwin Machanavajjhala</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.05131">PDF</a><br/><b>Abstract: </b>Joint distribution estimation of a dataset under differential privacy is a
fundamental problem for many privacy-focused applications, such as query
answering, machine learning tasks and synthetic data generation. In this work,
we examine the joint distribution estimation problem given two data points: 1)
differentially private answers of a workload computed over private data and 2)
a prior empirical distribution from a public dataset. Our goal is to find a new
distribution such that estimating the workload using this distribution is as
accurate as the differentially private answer, and the relative entropy, or KL
divergence, of this distribution is minimized with respect to the prior
distribution. We propose an approach based on iterative optimization for
solving this problem. An application of our solution won second place in the
NIST 2020 Differential Privacy Temporal Map Challenge, Sprint 2.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.05123</id>
    <link href="http://arxiv.org/abs/2106.05123" rel="alternate" type="text/html"/>
    <title>Pattern-defeating Quicksort</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Orson R. L. Peters <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.05123">PDF</a><br/><b>Abstract: </b>A new solution for the Dutch national flag problem is proposed, requiring no
three-way comparisons, which gives quicksort a proper worst-case runtime of
$O(nk)$ for inputs with $k$ distinct elements. This is used together with other
known and novel techniques to construct a hybrid sort that is never
significantly slower than regular quicksort while speeding up drastically for
many input distributions.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04973</id>
    <link href="http://arxiv.org/abs/2106.04973" rel="alternate" type="text/html"/>
    <title>Reachability Problems for Transmission Graphs</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Shinwoo An, Eunjin Oh <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04973">PDF</a><br/><b>Abstract: </b>Let $P$ be a set of $n$ points in the plane where each point $p$ of $P$ is
associated with a radius $r_p&gt;0$.The transmission graph $G=(P,E)$ of $P$ is
defined as the directed graph such that $E$ contains an edge from $p$ to $q$ if
and only if $|pq|\leq r_p$ for any two points $p$ and $q$ in $P$, where $|pq|$
denotes the Euclidean distance between $p$ and $q$. In this paper, we present a
data structure of size $O(n^{5/3})$ such that for any two points in $P$, we can
check in $O(n^{2/3})$ time if there is a path in $G$ between the two points.
This is the first data structure for answering reachability queries whose
performance depends only on $n$ but not on the number of edges.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-06-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04941</id>
    <link href="http://arxiv.org/abs/2106.04941" rel="alternate" type="text/html"/>
    <title>Symmetric Spaces for Graph Embeddings: A Finsler-Riemannian Approach</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/L=oacute=pez:Federico.html">Federico López</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pozzetti:Beatrice.html">Beatrice Pozzetti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Trettel:Steve.html">Steve Trettel</a>, Michael Strube, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wienhard:Anna.html">Anna Wienhard</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04941">PDF</a><br/><b>Abstract: </b>Learning faithful graph representations as sets of vertex embeddings has
become a fundamental intermediary step in a wide range of machine learning
applications. We propose the systematic use of symmetric spaces in
representation learning, a class encompassing many of the previously used
embedding targets. This enables us to introduce a new method, the use of
Finsler metrics integrated in a Riemannian optimization scheme, that better
adapts to dissimilar structures in the graph. We develop a tool to analyze the
embeddings and infer structural properties of the data sets. For
implementation, we choose Siegel spaces, a versatile family of symmetric
spaces. Our approach outperforms competitive baselines for graph reconstruction
tasks on various synthetic and real-world datasets. We further demonstrate its
applicability on two downstream tasks, recommender systems and node
classification.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2021-06-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04863</id>
    <link href="http://arxiv.org/abs/2106.04863" rel="alternate" type="text/html"/>
    <title>A Randomness Threshold for Online Bipartite Matching, via Lossless Online Rounding</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Buchbinder:Niv.html">Niv Buchbinder</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Naor:Joseph.html">Joseph Naor</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wajc:David.html">David Wajc</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04863">PDF</a><br/><b>Abstract: </b>Over three decades ago, Karp, Vazirani and Vazirani (STOC'90) introduced the
online bipartite matching problem. They observed that deterministic algorithms'
competitive ratio for this problem is no greater than $1/2$, and proved that
randomized algorithms can do better. A natural question thus arises: \emph{how
random is random}? i.e., how much randomness is needed to outperform
deterministic algorithms? The \textsc{ranking} algorithm of Karp et
al.~requires $\tilde{O}(n)$ random bits, which, ignoring polylog terms,
remained unimproved. On the other hand, Pena and Borodin (TCS'19) established a
lower bound of $(1-o(1))\log\log n$ random bits for any $1/2+\Omega(1)$
competitive ratio.
</p>
<p>We close this doubly-exponential gap, proving that, surprisingly, the lower
bound is tight. In fact, we prove a \emph{sharp threshold} of $(1\pm
o(1))\log\log n$ random bits for the randomness necessary and sufficient to
outperform deterministic algorithms for this problem, as well as its
vertex-weighted generalization. This implies the same threshold for the advice
complexity (nondeterminism) of these problems.
</p>
<p>Similar to recent breakthroughs in the online matching literature, for
edge-weighted matching (Fahrbach et al.~FOCS'20) and adwords (Huang et
al.~FOCS'20), our algorithms break the barrier of $1/2$ by randomizing matching
choices over two neighbors. Unlike these works, our approach does not rely on
the recently-introduced OCS machinery, nor the more established randomized
primal-dual method. Instead, our work revisits a highly-successful online
design technique, which was nonetheless under-utilized in the area of online
matching, namely (lossless) online rounding of fractional algorithms. While
this technique is known to be hopeless for online matching in general, we show
that it is nonetheless applicable to carefully designed fractional algorithms
with additional (non-convex) constraints.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04856</id>
    <link href="http://arxiv.org/abs/2106.04856" rel="alternate" type="text/html"/>
    <title>Strongly Sublinear Algorithms for Testing Pattern Freeness</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Newman:Ilan.html">Ilan Newman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Varma:Nithin.html">Nithin Varma</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04856">PDF</a><br/><b>Abstract: </b>Given a permutation $\pi:[k] \to [k]$, a function $f:[n] \to \mathbb{R}$
contains a $\pi$-appearance if there exists $1 \leq i_1 &lt; i_2 &lt; \dots &lt; i_k
\leq n$ such that for all $s,t \in [k]$, it holds that $f(i_s) &lt; f(i_t)$ if and
only if $\pi(s) &lt; \pi(t)$. The function is $\pi$-free if it has no
$\pi$-appearances. In this paper, we investigate the problem of testing whether
an input function $f$ is $\pi$-free or whether at least $\varepsilon n$ values
in $f$ need to be changed in order to make it $\pi$-free. This problem is a
generalization of the well-studied monotonicity testing and was first studied
by Newman, Rabinovich, Rajendraprasad and Sohler (Random Structures and
Algorithms 2019). We show that for all constants $k \in \mathbb{N}$,
$\varepsilon \in (0,1)$, and permutation $\pi:[k] \to [k]$, there is a
one-sided error $\varepsilon$-testing algorithm for $\pi$-freeness of functions
$f:[n] \to \mathbb{R}$ that makes $\tilde{O}(n^{o(1)})$ queries. We improve
significantly upon the previous best upper bound $O(n^{1 - 1/(k-1)})$ by
Ben-Eliezer and Canonne (SODA 2018). Our algorithm is adaptive, while the
earlier best upper bound is known to be tight for nonadaptive algorithms.
Hence, our results also show that adaptivity helps in testing freeness of order
patterns.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04819</id>
    <link href="http://arxiv.org/abs/2106.04819" rel="alternate" type="text/html"/>
    <title>Contextual Recommendations and Low-Regret Cutting-Plane Algorithms</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gollapudi:Sreenivas.html">Sreenivas Gollapudi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guruganesh:Guru.html">Guru Guruganesh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kollias:Kostas.html">Kostas Kollias</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manurangsi:Pasin.html">Pasin Manurangsi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leme:Renato_Paes.html">Renato Paes Leme</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schneider:Jon.html">Jon Schneider</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04819">PDF</a><br/><b>Abstract: </b>We consider the following variant of contextual linear bandits motivated by
routing applications in navigational engines and recommendation systems. We
wish to learn a hidden $d$-dimensional value $w^*$. Every round, we are
presented with a subset $\mathcal{X}_t \subseteq \mathbb{R}^d$ of possible
actions. If we choose (i.e. recommend to the user) action $x_t$, we obtain
utility $\langle x_t, w^* \rangle$ but only learn the identity of the best
action $\arg\max_{x \in \mathcal{X}_t} \langle x, w^* \rangle$. We design
algorithms for this problem which achieve regret $O(d\log T)$ and $\exp(O(d
\log d))$. To accomplish this, we design novel cutting-plane algorithms with
low "regret" -- the total distance between the true point $w^*$ and the
hyperplanes the separation oracle returns. We also consider the variant where
we are allowed to provide a list of several recommendations. In this variant,
we give an algorithm with $O(d^2 \log d)$ regret and list size
$\mathrm{poly}(d)$. Finally, we construct nearly tight algorithms for a weaker
variant of this problem where the learner only learns the identity of an action
that is better than the recommendation. Our results rely on new algorithmic
techniques in convex geometry (including a variant of Steiner's formula for the
centroid of a convex set) which may be of independent interest.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04769</id>
    <link href="http://arxiv.org/abs/2106.04769" rel="alternate" type="text/html"/>
    <title>Submodular + Concave</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitra:Siddharth.html">Siddharth Mitra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldman:Moran.html">Moran Feldman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karbasi:Amin.html">Amin Karbasi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04769">PDF</a><br/><b>Abstract: </b>It has been well established that first order optimization methods can
converge to the maximal objective value of concave functions and provide
constant factor approximation guarantees for (non-convex/non-concave)
continuous submodular functions. In this work, we initiate the study of the
maximization of functions of the form $F(x) = G(x) +C(x)$ over a solvable
convex body $P$, where $G$ is a smooth DR-submodular function and $C$ is a
smooth concave function. This class of functions is a strict extension of both
concave and continuous DR-submodular functions for which no theoretical
guarantee is known. We provide a suite of Frank-Wolfe style algorithms, which,
depending on the nature of the objective function (i.e., if $G$ and $C$ are
monotone or not, and non-negative or not) and on the nature of the set $P$
(i.e., whether it is downward closed or not), provide $1-1/e$, $1/e$, or $1/2$
approximation guarantees. We then use our algorithms to get a framework to
smoothly interpolate between choosing a diverse set of elements from a given
ground set (corresponding to the mode of a determinantal point process) and
choosing a clustered set of elements (corresponding to the maxima of a suitable
concave function). Additionally, we apply our algorithms to various functions
in the above class (DR-submodular + concave) in both constrained and
unconstrained settings, and show that our algorithms consistently outperform
natural baselines.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04727</id>
    <link href="http://arxiv.org/abs/2106.04727" rel="alternate" type="text/html"/>
    <title>ParChain: A Framework for Parallel Hierarchical Agglomerative Clustering using Nearest-Neighbor Chain</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Shangdi.html">Shangdi Yu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yiqiu.html">Yiqiu Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gu:Yan.html">Yan Gu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dhulipala:Laxman.html">Laxman Dhulipala</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shun:Julian.html">Julian Shun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04727">PDF</a><br/><b>Abstract: </b>This paper studies the hierarchical clustering problem, where the goal is to
produce a dendrogram that represents clusters at varying scales of a data set.
We propose the ParChain framework for designing parallel hierarchical
agglomerative clustering (HAC) algorithms, and using the framework we obtain
novel parallel algorithms for the complete linkage, average linkage, and Ward's
linkage criteria. Compared to most previous parallel HAC algorithms, which
require quadratic memory, our new algorithms require only linear memory, and
are scalable to large data sets. ParChain is based on our parallelization of
the nearest-neighbor chain algorithm, and enables multiple clusters to be
merged on every round. We introduce two key optimizations that are critical for
efficiency: a range query optimization that reduces the number of distance
computations required when finding nearest neighbors of clusters, and a caching
optimization that stores a subset of previously computed distances, which are
likely to be reused.
</p>
<p>Experimentally, we show that our highly-optimized implementations using 48
cores with two-way hyper-threading achieve 5.8--110.1x speedup over
state-of-the-art parallel HAC algorithms and achieve 13.75--54.23x
self-relative speedup. Compared to state-of-the-art algorithms, our algorithms
require up to 237.3x less space. Our algorithms are able to scale to data set
sizes with tens of millions of points, which existing algorithms are not able
to handle.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04708</id>
    <link href="http://arxiv.org/abs/2106.04708" rel="alternate" type="text/html"/>
    <title>Boolean Matrix Factorization via Nonnegative Auxiliary Optimization</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Truong:Duc_P=.html">Duc P. Truong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Skau:Erik.html">Erik Skau</a>, Derek Desantis, Boian Alexandrov <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04708">PDF</a><br/><b>Abstract: </b>A novel approach to Boolean matrix factorization (BMF) is presented. Instead
of solving the BMF problem directly, this approach solves a nonnegative
optimization problem with the constraint over an auxiliary matrix whose Boolean
structure is identical to the initial Boolean data. Then the solution of the
nonnegative auxiliary optimization problem is thresholded to provide a solution
for the BMF problem. We provide the proofs for the equivalencies of the two
solution spaces under the existence of an exact solution. Moreover, the
nonincreasing property of the algorithm is also proven. Experiments on
synthetic and real datasets are conducted to show the effectiveness and
complexity of the algorithm compared to other current methods.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04704</id>
    <link href="http://arxiv.org/abs/2106.04704" rel="alternate" type="text/html"/>
    <title>Pricing Ordered Items</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Shuchi Chawla, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rezvan:Rojin.html">Rojin Rezvan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Teng:Yifeng.html">Yifeng Teng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tzamos:Christos.html">Christos Tzamos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04704">PDF</a><br/><b>Abstract: </b>We study the revenue guarantees and approximability of item pricing. Recent
work shows that with $n$ heterogeneous items, item-pricing guarantees an
$O(\log n)$ approximation to the optimal revenue achievable by any (buy-many)
mechanism, even when buyers have arbitrarily combinatorial valuations. However,
finding good item prices is challenging -- it is known that even under
unit-demand valuations, it is NP-hard to find item prices that approximate the
revenue of the optimal item pricing better than $O(\sqrt{n})$.
</p>
<p>Our work provides a more fine-grained analysis of the revenue guarantees and
computational complexity in terms of the number of item ``categories'' which
may be significantly fewer than $n$. We assume the items are partitioned in $k$
categories so that items within a category are totally-ordered and a buyer's
value for a bundle depends only on the best item contained from every category.
</p>
<p>We show that item-pricing guarantees an $O(\log k)$ approximation to the
optimal (buy-many) revenue and provide a PTAS for computing the optimal
item-pricing when $k$ is constant. We also provide a matching lower bound
showing that the problem is (strongly) NP-hard even when $k=1$. Our results
naturally extend to the case where items are only partially ordered, in which
case the revenue guarantees and computational complexity depend on the width of
the partial ordering, i.e. the largest set for which no two items are
comparable.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04633</id>
    <link href="http://arxiv.org/abs/2106.04633" rel="alternate" type="text/html"/>
    <title>A Quantum Advantage for a Natural Streaming Problem</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kallaugher:John.html">John Kallaugher</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04633">PDF</a><br/><b>Abstract: </b>Data streaming, in which a large dataset is received as a "stream" of
updates, is an important model in the study of space-bounded computation.
Starting with the work of Le Gall [SPAA `06], it has been known that quantum
streaming algorithms can use asymptotically less space than their classical
counterparts for certain problems. However, so far, all known examples of
quantum advantages in streaming are for problems that are either specially
constructed for that purpose, or require many streaming passes over the input.
</p>
<p>We give a one-pass quantum streaming algorithm for one of the best studied
problems in classical graph streaming - the triangle counting problem.
Almost-tight parametrized upper and lower bounds are known for this problem in
the classical setting; our algorithm uses polynomially less space in certain
regions of the parameter space, resolving a question posed by Jain and Nayak in
2014 on achieving quantum advantages for natural streaming problems.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04629</id>
    <link href="http://arxiv.org/abs/2106.04629" rel="alternate" type="text/html"/>
    <title>New Competitive Semi-online Scheduling Algorithms for Small Number of Identical Machines</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dwibedy:Debasis.html">Debasis Dwibedy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mohanty:Rakesh.html">Rakesh Mohanty</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04629">PDF</a><br/><b>Abstract: </b>Design and analysis of constant competitive deterministic semi-online
algorithms for the multi-processor scheduling problem with small number of
identical machines have gained significant research interest in the last two
decades. In the semi-online scheduling problem for makespan minimization, we
are given a sequence of independent jobs one by one in order and upon arrival,
each job must be allocated to a machine with prior knowledge of some Extra
Piece of Information (EPI) about the future jobs. Researchers have designed
multiple variants of semi-online scheduling algorithms with constant
competitive ratios by considering one or more EPI. In this paper, we propose
four new variants of competitive deterministic semi-online algorithms for
smaller number of identical machines by considering two EPI such as Decr and
Sum. We obtain improved upper bound and lower bound results on the competitive
ratio for our proposed algorithms, which are comparable to the best known
results in the literature. In two identical machines setting with known Sum, we
show a tight bound of 1.33 on the competitive ratio by considering a sequence
of equal size jobs. In the same setting we achieve a lower bound of 1.04 and an
upper bound of 1.16 by considering Sum and a sequence of jobs arriving in order
of decreasing sizes. For three identical machines setting with known Decr and
Sum, we show a lower bound of 1.11 on the competitive ratio. In this setting,
we obtain an upper bound of 1.5 for scheduling a sequence of equal size jobs
and achieves an upper bound of 1.2 by considering a sequence of decreasing size
jobs. Further we develop an improved competitive algorithm with an upper bound
of 1.11 on the competitive ratio.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04486</id>
    <link href="http://arxiv.org/abs/2106.04486" rel="alternate" type="text/html"/>
    <title>Sketch-Based Streaming Anomaly Detection in Dynamic Graphs</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Siddharth Bhatia, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wadhwa:Mohit.html">Mohit Wadhwa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Philip_S=.html">Philip S. Yu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hooi:Bryan.html">Bryan Hooi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04486">PDF</a><br/><b>Abstract: </b>Given a stream of graph edges from a dynamic graph, how can we assign anomaly
scores to edges and subgraphs in an online manner, for the purpose of detecting
unusual behavior, using constant time and memory? For example, in intrusion
detection, existing work seeks to detect either anomalous edges or anomalous
subgraphs, but not both. In this paper, we first extend the count-min sketch
data structure to a higher-order sketch. This higher-order sketch has the
useful property of preserving the dense subgraph structure (dense subgraphs in
the input turn into dense submatrices in the data structure). We then propose
four online algorithms that utilize this enhanced data structure, which (a)
detect both edge and graph anomalies; (b) process each edge and graph in
constant memory and constant update time per newly arriving edge, and; (c)
outperform state-of-the-art baselines on four real-world datasets. Our method
is the first streaming approach that incorporates dense subgraph search to
detect graph anomalies in constant memory and time.
</p></div>
    </summary>
    <updated>2021-06-10T00:22:26Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04365</id>
    <link href="http://arxiv.org/abs/2106.04365" rel="alternate" type="text/html"/>
    <title>robustBF: A High Accuracy and Memory Efficient 2D Bloom Filter</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patgiri:Ripon.html">Ripon Patgiri</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04365">PDF</a><br/><b>Abstract: </b>Bloom Filter is an important probabilistic data structure to reduce memory
consumption for membership filters. It is applied in diverse domains such as
Computer Networking, Network Security and Privacy, IoT, Edge Computing, Cloud
Computing, Big Data, and Biometrics. But Bloom Filter has an issue of the false
positive probability. To address this issue, we propose a novel robust Bloom
Filter, robustBF for short. robustBF is a 2D Bloom Filter, capable of filtering
millions of data with high accuracy without compromising the performance. Our
proposed system is presented in two-fold. Firstly, we modify the murmur hash
function, and test all modified hash functions for improvements and select the
best-modified hash function experimentally. Secondly, we embed the modified
hash functions in 2D Bloom Filter. Our experimental results show that robustBF
is better than standard Bloom Filter and counting Bloom Filter in every aspect.
robustBF exhibits nearly zero false positive probability with more than
$10\times$ and $44\times$ lower memory consumption than standard Bloom filter
and counting Bloom Filter, respectively.
</p></div>
    </summary>
    <updated>2021-06-09T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04364</id>
    <link href="http://arxiv.org/abs/2106.04364" rel="alternate" type="text/html"/>
    <title>countBF: A General-purpose High Accuracy and Space Efficient Counting Bloom Filter</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nayak:Sabuzima.html">Sabuzima Nayak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patgiri:Ripon.html">Ripon Patgiri</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04364">PDF</a><br/><b>Abstract: </b>Bloom Filter is a probabilistic data structure for the membership query, and
it has been intensely experimented in various fields to reduce memory
consumption and enhance a system's performance. Bloom Filter is classified into
two key categories: counting Bloom Filter (CBF), and non-counting Bloom Filter.
CBF has a higher false positive probability than standard Bloom Filter (SBF),
i.e., CBF uses a higher memory footprint than SBF. But CBF can address the
issue of the false negative probability. Notably, SBF is also false negative
free, but it cannot support delete operations like CBF. To address these
issues, we present a novel counting Bloom Filter based on SBF and 2D Bloom
Filter, called countBF. countBF uses a modified murmur hash function to enhance
its various requirements, which is experimentally evaluated. Our experimental
results show that countBF uses $1.96\times$ and $7.85\times$ less memory than
SBF and CBF respectively, while preserving lower false positive probability and
execution time than both SBF and CBF. The overall accuracy of countBF is
$99.999921$, and it proves the superiority of countBF over SBF and CBF. Also,
we compare with other state-of-the-art counting Bloom Filters.
</p></div>
    </summary>
    <updated>2021-06-09T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04254</id>
    <link href="http://arxiv.org/abs/2106.04254" rel="alternate" type="text/html"/>
    <title>Coresets for Classification -- Simplified and Strengthened</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mai:Tung.html">Tung Mai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rao:Anup_B=.html">Anup B. Rao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Musco:Cameron.html">Cameron Musco</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04254">PDF</a><br/><b>Abstract: </b>We give relative error coresets for training linear classifiers with a broad
class of loss functions, including the logistic loss and hinge loss. Our
construction achieves $(1\pm \epsilon)$ relative error with $\tilde O(d \cdot
\mu_y(X)^2/\epsilon^2)$ points, where $\mu_y(X)$ is a natural complexity
measure of the data matrix $X \in \mathbb{R}^{n \times d}$ and label vector $y
\in \{-1,1\}^n$, introduced in by Munteanu et al. 2018. Our result is based on
subsampling data points with probabilities proportional to their $\ell_1$
$Lewis$ $weights$. It significantly improves on existing theoretical bounds and
performs well in practice, outperforming uniform subsampling along with other
importance sampling methods. Our sampling distribution does not depend on the
labels, so can be used for active learning. It also does not depend on the
specific loss function, so a single coreset can be used in multiple training
scenarios.
</p></div>
    </summary>
    <updated>2021-06-09T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04247</id>
    <link href="http://arxiv.org/abs/2106.04247" rel="alternate" type="text/html"/>
    <title>Private Counting from Anonymous Messages: Near-Optimal Accuracy with Vanishing Communication Overhead</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghazi:Badih.html">Badih Ghazi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Ravi.html">Ravi Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manurangsi:Pasin.html">Pasin Manurangsi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pagh:Rasmus.html">Rasmus Pagh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04247">PDF</a><br/><b>Abstract: </b>Differential privacy (DP) is a formal notion for quantifying the privacy loss
of algorithms. Algorithms in the central model of DP achieve high accuracy but
make the strongest trust assumptions whereas those in the local DP model make
the weakest trust assumptions but incur substantial accuracy loss. The shuffled
DP model (Bittau et al., 2017; Erlingsson et al., 2019; Cheu et al., 2019) has
recently emerged as a feasible middle ground between the central and local
models, providing stronger trust assumptions than the former while promising
higher accuracies than the latter. In this paper, we obtain practical
communication-efficient algorithms in the shuffled DP model for two basic
aggregation primitives used in machine learning: 1) binary summation, and 2)
histograms over a moderate number of buckets. Our algorithms achieve accuracy
that is arbitrarily close to that of central DP algorithms with an expected
communication per user essentially matching what is needed without any privacy
constraints! We demonstrate the practicality of our algorithms by
experimentally comparing their performance to several widely-used protocols
such as Randomized Response (Warner, 1965) and RAPPOR (Erlingsson et al.,
2014).
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04224</id>
    <link href="http://arxiv.org/abs/2106.04224" rel="alternate" type="text/html"/>
    <title>Improved Online Correlated Selection</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Ruiquan Gao, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/He:Zhongtian.html">Zhongtian He</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Zhiyi.html">Zhiyi Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nie:Zipei.html">Zipei Nie</a>, Bijun Yuan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhong:Yan.html">Yan Zhong</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04224">PDF</a><br/><b>Abstract: </b>This paper studies the online correlated selection (OCS) problem introduced
by Fahrbach, Huang, Tao, and Zadimoghaddam (2020) to get the first
edge-weighted online bipartite matching algorithm that breaks the $0.5$
barrier. Suppose that we receive a pair of elements in each round and select
one of them. Can we select with negative correlation to be more effective than
independent random selections? Our contributions are threefold. For semi-OCS,
which considers the probability that an element remains unselected after
appearing in $k$ rounds, we give an optimal algorithm that minimizes this
probability for all $k$. It leads to $0.536$-competitive unweighted and
vertex-weighted online bipartite matching algorithms that randomize over only
two options in each round, improving the previous 0.508-competitive ratio by
Fahrbach et al. (2020). Further, we give the first multi-way semi-OCS that
allows an arbitrary number of elements with arbitrary masses in each round. As
an application, it rounds the Balance algorithm in unweighted and
vertex-weighted online bipartite matching to get a $0.593$-competitive ratio.
This is the first algorithm other than Ranking whose competitive ratio is
beyond the $0.5 + \epsilon$ regime. Finally, we study OCS, which further
considers the probability that an element is unselected in any subset of
rounds. We prove that the optimal "level of negative correlation" is between
$0.167$ and $0.25$, improving the previous bounds of $0.109$ and $1$ by
Fahrbach et al. (2020). Our OCS gives a $0.519$-competitive edge-weighted
online bipartite matching algorithm, improving the previous $0.508$-competitive
ratio by Fahrbach et al. (2020).
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04191</id>
    <link href="http://arxiv.org/abs/2106.04191" rel="alternate" type="text/html"/>
    <title>FPT Algorithms to Compute the Elimination Distance to Bipartite Graphs and More</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jansen:Bart_M=_P=.html">Bart M. P. Jansen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kroon:Jari_J=_H=_de.html">Jari J. H. de Kroon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04191">PDF</a><br/><b>Abstract: </b>For a hereditary graph class $\mathcal{H}$, the $\mathcal{H}$-elimination
distance of a graph $G$ is the minimum number of rounds needed to reduce $G$ to
a member of $\mathcal{H}$ by removing one vertex from each connected component
in each round. The $\mathcal{H}$-treewidth of a graph $G$ is the minimum, taken
over all vertex sets $X$ for which each connected component of $G - X$ belongs
to $\mathcal{H}$, of the treewidth of the graph obtained from $G$ by replacing
the neighborhood of each component of $G-X$ by a clique and then removing $V(G)
\setminus X$. These parameterizations recently attracted interest because they
are simultaneously smaller than the graph-complexity measures treedepth and
treewidth, respectively, and the vertex-deletion distance to $\mathcal{H}$. For
the class $\mathcal{H}$ of bipartite graphs, we present non-uniform
fixed-parameter tractable algorithms for testing whether the
$\mathcal{H}$-elimination distance or $\mathcal{H}$-treewidth of a graph is at
most $k$. Along the way, we also provide such algorithms for all graph classes
$\mathcal{H}$ defined by a finite set of forbidden induced subgraphs.
</p></div>
    </summary>
    <updated>2021-06-09T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04179</id>
    <link href="http://arxiv.org/abs/2106.04179" rel="alternate" type="text/html"/>
    <title>Deterministic $(1+\varepsilon)$-Approximate Maximum Matching with $\mathsf{poly}(1/\varepsilon)$ Passes in the Semi-Streaming Model</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fischer:Manuela.html">Manuela Fischer</a>, Slobodan Mitrović, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Uitto:Jara.html">Jara Uitto</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04179">PDF</a><br/><b>Abstract: </b>We present a deterministic $(1+\varepsilon)$-approximate maximum matching
algorithm in $\mathsf{poly}(1/\varepsilon)$ passes in the semi-streaming model,
solving the long-standing open problem of breaking the exponential barrier in
the dependence on $1/\varepsilon$. Our algorithm exponentially improves on the
well-known randomized $(1/\varepsilon)^{O(1/\varepsilon)}$-pass algorithm from
the seminal work by McGregor [APPROX05], the recent deterministic algorithm by
Tirodkar with the same pass complexity [FSTTCS18], as well as the deterministic
$\log n \cdot \mathsf{poly}(1/\varepsilon)$-pass algorithm by Ahn and Guha
[ICALP11].
</p></div>
    </summary>
    <updated>2021-06-09T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04105</id>
    <link href="http://arxiv.org/abs/2106.04105" rel="alternate" type="text/html"/>
    <title>Entropic Independence in High-Dimensional Expanders: Modified Log-Sobolev Inequalities for Fractionally Log-Concave Polynomials and the Ising Model</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Anari:Nima.html">Nima Anari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Vishesh.html">Vishesh Jain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koehler:Frederic.html">Frederic Koehler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pham:Huy_Tuan.html">Huy Tuan Pham</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vuong:Thuy=Duong.html">Thuy-Duong Vuong</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04105">PDF</a><br/><b>Abstract: </b>We introduce a notion called entropic independence for distributions $\mu$
defined on pure simplicial complexes, i.e., subsets of size $k$ of a ground set
of elements. Informally, we call a background measure $\mu$ entropically
independent if for any (possibly randomly chosen) set $S$, the relative entropy
of an element of $S$ drawn uniformly at random carries at most $O(1/k)$
fraction of the relative entropy of $S$, a constant multiple of its ``share of
entropy.'' Entropic independence is the natural analog of spectral
independence, another recently established notion, if one replaces variance by
entropy.
</p>
<p>In our main result, we show that $\mu$ is entropically independent exactly
when a transformed version of the generating polynomial of $\mu$ can be upper
bounded by its linear tangent, a property implied by concavity of the said
transformation. We further show that this concavity is equivalent to spectral
independence under arbitrary external fields, an assumption that also goes by
the name of fractional log-concavity. Our result can be seen as a new tool to
establish entropy contraction from the much simpler variance contraction
inequalities. A key differentiating feature of our result is that we make no
assumptions on marginals of $\mu$ or the degrees of the underlying graphical
model when $\mu$ is based on one. We leverage our results to derive tight
modified log-Sobolev inequalities for multi-step down-up walks on fractionally
log-concave distributions. As our main application, we establish the tight
mixing time of $O(n\log n)$ for Glauber dynamics on Ising models with
interaction matrix of operator norm smaller than $1$, improving upon the prior
quadratic dependence on $n$.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04037</id>
    <link href="http://arxiv.org/abs/2106.04037" rel="alternate" type="text/html"/>
    <title>Online Algorithms for Network Robustness under Connectivity Constraints</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Muthirayan:Deepan.html">Deepan Muthirayan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khargonekar:Pramod_P=.html">Pramod P. Khargonekar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04037">PDF</a><br/><b>Abstract: </b>In this paper, we present algorithms for designing networks that are robust
to node failures with minimal or limited number of links. We present algorithms
for both the static network setting and the dynamic network setting; setting
where new nodes can arrive in the future. For the static setting, we present
algorithms for constructing the optimal network in terms of the number of links
used for a given node size and the number of nodes that can fail. We then
consider the dynamic setting where it is disruptive to remove any of the older
links. For this setting, we present online algorithms for two cases: (i) when
the number of nodes that can fail remains constant and (ii) when only the
proportion of the nodes that can fail remains constant. We show that the
proposed algorithm for the first case saves nearly $3/4$th of the total
possible links at any point of time. We then present algorithms for various
levels of the fraction of the nodes that can fail and characterize their link
usage. We show that when $1/2$ the number of nodes can fail at any point of
time, the proposed algorithm saves nearly $1/2$ of the total possible links at
any point of time. We show that when the number of nodes that can fail is
limited to the fraction $1/(2m)$ ($m \in \mathbb{N}$), the proposed algorithm
saves nearly as much as $(1-1/2m)$ of the total possible links at any point of
time. We also show that when the number of nodes that can fail at any point of
time is $1/2$ of the number of nodes plus $n$, $n \in \mathbb{N}$, the number
of links saved by the proposed algorithm reduces only linearly in $n$. We
conjecture that the saving ratio achieved by the algorithms we present is
optimal for the dynamic setting.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.03969</id>
    <link href="http://arxiv.org/abs/2106.03969" rel="alternate" type="text/html"/>
    <title>Chow-Liu++: Optimal Prediction-Centric Learning of Tree Ising Models</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Enric Boix-Adsera, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bresler:Guy.html">Guy Bresler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koehler:Frederic.html">Frederic Koehler</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.03969">PDF</a><br/><b>Abstract: </b>We consider the problem of learning a tree-structured Ising model from data,
such that subsequent predictions computed using the model are accurate.
Concretely, we aim to learn a model such that posteriors $P(X_i|X_S)$ for small
sets of variables $S$ are accurate. Since its introduction more than 50 years
ago, the Chow-Liu algorithm, which efficiently computes the maximum likelihood
tree, has been the benchmark algorithm for learning tree-structured graphical
models. A bound on the sample complexity of the Chow-Liu algorithm with respect
to the prediction-centric local total variation loss was shown in [BK19]. While
those results demonstrated that it is possible to learn a useful model even
when recovering the true underlying graph is impossible, their bound depends on
the maximum strength of interactions and thus does not achieve the
information-theoretic optimum. In this paper, we introduce a new algorithm that
carefully combines elements of the Chow-Liu algorithm with tree metric
reconstruction methods to efficiently and optimally learn tree Ising models
under a prediction-centric loss. Our algorithm is robust to model
misspecification and adversarial corruptions. In contrast, we show that the
celebrated Chow-Liu algorithm can be arbitrarily suboptimal.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.03943</id>
    <link href="http://arxiv.org/abs/2106.03943" rel="alternate" type="text/html"/>
    <title>Near-Optimal Dispersion on Arbitrary Anonymous Graphs</title>
    <feedworld_mtime>1623283200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kshemkalyani:Ajay_D=.html">Ajay D. Kshemkalyani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sharma:Gokarna.html">Gokarna Sharma</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.03943">PDF</a><br/><b>Abstract: </b>Given an undirected, anonymous, port-labeled graph of $n$ memory-less nodes,
$m$ edges, and degree $\Delta$, we consider the problem of dispersing $k\leq n$
robots (or tokens) positioned initially arbitrarily on one or more nodes of the
graph to exactly $k$ different nodes of the graph, one on each node. The
objective is to simultaneously minimize time to achieve dispersion and memory
requirement at each robot. If all $k$ robots are positioned initially on a
single node, depth first search (DFS) traversal solves this problem in
$O(\min\{m,k\Delta\})$ time with $\Theta(\log(k+\Delta))$ bits at each robot.
However, if robots are positioned initially on multiple nodes, the best
previously known algorithm solves this problem in $O(\min\{m,k\Delta\}\cdot
\log \ell)$ time storing $\Theta(\log(k+\Delta))$ bits at each robot, where
$\ell\leq k/2$ is the number of multiplicity nodes in the initial
configuration. In this paper, we present a novel multi-source DFS traversal
algorithm solving this problem in $O(\min\{m,k\Delta\})$ time with
$\Theta(\log(k+\Delta))$ bits at each robot, improving the time bound of the
best previously known algorithm by $O(\log \ell)$ and matching asymptotically
the single-source DFS traversal bounds. This is the first algorithm for
dispersion that is optimal in both time and memory in arbitrary anonymous
graphs of constant degree, $\Delta=O(1)$. Furthermore, the result holds in both
synchronous and asynchronous settings.
</p></div>
    </summary>
    <updated>2021-06-10T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2021-06-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2021/079</id>
    <link href="https://eccc.weizmann.ac.il/report/2021/079" rel="alternate" type="text/html"/>
    <title>TR21-079 |  The zero-rate threshold for adversarial bit-deletions is less than 1/2 | 

	Venkatesan Guruswami, 

	Xiaoyu He, 

	Ray Li</title>
    <summary>We prove that there exists an absolute constant $\delta&gt;0$ such any binary code $C\subset\{0,1\}^N$ tolerating $(1/2-\delta)N$ adversarial deletions must satisfy $|C|\le 2^{\poly\log N}$ and thus have rate asymptotically approaching $0$. This is the first constant fraction improvement over the trivial bound that codes tolerating $N/2$ adversarial deletions must have rate going to $0$ asymptotically.  Equivalently, we show that there exists absolute constants $A$ and $\delta&gt;0$ such that any set $C\subset\{0,1\}^N$ of $2^{\log^A N}$ binary strings must contain two strings $c$ and $c'$ whose longest common subsequence has length at least $(1/2+\delta)N$. As an immediate corollary, we show that $q$-ary codes tolerating a fraction $1-(1+2\delta)/q$ of adversarial deletions must also have rate approaching $0$.
 
Our techniques include string regularity arguments and a structural lemma that classifies binary strings by their oscillation patterns.  Leveraging these tools, we find in any large code two strings with similar oscillation patterns, which is exploited to find a long common subsequence.</summary>
    <updated>2021-06-09T16:59:13Z</updated>
    <published>2021-06-09T16:59:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2021-06-10T20:20:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=21799</id>
    <link href="https://gilkalai.wordpress.com/2021/06/09/to-cheer-you-up-in-difficult-times-26-two-real-life-lectures-yesterday-at-the-technion/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 26: Two real-life lectures yesterday at the Technion</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">After 16 months without lecturing to an audience in my same location, I gave yesterday two lectures at the Technion in front of a live audience (and some additional audience in remote locations). The main lecture was in COMSOC 2021, … <a href="https://gilkalai.wordpress.com/2021/06/09/to-cheer-you-up-in-difficult-times-26-two-real-life-lectures-yesterday-at-the-technion/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>After 16 months without lecturing to an audience in my same location, I gave yesterday two lectures at the Technion in front of a live audience (and some additional audience in remote locations). The main lecture was in <a href="https://comsoc2021.net.technion.ac.il/">COMSOC 2021,</a> an international conference on computational social choice,  and earlier I gave a guest lecture in Roy Meshulam’s class about simple polytopes. I also met many friends. </p>
<p><a href="https://reshef.net.technion.ac.il/">Reshef Meir</a> who organized (with Bill Zwicker) COMSOC 2021 wrote:</p>
<blockquote>
<div><span style="color: #993366;"><em>Hi all, </em></span></div>
<div><span style="color: #993366;"><em>today was beyond expectations – the first feeling of a real actual conference after almost a year and a half!  We had about 40 people attending, viewing posters, and listening to talks. I truly hope this will return to be a common scene and that we can all meet face to face soon.</em></span></div>
</blockquote>
<div> </div>
<p>In my COMSOC lecture I talked about some earlier ideas and results in my work on social choice, starting with my paper with Ariel Rubinstein and Rani Spiegler on rationalizing individual choice by multiple rationals, and my subsequent attempt to use learnability as a tool for understanding choices of economic agents. This led to interesting questions on social choice <a href="https://gilkalai.wordpress.com/2009/06/02/social-choice-preview/">that are discussed in this 2009 post.</a></p>
<p>In Roy’s course I explained <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>-vectors of polytopes and the Dehn-Sommerville relations based on counting outdegrees of the graph of the polytope when we direct its edges based on a generic abstract objective function. I moved on to present a proof of Blind-Mani’s theorem that the graph of the polytope determines the full combinatorics. This proof is probably the one proof I presented the most and it is given in <a href="https://gilkalai.wordpress.com/2009/01/16/telling-a-simple-polytope-from-its-graph/">this 2009 post</a>.</p>
<p><img alt="sc1" class="alignnone size-full wp-image-21802" height="391" src="https://gilkalai.files.wordpress.com/2021/06/sc1.png" width="420"/></p>
<p><span style="color: #ff0000;">In my  COMSOC lecture I described how to fill the two question marks in the table above.</span></p>
<p><img alt="sc2" class="alignnone size-full wp-image-21803" height="391" src="https://gilkalai.files.wordpress.com/2021/06/sc2.png" width="420"/></p>


<p/></div>
    </content>
    <updated>2021-06-09T06:30:14Z</updated>
    <published>2021-06-09T06:30:14Z</published>
    <category term="Combinatorics"/>
    <category term="Convex polytopes"/>
    <category term="Economics"/>
    <category term="Games"/>
    <category term="Rationality"/>
    <category term="COMSOC 2021"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2021-06-10T20:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://ptreview.sublinear.info/?p=1526</id>
    <link href="https://ptreview.sublinear.info/?p=1526" rel="alternate" type="text/html"/>
    <title>News for May 2021</title>
    <summary>We hope you are all staying safe. With massive vaccination programs across the globe we hope you and your loved ones are getting back to what used to be normal. With that out of the way, let us circle back to Property Testing. This month was less sleepy as compared to the two preceding months […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We hope you are all staying safe. With massive vaccination programs across the globe we hope you and your loved ones are getting back to what used to be normal. With that out of the way, let us circle back to Property Testing. This month was less sleepy as compared to the two preceding months and we saw six papers in total (two of them explore problems in quantum property testing). Without further ado, let us take a deeper dive.</p>



<p/>



<p><strong>GSF-locality is not sufficient for proximity-oblivious testing</strong>, by Isolde Adler, Noleen Kohler, Pan Peng (<a href="https://arxiv.org/abs/2105.08490">arXiv</a>) The notion of proximity oblivious testers was made explicit in the seminal work of Goldreich and Ron in 2009 [GR09]. A proximity oblivious tester for a graph property is a constant query tester that rejects a graph with probability that monotonically increases with distance to the property. (<strong>Edit</strong>: <em>Correction</em>) A property is called proximity oblivious testable (or PO testable) if it has a one sided proximity oblivious tester. [GR09] gave a characterization of which properties \(\Pi\) are PO testable in the bounded degree model <em>if and only if</em> it is a “local” property of some kind which satisfies a certain non propagation condition. [GR09] conjectured that all such “local” properties satisfy this non propagation condition. This paper refutes the above conjecture from [GR09].</p>



<p/>



<p>Coming up next. More action on triangle freeness.</p>



<p><strong>Testing Triangle Freeness in the General Model in Graphs with Arboricity \(O(\sqrt n)\)</strong>, by Reut Levi (<a href="https://arxiv.org/abs/2105.04809">arXiv</a>) PTReview readers are likely to be aware that triangle freeness has been a rich source of problems for developing new sublinear time algorithms. This paper considers the classic problem of testing triangle freeness in general graphs. In the dense case, algorithms with running time depending only on \(\varepsilon\) are known thanks to the work of Alon, Fischer, Krivelevich and Szegedy. In the bounded degree case, Goldreich and Ron gave testers with query complexity \(O(1/\varepsilon)\). This paper explores the problem in general graph case and proves an upper bound of \(O(\Gamma/d_{avg} + \Gamma)\) where \(\Gamma\) is the arboricity of the graph. The author also shows that this upperbound is tight for graphs with arboricity at most \(O(\sqrt n)\). Curiously enough, the algorithm does not take arboricity of the graph as an input and yet \(\Gamma\) (the arboricity) shows up in the upper and lower bounds.</p>



<p/>



<p><strong>Testing Dynamic Environments: Back to Basics</strong>, by Yonatan Nakar and Dana Ron (<a href="https://arxiv.org/abs/2105.00759">arXiv</a>) Goldreich and Ron introduced the problem of testing “dynamic environments” in 2014. Here is the setup for this problem. You are given an environment that evolves according to a local rule.  Your goal is to query some of the states in the system at some point of time and determine if the system is evolving according to some fixed rule or is far from it. In this paper, the authors consider environments defined by elementary cellular automata which evolve according to threshold rules as one of the first steps towards understanding what makes a dynamic environment tested efficiently.  The main result proves the following: if your local rules satisfy some <em>conditions</em>, you can use a meta algorithm with query complexity \(poly(1/\varepsilon)\) which is non adaptive and has one sided error. And all the threshold rules indeed satisfy these <em>conditions</em> which means they can be tested efficiently. </p>



<p/>



<p><strong>Identity testing under label mismatch</strong>, by Clement Canonne and Karl Wimmer (<a href="https://arxiv.org/abs/2105.01856">arXiv</a>) This paper considers a classic problem distribution testing with the following twist. Let \(q\) denote a distribution supported on \([n]\). You are given access to samples from another distribution \(p\) where \(p  = q \circ \pi\) where \(\pi\) is some unknown permutation. Thus, I relabel the data and I give you access to samples from the relabeled dataset. Under this promise, note that identity testing becomes a trivial problem if \(q\) is known to be uniform over \([n]\). The authors develop algorithms for testing and tolerant testing of distributions under this additional promise of \(p\) being a permutation of some known distribution \(q\). The main result shows as exponential gap between the sample complexity of testing and tolerant testing under this promise. In particular, identity testing under the promise of permutation has sample complexity \(\Theta(\log^2 n)\) whereas tolerant identity testing under this promise has sample complexity \(\Theta(n^{1-o(1)})\).</p>



<p/>



<p><strong>Testing symmetry on quantum computers</strong>, by Margarite L. LaBorde and Mark M. Wilde (<a href="https://arxiv.org/abs/2105.12758">arXiv</a>) This paper develops algorithms which test symmetries of a quantum states and changes generated by quantum circuits. These tests additionally also quantify how symmetric these states (or channels) are. For testing what are called “Bose states” the paper presents efficient algorithms. The tests for other kinds of symmetry presented in the paper rely on some aid from a quantum prover.</p>



<p/>



<p><strong>Quantum proofs of proximity</strong>, by Marcel Dall’Agnol, Tom Gur, Subhayan Roy Moulik, Justin Thaler (<a href="https://eccc.weizmann.ac.il/report/2021/068/">ECCC</a>) The sublinear time (quantum) computation model has been gathering momentum steadily over the past several years. This paper seeks to understand the power of \({\sf QMA}\) proofs of proximity for property testing (recall \({\sf QMA}\) is the quantum analogue of \({\sf NP}\)). On the algorithmic front, the paper develops sufficient conditions for properties to admit efficient \({\sf QMA}\) proofs of proximity. On the complexity front, the paper demonstrates a property which admits  an efficient \({\sf QMA}\) proof but does not admit a \({\sf MA}\) or an interactive proof of proximity.</p></div>
    </content>
    <updated>2021-06-09T05:31:17Z</updated>
    <published>2021-06-09T05:31:17Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Akash</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2021-06-10T04:21:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04332</id>
    <link href="http://arxiv.org/abs/2106.04332" rel="alternate" type="text/html"/>
    <title>Progressive Spatio-Temporal Bilinear Network with Monte Carlo Dropout for Landmark-based Facial Expression Recognition with Uncertainty Estimation</title>
    <feedworld_mtime>1623196800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heidari:Negar.html">Negar Heidari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iosifidis:Alexandros.html">Alexandros Iosifidis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04332">PDF</a><br/><b>Abstract: </b>Deep neural networks have been widely used for feature learning in facial
expression recognition systems. However, small datasets and large intra-class
variability can lead to overfitting. In this paper, we propose a method which
learns an optimized compact network topology for real-time facial expression
recognition utilizing localized facial landmark features. Our method employs a
spatio-temporal bilinear layer as backbone to capture the motion of facial
landmarks during the execution of a facial expression effectively. Besides, it
takes advantage of Monte Carlo Dropout to capture the model's uncertainty which
is of great importance to analyze and treat uncertain cases. The performance of
our method is evaluated on three widely used datasets and it is comparable to
that of video-based state-of-the-art methods while it has much less complexity.
</p></div>
    </summary>
    <updated>2021-06-09T22:38:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-06-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04299</id>
    <link href="http://arxiv.org/abs/2106.04299" rel="alternate" type="text/html"/>
    <title>A direct product theorem for quantum communication complexity with applications to device-independent QKD</title>
    <feedworld_mtime>1623196800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Rahul.html">Rahul Jain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kundu:Srijita.html">Srijita Kundu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04299">PDF</a><br/><b>Abstract: </b>We give a direct product theorem for the entanglement-assisted interactive
quantum communication complexity of an $l$-player predicate $\mathsf{V}$. In
particular we show that for a distribution $p$ that is product across the input
sets of the $l$ players, the success probability of any entanglement-assisted
quantum communication protocol for computing $n$ copies of $\mathsf{V}$, whose
communication is $o(\log(\mathrm{eff}^*(\mathsf{V},p))\cdot n)$, goes down
exponentially in $n$. Here $\mathrm{eff}^*(\mathsf{V}, p)$ is a distributional
version of the quantum efficiency or partition bound introduced by Laplante,
Lerays and Roland (2014), which is a lower bound on the distributional quantum
communication complexity of computing a single copy of $\mathsf{V}$ with
respect to $p$.
</p>
<p>As an application of our result, we show that it is possible to do
device-independent quantum key distribution (DIQKD) without the assumption that
devices do not leak any information after inputs are provided to them. We
analyze the DIQKD protocol given by Jain, Miller and Shi (2017), and show that
when the protocol is carried out with devices that are compatible with $n$
copies of the Magic Square game, it is possible to extract $\Omega(n)$ bits of
key from it, even in the presence of $O(n)$ bits of leakage. Our security proof
is parallel, i.e., the honest parties can enter all their inputs into their
devices at once, and works for a leakage model that is arbitrarily interactive,
i.e., the devices of the honest parties Alice and Bob can exchange information
with each other and with the eavesdropper Eve in any number of rounds, as long
as the total number of bits or qubits communicated is bounded.
</p></div>
    </summary>
    <updated>2021-06-09T22:40:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-06-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2106.04086</id>
    <link href="http://arxiv.org/abs/2106.04086" rel="alternate" type="text/html"/>
    <title>Complexity classification of counting graph homomorphisms modulo a prime number</title>
    <feedworld_mtime>1623196800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bulatov:Andrei_A=.html">Andrei A. Bulatov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kazeminia:Amirhossein.html">Amirhossein Kazeminia</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04086">PDF</a><br/><b>Abstract: </b>Counting graph homomorphisms and its generalizations such as the Counting
Constraint Satisfaction Problem (CSP), its variations, and counting problems in
general have been intensively studied since the pioneering work of Valiant.
While the complexity of exact counting of graph homomorphisms (Dyer and
Greenhill, 2000) and the counting CSP (Bulatov, 2013, and Dyer and Richerby,
2013) is well understood, counting modulo some natural number has attracted
considerable interest as well. In their 2015 paper Faben and Jerrum suggested a
conjecture stating that counting homomorphisms to a fixed graph H modulo a
prime number is hard whenever it is hard to count exactly, unless H has
automorphisms of certain kind. In this paper we confirm this conjecture. As a
part of this investigation we develop techniques that widen the spectrum of
reductions available for modular counting and apply to the general CSP rather
than being limited to graph homomorphisms.
</p></div>
    </summary>
    <updated>2021-06-09T22:37:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2021-06-09T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=5539</id>
    <link href="https://www.scottaaronson.com/blog/?p=5539" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=5539#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=5539" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">More quantum computing popularization!</title>
    <summary xml:lang="en-US">I now have a feature article up at Quanta magazine, entitled “What Makes Quantum Computing So Hard To Explain?” I.e., why do journalists, investors, etc. so consistently get central points wrong, even after the subject has been in public consciousness for more than 25 years? Perhaps unsurprisingly, I found it hard to discuss that meta-level […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>I now have a feature article up at <em>Quanta</em> magazine, entitled <a href="https://www.quantamagazine.org/why-is-quantum-computing-so-hard-to-explain-20210608/">“What Makes Quantum Computing So Hard To Explain?”</a>  I.e., why do journalists, investors, etc. so consistently get central points wrong, even after the subject has been in public consciousness for more than 25 years?  Perhaps unsurprisingly, I found it hard to discuss that meta-level question, as <em>Quanta</em>‘s editors asked me to do, without also engaging in the object-level task of actually explaining QC.  For regular <em>Shtetl-Optimized</em> readers, there will be nothing new here, but I’m happy with how the piece turned out.</p>



<p>Accompanying the <em>Quanta</em> piece is a <a href="https://www.youtube.com/watch?v=jHoEjvuPoB8&amp;t=6s">10-minute YouTube explainer on quantum computing</a>, which (besides snazzy graphics) features interviews with me, John Preskill, and Dorit Aharonov.</p>



<p>On a different note, my colleague <a href="https://www.markwilde.com/">Mark Wilde</a> has recorded a <a href="https://soundcloud.com/mark-m-wilde/quantum-computer">punk-rock song about BosonSampling</a>.  I can honestly report that it’s some of the finest boson-themed music I’ve heard in years.  It includes the following lyrics:</p>



<blockquote class="wp-block-quote"><p>Quantum computer, Ain’t no loser<br/>Quantum computer, Quantum computer</p><p>People out on the streets<br/>They don’t know what it is<br/>They think it finds the cliques<br/>Or finds graph colorings<br/>But it don’t solve anything<br/>Said it don’t solve anything<br/>Bosonic slot machine<br/>My lil’ photonic dream</p></blockquote>



<p>Speaking of BosonSampling, A. S. Popova and A. N. Rubtsov, of the Skolkovo Institute in Moscow, have a new preprint entitled <a href="https://arxiv.org/abs/2106.01445">Cracking the Quantum Advantage threshold for Gaussian Boson Sampling</a>.  In it, they claim to give an efficient classical algorithm to simulate noisy GBS experiments, like the <a href="https://www.scottaaronson.com/blog/?p=5159">one six months ago</a> from USTC in China.  I’m still unsure how well this scales from 30-40 photons up to 50-70 photons; which imperfections of the USTC experiment are primarily being taken advantage of (photon losses?); and how this relates to the earlier proposed classical algorithms for simulating noisy BosonSampling, like the one by <a href="https://arxiv.org/abs/1409.3093">Kalai and Kindler</a>.  Anyone with any insight is welcome to share!</p>



<p>OK, one last announcement: the Simons Institute for the Theory of Computing, in Berkeley, has a new online lecture series called <a href="https://simons.berkeley.edu/news/institute-launches-breakthroughs-lecture-series">“Breakthroughs,”</a> which many readers of this blog might want to check out.</p></div>
    </content>
    <updated>2021-06-08T20:29:24Z</updated>
    <published>2021-06-08T20:29:24Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2021-06-10T17:41:45Z</updated>
    </source>
  </entry>
</feed>
