<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-05-15T21:22:44Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/05/15/postdoc-at-boston-college-apply-by-june-1-2019/</id>
    <link href="https://cstheory-jobs.org/2019/05/15/postdoc-at-boston-college-apply-by-june-1-2019/" rel="alternate" type="text/html"/>
    <title>Postdoc at Boston College (apply by June 1, 2019)</title>
    <summary>We invite applications for a postdoc position hosted by Hsin-Hao Su at Boston College. Areas of specific interests include but not limited to distributed graph algorithms, local algorithms, dynamic graph algorithms, gossip algorithms, and massive parallel computation algorithms. The starting date is flexible between Fall 2019 and Spring 2020. The position is for a period […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>We invite applications for a postdoc position hosted by Hsin-Hao Su at Boston College. Areas of specific interests include but not limited to distributed graph algorithms, local algorithms, dynamic graph algorithms, gossip algorithms, and massive parallel computation algorithms. The starting date is flexible between Fall 2019 and Spring 2020. The position is for a period of up to two years.</p>
<p>Website: <a href="https://sites.google.com/site/distributedhsinhao/postdoc">https://sites.google.com/site/distributedhsinhao/postdoc</a><br/>
Email: suhx@bc.edu</p></div>
    </content>
    <updated>2019-05-15T19:23:45Z</updated>
    <published>2019-05-15T19:23:45Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2019-05-15T21:21:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4191</id>
    <link href="https://www.scottaaronson.com/blog/?p=4191" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4191#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4191" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">The SSL Certificate of Damocles</title>
    <summary xml:lang="en-US">Ever since I “upgraded” this website to use SSL, it’s become completely inaccessible once every three months, because the SSL certificate expires. Several years in, I’ve been unable to find any way to prevent this from happening, and Bluehost technical support was unable to suggest any solution. The fundamental problem is that, as long as […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Ever since I “upgraded” this website to use SSL, it’s become completely inaccessible once every three months, because the SSL certificate expires.  Several years in, I’ve been unable to find any way to prevent this from happening, and Bluehost technical support was unable to suggest any solution.  The fundamental problem is that, as long as the site remains up, the Bluehost control panel tells me that there’s nothing to do, since there <em>is</em> a current certificate.  Meanwhile, though, I start getting menacing emails saying that my SSL certificate is about to expire and “you must take action to secure the site”—<em>never</em>, of course, specifying what action to take.  The only thing to do seems to be to wait for the whole site to go down, then frantically take random certificate-related actions until somehow the site goes back up.  Those actions vary each time and are not repeatable.</p>



<p>Does anyone know a simple solution to this ridiculous problem?</p>



<p>(The deeper problem, of course, is that a PhD in theoretical computer science left me utterly unqualified for the job of webmaster.  And webmasters, as it turns out, need to do a lot just to prevent anything from changing.  And since childhood, I’ve been accustomed to countless tasks that are trivial for most people being difficult for me—-if that ever stopped being the case, I’d no longer feel like myself.)</p></div>
    </content>
    <updated>2019-05-15T02:56:05Z</updated>
    <published>2019-05-15T02:56:05Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Self-Referential"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-05-15T03:23:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.05679</id>
    <link href="http://arxiv.org/abs/1905.05679" rel="alternate" type="text/html"/>
    <title>List-Decodable Linear Regression</title>
    <feedworld_mtime>1557878400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karmalkar:Sushrut.html">Sushrut Karmalkar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kothari:Pravesh.html">Pravesh Kothari</a>, Adam Klivans <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.05679">PDF</a><br/><b>Abstract: </b>We give the first polynomial-time algorithm for robust regression in the
list-decodable setting where an adversary can corrupt a greater than $1/2$
fraction of examples. For any $\alpha &lt; 1$, our algorithm takes as input a
sample $\{ (x_i,y_i)\}_{i \leq n}$ of $n$ linear equations where $\alpha n$ of
the equations satisfy $y_i = \langle x_i,\ell^*\rangle +\zeta$ for some small
noise $\zeta$ and $(1-\alpha)n$ of the equations are \emph{arbitrarily} chosen.
It outputs a list $L$ of size $O(1/\alpha)$ - a fixed constant - that contains
an $\ell$ that is close to $\ell^*$. Our algorithm succeeds whenever the
inliers are chosen from a \emph{certifiably} anti-concentrated distribution
$D$. As a special case, this yields a $(d/\alpha)^{O(1/\alpha^8)}$ time
algorithm to find a $O(1/\alpha)$ size list when the inlier distribution is a
standard Gaussian.
</p>
<p>The anti-concentration assumption on the inliers is information-theoretically
necessary. Our algorithm works for more general distributions under the
additional assumption that $\ell^*$ is Boolean valued. To solve the problem we
introduce a new framework for list-decodable learning that strengthens the
sum-of-squares `identifiability to algorithms' paradigm.
</p>
<p>In an independent work, Raghavendra and Yau [RY19] have obtained a similar
result for list-decodable regression also using the sum-of-squares method.
</p></div>
    </summary>
    <updated>2019-05-15T01:21:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.05669</id>
    <link href="http://arxiv.org/abs/1905.05669" rel="alternate" type="text/html"/>
    <title>Stochastic thermodynamics of computation</title>
    <feedworld_mtime>1557878400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolpert:David_H=.html">David H. Wolpert</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.05669">PDF</a><br/><b>Abstract: </b>One of the major resource requirements of computers - ranging from biological
cells to human brains to high-performance (engineered) computers - is the
energy used to run them. Those costs of performing a computation have long been
a focus of research in physics, going back to the early work of Landauer. One
of the most prominent aspects of computers is that they are inherently
nonequilibrium systems. However, the early research was done when
nonequilibrium statistical physics was in its infancy, which meant the work was
formulated in terms of equilibrium statistical physics. Since then there have
been major breakthroughs in nonequilibrium statistical physics, which are
allowing us to investigate the myriad aspects of the relationship between
statistical physics and computation, extending well beyond the issue of how
much work is required to erase a bit. In this paper I review some of this
recent work on the `stochastic thermodynamics of computation'. After reviewing
the salient parts of information theory, computer science theory, and
stochastic thermodynamics, I summarize what has been learned about the entropic
costs of performing a broad range of computations, extending from bit erasure
to loop-free circuits to logically reversible circuits to information ratchets
to Turing machines. These results reveal new, challenging engineering problems
for how to design computers to have minimal thermodynamic costs. They also
allow us to start to combine computer science theory and stochastic
thermodynamics at a foundational level, thereby expanding both.
</p></div>
    </summary>
    <updated>2019-05-15T01:20:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-05-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.05655</id>
    <link href="http://arxiv.org/abs/1905.05655" rel="alternate" type="text/html"/>
    <title>Online Computation with Untrusted Advice</title>
    <feedworld_mtime>1557878400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Angelopoulos:Spyros.html">Spyros Angelopoulos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/D=uuml=rr:Christoph.html">Christoph Dürr</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jin:Shendan.html">Shendan Jin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kamali:Shahin.html">Shahin Kamali</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Renault:Marc.html">Marc Renault</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.05655">PDF</a><br/><b>Abstract: </b>The advice model of online computation captures the setting in which the
online algorithm is given some partial information concerning the request
sequence. This paradigm allows to establish tradeoffs between the amount of
this additional information and the performance of the online algorithm.
However, unlike real life in which advice is a recommendation that we can chose
to follow or to ignore based on trustworthiness, in the current advice model,
the online algorithm treats it as infallible. This means that if the advice is
corrupt or, worse, if it comes from a malicious source, the algorithm may
perform poorly. In this work, we study online computation in a setting in which
the advice is provided by an untrusted source. Our objective is to quantify the
impact of untrusted advice so as to design and analyze online algorithms that
are resilient and perform well even when the advice is generated in a
malicious, adversarial manner. To this end, we focus on well-studied online
problems such as ski rental, online bidding, bin packing, and list update. For
ski-rental and online bidding, we show how to obtain algorithms that are
Pareto-optimal with respect to the competitive ratios achieved; this improves
upon the framework of Purohit et al. [NeurIPS 2018] in which Pareto-optimality
is not necessarily guaranteed. For bin packing and list update, we give online
algorithms with worst-case tradeoffs in their competitiveness, depending on
whether the advice is trusted or not; this is motivated by work of Lykouris and
Vassilvitskii [ICML 2018] on the paging problem, but in which the
competitiveness depends on the reliability of the advice.
</p></div>
    </summary>
    <updated>2019-05-15T01:30:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.05643</id>
    <link href="http://arxiv.org/abs/1905.05643" rel="alternate" type="text/html"/>
    <title>Sample Efficient Toeplitz Covariance Estimation</title>
    <feedworld_mtime>1557878400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eldar:Yonina_C=.html">Yonina C. Eldar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jerry.html">Jerry Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Musco:Cameron.html">Cameron Musco</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Musco:Christopher.html">Christopher Musco</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.05643">PDF</a><br/><b>Abstract: </b>We study the query complexity of estimating the covariance matrix $T$ of a
distribution $\mathcal{D}$ over $d$-dimensional vectors, under the assumption
that $T$ is Toeplitz. This assumption arises in many signal processing
problems, where the covariance between any two measurements only depends on the
time or distance between those measurements. We are interested in estimation
strategies that may choose to view only a subset of entries in each vector
sample $x^{(\ell)} \sim \mathcal{D}$, which often equates to reducing hardware
and communication requirements in applications ranging from wireless signal
processing to advanced imaging. Our goal is to minimize both 1) the number of
vector samples drawn from $\mathcal{D}$ and 2) the number of entries accessed
in each sample.
</p>
<p>We provide some of the first non-asymptotic bounds on these sample complexity
measures that exploit $T$'s Toeplitz structure, and by doing so, significantly
improve on results for generic covariance matrices. Our bounds follow from a
novel analysis of classical and widely used estimation algorithms (along with
some new variants), including methods based on selecting entries from each
vector sample according to a so-called sparse ruler. In many cases, we pair our
upper bounds with matching or nearly matching lower bounds.
</p>
<p>In addition to results that hold for any Toeplitz $T$, we further study the
important setting when $T$ is close to low-rank, which is often the case in
practice. We show that methods based on sparse rulers perform even better in
this setting, with sample complexity scaling sublinearly in $d$. Motivated by
this finding, we develop a new covariance estimation strategy that further
improves on all existing methods in the low-rank case: when $T$ is rank-$k$ or
nearly rank-$k$, it achieves sample complexity depending polynomially on $k$
and only logarithmically on $d$.
</p></div>
    </summary>
    <updated>2019-05-15T01:22:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.05494</id>
    <link href="http://arxiv.org/abs/1905.05494" rel="alternate" type="text/html"/>
    <title>Practical Volume Estimation by a New Annealing Schedule for Cooling Convex Bodies</title>
    <feedworld_mtime>1557878400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chalkis:Apostolos.html">Apostolos Chalkis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Emiris:Ioannis_Z=.html">Ioannis Z. Emiris</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fisikopoulos:Vissarion.html">Vissarion Fisikopoulos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.05494">PDF</a><br/><b>Abstract: </b>We study the problem of estimating the volume of convex polytopes, focusing
on H- and V-polytopes, as well as zonotopes. Although a lot of effort is
devoted to practical algorithms for H-polytopes there is no such method for the
latter two representations. We propose a new, practical algorithm for all
representations, which is faster than existing methods. It relies on
Hit-and-Run sampling, and combines a new simulated annealing method with the
Multiphase Monte Carlo (MMC) approach. Our method introduces the following key
features to make it adaptive: (a) It defines a sequence of convex bodies in MMC
by introducing a new annealing schedule, whose length is shorter than in
previous methods with high probability, and the need of computing an enclosing
and an inscribed ball is removed; (b) It exploits statistical properties in
rejection-sampling and proposes a better empirical convergence criterion for
specifying each step; (c) For zonotopes, it may use a sequence of convex bodies
for MMC different than balls, where the chosen body adapts to the input. We
offer an open-source, optimized C++ implementation, and analyze its performance
to show that it outperforms state-of-the-art software for H-polytopes by
Cousins-Vempala (2016) and Emiris-Fisikopoulos (2018), while it undertakes
volume computations that were intractable until now, as it is the first
polynomial-time, practical method for V-polytopes and zonotopes that scales to
high dimensions (currently 100). We further focus on zonotopes, and
characterize them by their order (number of generators over dimension), because
this largely determines sampling complexity. We analyze a related application,
where we evaluate methods of zonotope approximation in engineering.
</p></div>
    </summary>
    <updated>2019-05-15T01:34:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-05-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.05376</id>
    <link href="http://arxiv.org/abs/1905.05376" rel="alternate" type="text/html"/>
    <title>Dimensionality Reduction for Tukey Regression</title>
    <feedworld_mtime>1557878400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Clarkson:Kenneth_L=.html">Kenneth L. Clarkson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Ruosong.html">Ruosong Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.05376">PDF</a><br/><b>Abstract: </b>We give the first dimensionality reduction methods for the overconstrained
Tukey regression problem. The Tukey loss function $\|y\|_M = \sum_i M(y_i)$ has
$M(y_i) \approx |y_i|^p$ for residual errors $y_i$ smaller than a prescribed
threshold $\tau$, but $M(y_i)$ becomes constant for errors $|y_i| &gt; \tau$. Our
results depend on a new structural result, proven constructively, showing that
for any $d$-dimensional subspace $L \subset \mathbb{R}^n$, there is a fixed
bounded-size subset of coordinates containing, for every $y \in L$, all the
large coordinates, with respect to the Tukey loss function, of $y$. Our methods
reduce a given Tukey regression problem to a smaller weighted version, whose
solution is a provably good approximate solution to the original problem. Our
reductions are fast, simple and easy to implement, and we give empirical
results demonstrating their practicality, using existing heuristic solvers for
the small versions. We also give exponential-time algorithms giving provably
good solutions, and hardness results suggesting that a significant speedup in
the worst case is unlikely.
</p></div>
    </summary>
    <updated>2019-05-15T01:32:01Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.05334</id>
    <link href="http://arxiv.org/abs/1905.05334" rel="alternate" type="text/html"/>
    <title>Generating Weighted MAX-2-SAT Instances of Tunable Difficulty with Frustrated Loops</title>
    <feedworld_mtime>1557878400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pei:Yan_Ru.html">Yan Ru Pei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manukian:Haik.html">Haik Manukian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Ventra:Massimiliano_Di.html">Massimiliano Di Ventra</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.05334">PDF</a><br/><b>Abstract: </b>Many optimization problems can be cast into the maximum satisfiability
(MAX-SAT) form, and many solvers have been developed for tackling such
problems. To evaluate the performance of a MAX-SAT solver, it is convenient to
generate difficult MAX-SAT instances with solutions known in advance. Here, we
propose a method of generating weighted MAX-2-SAT instances inspired by the
frustrated-loop algorithm used by the quantum annealing community to generate
Ising spin-glass instances with nearest-neighbor coupling. Our algorithm is
extended to instances whose underlying coupling graph is general, though we
focus here on the case of bipartite coupling, with the associated energy being
the restricted Boltzmann machine (RBM) energy. It is shown that any MAX-2-SAT
problem can be reduced to the problem of minimizing an RBM energy over the
nodal values. The algorithm is designed such that the difficulty of the
generated instances can be tuned through a central parameter known as the
frustration index. Two versions of the algorithm are presented: the random- and
structured-loop algorithms. For the random-loop algorithm, we provide a
thorough theoretical and empirical analysis on its mathematical properties from
the perspective of frustration, and observe empirically, using simulated
annealing, a double phase transition behavior in the difficulty scaling
behavior driven by the frustration index. For the structured-loop algorithm, we
show that it offers an improvement in difficulty of the generated instances
over the random-loop algorithm, with the improvement factor scaling
super-exponentially with respect to the frustration index for instances at high
loop density. At the end of the paper, we provide a brief discussion of the
relevance of this work to the pre-training of RBMs.
</p></div>
    </summary>
    <updated>2019-05-15T01:21:13Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-05-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.05329</id>
    <link href="http://arxiv.org/abs/1905.05329" rel="alternate" type="text/html"/>
    <title>Computing and Testing Small Vertex Connectivity in Near-Linear Time and Queries</title>
    <feedworld_mtime>1557878400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nanongkai:Danupon.html">Danupon Nanongkai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saranurak:Thatchaphol.html">Thatchaphol Saranurak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yingchareonthawornchai:Sorrachai.html">Sorrachai Yingchareonthawornchai</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.05329">PDF</a><br/><b>Abstract: </b>We present a new, simple, algorithm for the local vertex connectivity problem
(LocalVC) introduced by Nanongkai~et~al. [STOC'19]. Roughly, given an
undirected unweighted graph $G$, a seed vertex $x$, a target volume $\nu$, and
a target separator size $k$, the goal of LocalVC is to remove $k$ vertices
`near' $x$ (in terms of $\nu$) to disconnect the graph in `local time', which
depends only on parameters $\nu$ and $k$. In this paper, we present a simple
randomized algorithm with running time $O(\nu k^2)$ and correctness probability
$2/3$.
</p>
<p>Plugging our new localVC algorithm in the generic framework of
Nanongkai~et~al. immediately lead to a randomized $\tilde O(m+nk^3)$-time
algorithm for the classic $k$-vertex connectivity problem on undirected graphs.
($\tilde O(T)$ hides $\text{polylog}(T)$.) This is the {\em first} near-linear
time algorithm for any $4\leq k \leq \text{polylog} n$. Previous fastest
algorithm for small $k$ takes $\tilde O(m+n^{4/3}k^{7/3})$ time
[Nanongkai~et~al., STOC'19].
</p>
<p>This work is inspired by the algorithm of Chechik~et~al. [SODA'17] for
computing the maximal $k$-edge connected subgraphs. Forster and Yang [arXiv'19]
has independently developed local algorithms similar to ours, and showed that
they lead to an $\tilde O(k^3/\epsilon)$ bound for testing $k$-edge and -vertex
connectivity, resolving two long-standing open problems in property testing
since the work of Goldreich and Ron [STOC'97] and Orenstein and Ron [Theor.
Comput. Sci.'11]. Inspired by this, we use local approximation algorithms to
obtain bounds that are near-linear in $k$, namely $\tilde O(k/\epsilon)$ and
$\tilde O(k/\epsilon^2)$ for the bounded and unbounded degree cases,
respectively. For testing $k$-edge connectivity for simple graphs, the bound
can be improved to $\tilde O(\min(k/\epsilon, 1/\epsilon^2))$.
</p></div>
    </summary>
    <updated>2019-05-15T01:31:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.05291</id>
    <link href="http://arxiv.org/abs/1905.05291" rel="alternate" type="text/html"/>
    <title>5/4 approximation for Symmetric TSP</title>
    <feedworld_mtime>1557878400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Madhusudan Verma, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chauhan:Alok.html">Alok Chauhan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/V:Vijayakumar.html">Vijayakumar V</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.05291">PDF</a><br/><b>Abstract: </b>Travelling Salesman Problem (TSP) is one of the unsolved problems in computer
science. TSP is NP Hard. Till now the best approximation ratio found for
symmetric TSP is three by two by Christofides Algorithm more than thirty years
ago. There are different approaches to solve this problem. These range from
methods based on neural networks, genetic algorithm, swarm optimization, ant
colony optimization etc. The bound is further reduced from three by two but for
graphic TSP. A factor of thirteen by nine was found for Graphic TSP. A newly
proposed heuristic called k RNN is considered here. It seems from experimental
results that five by four is the approximation ratio. A performance analysis is
done for this heuristic and it confirms experimental bound of five by four.
</p></div>
    </summary>
    <updated>2019-05-15T01:31:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.05290</id>
    <link href="http://arxiv.org/abs/1905.05290" rel="alternate" type="text/html"/>
    <title>Revisiting Graph Width Measures for CNF-Encodings</title>
    <feedworld_mtime>1557878400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mengel:Stefan.html">Stefan Mengel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wallon:Romain.html">Romain Wallon</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.05290">PDF</a><br/><b>Abstract: </b>We consider bounded width CNF-formulas where the width is measured by popular
graph width measures on graphs associated to CNF-formulas. Such restricted
graph classes, in particular those of bounded treewidth, have been extensively
studied for their uses in the design of algorithms for various computational
problems on CNF-formulas. Here we consider the expressivity of these formulas
in the model of clausal encodings with auxiliary variables. We first show that
bounding the width for many of the measures from the literature leads to a
dramatic loss of expressivity, restricting the formulas to such of low
communication complexity. We then show that the width of optimal encodings with
respect to different measures is strongly linked: there are two classes of
width measures, one containing primal treewidth and the other incidence
cliquewidth, such that in each class the width of optimal encodings only
differs by constant factors. Moreover, between the two classes the width
differs at most by a factor logarithmic in the number of variables. Both these
results are in stark contrast to the setting without auxiliary variables where
all width measures we consider here differ by more than constant factors and in
many cases even by linear factors.
</p></div>
    </summary>
    <updated>2019-05-15T01:20:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-05-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.05254</id>
    <link href="http://arxiv.org/abs/1905.05254" rel="alternate" type="text/html"/>
    <title>Optimal Multithreaded Batch-Parallel 2-3 Trees</title>
    <feedworld_mtime>1557878400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lim:Wei_Quan.html">Wei Quan Lim</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.05254">PDF</a><br/><b>Abstract: </b>This paper presents a batch-parallel 2-3 tree T in the asynchronous PPM
(parallel pointer machine) model that supports searches, insertions and
deletions in sorted batches and has essentially optimal parallelism, even under
the QRMW (queued read-modify-write) memory model where concurrent memory
accesses to the same location are queued and serviced one by one.
</p>
<p>Specifically, if T has n items, then performing an item-sorted batch of b
operations on T takes only O( b * log(n/b+1) + b ) work and O( log b + log n )
span (in the worst case as b,n -&gt; inf). This is information-theoretically
work-optimal for b &lt;= n, and also span-optimal in the PPM model. The input
batch can be any balanced binary tree, and hence T can also be used to
implement sorted sets supporting optimal intersection, union and difference of
sets with sizes m &lt;= n in O( m * log(n/m+1) ) work and O( log m + log n ) span.
</p>
<p>To the author's knowledge, T is the first parallel sorted-set data structure
with these performance bounds that can be used in an asynchronous
multi-processor machine under a memory model with queued contention. This is
unlike PRAM data structures such as the PVW 2-3 tree (by Paul, Vishkin and
Wagener), which rely on lock-step synchronicity of the processors. In fact, T
is designed to have bounded contention and satisfy the claimed work and span
bounds regardless of the execution schedule.
</p>
<p>All data structures and algorithms in this paper fit into the dynamic
multithreading paradigm. Also, as a consequence of working in the asynchronous
PPM model, all their performance bounds are directly composable with those of
other data structures and algorithms in the same model.
</p></div>
    </summary>
    <updated>2019-05-15T01:31:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-15T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/071</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/071" rel="alternate" type="text/html"/>
    <title>TR19-071 |  Time-Space Lower Bounds for Two-Pass Learning | 

	Sumegha Garg, 

	Ran Raz, 

	Avishay Tal</title>
    <summary>A line of recent works showed that for a large class of learning problems, any learning algorithm  requires either super-linear memory size or a super-polynomial number of samples [Raz16,KRT17,Raz17,MM18,BOGY18,GRT18]. For example, any algorithm for learning parities of size $n$ requires either a memory of size $\Omega(n^{2})$ or an exponential number of samples [Raz16].

All these works modeled the learner as a one-pass branching program, allowing only one pass over the stream of samples. In this work, we prove the first memory-samples lower bounds (with a super-linear lower bound on the memory size and super-polynomial lower bound on the number of samples) when the learner is allowed two passes over the stream of samples. For example, we prove that any two-pass algorithm for learning parities of size $n$ requires either a memory of size $\Omega(n^{1.5})$ or at least $2^{\Omega(\sqrt{n})}$ samples.

More generally, a matrix $M: A \times X \rightarrow \{-1,1\}$ corresponds to the following learning problem: An unknown element $x \in X$ is chosen uniformly at random. A learner tries to learn $x$ from a stream of samples, $(a_1, b_1), (a_2, b_2) \ldots$, where for every $i$, $a_i \in A$ is chosen uniformly at random and $b_i = M(a_i,x)$.

Assume that $k,l, r$ are such that any submatrix of $M$ of at least $2^{-k} \cdot |A|$ rows and at least $2^{-l} \cdot |X|$ columns, has a bias of at most $2^{-r}$. We show that any two-pass learning algorithm for the learning problem corresponding to $M$ requires either a memory of size at least $\Omega\left(k \cdot  \min\{k,\sqrt{l}\} \right)$, or at least $2^{\Omega(\min\{k,\sqrt{l},r\})}$ samples.</summary>
    <updated>2019-05-14T16:35:18Z</updated>
    <published>2019-05-14T16:35:18Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-05-15T21:20:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15858</id>
    <link href="https://rjlipton.wordpress.com/2019/05/14/internet-dogs-and-the-abc-conjecture/" rel="alternate" type="text/html"/>
    <title>Internet, Dogs, and the ABC Conjecture</title>
    <summary>An inappropriate comment on the ABC conjecture Joseph Oesterlé and David Masser are famous for their independent discovery of the ABC conjecture. Today I want to point out an unfair comment about their discovery. Anonymity on the Internet was captured by a famous 1993 cartoon in the New Yorker magazine titled, “On the Internet, nobody […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>An inappropriate comment on the ABC conjecture</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<a href="https://rjlipton.wordpress.com/2019/05/14/internet-dogs-and-the-abc-conjecture/220px-david_masser/" rel="attachment wp-att-15867"><img alt="" class="alignright wp-image-15867" src="https://rjlipton.files.wordpress.com/2019/05/220px-david_masser.jpg?w=150" width="150"/></a><br/><a href="https://rjlipton.wordpress.com/2019/05/14/internet-dogs-and-the-abc-conjecture/220px-oesterle_joseph/" rel="attachment wp-att-15868"><img alt="" class="alignright  wp-image-15868" src="https://rjlipton.files.wordpress.com/2019/05/220px-oesterle_joseph.jpg?w=150" width="150"/></a><br/><table class="image alignright">
<tbody>
<tr>
<td>
</td>
</tr>
<tr>


</tr>
</tbody>
</table>
<p>
Joseph Oesterlé and David Masser are famous for their independent discovery of the ABC conjecture. </p>
<p>
Today I want to point out an unfair comment about their discovery.</p>
<p>
Anonymity on the Internet was captured by a famous 1993 <a href="https://en.wikipedia.org/wiki/On_the_Internet,_nobody_knows_you%27re_a_dog">cartoon</a> in the <i>New Yorker</i> magazine titled, “On the Internet, nobody knows you’re a dog.”  Amazing to think that was more than a quarter-century ago and remains true.  But people <i>can</i> tell if what you’ve written is something inappropriate.</p>
<p/><h2> The Comment </h2><p/>
<p/><p>
The comment is: </p>
<blockquote><p><b> </b> <em> <i>SAYS WHO??? I have some trouble with this item.</i> </em>
</p></blockquote>
<p/><p>
Masser is a Fellow of the Royal Society, who was elected in 2005. He is </p>
<blockquote><p><b> </b> <em> <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\dots}"/> also responsible, following an earlier insight of Joseph Oesterlé, for formulating the abc conjecture; this is a simple statement about integers which seems to hold the key to much of the future direction of number theory. </em>
</p></blockquote>
<p/><p>
See this <a href="https://royalsociety.org/people/david-masser-11903/">link</a> for his full citation and the comment. Click on the <i>show more bibliography</i> button there. The comment is apparently anonymous, although the author is probably known to some. I thank Joël Ouaknine for pointing out this strange comment.</p>
<p>
<b>Update:</b> Ken speculates that it’s a misplaced comment by an editor of the Royal Society website itself.  Perhaps they compose HTML from MS Word or Acrobat or other software that provides comment bubbles—but this one escaped the bubble and wasn’t noticed.  Editors of Wikipedia have automatic tools for flagging assertions that are unsupported or at least need citation.  </p>
<p>
What the comment undoubtedly shows is vigorous debate behind the walls of Britain’s august institution.  So let’s say a little more on what the comment is about.</p>
<p/><h2> The ABC Conjecture </h2><p/>
<p/><p>
The biggest mysteries about numbers often concern the interaction between addition and multiplication. For example: </p>
<ul>
<li>
The <a href="https://en.wikipedia.org/wiki/Twin_prime">twin</a> prime conjecture: There are an infinite number of primes <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> such that <img alt="{p+2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p+2}"/> is also prime. This is due to Alphonse de Polignac. <p/>
</li><li>
The <a href="https://en.wikipedia.org/wiki/Goldbach%27s_conjecture">Goldbach</a> conjecture: Every even number greater than four is the sum of two odd primes. This is due to Christian Goldbach. <p/>
</li><li>
The <a href="https://en.wikipedia.org/wiki/Brocard%27s_problem">Brocard</a> conjecture: There are only a finite number of solutions to <img alt="{n! = m^{2} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%21+%3D+m%5E%7B2%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n! = m^{2} + 1}"/> in natural numbers. This is due to Henri Brocard.
</li></ul>
<p>
Suppose that <img alt="{A + B = C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%2B+B+%3D+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A + B = C}"/> where <img alt="{A,B,C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B,C}"/> are positive and co-prime natural numbers. Let <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> be the product of all the distinct prime divisors of <img alt="{ABC}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BABC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ABC}"/>. Then the ABC conjecture says that 	</p>
<p align="center"><img alt="\displaystyle  C \le O(D^{2}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+O%28D%5E%7B2%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C \le O(D^{2}). "/></p>
<p>Note, this inequality does indeed connect adding with multiplying. The usual conjecture is stronger, see <a href="https://en.wikipedia.org/wiki/Abc_conjecture">this</a> for details.	</p>
<p>
The ABC conjecture appears to be open, even though Shinichi Mochizuki has claimed a <a href="https://rjlipton.wordpress.com/2012/09/12/the-abc-conjecture-and-cryptography/">proof</a> for years. See <a href="https://www.quantamagazine.org/titans-of-mathematics-clash-over-epic-proof-of-abc-conjecture-20180920">this</a> for a discussion about the status of the conjecture. </p>
<blockquote><p><b> </b> <em> Despite multiple conferences dedicated to explicating Mochizuki’s proof, number theorists have struggled to come to grips with its underlying ideas. His series of papers, which total more than 500 pages, are written in an impenetrable style, and refer back to a further 500 pages or so of previous work by Mochizuki, creating what one mathematician, Brian Conrad of Stanford University, has called “a sense of infinite regress.” </em>
</p></blockquote>
<p>
</p><p/><h2> The Comment II </h2><p/>
<p/><p>
The comment on Masser’s work is wrong, strange, inappropriate. Oesterlé and Masser deserve more credit, not less, for their brilliant discovery of the ABC conjecture. There are now many—perhaps hundreds—of applications of the ABC conjecture. For example consider generalizations of Fermat’s Last Theorem. Suppose that 	</p>
<p align="center"><img alt="\displaystyle  x^{p} + y^{q} = z^{r} \text{  (*)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7Bp%7D+%2B+y%5E%7Bq%7D+%3D+z%5E%7Br%7D+%5Ctext%7B++%28%2A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  x^{p} + y^{q} = z^{r} \text{  (*)}"/></p>
<p>where <img alt="{p,q,r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%2Cq%2Cr%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p,q,r}"/> are odd primes. And <img alt="r &gt; 6" class="latex" src="https://s0.wp.com/latex.php?latex=r+%3E+6&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r &gt; 6"/>. Provided <img alt="{x,y,z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%2Cz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y,z}"/> are positive and co-prime, it follows by the ABC conjecture that <img alt="{z^{r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%5E%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z^{r}}"/> is bounded by <img alt="{O(z^{2})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28z%5E%7B2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(z^{2})}"/>. This is impossible for <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/> large enough since <img alt="{r \ge 3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%5Cge+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r \ge 3}"/>. Therefore, (*) can only have a finite number of solutions. Pretty neat.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Do you know of any other inappropriate comments of this kind?</p>
<p/><p><br/>
[added remark by Ken, linked rather than embed dog cartoon]<br/>
[Added prime r must be 7 or larger. Thanks to comment by MadHatter.]</p></font></font></div>
    </content>
    <updated>2019-05-14T14:49:25Z</updated>
    <published>2019-05-14T14:49:25Z</published>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="ABC conjecture"/>
    <category term="Diophantine"/>
    <category term="equation"/>
    <category term="Fermat"/>
    <category term="strange"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-05-15T21:20:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/070</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/070" rel="alternate" type="text/html"/>
    <title>TR19-070 |  On Local Testability in the Non-Signaling Setting | 

	Alessandro Chiesa, 

	Peter Manohar, 

	Igor Shinkar</title>
    <summary>Non-signaling strategies are a generalization of quantum strategies that have been studied in physics for decades, and have recently found applications in theoretical computer science. These applications motivate the study of local-to-global phenomena for non-signaling functions.

We present general results about the local testability of linear codes in the non-signaling setting. Our contributions include formulating natural definitions that capture the condition that a non-signaling function "belongs" to a given code, and characterizing the sets of local constraints that imply membership in the code. We prove these results by relating the Fourier spectrum of non-signaling functions to Cayley hypergraphs induced by local constraints.

We apply the above results to show a separation between locally testable codes in the classical and non-signaling setting by proving that bivariate low-degree testing fails spectacularly in the non-signaling setting. Specifically, we show that there exist non-signaling functions that pass bivariate low-degree tests with probability 1, and yet are maximally far from low-degree.</summary>
    <updated>2019-05-14T05:26:11Z</updated>
    <published>2019-05-14T05:26:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-05-15T21:20:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.05114</id>
    <link href="http://arxiv.org/abs/1905.05114" rel="alternate" type="text/html"/>
    <title>On Semigroups of Two-Dimensional Upper-Triangular Integer Matrices</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaax:Stefan.html">Stefan Jaax</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kiefer:Stefan.html">Stefan Kiefer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.05114">PDF</a><br/><b>Abstract: </b>We analyze algorithmic problems in finitely generated semigroups of
two-dimensional upper-triangular integer matrices. These semigroup problems are
tightly connected with problems about compositions of affine functions over one
variable. Building on a variety of techniques from recent years, we obtain a
number of complexity results, including NP-completeness of the mortality
problem for matrices with determinants +1 and 0.
</p></div>
    </summary>
    <updated>2019-05-14T23:22:45Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.05094</id>
    <link href="http://arxiv.org/abs/1905.05094" rel="alternate" type="text/html"/>
    <title>Orthogonal tensor decomposition and orbit closures from a linear algebraic perspective</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koiran:Pascal.html">Pascal Koiran</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.05094">PDF</a><br/><b>Abstract: </b>We study orthogonal decompositions of symmetric and ordinary tensors using
methods from linear algebra. For the field of real numbers we show that the
sets of decomposable tensors can be defined be equations of degree 2. This
gives a new proof of some of the results of Robeva and Boralevi et al.
Orthogonal decompositions over the field of complex numbers had not been
studied previously; we give an explicit description of the set of decomposable
tensors using polynomial equalities and inequalities, and we begin a study of
their closures. The main open problem that arises from this work is to obtain a
complete description of the closures. This question is akin to that of
characterizing border rank of tensors in algebraic complexity. We give partial
results using in particular a connection with approximate simultaneous
diagonalization (the so-called "ASD property").
</p></div>
    </summary>
    <updated>2019-05-14T23:23:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.05067</id>
    <link href="http://arxiv.org/abs/1905.05067" rel="alternate" type="text/html"/>
    <title>Dynamic Matrix Inverse: Improved Algorithms and Matching Conditional Lower Bounds</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brand:Jan_van_den.html">Jan van den Brand</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nanongkai:Danupon.html">Danupon Nanongkai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saranurak:Thatchaphol.html">Thatchaphol Saranurak</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.05067">PDF</a><br/><b>Abstract: </b>The dynamic matrix inverse problem is to maintain the inverse of a matrix
undergoing element and column updates. It is the main subroutine behind the
best algorithms for many dynamic problems whose complexity is not yet
well-understood, such as maintaining the largest eigenvalue, rank and
determinant of a matrix and maintaining reachability, distances, maximum
matching size, and $k$-paths/cycles in a graph. Understanding the complexity of
dynamic matrix inverse is a key to understand these problems.
</p>
<p>In this paper, we present (i) improved algorithms for dynamic matrix inverse
and their extensions to some incremental/look-ahead variants, and (ii) variants
of the Online Matrix-Vector conjecture [Henzinger et al. STOC'15] that, if
true, imply that these algorithms are tight. Our algorithms automatically lead
to faster dynamic algorithms for the aforementioned problems, some of which are
also tight under our conjectures, e.g. reachability and maximum matching size
(closing the gaps for these two problems was in fact asked by Abboud and V.
Williams [FOCS'14]). Prior best bounds for most of these problems date back to
more than a decade ago [Sankowski FOCS'04, COCOON'05, SODA'07; Kavitha
FSTTCS'08; Mucha and Sankowski Algorithmica'10; Bosek et al. FOCS'14].
</p>
<p>Our improvements stem mostly from the ability to use fast matrix
multiplication ``one more time'', to maintain a certain transformation matrix
which could be maintained only combinatorially previously (i.e. without fast
matrix multiplication). Oddly, unlike other dynamic problems where this
approach, once successful, could be repeated several times (``bootstrapping''),
our conjectures imply that this is not the case for dynamic matrix inverse and
some related problems. However, when a small additional ``look-ahead''
information is provided we can perform such repetition to drive the bounds down
further.
</p></div>
    </summary>
    <updated>2019-05-14T23:28:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.05066</id>
    <link href="http://arxiv.org/abs/1905.05066" rel="alternate" type="text/html"/>
    <title>Color spanning Localized query</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Acharyya:Ankush.html">Ankush Acharyya</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maheshwari:Anil.html">Anil Maheshwari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nandy:Subhas_C=.html">Subhas C. Nandy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.05066">PDF</a><br/><b>Abstract: </b>Let P be a set of n points and each of the points is colored with one of the
k possible colors. We present efficient algorithms to pre-process P such that
for a given query point q, we can quickly identify the smallest color spanning
object of the desired type containing q. In this paper, we focus on (i)
intervals, (ii) axis-parallel square, (iii) axis-parallel rectangle, (iv)
equilateral triangle of fixed orientation and (v) circle, as our desired type
of objects.
</p></div>
    </summary>
    <updated>2019-05-14T23:41:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04989</id>
    <link href="http://arxiv.org/abs/1905.04989" rel="alternate" type="text/html"/>
    <title>A Distributed Laplacian Solver and its Applications to Electrical Flow and Random Spanning Tree Computation</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gillani:Iqra_Altaf.html">Iqra Altaf Gillani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bagchi:Amitabha.html">Amitabha Bagchi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04989">PDF</a><br/><b>Abstract: </b>We present a distributed solver for a large and important class of Laplacian
systems that we call "one-sink" Laplacian systems. Specifically, our solver can
produce solutions for systems of the form $L\mathbf{x} = \mathbf{b}$ where
exactly one of the coordinates of $\mathbf{b}$ is negative. Our solver is an
organically distributed algorithm that takes $\widetilde{O}(n/\lambda_2^L)$
rounds for bounded degree graphs to produce an approximate solution where
$\lambda_2^L$ is the second smallest eigenvalue of the Laplacian matrix of
graph, also known as the Fiedler value or algebraic connectivity of graph. The
class of one-sink Laplacians includes the important voltage computation problem
and allows us to compute the effective resistance between nodes in a
distributed manner. As a result, our Laplacian solver can be used to adapt the
approach by Kelner and M\k{a}dry (2009) to give the first distributed algorithm
to compute approximate random spanning trees efficiently.
</p>
<p>Our solver, which we call "Distributed Random Walk-based Laplacian Solver"
(DRW-LSolve) works by approximating the stationary distribution of a
multi-dimensional Markov chain. This chain describes the evolution of a "data
collection" process where each node $v$ for which $\mathbf{b}_v &gt; 0$ generates
data packets with a rate proportional to $\mathbf{b}_v$ and the node for which
$\mathbf{b}_v &lt; 0$ acts as a sink. The nodes of the graph relay the packets,
staging them in their queues and transmitting one at a time. We show that when
this multidimensional chain is ergodic the vector whose $v$th coordinate is
proportional to the probability at stationarity of the queue at $v$ being
non-empty is a solution to $L\mathbf{x} = \mathbf{b}$.
</p></div>
    </summary>
    <updated>2019-05-14T23:25:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04941</id>
    <link href="http://arxiv.org/abs/1905.04941" rel="alternate" type="text/html"/>
    <title>An improved algorithm for the submodular secretary problem with a cardinality constraint</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fujii:Kaito.html">Kaito Fujii</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04941">PDF</a><br/><b>Abstract: </b>We study the submodular secretary problem with a cardinality constraint. In
this problem, $n$ candidates for secretaries appear sequentially in random
order. At the arrival of each candidate, a decision maker must irrevocably
decide whether to hire him. The decision maker aims to hire at most $k$
candidates that maximize a non-negative submodular set function. We propose an
$(\mathrm{e} - 1)^2 / (\mathrm{e}^2 (1 + \mathrm{e}))$-competitive algorithm
for this problem, which improves the best one known so far.
</p></div>
    </summary>
    <updated>2019-05-14T23:24:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04897</id>
    <link href="http://arxiv.org/abs/1905.04897" rel="alternate" type="text/html"/>
    <title>Streaming Algorithms for Bin Packing and Vector Scheduling</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cormode:Graham.html">Graham Cormode</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vesel=yacute=:Pavel.html">Pavel Veselý</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04897">PDF</a><br/><b>Abstract: </b>Problems involving the efficient arrangement of simple objects, as captured
by bin packing and makespan scheduling, are fundamental tasks in combinatorial
optimization. These are well understood in the traditional online and offline
cases, but have been less well-studied when the volume of the input is truly
massive, and cannot even be read into memory. This is captured by the streaming
model of computation, where the aim is to approximate the cost of the solution
in one pass over the data, using small space. As a result, streaming algorithms
produce concise input summaries that approximately preserve the optimum value.
</p>
<p>We design the first efficient streaming algorithms for these fundamental
problems in combinatorial optimization. For Bin Packing, we provide a streaming
asymptotic $1+\varepsilon$-approximation with
$\widetilde{O}\left(\frac{1}{\varepsilon}\right)$ memory, where $\widetilde{O}$
hides logarithmic factors. Moreover, such a space bound is essentially optimal.
Our algorithm implies a streaming $d+\varepsilon$-approximation for Vector Bin
Packing in $d$ dimensions, running in space
$\widetilde{O}\left(\frac{d}{\varepsilon}\right)$. For the related Vector
Scheduling problem, we show how to construct an input summary in space
$\widetilde{O}(d^2\cdot m / \varepsilon^2)$ that preserves the optimum value up
to a factor of $2 - \frac{1}{m} +\varepsilon$, where $m$ is the number of
identical machines.
</p></div>
    </summary>
    <updated>2019-05-14T23:26:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04853</id>
    <link href="http://arxiv.org/abs/1905.04853" rel="alternate" type="text/html"/>
    <title>Maximum Weighted Matching with Few Edge Crossings for 2-Layered Bipartite Graph</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haraguchi:Kazuya.html">Kazuya Haraguchi</a>, Kotaro Torii, Motomu Endo <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04853">PDF</a><br/><b>Abstract: </b>Let c denote a non-negative constant. Suppose that we are given an
edge-weighted bipartite graph G=(V,E) with its 2-layered drawing and a family X
of intersecting edge pairs. We consider the problem of finding a maximum
weighted matching M* such that each edge in M* intersects with at most c other
edges in M*, and that all edge crossings in M* are contained in X. In the
present paper, we propose polynomial-time algorithms for the problem for c=1
and 2. The time complexities of the algorithms are O((k+m)log n) for c=1 and
O(m^4log n+k^3+n(k^2+log n)) for c=2, respectively, where n=|V|, m=|E| and
k=|X|.
</p></div>
    </summary>
    <updated>2019-05-14T23:25:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04827</id>
    <link href="http://arxiv.org/abs/1905.04827" rel="alternate" type="text/html"/>
    <title>Satisfiability Threshold for Power Law Random 2-SAT in Configuration Model</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Oleksii Omelchenko, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bulatov:Andrei_A=.html">Andrei A. Bulatov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04827">PDF</a><br/><b>Abstract: </b>The Random Satisfiability problem has been intensively studied for decades.
For a number of reasons the focus of this study has mostly been on the model,
in which instances are sampled uniformly at random from a set of formulas
satisfying some clear conditions, such as fixed density or the probability of a
clause to occur. However, some non-uniform distributions are also of
considerable interest. In this paper we consider Random 2-SAT problems, in
which instances are sampled from a wide range of non-uniform distributions.
</p>
<p>The model of random SAT we choose is the so-called configuration model, given
by a distribution $\xi$ for the degree (or the number of occurrences) of each
variable. Then to generate a formula the degree of each variable is sampled
from $\xi$, generating several \emph{clones} of the variable. Then 2-clauses
are created by choosing a random paritioning into 2-element sets on the set of
clones and assigning the polarity of literals at random.
</p>
<p>Here we consider the random 2-SAT problem in the configuration model for
power-law-like distributions $\xi$. More precisely, we assume that $\xi$ is
such that its right tail $F_{\xi}(x)$ satisfies the conditions
$W\ell^{-\alpha}\le F_{\xi}(\ell)\le V\ell^{-\alpha}$ for some constants $V,W$.
The main goal is to study the satisfiability threshold phenomenon depending on
the parameters $\alpha,V,W$. We show that a satisfiability threshold exists and
is determined by a simple relation between the first and second moments of
$\xi$.
</p></div>
    </summary>
    <updated>2019-05-14T23:23:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04773</id>
    <link href="http://arxiv.org/abs/1905.04773" rel="alternate" type="text/html"/>
    <title>Approximating a Target Surface with 1-DOF Rigid Origami</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Zeyuan He, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guest:Simon_D=.html">Simon D. Guest</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04773">PDF</a><br/><b>Abstract: </b>We develop some design examples for approximating a target surface at the
final rigidly folded state of a developable quadrilateral creased paper, which
is folded with a 1-DOF rigid folding motion from the planar state. The final
rigidly folded state is reached due to the clashing of panels. Now we can
approximate some specific types of non-developable surfaces, but we do not yet
fully understand how to approximate an arbitrary surface with a developable
creased paper that has limited DOFs. Our designs might have applications in
areas related to the formation of a shell structure from a planar region.
</p></div>
    </summary>
    <updated>2019-05-14T23:30:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04770</id>
    <link href="http://arxiv.org/abs/1905.04770" rel="alternate" type="text/html"/>
    <title>Algorithms for Online Matching, Assortment, and Pricing with Tight Weight-dependent Competitive Ratios</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Ma:Will.html">Will Ma</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Simchi=Levi:David.html">David Simchi-Levi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04770">PDF</a><br/><b>Abstract: </b>Motivated by the dynamic assortment offerings and item pricings occurring in
e-commerce, we study a general problem of allocating finite inventories to
heterogeneous customers arriving sequentially. We analyze this problem under
the framework of competitive analysis, where the sequence of customers is
unknown and does not necessarily follow any pattern. Previous work in this
area, studying online matching, advertising, and assortment problems, has
focused on the case where each item can only be sold at a single price,
resulting in algorithms which achieve the best-possible competitive ratio of
1-1/e.
</p>
<p>In this paper, we extend all of these results to allow for items having
multiple feasible prices. Our algorithms achieve the best-possible
weight-dependent competitive ratios, which depend on the sets of feasible
prices given in advance. Our algorithms are also simple and intuitive; they are
based on constructing a class of universal ``value functions'' which integrate
the selection of items and prices offered.
</p>
<p>Finally, we test our algorithms on the publicly-available hotel data set of
Bodea et al. (2009), where there are multiple items (hotel rooms) each with
multiple prices (fares at which the room could be sold). We find that applying
our algorithms, as a ``hybrid'' with algorithms which attempt to forecast and
learn the future transactions, results in the best performance.
</p></div>
    </summary>
    <updated>2019-05-14T23:24:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04695</id>
    <link href="http://arxiv.org/abs/1905.04695" rel="alternate" type="text/html"/>
    <title>Complexity of fall coloring for restricted graph classes</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lauri:Juho.html">Juho Lauri</a>, Christodoulos Mitillos <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04695">PDF</a><br/><b>Abstract: </b>We strengthen a result by Laskar and Lyle (Discrete Appl. Math. (2009),
330-338) by proving that it is NP-complete to decide whether a bipartite planar
graph can be partitioned into three independent dominating sets. In contrast,
we show that this is always possible for every maximal outerplanar graph with
at least three vertices. Moreover, we extend their previous result by proving
that deciding whether a bipartite graph can be partitioned into $k$ independent
dominating sets is NP-complete for every $k \geq 3$. We also strengthen a
result by Henning et al. (Discrete Math. (2009), 6451-6458) by showing that it
is NP-complete to determine if a graph has two disjoint independent dominating
sets, even when the problem is restricted to triangle-free planar graphs.
Finally, for every $k \geq 3$, we show that there is some constant $t$
depending only on $k$ such that deciding whether a $k$-regular graph can be
partitioned into $t$ independent dominating sets is NP-complete. We conclude by
deriving moderately exponential-time algorithms for the problem.
</p></div>
    </summary>
    <updated>2019-05-14T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04678</id>
    <link href="http://arxiv.org/abs/1905.04678" rel="alternate" type="text/html"/>
    <title>HLO: Half-kernel Laplacian Operator for Surface Smoothing</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pan:Wei.html">Wei Pan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Xuequan.html">Xuequan Lu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gong:Yuanhao.html">Yuanhao Gong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Wenming.html">Wenming Tang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Jun.html">Jun Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/He:Ying.html">Ying He</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Qiu:Guoping.html">Guoping Qiu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04678">PDF</a><br/><b>Abstract: </b>This paper presents a simple yet effective method for feature-preserving
surface smoothing. Through analyzing the differential property of surfaces, we
show that the conventional discrete Laplacian operator with uniform weights is
not applicable to feature points at which the surface is non-differentiable and
the second order derivatives do not exist. To overcome this difficulty, we
propose a Half-kernel Laplacian Operator (HLO) as an alternative to the
conventional Laplacian. Given a vertex v, HLO first finds all pairs of its
neighboring vertices and divides each pair into two subsets (called half
windows); then computes the uniform Laplacians of all such subsets and
subsequently projects the computed Laplacians to the full-window uniform
Laplacian to alleviate flipping and degeneration. The half window with least
regularization energy is then chosen for v. We develop an iterative approach to
apply HLO for surface denoising. Our method is conceptually simple and easy to
use because it has a single parameter, i.e., the number of iterations for
updating vertices. We show that our method can preserve features better than
the popular uniform Laplacian-based denoising and it significantly alleviates
the shrinkage artifact. Extensive experimental results demonstrate that HLO is
better than or comparable to state-of-the-art techniques both qualitatively and
quantitatively and that it is particularly good at handling meshes with high
noise. We will make our source code publicly available.
</p></div>
    </summary>
    <updated>2019-05-14T23:30:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04660</id>
    <link href="http://arxiv.org/abs/1905.04660" rel="alternate" type="text/html"/>
    <title>List Decodable Learning via Sum of Squares</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raghavendra:Prasad.html">Prasad Raghavendra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yau:Morris.html">Morris Yau</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04660">PDF</a><br/><b>Abstract: </b>In the list-decodable learning setup, an overwhelming majority (say a
$1-\beta$-fraction) of the input data consists of outliers and the goal of an
algorithm is to output a small list $\mathcal{L}$ of hypotheses such that one
of them agrees with inliers. We develop a framework for list-decodable learning
via the Sum-of-Squares SDP hierarchy and demonstrate it on two basic
statistical estimation problems
</p>
<p>{\it Linear regression:} Suppose we are given labelled examples
$\{(X_i,y_i)\}_{i \in [N]}$ containing a subset $S$ of $\beta N$ {\it inliers}
$\{X_i \}_{i \in S}$ that are drawn i.i.d. from standard Gaussian distribution
$N(0,I)$ in $\mathbb{R}^d$, where the corresponding labels $y_i$ are
well-approximated by a linear function $\ell$. We devise an algorithm that
outputs a list $\mathcal{L}$ of linear functions such that there exists some
$\hat{\ell} \in \mathcal{L}$ that is close to $\ell$.
</p>
<p>This yields the first algorithm for linear regression in a list-decodable
setting. Our results hold for any distribution of examples whose concentration
and anticoncentration can be certified by Sum-of-Squares proofs.
</p>
<p>{\it Mean Estimation:}
</p>
<p>Given data points $\{X_i\}_{i \in [N]}$ containing a subset $S$ of $\beta N$
{\it inliers} $\{X_i \}_{i \in S}$ that are drawn i.i.d. from a Gaussian
distribution $N(\mu,I)$ in $\mathbb{R}^d$, we devise an algorithm that
generates a list $\mathcal{L}$ of means such that there exists $\hat{\mu} \in
\mathcal{L}$ close to $\mu$.
</p>
<p>The recovery guarantees of the algorithm are analogous to the existing
algorithms for the problem by Diakonikolas \etal and Kothari \etal.
</p>
<p>In an independent and concurrent work, Karmalkar \etal \cite{KlivansKS19}
also obtain an algorithm for list-decodable linear regression using the
Sum-of-Squares SDP hierarchy.
</p></div>
    </summary>
    <updated>2019-05-14T23:25:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04612</id>
    <link href="http://arxiv.org/abs/1905.04612" rel="alternate" type="text/html"/>
    <title>Continuous-Time Systems for Solving 0-1 Integer Linear Programming Feasibility Problems</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Chengrui.html">Chengrui Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/MacLennan:Bruce_J=.html">Bruce J. MacLennan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04612">PDF</a><br/><b>Abstract: </b>The 0-1 integer linear programming feasibility problem is an important
NP-complete problem. This paper proposes a continuous-time dynamical system for
solving that problem without getting trapped in non-solution local minima.
First, the problem is transformed to an easier form in linear time. Then, we
propose an "impulse algorithm" to escape from local traps and show its
performance is better than randomization for escaping traps. Second, we present
the time-to-solution distribution of the impulse algorithm and compare it with
exhaustive search to see its advantages. Third, we show that the fractional
size of the basin of attraction of the global minimum is significantly larger
than $2^{-N}$, the corresponding discrete probability for exhaustive search.
Finally, we conduct a case study to show that the location of the basin is
independent of different dimensions. These findings reveal a better way to
solve the 0-1 integer linear programming feasibility problem continuously and
show that its cost could be less than discrete methods in average cases.
</p></div>
    </summary>
    <updated>2019-05-14T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04564</id>
    <link href="http://arxiv.org/abs/1905.04564" rel="alternate" type="text/html"/>
    <title>PrivateJobMatch: A Privacy-Oriented Deferred Multi-Match Recommender System for Stable Employment</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Amar Saini <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04564">PDF</a><br/><b>Abstract: </b>Coordination failure reduces match quality among employers and candidates in
the job market, resulting in a large number of unfilled positions and/or
unstable, short-term employment. Centralized job search engines provide a
platform that connects directly employers with job-seekers. However, they
require users to disclose a significant amount of personal data, i.e., build a
user profile, in order to provide meaningful recommendations. In this paper, we
present PrivateJobMatch -- a privacy-oriented deferred multi-match recommender
system -- which generates stable pairings while requiring users to provide only
a partial ranking of their preferences. PrivateJobMatch explores a series of
adaptations of the game-theoretic Gale-Shapley deferred-acceptance algorithm
which combine the flexibility of decentralized markets with the intelligence of
centralized matching. We identify the shortcomings of the original algorithm
when applied to a job market and propose novel solutions that rely on machine
learning techniques. Experimental results on real and synthetic data confirm
the benefits of the proposed algorithms across several quality measures. Over
the past year, we have implemented a PrivateJobMatch prototype and deployed it
in an active job market economy. Using the gathered real-user preference data,
we find that the match-recommendations are superior to a typical decentralized
job market---while requiring only a partial ranking of the user preferences.
</p></div>
    </summary>
    <updated>2019-05-14T23:26:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04469</id>
    <link href="http://arxiv.org/abs/1905.04469" rel="alternate" type="text/html"/>
    <title>A New Shortest Path Algorithm Generalized on Dynamic Graph for Commercial Intelligent Navigation for Transportation Management</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tan:Yong.html">Yong Tan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04469">PDF</a><br/><b>Abstract: </b>Dynamic graph research is an essential subject in Computer Science. The
shortest path problem is still the central in this field; moreover there is a
variety of applications in practical projects.
</p>
<p>In this paper, we select the transportation activity as a paradigm to study.
Of course there exists the most clear and appealing practical application over
the intelligent navigation, also which is an important part in intelligent
transportation system (ITS). Totally speaking, this activity is fairly simple
and well-behavior under our consideration, for which, there is a lot of
sophisticated theories and techniques to motivate our researches although this
problem relates to interdisciplinary; so that we can be dedicated to computing
aspect. Below, a host of practical problems will by the way be discussed in
theory and empiricism including correctness, sampling, accuracy, compatibility,
quick query and the application into other research; therein some have been
scarcely argued intentionally or not in literatures before. Through these
contents, we are able to have a smart system built which easy to incorporate
other modules to realize a sophisticated industrial system.
</p></div>
    </summary>
    <updated>2019-05-14T23:25:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04447</id>
    <link href="http://arxiv.org/abs/1905.04447" rel="alternate" type="text/html"/>
    <title>Solving Empirical Risk Minimization in the Current Matrix Multiplication Time</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Yin_Tat.html">Yin Tat Lee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Song:Zhao.html">Zhao Song</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Qiuyi.html">Qiuyi Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04447">PDF</a><br/><b>Abstract: </b>Many convex problems in machine learning and computer science share the same
form: \begin{align*} \min_{x} \sum_{i} f_i( A_i x + b_i), \end{align*} where
$f_i$ are convex functions on $\mathbb{R}^{n_i}$ with constant $n_i$, $A_i \in
\mathbb{R}^{n_i \times d}$, $b_i \in \mathbb{R}^{n_i}$ and $\sum_i n_i = n$.
This problem generalizes linear programming and includes many problems in
empirical risk minimization. In this paper, we give an algorithm that runs in
time \begin{align*} O^* ( ( n^{\omega} + n^{2.5 - \alpha/2} + n^{2+ 1/6} ) \log
(n / \delta) ) \end{align*} where $\omega$ is the exponent of matrix
multiplication, $\alpha$ is the dual exponent of matrix multiplication, and
$\delta$ is the relative accuracy. Note that the runtime has only a log
dependence on the condition numbers or other data dependent parameters and
these are captured in $\delta$. For the current bound $\omega \sim 2.38$
[Vassilevska Williams'12, Le Gall'14] and $\alpha \sim 0.31$ [Le Gall,
Urrutia'18], our runtime $O^* ( n^{\omega} \log (n / \delta))$ matches the
current best for solving a dense least squares regression problem, a special
case of the problem we consider. Very recently, [Alman'18] proved that all the
current known techniques can not give a better $\omega$ below $2.168$ which is
larger than our $2+1/6$. Our result generalizes the very recent result of
solving linear programs in the current matrix multiplication time [Cohen, Lee,
Song'19] to a more broad class of problems. Our algorithm proposes two concepts
which are different from [Cohen, Lee, Song'19] :
</p>
<p>$\bullet$ We give a robust deterministic central path method, whereas the
previous one is a stochastic central path which updates weights by a random
sparse vector.
</p>
<p>$\bullet$ We propose an efficient data-structure to maintain the central path
of interior point methods even when the weights update vector is dense.
</p></div>
    </summary>
    <updated>2019-05-14T23:28:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04434</id>
    <link href="http://arxiv.org/abs/1905.04434" rel="alternate" type="text/html"/>
    <title>Efficient Algorithms for Optimal Perimeter Guarding</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Si Wei Feng, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Han:Shuai_D=.html">Shuai D. Han</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Kai.html">Kai Gao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Jingjin.html">Jingjin Yu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04434">PDF</a><br/><b>Abstract: </b>We investigate the problem of optimally assigning a large number of robots
(or other types of autonomous agents) to guard the perimeters of closed 2D
regions, where the perimeter of each region to be guarded may contain multiple
disjoint polygonal chains. Each robot is responsible for guarding a subset of a
perimeter and any point on a perimeter must be guarded by some robot. In
allocating the robots, the main objective is to minimize the maximum 1D
distance to be covered by any robot along the boundary of the regions. For this
optimization problem which we call optimal perimeter guarding (OPG), thorough
structural analysis is performed, which is then exploited to develop fast exact
algorithms that run in guaranteed low polynomial time. In addition to formal
analysis and proofs, experimental evaluations and simulations are performed
that further validate the correctness and effectiveness of our algorithmic
results.
</p></div>
    </summary>
    <updated>2019-05-14T23:29:30Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04383</id>
    <link href="http://arxiv.org/abs/1905.04383" rel="alternate" type="text/html"/>
    <title>Persistent homology of the sum metric</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Carlsson:Gunnar.html">Gunnar Carlsson</a>, Benjamin Filippenko <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04383">PDF</a><br/><b>Abstract: </b>Given finite metric spaces $(X, d_X)$ and $(Y, d_Y)$, we investigate the
persistent homology $PH_*(X \times Y)$ of the Cartesian product $X \times Y$
equipped with the sum metric $d_X + d_Y$. Interpreting persistent homology as a
module over a polynomial ring, one might expect the usual K\"unneth short exact
sequence to hold. We prove that it holds for $PH_0$ and $PH_1$, and we
illustrate with the Hamming cube $\{0,1\}^k$ that it fails for $PH_n,\,\, n
\geq 2$. For $n = 2$, the prediction for $PH_2(X \times Y)$ from the expected
K\"unneth short exact sequence has a natural surjection onto $PH_2(X \times
Y)$. We compute the nontrivial kernel of this surjection for the splitting of
Hamming cubes $\{0,1\}^k = \{0,1\}^{k-1} \times \{0,1\}$. For all $n \geq 0$,
the interleaving distance between the prediction for $PH_n(X \times Y)$ and the
true persistent homology is bounded above by the minimum of the diameters of
$X$ and $Y$. As preliminary results of independent interest, we establish an
algebraic K\"unneth formula for simplicial modules over the ring
$\kappa[\mathbb{R}_+]$ of polynomials with coefficients in a field $\kappa$ and
exponents in $\mathbb{R}_+ = [0,\infty)$, as well as a K\"unneth formula for
the persistent homology of $\mathbb{R}_+$-filtered simplicial sets -- both of
these K\"unneth formulas hold in all homological dimensions $n \geq 0$.
</p></div>
    </summary>
    <updated>2019-05-14T23:44:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04329</id>
    <link href="http://arxiv.org/abs/1905.04329" rel="alternate" type="text/html"/>
    <title>Delay Parameter Selection in Permutation Entropy Using Topological Data Analysis</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Audun D. Myers, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khasawneh:Firas_A=.html">Firas A. Khasawneh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04329">PDF</a><br/><b>Abstract: </b>Permutation Entropy (PE) is a powerful tool for quantifying the
predictability of a sequence which includes measuring the regularity of a time
series. Despite its successful application in a variety of scientific domains,
PE requires a judicious choice of the delay parameter $\tau$. While another
parameter of interest in PE is the motif dimension $n$, Typically $n$ is
selected between $4$ and $8$ with $5$ or $6$ giving optimal results for the
majority of systems. Therefore, in this work we focus solely on choosing the
delay parameter. Selecting $\tau$ is often accomplished using trial and error
guided by the expertise of domain scientists. However, in this paper, we show
that persistent homology, the flag ship tool from Topological Data Analysis
(TDA) toolset, provides an approach for the automatic selection of $\tau$. We
evaluate the successful identification of a suitable $\tau$ from our TDA-based
approach by comparing our results to a variety of examples in published
literature.
</p></div>
    </summary>
    <updated>2019-05-14T23:41:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1905.04325</id>
    <link href="http://arxiv.org/abs/1905.04325" rel="alternate" type="text/html"/>
    <title>Seeding with Costly Network Information</title>
    <feedworld_mtime>1557792000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eckles:Dean.html">Dean Eckles</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Esfandiari:Hossein.html">Hossein Esfandiari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mossel:Elchanan.html">Elchanan Mossel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rahimian:M=_Amin.html">M. Amin Rahimian</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1905.04325">PDF</a><br/><b>Abstract: </b>The spread of behavior over social networks depends on the contact structure
among individuals, and seeding the most influential agents can substantially
enhance the extent of the spread. While the choice of the best seed set, known
as influence maximization, is a computationally hard problem, many
computationally efficient algorithms have been proposed to approximate the
optimal seed sets with provable guarantees. Most of the previous work on
influence maximization assumes the knowledge of the entire network graph.
However, in practice, obtaining full knowledge of the network structure is very
costly.
</p>
<p>In this work, we consider the choice of $k$ initial seeds to maximize the
expected number of adopters under the independent cascade model. We propose a
''probe-and-seed'' algorithm that provides almost tight approximation
guarantees using $\tilde{O}({p} n^2 + \sqrt{p} n^{1.5})$ edge queries in
$\tilde{O}({p} n^2 + \sqrt{p} n^{1.5})$ time, where $n$ is the network size and
$p$ is the probability of spreading through an edge. To the best of our
knowledge, this is the first result to provide approximation guarantees for
influence maximization, using a sub-quadratic number of queries for
polynomially small $p$. We complement this result by showing that it is
impossible to approximate the problem using $o(n^2)$ edge queries for constant
$p$. In the end, we consider a more advanced query model, where one seeds a
node and observes the resultant adopters after running the spreading process.
We provide an algorithm that uses only $\tilde O(k^2)$ such queries and
provides almost tight approximation guarantees.
</p></div>
    </summary>
    <updated>2019-05-14T23:21:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-05-14T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=633</id>
    <link href="https://emanueleviola.wordpress.com/2019/05/13/and-this-is-me-with-my-buddies/" rel="alternate" type="text/html"/>
    <title>And this is me with my buddies</title>
    <summary>  Advertisements</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div class="RY3tic">
<div class="eGiHwc"><img alt="warriors2" class="alignnone size-full wp-image-634" src="https://emanueleviola.files.wordpress.com/2019/05/warriors2.jpg?w=640"/></div>
<div class="KYCEmd"/>
</div>
<div class="RY3tic">
<div class="eGiHwc"/>
<div class="KYCEmd"/>
</div>
<p> </p></div>
    </content>
    <updated>2019-05-13T15:24:14Z</updated>
    <published>2019-05-13T15:24:14Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Emanuele</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2019-05-15T21:21:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3507110503322010708</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3507110503322010708/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/05/ronald-grahams-other-large-number-well.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3507110503322010708" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3507110503322010708" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/05/ronald-grahams-other-large-number-well.html" rel="alternate" type="text/html"/>
    <title>Ronald Graham's other large number. Well---- it was large in 1964 anyway.</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Graham's number (see <a href="https://en.wikipedia.org/wiki/Graham%27s_number">here</a>) was at one time the largest number to appear in a math proof.<br/>
<br/>
a) GN was an upper bound on a problem in Ramsey theory. There are now better upper bounds, see <a href="https://www.sciencedirect.com/science/article/pii/S0195669814000936?via%3Dihub">here</a>. These better upper bounds are still large- Hales-Jewitt-Large, but that's already much smaller than the original GN.<br/>
<br/>
b) Other proofs now have numbers even larger than GN. For example Harvey Friedman's work on the finite versions of Kruskal's Tree Theorem. (There may be other cases- if you know some then let me know in the comments.)<br/>
<br/>
Since my dept recently moved buildings I found old papers that I had not looked at in years. One of them was<br/>
<br/>
<i>Old and New Problems and Results in Combinatorial Number Theory</i><br/>
<br/>
by Erdos and Graham<br/>
<br/>
(see <a href="http://www.math.ucsd.edu/~ronspubs/79_09_combinatorial_number_theory.pdf">here</a>)<br/>
<br/>
So I began reading it and came across a result of Graham from 1964 that used large numbers. No where near as large as GN, but I found it interesting that Graham was involved with large numbers way back then.<br/>
<br/>
Here is the problem:<br/>
<br/>
A <i>Lucas Sequence</i> is a sequence that obeys<br/>
<br/>
a(n) = a(n-1) + a(n-2).<br/>
<br/>
Clearly such a sequence is determined by a(0) and a(1).<br/>
<br/>
QUESTION: Does there exists a(0) and a(1)  that are rel prime such that the sequence has only composite numbers?<br/>
<br/>
By ingenuity and some computing power Graham found YES. For how the got the numbers see <a href="http://www.math.ucsd.edu/~ronspubs/64_06_fibonacci.pdf">here</a>. The numbers are of course in the paper, and how they got them is interesting, but I present them anyway. Hope I don't make a typo:<br/>
<br/>
a(0) = 1786772701928802632268715130455793<br/>
<br/>
a(1) = 1059683225053915111058164141686995<br/>
<br/>
The paper Old and New... says its open if there is a smaller pair of numbers, I do not know if it is still open. If you know, let us all  know in the comments!<br/>
<br/>
These numbers seem small today since we have modern computers that can store and manipulate them easily. Were the considered large numbers in 1964? They were never called Graham Numbers which is probably just as well since that honor lay ahead.<br/>
<br/>
<br/></div>
    </content>
    <updated>2019-05-13T04:39:00Z</updated>
    <published>2019-05-13T04:39:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-05-15T18:02:04Z</updated>
    </source>
  </entry>
</feed>
