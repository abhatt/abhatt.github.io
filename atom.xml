<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-01-02T12:22:09Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/01/02/postdoc-at-kth-royal-insitute-of-technology-apply-by-january-23-2020/</id>
    <link href="https://cstheory-jobs.org/2020/01/02/postdoc-at-kth-royal-insitute-of-technology-apply-by-january-23-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc at KTH – Royal Insitute of Technology (apply by January 23, 2020)</title>
    <summary>The postdoc position is in the area of computational complexity theory, focusing on questions at the intersection of approximation algorithms and subexponential algorithms. . This is includes both hardness results and algorithmic results. If so desired, up to 20% teaching can be included in the position. The position is for one year with a possible […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The postdoc position is in the area of computational complexity theory, focusing on questions at the intersection of approximation algorithms and subexponential algorithms. . This is includes both hardness results and algorithmic results. If so desired, up to 20% teaching can be included in the position. The position is for one year with a possible (and likely) extension to a second year.</p>
<p>Website: <a href="https://www.kth.se/en/om/work-at-kth/lediga-jobb/what:job/jobID:308077/where:4/">https://www.kth.se/en/om/work-at-kth/lediga-jobb/what:job/jobID:308077/where:4/</a><br/>
Email: johanh@kth.se</p></div>
    </content>
    <updated>2020-01-02T09:14:29Z</updated>
    <published>2020-01-02T09:14:29Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-01-02T12:20:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.13140</id>
    <link href="http://arxiv.org/abs/1912.13140" rel="alternate" type="text/html"/>
    <title>Bas-relief Generation from Point Clouds Based on Normal Space Compression with Real-time Adjustment on CPU</title>
    <feedworld_mtime>1577923200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nie:Jianhui.html">Jianhui Nie</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shi:Wenkai.html">Wenkai Shi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Ye.html">Ye Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Hao.html">Hao Gao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Feng.html">Feng Xu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Zhaochen.html">Zhaochen Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Guoping.html">Guoping Jiang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.13140">PDF</a><br/><b>Abstract: </b>Bas-relief generation based on 3d models is a hot topic in computer graphics.
State-of-the-art algorithms take a mesh surface as input, but real-time
interaction via CPU cannot be realized. In this paper, a bas-relief generation
algorithm that takes a scattered point cloud as input is proposed. The
algorithm takes normal vectors as the operation object and the variation of the
local surface as the compression criterion. By constructing and solving linear
equations of bas-relief vertices, the closed-form solution can be obtained.
Since there is no need to compute discrete gradients on a point cloud lacking
topology information, it is easier to implement and more intuitive than
gradient domain methods. The algorithm provides parameters to adjust the
bas-relief height, saturation and detail richness. At the same time, through
the solution strategy based on the subspace, it realizes the real-time
adjustment of the bas-relief effect based on the computing power of a consumer
CPU. In addition, an iterative solution to generate a bas-relief model of a
specified height is presented to meet specific application requirements.
Experiments show that our algorithm provides a unified solution for various
types of bas-relief creation and can generate bas-reliefs with good saturation
and rich details.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12973</id>
    <link href="http://arxiv.org/abs/1912.12973" rel="alternate" type="text/html"/>
    <title>Geometry and Analytics of the Multifacility Weber Problem</title>
    <feedworld_mtime>1577923200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Uteshev:Alexei_Yu=.html">Alexei Yu. Uteshev</a>, Elizaveta A. Semenova <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12973">PDF</a><br/><b>Abstract: </b>For the Weber problem of construction of the minimal cost planar weighted
network connecting four terminals with two extra facilities, the solution by
radicals is proposed. The conditions for the existence of the network in the
assumed topology and the explicit formulae for coordinates of the facilities
are presented. The obtained results are utilized for investigation of the
network dynamics under variation of parameters. Extension of the results to the
general Weber problem is also discussed.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12759</id>
    <link href="http://arxiv.org/abs/1912.12759" rel="alternate" type="text/html"/>
    <title>Persistence Diagrams for Efficient Simplicial Complex Reconstruction</title>
    <feedworld_mtime>1577923200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fasy:Brittany_Terese.html">Brittany Terese Fasy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Micka:Samuel.html">Samuel Micka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Millman:David_L=.html">David L. Millman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schenfisch:Anna.html">Anna Schenfisch</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Williams:Lucia.html">Lucia Williams</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12759">PDF</a><br/><b>Abstract: </b>Topological descriptors have been shown to be useful for summarizing and
differentiating shapes. Related work uses persistence diagrams and Euler
characteristic curves to differentiate between shapes and quantifies the number
of descriptors necessary for shape reconstruction, given certain assumptions
such as minimum curvature. In this work, we provide the first deterministic
algorithm using directional persistence diagrams to reconstruct simplicial
complexes in arbitrary finite dimension.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12399</id>
    <link href="http://arxiv.org/abs/1912.12399" rel="alternate" type="text/html"/>
    <title>Persistent Homotopy Groups of Metric Spaces</title>
    <feedworld_mtime>1577923200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/M=eacute=moli:Facundo.html">Facundo Mémoli</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Ling.html">Ling Zhou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12399">PDF</a><br/><b>Abstract: </b>We study notions of persistent homotopy groups of compact metric spaces
together with their stability properties in the Gromov-Hausdorff sense. We pay
particular attention to the case of fundamental groups for which we obtain a
more precise description.
</p></div>
    </summary>
    <updated>2020-01-02T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=684</id>
    <link href="https://emanueleviola.wordpress.com/2020/01/01/publish-and-perish/" rel="alternate" type="text/html"/>
    <title>Publish and perish</title>
    <summary>Moshe Vardi’s latest insight in the Communications of the ACM (whose title we adopt for this post) agrees with our previous post “Because of pollution, conferences should be virtual.” Vardi calls for “sweeping policy change […] requiring that authors of accepted papers that must fly to participate in a conference may opt out from in-person […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://cacm.acm.org/magazines/2020/1/241717-publish-and-perish/fulltext">Moshe Vardi’s latest insight in the Communications of the ACM </a>(whose title we adopt for this post) agrees with our previous post “<a href="https://emanueleviola.wordpress.com/2019/08/04/because-of-pollution-conferences-should-be-virtual/">Because of pollution, conferences should be virtual.</a>” Vardi calls for “sweeping policy change […] requiring that authors of accepted papers that must fly to  participate in a conference may opt out from in-person involvement and  contribute instead by video.”  Vardi gives some indication of the environmental impact of the travel-based system, and further suspects that in-person conference participation is “much less valuable than we would like to believe.”</p>



<p>These issues are closely related to the decades-old discussion of journals vs. conferences. <a href="https://emanueleviola.wordpress.com/tag/utopia/">Several older posts on this blog </a>were devoted to that. Lance Fortnow, back in 2009, wrote that it’s <a href="https://cacm.acm.org/magazines/2009/8/34492-viewpoint-time-for-computer-science-to-grow-up/abstract">Time for computer science to grow up</a>.  The full text of this article is premium content, but you can read a pre-publication version <a href="http://www.cs.uchicago.edu/~fortnow/papers/growup.pdf">here</a>. Basically, he argues in favor of a journal-based publication system.</p>



<p>Apparently in response, judging from the title, Boaz Barak wrote a piece titled <a href="https://cacm.acm.org/magazines/2016/6/202644-computer-science-should-stay-young/abstract">Computer science should stay young.</a> I can’t quickly find a link to the whole thing, but his bottom line is online “I disagree with the conclusion that we should transition to a classical journal-based model similar to that of other fields. I believe conferences offer a number of unique advantages that have helped make computer science dynamic and successful, and can continue to do so in the future.”</p>



<p>I disagree that conferences are young. They belong to the BI (before internet) era, and so look rather anchored in the past to me.  Historically, I also suppose in-person discussion predates writing, though this is irrelevant.  What is young is the health impact of pollution (Fortnow and Barak’s pieces don’t touch on health issues). (By health impact I include climate change, but I prefer not to use that term for various reasons.)</p>



<p>And what is young and cool is arxiv overlay journals, TCS+ talks, videoconferences,  <a href="https://eccc.weizmann.ac.il/">ECCC</a>, etc.</p>



<p>Instead, we impose on our community most inconvenient transoceanic flights.  To end I’ll quote from <a href="http://www.wisdom.weizmann.ac.il/~oded/MC/269.html">Oded Goldreich’s my choices</a>:</p>



<p><b>Phoenix in June:</b> […] One must be out of their mind to hold a conference under such weather conditions. I guess humans can endure such weather conditions and even worse ones, but why choose to do so? Why call upon people from all over the world to travel to one of the least comfortable locations (per the timing)?</p>


<p><!--EndFragment--><br/><br/></p></div>
    </content>
    <updated>2020-01-01T17:03:39Z</updated>
    <published>2020-01-01T17:03:39Z</published>
    <category term="Uncategorized"/>
    <category term="health"/>
    <category term="Utopia"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-01-02T12:21:24Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/001</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/001" rel="alternate" type="text/html"/>
    <title>TR20-001 |  Nullstellensatz Size-Degree Trade-offs from Reversible Pebbling | 

	Or Meir, 

	Susanna de Rezende, 

	Jakob Nordström, 

	Robert Robere</title>
    <summary>We establish an exactly tight relation between reversible pebblings of graphs and Nullstellensatz refutations of pebbling formulas, showing that a graph $G$ can be reversibly pebbled in time $t$ and space $s$ if and only if there is a Nullstellensatz refutation of the pebbling formula over $G$ in size $t+1$ and degree $s$ (independently of the field in which the Nullstellensatz refutation  is made). We use this correspondence to prove a number of strong size-degree trade-offs for Nullstellensatz, which to the best of our   knowledge are the first such results for this proof system.</summary>
    <updated>2020-01-01T07:53:22Z</updated>
    <published>2020-01-01T07:53:22Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-01-02T11:20:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.13446</id>
    <link href="http://arxiv.org/abs/1912.13446" rel="alternate" type="text/html"/>
    <title>Proximity Search For Maximal Subgraph Enumeration</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Conte:Alessio.html">Alessio Conte</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marino:Andrea.html">Andrea Marino</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grossi:Roberto.html">Roberto Grossi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Uno:Takeaki.html">Takeaki Uno</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Versari:Luca.html">Luca Versari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.13446">PDF</a><br/><b>Abstract: </b>This paper considers the subgraphs of an input graph that satisfy a given
property and are maximal under inclusion. The main result is a seemingly novel
technique, proximity search, to list these subgraphs in polynomial delay each.
These include Maximal Bipartite Subgraphs, Maximal $k$-Degenerate Subgraphs
(for bounded $k$), Maximal Induced Chordal Subgraphs, and Maximal Induced
Trees. Using known techniques, such as reverse search, the space of sought
solutions induces an implicit directed graph called ``solution graph'':
however, the latter can give rise to exponential out-degree, thus preventing
polynomial delay. The novelty of our algorithm in this paper consists in
providing a technique for generating a better solution graph, significantly
reducing the out-degree with respect to existing approaches, so that it still
remains strongly connected and guarantees that all solutions can be reported
with polynomial delay by a suitable traversal. While traversing the solution
graph incur in space proportional to the number of solutions to keep track of
visited ones, we further propose a technique to induce a parent-child
relationship and achieve polynomial space when suitable conditions are met.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.13347</id>
    <link href="http://arxiv.org/abs/1912.13347" rel="alternate" type="text/html"/>
    <title>$2$-edge-twinless blocks</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaberi:Raed.html">Raed Jaberi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.13347">PDF</a><br/><b>Abstract: </b>Let $G=(V,E))$ be a directed graph. A $2$-edge-twinless block in $G$ is a
maximal vertex set $C^{t}\subseteq V$ of with $|C^{t}|&gt;1$ such that for any
distinct vertices $v,w \in C^{t}$, and for every edge $e\in E$, the vertices
$v,w$ are in the same twinless strongly connected component of $G\setminus\left
\lbrace e \right\rbrace $. An edge $e$ in a twinless strongly connected graph
is a twinless bridge if the subgraph obtained from $G$ by removing $e$ is not
twinless strongly connected.
</p>
<p>In this paper we show that the $2$-edge-twinless blocks of $G$ can be
computed in $O((b_{t}n+m)n)$ time, where $b_{t}$ is the number of twinless
bridges of $G$.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.13287</id>
    <link href="http://arxiv.org/abs/1912.13287" rel="alternate" type="text/html"/>
    <title>Efficiently Realizing Interval Sequences</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bar=Noy:Amotz.html">Amotz Bar-Noy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Choudhary:Keerti.html">Keerti Choudhary</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peleg:David.html">David Peleg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rawitz:Dror.html">Dror Rawitz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.13287">PDF</a><br/><b>Abstract: </b>We consider the problem of realizable interval-sequences. An interval
sequence comprises of $n$ integer intervals $[a_i,b_i]$ such that $0\leq a_i
\leq b_i \leq n-1$, and is said to be graphic/realizable if there exists a
graph with degree sequence, say, $D=(d_1,\ldots,d_n)$ satisfying the condition
$a_i \leq d_i \leq b_i$, for each $i \in [1,n]$. There is a characterisation
(also implying an $O(n)$ verifying algorithm) known for realizability of
interval-sequences, which is a generalization of the Erdos-Gallai
characterisation for graphic sequences. However, given any realizable
interval-sequence, there is no known algorithm for computing a corresponding
graphic certificate in $o(n^2)$ time.
</p>
<p>In this paper, we provide an $O(n \log n)$ time algorithm for computing a
graphic sequence for any realizable interval sequence. In addition, when the
interval sequence is non-realizable, we show how to find a graphic sequence
having minimum deviation with respect to the given interval sequence, in the
same time. Finally, we consider variants of the problem such as computing the
most regular graphic sequence, and computing a minimum extension of a length
$p$ non-graphic sequence to a graphic one.
</p></div>
    </summary>
    <updated>2020-01-01T23:32:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.13286</id>
    <link href="http://arxiv.org/abs/1912.13286" rel="alternate" type="text/html"/>
    <title>Graph Realizations: Maximum and Minimum Degree in Vertex Neighborhoods</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bar=Noy:Amotz.html">Amotz Bar-Noy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Choudhary:Keerti.html">Keerti Choudhary</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peleg:David.html">David Peleg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rawitz:Dror.html">Dror Rawitz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.13286">PDF</a><br/><b>Abstract: </b>The classical problem of degree sequence realizability asks whether or not a
given sequence of $n$ positive integers is equal to the degree sequence of some
$n$-vertex undirected simple graph. While the realizability problem of degree
sequences has been well studied for different classes of graphs, there has been
relatively little work concerning the realizability of other types of
information profiles, such as the vertex neighborhood profiles.
</p>
<p>In this paper, we initiate the study of neighborhood degree profiles. We
focus on the natural problem of realizing maximum and minimum neighborhood
degrees. More specifically, we ask the following question: Given a sequence $D$
of $n$ non-negative integers $0\leq d_1\leq \cdots \leq d_n$, does there exist
a simple graph with vertices $v_1,\ldots, v_n$ such that for every $1\le i \le
n$, the maximum (resp. minimum) degree in the neighborhood of $v_i$ is exactly
$d_i$?
</p>
<p>We provide in this work various results for both maximum as well as minimum
neighborhood degree for general $n$ vertex graphs. Our results are first of its
kind that studies extremal neighborhood degree profiles. For maximum
neighborhood degree profiles, we provide a {\em complete realizability
criteria}. In comparison, we observe that the minimum neighborhood profiles are
not so well-behaved, for these our necessary and sufficient conditions for
realizability {\em differ by a factor of at most two}.
</p></div>
    </summary>
    <updated>2020-01-01T23:22:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.13190</id>
    <link href="http://arxiv.org/abs/1912.13190" rel="alternate" type="text/html"/>
    <title>LinearPartition: Linear-Time Approximation of RNA Folding Partition Function and Base Pairing Probabilities</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:He.html">He Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Liang.html">Liang Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mathews:David_H=.html">David H. Mathews</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Liang.html">Liang Huang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.13190">PDF</a><br/><b>Abstract: </b>RNA secondary structure prediction is widely used to understand RNA function.
Recently, there has been a shift away from the classical minimum free energy
(MFE) methods to partition function-based methods that account for folding
ensembles and can therefore estimate structure and base pair probabilities.
However, the classic partition function algorithm scales cubically with
sequence length, and is therefore a slow calculation for long sequences. This
slowness is even more severe than cubic-time MFE-based methods due to a larger
constant factor in runtime. Inspired by the success of LinearFold algorithm
that computes the MFE structure in linear time, we address this issue by
proposing a similar linear-time heuristic algorithm, LinearPartition, to
approximate the partition function and base pairing probabilities.
LinearPartition is 256x faster than Vienna RNAfold for a sequence with length
15,780, and 2,771x faster than CONTRAfold for a sequence with length 32,753.
Interestingly, although LinearPartition is approximate, it runs in linear time
without sacrificing accuracy when base pair probabilities are used to assemble
structures, and even leads to a small accuracy improvement on longer families
(16S and 23S rRNA).
</p></div>
    </summary>
    <updated>2020-01-01T23:53:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.13117</id>
    <link href="http://arxiv.org/abs/1912.13117" rel="alternate" type="text/html"/>
    <title>Exact exponential algorithms for two poset problems</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kozma:L=aacute=szl=oacute=.html">László Kozma</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.13117">PDF</a><br/><b>Abstract: </b>Partially ordered sets (posets) are fundamental combinatorial objects with
important applications in computer science. Perhaps the most natural
algorithmic task, given a size-$n$ poset, is to compute its number of linear
extensions. In 1991 Brightwell and Winkler showed this problem to be
$\#P$-hard. In spite of extensive research, the fastest known algorithm is
still the straightforward $O(n 2^n)$-time dynamic programming (an adaptation of
the Bellman-Held-Karp algorithm for the TSP). Very recently, Dittmer and Pak
showed that the problem remains $\#P$-hard for two-dimensional posets, and no
algorithm was known to break the $2^n$-barrier even in this special case. The
question of whether the two-dimensional problem is easier than the general case
was raised decades ago by M\"ohring, Felsner and Wernisch, and others. In this
paper we show that the number of linear extensions of a two-dimensional poset
can be computed in time $O(1.8286^n)$.
</p>
<p>The related jump number problem asks for a linear extension of a poset,
minimizing the number of neighboring incomparable pairs. The problem has
applications in scheduling, and has been widely studied. In 1981 Pulleyblank
showed it to be NP-complete. We show that the jump number problem can be solved
(in arbitrary posets) in time $O(1.824^n)$. This improves (slightly) the
previous best bound of Kratsch and Kratsch.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12820</id>
    <link href="http://arxiv.org/abs/1912.12820" rel="alternate" type="text/html"/>
    <title>Linear Programming using Limited-Precision Oracles</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Ambros Gleixner, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Steffy:Daniel_E=.html">Daniel E. Steffy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12820">PDF</a><br/><b>Abstract: </b>Since the elimination algorithm of Fourier and Motzkin, many different
methods have been developed for solving linear programs. When analyzing the
time complexity of LP algorithms, it is typically either assumed that
calculations are performed exactly and bounds are derived on the number of
elementary arithmetic operations necessary, or the cost of all arithmetic
operations is considered through a bit-complexity analysis. Yet in practice,
implementations typically use limited-precision arithmetic. In this paper we
introduce the idea of a limited-precision LP oracle and study how such an
oracle could be used within a larger framework to compute exact precision
solutions to LPs. Under mild assumptions, it is shown that a polynomial number
of calls to such an oracle and a polynomial number of bit operations, is
sufficient to compute an exact solution to an LP. This work provides a
foundation for understanding and analyzing the behavior of the methods that are
currently most effective in practice for solving LPs exactly.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12790</id>
    <link href="http://arxiv.org/abs/1912.12790" rel="alternate" type="text/html"/>
    <title>Computing $2$-twinless blocks</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaberi:Raed.html">Raed Jaberi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12790">PDF</a><br/><b>Abstract: </b>Let $G=(V,E))$ be a directed graph. A $2$-twinless block in $G$ is a maximal
vertex set $B\subseteq V$ of size at least $2$ such that for each pair of
distinct vertices $x,y \in B$, and for each vertex $w\in V\setminus\left\lbrace
x,y \right\rbrace $, the vertices $x,y$ are in the same twinless strongly
connected component of $G\setminus\left \lbrace w \right\rbrace $.
</p>
<p>In this paper we present an algorithm for computing the $2$-twinless blocks
of $G$ in $O(n^{3})$ time.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12765</id>
    <link href="http://arxiv.org/abs/1912.12765" rel="alternate" type="text/html"/>
    <title>Deleting to Structured Trees</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dayal:Pratyush.html">Pratyush Dayal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Misra:Neeldhara.html">Neeldhara Misra</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12765">PDF</a><br/><b>Abstract: </b>We consider a natural variant of the well-known Feedback Vertex Set problem,
namely the problem of deleting a small subset of vertices or edges to a full
binary tree. This version of the problem is motivated by real-world scenarios
that are best modeled by full binary trees. We establish that both versions of
the problem are NP-hard, which stands in contrast to the fact that deleting
edges to obtain a forest or a tree is equivalent to the problem of finding a
minimum cost spanning tree, which can be solved in polynomial time. We also
establish that both problems are FPT by the standard parameter.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12747</id>
    <link href="http://arxiv.org/abs/1912.12747" rel="alternate" type="text/html"/>
    <title>Worst-Case Optimal Radix Triejoin</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fekete:Alan.html">Alan Fekete</a>, Brody Franks, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jordan:Herbert.html">Herbert Jordan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scholz:Bernhard.html">Bernhard Scholz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12747">PDF</a><br/><b>Abstract: </b>Relatively recently, the field of join processing has been swayed by the
discovery of a new class of multi-way join algorithms. The new algorithms join
multiple relations simultaneously rather than perform a series of pairwise
joins. The new join algorithms satisfy stronger worst-case runtime complexity
guarantees than any of the existing approaches based on pairwise joins -- they
are worst-case optimal in data complexity. These research efforts have resulted
in a flurry of papers documenting theoretical and some practical contributions.
However, there is still the quest of making the new worst-case optimal join
algorithms truly practical in terms of (1) ease of implementation and (2)
secondary index efficiency in terms of number of indexes created to answer a
query.
</p>
<p>In this paper, we present a simple worst-case optimal multi-way join
algorithm called the radix triejoin. Radix triejoin uses a binary encoding for
reducing the domain of a database. Our main technical contribution is that
domain reduction allows a bit-interleaving of attribute values that gives rise
to a query-independent relation representation, permitting the computation of
multiple queries over the same relations worst-case optimally without having to
construct additional secondary indexes. We also generalise the core algorithm
to conjunctive queries with inequality constraints and provide a new proof
technique for the worst-case optimal join result.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12740</id>
    <link href="http://arxiv.org/abs/1912.12740" rel="alternate" type="text/html"/>
    <title>Practice of Streaming and Dynamic Graphs: Concepts, Models, Systems, and Parallelism</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Besta:Maciej.html">Maciej Besta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fischer:Marc.html">Marc Fischer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kalavri:Vasiliki.html">Vasiliki Kalavri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kapralov:Michael.html">Michael Kapralov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hoefler:Torsten.html">Torsten Hoefler</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12740">PDF</a><br/><b>Abstract: </b>Graph processing has become an important part of various areas of computing,
including machine learning, medical applications, social network analysis,
computational sciences, and others. A growing amount of the associated graph
processing workloads are dynamic, with millions of edges added or removed per
second. Graph streaming frameworks are specifically crafted to enable the
processing of such highly dynamic workloads. Recent years have seen the
development of many such frameworks. However, they differ in their general
architectures (with key details such as the support for the parallel execution
of graph updates, or the incorporated graph data organization), the types of
updates and workloads allowed, and many others. To facilitate the understanding
of this growing field, we provide the first analysis and taxonomy of dynamic
and streaming graph processing. We focus on identifying the fundamental system
designs and on understanding their support for concurrency and parallelism, and
for different graph updates as well as analytics workloads. We also crystallize
the meaning of different concepts associated with streaming graph processing,
such as dynamic, temporal, online, and time-evolving graphs, edge-centric
processing, models for the maintenance of updates, and graph databases.
Moreover, we provide a bridge with the very rich landscape of graph streaming
theory by giving a broad overview of recent theoretical related advances, and
by analyzing which graph streaming models and settings could be helpful in
developing more powerful streaming frameworks and designs. We also outline
graph streaming workloads and research challenges.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12665</id>
    <link href="http://arxiv.org/abs/1912.12665" rel="alternate" type="text/html"/>
    <title>Adaptive Algorithm for Finding Connected Dominating Sets in Uncertain Graphs</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fukunaga:Takuro.html">Takuro Fukunaga</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12665">PDF</a><br/><b>Abstract: </b>The problem of finding a minimum-weight connected dominating set (CDS) of a
given undirected graph has been studied actively, motivated by operations of
wireless ad hoc networks. In this paper, we formulate a new stochastic variant
of the problem. In this problem, each node in the graph has a hidden random
state, which represents whether the node is active or inactive, and we seek a
CDS of the graph that consists of the active nodes. We consider an adaptive
algorithm for this problem, which repeat choosing nodes and observing the
states of the nodes around the chosen nodes until a CDS is found. Our
algorithms have a theoretical performance guarantee that the sum of the weights
of the nodes chosen by the algorithm is at most $O(\alpha \log (1/\delta))$
times that of any adaptive algorithm in expectation, where $\alpha$ is an
approximation factor for the node-weighted polymatroid Steiner tree problem and
$\delta$ is the minimum probability of possible scenarios on the node states.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12599</id>
    <link href="http://arxiv.org/abs/1912.12599" rel="alternate" type="text/html"/>
    <title>Quantum Image Preparation Based on Exclusive Sum-of-Product Minimization and Ternary Trees</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Younatan Matthew, Ghose Shohini <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12599">PDF</a><br/><b>Abstract: </b>Quantum image processing is one of the promising fields of quantum
information. The complexity overhead to design circuits to represent quantum
images is a significant problem. So, we proposed a new method to minimize the
total number required of quantum gates to represent the quantum image. Our
approach uses ternary trees to reduce the number of Toffoli gates in a quantum
image circuit. Also, it uses the complement property of Boolean algebra on a
set of Toffoli gates to combine two Toffoli gates into one, therefore reducing
the number of overall gates. Ternary trees are used to represent Toffoli gates
as they significantly increase run time and is supported through experiments on
sample images. The experimental results show that there is a high-speed up
compared with previous methods, bringing the processing time for thousands of
Toffoli gates from minutes to seconds.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12561</id>
    <link href="http://arxiv.org/abs/1912.12561" rel="alternate" type="text/html"/>
    <title>Towards Optimal Separations between Quantum and Randomized Query Complexities</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tal:Avishay.html">Avishay Tal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12561">PDF</a><br/><b>Abstract: </b>The query model offers a concrete setting where quantum algorithms are
provably superior to randomized algorithms. Beautiful results by
Bernstein-Vazirani, Simon, Aaronson, and others presented partial Boolean
functions that can be computed by quantum algorithms making much fewer queries
compared to their randomized analogs. To date, separations of $O(1)$ vs.
$\sqrt{N}$ between quantum and randomized query complexities remain the
state-of-the-art (where $N$ is the input length), leaving open the question of
whether $O(1)$ vs. $N^{1/2+\Omega(1)}$ separations are possible?
</p>
<p>We answer this question in the affirmative. Our separating problem is a
variant of the Aaronson-Ambainis $k$-fold Forrelation problem. We show that our
variant:
</p>
<p>(1) Can be solved by a quantum algorithm making $2^{O(k)}$ queries to the
inputs.
</p>
<p>(2) Requires at least $\tilde{\Omega}(N^{2(k-1)/(3k-1)})$ queries for any
randomized algorithm.
</p>
<p>For any constant $\varepsilon&gt;0$, this gives a $O(1)$ vs.
$N^{2/3-\varepsilon}$ separation between the quantum and randomized query
complexities of partial Boolean functions.
</p>
<p>Our proof is Fourier analytical and uses new bounds on the Fourier spectrum
of classical decision trees, which could be of independent interest.
</p>
<p>Looking forward, we conjecture that the Fourier bounds could be further
improved in a precise manner, and show that such conjectured bounds imply
optimal $O(1)$ vs. $N^{1-\varepsilon}$ separations between the quantum and
randomized query complexities of partial Boolean functions.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12541</id>
    <link href="http://arxiv.org/abs/1912.12541" rel="alternate" type="text/html"/>
    <title>Approximating Nash Social Welfare under Submodular Valuations through (Un)Matchings</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garg:Jugal.html">Jugal Garg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kulkarni:Pooja.html">Pooja Kulkarni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kulkarni:Rucha.html">Rucha Kulkarni</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12541">PDF</a><br/><b>Abstract: </b>We study the problem of approximating maximum Nash social welfare (NSW) when
allocating m indivisible items among n asymmetric agents with submodular
valuations. The NSW is a well-established notion of fairness and efficiency,
defined as the weighted geometric mean of agents' valuations. For special cases
of the problem with symmetric agents and additive(-like) valuation functions,
approximation algorithms have been designed using approaches customized for
these specific settings, and they fail to extend to more general settings.
Hence, no approximation algorithm with factor independent of m is known either
for asymmetric agents with additive valuations or for symmetric agents beyond
additive(-like) valuations.
</p>
<p>In this paper, we extend our understanding of the NSW problem to far more
general settings. Our main contribution is two approximation algorithms for
asymmetric agents with additive and submodular valuations respectively. Both
algorithms are simple to understand and involve non-trivial modifications of a
greedy repeated matchings approach. Allocations of high valued items are done
separately by un-matching certain items and re-matching them, by processes that
are different in both algorithms. We show that these approaches achieve
approximation factors of O(n) and O(n log n) for additive and submodular case
respectively, which is independent of the number of items. For additive
valuations, our algorithm outputs an allocation that also achieves the fairness
property of envy-free up to one item (EF1).
</p>
<p>Furthermore, we show that the NSW problem under submodular valuations is
strictly harder than all currently known settings with an e/(e-1) factor of the
hardness of approximation, even for constantly many agents. For this case, we
provide a different approximation algorithm that achieves a factor of e/(e-1),
hence resolving it completely.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12529</id>
    <link href="http://arxiv.org/abs/1912.12529" rel="alternate" type="text/html"/>
    <title>Approximating Subset Sum is equivalent to Min-Plus-Convolution</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bringmann:Karl.html">Karl Bringmann</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12529">PDF</a><br/><b>Abstract: </b>Approximating Subset Sum is a classic and fundamental problem in computer
science and mathematical optimization. The state-of-the-art approximation
scheme for Subset Sum computes a $(1-\varepsilon)$-approximation in time
$\tilde{O}(\min\{n/\varepsilon, n+1/\varepsilon^2\})$ [Gens, Levner'78,
Kellerer et al.'97]. In particular, a $(1-1/n)$-approximation can be computed
in time $O(n^2)$.
</p>
<p>We establish a connection to the Min-Plus-Convolution problem, which is of
particular interest in fine-grained complexity theory and can be solved naively
in time $O(n^2)$. Our main result is that computing a $(1-1/n)$-approximation
for Subset Sum is subquadratically equivalent to Min-Plus-Convolution. Thus,
assuming the Min-Plus-Convolution conjecture from fine-grained complexity
theory, there are no approximation schemes for Subset Sum with strongly
subquadratic dependence on $n$ and $1/\varepsilon$. In the other direction, our
reduction allows us to transfer known lower order improvements from
Min-Plus-Convolution to Subset Sum, which yields a mildly subquadratic
approximation scheme. This adds the first approximation problem to the list of
Min-Plus-Convolution-equivalent problems.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12447</id>
    <link href="http://arxiv.org/abs/1912.12447" rel="alternate" type="text/html"/>
    <title>Minmax Regret for sink location on paths with general capacities</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Mordecai Golin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sandeep:Sai.html">Sai Sandeep</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12447">PDF</a><br/><b>Abstract: </b>In dynamic flow networks, every vertex starts with items (flow) that need to
be shipped to designated sinks.
</p>
<p>All edges have two associated quantities: length, the amount of time required
for a particle to traverse the edge, and capacity, the number of units of flow
that can enter the edge in unit time. The goal is move all flow to the sinks. A
variation of the problem, modelling evacuation protocols, is to find the sink
location(s) that minimize evacuation time, restricting the flow to be
CONFLUENT. Solving this problem is is NP-hard on general graphs, and thus
research into optimal algorithms has traditionally been restricted to special
graphs such as paths, and trees.
</p>
<p>A specialized version of robust optimization is minmax REGRET, in which the
input flows at the vertices are only partially defined by constraints. The goal
is to find a sink location that has the minimum{ regret} over all input flows
that satisfy the partially defined constraints. Regret for a fully defined
input flow and a sink is defined to be the difference between the evacuation
time to that sink and the optimal evacuation time.
</p>
<p>A large recent literature derives polynomial time algorithms for the minmax
regret $k$-sink location problem on paths and trees under the simplifying
condition that all edges have the same (uniform) capacity.
</p>
<p>This paper develops a $O(n^4 \log n)$ time algorithm for the minmax regret
$1$-sink problem on paths with general (non-uniform) capacities. To the best of
our knowledge, this is the first minmax regret result for dynamic flow problems
in any type of graph with general capacities.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12430</id>
    <link href="http://arxiv.org/abs/1912.12430" rel="alternate" type="text/html"/>
    <title>Approximate #Knapsack Computations to Count Semi-Fair Allocations</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Theofilos Triommatis, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pagourtzis:Aris.html">Aris Pagourtzis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12430">PDF</a><br/><b>Abstract: </b>In this paper, we study the problem of counting the number of different
knapsack solutions with a prescribed cardinality. We present an FPTAS for this
problem, based on dynamic programming. We also introduce two different types of
semi-fair allocations of indivisible goods between two players. By semi-fair
allocations, we mean allocations that ensure that at least one of the two
players will be free of envy. We study the problem of counting such allocations
and we provide FPTASs for both types, by employing our FPTAS for the prescribed
cardinality knapsack problem.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12409</id>
    <link href="http://arxiv.org/abs/1912.12409" rel="alternate" type="text/html"/>
    <title>Online Rainbow Coloring In Graphs</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Debasis Dwibedy, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mohanty:Rakesh.html">Rakesh Mohanty</a>, Arun Khamari <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12409">PDF</a><br/><b>Abstract: </b>Rainbow coloring is a special case of edge coloring, where there must be at
least one path between every distinct pair of vertices that consists of
different color edges. Here, we may use the same color for the adjacent edges
of a graph representing two different paths from a single vertex. In online
rainbow coloring, we have no priori knowledge about the vertices and edges of
the graph, in fact the edges are available one by one. We have to color an edge
as soon as it arrives and before the arrival of the next edge. We can not
revoke the coloring decision once it is made. According to our knowledge, there
is no study of online rainbow coloring for graphs. In this paper, we make a
first attempt to propose an online algorithm named Least Recently Used
Color(LRUC) for online rainbow coloring. We analyze the performance of LRUC
through competitive analysis. We show that LRUC is optimal for line graph, tree
and star graph. For 1-cyclic graph, LRUC is shown to be (2-2/n)-competitive,
where n&gt;3. We obtain the competitive ratios of (n-1)/3 and n-1 for wheel and
complete graphs respectively, where n is the number of vertices.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1912.12366</id>
    <link href="http://arxiv.org/abs/1912.12366" rel="alternate" type="text/html"/>
    <title>Approximate Graph Spectral Decomposition with the Variational Quantum Eigensolver</title>
    <feedworld_mtime>1577836800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Payne:Josh.html">Josh Payne</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Srouji:Mario.html">Mario Srouji</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1912.12366">PDF</a><br/><b>Abstract: </b>Spectral graph theory is a branch of mathematics that studies the
relationships between the eigenvectors and eigenvalues of Laplacian and
adjacency matrices and their associated graphs. The Variational Quantum
Eigensolver (VQE) algorithm was proposed as a hybrid quantum/classical
algorithm that is used to quickly determine the ground state of a Hamiltonian,
and more generally, the lowest eigenvalue of a matrix $M\in \mathbb{R}^{n\times
n}$. There are many interesting problems associated with the spectral
decompositions of associated matrices, such as partitioning, embedding, and the
determination of other properties. In this paper, we will expand upon the VQE
algorithm to analyze the spectra of directed and undirected graphs. We evaluate
runtime and accuracy comparisons (empirically and theoretically) between
different choices of ansatz parameters, graph sizes, graph densities, and
matrix types, and demonstrate the effectiveness of our approach on Rigetti's
QCS platform on graphs of up to 64 vertices, finding eigenvalues of adjacency
and Laplacian matrices. We finally make direct comparisons to classical
performance with the Quantum Virtual Machine (QVM) in the appendix, observing a
superpolynomial runtime improvement of our algorithm when run using a quantum
computer.
</p></div>
    </summary>
    <updated>2020-01-01T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-01-01T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16509</id>
    <link href="https://rjlipton.wordpress.com/2019/12/31/resolutions-for-2020/" rel="alternate" type="text/html"/>
    <title>Resolutions For 2020</title>
    <summary>Some fun about resolutions. source Ben Orlin is a funny mathematician. His book title Change Is the Only Constant was selected by the blog Math-Frolic as the best mathematics book of 2019. Today Ken and I want to try to get you to at least smile, if not laugh. Orlin is a funny chap—okay I […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Some fun about resolutions.</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/12/benorlin.jpg"><img alt="" class="alignright wp-image-16511" height="192" src="https://rjlipton.files.wordpress.com/2019/12/benorlin.jpg?w=122&amp;h=192" width="122"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><a href="https://mathwithbaddrawings.com/about-2/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Ben Orlin is a funny mathematician. His <a href="https://www.amazon.com/Change-Only-Constant-Wisdom-Calculus/dp/0316509086/ref=as_li_ss_tl?ie=UTF8&amp;linkCode=sl1&amp;tag=math0b2-20&amp;linkId=4b0342416ae54d5080032b8cc09bfc93&amp;language=en_US">book</a> title <i>Change Is the Only Constant</i> was <a href="https://math-frolic.blogspot.com/2019/12/books-closing-out-2019-with-some-faves.html">selected</a> by the blog <em>Math-Frolic</em> as the best mathematics book of 2019.</p>
<p>
Today Ken and I want to try to get you to at least smile, if not laugh.</p>
<p>
Orlin is a funny chap—okay I just got back from London—so forgive me for using “chap”. Check Orlin’s site out for <a href="https://mathwithbaddrawings.com/2015/12/30/a-mathematicians-new-years-resolutions/">proof</a> that he is funny. Here are some of his <a href="https://mathwithbaddrawings.com/2017/09/13/literatures-greatest-opening-lines-as-written-by-mathematicians/">examples</a> of math types rewriting famous opening lines from books. We will make this into a kind of quiz. You must guess the book title from the modified quote:</p>
<ol>
<li>
The times had high variance. <p/>
</li><li>
Up to isomorphism there is one happy family. <p/>
</li><li>
It was a bright cold day, and the clocks were not mod 12. <p/>
</li><li>
All this happened, but not with equality. <p/>
</li><li>
<img alt="{2^2 \cdot 31}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E2+%5Ccdot+31%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^2 \cdot 31}"/> was spiteful, full of a baby’s venom. <p/>
</li><li>
It was zero at the leading ordinal of viewing.
</li></ol>
<p>
The third is the first hard one—I did not get it. The last one (of three from Ken not Ben) is probably unfair. All six of them, however, are on the “<a href="https://www.amazon.com/First-Lines-Literature-Coffee-Slaughterhouse/dp/B01D6TGVHW">First Lines Literature Coffee Mug</a>” which Ken received a year ago as a Christmas present from his sister. I did not know this when I chose the first three.</p>
<p>
</p><p/><h2> Orlin’s Resolutions </h2><p/>
<p/><p>
Many of us make resolutions for the new year. Here are some examples from Orlin:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Be better at explaining what I do to family and friends. I, Dick, have trouble with this one.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Not to prove by contradiction what can be proved directly. Assume that <img alt="{1+1 \neq 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2B1+%5Cneq+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1+1 \neq 2}"/> and <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/></p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Stop using the word “obviously.” Here at GLL we try to avoid this, at least when it is not obvious. We <a href="https://rjlipton.wordpress.com/2019/02/28/phrases-that-drive-me-crazy/">posted</a> about phrases to avoid a year ago.</p>
<p>
</p><p/><h2> Our Resolutions </h2><p/>
<p/><p>
Here are some of ours:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Stop doubting quantum computer claims. Unless, adds Ken, you have a possible concrete way of challenging them…</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Start trying to apply AI methods to complexity theory. Could there be a new learning approach to 3-SAT? Note that PAC learning kind-of came from there. See for instance the end of <a href="https://elmos.scripts.mit.edu/mathofdeeplearning/2017/05/08/mathematics-of-deep-learning-lecture-4/">this</a>.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Stop trying to understand proofs that Peano arithmetic is inconsistent. I still do not understand what logic they use to prove that Peano is inconsistent. What if that logic is inconsistent? </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Start up some fundamental research ideas and attempts on hard problems again.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> And try to make GLL better, including making it appeal to a wider community. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
The answers are:</p>
<ol>
<li>
<em>A Tale of Two Cities</em> by Charles Dickens: “It was the best of times, it was the worst of times.” <p/>
</li><li>
<em>Anna Karenina</em> by Leo Tolstoy: “Happy families are alike; every unhappy family is unlike in its own way.” <p/>
</li><li>
<em>1984</em> by George Orwell: “It was a bright cold day, and the clocks were striking thirteen.” <p/>
</li><li>
<em>Slaughterhouse-Five</em> by Kurt Vonnegut: “All this happened, more or less.” <p/>
</li><li>
<em>Beloved</em> by Toni Morrison, who died this year: “124 was spiteful, full of a baby’s venom.” This <a href="https://www.shmoop.com/quotes/124-was-spiteful.html">explanation</a> of the line continues: “We know all about numbers being spiteful. We took high school algebra. We’ve experienced the pain. But in this instance, the quote isn’t actually referring to a number. There’s not some mysterious mathematical entity that’s come to wreak havoc on the characters in our story. Here, ‘124’ refers to…” <p/>
</li><li>
<em>Lolita</em> by Vladimir Nabokov: “It was love at first sight…” But wait—this is not the first line of the novel. The first line is maybe not suitable for a coffee mug or family-friendly blog. Instead it is the first line of chapter 29 of part II. We did say it was unfair. <b>Update: Oops</b>—as noted <a href="https://rjlipton.wordpress.com/2019/12/31/resolutions-for-2020/#comment-107459">here</a>, it is the first line of <em>Catch-22</em> by Joseph Heller.  Maybe Ken’s Google engine shares his tendency toward chess-playing authors…
</li></ol>
<p>
Have a happy new year, and make some fun resolutions. Please let us know some of them, or ideas for ours.</p>
<p/><p><br/>
[added Update fixing last first-line answer.]</p></font></font></div>
    </content>
    <updated>2019-12-31T22:02:18Z</updated>
    <published>2019-12-31T22:02:18Z</published>
    <category term="All Posts"/>
    <category term="People"/>
    <category term="Ben Orlin"/>
    <category term="humor"/>
    <category term="literature"/>
    <category term="New Year's"/>
    <category term="quiz"/>
    <category term="resolutions"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-01-02T12:20:53Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/12/31/year-end-linkage</id>
    <link href="https://11011110.github.io/blog/2019/12/31/year-end-linkage.html" rel="alternate" type="text/html"/>
    <title>Year-end linkage</title>
    <summary>Reign in graphs (). Interesting collection of 3d models of graphs</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.shapeways.com/shops/jankrhaugland">Reign in graphs</a> (<a href="https://mathstodon.xyz/@11011110/103321651787290257"/>). Interesting collection of 3d models of graphs</p>
  </li>
  <li>
    <p><a href="https://euro-math-soc.eu/news/19/12/17/zbmath-become-open-access">Zentralblatt going open access</a> (<a href="https://mathstodon.xyz/@11011110/103324328632714865"/>). I mostly use a mix of Google Scholar (for searching), MathSciNet (for more targeted searches, reviews, and high-quality bibtex), and DBLP (for bibtex of CS papers not in MathSciNet) but maybe this will convince me to add ZB into the mix.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@christianp/103328394093228909">Christian Lawson-Perfect can’t explain why the Wikipedia article for “Author” was illustrated by a Ukrainian copyright certificate for a supposed proof of Fermat’s last theorem</a>. It seems to have been added in good faith there, but maybe as self-promotion to the “Copyright” article. Whatever, it’s now on “<a href="https://en.wikipedia.org/wiki/Pseudomathematics">Pseudomathematics</a>” where it belongs.</p>
  </li>
  <li>
    <p><a href="https://lemire.me/blog/2019/12/19/xor-filters-faster-and-smaller-than-bloom-filters/">Xor filters</a> (<a href="https://mathstodon.xyz/@11011110/103338548071725282"/>, <a href="https://arxiv.org/abs/1912.08258">preprint</a>, <a href="https://news.ycombinator.com/item?id=21840821">via</a>): A new alternative to Bloom filters and cuckoo filters for approximate set membership with a controlled rate of false positives and no false negatives. It’s fast and (for realistic error rates) uses fewer bits than Bloom or cuckoo. Cuckoo still wins if you need your sets dynamic, though: you can insert or delete elements easily, while Bloom can only insert and xor can’t handle any change.</p>
  </li>
  <li>
    <p><a href="https://www.jamisbuck.org/mazes/">Visualizations of several maze-generation algorithms</a> (<a href="https://mathstodon.xyz/@11011110/103349055666314448"/>, <a href="https://news.ycombinator.com/item?id=21828903">via</a>). They all appear to generate random tree-like mazes in a square grid, but with different probability distributions on the trees. E.g. Kruskal and Prim generate minimum spanning trees for random weights, different from the uniformly random trees of Aldous–Broder and Wilson, and many others appear quite different from both.
The alternative algorithm at the main link of the via link is probably not the best choice.</p>
  </li>
  <li>
    <p><a href="https://twitter.com/johncarlosbaez/status/1208768265830354945">It’s easy for mathematical physics crackpottery to get published in a prestigious-sounding pay-to-publish journal from an actually-prestigious publisher, <em>Nature Scientific Reports</em></a> (<a href="https://mathstodon.xyz/@11011110/103355963066100289"/>).
In the ensuing discussion, Flavio Nogueira reports that <a href="https://twitter.com/F_S_Nogueira/status/1208787145911152640">editors rejected papers only to see them published anyway</a>. Should we start treating <em>Nature</em> as a predatory publisher?</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Convex_hull_of_a_simple_polygon">Convex hull of a simple polygon</a> (<a href="https://mathstodon.xyz/@11011110/103360225573578914"/>). I’ve been working on cleaning up Wikipedia’s main convex hull article (not yet finished) and added this one to fill in some details. The problem has an interesting history: it’s been known to be solvable in linear time since 1979, and many different algorithms for the same problem have been published before and since, but most of them are wrong.</p>
  </li>
  <li>
    <p><a href="https://mathoverflow.net/q/349228/440">Open convex hull of a closed set</a> (<a href="https://mathstodon.xyz/@11011110/103365014241600450"/>). I can prove that (in Euclidean spaces) such sets are always Cartesian products of a line with a lower-dimensional set. But is there a reference in the literature for this, so I can add it to the Wikipedia article? If you know, please leave an answer on the MathOverflow link.</p>
  </li>
  <li>
    <p><a href="https://youtu.be/fhBPhie1Tm0">David Bachman, Saul Schleimer and Henry Segerman finally explain what their cohomology fractals are</a> (<a href="https://mathstodon.xyz/@henryseg/103341309414601843"/>).</p>
  </li>
  <li>
    <p><a href="https://www.theguardian.com/world/2019/dec/26/turkish-court-wikipedia-block-lifted">Turkish supreme court rules that the country’s two-year block on Wikipedia is unconstitutional</a> (<a href="https://mathstodon.xyz/@11011110/103378814260578782"/>, <a href="https://news.ycombinator.com/item?id=21888759">also</a>, <a href="https://www.washingtonpost.com/world/europe/court-rules-turkey-violated-freedoms-by-banning-wikipedia/2019/12/26/880f263c-27de-11ea-9cc9-e19cfbc87e51_story.html">also</a>, <a href="https://www.nytimes.com/2019/12/26/world/europe/wikipedia-ban-turkey.html">also</a>).</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/mathematician-makes-euler-equations-blow-up-20191218/">Famous fluid equations spring a leak</a> (<a href="https://mathstodon.xyz/@11011110/103384319532164607"/>). We still don’t know whether the differential equations governing fluid flow lead to consistent and unique solutions for all time. But if you simplify the equations to throw away viscosity and compressability, and you allow the initial state of the fluid to have discontinuous boundaries between volumes of fluid with very different motion, you can cause it to reach a point at which it spins infinitely quickly.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Relative_convex_hull">Relative convex hull</a> (<a href="https://mathstodon.xyz/@11011110/103390220528024772"/>). Another new article related to my revision of the Wikipedia convex hull article. These are the shapes you get by stretching a rubber band around one set while fencing it inside a polygon. You don’t always get a simple polygon as a result, but it’s “weakly simple”.</p>
  </li>
  <li>
    <p><a href="https://www.nytimes.com/2019/12/28/climate/trump-administration-war-on-science.html">Science under attack: How Trump is sidelining researchers and their work</a> (<a href="https://mathstodon.xyz/@11011110/103393997740330853"/>). The fact that this link was <a href="https://news.ycombinator.com/item?id=21905957">flagged and censored from ycombinator hacker news</a> is also interesting, in its own way. Fortunately my RSS aggregator copied the link before it was taken down.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2019-12-27/Special_report">Are reputation management operatives scrubbing Wikipedia articles</a> (<a href="https://mathstodon.xyz/@11011110/103399857216270322"/>). Answer: duh. The linked report has details of one such case, involving Theranos.</p>
  </li>
  <li>
    <p><a href="https://johncarlosbaez.wordpress.com/2019/12/30/compositionality-first-issue/">New open-access journal <em>Compositionality</em></a> (<a href="https://mathstodon.xyz/@11011110/103406379623694356"/>), on the mathematics of “how complex things can be assembled out of simpler parts”. It’s not a good fit for my own research, and the word “fuzzy” in the title of one of the initial papers is kind of a red flag for me, but I think it’s a good thing that the move towards diamond-model open access is continuing.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-12-31T21:23:00Z</updated>
    <published>2019-12-31T21:23:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-01-01T05:48:15Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5060142193352763387</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5060142193352763387/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/12/complexity-year-in-review-2019.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5060142193352763387" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5060142193352763387" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/12/complexity-year-in-review-2019.html" rel="alternate" type="text/html"/>
    <title>Complexity Year in Review 2019</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Some great theorems this year including <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">non-deterministic double exponential time by quantumly entangled provers</a> and <a href="https://rjlipton.wordpress.com/2019/03/29/integer-multiplication-in-nlogn-time/">integer multiplication in O(n log n) time</a>. But the result of the year has to go to a paper that gave a <a href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html">shockingly simple proof of a major longstanding conjecture</a>.<br/>
<br/>
<div style="text-align: center;">
<a href="https://arxiv.org/abs/1907.00847">Induced subgraphs of hypercubes and a proof of the Sensitivity Conjecture</a> by Hao Huang</div>
<div>
<br/></div>
<div>
Of course 2019 will be remembered in some circles for giving us Google's claims of quantum supremacy and all the quantum hype, deserved and otherwise, that goes with it.<br/>
<br/>
Personally Bill came out with his new book <a href="https://www.worldscientific.com/worldscibooks/10.1142/11261#t=toc">Problems with a Point; Exploring Math and Computer Science</a> co-authored with Clyde Kruskal (<a href="https://amzn.to/2s6IlPl">Amazon</a>, <a href="https://blog.computationalcomplexity.org/2019/02/problems-with-point-exploring-math-and.html">blog</a> <a href="https://blog.computationalcomplexity.org/2019/04/problems-with-point-not-plug-just-some.html">posts</a>). Lance <a href="https://www.iit.edu/news/lance-fortnow-designated-new-college-science-dean">became a dean</a>. </div>
<div>
<br/></div>
<div>
We remember <a href="https://www.nytimes.com/2019/01/11/obituaries/michael-atiyah-dead.html">Michael Atiyah</a>, <a href="https://blog.computationalcomplexity.org/2019/04/elwyn-berlekamp-died-april-9-2019.html">Elwyn Berlekamp</a>, <a href="https://blog.computationalcomplexity.org/2019/04/quiz-show-scandalsadmissions.html">Charles van Doren</a>, <a href="https://blog.computationalcomplexity.org/2019/06/ray-miller-one-of-our-founders-passes.html">Ray Miller</a>, <a href="https://www.lamsade.dauphine.fr/fr/actualites/detail-de-lactualite/article/deces-de-jerome-monnot-membre-du-laboratoire-lamsade.html">Jérôme Monnot</a> and <a href="https://news.stanford.edu/2019/04/24/nils-nilsson-pioneer-robotics-artificial-intelligence-dies-86/">Nils Nilsson</a>.</div>
<div>
<br/></div>
<div>
Thanks to guest posters <a href="https://blog.computationalcomplexity.org/2019/10/quantum-supremacy-guest-post-by-abhinav.html">Abhinav Deshpande</a>, <a href="https://blog.computationalcomplexity.org/2019/01/the-paradigm-shift-in-fintech.html">Evangelos Georgiadis</a>, <a href="https://blog.computationalcomplexity.org/2019/07/guest-post-by-samir-khuller-on.html">Samir Khuller</a>, <a href="https://blog.computationalcomplexity.org/2019/06/ray-miller-one-of-our-founders-passes.html">Ming Lin</a>, <a href="https://blog.computationalcomplexity.org/2019/07/answer-to-both-infinite-hats-problems.html">David</a> <a href="https://blog.computationalcomplexity.org/2019/07/fortran-is-underated.html">Marcus</a>, <a href="https://blog.computationalcomplexity.org/2019/06/ray-miller-one-of-our-founders-passes.html">Ben Shneiderman</a> and <a href="https://blog.computationalcomplexity.org/2019/04/cuckoo-cycles.html">John Tromp</a>.</div>
<div>
<br/></div>
<div>
As we move into the 2020s, we tend to look back and look forward. The 2010s will go down as the decade computing and data transformed society, for better and worse. Google turned 21 this year as its OG leadership stepped down. I turned 21 in 1984, but 1984 seems closer than ever.</div>
<div>
<br/></div>
<div>
Last year we ended the <a href="https://blog.computationalcomplexity.org/2018/12/complexity-year-in-review-2018.html">year in review</a> by </div>
<blockquote class="tr_bq">
We end the year with craziness, the stock market is going through wild gyrations, we have a partial government shutdown including all of NSF and an uncertain political landscape with different parties leading the two houses of congress. We're still in the midst of a technological revolution and governments around the world try to figure how to regulate it. I find it hard to predict 2019 but it will not be quiet.</blockquote>
2019 was not quiet and we're about to head into an impeachment trial, Brexit and a critical US presidential election. The real challenges of the twenties will come from massive transformation from automation, climate change and deepening divisions in our society. How will academia cope with changing demographics, financial challenges and educating to manage the technological revolution?<br/>
<br/>
Let's all take a deep breath, roll up our sleeves and get the decade going.</div>
    </content>
    <updated>2019-12-31T18:02:00Z</updated>
    <published>2019-12-31T18:02:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-01-02T10:17:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/186</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/186" rel="alternate" type="text/html"/>
    <title>TR19-186 |  Lifting with Simple Gadgets and Applications to Circuit and Proof Complexity | 

	Or Meir, 

	Susanna de Rezende, 

	Jakob Nordström, 

	Robert Robere, 

	Toniann Pitassi</title>
    <summary>We significantly strengthen and generalize the theorem lifting Nullstellensatz degree to monotone span program size by Pitassi and  Robere (2018) so that it works for any gadget with high enough rank, in particular, for useful gadgets such as  equality and greater-than. We apply our generalized theorem to solve two open problems:

* We present the first result that demonstrates a separation in proof power for cutting planes with unbounded versus polynomially bounded    coefficients.
Specifically, we exhibit CNF formulas that can be refuted in quadratic length and constant line space in cutting planes with unbounded coefficients, but for which there are no refutations in subexponential length and subpolynomial line space if coefficients are restricted to be of polynomial magnitude.

* We give the first explicit separation between monotone Boolean formulas and monotone real formulas. Specifically, we give an explicit family of functions that can be computed with monotone real formulas of nearly linear size but require monotone Boolean formulas of exponential size. Previously only a non-explicit separation was known.  
  
An important technical ingredient, which may be of independent interest, is that we show that the Nullstellensatz degree of refuting the pebbling formula over a DAG $G$ over any field coincides exactly with the reversible pebbling price of $G$. 
In particular, this implies that the standard decision tree complexity and the parity  decision tree complexity of the corresponding falsified clause search problem are equal.</summary>
    <updated>2019-12-31T16:41:23Z</updated>
    <published>2019-12-31T16:41:23Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-01-02T11:20:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7610</id>
    <link href="https://windowsontheory.org/2019/12/30/a-bet-for-the-new-decade/" rel="alternate" type="text/html"/>
    <title>A bet for the new decade</title>
    <summary>I am in Tel Aviv Theory Fest this week – a fantastic collection of talks and workshops organized by Yuval Filmus , Gil Kalai, Ronen Eldan, and Muli Safra. It was a good chance to catch up with many friends and colleagues. In particular I met Elchanan Mossel and Subhash Khot, who asked me to […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I am in <a href="https://sites.google.com/view/tau-theory-fest/home">Tel Aviv Theory Fest</a> this week – a fantastic collection of talks and workshops organized by Yuval Filmus , Gil Kalai, Ronen Eldan, and Muli Safra.</p>



<p>It was a good chance to catch up with many friends and colleagues. In particular I met Elchanan Mossel and Subhash Khot, who asked me to serve as a “witness” for their bet on the unique games conjecture. I am recording it here so we can remember it a decade from noe.</p>



<p>Specifically, Elchanan bets that the Unique Games conjecture will be proven in the next decade – sometime between January 1, 2020 and December 31, 2029 there will be a paper uploaded to the arxiv with a correct proof of the conjecture. Subhash bets that this won’t happen. They were not sure what to bet on, but eventually agreed to take my offer that the loser will have to collaborate on a problem chosen by the winner, so I think science will win in either case. (For what it’s worth, I think there is a good chance that Subhash will lose the bet because he himself will prove the UGC in this decade, though it’s always possible Subhash can both win the bet and prove the UGC if he manages to do it by tomorrow <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/> )</p>



<p/>



<figure class="wp-block-image size-large"><img alt="" class="wp-image-7612" src="https://windowsontheory.files.wordpress.com/2019/12/img-1240.jpg?w=1024"/></figure>



<p>The conference itself is, as I mentioned, wonderful with an amazing collection of speakers.  Let me mention just a couple of talks from this morning. Shafi Goldwasser talked about “Law and Algorithms”. There is a recent area of research studying how to regulate algorithms, but Shafi’s talk focused mostly on the other direction: how algorithms and cryptography can help achieve legal objectives such as the “right to be forgotten” or the ability to monitor secret proceedings such as wiretap requests. </p>



<p>Christos Papadimitriou  talked about “Language, Brain, and Computation”.  Christos is obviously excited about understanding the language mechanisms in the brain. He said that studying the brain gives him the same feeling that you get when you sit in a coffee shop in Cambridge and hear intellectual discussions all around you: you don’t understand why everyone is not dropping everything they are doing and come here. (Well, his actual words were “sunsets over the Berkeley hills” but I think the Cambridge coffee shops are a better metaphor <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/> )</p>



<p/></div>
    </content>
    <updated>2019-12-30T21:50:04Z</updated>
    <published>2019-12-30T21:50:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-01-02T12:21:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/12/30/assistant-professor-at-computer-science-dept-higher-school-of-economics-moscow-apply-by-january-12-2020/</id>
    <link href="https://cstheory-jobs.org/2019/12/30/assistant-professor-at-computer-science-dept-higher-school-of-economics-moscow-apply-by-january-12-2020/" rel="alternate" type="text/html"/>
    <title>Assistant Professor at Computer Science Dept, Higher School of Economics, Moscow (apply by January 12, 2020)</title>
    <summary>National Research University Higher School of Economics (HSE University, Moscow, Russia), tenure track positions starting in 2020/2021 academic year. Knowledge of Russian is not required. The applicant should provide a CV, a statement and a recent research paper via online application form. At least two letters of recommendation should be sent directly to iri@hse.ru before […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>National Research University Higher School of Economics (HSE University, Moscow, Russia), tenure track positions starting in 2020/2021 academic year. Knowledge of Russian is not required. The applicant should provide a CV, a statement and a recent research paper via online application form. At least two letters of recommendation should be sent directly to iri@hse.ru before January 12, 2020.</p>
<p>Website: <a href="https://iri.hse.ru/announcements/304656320.html">https://iri.hse.ru/announcements/304656320.html</a><br/>
Email: sasha.shen@gmail.com</p></div>
    </content>
    <updated>2019-12-30T14:41:27Z</updated>
    <published>2019-12-30T14:41:27Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-01-02T12:20:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blogs.princeton.edu/imabandit/?p=1416</id>
    <link href="https://blogs.princeton.edu/imabandit/2019/12/30/a-decade-of-fun-and-learning/" rel="alternate" type="text/html"/>
    <title>A decade of fun and learning</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I started out this decade with the project of writing a survey of the multi-armed bandit literature, which I had read thoroughly during the graduate studies that I was about to finish. At the time we resisted the temptation to … <a href="https://blogs.princeton.edu/imabandit/2019/12/30/a-decade-of-fun-and-learning/">Continue reading <span class="meta-nav">→</span></a></p></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I started out this decade with the project of writing a survey of the multi-armed bandit literature, which I had read thoroughly during the graduate studies that I was about to finish. At the time we resisted the temptation to name the survey “modern banditology”, which was indeed the right call given how much this “modern” picture has evolved over the decade! It is truly wonderful to now end the decade with two new iterations on the work we did in that survey: </p>
<ol>
<li><a class="lipdf" href="https://tor-lattimore.com/downloads/book/book.pdf">Bandit algorithms</a> by Tor Lattimore and Csaba Szepesvari</li>
<li><a class="liinternal" href="https://arxiv.org/abs/1904.07272">Introduction to bandits</a> by Alex Slivkins</li>
</ol>
<p>These new references very significantly expand the 2012 survey, and they are wonderful starting points for anyone who wants to enter the field.</p>
<p>Here are some of the discoveries in the world of bandits that stood out for me this decade:</p>
<ol>
<li>We now understand very precisely Thompson Sampling, the first bandit strategy that was proposed back in 1933. The most beautiful reference here is the one by Dan Russo and Ben Van Roy: <a class="lipdf" href="http://www.jmlr.org/papers/volume17/14-087/14-087.pdf">An Information-Theoretic Analysis of Thompson Sampling</a>, JMLR 2016. Another one that stands out is <a class="lipdf" href="http://www.jmlr.org/proceedings/papers/v23/agrawal12/agrawal12.pdf">Analysis of thompson sampling for the multi-armed bandit problem</a> by S. Agrawal and N. Goyal at COLT 2012.</li>
<li>T^{2/3} lower bound for  *non-stochastic* bandit with switching cost by Dekel, Ding, Koren and Peres at <u><font color="#000121"><a class="liinternal" href="https://arxiv.org/abs/1310.2997">STOC 201</a></font></u><a class="liinternal" href="https://arxiv.org/abs/1310.2997">4</a>. This is a striking result for several reasons. In particular the proof has to be based on a non-trivial stochastic process, since for the classical stochastic i.i.d. model one can obtain \sqrt{T} (very easily in fact). </li>
<li>We now know that bandit convex optimization is “easy”, in the sense that it is a \sqrt{T}-regret type problem. What’s more is that in our <a class="liinternal" href="https://arxiv.org/abs/1607.03084">STOC 2017 paper</a> with Y.T. Lee and R. Eldan we introduced a new way to do function estimation based on bandit feedback, using kernels (I have written at length about this on <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2016/08/06/kernel-based-methods-for-bandit-convex-optimization-part-1/">this blog</a>).</li>
<li>A very intriguing model of computation for contextual bandit was proposed, where one can access the policy space only through an offline optimization oracle. With such access, the classical Exp4 algorithm cannot be simulated, and thus one needs new strategies. We now have a reasonable understanding that \sqrt{T} is doable with mild assumptions (see e.g. this ICML 2014 paper on “<u><font color="#000117"><a class="liexternal" href="http://arxiv.org/abs/1402.0555">Taming the Monster</a></font>“</u> by Hsu, Kale, Langford, L. Li and Schapire) and that it is impossible with no assumptions (work of Hazan and Koren at <a class="liinternal" href="https://arxiv.org/abs/1504.02089">STOC 2016</a>).</li>
<li>Honorable mentions also go to the work of Wei and Luo showing that very strong variation bounds are possible in bandits (see this <a class="liinternal" href="https://arxiv.org/abs/1801.03265">COLT 2018 paper</a>), and Zimmert and Seldin who made striking progress on the best of both worlds phenomenon that we discovered with Slivkins at the beginning of the decade (I blogged about it <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/06/10/amazing-progress-in-adversarially-robust-stochastic-multi-armed-bandits/">here</a> already).</li>
</ol>
<h2>Life beyond bandits</h2>
<p>In addition to starting the decade with the bandit survey, I also started it with being bored with the bandit topic altogether. I thought that many (if not most) of the fundamental results were now known, and it was a good idea to move on to something else. Obviously I was totally wrong, as you can see with all the works cited above (and many many more for stochastic bandits, including much deeper understanding of best arm identification, a topic very close to my heart, see e.g., <a class="lipdf" href="http://www.jmlr.org/papers/volume17/kaufman16a/kaufman16a.pdf">[Kaufmann, Cappe, Garivier, JMLR 16]</a>). In fact I am now optimistic that there is probably another decade-worth of exploration left for the bandit problem(s). Nevertheless I ventured outside, and explored the world of optimization (out of which first came <a class="lipdf" href="http://sbubeck.com/Bubeck15.pdf">a survey</a>, and more recently <a class="liinternal" href="https://www.youtube.com/playlist?list=PLAPSKVSdi0oZPbS-UD_kwT4ePZQx_CiME">video lectures</a>) and briefly networks (another <a class="liinternal" href="https://arxiv.org/abs/1609.03511">modest survey</a> came out of this too). </p>
<p>Here are some of the landmark optimization results of this decade in my view:</p>
<ol>
<li>Perhaps the most striking result of the decade in optimization is the observation that for finite sum problems, one can reduce the variance in stochastic gradient descent by somehow centering the estimates (e.g., using a slowly moving sequence on which we can afford to compute full gradients; but this is not the only way to perform such variance reduction). This idea, while very simple, has a lot of implications, both in practice and in theory! The origin of the idea are in the SAG algorithm of <a class="liexternal" href="http://papers.nips.cc/paper/4633-a-stochastic-gradient-method-with-an-exponential-convergence-_ra">[Schmidt, Le Roux, Bach, NIPS 2012]</a> and SDCA <a class="lipdf" href="http://www.jmlr.org/papers/volume14/shalev-shwartz13a/shalev-shwartz13a.pdf">[Shalev-Shwartz and Zhang, JMLR 2013]</a>. A simpler instantiation of the idea, called SVRG appeared shortly after in <a class="lipdf" href="http://papers.nips.cc/paper/4937-accelerating-stochastic-gradient-descent-using-predictive-variance-reduction.pdf">[Johnson and Zhang, NIPS 2013]</a> (and also independently at the same NeurIPS, in <a class="liinternal" href="https://papers.nips.cc/paper/4941-mixed-optimization-for-smooth-functions">[M. Madhavi, L. Zhang, R. Li, NIPS 2013]</a>).</li>
<li>An intriguing direction that I pursued fervently is the use of convex optimization for problems that have a priori nothing to do with convex optimization. A big inspiration for me was the COLT 2008 paper by Abernethy, Hazan and Rakhlin, who showed how mirror descent naturally solves bandit problems. In this decade, we (this we includes myself and co-authors, but also various other teams) explored how to use mirror descent for other online decision making problems, and made progress on some long-standing problems (k-server and MTS), see for example this set of <a class="liinternal" href="https://www.youtube.com/playlist?list=PLAPSKVSdi0obG1b3w4k41JMLFbyBJS5AQ">video lectures</a> on the “Five miracles of mirror descent”.</li>
<li>Arnak Dalalyan showed how to use ideas inspired from convex optimization to <a class="liinternal" href="https://arxiv.org/abs/1412.7392">analyze the Langevin Monte Carlo algorithm</a>. This was absolutely beautiful work, that led to many many follow-ups.</li>
<li>There has been a lot of rewriting of Nesterov’s acceleration, to try to demystify it. Overall the enterprise is not yet a resounding success in my opinion, but certainly a lot of progress has been made (again I have written a lot about it on this blog already). We now even have optimal acceleration for higher order of smoothness (see this 15 authors <u><font color="#000117"/><font><a class="lipdf" href="http://proceedings.mlr.press/v99/gasnikov19b/gasnikov19b.pdf">paper at COLT 2019</a></font></u>), but these techniques are clouded with the same shroud of mystery as was Nesterov’s original method.</li>
<li>Yin Tat Lee and Aaron Sidford obtained an <a class="liinternal" href="https://arxiv.org/abs/1910.08033">efficient construction of a universal barrier</a>.</li>
<li>We now know that certain problems cannot be efficiently represented by SDPs (the so-called “extension complexity), see e.g. this work by <a class="liinternal" href="https://arxiv.org/abs/1411.6317">Lee-Raghavendra-Steurer</a>.</li>
<li>We now know how to chase convex bodies, and we can even do so very elegantly with <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/11/05/convex-body-chasing-steiner-point-sellke-point-and-soda-2020-best-papers/">the Steiner/Sellke point</a>.</li>
</ol>
<h2>Some other things that captivated me</h2>
<p>The papers above are mostly topics on which I tried to work at some point. Here are some questions that I didn’t work on but followed closely and was fascinated by the progress:</p>
<ol>
<li>The stochastic block model was essentially solved during this decade, see for example <a class="lipdf" href="http://www.princeton.edu/~eabbe/publications/abbe_FNT_2.pdf">this survey</a> by Emmanuel Abbe.</li>
<li>The computational/statistical tradeoffs were extensively explored, yet they remain mysterious. A nice impulse to the field was given by this <a class="liinternal" href="https://projecteuclid.org/euclid.aos/1378386239">COLT 2013 paper</a> by Berthet and Rigollet relating sparse PCA and planted clique. In a similar spirit I also enjoyed the more recent work by Moitra, Jerry Li, and many co-authors on computationally efficient robust estimation (see e.g., <a class="liinternal" href="https://arxiv.org/abs/1906.11366">this recent paper</a>)</li>
<li>Adaptive data analysis strikes me as both very important in practice, and quite deep theoretically, see e.g. <a class="lipdf" href="http://nematilab.info/bmijc/assets/091218_paper.pdf">the reusable holdout by Dwork et al</a>. A related paper that I liked a lot is this <a class="liinternal" href="https://arxiv.org/abs/1502.04585">ICML 2015 paper</a> by Blum and Hardt, which essentially explores the regularization effect of publishing only models that beat the state of the art significantly (more generally this is an extremely interesting question, of why we can keep using the same datasets to evaluate progress in machine learning, see this provokingly titled paper “<a class="liinternal" href="https://arxiv.org/abs/1902.10811">Do ImageNet Classifiers Generalize to ImageNet?</a>“).</li>
<li>A general trend has been in finding very fast (nearly linear time) method for many classical problems. Sometimes these investigations even led to actually practical algorithm, as with this now classical paper by Marco Cuturi at NIPS 2013 titled “<a class="liexternal" href="http://papers.nips.cc/paper/4927-sinkhorn-distances-lightspeed-computation-of-optimal-transport">Sinkhorn Distances: Lightspeed Computation of Optimal Transport</a>“.</li>
</ol>
<h2>Oh, one last thing</h2>
<p>I also heard that, surprisingly, gradient descent can work to optimize highly non-convex functions such as training loss for neural networks. Not sure what this is about, it’s a pretty obscure topic, maybe it will catch up in the decade 2020-2029…</p>
<h2>Share some more in the comments!</h2>
<p>The above is only a tiny sample, there were many many more interesting directions being explored (tensor methods for latent variable models <a class="lipdf" href="http://www.jmlr.org/papers/volume15/anandkumar14b/anandkumar14b.pdf">[Anandkumar, Ge, Hsu, Kakade, Telgarsky, JMLR 14]</a>; phenomenon of “all local minima are good” for various non-convex learning problems, see e.g., <a class="liexternal" href="http://papers.nips.cc/paper/6048-matrix-completion-has-no-spurious-local-minimum">[Ge, Lee, Ma, NIPS 2016]</a>; etc etc). Feel free to share your favorite ML theory paper in the comments!</p></div>
    </content>
    <updated>2019-12-30T07:22:52Z</updated>
    <published>2019-12-30T07:22:52Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Sebastien Bubeck</name>
    </author>
    <source>
      <id>https://blogs.princeton.edu/imabandit</id>
      <link href="https://blogs.princeton.edu/imabandit/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blogs.princeton.edu/imabandit" rel="alternate" type="text/html"/>
      <subtitle>Random topics in optimization, probability, and statistics. By Sébastien Bubeck</subtitle>
      <title>I’m a bandit</title>
      <updated>2020-01-02T00:17:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/185</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/185" rel="alternate" type="text/html"/>
    <title>TR19-185 |  Strategy-Stealing is Non-Constructive | 

	Greg Bodwin, 

	Ofer Grossman</title>
    <summary>In many combinatorial games, one can prove that the first player wins under best play using a simple but non-constructive argument called strategy-stealing.
This work is about the complexity behind these proofs: how hard is it to actually find a winning move in a game, when you know by strategy-stealing that one exists? 
We prove that this problem is PSPACE-Complete already for Minimum Poset Games and Symmetric Maker-Maker Games, which are simple classes of games that capture two of the main types of strategy-stealing arguments in the current literature.</summary>
    <updated>2019-12-29T05:25:12Z</updated>
    <published>2019-12-29T05:25:12Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-01-02T11:20:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7604</id>
    <link href="https://windowsontheory.org/2019/12/28/quantum-school-lecture-notes-videos-and-more-guest-post-by-dorit-aharonov/" rel="alternate" type="text/html"/>
    <title>A crash course on the math of quantum computing (guest post by Dorit Aharonov)</title>
    <summary>[The post below is by Dorit Aharonov who co-organized the wonderful school on quantum computing last week which I attended and greatly enjoyed. –Boaz] TL;DR: Last week we had a wonderful one-week intro course into the math of quantum computing at Hebrew U;  It included a one day crash course on the basics, and 7 mini-courses on math-oriented research […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>[The post below is by Dorit Aharonov who co-organized the wonderful school on quantum computing last week which I attended and greatly enjoyed. –Boaz] </em></p>



<p><strong>TL;DR: </strong> Last week we had a wonderful one-week intro course into the math of quantum computing at Hebrew U;  It included a one day crash course on the basics, and 7 mini-courses on math-oriented research topics (quantum delegation, Hamiltonian complexity, algorithms and more) by top-notch speakers. Most importantly – it is all online, and could be very useful if you want to take a week or two to enter the area and don’t know <a href="https://iias.huji.ac.il/SchoolCSE4" rel="noreferrer noopener" target="_blank">where to start</a>.   </p>



<p><br/><br/><br/></p>



<p>Hi Theory people!  </p>



<p>I want to tell you about a 5-days winter school called “<a href="https://iias.huji.ac.il/SchoolCSE4" rel="noreferrer noopener" target="_blank">The Mathematics of Quantum Computation</a>“, which we (me, Zvika Brakerski, Or Sattath and Amnon Ta-Shma) organized last week at the Institute for advanced studies (IIAS) at the Hebrew university in Jerusalem. </p>



<p>There were two reasons I happily agreed to Boaz’s suggestion to write a guest blogpost about this school. <br/><br/>a) The school was really great fun. We enjoyed it so much, that I think you might find it interesting to hear about it even if you were not there, or are not even into quantum computation. <br/><br/>And b), it might actually be useful for you or your quantum-curious friends. We put all material online, with the goal in mind that after the school, this collection of talks+written material will constitute all that is needed for an almost self-contained <strong>very-intensive-one-week-course of introduction into the mathematical side of quantum computation</strong>; I think this might be of real use for any theoretical computer scientist or mathematician interested in entering this fascinating but hard-to-penetrate area, and not knowing where to start.<br/>Before telling you a little more about what we actually learned in this school, let’s start with some names and numbers. We had:  </p>



<ul><li>160 participants (students and faculty) from all over the world. </li><li>7 terrific speakers: Adam Bouland (UC Berkeley), Sergey Bravyi (IBM), Matthias Christandl (Coppenhagen), András Gilyén (Caltech), Sandy Irani (UC Irvine), Avishay Tal (Berkeley), and Thomas Vidick (Caltech); </li><li>2 great TAs:  András Gilyén (Caltech) and Chinmay Nirkhe (UC Berkeley)</li><li>4 busy organizers: myself (Hebrew U), Zvika Brakerski (Weizmann), Or Sattath (Ben Gurion U), and Amnon Ta-Shma (Tel Aviv U)</li><li>1 exciting and very intensive <a href="https://docs.google.com/document/d/1OcFzE1PHxBN4l87sOQB033FZLTgY934GHxnpVKi3NaM/edit" rel="noreferrer noopener" target="_blank">program</a></li><li>5 challenging and fascinating days of <a href="https://www.youtube.com/playlist?list=PLTn74Qx5mPsS2dqTpEq_2zxq8kWBmPUfb" rel="noreferrer noopener" target="_blank"> talks</a>, <a href="https://drive.google.com/drive/u/0/folders/1n6W3Yjq2TYsyRwrocbN2bWK-xpyzkqSM" rel="noreferrer noopener" target="_blank">problem sessions</a> and really <a href="https://shvil.im/" rel="noreferrer noopener" target="_blank">nice food</a>.   </li><li>1 great <a href="https://huji.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=599bc3e9-855e-42c1-ab1d-ab1f0062c481" rel="noreferrer noopener" target="_blank">Rabin’s lecture</a> by Boaz Barak (Harvard)</li><li>1 beautiful <a href="https://www.youtube.com/watch?v=DxrxXneg3lU&amp;list=PLTn74Qx5mPsS2dqTpEq_2zxq8kWBmPUfb&amp;index=21&amp;t=0s" rel="noreferrer noopener" target="_blank">Quantum perspective lecture</a> by Sergey Bravyi (IBM)</li><li>8 panelists in the <a href="https://www.youtube.com/watch?v=H4t2G2gay7Q&amp;feature=youtu.be" rel="noreferrer noopener" target="_blank">supremacy panel</a> we had on the fifth day: Sandy Irani (UC Irvine), our wise moderator, and 7 panelists on stage and online: myself, Scott Aaronson (Austin, online), Boaz Barak, Adam Bouland, Sergio Boixo (Google, online), Gil Kalai (Hebrew U), and Umesh Vazirani (UC Berkeley, online) </li><li>8 brave speakers in the gong show, our very last session, each talking for 3 minutes;    </li><li>1 group-tour to 1 UNESCO site (<a href="https://everything-everywhere.com/caves-of-maresha-and-bet-guvrin-in-the-judean-lowlands-as-a-microcosm-of-the-land-of-the-caves/" rel="noreferrer noopener" target="_blank">Tel Maresha</a>) and <a href="https://www.srigim-beer.co.il/" rel="noreferrer noopener" target="_blank">6 beers tasted</a> by ~80 tour participants</li><li>3 problem sets with 43 <a href="https://drive.google.com/drive/u/0/folders/1n6W3Yjq2TYsyRwrocbN2bWK-xpyzkqSM" rel="noreferrer noopener" target="_blank">problems</a> and (!) their <a href="https://drive.google.com/drive/u/0/folders/1n6W3Yjq2TYsyRwrocbN2bWK-xpyzkqSM" rel="noreferrer noopener" target="_blank">solution</a>s.   </li></ul>



<p>So why did we decide to organize this particular quantum school, given the many quantum schools around? Well, the area of quantum computation is just bursting now with excitement and new mathematical challenges; But there seems to be no easy way for theoreticians to learn about all these things unless you are already in the loop… The (admittedly) very ambitious goal of the school was to assume zero background in quantum computation, and quickly bring people up to speed on six or seven of the most interesting mathematical research forefronts in the area. </p>



<p>The first day of the school was intended to put everyone essentially on the same page: it included four talks about the very basics (qubits by Or Sattath, circuits, by myself, algorithms by Adam Bouland, and error correction by Sergey Bravyi). By the end of this first day everyone was at least supposed to be familiar with the basic concepts, and capable of listening to the mini-courses to follow. The rest of the school was devoted mainly to those mini-courses, whose topics included what I think are some of the most exciting topics on the more theoretical and mathematical side of quantum computation.</p>



<p>Yes, it was extremely challenging… the good thing was that we had two great TAs, András and Chinmay, who helped prepare problem sets, which people actually seriously tried to solve (!) during the daily one+ hour TA problem-solving sessions (with the help of the team strolling around ready to answer questions…). It seems that this indeed helped people follow, despite the fact that we did get into some hard stuff in those mini-courses… The many questions that were asked throughout the school proved that many people were following and interested till the bitter end. </p>



<p>So here is a summary of the mini-courses, by order of appearance. <br/>I added some buzz words of interesting related mathematical notions so that you know where these topics might lead you if you take the paths they suggest.   <br/></p>



<ul><li> Thomas Vidick gave a three-lecture wonderfully clear mini-course providing an intro to the recently very active and exciting area of <strong>quantum verification and delegation</strong>, connecting cryptography and quantum computational complexity. [Thomas didn’t have time to talk about it, but down the road this eventually connects to  approximate representation theory, as well as to Connes embedding conjecture, and more.]</li><li> Sandy Irani gave a beautiful exposition (again, in a a three lecture mini-course) on <strong>quantum Hamiltonian complexity</strong>. Sandy started with Kitaev’s quantum version of the Cook Levin theorem, showing that the local Hamiltonian problem is quantum NP complete; she then explained how this can be extended to more physically relevant questions such as translationally invariant 1D systems, questions about the thermodynamical limit, and more. [This topic is related to open questions such as quantum PCP, which was not mentioned in the school, as well as to beautiful recent results about undecidability of the spectral gap problem, and more.]    </li><li> Matthias Christandl gave an exciting two-lecture mini-course on the fascinating connection between <strong>tensor ranks and matrix product multiplication</strong>. Starting from what seemed to be childish games with small pictures in his first talk, he cleverly used those as his building blocks in his second talk, to enable him to talk about Strassen’s universal spectral points program for approaching the complexity of matrix multiplication, asymptotic ranks, border ranks and more. That included also very beautiful pictures of polytopes! Matthias explained the connection that underlines this entire direction, between entanglement properties of three body systems, with these old combinatorial problems.  </li><li> Avishay Tal gave a really nice two-lecture exposition on his recent breakthrough result with Ran Raz, proving that <strong>quantum polynomial time computation is not contained in the polynomial Hierarchy, in the oracle model</strong>. This included talking about AC0, a problem called forrelation, Fourier expansion, Gaussians and much more.</li><li>  András Gilyén gave a wonderful talk about a recent development: the evolution of the <strong>singular value approach to quantum algorithms</strong>. He left us all in awe showing that essentially almost any quantum algorithm you can think of falls into this beautiful framework… Among other things, he mentioned Chebychev’s polynomials, quantum walks, Hamiltonian simulations, and more. What else can be done with this framework remains to be seen.</li><li>Sergey Bravyi gave two talks (on top of his intro to quantum error correction). The first was as part of a monthly series at Hebrew university, called  “quantum perspectives”; in this talk, Sergey gave a really nice exposition of his breakthrough result (with Gosset and Konig) demonstrating an <strong><em>information theoretical</em> separation between quantum and classical constant depth circuits</strong>; this uses in a clever way the well known quantum magic square game enabling quantum correlations to win with probability one, while classical correlations are always bounded away from one;  somehow this result manages to cleverly turn this game into a computational advantage. In Sergey’s last talk, he gave the basics of the beautiful topic of <strong>stoqaustic Hamiltonians </strong>–  a model in between quantum Hamiltonians and classical constrained satisfaction problems, which poses many fundamental and interesting open questions (and is tightly related to classical Markov chains, and Markov chain Monte Carlo). </li><li>Finally, Adam Bouland gave two superb talks on <strong>quantum supremacy</strong>, explaining the beautiful challenges in this area – including his recent average case to worst case hardness results about sampling using quantum circuits, which is related to Google’s supremacy experiment.  </li><li>Ah, I also gave a talk – it was about three of the many different equivalent models of quantum computation – <strong>adiabatic computation</strong>, <strong>quantum walks</strong>, and the <strong>Jones polynomial </strong>(I also briefly mentioned a differential geometry model). The talk came out way too disordered in my mind (never give a talk when you are an organizer!), but hopefully it gave some picture about the immense variety of ways to think about quantum computation and quantum algorithms.</li></ul>



<p>In addition to the main lectures, we also had some special events intertwined: </p>



<ul><li>Boaz Barak gave the distinguished annual Rabin lecture, joint with the CS colloquium; His talk, which was given the intriguing title  <strong>“Quantum computing and classical algorithms: The best of frenemies”</strong>, focused on the fickle relationships between quantum and classical algorithms. The main players in this beautiful talk were SDPs and sums of squares, and it left us with many open questions.     </li><li>Last but not least, we had an <strong>international panel about the meaning of Google’s recent experiment claiming supremacy</strong>, joined by Sergio Boixo from Google explaining the experiment, as well as Scott Aaronson and Umesh Vazirani who woke up very early in the US to join us. I feared we would have some friction and fist fights, but this actually became a deep and interesting discussion! We went with quite some depth into the most important question in my mind about the supremacy experiment, which is the issue of noise; Unbelievably, it all went well even from the technological aspect! I really recommend watching this <a href="https://www.youtube.com/watch?v=H4t2G2gay7Q&amp;feature=youtu.be" rel="noreferrer noopener" target="_blank">discussion</a>. </li></ul>



<p>So, we had a great time…. and as I said, one of the best things is that it is all recorded and saved. You are welcome to follow the <a href="https://docs.google.com/document/d/1OcFzE1PHxBN4l87sOQB033FZLTgY934GHxnpVKi3NaM/edit" rel="noreferrer noopener" target="_blank">program</a>, watch the recorded <a href="https://www.youtube.com/playlist?list=PLTn74Qx5mPsS2dqTpEq_2zxq8kWBmPUfb" rel="noreferrer noopener" target="_blank">talks</a>, consult the <a href="https://drive.google.com/drive/u/0/folders/1n6W3Yjq2TYsyRwrocbN2bWK-xpyzkqSM" rel="noreferrer noopener" target="_blank">Lecture notes, slides, and the problems sets and their solutions</a>, and also read the <a href="https://docs.google.com/document/d/1s-DLl_M-Dpqh9RdSqn6f9l01e09AaLndMlbxDEmlPrw/edit?ts=5dc7c2b3" rel="noreferrer noopener" target="_blank">reading material</a> if you want to extend your knowledge beyond what is covered in the school. In case you know of any math or TCS-oriented person who wants to enter the field and start working on some problem at the forefront of research, just send him or her this post, or the link of the <a href="https://iias.huji.ac.il/SchoolCSE4" rel="noreferrer noopener" target="_blank">school’s website</a>;  It will take a very intensive week (well, maybe two) of following lectures and doing the exercises, but by the end of that time, one is guaranteed to be no longer a complete amateur to the area, as the set of topics covered gives a pretty good picture of what is going on in the field.   <br/>  </p>



<p>Last but not least, I would like to thank the Israeli quantum initiative, Vatat, and the IIAS, for their generous funding which enabled this school and the funding of students; the IIAS team for their immense help in organization;   and of course, thanks a lot to all participants who attended the school!<br/></p>



<p>Wishing everyone a very happy year of 2020,  </p>



<p>Dorit</p></div>
    </content>
    <updated>2019-12-28T22:11:53Z</updated>
    <published>2019-12-28T22:11:53Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-01-02T12:21:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4447</id>
    <link href="https://www.scottaaronson.com/blog/?p=4447" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4447#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4447" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Quantum computing motte-and-baileys</title>
    <summary xml:lang="en-US">In the wake of two culture-war posts—the first on the term “quantum supremacy,” the second on the acronym “NIPS”—it’s clear that we all need to cool off with something anodyne and uncontroversial. Fortunately, this holiday season, I know just the thing to bring everyone together: groaning about quantum computing hype! When I was at the […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>In the wake of two culture-war posts—the <a href="https://www.scottaaronson.com/blog/?p=4450">first</a> on the term “quantum supremacy,” the <a href="https://www.scottaaronson.com/blog/?p=4476">second</a> on the acronym “NIPS”—it’s clear that we all need to cool off with something anodyne and uncontroversial.  Fortunately, this holiday season, I know just the thing to bring everyone together: groaning about quantum computing hype!</p>



<p>When I was at the <a href="https://q2b.qcware.com/">Q2B conference</a> in San Jose, I learned about lots of cool stuff that’s happening in the wake of Google’s quantum supremacy announcement.  I heard about the 57-qubit superconducting chip that the Google group is now building, following up on its 53-qubit one; and also about their first small-scale experimental demonstration of my certified randomness protocol.  I learned about recent progress on costing out the numbers of qubits and gates needed to do fault-tolerant quantum simulations of useful chemical reactions (IIRC, maybe a hundred thousand qubits and a few hours’ worth of gates—scary, but not Shor’s algorithm scary).</p>



<p>I also learned about two claims about quantum algorithms that startups have made, and which are being wrongly interpreted.  The basic pattern is one that I’ve come to know well over the years, and which you could call a science version of the <a href="https://philpapers.org/archive/SHATVO-2.pdf">motte-and-bailey</a>.  (For those not up on nerd blogosphere terminology: in medieval times, the motte was a dank castle to which you’d retreat while under attack; the bailey was the desirable land that you’d farm once the attackers left.)</p>



<p>To wit:</p>



<ol><li>Startup makes claims that have both a true boring interpretation (e.g., you can do X with a quantum computer), as well as a false exciting interpretation (e.g., you can do X with a quantum computer, <em>and it would actually make sense to do this, because you’ll get an asymptotic speedup over the best known classical algorithm</em>).</li><li>Lots of business and government people get all excited, because they assume the false exciting interpretation must be true (or why else would everyone be talking about this?).  Some of those people ask me for comment.</li><li>I look into it, perhaps by asking the folks at the startup.  The startup folks clarify that they meant only the true boring interpretation.  To be sure, they’re actively <em>exploring</em> the false exciting interpretation—whether some parts of it might be true after all—but they’re certainly not making any claims about it that would merit, say, a harsh post on <em>Shtetl-Optimized</em>.</li><li>I’m satisfied to have gotten to the bottom of things, and I tell the startup folks to go their merry way.</li><li>Yet many people continue to seem as excited as if the false exciting interpretation had been shown to be true.  They continue asking me questions that presuppose its truth.</li></ol>



<p>Our first instance of this pattern is the <a href="https://www.newscientist.com/article/2227387-quantum-computer-sets-new-record-for-finding-prime-number-factors/">recent claim</a>, by <a href="https://www.zapatacomputing.com/">Zapata Computing</a>, to have set a world record for integer factoring (1,099,551,473,989 =  1,048,589 × 1,048,601) with a quantum computer, by running a QAOA/variational algorithm on IBM’s superconducting device.  Gosh!  That sure sounds a lot better than the 21 that’s been factored with Shor’s algorithm, doesn’t it?</p>



<p>I read the <a href="https://arxiv.org/abs/1808.08927">Zapata paper</a> that this is based on, entitled “Variational Quantum Factoring,” and I don’t believe that a single word in it is false.  My issue is something the paper <em>omits</em>: namely, that once you’ve reduced factoring to a generic optimization problem, you’ve thrown away all the mathematical structure that <a href="https://en.wikipedia.org/wiki/Shor%27s_algorithm">Shor’s algorithm</a> cleverly exploits, and that makes factoring asymptotically easy for a quantum computer.  And hence there’s no reason to expect your quantum algorithm to scale any better than brute-force trial division (or in the most optimistic scenario, trial division enhanced with Grover search).  On large numbers, your algorithm will be roundly outperformed even by <em>classical</em> algorithms that do exploit structure, like the <a href="https://en.wikipedia.org/wiki/General_number_field_sieve">Number Field Sieve</a>.  Indeed, the quantum computer’s success at factoring the number will have had little or nothing to do with its being <em>quantum</em> at all—a classical optimization algorithm would’ve served as well.  And thus, the only reasons to factor a number on a quantum device in this way, would seem to be stuff like calibrating the device.</p>



<p>Admittedly, to people who work in quantum algorithms, everything above is so obvious that it doesn’t need to be said.  But I learned at Q2B that there are interested people for whom this is <em>not</em> obvious, and even comes as a revelation.  So that’s why I’m saying it.</p>



<p>Again and again over the past twenty years, I’ve seen people reinvent the notion of a “simpler alternative” to Shor’s algorithm: one that cuts out all the difficulty of building a fault-tolerant quantum computer.  In every case, the trouble, typically left unstated, has been that these alternatives <em>also</em> cut out the exponential speedup that’s Shor’s algorithm’s raison d’être.</p>



<p>Our second example today of a quantum computing motte-and-bailey is the claim, by Toronto-based quantum computing startup <a href="https://www.xanadu.ai/">Xanadu</a>, that <a href="https://arxiv.org/abs/1612.01199">Gaussian BosonSampling</a> can be used to solve all sorts of graph problems, like graph isomorphism, graph similarity, and densest subgraph.  As the co-inventor of <a href="https://en.wikipedia.org/wiki/Boson_sampling">BosonSampling</a>, few things would warm my heart more than finding an actual application for that model (besides quantum supremacy experiments and, perhaps, certified random number generation).  But I still regard this as an open problem—if by “application,” we mean outperforming what you could’ve done classically.</p>



<p>In papers (see for example <a href="https://arxiv.org/abs/1810.10644">here</a>, <a href="https://arxiv.org/abs/1905.12646">here</a>, <a href="https://arxiv.org/abs/1803.10730">here</a>), members of the Xanadu team have given all sorts of ways to take a graph, and encode it into an instance of Gaussian BosonSampling, in such a way that the output distribution will then reveal features of the graph, like its isomorphism type or its dense subgraphs.  The trouble is that so far, I’ve seen no indications that this will actually lead to quantum algorithms that outperform the best classical algorithms, for any graph problems of practical interest.</p>



<p>In the case of Densest Subgraph, the Xanadu folks use the output of a Gaussian BosonSampler to seed (that is, provide an initial guess for) a classical local search algorithm.  They say they observe better results this way than if they seed that classical local search algorithm with completely random initial conditions.  But of course, the real question is: could we get equally good results by seeding with the output of some <em>classical</em> heuristic?  Or by solving Densest Subgraph with a different approach entirely?  Given how hard it’s turned out to be just to <em>verify</em> that the outputs of a BosonSampling device come from such a device at all, it would seem astonishing if the answer to these questions wasn’t “yes.”</p>



<p>In the case of Graph Isomorphism, the situation is even clearer.  There, the central claim made by the Xanadu folks is that given a graph G, they can use a Gaussian BosonSampling device to sample a probability distribution that encodes G’s isomorphism type.  So, isn’t this “promising” for solving GI with a quantum computer?  All you’d need to do now is invent some fast classical algorithm that could look at the samples coming from two graphs G and H, and tell you whether the probability distributions were the same.</p>



<p>Except, not really.  While the Xanadu paper never says so, if all you want is to sample a distribution that encodes a graph’s isomorphism type, that’s easy to do classically!  (I even put this on the final exam for my undergraduate Quantum Information Science course a couple weeks ago.)  Here’s how: given as input a graph G, just output G but with its vertices randomly permuted.  Indeed, this will even provide a further property, better than anything the BosonSampling approach has been shown to provide (or than it probably does provide): namely, if G and H are <em>not</em> isomorphic, then the two probability distributions will not only be different but will have disjoint supports.  Alas, this still leaves us with the problem of distinguishing which distribution a given sample came from, which is as hard as Graph Isomorphism itself.  None of these approaches, classical or quantum, seem to lead to any algorithm that’s subexponential time, let alone competitive with the <a href="https://www.scottaaronson.com/blog/?p=2521">“Babai approach”</a> of thinking really hard about graphs.</p>



<p>All of this stuff falls victim to what I regard as the Fundamental Error of Quantum Algorithms Research: namely, to treat it as “promising” that a quantum algorithm works at all, or works better than some brute-force classical algorithm, without asking yourself whether there are any indications that your approach will <em>ever</em> be able to exploit interference of amplitudes to outperform the <em>best</em> classical algorithm.</p>



<p>Incidentally, I’m not sure exactly why, but in practice, a major red flag that the Fundamental Error is about to be committed is when someone starts talking about “hybrid quantum/classical algorithms.”  By this they seem to mean: “outside the domain of traditional quantum algorithms, so don’t judge us by the standards of that domain.”  But I liked the way someone at Q2B put it to me: <em>every</em> quantum algorithm is a “hybrid quantum/classical algorithm,” with classical processors used wherever they can be, and qubits used only where they must be.</p>



<p>The other thing people do, when challenged, is to say “well, admittedly we have no <em>rigorous proof</em> of an asymptotic quantum speedup”—thereby brilliantly reframing the whole conversation, to make people like me look like churlish theoreticians insisting on an impossible and perhaps irrelevant standard of rigor, blind to some huge practical quantum speedup that’s about to change the world.  The real issue, of course, is not that they haven’t given a <em>proof</em> of a quantum speedup (in either the real world or the black-box world); rather, it’s that they’ve typically given no reasons whatsoever to think that there <em>might</em> be a quantum speedup, compared to the best classical algorithms available.</p>



<p>In the holiday spirit, let me end on a positive note.  When I did the Q&amp;A at Q2B—the same one where Sarah Kaiser asked me to comment on the term “quantum supremacy”—one of my answers touched on the most important theoretical open problems about sampling-based quantum supremacy experiments.  At the top of the list, I said, was whether there’s some interactive protocol by which a near-term quantum computer can not only exhibit quantum supremacy, but <em>prove</em> it to a polynomial-time-bounded classical skeptic.  I mentioned that there was <em>one</em> proposal for how to do this, in the IQP model, due to <a href="https://arxiv.org/abs/0809.0847">Bremner and Shepherd</a>, from way back in 2008.  I said that their proposal deserved much more attention than it had received, and that trying to break it would be one obvious thing to work on.  Little did I know that, <strong>literally while I was speaking</strong>, a <a href="https://arxiv.org/abs/1912.05547">paper was being posted to the arXiv</a>, by Gregory Kahanamoku-Meyer, that claims to break Bremner and Shepherd’s protocol.  I haven’t yet studied the paper, but assuming it’s correct, it represents the first clear progress on this problem in years (even though of a negative kind).  Cool!!</p></div>
    </content>
    <updated>2019-12-28T16:08:12Z</updated>
    <published>2019-12-28T16:08:12Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Complexity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-12-29T00:44:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16497</id>
    <link href="https://rjlipton.wordpress.com/2019/12/26/a-math-gift-for-all/" rel="alternate" type="text/html"/>
    <title>A Math Gift For All</title>
    <summary>Happy holidays to all. Kathryn Farley is my dear wife. We just celebrated Christmas together and then went off to London for a holiday. Today I thought I would share a gift with you. Kathryn and I exchange books for the holiday. We do not wrap them—our tradition, which she started years ago. I like […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Happy holidays to all.</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2019/12/kathrynart.jpg"><img alt="" class="alignright size-medium wp-image-16499" height="300" src="https://rjlipton.files.wordpress.com/2019/12/kathrynart.jpg?w=158&amp;h=300" width="158"/></a></p>
<p>
Kathryn Farley is my dear wife. We just celebrated Christmas together and then went off to London for a holiday.</p>
<p>
Today I thought I would share a gift with you.<br/>
<span id="more-16497"/></p>
<p>
Kathryn and I exchange books for the holiday. We do not wrap them—our tradition, which she started years ago. I like doing this. Ken’s family re-uses wrapping paper year-to-year. I am pleased to see that there is a call to save wrapping on three <a href="https://frugalkite.com/zero-waste-christmas-three-genius-wrapping-methods/">gifts</a>.</p>
<blockquote><p><b> </b> <em> If every American family wrapped just 3 presents in reused materials, it would save enough paper to cover 45,000 football fields. </em>
</p></blockquote>
<p/><p>
Kathryn gave me a wonderful collection of books. One of them is not the <a href="https://www.amazon.com/Computers-Rigidity-Moduli-Large-Scale-Riemannian/dp/B01FJ1E910">book</a>: <i>Computers, Rigidity, and Moduli: The Large-Scale Fractal Geometry of Riemannian Moduli Space</i>. The author is Shmuel Weinberger a mathematician from the University of Chicago. I already had his book but finally took a look at it while browsing my other gifts. So it is a delayed gift, from a Christmas past.</p>
<p>
The book is a combination of computer results, basic math results, and advanced math results. The last are a variety of topics that are well outside of my zone. I did like the book. Weinberger is a terrific writer, a terrific explainer, a gifted selector of topics. I was surprised to see that his book contained a puzzle that I had not thought about before. The puzzle is, like all good puzzles, easy to state—but hard to solve. At least for me. I did not see how to solve it. I hope you like it.</p>
<p>
</p><p/><h2> A Puzzle </h2><p/>
<p/><p>
Imagine that there are <img alt="{2n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2n}"/> distinct points in the plane. No three points are collinear. Half of them, <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> are labeled <font color="red"><b>red</b></font> and the other half are labelled <font color="green"><b>green</b></font>. Festive colors. Your job is to connect each red point with a unique green point by a straight line. That is easy, of course. But we hate when lines cross. So your job is more: Please select the lines so that the fewest ones cross.</p>
<p>
Thus the problem is. Find the fewest line crossings possible. As usual we wish to know the answer as a function of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. Is it <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>? Or <img alt="{\log(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log(n)}"/>? What is the best possible in the worst case?</p>
<p>
The artwork on the wall behind Kathryn suggests a possible arrangement, likewise the floor. The art object directly behind her is in 3D space which is not allowed—but this is a photograph so its points are projected onto a plane anyway. Again, it’s important that no three points are collinear. </p>
<p>
</p><p/><h2> There is a Best </h2><p/>
<p/><p>
For start we note that there is always a best. Each of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> red points can match one of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> green points. So there are only a finite number of possible matchings, namely 	</p>
<p align="center"><img alt="\displaystyle  n! = n \times (n-1) \times \cdots \times 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++n%21+%3D+n+%5Ctimes+%28n-1%29+%5Ctimes+%5Ccdots+%5Ctimes+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  n! = n \times (n-1) \times \cdots \times 1. "/></p>
<p>This shows that there is always a best answer; moreover, it can be found. But <img alt="{n!}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%21%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n!}"/> can be huge, so another part of the question is: Can you find the best answer fast? How about finding the best answer in polynomial time?</p>
<p>
</p><p/><h2> A Solution </h2><p/>
<p/><p>
The best answer is that the number of crossings is always at most 	</p>
<p align="center"><img alt="\displaystyle  b(n) = c \log(n), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++b%28n%29+%3D+c+%5Clog%28n%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  b(n) = c \log(n), "/></p>
<p>where <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/> is the constant 	</p>
<p align="center"><img alt="\displaystyle  10^{2}+11^{2}+12^{2}- 13^{2} - 14^{2}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++10%5E%7B2%7D%2B11%5E%7B2%7D%2B12%5E%7B2%7D-+13%5E%7B2%7D+-+14%5E%7B2%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  10^{2}+11^{2}+12^{2}- 13^{2} - 14^{2}. "/></p>
<p>
Here is a proof that this bound is correct. Suppose that you have selected the fewest number of line crossings. We will argue that there are at most <img alt="{b(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b(n)}"/> line crossings. The plan is to show that we can descend—that is given a matching we can try and decrease the number of lines that cross. </p>
<p>
Given any two red nodes and any two green nodes, we can define the operation <em>swap</em> by having them exchange partners. If their lines cross before the swap, then after the swap the lines will <em>not</em> cross. The following figure shows this:</p>
<p><a href="https://rjlipton.files.wordpress.com/2019/12/points.png"><img alt="" class="aligncenter size-medium wp-image-16500" height="217" src="https://rjlipton.files.wordpress.com/2019/12/points.png?w=300&amp;h=217" width="300"/></a></p>
<p/><p><br/>
Oops. I thought the idea was to define an operation so that the number of line crossing could always be decreased. Wait the argument does not work. In the above figure the switch <em>increases</em> the number of crossings.</p>
<p>
There is a saving trick, however. Do not attempt to decrease the number of lines that cross. Instead decrease the total <i>length</i> of the lines selected. The above figure can be turned into a proof of a lemma that a <em>swap</em> of two crossing lines always decreases the sum of their lengths. The cool idea is that the swaps may actually increase the number of crossings, but they will always decrease the total length. </p>
<p>
In the end the length is minimal and there are <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> crossings. Thus 	</p>
<p align="center"><img alt="\displaystyle  b(n) = 0. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++b%28n%29+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  b(n) = 0. "/></p>
<p>I cheated and used that 	</p>
<p align="center"><img alt="\displaystyle  10^{2}+11^{2}+12^{2} = 13^{2} + 14^{2}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++10%5E%7B2%7D%2B11%5E%7B2%7D%2B12%5E%7B2%7D+%3D+13%5E%7B2%7D+%2B+14%5E%7B2%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  10^{2}+11^{2}+12^{2} = 13^{2} + 14^{2}, "/></p>
<p>and so the constant <img alt="{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c}"/> is zero. Finally, no swap is ever undone—since the length always decreases—and so the process must finish within <img alt="{O(n^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(n^2)}"/> swaps.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Hope that you liked this puzzle. I think it shows that are sometimes methods that while simple may be hard to find. Is <img alt="{O(n^2)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(n^2)}"/> really the needed number of swaps? Are more than a linear number of swaps ever required?<br/>
 Happy holidays to all.</p>
<p/></font></font></div>
    </content>
    <updated>2019-12-27T04:04:37Z</updated>
    <published>2019-12-27T04:04:37Z</published>
    <category term="All Posts"/>
    <category term="Oldies"/>
    <category term="Proofs"/>
    <category term="trick"/>
    <category term="Christmas"/>
    <category term="complexity"/>
    <category term="Kathryn Farley"/>
    <category term="puzzle"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-01-02T12:20:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=18835</id>
    <link href="https://gilkalai.wordpress.com/2019/12/27/the-google-quantum-supremacy-demo/" rel="alternate" type="text/html"/>
    <title>The Google Quantum Supremacy Demo and the Jerusalem HQCA debate.</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Below are 10 annotated slides from a spontaneous informal talk that I gave at the school on mathematics of quantum computing a weak ago. (Power point presentation.) Later in the afternoon we had  a panel/debate on quantum supremacy (click for … <a href="https://gilkalai.wordpress.com/2019/12/27/the-google-quantum-supremacy-demo/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Below are 10 annotated slides from a spontaneous informal talk that I gave at the <a href="http://ias.huji.ac.il/SchoolCSE4">school on mathematics of quantum computing</a> a weak ago. (<a href="https://gilkalai.files.wordpress.com/2019/12/google-demo-blog.pptx">Power point presentation</a>.) Later in the afternoon we had  <strong>a panel/debate on quantum supremacy </strong>(<a href="https://www.youtube.com/watch?v=H4t2G2gay7Q&amp;feature=youtu.be">click for the video</a>) moderated by Sandy Irani and featuring Scott Aaronson, Dorit Aharonov, Boaz Barak, Sergio Boixo, Adam Bouland,  Umesh Vazirani, and me. It was a thoughtful and interesting discussion. (The presentation was initially prepared for the afternoon debate but at the end I gave it as a separate talk and presented just one slide at the panel itself. The plan was also to post it as a background material before the discussion, but not untypically, I was too slow, so here it is a week later.) I am thankful to Dorit for inviting me to the panel (and for organizing a great school!), to Sandy for her excellent moderation, and to all the panelists for their good spirit. (Update: <a href="https://windowsontheory.org/2019/12/28/quantum-school-lecture-notes-videos-and-more-guest-post-by-dorit-aharonov/">A blog post by Dorit</a> at Windows on Theory)</p>
<p><span style="color: #ff0000;"><strong>My assessment continues to be that both the Google supremacy claims and their other central claim about fidelity estimation are incorrect.</strong></span></p>
<p>(Dec 23, 2019: Following some <a href="https://www.scottaaronson.com/blog/?p=4450">renewed discussion</a> in the last days on the terminology I proposed to replace the term “quantum supremacy” with <strong><span style="color: #0000ff;">“HQCA – Huge Quantum Computational Advantage”</span></strong> and I myself may try to follow my new term in my own lectures/papers in the future and see how it goes. In fact, I already used HQCA in our Sunday’s Kazhdan seminar where I lectured about noise stability and sensitivity for Boolean functions, Boson Sampling, and quantum circuits (<a href="https://gilkalai.files.wordpress.com/2019/12/d7a1d7a8d799d7a7d7940006.pdf">lecture</a> <a href="https://gilkalai.files.wordpress.com/2019/12/d7a1d7a8d799d7a7d7940007.pdf">notes</a>).)</p>
<h2>My Presentation on the Google Quantum Supremacy Demonstration</h2>
<p><strong>Note:</strong> you may click on a slide to see it in full screen.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/google-slide1.png"><img alt="" class="alignnone size-full wp-image-18836" height="365" src="https://gilkalai.files.wordpress.com/2019/12/google-slide1.png?w=640&amp;h=365" width="640"/></a></p>
<p>My lecture is not about quantum computers and quantum supremacy in general but about the Google quantum supremacy claims. (If you want to know more about my general argument against quantum computers, quantum supremacy and quantum error correction go to the previous post <a href="https://gilkalai.wordpress.com/2019/11/13/gils-collegial-quantum-supremacy-skepticism-faq/" rel="bookmark">Gil’s Collegial Quantum Supremacy Skepticism FAQ </a>and to <a href="https://gilkalai.files.wordpress.com/2019/09/main-pr.pdf">several</a> of <a href="https://arxiv.org/abs/1908.02499">my</a> <a href="https://arxiv.org/abs/1908.02499">papers</a> and <a href="https://gilkalai.files.wordpress.com/2019/09/cern.pptx">presentations</a> <a href="https://www.youtube.com/watch?v=oR-ufBz13Eg">linked</a> there.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/google-slide12.png"><img alt="" class="alignnone size-full wp-image-18875" height="362" src="https://gilkalai.files.wordpress.com/2019/12/google-slide12.png?w=640&amp;h=362" width="640"/></a></p>
<p>In this presentation I will concentrate on aspects of the Google experiment that are “too good to be true”. (Which is a bad sign, not a good sign.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/google-slide13.png"><img alt="" class="alignnone size-full wp-image-18874" height="350" src="https://gilkalai.files.wordpress.com/2019/12/google-slide13.png?w=640&amp;h=350" width="640"/></a></p>
<p>There is an amazing agreement between the fidelity as estimated from the experimental data and a very simple high-school model based on the probability of individual qubits and gates to malfunction.  (An even simplified version, below in purple, requires just three parameters – the number n of qubits, the number g1 of 1-qubit gates and the number g2 of 2-qubit gates.)</p>
<p>Formula (77) itself is not surprising but the terrific success of Formula (77) may serve as a smoking gun for the claim that the Google’s experiment has serious methodological problems.</p>
<p>I was not the only one to be amazed. Here is what John Martinis, the scientific leader of the Google supremacy experiment told about it. (Nov 1., 2019) Read carefully!</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/google-slide6.png"><img alt="" class="alignnone size-full wp-image-18849" height="400" src="https://gilkalai.files.wordpress.com/2019/12/google-slide6.png?w=640&amp;h=400" width="640"/></a></p>
<p>The accuracy of Formula (77) is the most amazing thing about the data, something that came as a big surprise, and that (jokingly) will let quantum scientists keep their jobs.</p>
<p>And here is what I think</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/google-slide7.png"><img alt="" class="alignnone size-full wp-image-18851" height="367" src="https://gilkalai.files.wordpress.com/2019/12/google-slide7.png?w=640&amp;h=367" width="640"/></a></p>
<p>No no, you cannot estimate with precision of 10-20% the probability of failure of a physical system with 1000 interacting elements as the product of 1000 error-probabilities.</p>
<p><strong>This remarkable agreement is a major new discovery, and it is <em>not needed</em> for building quantum computers. It is only needed for the extrapolation argument leading the Google team to supremacy.</strong></p>
<p>Even if quantum computers will be built this is something that we are not going to witness. It is interesting to check if we see anything remotely like this for the IBM quantum computers.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/google-slide8.png"><img alt="" class="alignnone size-full wp-image-18853" height="334" src="https://gilkalai.files.wordpress.com/2019/12/google-slide8.png?w=640&amp;h=334" width="640"/></a></p>
<p>Here on the left you see for various values of <em>n</em>, the number of qubits, two experiments with different circuits that leads to entirely different probability distributions. Since each pair have a similar number of gates, Formula (77) leads to very close fidelity estimates which are so accurate that the green and blue lines coincide! We do not expect to see such close agreements in experimental data.</p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/google-slide9.png"><img alt="" class="alignnone size-full wp-image-18857" height="350" src="https://gilkalai.files.wordpress.com/2019/12/google-slide9.png?w=640&amp;h=350" width="640"/></a></p>
<p>Blue, orange and green analytic smooth curves representing three distributions. For all three you see also empirical samples from the distributions. For two of them the samples are perfect, for the other one you see a sample based on a complicated physical experiment.</p>
<p><strong>Test your intuition:</strong> can you tell the difference? Can you tell which is which?</p>
<p>(You can also test your intuition which was the single slide presented at the afternoon debate.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/google-slide10.png"><img alt="" class="alignnone size-full wp-image-18860" height="360" src="https://gilkalai.files.wordpress.com/2019/12/google-slide10.png?w=640&amp;h=360" width="640"/></a></p>
<p><strong>Blind tests</strong> are standard in scientific experiments and are quite easy to implement here.</p>
<p>The meaning of the surprising statistical success of Formula (77) should be <strong>carefully examined</strong>.</p>
<h2>Two extra slides</h2>
<p>To put my view in context,  I devote one slide for my general argument against quantum computers, quantum supremacy and quantum error correction.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/google-slide2.png"><img alt="" class="alignnone size-full wp-image-18839" height="363" src="https://gilkalai.files.wordpress.com/2019/12/google-slide2.png?w=640&amp;h=363" width="640"/></a></p>
<p>I mentioned that most experts do not agree with my argument or do not even understand it, and for some of them, this may give reasons for skepticism also about my critique on the Google experiment. I  personally think that my general argument is good, but  I don’t think it is ironclad and I am pleased to see this matter explored experimentally (properly). I also think that my critique on the Google demo stands well on its own.</p>
<p>And what may convince me to change my mind? poetry!</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/dslide16.png"><img alt="" class="alignnone size-full wp-image-19013" height="362" src="https://gilkalai.files.wordpress.com/2019/12/dslide16.png?w=640&amp;h=362" width="640"/></a></p>
<p>Let me add that all my critique as described here and elsewhere was first presented to the Google team.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/fp12.png"><img alt="" class="alignnone size-full wp-image-19089" height="178" src="https://gilkalai.files.wordpress.com/2019/12/fp12.png?w=640&amp;h=178" width="640"/></a></p>
<p><span style="color: #ff0000;">From right to left: Sandy Irani, me, Boaz Barak, Adam Bouland, Dorit Aharonov, and on the left Umesh Vazirani, Scott Aaronson, and Sergio Boixo. (Collage; More pictures – below.)</span></p>
<p><span id="more-18835"/></p>
<p><strong>Answer to Test your intuition:</strong> The orange graph is the one that comes from the experiments.</p>
<h2>Some recollections, reactions, and comments from the debate:</h2>
<h3>Uploading data for verification</h3>
<p>At the beginning of the debate, I nudged Sergio to upload some (additional; promised) data that is needed for verification and analysis of their results.</p>
<h3>Formula (77)</h3>
<p>Formula (77) was discussed in some details in Q/A of the the informal talk and also in the panel/debate. (I raised the question if the Google experiment is correct and specifically the issue with Formula (77) at <a href="https://youtu.be/H4t2G2gay7Q?t=2097">35:00</a> and Formula (77) was discussed for the next 25 minutes.) Of course, the surprising issue is the accurate predictions that Formula (77) gives.</p>
<p>Sergio briefly explained the statistical rationale for such a precision. The way I see it, the quality of the prediction for (77) requires two assumptions: (1) No systematic errors, (2) statistical independence. Both these assumptions seem utterly unrealistic. No systematic errors means that the average error estimation say for read-out errors or for gate errors are precise and fluctuations are symmetric. This is very unrealistic. The assumption of statistical independence also seems unrealistic. (Positive correlations will actually lead to better fidelity.)  Dorit, Boaz and several other people (and also Peter Shor earlier <a href="https://gilkalai.wordpress.com/2019/11/13/gils-collegial-quantum-supremacy-skepticism-faq/#comment-61697">here on the blog</a>) proposed that the remarkable predictive power of (77) and, in particular, the required statistical independence may follow from having a random circuit. I don’t understand that.</p>
<p>Beside the concrete attempts to understand the predictive power of Formula (77) there were some general comments about it. Adam opined that <em>in physics</em> the data fits the models very well. Scott  joked that here I am arguing that the results fits the model too well and he could imagine me arguing in another universe that the results don’t fit the model well enough. At another point he said “First the data is not good enough, and now the data is too good, what will make you happy, Gil” and I answered that the data should be <em>reliable.</em></p>
<h3>The extended Church-Turing thesis (ECTT)</h3>
<p>Does “supremacy” (or HQCA), in general and in the context of Google’s experiment violates the extended Church-Turing thesis? Dorit claimed that the answer is negative since (roughly) the experiments cannot be scaled. Sergio sort of agreed and said they only claim to <em>challenge</em> the ECCT. (Indeed the fidelity goes exponentially to zero and even if producing such samples is beyond the power of a classical computer the sample sizes need to be exponential; it is an interesting question if every scalable supremacy demonstration requires quantum fault tolerance.)  A point that I made is that if we assume further certain “naturalness” principle, namely that, in practice,  constants in computational complexity asymptotic behavior are mild, then an astronomical speed-up as claimed by Google, can be considered as violating ECCT.</p>
<h3>Trillions</h3>
<p>Actually, in the early lecture I presented another slide about my initial feeling towards the Google (then licked) paper. I was surprised by the trillions-time speed up, and regarded the 300,000,000,000 speed-up as expressing some “supremacy fever:” why not start with a more modest speed-up but with convincing direct evidence?</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/google-slide3.png"><img alt="" class="alignnone size-medium wp-image-18841" height="170" src="https://gilkalai.files.wordpress.com/2019/12/google-slide3.png?w=300&amp;h=170" width="300"/></a></p>
<p>Why the trillions speed up should not surprise us? Adam Bouland commented that this is to be expected when we think about exponential speed-up. BTW, Adam gave very nice lectures on quantum algorithms and quantum supremacy.</p>
<h3>Miscellaneous</h3>
<ol>
<li>I was slowly loosing my voice so in the earlier lecture Or Sattath read the quote from Martinis, and Adam read the poem by Renan. (I should try that also in talks where I am not loosing my voice.)</li>
<li> Sandy asked about other reasons for skepticism regarding the Google claims and Scott mentioned the possibility that much better classical algorithms will be found.</li>
<li>Both me and Scott (and perhaps others in the panel as well) emphasized the importance of replications.</li>
<li>Adam was Scott’s Ph. D student and Scott was Umesh’s Ph. D. student so we had on the panel three academic generations!</li>
<li>Toward the end Scott described briefly the decade-old history, theory+experiment, of quantum supremacy.</li>
<li>There were various other interesting issues that were raised.</li>
<li>For history: The video flipped left and right. In reality Sandy was right farthermost and I was second to the right.</li>
</ol>
<h3>Quantum error-correction</h3>
<p>Dorit asked about quantum error correction and I asked specifically about distance-3 surface code and Sergio said that the quality of gates is insufficient for that. If I understood correctly the error rate needs to be reduced by a factor of five. (The fact that good quality quantum error correction requires achieving lower error rate than what is required for quantum supremacy is an important ingredient of my general argument against quantum computers.)</p>
<h3>Noise models and the noisy data.</h3>
<p>Dorit and others raised the issue of the noise model and discussed some toy noise models.  There was some discussion on correlated errors. (This is unrelated to the statistical dependence of (77).) I pointed out that correlated errors are irrelevant to random circuits (but relevant to quantum error-correction). Later in the debate I mentioned the concern regarding not having large enough samples to determine the empirical noisy distribution.</p>
<p>At some point Umesh referred to another issue that I raised which is that the noisy model in the Google paper seems oversimplified. I came back to it briefly but we did not discuss this further. (At the Q/A part of my early lecture Boaz have made some interesting comments about identifying the effect of the errors in the last round of the computation.)</p>
<p>I also repeated my suggestion of “Beckner noise” (and correlated variants) as a good toy noise model for noisy quantum circuits.</p>
<h3>My argument against quantum computers</h3>
<p>At the panel I mentioned my general argument against quantum computers, quantum supremacy and quantum error correction only in a few sentences.</p>
<p>BTW, one way to think about the argument is as comparing four thresholds for the level of noise (on gates) <img alt="\rho_{\bf R}, \rho_{\bf S}, \rho_{\bf QEC}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7B%5Cbf+R%7D%2C+%5Crho_%7B%5Cbf+S%7D%2C+%5Crho_%7B%5Cbf+QEC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{\bf R}, \rho_{\bf S}, \rho_{\bf QEC}"/> and <img alt="\rho_{\bf U}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7B%5Cbf+U%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{\bf U}"/>. <img alt="\rho_{\bf S}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7B%5Cbf+S%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{\bf S}"/> is what is required for <strong>HQCA</strong> (quantum supremacy); <img alt="\rho_{\bf QEC}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7B%5Cbf+QEC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{\bf QEC}"/> is what is required for good quality quantum error correction (say, distance-5 surface code); <img alt="\rho_{\bf U}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7B%5Cbf+U%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{\bf U}"/> is what is required for universal quantum computing; <img alt="\rho_{\bf R}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7B%5Cbf+R%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{\bf R}"/> is the lower error rate that can realistically be achieved. I have a computational complexity argument (based on naturalness) that <img alt="\rho_{\bf R} &gt; \rho_{\bf S}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7B%5Cbf+R%7D+%3E+%5Crho_%7B%5Cbf+S%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{\bf R} &gt; \rho_{\bf S}"/>. I also rely on <img alt="\rho_{\bf S} &gt; \rho_{\bf QEC}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Crho_%7B%5Cbf+S%7D+%3E+%5Crho_%7B%5Cbf+QEC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\rho_{\bf S} &gt; \rho_{\bf QEC}"/>.</p>
<h3>Comparisons to Wright brothers’s first flight or to Fermi’s 1942 nuclear chain reaction</h3>
<p>Nobody in the afternoon panel discussion (to the best of my memory) repeated earlier enthusiastic comparisons between Google’s experiment and the first flight in 1903, the first landing on the moon in 1968 (well, I referred to that), Fermi’s 1942 nuclear chain reaction, the first vacuum tubes computers, the discovery of the Higgs boson, etc. etc.</p>
<h3>Silver lining (after-thought)</h3>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/silverlining.png"><img alt="" class="alignnone size-medium wp-image-19048" height="192" src="https://gilkalai.files.wordpress.com/2019/12/silverlining.png?w=300&amp;h=192" width="300"/></a></p>
<p><span style="color: #ff0000;">The beach of Tel Aviv</span></p>
<p>Major advances in human ability to simulate quantum physics and quantum chemistry are expected both if quantum supremacy can be demonstrated and quantum computers can be built and also if quantum supremacy cannot be demonstrated and quantum computers cannot be built.</p>
<p><span style="color: #ff0000;">Debate picture collage</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/panel-gallery.png"><img alt="" class="alignnone size-full wp-image-19042" height="371" src="https://gilkalai.files.wordpress.com/2019/12/panel-gallery.png?w=640&amp;h=371" width="640"/></a></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/panel-umesh.png"> </a></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/daud3.png"><img alt="" class="alignnone size-medium wp-image-19070" height="163" src="https://gilkalai.files.wordpress.com/2019/12/daud3.png?w=300&amp;h=163" width="300"/></a></p>
<p><span style="color: #ff0000;">The audience was happy</span></p></div>
    </content>
    <updated>2019-12-26T22:04:52Z</updated>
    <published>2019-12-26T22:04:52Z</published>
    <category term="Controversies and debates"/>
    <category term="Quantum"/>
    <category term="Adam Bouland"/>
    <category term="Boaz Barak"/>
    <category term="Dorit Aharonov"/>
    <category term="Google"/>
    <category term="HQCA"/>
    <category term="Huge Quantum Computational Advantage"/>
    <category term="quantum supremacy"/>
    <category term="Sandy Irani"/>
    <category term="Scott Aaronson"/>
    <category term="Sergio Boixo"/>
    <category term="Umesh Vazirani"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-01-02T12:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2019/12/25/postdoctoral-research-associate-at-massachusetts-institute-of-technology-theory-of-distributed-systems-group-nancy-lynch-apply-by-february-28-2019/</id>
    <link href="https://cstheory-jobs.org/2019/12/25/postdoctoral-research-associate-at-massachusetts-institute-of-technology-theory-of-distributed-systems-group-nancy-lynch-apply-by-february-28-2019/" rel="alternate" type="text/html"/>
    <title>Postdoctoral Research Associate at Massachusetts Institute of Technology, Theory of Distributed Systems Group, Nancy Lynch (apply by February 28, 2019)</title>
    <summary>Area: “Distributed Algorithms for Dynamic, Noisy Platforms: Wireless Networks, Robot Swarms, and Insect Colonies”. Candidates should have research experience with algorithms for at least one of these topics, preferably with noise and change. Strong background in probabilistic modeling/analysis is essential. Work will also involve simulation, and coordination with experimental researchers. Website: https://groups.csail.mit.edu/tds/reflist.html Email: lynch@csail.mit.edu</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Area: “Distributed Algorithms for Dynamic, Noisy Platforms: Wireless Networks, Robot Swarms, and Insect Colonies”.</p>
<p>Candidates should have research experience with algorithms for at least one of these topics, preferably with noise and change. Strong background in probabilistic modeling/analysis is essential. Work will also involve simulation, and coordination with experimental researchers.</p>
<p>Website: <a href="https://groups.csail.mit.edu/tds/reflist.html">https://groups.csail.mit.edu/tds/reflist.html</a><br/>
Email: lynch@csail.mit.edu</p></div>
    </content>
    <updated>2019-12-25T12:37:19Z</updated>
    <published>2019-12-25T12:37:19Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-01-02T12:20:57Z</updated>
    </source>
  </entry>
</feed>
