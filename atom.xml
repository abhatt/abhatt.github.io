<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-07-12T10:21:47Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/103</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/103" rel="alternate" type="text/html"/>
    <title>TR20-103 |  One-Tape Turing Machine and Branching Program Lower Bounds for MCSP | 

	Mahdi Cheraghchi, 

	Shuichi Hirahara, 

	Dimitrios Myrisiotis, 

	Yuichi Yoshida</title>
    <summary>For a size parameter $s\colon\mathbb{N}\to\mathbb{N}$, the Minimum Circuit Size Problem (denoted by ${\rm MCSP}[s(n)]$) is the problem of deciding whether the minimum circuit size of a given function $f \colon \{0,1\}^n \to \{0,1\}$ (represented by a string of length $N := 2^n$) is at most a threshold $s(n)$. A recent line of work exhibited ``hardness magnification'' phenomena for MCSP: A very weak lower bound for MCSP implies a breakthrough result in complexity theory. For example, McKay, Murray, and Williams (STOC 2019) implicitly showed that, for some constant $\mu_1 &gt; 0$, if ${\rm MCSP}[2^{\mu_1\cdot n}]$ cannot be computed by a one-tape Turing machine (with an additional one-way read-only input tape) running in time $N^{1.01}$, then ${\rm P}\neq{\rm NP}$.
    
    In this paper, we present the following new lower bounds against one-tape Turing machines and branching programs:
    \begin{enumerate}
        \item  A randomized two-sided error one-tape Turing machine (with an additional one-way read-only input tape) cannot compute ${\rm MCSP}[2^{\mu_2\cdot n}]$ in time $N^{1.99}$, for some constant $\mu_2 &gt; \mu_1$.  
        \item A non-deterministic (or parity) branching program of size $o(N^{1.5}/\log N)$ cannot compute MKTP, which is a time-bounded Kolmogorov complexity analogue of MCSP. This is shown by directly applying the Nechiporuk method to MKTP, which previously appeared to be difficult.
    \end{enumerate}
    These results are the first non-trivial lower bounds for MCSP and MKTP against one-tape Turing machines and non-deterministic branching programs, and essentially match the best-known lower bounds for any explicit functions against these computational models.
    
    The first result is based on recent constructions of pseudorandom generators for read-once oblivious branching programs (ROBPs) and combinatorial rectangles (Forbes and Kelley, FOCS 2018; Viola 2019). En route, we obtain several related results:
    \begin{enumerate}
        \item There exists a (local) hitting set generator with seed length $\widetilde{O}(\sqrt{N})$ secure against read-once polynomial-size non-deterministic branching programs on $N$-bit inputs.
        \item Any read-once co-non-deterministic branching program computing MCSP must have size at least $2^{\widetilde{\Omega}(N)}$.
    \end{enumerate}</summary>
    <updated>2020-07-11T05:31:21Z</updated>
    <published>2020-07-11T05:31:21Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-12T10:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/07/11/2020-virtual-telluride-neuromorphic-cognition-engineering-workshop/</id>
    <link href="https://cstheory-events.org/2020/07/11/2020-virtual-telluride-neuromorphic-cognition-engineering-workshop/" rel="alternate" type="text/html"/>
    <title>2020 Virtual Telluride Neuromorphic Cognition Engineering Workshop</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 27-31, 2020 Telluride CO (virtual) https://sites.google.com/view/telluride2020/home We are happy to announce a Virtual Telluride Neuromorphic Cognition Engineering Workshop 2020 (https://tellurideneuromorphic.org/) this year in replacement of our usual Workshop in Telluride. The workshop will take place from July 27 to July 31 (8am to 10am PDT, or 17:00 to 19:00 CET). The format will be … <a class="more-link" href="https://cstheory-events.org/2020/07/11/2020-virtual-telluride-neuromorphic-cognition-engineering-workshop/">Continue reading <span class="screen-reader-text">2020 Virtual Telluride Neuromorphic Cognition Engineering Workshop</span></a></div>
    </summary>
    <updated>2020-07-11T05:05:01Z</updated>
    <published>2020-07-11T05:05:01Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-07-12T10:21:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/07/11/international-conference-on-neuromorphic-systems/</id>
    <link href="https://cstheory-events.org/2020/07/11/international-conference-on-neuromorphic-systems/" rel="alternate" type="text/html"/>
    <title>International Conference on Neuromorphic Systems</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 28-30, 2020 Oak Ridge National Laboratory (virtual) https://icons.ornl.gov ICONS 2020 will be held as a virtual conference. The goal of this conference is to bring together leading researchers in neuromorphic computing to present new research, develop new collaborations, and provide a forum to publish work in this area. Our focus will be on architectures, … <a class="more-link" href="https://cstheory-events.org/2020/07/11/international-conference-on-neuromorphic-systems/">Continue reading <span class="screen-reader-text">International Conference on Neuromorphic Systems</span></a></div>
    </summary>
    <updated>2020-07-11T05:04:39Z</updated>
    <published>2020-07-11T05:04:39Z</published>
    <category term="conference"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-07-12T10:21:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/07/11/neuromorphic-computing-opportunities-challenges-and-perspectives/</id>
    <link href="https://cstheory-events.org/2020/07/11/neuromorphic-computing-opportunities-challenges-and-perspectives/" rel="alternate" type="text/html"/>
    <title>Neuromorphic Computing: Opportunities, Challenges, and Perspectives</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">July 19, 2020 Virtual https://teuscher-lab.com/dac2020_neuromorphic_workshop/program/ The objective of this workshop is to bring together researchers from multiple disciplines, ranging from physical to biological sciences, to discuss the most promising approaches and overarching goals of neuromorphic computing technologies and paradigms that have the potential to drastically improve conventional approaches. The neuromorphic computing workshop aims to establish … <a class="more-link" href="https://cstheory-events.org/2020/07/11/neuromorphic-computing-opportunities-challenges-and-perspectives/">Continue reading <span class="screen-reader-text">Neuromorphic Computing: Opportunities, Challenges, and Perspectives</span></a></div>
    </summary>
    <updated>2020-07-11T05:04:18Z</updated>
    <published>2020-07-11T05:04:18Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-07-12T10:21:20Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.04937</id>
    <link href="http://arxiv.org/abs/2007.04937" rel="alternate" type="text/html"/>
    <title>Practical Budgeted Submodular Maximization</title>
    <feedworld_mtime>1594425600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nutov:Zeev.html">Zeev Nutov</a>, Elad Shoham <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.04937">PDF</a><br/><b>Abstract: </b>We consider the Budgeted Submodular Maximization problem, that seeks to
maximize an increasing submodular function subject to budget constraints.
Extending a result of Khuller, Moss, and Naor for the Budgeted Coverage
problem, Sviridenko showed that the greedy algorithm combined with guessing 3
most profitable elements of an optimal solution has approximation ratio
$\alpha=1-\frac{1}{e} \approx 0.632$. We show that just $2$ guesses suffice to
achieve ratio $\alpha$, 1 guess suffices to achieve ratio $0.899 \alpha \approx
0.568$, while ratio $0.68\alpha \approx 0.43$ can be achieved without any
guessing. We note that ratio $\alpha-\epsilon$ can be achieved using
${(1/\epsilon)}^{O(1/\epsilon^4)}n\log n$ value oracle calls, but this
algorithm is impractical already for large values of $\epsilon$. Among
practical algorithms, our is the currently best known one.
</p></div>
    </summary>
    <updated>2020-07-11T23:29:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.04842</id>
    <link href="http://arxiv.org/abs/2007.04842" rel="alternate" type="text/html"/>
    <title>An Interior Point Method Solving Motion Planning Problems with Narrow Passages</title>
    <feedworld_mtime>1594425600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mainprice:Jim.html">Jim Mainprice</a>, Nathan Ratliff, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Toussaint:Marc.html">Marc Toussaint</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schaal:Stefan.html">Stefan Schaal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.04842">PDF</a><br/><b>Abstract: </b>Algorithmic solutions for the motion planning problem have been investigated
for five decades. Since the development of A* in 1969 many approaches have been
investigated, traditionally classified as either grid decomposition, potential
fields or sampling-based. In this work, we focus on using numerical
optimization, which is understudied for solving motion planning problems. This
lack of interest in the favor of sampling-based methods is largely due to the
non-convexity introduced by narrow passages. We address this shortcoming by
grounding the motion planning problem in differential geometry. We demonstrate
through a series of experiments on 3 Dofs and 6 Dofs narrow passage problems,
how modeling explicitly the underlying Riemannian manifold leads to an
efficient interior-point non-linear programming solution.
</p></div>
    </summary>
    <updated>2020-07-11T23:35:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-07-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.04726</id>
    <link href="http://arxiv.org/abs/2007.04726" rel="alternate" type="text/html"/>
    <title>Safety in $s$-$t$ Paths, Trails and Walks</title>
    <feedworld_mtime>1594425600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cairo:Massimo.html">Massimo Cairo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khan:Shahbaz.html">Shahbaz Khan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rizzi:Romeo.html">Romeo Rizzi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Sebastian.html">Sebastian Schmidt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tomescu:Alexandru_I=.html">Alexandru I. Tomescu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.04726">PDF</a><br/><b>Abstract: </b>Given a directed graph $G$ and a pair of nodes $s$ and $t$, an \emph{$s$-$t$
bridge} of $G$ is an edge whose removal breaks all $s$-$t$ paths of $G$ (and
thus appears in all $s$-$t$ paths). Computing all $s$-$t$ bridges of $G$ is a
basic graph problem, solvable in linear time.
</p>
<p>In this paper, we consider a natural generalisation of this problem, with the
notion of "safety" from bioinformatics. We say that a walk $W$ is \emph{safe}
with respect to a set $\mathcal{W}$ of $s$-$t$ walks, if $W$ is a subwalk of
all walks in $\mathcal{W}$. We start by considering the maximal safe walks when
$\mathcal{W}$ consists of: all $s$-$t$ paths, all $s$-$t$ trails, or all
$s$-$t$ walks of $G$. We show that the first two problems are immediate
linear-time generalisations of finding all $s$-$t$ bridges, while the third
problem is more involved. In particular, we show that there exists a compact
representation computable in linear time, that allows outputting all maximal
safe walks in time linear in their length.
</p>
<p>We further generalise these problems, by assuming that safety is defined only
with respect to a subset of \emph{visible} edges. Here we prove a dichotomy
between the $s$-$t$ paths and $s$-$t$ trails cases, and the $s$-$t$ walks case:
the former two are NP-hard, while the latter is solvable with the same
complexity as when all edges are visible. We also show that the same complexity
results hold for the analogous generalisations of \emph{$s$-$t$ articulation
points} (nodes appearing in all $s$-$t$ paths).
</p>
<p>We thus obtain the best possible results for natural "safety"-generalisations
of these two fundamental graph problems. Moreover, our algorithms are simple
and do not employ any complex data structures, making them ideal for use in
practice.
</p></div>
    </summary>
    <updated>2020-07-11T23:25:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.04620</id>
    <link href="http://arxiv.org/abs/2007.04620" rel="alternate" type="text/html"/>
    <title>Treewidth-Aware Complexity in ASP: Not all Positive Cycles are Equally Hard</title>
    <feedworld_mtime>1594425600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hecher:Markus.html">Markus Hecher</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fandinno:Jorge.html">Jorge Fandinno</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.04620">PDF</a><br/><b>Abstract: </b>It is well-know that deciding consistency for normal answer set programs
(ASP) is NP-complete, thus, as hard as the satisfaction problem for classical
propositional logic (SAT). The best algorithms to solve these problems take
exponential time in the worst case. The exponential time hypothesis (ETH)
implies that this result is tight for SAT, that is, SAT cannot be solved in
subexponential time. This immediately establishes that the result is also tight
for the consistency problem for ASP. However, accounting for the treewidth of
the problem, the consistency problem for ASP is slightly harder than SAT: while
SAT can be solved by an algorithm that runs in exponential time in the
treewidth k, it was recently shown that ASP requires exponential time in k
\cdot log(k). This extra cost is due checking that there are no self-supported
true atoms due to positive cycles in the program. In this paper, we refine the
above result and show that the consistency problem for ASP can be solved in
exponential time in k \cdot log({\lambda}) where {\lambda} is the minimum
between the treewidth and the size of the largest strongly-connected component
in the positive dependency graph of the program. We provide a dynamic
programming algorithm that solves the problem and a treewidth-aware reduction
from ASP to SAT that adhere to the above limit.
</p></div>
    </summary>
    <updated>2020-07-11T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-07-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.04513</id>
    <link href="http://arxiv.org/abs/2007.04513" rel="alternate" type="text/html"/>
    <title>Computing the Largest Bond and the Maximum Connected Cut of a Graph</title>
    <feedworld_mtime>1594425600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Duarte:Gabriel_L=.html">Gabriel L. Duarte</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eto:Hiroshi.html">Hiroshi Eto</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hanaka:Tesshu.html">Tesshu Hanaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobayashi:Yasuaki.html">Yasuaki Kobayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobayashi:Yusuke.html">Yusuke Kobayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lokshtanov:Daniel.html">Daniel Lokshtanov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pedrosa:Lehilton_L=_C=.html">Lehilton L. C. Pedrosa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schouery:Rafael_C=_S=.html">Rafael C. S. Schouery</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Souza:U=eacute=verton_S=.html">Uéverton S. Souza</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.04513">PDF</a><br/><b>Abstract: </b>The cut-set $\partial(S)$ of a graph $G=(V,E)$ is the set of edges that have
one endpoint in $S\subset V$ and the other endpoint in $V\setminus S$, and
whenever $G[S]$ is connected, the cut $[S,V\setminus S]$ of $G$ is called a
connected cut. A bond of a graph $G$ is an inclusion-wise minimal disconnecting
set of $G$, i.e., bonds are cut-sets that determine cuts $[S,V\setminus S]$ of
$G$ such that $G[S]$ and $G[V\setminus S]$ are both connected. Contrasting with
a large number of studies related to maximum cuts, there exist very few results
regarding the largest bond of general graphs. In this paper, we aim to reduce
this gap on the complexity of computing the largest bond, and the maximum
connected cut of a graph. Although cuts and bonds are similar, we remark that
computing the largest bond and the maximum connected cut of a graph tends to be
harder than computing its maximum cut. We show that it does not exist a
constant-factor approximation algorithm to compute the largest bond, unless P =
NP. Also, we show that {\sc Largest Bond} and {\sc Maximum Connected Cut} are
NP-hard even for planar bipartite graphs, whereas \textsc{Maximum Cut} is
trivial on bipartite graphs and polynomial-time solvable on planar graphs. In
addition, we show that {\sc Largest Bond} and {\sc Maximum Connected Cut} are
NP-hard on split graphs, and restricted to graphs of clique-width $w$ they can
not be solved in time $f(w)\times n^{o(w)}$ unless the Exponential Time
Hypothesis fails, but they can be solved in time $f(w)\times n^{O(w)}$.
Finally, we show that both problems are fixed-parameter tractable when
parameterized by the size of the solution, the treewidth, and the twin-cover
number.
</p></div>
    </summary>
    <updated>2020-07-11T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.04468</id>
    <link href="http://arxiv.org/abs/2007.04468" rel="alternate" type="text/html"/>
    <title>FPT and kernelization algorithms for the k-in-a-tree problem</title>
    <feedworld_mtime>1594425600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gomes:Guilherme_C=_M=.html">Guilherme C. M. Gomes</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santos:Vinicius_F=_dos.html">Vinicius F. dos Santos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Silva:Murilo_V=_G=_da.html">Murilo V. G. da Silva</a>, Jayme L. Szwarcfiter <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.04468">PDF</a><br/><b>Abstract: </b>The three-in-a-tree problem asks for an induced tree of the input graph
containing three mandatory vertices. In 2006, Chudnovsky and Seymour
[Combinatorica, 2010] presented the first polynomial time algorithm for this
problem, which has become a critical subroutine in many algorithms for
detecting induced subgraphs, such as beetles, pyramids, thetas, and even and
odd-holes. In 2007, Derhy and Picouleau [Discrete Applied Mathematics, 2009]
considered the natural generalization to $k$ mandatory vertices, proving that,
when $k$ is part of the input, the problem is $\mathsf{NP}$-complete, and ask
what is the complexity of four-in-a-tree. Motivated by this question and the
relevance of the original problem, we study the parameterized complexity of
$k$-in-a-tree. We begin by showing that the problem is $\mathsf{W[1]}$-hard
when jointly parameterized by the size of the solution and minimum clique cover
and, under the Exponential Time Hypothesis, does not admit an $n^{o(k)}$ time
algorithm. Afterwards, we use Courcelle's Theorem to prove fixed-parameter
tractability under cliquewidth, which prompts our investigation into which
parameterizations admit single exponential algorithms; we show that such
algorithms exist for the unrelated parameterizations treewidth, distance to
cluster, and distance to co-cluster. In terms of kernelization, we present a
linear kernel under feedback edge set, and show that no polynomial kernel
exists under vertex cover nor distance to clique unless $\mathsf{NP} \subseteq
\mathsf{coNP}/\mathsf{poly}$. Along with other remarks and previous work, our
tractability and kernelization results cover many of the most commonly employed
parameters in the graph parameter hierarchy.
</p></div>
    </summary>
    <updated>2020-07-11T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.04411</id>
    <link href="http://arxiv.org/abs/2007.04411" rel="alternate" type="text/html"/>
    <title>An Efficient Updation Approach for Enumerating Maximal $(\Delta, \gamma)$\mbox{-}Cliques of a Temporal Network</title>
    <feedworld_mtime>1594425600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Banerjee:Suman.html">Suman Banerjee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pal:Bithika.html">Bithika Pal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.04411">PDF</a><br/><b>Abstract: </b>Given a temporal network $\mathcal{G}(\mathcal{V}, \mathcal{E},
\mathcal{T})$, $(\mathcal{X},[t_a,t_b])$ (where $\mathcal{X} \subseteq
\mathcal{V}(\mathcal{G})$ and $[t_a,t_b] \subseteq \mathcal{T}$) is said to be
a $(\Delta, \gamma)$\mbox{-}clique of $\mathcal{G}$, if for every pair of
vertices in $\mathcal{X}$, there must exist at least $\gamma$ links in each
$\Delta$ duration within the time interval $[t_a,t_b]$. Enumerating such
maximal cliques is an important problem in temporal network analysis, as it
reveals contact pattern among the nodes of $\mathcal{G}$. In this paper, we
study the maximal $(\Delta, \gamma)$\mbox{-}clique enumeration problem in
online setting; i.e.; the entire link set of the network is not known in
advance, and the links are coming as a batch in an iterative manner. Suppose,
the link set till time stamp $T_{1}$ (i.e., $\mathcal{E}^{T_{1}}$), and its
corresponding $(\Delta, \gamma)$-clique set are known. In the next batch (till
time $T_{2}$), a new set of links (denoted as $\mathcal{E}^{(T_1,T_2]}$) is
arrived.
</p></div>
    </summary>
    <updated>2020-07-11T23:27:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-07-10T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-07-10-encrypted-blockchain-databases-part-ii/</id>
    <link href="https://decentralizedthoughts.github.io/2020-07-10-encrypted-blockchain-databases-part-ii/" rel="alternate" type="text/html"/>
    <title>Encrypted Blockchain Databases (Part II)</title>
    <summary>In this second part of the series on Encrypted Blockchain Databases, we are going to describe three schemes to store dynamic encrypted multi-maps (EMMs) on blockchains, each of which achieves different tradeoffs between query, add and delete efficiency. A List-Based Scheme (LSX) Recall that a multi-map is a collection of...</summary>
    <updated>2020-07-10T20:25:00Z</updated>
    <published>2020-07-10T20:25:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-07-11T23:40:54Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-07-10-encrypted-blockchain-databases-part-i/</id>
    <link href="https://decentralizedthoughts.github.io/2020-07-10-encrypted-blockchain-databases-part-i/" rel="alternate" type="text/html"/>
    <title>Encrypted Blockchain Databases (Part I)</title>
    <summary>Blockchain databases are storage systems that combine properties of both blockchains and databases like decentralization, tamper-resistance, low query latency, and support for complex queries. As they gain wider adoption, concerns over the confidentiality of the data they manage will increase. Already, several projects use blockchains to store sensitive data like...</summary>
    <updated>2020-07-10T20:10:00Z</updated>
    <published>2020-07-10T20:10:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-07-11T23:40:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7764</id>
    <link href="https://windowsontheory.org/2020/07/10/tcs-book-call-for-github-issues/" rel="alternate" type="text/html"/>
    <title>TCS book: Call for GitHub issues</title>
    <summary>I originally planned this summer to finish the work on my Introduction to Theoretical Computer Science book, and in particular write the two missing chapters on space complexity and interactive proof systems. Needless to say, this summer did not go as planned and I won’t be able to write these chapters. However, I still intend […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I originally planned this summer to finish the work on my <a href="https://introtcs.org/">Introduction to Theoretical Computer Science</a> book, and in particular write the two missing chapters on space complexity and interactive proof systems. Needless to say, this summer did not go as planned and I won’t be able to write these chapters. However, I still intend to go over the existing chapters, fixing typos, adding examples, exercises, and generally making it friendlier to beginning undergraduate students. </p>



<p>Toward this end, I would be grateful for people posting bugs, typos, and suggestions as <a href="https://github.com/boazbk/tcs/issues">GitHub issues</a> (I currently have 267 closed and 14 open issues which I hope to get to soon). Of course, if you are technically inclined and there’s a simple local fix, you can also make  a <a href="https://github.com/boazbk/tcs/pulls">pull request</a>.</p>



<p>Aside from these fixes, I am making two more “global” changes to the book. First, I am adding a “non mathy overview” for each chapter. While some students got a lot from reading the book prior to lectures, others were intimidated by the mathematical notation, and so I hope this more gentle introduction will be helpful. I am also adding more examples &amp; solved exercises toward this end. </p>



<p>Another change is that I now follow the more traditional way of presenting deterministic finite automata <em>before </em>Turing machines – DFAs are still optional and can be skipped without missing anything, but some instructors find them as a good introduction to Turing Machines. Thus the order of presentation of materials in the book is roughly as follows:<br/></p>



<ol><li><strong>Introduction, representing objects as strings</strong> –  Representing numbers, lists, etc. Specifying computational tasks as functions mapping binary strings to binary strings,  Cantor’s theorem.</li><li><strong>Finite functions and Boolean circuits</strong> – Every function can be computed by some circuit, circuits as straightline programs, representing circuits as strings, universal circuit evaluator, counting lower bound.</li><li><strong>Computing on unbounded inputs</strong> – DFAs (optional), Turing Machines, equivalence between Turing machines, RAM machines and programming languages, λ calculus (optional), cellular automata (optional)</li><li><strong>Uncomputability</strong> – Universal Turing machine, Halting problem, reductions, Rice’s Theorem. Optional: Gödel’s incompleteness theorem, uncomputability of quantified arithmetic statements, context free grammars.</li><li><strong>Efficient computation</strong> – Modeling running time, time hierarchy theorem,  <strong>P</strong> and <strong>EXP</strong></li><li><strong>NP and NP completeness</strong> – Polynomial-time reductions, Cook-Levin Theorem (using circuits), definition of <strong>NP</strong> using “proof system”/”verifying algorithms” (no non-deterministic TMs), <strong>NP</strong> completeness, consequences of <strong>P</strong>=<strong>NP</strong>: search to decision, optimal machine learning, etc..</li><li><strong>Randomized computation:</strong> Worst-case randomized computation, defining <strong>BPP</strong>,  Sipser-Gács, does <strong>BPP</strong>=<strong>P</strong>? (a little on derandomization)</li><li><strong>Cryptography:</strong> One time pad, necessity of long keys for information theoretic crypto,  pseudorandom generators and stream ciphers, taste of public key and “magic” (ZKP, FHE, MPC)</li><li><strong>Quantum computing:</strong> Some quantum mechanics background – double slit experiment,  Bell’s inequality. Modeling quantum computation. Bird’s eye view of Shor’s algorithm and quantum Fourier transform.</li></ol>



<p/></div>
    </content>
    <updated>2020-07-10T17:29:02Z</updated>
    <published>2020-07-10T17:29:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-07-12T10:20:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17276</id>
    <link href="https://rjlipton.wordpress.com/2020/07/10/ron-graham-1935-2020/" rel="alternate" type="text/html"/>
    <title>Ron Graham, 1935–2020</title>
    <summary>Ron Graham passed away, but he lives on… Cropped from tribute by Tom Leighton Ron Graham just passed away Monday at the age of in La Jolla near UCSD. Today Ken and I wish to say a few words about Ron. Tributes are being written as we write, including this from the Simons Foundation. Here […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Ron Graham passed away, but he lives on…</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/07/grahamjuggling.jpg"><img alt="" class="alignright wp-image-17278" height="128" src="https://rjlipton.files.wordpress.com/2020/07/grahamjuggling.jpg?w=175&amp;h=128" width="175"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from <a href="https://securityboulevard.com/2020/07/ronald-graham-and-the-magic-of-math/">tribute</a> by Tom Leighton</font></td>
</tr>
</tbody>
</table>
<p>
Ron Graham just passed away Monday at the age of <img alt="{84}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B84%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{84}"/> in La Jolla near UCSD. </p>
<p>
Today Ken and I wish to say a few words about Ron.</p>
<p>
Tributes are being written as we write, including <a href="https://www.simonsfoundation.org/2016/01/11/ronald-graham/">this</a> from the Simons Foundation. Here is the American Mathematical Society <a href="https://www.ams.org/news?news_id=6244">announcement</a>, which we saw first: </p>
<blockquote><p><b> </b> <em> Ron Graham, a leader in discrete mathematics and a former president of both the AMS (1993-1994) and the MAA (2003-2004), died on July 6. He was 84. Graham published more than 350 papers and books with many collaborators, including more than 90 with his wife, Fan Chung, and more than 30 with Paul Erdős. He was known for his infectious enthusiasm, his originality, and his accessibility to anyone who had a mathematics question. </em>
</p></blockquote>
<p/><p>
A <a href="https://www.bradyharanblog.com/blog/the-day-i-met-ron-graham">tribute</a> by Brady Haran embeds several short videos of Ron and his work. Fan’s own <a href="http://www.math.ucsd.edu/~fan/ron/">page</a> for Ron has much more. We have made a collage of images from his life:</p>
<p/><p><br/>
<a href="https://rjlipton.files.wordpress.com/2020/07/rongrahamcollage.jpg"><img alt="" class="aligncenter size-full wp-image-17279" src="https://rjlipton.files.wordpress.com/2020/07/rongrahamcollage.jpg?w=600"/></a></p>
<p/><p><br/>
Ron was special and will be greatly missed by all. We at GLL send our thoughts to his dear wife, Fan. Ken and I knew Ron for many years. Ken knew Ron since a visit to Bell Labs in the 1980s and meeting Fan too at STOC 1990. I knew Ron since I was at Yale in the 1970’s—a long time ago. I recall fondly meeting him for the first time when he was at Bell Labs.</p>
<p>
</p><p/><h2> Some Stories </h2><p/>
<p/><p>
Ken and I thought we would give some personal stories about Graham. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Ken’s story is told <a href="https://rjlipton.wordpress.com/2013/03/28/happy-100th-birthday-paul-erdos/">here</a>. In breaking a confidence by telling Erdős the secret about Bobby Fischer recounted there, Ken hoped that it would spread behind the scenes to enough people that Fischer would be less blamed for failing to play Anatoly Karpov in 1975. Since Erdős was staying with the Grahams, presumably it would have emerged there. The social excursion during STOC 1990 was a dinner cruise in Baltimore’s harbor. Ron and Fan and Ken found each other right away, and some questions to Ken about chess quickly went to the Fischer topic. At least Ken knows the secret was retold at least once. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Ron told me once that he was the accountant for Erdős. One of Ron’s jobs was to keep track of the prize money that Erdős owed. Ron would send out the checks to whoever solved the next problem. One of the brilliant insights of Erdős was to make the problems hard, but at least some where solvable. Ron told me that for years no one would actually cash the checks. They would frame them and proudly display them.</p>
<p/><p>
<a href="https://rjlipton.files.wordpress.com/2020/07/check.png"><img alt="" class="aligncenter wp-image-17280" height="102" src="https://rjlipton.files.wordpress.com/2020/07/check.png?w=220&amp;h=102" width="220"/></a></p>
<p/><p><br/>
Ron said that he liked this for the obvious reason—less cash for Erdős to have to pay. But the advent of color xerox machines in the 1970’s changed this. He told me that people began cashing the checks and displaying the color copy. Bummer.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> My first talk at Bell Labs was on my work on the planar separator theorem—joint work with Bob Tarjan. At the beginning of the talk I saw that Ron had a pile of papers on his desk. He was a manager and I guessed he had some paper work to do. I gave my talk. At the end I when up to Ron in the back and he said:</p>
<blockquote><p><b> </b> <em> I did not get any work done. </em>
</p></blockquote>
<p/><p>
I still fondly remember that as high praise. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> Graham loved to do hand stands. I recall walking around Bell Labs one day when out of the blue Ron did a full handstand. He said that he liked to do these on the hand rail of the stairs. The trick he said was: “To not fall down.” </p>
<p/><p><br/>
<a href="https://rjlipton.files.wordpress.com/2020/07/well.jpg"><img alt="" class="aligncenter size-full wp-image-17281" src="https://rjlipton.files.wordpress.com/2020/07/well.jpg?w=600"/></a></p>
<p/><p><br/>
I searched for him doing handstands and found out he and Fan lived in a modern beautiful <a href="http://www.math.ucsd.edu/~fan/home/">house</a>. </p>
<blockquote><p><b> </b> <em> When two mathematicians found a circular home designed by architect Kendrick Bangs Kellogg in La Jolla, they treasured their unique discovery. </em>
</p></blockquote>
<p/><p><br/>
<a href="https://rjlipton.files.wordpress.com/2020/07/home1.jpg"><img alt="" class="aligncenter size-full wp-image-17283" src="https://rjlipton.files.wordpress.com/2020/07/home1.jpg?w=600"/></a></p>
<p>
</p><p/><h2> Fun and Games </h2><p/>
<p/><p>
Ron kept a simply organized <a href="http://www.math.ucsd.edu/~ronspubs/">page</a> of all his papers. They are not sorted by subject or kind, but the titles are so descriptive that you can tell at a glance where the fun is. A number of them are expositions in the popular magazines of the AMS and MAA. </p>
<p>
Among them, we’ll mention this <a href="http://www.math.ucsd.edu/~ronspubs/16_02_insert_and_add.pdf">note</a> from 2016, titled “Inserting Plus Signs and Adding.” It is joint with Steve Butler, who penned his own <a href="https://blog.computationalcomplexity.org/2020/07/reflections-on-ronald-graham-by-steve.html">reminiscence</a> for Lance and Bill’s blog, and Richard Strong. </p>
<p>
Say that a number <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> is “reducible” to a number <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> in one step (in base <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/>) if there is a way to insert one or more <img alt="{+}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+}"/> signs into the base-<img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/> representation of <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> so that the resulting numbers add up to <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/>. For example, 1935 is reducible to 99 via <img alt="{1 + 93 + 5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%2B+93+%2B+5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1 + 93 + 5}"/>. The number 99 reduces only to 18 via <img alt="{9+9}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B9%2B9%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{9+9}"/>, and 18 reduces only to 9, which cannot be reduced further. Thus Ron’s birth year took <img alt="{3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{3}"/> reduction steps to become a single digit. However, doing <img alt="{1+9+3+5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2B9%2B3%2B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1+9+3+5}"/> gives 18 straightaway and thus saves a step. The paper gives cases where inserting <img alt="{+}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+}"/> everywhere is <em>not</em> a quickest way to reduce to a single digit.</p>
<blockquote><p><b>Definition 1</b> <em> For any base <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{b}"/> and number <img alt="{n \geq 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cgeq+1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n \geq 1}"/> denoting an input <b>length</b>, not magnitude, define <img alt="{f_b(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_b%28n%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f_b(n)}"/> to be the least integer <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{m}"/> such that all base-<img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{b}"/> numbers of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> can be reduced to a single digit within <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{m}"/> steps. </em>
</p></blockquote>
<p/><p>
The question—of a complexity theoretic nature—is:</p>
<blockquote><p><b> </b> <em> Given <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{b}"/>, what is the growth rate of <img alt="{f_b(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_b%28n%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f_b(n)}"/> as <img alt="{n \rightarrow \infty}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n \rightarrow \infty}"/>? </em>
</p></blockquote>
<p/><p>
Here are some possible answers—which would you expect to be correct in the case where <img alt="{b}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b}"/> is base 10?</p>
<ul>
<li>
<img alt="{f_{10}(n) = \Theta(\sqrt{n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B10%7D%28n%29+%3D+%5CTheta%28%5Csqrt%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{10}(n) = \Theta(\sqrt{n})}"/>. <p/>
</li><li>
<img alt="{f_{10}(n) = \Theta(n^{1/10})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B10%7D%28n%29+%3D+%5CTheta%28n%5E%7B1%2F10%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{10}(n) = \Theta(n^{1/10})}"/>. <p/>
</li><li>
<img alt="{f_{10}(n) = O(\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B10%7D%28n%29+%3D+O%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{10}(n) = O(\log n)}"/>. <p/>
</li><li>
<img alt="{f_{10}(n) = O(\log\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B10%7D%28n%29+%3D+O%28%5Clog%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{10}(n) = O(\log\log n)}"/>. <p/>
</li><li>
<img alt="{f_{10}(n) = O(\alpha(n))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B10%7D%28n%29+%3D+O%28%5Calpha%28n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{10}(n) = O(\alpha(n))}"/>, where <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/> is the inverse Ackermann <a href="https://en.wikipedia.org/wiki/Ackermann_function#Inverse">function</a>.
</li></ul>
<p>
Your expectation might be wrong—see the paper for the answer and its nifty proof. For a warmup, if you want to answer without looking at the paper, prove that the final reduced digit is the same regardless of the sequence of reductions.</p>
<p>
Ron is also known for very big integers, including <a href="https://en.wikipedia.org/wiki/Graham's_number">one</a> that held the record for largest to appear in a published mathematical proof. You can find it among the above tributes and also on a <a href="https://www.zazzle.com/store/grahamsnumber">T-shirt</a>.  We could also mention his role in the largest <a href="https://news.slashdot.org/story/16/05/30/2241225/computer-generates-largest-math-proof-ever-at-200tb-of-data">proof</a> known to date—at 200 terabytes it almost doubles the size of the <a href="http://tb7.chessok.com/">tables</a> for proving results of seven-piece chess endgames.</p>
<p>
If you desire serious fun, look also to Ron’s books. He wrote several, including co-authoring the nonpareil <a href="https://en.wikipedia.org/wiki/Concrete_Mathematics">textbook</a> <em>Concrete Mathematics</em> with Don Knuth and Oren Patashnik.</p>
<p>
</p><p/><h2> Some Prizes </h2><p/>
<p/><p>
Ron, in the tradition famously followed by Erdős, liked to put <a href="https://www.quantamagazine.org/cash-for-math-the-erdos-prizes-live-on-20170605/">money</a> on problems. A $10 dollar problem was much easier than a $100 one. A $1,000 one is extremely hard, and so on. In Ron’s paper on his favorite <a href="http://www.math.ucsd.edu/~ronspubs/20_02_favorite.pdf">problems</a> he stated this one: </p>
<blockquote><p><b> </b> <em> Let <img alt="{H_{n} = \sum_{j=1}^{n} \frac{1}{j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH_%7Bn%7D+%3D+%5Csum_%7Bj%3D1%7D%5E%7Bn%7D+%5Cfrac%7B1%7D%7Bj%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{H_{n} = \sum_{j=1}^{n} \frac{1}{j}}"/>. Challenge: prove the inequality for all <img alt="{n \ge 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cge+1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n \ge 1}"/>, </em></p><em>
<p align="center"><img alt="\displaystyle  \sum_{d | n} d \le H_{n} + \exp(H_{n})\log(H_{n}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bd+%7C+n%7D+d+%5Cle+H_%7Bn%7D+%2B+%5Cexp%28H_%7Bn%7D%29%5Clog%28H_%7Bn%7D%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  \sum_{d | n} d \le H_{n} + \exp(H_{n})\log(H_{n}). "/></p>
</em><p><em>	 </em>
</p></blockquote>
<p/><p>
And he put the prize at $1,000,000. He added:</p>
<blockquote><p><b> </b> <em/></p><em>
</em><p><em>
Why is this reward so outrageous? Because this <a href="https://arxiv.org/pdf/math/0008177.pdf">conjecture</a> is equivalent to the Riemann Hypothesis! A single <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> violating would imply there are infinitely many zeroes of the Riemann zeta function off the critical line <img alt="{R(z) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BR%28z%29+%3D+1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{R(z) = 1}"/>. Of course, the $1,000,000 prize is not from me but rather is offered by the Clay Mathematics Institute since the Riemann Hypothesis is one of their six remaining Millennium Prize Problems. We hope to live to see progress in the Challenges and Conjectures mentioned in this note, especially the last one! </em>
</p></blockquote>
<p/><p>
Alas Ron did not get to see this resolved. Nor of course did Erdős, nor may any of us. But Ron is prominently mentioned on another Simons <a href="https://www.simonsfoundation.org/2015/12/10/new-erdos-paper-solves-egyptian-fraction-problem/">page</a> where Erdős lives on, and so may Ron.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Ron died at age <img alt="{84}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B84%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{84}"/>. Perhaps he liked that it is the sum of a twin prime <img alt="{41 + 43}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B41+%2B+43%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{41 + 43}"/>, and also three times a perfect number. We will always remember <img alt="{84}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B84%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{84}"/> because of Ron.  <b>Added 7/10:</b> <img alt="{84}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B84%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{84}"/> is also his current h-index <a href="https://scholar.google.com/citations?user=qrPaF3QAAAAJ&amp;hl=en&amp;oi=sra&amp;fbclid=IwAR2Tx1GkRQ6-6K-hlumvpBqWUku2Msea6_dybwrYK8tVeNUuYOD6czZ24ZY">according to</a> Google Scholar.  HT in <a href="https://rjlipton.wordpress.com/2020/07/10/ron-graham-1935-2020/#comment-111482">comment</a>.</p>
<p>
[some word changes, update about h-index]</p></font></font></div>
    </content>
    <updated>2020-07-10T16:08:04Z</updated>
    <published>2020-07-10T16:08:04Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Teaching"/>
    <category term="trick"/>
    <category term="Fan Chung Graham"/>
    <category term="games"/>
    <category term="in memoriam"/>
    <category term="number theory"/>
    <category term="Paul Erdos"/>
    <category term="Ron Graham"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-07-12T10:20:40Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/102</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/102" rel="alternate" type="text/html"/>
    <title>TR20-102 |  Notes on Hazard-Free Circuits | 

	Stasys Jukna</title>
    <summary>The problem of constructing hazard-free Boolean circuits (those avoiding electronic glitches) dates back to the 1940s and is an important problem in circuit design. Recently, Ikenmeyer et al. [J. ACM, 66:4 (2019), Article 25] have shown that the hazard-free circuit complexity of any Boolean function $f(x)$ is lower-bounded by the monotone circuit complexity of the monotone Boolean function which accepts an input $x$ iff $f(z)=1$ for some vector $z\leq x$. We give a short and amazingly simple proof of this interesting result. We also show that a circuit is hazard-free if and only if the circuit and its dual produce (purely syntactically) all prime implicants of the functions they compute. This extends a classical result of Eichelberger [IBM J. Res. Develop., 9 (1965)] showing this property for depth-two circuits producing no terms containing a variable together with its negation. Finally, we give a very simple non-monotone Boolean function whose hazard-free circuit complexity is super-polynomially larger than its unrestricted circuit complexity.</summary>
    <updated>2020-07-09T19:01:07Z</updated>
    <published>2020-07-09T19:01:07Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-12T10:20:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-713901807945793095</id>
    <link href="https://blog.computationalcomplexity.org/feeds/713901807945793095/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/reflections-on-ronald-graham-by-steve.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/713901807945793095" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/713901807945793095" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/reflections-on-ronald-graham-by-steve.html" rel="alternate" type="text/html"/>
    <title>Reflections on Ronald Graham by Steve Butler</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div>
<i>Ronald Graham passed away on July 6 at the age of 84. We present reflections on Ronald Graham by </i><i>Steve Butler.</i></div>
<div>
<i><br/></i></div>
<hr/>
<div>
<br/></div>
<div>
Getting to work with Ron Graham</div>
<div>
<br/></div>
<div>
Ron Graham has helped transform the mathematics community and in particular been a leader in discrete mathematics for more than 50 years. It is impossible to fully appreciate the breadth of his work in one sitting, and I will not try to do so here. Ron has put his papers online and made them <a href="http://www.math.ucsd.edu/~ronspubs/">freely available</a>, a valuable treasure; and there are still many a hidden gem inside of these papers that are waiting to be picked up, polished, and pushed further.</div>
<div>
<br/></div>
<div>
I want to share about how I got to know and work with Ron. To be fair I knew about Ron long before I ever knew Ron. He was that rare pop-star mathematician who had managed to reach out and become visible outside of the mathematical community. And so as a teenager I read about Ron in a book about Erdos. I thought to myself that this guy sounds really cool and someday I might even get to see him give a talk (if I was lucky).</div>
<div>
<br/></div>
<div>
I went to UC San Diego for graduate school and after a series of near-misses ended up studying under Fan Chung. I passed Ron in the stairwell once, and then also helped them move some furniture between their two adjoining homes (graduate students are great for manual labor). But I became determined to try and find a way to start a conversation with Ron and maybe work up to working on a problem. So I took the usual route: I erased the chalkboards for him.</div>
<div>
<br/></div>
<div>
Before his class on discrete mathematics would start, I would come in and clean the chalkboards making them pristine. It also gave me time to occasionally engage in some idle chat, and he mentioned that his papers list was far from complete. I jumped on it and got to work right away and put his papers online and have been maintaining that list for the last fifteen years. This turned out to be no small feat and required about six months of work.  Many papers had no previous online version, and there were even a few papers that Ron had written that he had forgotten about! But this gave me a reason to come to Ron and talk with him about his various papers and then he would mention some problems he was working on with others and where they were stuck and thought I might give them a try.</div>
<div>
<br/></div>
<div>
So I started to work on these problems and started to make progress. And Ron saw what I was able to do and would send me more problems that fit my abilities and interests, and I would come back and show him partial solutions, or computations, and then he would often times fill in the gaps. He was fun to work with, because we almost always made progress; even when we didn't make progress we still understood things more fully. Little by little our publications (and friendship) grew and we now have 25+ joint publications, and one more book that will be coming out in the next few years about the enumerating juggling patterns.</div>
<div>
<br/></div>
<div>
After all of that though, I discovered something. I could have just gone to Ron's door and knocked and he would have talked to me, and given me problems (though our friendship would not become so deep if I had chosen the forthright method). But almost no graduate students in math were brave enough to do it; they were scared off by his reputation. As a consequence, Ron had far fewer math graduate students than you would expect. (To any math graduate student out there, don't let fear stop you from talking with professors; many of them are much nicer than you think, and the ones that are not nice are probably not that great to work with.)</div>
<div>
<br/></div>
<div>
So one of the most important lessons I learned from Ron was the importance of kindness. Ron was generous and kind to everyone (and I really stress the word everyone) that he met. It didn't matter what walk of life you were in, what age you were, or what level of math (if any) that you knew, he was kind and willing to share his time and talents. He always had something in reach in his bag or pocket that he could pull out and show someone and give them an unexpected sense of wonder.</div>
<div>
<br/></div>
<div>
Richard Hamming <a href="https://www.cs.virginia.edu/~robins/YouAndYourResearch.html">once said</a> "you can be a nice guy or you can be a great scientist", the implication being that you cannot do both. Ron showed that you can be a nice guy and a great scientist. And I believe that a significant portion of his success is owed to his being kind; all of us should learn from his examples and show more kindness towards others.</div>
<div>
<br/></div>
<div>
This is only one of many lessons I learned from Ron. Another thing I learned from Ron is the importance of data. I have seen multiple times when we would work on a problem and generate data resulting in what I thought were hopeless numbers to understand. But Ron looked at that same data and with a short bit of trial and error was able to make a guess of what the general form was. And almost inevitably he would be right! One way that Ron could do this was to start by factoring the values, and if all the prime factors were small he could guess that the expression was some combination of factorials and powers and then start to play with expressions until things worked out. Even when I knew what he did, I still am amazed that he was able to do it.</div>
<div>
<br/></div>
<div>
I will miss Ron, I will never have a collaboration as deep, as meaningful, and as personal. I am better for having worked with him, and learning from him about how to be a better mathematician and a better person.</div>
<div>
<br/></div>
<div>
Thank you, Ron.</div></div>
    </content>
    <updated>2020-07-09T15:57:00Z</updated>
    <published>2020-07-09T15:57:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-07-12T08:06:06Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1361</id>
    <link href="https://ptreview.sublinear.info/?p=1361" rel="alternate" type="text/html"/>
    <title>Policy on reporting papers</title>
    <summary>While we at PTReview always look through the posted papers, we do not check for correctness. We make a serious attempt to make sure the paper is reasonable. In a few instances, we have decided not to post a (topically relevant) paper, because it looks absolutely wrong. Our position is: the benefit of doubt goes […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>While we at PTReview always look through the posted papers, we do not check for correctness. We make a serious attempt to make sure the paper is reasonable. In a few instances, we have decided not to post a (topically relevant) paper, because it looks absolutely wrong. Our position is: the benefit of doubt goes to the author, and a borderline paper should be posted. We are only curating relevant tech reports, not passing judgment on results. </p>



<p>In some borderline cases, readers familiar with the subject complained to us that the paper should be not be considered a scientific contribution (because of, say, unspecified algorithms, blatantly incorrect or unverifiable central claims). These are cases where we were also unsure of the paper. We have usually removed/not posted such papers.</p>



<p><strong>If the paper author(s) feels that his/her paper should nonetheless be posted, then they should email us at little.oh.of.n@gmail.com.</strong> As long as the paper is not complete nonsense and appears to cite relevant history, we will defer to the authors’ wishes.</p></div>
    </content>
    <updated>2020-07-09T00:38:05Z</updated>
    <published>2020-07-09T00:38:05Z</published>
    <category term="Announcement"/>
    <author>
      <name>Seshadhri</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2020-07-11T23:40:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4399</id>
    <link href="https://lucatrevisan.wordpress.com/2020/07/08/silver-linings/" rel="alternate" type="text/html"/>
    <title>Silver linings</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">To put it mildly, 2020 is not shaping up to be a great year, so it is worthwhile to emphasize the good news, wherever we may find them. Karlin, Klein, and Oveis Gharan have just posted a paper in which, … <a href="https://lucatrevisan.wordpress.com/2020/07/08/silver-linings/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>To put it mildly, 2020 is not shaping up to be a great year, so it is worthwhile to emphasize the good news, wherever we may find them.</p>
<p>Karlin, Klein, and Oveis Gharan have just <a href="https://arxiv.org/abs/2007.01409">posted a paper</a> in which, at long last, they improve over the 1.5 approximation ratio for metric TSP which was achieved, in 1974, by Christofides. For a long time, it was suspected that the Held-Karp relaxation of metric TSP had an approximation ratio better than 1.5, but there was no viable approach to prove such a result. In 2011, two different approaches were developed to improve 1.5 in the case of shortest-path metrics on unweighted graphs: one by Oveis Gharan, Saberi and Singh and one by Momke and Svensson. The algorithm of Karlin, Klein and Oveis Gharan (which does not establish that the Held-Karp relaxation has an integrality gap better than 1.5) takes as a starting point ideas from the work of Oveis Gharan, Saberi and Singh. </p>
<p><span id="more-4399"/></p>
<p>Yesterday, Bloom and Sisask <a href="https://arxiv.org/abs/2007.03528">posted a paper</a> in which they show that there is a constant <img alt="c&gt;0" class="latex" src="https://s0.wp.com/latex.php?latex=c%3E0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c&gt;0"/> such that, for every sufficiently large <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/>, if <img alt="A \subseteq \{1,\ldots, N \}" class="latex" src="https://s0.wp.com/latex.php?latex=A+%5Csubseteq+%5C%7B1%2C%5Cldots%2C+N+%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A \subseteq \{1,\ldots, N \}"/> has cardinality at least <img alt="N / (\log N)^{1+c}" class="latex" src="https://s0.wp.com/latex.php?latex=N+%2F+%28%5Clog+N%29%5E%7B1%2Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N / (\log N)^{1+c}"/>, then <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> contains a non-trivial length-3 arithmetic progression. Without context, this may seem like a strange result to get excited about, but it sits at the nexus of a number of fundamental results and open questions in combinatorics. Gil Kalai <a href="https://gilkalai.wordpress.com/2020/07/08/to-cheer-you-up-in-difficult-times-7-bloom-and-sisask-just-broke-the-logarithm-barrier-for-roths-theorem/">has written an excellent post</a> telling the story of this problem, so instead of writing a worse version of it I will refer the reader to Gil’s blog.</p>
<p>Back to bad news, the day after Harvard announced that it would deliver courses online only in 2020-21, the Trump administration announced that it would void student visas of students who are not attending in-person classes in 2020-21. Back to good news, Harvard and MIT announced that they will sue the federal government over this, and other universities, including the University of California system, are planning similar responses. Apart from the action, I was really heartened to read MIT’s President <a href="http://news.mit.edu/2020/mit-and-harvard-file-suit-against-new-ice-regulations-0708">statement on the matter</a> (thanks to Vinod Vaikuntanathan for bringing it my attention) which is worth reproducing:</p>
<blockquote><p>
To the members of the MIT community,</p>
<p>On Monday, in a surprising development, a division of Immigration and Customs Enforcement announced that it will not permit international students on F-1 visas to take a full online course load this fall while studying in the United States. As I wrote yesterday, this ruling has potentially serious implications for MIT’s international students and those enrolled at institutions across the country.</p>
<p>This morning, in response, MIT and Harvard jointly filed suit against ICE and the US Department of Homeland Security in federal court in Massachusetts. In the lawsuit, we ask the court to prevent ICE and DHS from enforcing the new guidance and to declare it unlawful.</p>
<p>The announcement disrupts our international students’ lives and jeopardizes their academic and research pursuits. ICE is unable to offer the most basic answers about how its policy will be interpreted or implemented. And the guidance comes after many US colleges and universities either released or are readying their final decisions for the fall – decisions designed to advance their educational mission and protect the health and safety of their communities.</p>
<p>Our international students now have many questions – about their visas, their health, their families and their ability to continue working toward an MIT degree. Unspoken, but unmistakable, is one more question: Am I welcome?</p>
<p>At MIT, the answer, unequivocally, is yes.</p>
<p>MIT’s strength is its people – no matter where they come from. I know firsthand the anxiety of arriving in this country as a student, excited to advance my education, but separated from my family by thousands of miles. I also know that welcoming the world’s brightest, most talented and motivated students is an essential American strength.</p>
<p>While we pursue legal protections for our international students, we will continue to stay in close touch with them through email and updates on the International Students Office’s website. If you have questions, you may write to the ISO at iso-help@mit.edu.</p>
<p>Sincerely,</p>
<p>L. Rafael Reif
</p></blockquote>
<p>This way of talking like a human being, and like you actually care about the matter at hand, is a big contrast with the robotic statements that usually come out of campus leadership. The corresponding message from UC Berkeley’s Chancellor is the way such statements usually are like:</p>
<blockquote><p>
Dear campus community,</p>
<p>Yesterday, the Department of Homeland Security issued new guidance to universities related to international students and fall instruction requirements. The guidance is deeply concerning: it could potentially force the return of many international students to their home countries if they are unable to find the appropriate balance of in-person and remote classes. These requirements run counter to our values of being an inclusive community and one that has a long tradition of welcoming international students from around the globe. International students enrich campus life immeasurably, through their participation in classes, research collaborations and extracurricular activities.</p>
<p>We will explore all of our options, legal and otherwise, to counter the deleterious effects of these policies that imp act the ability for international students to achieve their academic goals. It is not only important for UC Berkeley but for all of higher education across the U.S. to take every step possible to mitigate these policies that send a message of exclusion to our international community of scholars. We will partner with our professional associations to advocate for sound legislation that continues to support international educational exchange.</p>
<p>More immediately, we are working with colleagues across our campus to identify a path that will allow us to comply with these requirements while ensuring a healthy learning environment, and paying attention to the needs of our international students. We recognize the concern and anxiety these new rules have created, and we are moving quickly to ensure that we offer the proper balance of online and in-person classes so that our students can remain in the U.S. and satisfy their visa requirements, and that those students residing outside the U.S. can maintain their enrollment status.</p>
<p>We expect to announce more details soon. Should you have any questions, please contact the Berkeley International Office at internationaloffice@berkeley.edu.</p>
<p>Sincerely,</p>
<p>Carol Christ<br/>
Chancellor</p>
<p>Lisa Alvarez-Cohen<br/>
Vice Provost for Academic Planning and Senior International Officer
</p></blockquote>
<p>It is interesting to think about where this difference in tone is coming from. Carol Christ is a renown humanities scholar who, I suppose, writes well. She comes across as charismatic and caring, and she is definitely straight-talking in person. Probably, as for everything else, Berkeley has a byzantine process to create announcements and press releases, and if Stephen Colbert was the Chancellor of UC Berkeley, after a couple of weeks on the job he would sound just as <i>deeply concerned</i> and just as into <i>exploring all options</i>, while meanwhile <i>working to identify a path</i> and <i>paying attention</i> about something that is totally fucked up and needs action <i>today</i>.</p>
<p>Which brings me to all the statements in support of Black Lives Matter that have been coming out of every scholarly institution in the last few days. While their messages are generally unobjectionable, there is a certain sameness to their form (“we say their names…”, “we will do the work…”, “we see you…”) and they don’t sound at all like the way the people putting them out speak. This has complicated causes, including the fact that many such statements came out of letter-writing campaigns that demanded statements in a very specific way, without leaving a lot of room for individual expression. The association of American Poets, for example, put out a statement of solidarity with the Black community; in response, a <a href="https://www.nytimes.com/2020/06/09/books/poetry-foundation-black-lives-matter.html">letter with 1800 signatories</a> claimed that it was too weak a statement and that it was, in fact, itself an act of violence against Black people; several resignations followed. The Board of the National Book Critics Circle was working on such a statement, and the work devolved into acrimony and several rounds of “I am outraged and I resign,” “no <i>I</i> am outraged at your outrage and <i>I</i> resign, “well then <i>I</i> am outraged that you are outraged at her outrage” until almost the whole board was gone in a “<a href="https://www.vulture.com/2020/06/national-book-critics-circle-resignations.html">sequence of events [that] was bizarre and bloody in an end-of-a-Tarantino-movie way</a>.”</p>
<p>Also, people in America talk about race the way UC Berkeley administrators talk about anything, that is extremely carefully and vacuously. But, back to the statements about foreign students, the difference between the administrative cultures at MIT and Berkeley is not the only difference between the statements of Reif and Christ: clearly a big difference is that Reif is an immigrant himself. When Trayvon Martin was killed, Obama talked about the killing in a way that was very different, and much more meaningful, than other politicians: if I had a son, Obama said, he would look a lot like Trayvon. If there were more people of color in positions of academic leadership, I think that we would have seen an academic response to Black Lives Matter that would have been less fearful, dogmatic and robotic and more meaningful and productive. Or perhaps we would have all ended up like the National Book Critic Circle, it’s hard to say.</p></div>
    </content>
    <updated>2020-07-08T21:11:06Z</updated>
    <published>2020-07-08T21:11:06Z</published>
    <category term="Berkeley"/>
    <category term="philosophy"/>
    <category term="things that are excellent"/>
    <category term="things that are terrible"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2020-07-12T10:20:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=14203</id>
    <link href="https://gilkalai.wordpress.com/2020/07/08/to-cheer-you-up-in-difficult-times-7-bloom-and-sisask-just-broke-the-logarithm-barrier-for-roths-theorem/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 7: Bloom and Sisask just broke the logarithm barrier for Roth’s theorem!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Thomas Bloom and Olof Sisask: Breaking the logarithmic barrier in Roth’s theorem on arithmetic progressions,    arXiv:200703528   Once again Extraordinary news regarding Roth Theorem! (I thank Ryan Alweiss for telling me about it and Rahul Santhanam for telling me … <a href="https://gilkalai.wordpress.com/2020/07/08/to-cheer-you-up-in-difficult-times-7-bloom-and-sisask-just-broke-the-logarithm-barrier-for-roths-theorem/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><img alt="rothnew" class="alignnone size-full wp-image-19954" src="https://gilkalai.files.wordpress.com/2020/07/rothnew.png?w=640"/></p>
<h3 class="title mathjax">Thomas Bloom and Olof Sisask: <a href="https://arxiv.org/abs/2007.03528">Breaking the logarithmic barrier in Roth’s theorem on arithmetic progressions,    arXiv:200703528</a></h3>
<p> </p>
<p>Once again Extraordinary news regarding Roth Theorem! (I thank Ryan <span class="qu"><span class="gD">Alweiss for telling me about it and </span></span>Rahul Santhanam for telling me about Thomas and Olof’s earlier attempts.)</p>
<p>Suppose that <img alt="R_n" class="latex" src="https://s0.wp.com/latex.php?latex=R_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="R_n"/>  is a subset of <img alt="\{1,2,\dots, n \}" src="http://l.wordpress.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots%2C+n+%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{1,2,\dots, n \}"/> of maximum cardinality not containing an arithmetic progression of length 3. Let <img alt="r_3(n)=|R_n|" class="latex" src="https://s0.wp.com/latex.php?latex=r_3%28n%29%3D%7CR_n%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r_3(n)=|R_n|"/>. Roth proved that <img alt="r_3(n)=o(n)" class="latex" src="https://s0.wp.com/latex.php?latex=r_3%28n%29%3Do%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r_3(n)=o(n)"/>.</p>
<p>A few days ago Thomas Bloom and Olof Sisask proved that for some <img alt="c&gt;0" class="latex" src="https://s0.wp.com/latex.php?latex=c%3E0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c&gt;0"/></p>
<p style="text-align: center;"><img alt="r_3(n) \le \frac {n}{\log^{1+c} n}" class="latex" src="https://s0.wp.com/latex.php?latex=r_3%28n%29+%5Cle+%5Cfrac+%7Bn%7D%7B%5Clog%5E%7B1%2Bc%7D+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r_3(n) \le \frac {n}{\log^{1+c} n}"/></p>
<p>This is an extraordinary result!!! I will tell you a little more about it below.</p>
<h2>Ron Graham</h2>
<p>I just heard yesterday the sad news that <a href="https://en.wikipedia.org/wiki/Ronald_Graham">Ron Graham</a> passed away. Ron was an extraordinary mathematician and an extraordinary person. I first met Ron in Montreal in 1978 and we met many times since then. Ron will be dearly missed.</p>
<h3>Back to the new bounds on Roth’s theorem</h3>
<p>From an abstract of a lecture by Thomas and Olof: “This is the integer analogue of a result of Bateman and Katz for the model setting of vector spaces over a finite field, and the proof follows a similar structure.”</p>
<p>A catchy (weaker) formulation which goes back to Erdos and Turan is:</p>
<p>Let <img alt="a_n" class="latex" src="https://s0.wp.com/latex.php?latex=a_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_n"/> be a sequence of integers so that <img alt="\sum \frac{1}{a_n} = \infty" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csum+%5Cfrac%7B1%7D%7Ba_n%7D+%3D+%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\sum \frac{1}{a_n} = \infty"/>, then the sequence contains an arithmetic progression of length three!!</p>
<p>Bloom and Sisask’s result implies, of course, Van der Korput’s result that the primes contain infinitely many 3-terms arithmetic progression as well as Green’s 2005 result asserting it for every  dense subset of primes.</p>
<p>Szemeredi’s celabrated result extended Roth’s theorem to arithmetic progression of any fixed size, and Green-Tao celebrated 2008 result asserts that the primes (or a dense subsets of primes) contain arithmetic progression of any length. (The case of 3-term AP is so far much simpler for all the results mentioned below.)</p>
<p> </p>
<p>A little more about the history of the problem below the fold</p>
<p><span id="more-14203"/></p>
<h2>Roth, Szemeredi, Heath-Brown, and Bourgain; Salem-Spencer and Behrend.</h2>
<p>Let’s wrire $r_3(n)=n/g(n)$. Roth proved that <img alt="g(n) \ge \log\log n" class="latex" src="https://s0.wp.com/latex.php?latex=g%28n%29+%5Cge+%5Clog%5Clog+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g(n) \ge \log\log n"/>. Szemeredi and Heath-Brown improved it to <img alt="g(n) \ge \log^c n" class="latex" src="https://s0.wp.com/latex.php?latex=g%28n%29+%5Cge+%5Clog%5Ec+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g(n) \ge \log^c n"/> for some <img/>$latex c&gt;0$ (Szemeredi’s argument gave <img alt="c=1/4" src="http://l.wordpress.com/latex.php?latex=c%3D1%2F4&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c=1/4"/>.) Jean Bourgain improved the bound in 1999 to <img alt="c=1/2" class="latex" src="https://s0.wp.com/latex.php?latex=c%3D1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c=1/2"/> and in 2008 to <img alt="c=3/4" class="latex" src="https://s0.wp.com/latex.php?latex=c%3D3%2F4&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c=3/4"/> (up to lower order terms).</p>
<p>Erdös and Turan who posed the problem in 1936 described a set not containing an arithmetic progression of size <img alt="n^c" src="http://l.wordpress.com/latex.php?latex=n%5Ec&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n^c"/>.  Salem and Spencer improved this bound to <img alt="g(n) \le e^{logn/ loglogn}" src="http://l.wordpress.com/latex.php?latex=g%28n%29+%5Cle+e%5E%7Blogn%2F+loglogn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="g(n) \le e^{logn/ loglogn}"/>. Behrend’s upper bound from 1946 is of the form <img alt="g(n) \le e^{C\sqrt {\log n}}" src="http://l.wordpress.com/latex.php?latex=g%28n%29+%5Cle+e%5E%7BC%5Csqrt+%7B%5Clog+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="g(n) \le e^{C\sqrt {\log n}}"/>. A small improvement was achieved  by Elkin and is discussed <a href="https://gilkalai.wordpress.com/2008/07/10/pushing-behrend-around/" rel="noopener" target="_blank" title="Elkin's result">here</a>.  (Look also at the remarks following that post.)</p>
<h2>Sanders</h2>
<p>In 2010 Tom Sanders was able to refine Bourgain’s argument and proved that <img alt="g(n) \ge (\log n)^{3/4}" class="latex" src="https://s0.wp.com/latex.php?latex=g%28n%29+%5Cge+%28%5Clog+n%29%5E%7B3%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g(n) \ge (\log n)^{3/4}"/>. A few month later  <a href="http://arxiv.org/abs/1011.0104">Tom have managed to reach the logarithmic barrier and to prove </a>that</p>
<p><img alt="g(n) \ge (\log n)/(\log \log n)^{6}." class="latex" src="https://s0.wp.com/latex.php?latex=g%28n%29+%5Cge+%28%5Clog+n%29%2F%28%5Clog+%5Clog+n%29%5E%7B6%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g(n) \ge (\log n)/(\log \log n)^{6}."/></p>
<p>We reported about this outstanding achievement in <a href="https://gilkalai.wordpress.com/2010/11/24/roths-theorem-sanders-reaches-the-logarithmic-barrier/">this blog post</a> and quoted from his paper: “There are two main new ingredients in the present work: the first is a way of transforming sumsets introduced by <a href="http://front.math.ucdavis.edu/0802.4371">Nets Katz and Paul Koester</a> in 2008, and the second is a result on the <img alt="L_p" class="latex" src="https://s0.wp.com/latex.php?latex=L_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="L_p"/>-invariance of convolutions due to <a href="http://front.math.ucdavis.edu/1003.2978">Ernie Croot and Olof Sisask</a> (2010).”</p>
<p>The exponent 6 for the loglog term was improved to 4 by Thomas Bloom and recently to 3 by Thomas Schoen in his paper: <a href="https://arxiv.org/abs/2005.01145">Improved bound in Roth’s theorem on arithmetic progressions.</a> Schoen uses ingredients from Bateman and Katz’s work (see below).</p>
<h2>Cap sets  – Meshulam</h2>
<p>A closely related problem  in <img alt="\Gamma=" src="http://l.wordpress.com/latex.php?latex=%5CGamma%3D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Gamma="/><img alt="\{0,1,2\}^n" src="http://l.wordpress.com/latex.php?latex=%5C%7B0%2C1%2C2%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{0,1,2\}^n"/>. It is called the <a href="http://terrytao.wordpress.com/2007/02/23/open-question-best-bounds-for-cap-sets/" rel="noopener" target="_blank" title="Cap sets at Tao">cap set problem</a>. A subset of <img alt="\Gamma" src="http://l.wordpress.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Gamma"/> is called a cap set if it contains no arithmetic progression of size three or, alternatively, no three vectors that sum up to 0(modulo 3). If $latex <img alt="A" src="http://l.wordpress.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A"/>_n$  is a cap set of maximum size in <img alt="\Gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Gamma"/> we can ask how the function <img alt="f(n)=|A_n|" class="latex" src="https://s0.wp.com/latex.php?latex=f%28n%29%3D%7CA_n%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(n)=|A_n|"/> behaves. In 1995 Roy Meshulam proved, using Roth’s argument, that <img alt="f(n) \le 3^n/n" class="latex" src="https://s0.wp.com/latex.php?latex=f%28n%29+%5Cle+3%5En%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(n) \le 3^n/n"/> . Edell found an example of a cap set of size <img alt="2.2^n" src="http://l.wordpress.com/latex.php?latex=2.2%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="2.2^n"/>.  Again the gap is exponential.  What is the truth? Improving Meshulam’s result may be closely related to crossing the <img alt="\log n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clog+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\log n"/> barrier for Roth’s theorem. In 2007 Tom Sanders  <a href="http://arxiv.org/abs/0807.5101">managed to achieve it </a>, not for the cup problem, but for a related problem over Z/4Z.</p>
<h2>Bateman and Katz</h2>
<p>In 2011, <a href="http://front.math.ucdavis.edu/1101.5851" rel="noopener" target="_blank">Michael Bateman and Nets Katz</a> improved, after many years of attempts by many, the Roth-Meshulam bound.  They proved using Fourier methods that <img alt="f(n) \le 3^n/n^{1+c}" class="latex" src="https://s0.wp.com/latex.php?latex=f%28n%29+%5Cle+3%5En%2Fn%5E%7B1%2Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(n) \le 3^n/n^{1+c}"/> for some <img alt="c&gt;0" class="latex" src="https://s0.wp.com/latex.php?latex=c%3E0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c&gt;0"/>! This was very exciting.   See these two posts on Gowers’s blog (<a href="http://gowers.wordpress.com/2011/01/11/what-is-difficult-about-the-cap-set-problem/" rel="noopener" target="_blank">I</a>,<a href="http://gowers.wordpress.com/2011/01/18/more-on-the-cap-set-problem/" rel="noopener" target="_blank">II</a>). This raised the question if the new method allows breaking the  logarithmic barrier for Roth’s theorem.</p>
<h3>Polymath 6</h3>
<p>Tim Gowers <a href="https://gowers.wordpress.com/2011/02/05/polymath6-a-is-to-b-as-c-is-to/">proposed in 2011 polymath6 </a> to try to break the logarithmic barrier for Roth based on the Bateman-Katz breakthrough. (Here is<a href="http://michaelnielsen.org/polymath1/index.php?title=Improving_the_bounds_for_Roth%27s_theorem"> the wiki</a>; and a <a href="https://polymathprojects.org/2011/02/05/polymath6-improving-the-bounds-for-roths-theorem/">related post by Sanders</a>, and a <a href="https://polymathprojects.files.wordpress.com/2011/02/polymath-3.pdf">document by Katz</a>) This project did not get off the ground. We can regard the news as giving support that the polymath6 project was timely and of an appropriate level, and also as giving some support to an advantage of the conventional way of doing mathematics compared to the polymath way.</p>
<h2> Croot-Lev-Pach-Ellenberg-Gijswijt solution to the Cap set problem via the polynomial method</h2>
<p>Next and quite recently came a startling development  – the Croot-Lev-Pach-Ellenberg-Gijswijt capset bound <img alt="f(n) \le 2.756^n" class="latex" src="https://s0.wp.com/latex.php?latex=f%28n%29+%5Cle+2.756%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(n) \le 2.756^n"/>. (Croot, Lev, and Pach gave an exponential improvement for the Z/4Z case (see <a href="https://gilkalai.wordpress.com/2016/05/10/math-from-facebook/">this post</a>) and a few weeks later Ellenberg and Gijswijt used the method for the Z/3Z case (see <a href="https://gilkalai.wordpress.com/2016/05/15/mind-boggling-following-the-work-of-croot-lev-and-pach-jordan-ellenberg-settled-the-cap-set-problem/">this post</a>).)</p>
<p>A natural question that many people asked was how this development relates to improving the bounds for Roth perhaps even towards the Behrend bound. We discussed it a little over here and in other places. This is still an interesting possibility.</p>
<h2>The new result: Bloom and Sisask</h2>
<p>However, just a <del>few months</del> few years after the Bateman-Katz result have become obsolete for the cap-set problem, the Bateman-Katz method prevailed in this wonderful breakthrough of Bloom and Sisask giving <img alt="g(n) \ge \log^c n" class="latex" src="https://s0.wp.com/latex.php?latex=g%28n%29+%5Cge+%5Clog%5Ec+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g(n) \ge \log^c n"/> for <img alt="c&gt;1" class="latex" src="https://s0.wp.com/latex.php?latex=c%3E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c&gt;1"/>.</p>
<h3 style="text-align: center;"><span style="color: #ff0000;">Congratulations!!!</span></h3>
<h2>An old post and poll</h2>
<p>In <a href="https://gilkalai.wordpress.com/2009/03/25/an-open-discussion-and-polls-around-roths-theorem/">an old post we asked</a>: “How does <img alt="r_3(n)" class="latex" src="https://s0.wp.com/latex.php?latex=r_3%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r_3(n)"/> behave? Since we do not really know, will it help talking about it? Can we somehow look beyond the horizon and try to guess what the truth is? (I still don’t know if softly discussing this or other mathematical problems is a fruitful idea, but it can be enjoyable.)” We even had a poll collecting people’s predictions about <img alt="r_3(n)" class="latex" src="https://s0.wp.com/latex.php?latex=r_3%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r_3(n)"/>.  Somewhat surprisingly 18.18% of answerers predicted that <img alt="r_3(n)" class="latex" src="https://s0.wp.com/latex.php?latex=r_3%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="r_3(n)"/> behaves like <img alt="\frac{1}{(\log n)^c}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%28%5Clog+n%29%5Ec%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac{1}{(\log n)^c}"/> for some <img alt="c&lt;1" class="latex" src="https://s0.wp.com/latex.php?latex=c%3C1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c&lt;1"/>.</p>
<p> </p></div>
    </content>
    <updated>2020-07-08T16:00:41Z</updated>
    <published>2020-07-08T16:00:41Z</published>
    <category term="Algebra"/>
    <category term="Combinatorics"/>
    <category term="Updates"/>
    <category term="Olef Sisask"/>
    <category term="Thomas Bloom"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-07-12T10:20:36Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2020/07/08/gain-margin/</id>
    <link href="http://benjamin-recht.github.io/2020/07/08/gain-margin/" rel="alternate" type="text/html"/>
    <title>Margin Walker</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I want to dive into some classic results in robust control and try to relate them to our current data-driven mindset. I’m going to try to do this in a modern way, avoiding any frequency domain analyses.</p>

<p>Suppose you want to solve some optimal control problem: you spend time modeling the dynamics of your system, how it responds to stimuli, and which objectives you’d like to maximize and constraints you must adhere to. Each of these modeling decisions explicitly encodes both your beliefs about reality and your mental criteria of success and failure. <em>Robustness</em> aims to quantify the effects of oversight on your systems behavior. Perhaps your model wasn’t accurate enough, or perhaps you forgot to include some constraint in your objective. What are the downstream consequences?</p>

<p>In the seventies, it was believed that optimization-based frameworks for control had “natural robustness.” The solutions of optimal control problems were often robust to phenomena not explicitly modeled by the engineer. As a simple example, suppose you have an incorrect model of the dynamical system you are trying to steer. How accurate do you need to be in order for this policy to be reasonably successful?</p>

<p>To focus in on this, let’s study the continuous-time linear quadratic regulator (LQR). I know I’ve been arguing that we should  be moving away from LQR in order to understand the broader challenges in learning and control, but the LQR baseline has so many lessons to teach us. Please humor me again for a few additional reasons: First, most of the history I want to tell arises from studying continuous-time LQR in the 1970s. It’s worth understanding that history with a modern perspective. Second, LQR does admit elegant closed form formulae that are helpful for pedagogy, and they are particularly nice in continuous time.</p>

<h2 id="lqr-in-continuous-time">LQR in Continuous Time</h2>

<p>Suppose we have a dynamical system that we model as an ODE:</p>



<p>Here, as always, $x_t$ is the state, $u_t$ is the control input signal, and $A$ and $B$ are matrices of appropriate dimensions. The goal of the continuous-time LQR problem is to minimize the cost functional</p>



<p>over all possible control inputs $u_t$. Let’s assume for simplicity that $Q$ is a positive semidefinite matrix and $R$ is positive definite.</p>

<p>The optimal LQR policy is <em>static state feedback</em>: there is some matrix $K$ such that</p>



<p>for all time. $K$ has a closed form solution that can be found by solving a <em>continuous algebraic Riccatti equation</em> (CARE) for a matrix $P$:</p>



<p>and then setting</p>



<p>Importantly, we take the solution of the CARE where $P$ that is positive definite. If a positive definite solution of the CARE exists, then it is optimal for continuous time LQR. There are a variety of ways to prove this condition is sufficient, including an appeal to dynamic programming in continuous time. A simple argument I like uses the quadratic structure of LQR to derive the necessity of the CARE solution. (I found this argument in <a href="https://www.ece.ucsb.edu/~hespanha/linearsystems/">Joao Hespansha’s book</a>).</p>

<p>Regardless, showing a positive definite CARE solution exists takes considerably more work. It suffices to assume that the pair $(A,B)$ is controllable and the pair $(Q,A)$ is detectable. But proving these conditions are sufficient requires a lot of manipulation of linear algebra, and I don’t think I could cleanly distill a proof into a blog post. I mention this just to reiterate that while LQR is definitely the simplest problem to study, its analysis in continuous time on an infinite time horizon is nontrivial. LQR is not really “easy.” It’s merely the easiest problem in a space of rather hard problems.</p>

<h2 id="gain-margins">Gain margins</h2>

<p>Let’s now turn to robustness. Suppose there is a mismatch between our modeled dynamics and reality. For example, what if the actual system is</p>



<p>for some matrix $B_\star$. Such model mismatches occur all the time. For example, in robotics, we can send a signal “u” to the joint of some robot. This would be some voltage that would need to be linearly transformed into some torque by a motor. It requires a good deal of calibration to make sure that the output of the motor is precisely the force dictated by the voltage output from our controller. Is there a way to guarantee some leeway in the mapping from voltage to torque?</p>

<p>An attractive feature of LQR is that we can quantify precisely how much slack we have directly from the CARE solution. We can use the solution of the CARE to build a <em>Lyapunov function</em> to guarantee stability of the system. Recall that a Lyapunov function is a function $V$ that maps states to real numbers, is nonnegative everywhere, is equal to $0$ only when $x=0$, and whose value is strictly decreasing along any trajectory of a dynamical system. In equations:</p>



<p>If you have a Lyapunov function, then all trajectories must converge to $x=0$: if you are at any nonzero state, the value of $V$ will decrease. If you are at $0$, then you will be at a global minimum of $V$ and hence can’t move to any other state.</p>

<p>Let $P$ be the solution of the CARE and let’s posit that $V(x) = x^\top  P x$ is a Lyapunov function. Since $P$ is positive definite, we have $V(x)\geq 0$ and $V(x)=0$ if and only if $x=0$. To prove that the derivative of the Lyapunov function is negative, we can first compute the derivative:</p>



<p>Note that it is sufficient to show that  $(A-B_\star K)^\top P + P(A-B_\star K)$ is a negative definite matrix as this would prove that the derivative is negative for all nonzero $x_t$. To prove that this expression is negative definite, let’s apply a bit of algebra to generate some sufficient conditions. Using the definition of $K$ and the fact that $P$ solves the CARE gives the following chain of equalities:</p>



<p>Here, the first equality is simply expanding the matrix product. The second equation uses the fact that $P$ is a solution to the CARE. The third equality uses the definition of $K$. The final equation is an algebraic rearrangement.</p>

<p>With this final expression, we can cook up a huge number of conditions under which we get “robustness for free.” First, consider the base case where $B=B_\star$. Since $R$ is positive definite and $Q$ is positive semidefinite, the entire expression is negative definite, and hence we have proven the system is stable.</p>

<p>Second, there is a famous result that LQR has “large gain margins.” The gain margin of a control system is an interval $(t_0,t_1)$ such that for all $t$ in this interval, our control system is stable with the controller $tK$. Another way of thinking about the gain margin is to assume that $B_\star = tB$, and to find the largest interval such that the system $(A,B_\star)$ is stabilized by a control policy $K$. For LQR, there are very large margins: if we plug in the identity $B_\star=tB$, we find that $x^\top  P x$ is a Lyapunov function provided that $t \in (\tfrac{1}{2},\infty)$. LQR control turns out to be robust to a wide range of perturbations to the matrix $B$. Intuitively, it makes sense that if we would like to drive a signal to zero and have more control authority than we anticipated then our policy will still drive the system to zero. This is the range of $t \in [1,\infty)$. The other part of the interval is perhaps more interesting: for the LQR problem, even if we only have half of the control authority we had planned for, we still will successfully stabilize our system from any initial condition.</p>

<p>In discrete time, you can derive similar formulae with essentially the same argument. Unfortunately, the expressions are not as elegant. Also, note that you cannot expect infinite gain margins in discrete time. In continuous time a differential equation $\dot{x}_t = M x_t$ is stable if all of the eigenvalues of $M$ have negative real parts. In discrete time, you need all of the eigenvalues to have magnitude less than $1$. For almost any random set triple $(A,B,K)$, $A-t B K$ is going to have large eigenvalues for $t$ large enough. Nonetheless, you can certainly derive analogous conditions as to which errors are tolerable.</p>

<p>There are a variety of other conditions that can be derived from our matrix expression. Most generally, the control system will be stable provided that</p>



<p>The LQR gain margins fall out naturally from this expression when we assume $B_\star = t B$. However, we can guarantee much more general robustness using this inequality. For example, if we assume that $B_\star = BM$ for some square matrix $M$, then $K$ stabilizes the pair $(A,B_\star)$ if all of the eigenvalues of $M+M^\top $ are greater than $1$.</p>

<p>Perhaps more in line with what we do in machine learning, suppose we are able to collect a lot of data, do some uncertainty quantification, and guarantee a bound $|B-B_\star|_2&lt;\epsilon$. Then as long as</p>



<p>we will be guaranteed stable execution. This expression depends on the matrices $P$, $Q$, and $R$, so it has a different flavor of the infinite gain margin conditions which held irrespective of the dynamics or the cost. Moreover, if $P$ has large eigenvalues, then we are only able to guarantee safe execution for small perturbations to $B$. This foreshadows issues I’ll dive into in later posts. I want to flag here that these calculations reveal some fragilities of LQR: While the controller is always robust to perturbations along the direction of the matrix $B$, you can construct examples where the system is highly sensitive to tiny perturbations orthogonal to $B$. I’ll return in the next post to start to unpack how optimal control has some natural robustness, but it has natural fragility as well.</p></div>
    </summary>
    <updated>2020-07-08T00:00:00Z</updated>
    <published>2020-07-08T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2020-07-11T23:40:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/07/07/postdoc-at-uc-san-diego-apply-by-august-7-2020/</id>
    <link href="https://cstheory-jobs.org/2020/07/07/postdoc-at-uc-san-diego-apply-by-august-7-2020/" rel="alternate" type="text/html"/>
    <title>postdoc at UC San Diego (apply by August 7, 2020)</title>
    <summary>The UCSD CS department created a new postdoc program, modeled after the CI fellows program. To apply, you need to identify a UCSD theory faculty as a mentor, contact them and see if they are interested. If so, both you and the mentor need to apply. The deadline for both applications is Aug 7, so […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The UCSD CS department created a new postdoc program, modeled after the CI fellows program. To apply, you need to identify a UCSD theory faculty as a mentor, contact them and see if they are interested. If so, both you and the mentor need to apply. The deadline for both applications is Aug 7, so time is of the essence.</p>
<p>Website: <a href="https://forms.gle/7mMKS6xmCjWoMT817">https://forms.gle/7mMKS6xmCjWoMT817</a><br/>
Email: shachar.lovett@gmail.com</p></div>
    </content>
    <updated>2020-07-07T21:36:50Z</updated>
    <published>2020-07-07T21:36:50Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-12T10:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/101</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/101" rel="alternate" type="text/html"/>
    <title>TR20-101 |  Lower Bounds for XOR of Forrelations | 

	Uma Girish, 

	Ran Raz, 

	Wei Zhan</title>
    <summary>The Forrelation problem, first introduced by Aaronson [AA10] and Aaronson and Ambainis [AA15], is  a well studied computational problem in the context of separating quantum and classical computational models. Variants of this problem were used to give tight separations between quantum and classical query complexity [AA15]; the first separation between poly-logarithmic quantum query complexity and bounded-depth circuits of super-polynomial size, a result that also implied an oracle separation of the classes BQP and PH [RT19]; and improved separations between quantum and classical communication complexity [GRT19]. In all these separations, the lower bound for the classical model only holds when the advantage of the protocol (over a random guess) is more than $\approx 1/\sqrt{N}$, that is, the success probability is larger than $\approx 1/2 + 1/\sqrt{N}$. This is unavoidable as $\approx 1/\sqrt{N}$ is the correlation between two coordinates of an input that is sampled from the Forrelation distribution, and hence there are simple classical protocols that achieve advantage $\approx 1/\sqrt{N}$, in all these models.

To achieve separations when the classical protocol has smaller advantage, we study in this work the XOR of $k$ independent copies of (a variant of) the Forrelation function (where $k\ll N$). We prove a very general result that shows that any family of Boolean functions that is closed under restrictions, whose Fourier mass at level $2k$ is bounded by $\alpha^k$ (that is, the sum of the absolute values of all Fourier coefficients at level $2k$ is bounded by $\alpha^k$), cannot compute the XOR of $k$ independent copies of the Forrelation function with advantage better than $O\left(\frac{\alpha^k}{{N^{k/2}}}\right)$. This is a strengthening of a result of [CHLT19], that gave a similar statement for $k=1$, using the technique of [RT19]. We give several applications of our result. In particular, we obtain the following separations:

Quantum versus Classical Communication Complexity: We give the first example of a partial Boolean function that can be computed by a simultaneous-message quantum protocol with communication complexity $\mbox{polylog}(N)$ (where Alice and Bob also share $\mbox{polylog}(N)$ EPR pairs), and such that, any classical randomized protocol of communication complexity at most $\tilde{o}(N^{1/4})$, with any number of rounds,  has quasipolynomially small advantage over a random guess. Previously, only separations where the classical protocol has polynomially small advantage were known between these models [G16, GRT19].

Quantum Query Complexity versus Bounded Depth Circuits: We give the first example of a partial Boolean function that has a quantum query algorithm with query complexity $\mbox{polylog}(N)$, and such that, any constant-depth circuit of quasipolynomial size has quasipolynomially small advantage over a random guess. Previously, only separations where the constant-depth circuit has polynomially small advantage were known [RT19].</summary>
    <updated>2020-07-07T16:03:43Z</updated>
    <published>2020-07-07T16:03:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-12T10:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4892</id>
    <link href="https://www.scottaaronson.com/blog/?p=4892" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4892#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4892" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">My Enlightenment fanaticism</title>
    <summary xml:lang="en-US">If there were ever a time for liberals and progressives to put aside their internal squabbles, you’d think it was now. The President of the United States is a racist gangster, who might not leave if he loses the coming election—all the more reason to ensure he loses in a landslide. Due in part to […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>If there were ever a time for liberals and progressives to put aside their internal squabbles, you’d think it was now.  The President of the United States is a racist gangster, who might not leave if he loses the coming election—all the more reason to ensure he loses in a landslide.  Due in part to that gangster’s breathtaking incompetence, 130,000 Americans are now dead, and the economy tanked, from a pandemic that the rest of the world has under much better control.  The gangster’s latest “response” to the pandemic has been to disrupt the lives of thousands of foreign scientists—including several of my students—by threatening to cancel their visas.  (American universities will, of course, do whatever they legally can to work around this act of pure spite.)</p>



<p>So how is the left responding to this historic moment?</p>



<p>This weekend, 536 people did so by … <a href="https://docs.google.com/document/d/17ZqWl5grm_F5Kn_0OarY9Q2jlOnk200PvhM5e3isPvY/preview?pru=AAABc0ugms8*_1VPq2TCPXlcaha9KVY3_Q">trying to cancel Steven Pinker</a>, stripping him of “distinguished fellow” and “media expert” status (whatever those are) in the Linguistics Society of America for ideological reasons.</p>



<p>Yes, Steven Pinker: the celebrated linguist and cognitive scientist, author of <em>The Language Instinct</em> and <em>How the Mind Works</em> (which had a massive impact on me as a teenager) and many other books, and academic torch-bearer for the Enlightenment in our time.  For years, I’d dreaded the day they’d <em>finally</em> come for Steve, even while friends assured me my fears must be inflated since, after all, they hadn’t come for him yet.</p>



<p>I concede that the cancelers’ logic is impeccable.  If they can get Pinker, everyone will quickly realize that there’s no longer any limit to who they can get—including me, including any writer or scientist who crosses them.  If you’ve ever taken, or aspire to take, any public stand riskier than “waffles are tasty,” then don’t delude yourself that you’ll be magically spared—<em>certainly</em> not by your own progressive credentials.</p>



<p>I don’t know if the “charges” against Pinker merit a considered response  (Pinker <a href="https://twitter.com/sapinker/status/1279934082210816003">writes</a> that some people wondered if they were satire).  For those who care, though, <a href="https://whyevolutionistrue.com/2020/07/05/the-purity-posse-pursues-pinker/">here’s</a> a detailed and excellent takedown by the biologist and blogger Jerry Coyne, and <a href="https://medium.com/@bhpartee/my-response-to-the-pinker-petition-open-letter-to-the-linguistics-community-80e2e4d9dbe2">here’s another</a> by Barbara Partee.</p>



<p>So, it seems Pinker once used the term “urban crime,” which can be a racist dogwhistle—except that in this case, it literally meant “urban crime.”  Pinker once referred to <a href="https://en.wikipedia.org/wiki/1984_New_York_City_Subway_shooting">Bernie Goetz</a>, whose 1984 shooting of four robbers in the NYC subway polarized the US at the time, as a “mild-mannered engineer,” in a sentence whose purpose was to <em>contrast</em> that description with the ferocity of Goetz’s act.  Pinker “appropriated” the work of a Black scholar, Harvard Dean Lawrence Bobo, which apparently meant <a href="https://twitter.com/sapinker/status/1268180637418164224?fbclid=IwAR1drpt4R2khSEEyiKiQMXEYloxy_6YzDTIvUEhb_FEkxL-KAPe9XvPYurg">approvingly citing him</a> in a tweet.  Etc.  Ironically, it occurred to me that the would-be Red Guards could’ve built a much stronger case against Pinker had they seriously engaged with his decades of writing—writing that really <em>does</em> take direct aim at their whole worldview, they aren’t wrong about that—rather than superficially collecting a few tweets.</p>



<p>What Coyne calls the “Purity Posse” sleazily gaslights its readers as follows:</p>



<blockquote class="wp-block-quote"><p>We want to note here that we have no desire to judge Dr. Pinker’s actions in moral terms, or claim to know what his aims are. Nor do we seek to “cancel” Dr. Pinker, or to bar him from participating in the linguistics and LSA communities (though many of our signatories may well believe that doing so would be the right course of action).</p></blockquote>



<p>In other words: many of us “may well believe” that Pinker’s scientific career should be ended entirely.  But magnanimously, <em>for now</em>, we’ll settle for a display of our power that leaves the condemned heretic still kicking.  So don’t accuse us of wanting to “cancel” anyone!</p>



<p>In that same generous spirit:</p>



<blockquote class="wp-block-quote"><p>Though no doubt related, we set aside questions of Dr. Pinker’s tendency to move in the proximity of what The Guardian called a revival of “scientific racism”, his public support for David Brooks (who has been argued to be a proponent of “gender essentialism”), his expert testimonial in favor of Jeffrey Epstein (which Dr. Pinker now regrets), or his dubious past stances on rape and feminism.</p></blockquote>



<p>See, even while we make these charges, we disclaim all moral responsibility for making them.  (For the record, Alan Dershowitz asked Pinker for a linguist’s opinion of a statute, so Pinker provided it; Pinker didn’t know at the time that the request had anything to do with Epstein.)</p>



<p>Again and again, spineless institutions have responded to these sorts of ultimatums by capitulating to them.  So I confess that the news about Pinker depressed me all weekend.  The more time passed, though, the more it looked like the Purity Posse might have <em>actually</em> overplayed its hand this time.  Steven Pinker is not weak prey.</p>



<p>Let’s start with what’s missing from the petition: Noam Chomsky <a href="https://twitter.com/ZaidJilani/status/1279505236181356544">pointedly refused to sign</a>.  How that must’ve stung his comrades!  For that matter, virtually all of the world’s well-known linguists refused to sign.  <a href="https://en.wikipedia.org/wiki/Ray_Jackendoff">Ray Jackendoff</a> and <a href="https://en.wikipedia.org/wiki/Michel_DeGraff">Michel DeGraff</a> were originally on the petition, but their names turned out to have been forged (were others?).</p>



<p>But despite the flimsiness of the petition, suppose the Linguistics Society of America caved.  OK, I mused, how many people have even <em>heard</em> of the Linguistics Society of America, compared to the number who’ve heard of Pinker or read his books?  If the LSA expelled Pinker, wouldn’t they be forever known to the world <em>only</em> as the organization that had done that?</p>



<p>I’m tired of the believers in the Enlightenment being constantly on the defensive.  “No, I’m not a racist or a misogynist … on the contrary, I’ve spent decades advocating for … yes, I did say that, but you completely misunderstood my meaning, which in context was … <em>please, I’m begging you</em>, can’t we sit and discuss this like human beings?”</p>



<p>It’s time for more of us to stand up and say: yes, I am a center-left extremist.  Yes, I’m an Enlightenment fanatic, a radical for liberal moderation and reason.  If liberalism is the vanilla of worldviews, then I aspire to be the most intense vanilla anyone has ever tasted.  I’m not a closeted fascist.  I’m not a watered-down leftist.  I’m something else.  I consider myself ferociously anti-racist and anti-sexist and anti-homophobic and pro-downtrodden, but I don’t cede to any ideological faction the right to dictate what those terms mean.  The world is too complicated, too full of ironies and surprises, for me to outsource my conscience in that way.</p>



<p>Enlightenment liberalism at least has the virtue that it’s not some utopian dream: on the contrary, it’s already led to most of the peace and prosperity that this sorry world has ever known, wherever and whenever it’s been allowed to operate.  And while “the death of the Enlightenment” gets proclaimed every other day, liberal ideals have by now endured for centuries.  They’ve outlasted kings and dictators, the Holocaust and the gulag.  They certainly have it within them to outlast some online sneerers.</p>



<p>Yes, sometimes martyrdom (or at least career martyrdom) is the only honorable course, and yes, the childhood bullies <em>did</em> gift me with a sizeable persecution complex—I’ll grant the sneerers that.  But on reflection, no, I don’t want to be a martyr for Enlightenment values.  I want Enlightenment values to <em>win</em>, and not by vanquishing their opponents but by persuading them.  As Pinker <a href="https://twitter.com/sapinker/status/1279936590236790784">writes</a>:</p>



<blockquote class="wp-block-quote"><p>A final comment: I feel sorry for the signatories. Moralistic dudgeon is a shallow and corrosive indulgence, &amp; policing the norms of your peer group a stunting of the intellect. Learning new ideas &amp; rethinking conventional wisdom are deeper pleasures … and ultimately better for the world. Our natural state is ignorance, fallibility, &amp; self-deception. Progress comes only from broaching &amp; evaluating ideas, including those that feel unfamiliar and uncomfortable.</p></blockquote>



<p>Spend a lot of time on Twitter and Reddit and news sites, and it <em>feels like</em> the believers in the above sentiment are wildly outnumbered by the self-certain ideologues of all sides.  But just like the vanilla in a cake can be hard to taste, so there are more Enlightenment liberals than it seems, even in academia—especially if we include all those who never explicitly identified that way, because they were too busy building or fixing or discovering or teaching, and because they mistakenly imagined that if they just left the Purity Posse alone then the Posse would do likewise.  If that’s you, then please ask yourself now: <em>what is my personal break-point for speaking up?</em></p></div>
    </content>
    <updated>2020-07-07T14:21:30Z</updated>
    <published>2020-07-07T14:21:30Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-07-07T18:40:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>http://ptreview.sublinear.info/?p=1352</id>
    <link href="https://ptreview.sublinear.info/?p=1352" rel="alternate" type="text/html"/>
    <title>News for June 2020</title>
    <summary>Sublinear algorithms in times of social distancing…always something exciting. This month we have a slew of results on sublinear algorithms for classic graph problems. (Ed: We have removed a previously posted paper due to correctness concerns raised by our readers. Please look at the post on our paper policy.) Palette Sparsification Beyond (∆ + 1) […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Sublinear algorithms in times of social distancing…always something exciting. This month we have a slew of results on sublinear algorithms for classic graph problems.</p>



<p><em>(Ed: We have removed a previously posted paper due to correctness concerns raised by our readers. Please look at the <a href="https://ptreview.sublinear.info/?p=1361">post on our paper policy</a>.)</em></p>



<p><strong>Palette Sparsification Beyond (∆ + 1) Vertex Coloring</strong> by Noga Alon and Sepehr Assadi (<a href="https://arxiv.org/pdf/2006.10456.pdf">arXiv</a>). A basic fact from graph theory is that any graph has a \((\Delta+1)\)-coloring, where \(\Delta\) is the maximum degree. Followers of property testing are likely familiar with a fantastic result of <a href="https://www.cs.rutgers.edu/~sa1497/pages/sublinear_vertex-coloring_2019.html">Assadi-Chen-Khanna</a> (ACK) on sublinear algorithms, that gives a sublinear algorithm for \((\Delta+1)\)-coloring. (The running time is \(\widetilde{O}(n^{3/2})\), where \(n\) is the number of vertices.) The key tool is a palette sparsification theorem: suppose each vertex is given a “palette” of \((\Delta+1)\) colors. Each vertex randomly sparsifies its palette by sampling \(O(\log n)\) colors, and is constrained to only use these colors. Remarkably, whp the graph can still be properly colored. This tool is at the heart of sublinear time/space algorithms for coloring. This paper gives numerous extensions to this theorem, where one can tradeoff a larger initially palette for a smaller final sample. Another extension is for triangle-free graphs, where the initial palette is of size \(O(\Delta/\ln \Delta)\) and the sample is of size \(O(\Delta^\gamma + \sqrt{\ln n})\) (for parameter \(\gamma &lt; 1\). This leads to an \(O(n^{3/2 + \gamma})\) time algorithm for \(O(\Delta/\ln \Delta)\) coloring of triangle-free graphs.</p>



<p><strong>When Algorithms for Maximal Independent Set and Maximal Matching Run in Sublinear-Time</strong> by Sepehr Assadi and Shay Solomon (<a href="https://arxiv.org/pdf/2006.07628.pdf">arXiv</a>). Taking off from sublinear coloring algorithms, one can ask if there are sublinear time algorithms for Maximal Independent Set (MIS) and Maximal Matching (MM). Alas, ACK prove that this is impossible. This paper investigates when one can get a sublinear time algorithm for these problems. For graph \(G\), let \(\beta(G)\) be the “neighborhood independence number”, the size of the largest independent set contained in a vertex neighborhood. This papers shows that both problems can be solved in \(\widetilde{O}(n \beta(G))\) time. Examples of natural classes of graphs where \(\beta(G)\) is constant: line graphs and unit-disk graphs. An interesting aspect is that MIS algorithm is actually deterministic! It’s the simple marking algorithm that rules out neighborhoods of chosen vertices; the analysis shows that not much time is wasted in remarking the same vertex. </p>



<p><strong>Sublinear Algorithms and Lower Bounds for Metric TSP Cost Estimation</strong> by Yu Chen, Sampath Kannan, and Sanjeev Khanna (<a href="https://arxiv.org/pdf/2006.05490.pdf">arXiv</a>). This paper studies sublinear algorithms for the metric TSP problem. The input is an \(n \times n\) distance matrix. One can 2-approximate the TSP by computing the MST, and a result of <a href="http://wrap.warwick.ac.uk/2416/">Czumaj-Sohler</a> gives a \((1+\varepsilon)\)-approximation algorithm for the latter, running in \(O(n\varepsilon^{-O(1)})\) time. The main question is: can one beat the 2-factor approximation in sublinear time? This paper considers the graphic TSP setting, where the distance matrix corresponds to the shortest path metric of an unweighted graph. One result is a \((2-\varepsilon_0)\)-approximation algorithm (for an explicit constant \(\varepsilon_0\)) that runs in \(\widetilde{O}(n)\) time. For the important \((1,2)\) TSP setting (all distances are either 1 or 2), the paper gives a \(O(n^{1.5})\) time 1.63-approximation algorithm. Interestingly, there is a lower bound showing that \((1+\varepsilon)\)-approximations, for arbitrarily small \(\varepsilon\), cannot be achieved in \(o(n^2)\) time. One of the key tools is sublinear algorithms for estimating the maximum matching size, itself a well-studied problem in the community.</p></div>
    </content>
    <updated>2020-07-07T06:26:32Z</updated>
    <published>2020-07-07T06:26:32Z</published>
    <category term="Monthly digest"/>
    <author>
      <name>Seshadhri</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/?feed=rss2" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2020-07-11T23:40:36Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/100</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/100" rel="alternate" type="text/html"/>
    <title>TR20-100 |  Streaming Verification for Graph Problems: Optimal Tradeoffs and Nonlinear Sketches | 

	Amit Chakrabarti, 

	Prantar Ghosh, 

	Justin Thaler</title>
    <summary>We study graph computations in an enhanced data streaming setting, where a space-bounded client reading the edge stream of a massive graph may delegate some of its work to a cloud service. We seek algorithms that allow the client to verify a purported proof sent by the cloud service that the work done in the cloud is correct.
  A line of work starting with Chakrabarti et al. (ICALP 2009) has provided such algorithms, which we call schemes, for several statistical and graph-theoretic problems, many of which exhibit a tradeoff between the length of the proof and the space used by the streaming verifier.
  
  This work designs new schemes for a number of basic graph problems---including triangle counting, maximum matching, topological sorting, and single-source shortest paths---where past work had either failed to obtain smooth tradeoffs between these two key complexity measures or only obtained suboptimal tradeoffs. Our key innovation is having the verifier compute certain nonlinear sketches of the input stream, leading to either new or improved tradeoffs. In many cases, our schemes in fact provide optimal tradeoffs up to logarithmic factors. 

  Specifically, for most graph problems that we study, it is known that the product of the verifier's space cost $v$ and the proof length $h$ must be at least $\Omega(n^2)$ for $n$-vertex graphs. However, matching upper bounds are only known for a handful of settings of $h$ and $v$ on the curve $h \cdot v=\tilde{\Theta}(n^2)$. For example, for counting triangles and maximum matching, schemes with costs lying on this curve are only known for $(h=\tilde{O}(n^2), v=\tilde{O}(1))$, $(h=\tilde{O}(n), v=\tilde{O}(n))$, and the trivial $(h=\tilde{O}(1), v=\tilde{O}(n^2))$. A major message of this work is that by exploiting nonlinear sketches, a significant ``portion'' of costs on the tradeoff curve $h \cdot v = n^2$ can be achieved.</summary>
    <updated>2020-07-06T17:16:45Z</updated>
    <published>2020-07-06T17:16:45Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-12T10:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/099</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/099" rel="alternate" type="text/html"/>
    <title>TR20-099 |  KRW Composition Theorems via Lifting | 

	Susanna de Rezende, 

	Or Meir, 

	Jakob Nordström, 

	Toniann Pitassi, 

	Robert Robere</title>
    <summary>One of the major open problems in complexity theory is proving super-logarithmic lower bounds on the depth of circuits (i.e., $\mathbf{P}\not\subseteq\mathbf{NC}^1$). Karchmer, Raz, and Wigderson (Computational Complexity 5(3/4), 1995) suggested to approach this problem by proving that depth complexity behaves “as expected” with respect to the composition of functions $f \diamond g$. They showed that the validity of this conjecture would imply that $\mathbf{P}\not\subseteq\mathbf{NC}^1$.

Several works have made progress toward resolving this conjecture by proving special cases. In particular, these works proved the KRW conjecture for every outer function $f$, but only for few inner functions $g$. Thus, it is an important challenge to prove the KRW conjecture for a wider range of inner functions.

In this work, we extend significantly the range of inner functions that can be handled. First, we consider the $\textit{monotone}$ version of the KRW conjecture. We prove it for every monotone inner function $g$ whose depth complexity can be lower bounded via a query-to-communication lifting theorem. This allows us to handle several new and well-studied functions such as the $s\textbf{-}t$-connectivity, clique, and generation functions.

In order to carry this progress back to the $\textit{non-monotone}$ setting, we introduce a new notion of $\textit{semi-monotone}$ composition, which combines the non-monotone complexity of the outer function $f$ with the monotone complexity of the inner function $g$. In this setting, we prove the KRW conjecture for a similar selection of inner functions $g$, but only for a specific choice of the outer function $f$.</summary>
    <updated>2020-07-06T11:22:16Z</updated>
    <published>2020-07-06T11:22:16Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-12T10:20:32Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2020/07/06/GAN-min-max/</id>
    <link href="http://offconvex.github.io/2020/07/06/GAN-min-max/" rel="alternate" type="text/html"/>
    <title>Training GANs - From Theory to Practice</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>GANs, originally discovered in the context of unsupervised learning, have had far reaching implications to science, engineering, and society. However, training GANs remains challenging (in part) due to the lack of convergent algorithms for nonconvex-nonconcave min-max optimization. In this post, we present a <a href="https://arxiv.org/abs/2006.12376">new first-order algorithm</a> for min-max optimization which is particularly suited to GANs. This algorithm is guaranteed to converge to an equilibrium, is competitive in terms of time and memory with gradient descent-ascent and, most importantly, GANs trained using it seem to be stable.</p>

<h2 id="gans-and-min-max-optimization">GANs and min-max optimization</h2>

<p>Starting with the work of <a href="http://papers.nips.cc/paper/5423-generative-adversarial-nets">Goodfellow et al.</a>, Generative Adversarial Nets (GANs) have become a critical component in various ML systems; for prior posts on GANs, see <a href="https://www.offconvex.org/2018/03/12/bigan/">here</a> for a post on  GAN architecture, and <a href="https://www.offconvex.org/2017/03/15/GANs/">here</a> and <a href="https://www.offconvex.org/2017/07/06/GANs3/">here</a> for posts which discuss  some of the many difficulties arising when training GANs.</p>

<p>Mathematically, a GAN consists of a generator neural network $\mathcal{G}$ and a discriminator neural network $\mathcal{D}$ that are competing against each other in a way that, together, they learn the unknown distribution from which a given dataset arises.  The generator takes a random “noise” vector as input and maps this vector to a sample; for instance, an image. The discriminator takes samples – “fake” ones produced by the generator and “real” ones from the given dataset – as inputs.  The discriminator then tries to classify these samples as “real” or “fake”. As a designer, we would like the generated samples to be indistinguishable from those of the dataset. Thus, our goal is to choose weights $x$ for the generator network that allow it to generate samples which are difficult for <em>any</em> discriminator to tell apart from real samples. This leads to a min-max optimization problem where we look for weights $x$ which <em>minimize</em> the rate (measured by a loss function $f$) at which any discriminator correctly classifies the real and fake samples. And, we seek weights $y$ for the discriminator network which <em>maximize</em> this rate.</p>

<blockquote>
  <p><strong>Min-max formulation of GANs</strong> <br/> <br/></p>

  

  

  <p>where $\zeta$ is a random sample from the dataset, and $\xi \sim N(0,I_d)$ is a noise vector which the generator maps to a “fake” sample.  $f_{\zeta, \xi}$ measures how accurately the discriminator $\mathcal{D}(y;\cdot)$ distinguishes $\zeta$ from $\mathcal{G}(x;\xi)$ produced by the generator using the input noise $\xi$.</p>
</blockquote>

<p>In this formulation, there are several choices that we have to make as a GAN designer, and an important one is that of a loss function. One concrete choice is from the paper of Goodfellow et al.: the cross-entropy loss function:</p>



<p>See <a href="https://machinelearningmastery.com/generative-adversarial-network-loss-functions/">here</a> for a summary and comparison of different loss functions.</p>

<p>Once we fix the loss function (and the architecture of the generator and discriminator), we can compute unbiased estimates of the value of $f$ and its gradients $\nabla_x f$ and $\nabla_y f$ using batches consisting of random Gaussian noise vectors $\xi_1,\ldots, \xi_n \sim N(0,I_d)$ and random samples from the dataset $\zeta_1, \ldots, \zeta_n$.  For example, the stochastic batch gradient</p>



<p>gives us an unbiased estimate for $\nabla_x f(x,y)$.</p>

<blockquote>
  <p>But how do we solve the min-max optimization problem above using such a first-order access to $f$?</p>
</blockquote>

<h2 id="gradient-descent-ascent-and-variants">Gradient descent-ascent and variants</h2>

<p>Perhaps the simplest algorithm we can try for min-max optimization is gradient descent-ascent (GDA). As the generator wants to minimize with respect to $x$ and the discriminator wants to maximize with respect to $y$, the idea is to do descent steps for $x$ and ascent steps for $y$. How exactly to do this is not clear, and one strategy is to let the generator and discriminator alternate:</p>





<p>Other variants include, for instance, <a href="https://arxiv.org/abs/1311.1869">optimistic mirror descent</a> (OMD) (see also <a href="https://arxiv.org/abs/1807.02629">here</a> and  <a href="https://arxiv.org/abs/1711.00141">here</a> for applications of OMD to GANs, and <a href="https://arxiv.org/abs/1901.08511">here</a> for an analysis of OMD and related methods)</p>





<p>The advantage of such algorithms is that they are quite practical. The problem, as we discuss next, is that they are not always guaranteed to converge. Most of these guarantees only hold for special classes of loss functions $f$ that satisfy properties such as concavity (see <a href="https://papers.nips.cc/paper/9430-efficient-algorithms-for-smooth-minimax-optimization.pdf">here</a> and <a href="https://arxiv.org/abs/1906.00331">here</a>) or <a href="https://papers.nips.cc/paper/9631-solving-a-class-of-non-convex-min-max-games-using-iterative-first-order-methods.pdf">monotonicity</a>, or under the assumptions that these algorithms are provided with special starting points (see <a href="https://arxiv.org/abs/1706.08500">here</a>, <a href="https://arxiv.org/abs/1910.07512">here</a>).</p>

<h2 id="convergence-problems-with-current-algorithms">Convergence problems with current algorithms</h2>

<p>Unfortunately there are simple functions for which some min-max optimization algorithms may never converge to <em>any</em> point.  For instance GDA may not converge on $f(x,y) = xy$  (see Figure 1, and our <a href="https://www.offconvex.org/2020/06/24/equilibrium-min-max/">previous post</a> for a more detailed discussion).</p>

<div>
<img alt="" src="http://www.offconvex.org/assets/GDA_spiral_2.gif"/>
<br/>
<b>Figure 1.</b> GDA on $f(x,y) = xy, \, \, \, \, x,y \in [-5,5]$ (the red line is the set of global min-max points). GDA is non-convergent from almost every initial point. 
</div>
<p><br/></p>

<p>As for examples relevant to ML, when using GDA to train a GAN on a dataset consisting of points sampled from a mixture of four Gaussians in $\mathbb{R}^2$, we observe that GDA tends to cause the generator to cycle between different modes corresponding to the four Gaussians. We also used GDA to train a GAN on the subset of the MNIST digits which have “0” or “1” as their label, which we refer to as the 0-1 MNIST dataset.  We observed a cycling behavior for this dataset as well: After learning how to generate images of $0$’s, the GAN trained by GDA then forgets how to generate $0$’s for a long time and only generates $1$’s.</p>

<div>
<img alt="" src="http://www.offconvex.org/assets/GDA_Gaussian.gif" style="width: 400px;"/>
<img alt="" src="http://www.offconvex.org/assets/GDA_MNIST.gif" style="width: 400px;"/>
<br/>
<b>Figure 2.</b> Mode oscillation when GDA is used to train GANs on the four Guassian mixture dataset (left) and the 0-1 MNIST dataset (right).
</div>

<p><br/></p>

<p>In algorithms such as GDA where the discriminator only makes local updates, cycling can happen for the following reason: Once the discriminator learns to identify one of the modes (say mode “A”), the generator can update $x$ in a way that greatly decreases f, by (at least temporarily) ìfoolingî the discriminator. The generator does this by learning to generate samples from a different mode (say mode “B”) which the discriminator has not yet learned to identify, and stops generating samples from mode A. However, after many iterations, the discriminator ìcatches upî to the generator and learns how to identify mode B. Since the generator is no longer generating samples from mode A, the discriminator may then ìforgetî how to identify samples from this mode. And this can cause the generator to switch back to generating only mode A.</p>

<h2 id="our-first-order-algorithm">Our first-order algorithm</h2>

<p>To solve the min-max optimization problem, at any point $(x,y)$, we should ideally allow the discriminator to find the global maximum, $\max_z f(x,z)$. However, this may be hard for nonconcave $f$. But we could still let the discriminator run a convergent algorithm (such as gradient ascent) until it reaches a <strong>first-order stationary point</strong>, allowing it to compute an approximation $h$ for the global max function.  (Note that even though $\max_z f(x,z)$ is only a function of $x$, since $h$ is a “local’’ approximation it could also depend on the initial point $y$ where we start gradient ascent.) And we also empower the generator to simulate the discriminator’s update by running gradient ascent (see <a href="https://arxiv.org/abs/2006.12376">our paper</a> for discriminators with access to a more general class of first-order algorithms).</p>

<blockquote>
  <p><strong>Idea 1: Use a local approximation to global max</strong>
<br/><br/>
Starting at the point $(x,y)$, update $y$ by computing multiple gradient ascent steps for $y$ until a point $w$ is reached where  is close to zero and define $h(x,y) := f(x,w)$.</p>
</blockquote>

<p>We would like the generator to minimize $h(\cdot,y)$. To minimize $h$, we would ideally like to update $x$ in the direction $-\nabla_x h$.  However, $h$ may be discontinuous in $x$ (see our <a href="https://www.offconvex.org/2020/06/24/equilibrium-min-max/">previous post</a> for why this can happen). Moreover, even at points where $h$ is differentiable, computing the gradient of $h$ can take a long time and requires a large amount of memory.</p>

<p>Thus, realistically, we only have access to the value of $h$. A naive approach to minimizing $h$ would be to propose a random update to $x$, for instance an update sampled from a standard Gaussian, and then only accept this update if it causes the value of $h$ to decrease. Unfortunately, this does not lead to fast algorithms as even at points where $h$ is differentiable, in high dimensions, a random Gaussian step will be almost orthogonal to the steepest descent direction $-\nabla_x h(x,y)$, making the progress slow.</p>

<p>Another idea is to have the generator propose at each iteration an update in the direction of the gradient $-\nabla_x f(x,y)$, and to then have the discriminator update $y$ using gradient ascent. To see why this may be a reasonable thing to do, notice that once the generator proposes an update $v$ to $x$, the discriminator will only make updates which increase the value of f or, $h(x+v,y) \geq f(x+v,y)$. And, since $y$ is a first-order stationary point for $f(x, \cdot)$ (because $y$ was computed using gradient ascent in the <em>previous</em> iteration), we also have that $h(x,y)=f(x,y)$. Hence,</p>



<p><em>This means that decreasing $h$ requires us to decrease $f$ (the converse is not true). So it indeed makes sense to move in the direction $-\nabla_x f(x,y)$!</em></p>

<p>While making updates using $-\nabla_x f(x,y)$ may allow the generator to decrease $h$ more quickly than updating in a random direction, it is not always the case that updating in the direction of $-\nabla_x f$ will lead to a decrease in $h$ (and doing so may even lead to an increase in $h$!). Instead, our algorithm has the generator perform a random search by proposing an update in the direction of a batch gradient with mean $-\nabla_x f$, and accepts this move only if the value of $h$ (the local approximation) decreases. The accept-reject step prevents our algorithm from cycling between modes, and using the batch gradient for the random search allows our algorithm to be competitive with prior first-order methods in terms of running time.</p>

<blockquote>
  <p><strong>Idea 2: Use zeroth-order optimization with batch gradients</strong>
<br/><br/>
Sample a batch gradient $v$ with mean $-\nabla_x f(x,y)$.
<br/>
If $h(x+ v, y) &lt; h(x,y) $ accept the step $x+v$; otherwise reject it.</p>
</blockquote>

<p>A final issue, that applies even in the special case of minimization, is that converging to a <em>local</em> minimum point does not mean that point is desirable from an application standpoint. The same is true for the more general setting of min-max optimization. To help our algorithm escape undesirable local min-max equilibria, we use a randomized accept-reject rule inspired by <a href="https://towardsdatascience.com/optimization-techniques-simulated-annealing-d6a4785a1de7">simulated annealing</a>. Simulated annealing algorithms seek to minimize a function via a randomized search, while gradually decreasing the acceptance probability of this search; in some cases this allows one to reach the global minimum of a nonconvex function (see for instance <a href="https://arxiv.org/abs/1711.02621">this paper</a>). These three ideas lead us to our algorithm.</p>

<blockquote>
  <p><strong>Our algorithm</strong>
<br/><br/>
<em>Input</em>: Initial point $(x,y)$, $f: \mathbb{R}^d \times \mathbb{R}^d\rightarrow \mathbb{R}$
<br/>
<em>Output:</em> A local min-max equilibrium $(x,y)$</p>

  <p><br/> <br/></p>

  <p>For $i = 1,2, \ldots$ <br/>
<br/>
<strong>Step 1:</strong> Generate a batch gradient $v$ with mean $-\nabla_x f(x,y)$ and propose the generator update $x+v$.
<br/><br/>
<strong>Step 2:</strong> Compute $h(x+v, y) = f(x+v, w)$, by simulating a discriminator update $w$ via gradient ascent on $f(x+v, \cdot)$ starting at $y$.
<br/><br/>
<strong>Step 3:</strong>  If $h(x+v, y)$ is less than $h(x,y) = f(x,y)$, accept both updates: $(x,y) = (x+v, w)$. Else, accept both updates with some small probability.</p>
</blockquote>

<p>In our paper, we show that our algorithm is guaranteed to converge to a type of local min-max equilibrium in $\mathrm{poly}(\frac{1}{\varepsilon},d, b, L)$ time whenever $f$ is bounded by some $b&gt;0$ and has $L$-Lipschitz gradients. Our algorithm does not require any special starting points, or any additional assumptions on $f$ such as convexity or monotonicity. (See Definition 3.2 and Theorem 3.3 in our paper.)</p>

<div>
<img alt="" src="http://www.offconvex.org/assets/GDA_spiral_2.gif" style="width: 400px;"/>
<img alt="" src="http://www.offconvex.org/assets/OurAlgorithm_surface_run1.gif" style="width: 400px;"/>
<br/>
<b>Figure 3.</b> GDA (left) and a version of our algorithm (right) on $f(x,y) = xy, \, \, \, \, x,y \in [-5,5]$. While GDA is non-convergent from almost every initial point, our algorithm converges to the set of global min-max points (the red line). To ensure it converges to a (local) equilibrium, our algorithm's generator proposes multiple updates, simulates the discriminator's response, and rejects updates which do not lead to a net decrease in $f$. It only stops if it can't find such an update after many attempts. (To stay inside $[-5,5]\times [-5,5]$ this version of our algorithm uses <i>projected</i> gradients.)
</div>

<p><br/></p>

<h2 id="so-how-does-our-algorithm-perform-in-practice">So, how does our algorithm perform in practice?</h2>

<p>When training a GAN on the mixture of four Gaussians dataset, we found that our algorithm avoids the cycling behavior observed in GDA. We ran each algorithm multiple times, and evaluated the results visually. By the 1500’th iteration GDA learned only one mode in 100% of the runs, and tended to cycle between two or more modes. In contrast, our algorithm was able to learn all four modes 68% of the runs, and three modes 26% of the runs.</p>

<div>
<img alt="" src="http://www.offconvex.org/assets/Both_algorithms_Gaussian.gif"/>
<br/>
<b>Figure 4.</b> GAN trained using GDA and our algorithm on a four Gaussian mixture dataset. While GDA cycles between the Gaussian modes (red dots), our algorithm learns all four modes.
</div>
<p><br/></p>

<p>When training on the 0-1 MNIST dataset, we found that GDA tends to briefly generate shapes that look like a combination of $0$’s and $1$’s, then switches to generating only $1$’s, and then re-learns how to generate $0$’s. In contrast, our algorithm seems to learn how to generate both $0$’s and $1$’s early on and does not stop generating either digit. We repeated this simulation multiple times for both algorithms, and visually inspected the images at the 1000’th iteration. GANs trained using our algorithm generated both digits by the 1000’th iteration in 86% of the runs, while those trained using GDA only did so in 23% of the runs.</p>

<div>
<img alt="" src="http://www.offconvex.org/assets/MNIST_bothAlgorithms.gif"/>
<br/>
<b>Figure 5.</b> We trained a GAN with GDA and our algorithm on the
0-1 MNIST dataset.  During the first 1000 iterations, GDA (left)
forgets how to generate $0$'s, while our algorithm (right) learns how to
generate both $0$'s and $1$'s early on and does not stop generating either digit.
</div>

<p><br/></p>

<p>While here we have focused on comparing our algorithm to GDA, in our paper we also include a comparison to <a href="https://arxiv.org/abs/1611.02163">Unrolled GANs</a>, which exhibits cycling between modes. We also present results for CIFAR-10 (see Figures 3 and 7 in our paper), where we compute FID scores to track the progress of our algorithm. See our paper for more details; the code is available on <a href="https://github.com/mangoubi/Min-max-optimization-algorithm-for-training-GANs">GitHub</a>.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In this post we have shown how to develop a practical and convergent first-order algorithm for training GANs. Our algorithm synthesizes an approximation to the global max function based on first-order algorithms, random search using batch gradients, and simulated annealing. Our simulations show that a version of this algorithm can lead to more stable training of GANs. And yet the amount of memory and time required by each iteration of our algorithm is competitive with GDA. This post, together with the <a href="https://www.offconvex.org/2020/06/24/equilibrium-min-max/">previous post</a>, show that different local approximations to the global max function $\max_z f(x,z)$ can lead to different types of convergent algorithms for min-max optimization. We believe that this idea should be useful in other applications of min-max optimization.</p></div>
    </summary>
    <updated>2020-07-06T09:00:00Z</updated>
    <published>2020-07-06T09:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2020-07-11T23:40:09Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://decentralizedthoughts.github.io/2020-07-05-the-first-blockchain-or-how-to-time-stamp-a-digital-document/</id>
    <link href="https://decentralizedthoughts.github.io/2020-07-05-the-first-blockchain-or-how-to-time-stamp-a-digital-document/" rel="alternate" type="text/html"/>
    <title>The First Blockchain or How to Time-Stamp a Digital Document</title>
    <summary>This post is about the work of Stuart Haber and W. Scott Stornetta from 1991 on How to Time-Stamp a Digital Document and their followup paper Improving the Efficiency and Reliability of Digital Time-Stamping. In many ways, this work introduced the idea of a chain of hashes to create a...</summary>
    <updated>2020-07-06T02:58:00Z</updated>
    <published>2020-07-06T02:58:00Z</published>
    <source>
      <id>https://decentralizedthoughts.github.io</id>
      <author>
        <name>Decentralized Thoughts</name>
      </author>
      <link href="https://decentralizedthoughts.github.io" rel="alternate" type="text/html"/>
      <link href="https://decentralizedthoughts.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Decentralized thoughts about decentralization</subtitle>
      <title>Decentralized Thoughts</title>
      <updated>2020-07-11T23:40:54Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3270621784797289581</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3270621784797289581/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/a-table-for-matrix-mortality-what-i.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3270621784797289581" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3270621784797289581" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/a-table-for-matrix-mortality-what-i.html" rel="alternate" type="text/html"/>
    <title>A table for Matrix Mortality- what I wanted for Hilbert's 10th problem</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In <a href="https://blog.computationalcomplexity.org/2020/05/why-is-there-no-dn-grid-for-hilberts.html">this post</a> I speculated on why I could not find anywhere a table of which cases of Hilbert's 10th problem were solvable, unsolvable, and unknown. (I then made such a table. It was very clunky,  which may answer the question.)<br/>
<br/>
I told my formal lang theory class about Hilbert's 10th problem as a natural example of an undecidable question- that is, an example that had nothing to do with Turing Machines. On the final I asked<br/>
<br/>
<i>Give an example of an undecidable problem that has nothing to do with Turing Machines.</i><br/>
<br/>
Because of the pandemic this was a 2-day take home final which was open-book, open-notes, open-web. So they could have looked at my slides.<br/>
<br/>
And indeed, most of them did give Hilbert's 10 problem (more formally, the set of all polynomials in many vars over Z which have a Diophantine solution).<br/>
<br/>
But some did not. Some said there could never be such a problem (this is an incorrect answer), Some were incoherent. One just wrote ``Kruskal Trees''  (not sure if he was referring to MSTs or WQOs or to something that Clyde Kruskal did in class one day).<br/>
<br/>
One student said that the problem of, given a CFG G, is the complement of L(G) also CFG.<br/>
This is indeed undecidable and does not have to do with TMs. I doubt the student could have proven that. I doubt I could have proven that. I do not doubt that my advisor Harry Lewis could have proven that, and indeed I emailed him asking for a proof and he emailed me a sketch, which I wrote out in more detail <a href="https://www.cs.umd.edu/users/gasarch/COURSES/452/S20/notes/undcfg.pdf">here</a>.<br/>
<br/>
The most interesting answer was given by some students who apparently looked at the web (rather than at my slides) for lists of problems and found the following called Matrix Mortality:<br/>
<br/>
{ (M_1,...,M_L) : such that some product of these matrices (you are allowed to use a matrix many times) is the 0 matrix}<br/>
<br/>
Why was this the most interesting? The TA did not know this problem was undecidable until he saw it on the exams and looked it up. I did not know it was undecidable until my TA told me.<br/>
<br/>
I then raised the question: How many matrices to you need and how big do their dimensions have to be?<br/>
<br/>
Unlike H10, there IS a table of this. In <a href="https://arxiv.org/abs/1404.0644">this paper</a> they have such a table. I state some results:<br/>
<br/>
Undecidable:<br/>
6 matrices, 3x3<br/>
4 matrices, 5x5<br/>
3 matrices 9x9<br/>
2 matrices 15x15<br/>
<br/>
Decidable<br/>
2 matrices 2x2<br/>
<br/>
So there are some gaps to fill, but there is not the vast gulf that exists between dec and undec for Hilberts 10th problem. I also note that the paper was about UNDEC but mentioned the DEC results, where as the papers on H10 about UNDEC seem to never mention the DEC.<br/>
<br/>
I am glad to know another natural Undec problem and I will likely tell my students about it next spring. And much like H10, I won't be proving it.<br/>
<br/>
An open problem in education: how come some of my students got it wrong? gave an answer that was not in my notes or slides? One student told me it was easier to google<br/>
<br/>
<i>Natural Undecidable Questions</i><br/>
<br/>
then look through my slides. Another one said:<br/>
<br/>
<i>In class you said `this is a natural undecidable problem'.</i><br/>
<i><br/></i>
<i>On the exam you said `a problem that does not mention Turing Machines'</i><br/>
<i><br/></i>
<i>I did not know they were the same. </i><br/>
<br/>
That student submitted the Matrix problem stated above. It IS a fair point that `natural' is an<br/>
undefined term.  But the problem on the final used the well defined concept `does not mention Turing Machines'<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2020-07-06T02:19:00Z</updated>
    <published>2020-07-06T02:19:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-07-12T08:06:06Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor</id>
    <link href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html" rel="alternate" type="text/html"/>
    <title>The shape of the Wankel rotor</title>
    <summary>I’ve written a number of posts about curvilinear triangles that are not the Reuleaux triangle, including MIT’s Kresge Auditorium, triforce string art, valve covers, a patio table, and the logo of Whale Cove, Nunavut. I’ve long intended to write about another obvious topic in this theme, the curved-triangle rotor of the Wankel engine, but was finally pushed into doing so by seeing that two recent popular mathematics books, How Round Is Your Circle? (2008) and Icons of Mathematics (2011) repeat the falsehood that Wankel rotors are Reuleaux triangles. They are not.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’ve written a number of posts about curvilinear triangles that are not the <a href="https://en.wikipedia.org/wiki/Reuleaux_triangle">Reuleaux triangle</a>, including <a href="https://11011110.github.io/blog/2016/04/30/shape-of-kresge.html">MIT’s Kresge Auditorium</a>, <a href="https://web.archive.org/web/20190217225035/https://plus.google.com/100003628603413742554/posts/DpF5krEaU9u">triforce string art</a>, <a href="https://11011110.github.io/blog/2018/04/17/mythical-reuleaux-manhole.html">valve covers</a>, <a href="https://11011110.github.io/blog/2018/06/24/la-maddalena-non-reuleaux.html">a patio table</a>, and <a href="https://11011110.github.io/blog/2020/06/30/linkage.html">the logo of Whale Cove, Nunavut</a>. I’ve long intended to write about another obvious topic in this theme, the curved-triangle rotor of the <a href="https://en.wikipedia.org/wiki/Wankel_engine">Wankel engine</a>, but was finally pushed into doing so by seeing that two recent popular mathematics books, <em><a href="https://en.wikipedia.org/wiki/How_Round_Is_Your_Circle">How Round Is Your Circle?</a></em> (2008) and <em><a href="https://en.wikipedia.org/wiki/Icons_of_Mathematics">Icons of Mathematics</a></em> (2011) repeat the falsehood that Wankel rotors are Reuleaux triangles. They are not.</p>

<p>Wikipedia has <a href="https://commons.wikimedia.org/wiki/File:Wankel_Cycle_anim_en.gif">a good visualization of how Wankel engines work</a>, which I’ve copied below. They go through the same four steps as a conventional <a href="https://en.wikipedia.org/wiki/Four-stroke_engine">four-stroke combustion engine</a>, in which a piston pulls away from the combustion chamber, sucking in a mixture of fuel and air, pushes back towards the chamber, compressing the mixture, ignites the mixture, pushing the piston back out and applying force to the drive shaft, and then pushes back towards the chamber, pushing the exhaust out. The difference is that in a Wankel engine, these four steps happen at four different locations within the combustion chamber, as the gases within it are pushed around by a curved triangular piston, the rotor of the engine.</p>

<p style="text-align: center;"><img alt="Animation of a Wankel engine by Y tambe from https://commons.wikimedia.org/wiki/File:Wankel_Cycle_anim_en.gif" src="https://11011110.github.io/blog/assets/2020/animated-wankel.gif"/></p>

<p>The driveshaft in the engine is the fixed smaller gear in the center of the animation; in the actual engine, this gearwheel would itself be spinning, but this is not shown. The triangular rotor connects to the driveshaft by an eccentric planetary gear, and spins around the driveshaft like a hula hoop around a spinning dancer. The gears have teeth and radii in the ratio 3:2, causing the driveshaft to spin three times faster than the rotor. As it does so, the three corners of the rotor (the “apex seals”) stay in contact with the outer wall of the engine, called its stator, so that the gases in the engine do not leak between different phases.</p>

<p>The shape of the stator is not determined by the curve of the rotor itself, but only by the trajectory of the moving apex seals. This trajectory is a curve called an <a href="https://en.wikipedia.org/wiki/Epitrochoid">epitrochoid</a>. If you’ve ever played with a spirograph, you know what an epitroichoid is: it’s what you get by fixing one circular disk, letting another circular disk rotate around it, placing a point somewhere within the rotating disk, and tracing the curve that it follows. Here’s <a href="https://commons.wikimedia.org/wiki/File:EpitrochoidIn3.gif">another Wikipedia animation</a>:</p>

<p style="text-align: center;"><img alt="Animation of an epitrochoid by Sam Derbyshire from https://commons.wikimedia.org/wiki/File:EpitrochoidIn3.gif" src="https://11011110.github.io/blog/assets/2020/animated-epitrochoid.gif"/></p>

<p>Different ratios of radii between the inner and outer disk give you different numbers of lobes in the curve, and different placements of the moving point in the outer disk (closer to or farther from the disk center) give you curves that are closer to a circle or more curvy. Placing the moving point on the outer circle itself gives you pointy rather than curvy epitrochoids, and placing it even farther out turns the inner bulges of these curves into self-crossing loops.</p>

<p>Spirograph trajectories differ from rotating apex seal trajectories in at least three ways: in the Wankel engine, the central circle (the driveshaft) rotates rather than being held stationary, the outer circle (the planetary gear) surrounds the central circle rather than being outside it, and the point whose motion is being traced (the apex seal) is outside the outer circle rather than inside it. Nevertheless, the shape is still a two-lobed epitrochoid; see the “double generation theorem” of the Bernoullis, as described by Nash,<sup id="fnref:nash"><a class="footnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fn:nash">1</a></sup> for why the same curve can be generated in multiple ways. Modulo the scale of the whole system, there is one free parameter controlling the precise shape of this epitrochoid: the ratio of the distances from the center of the rotor to the apex seals and to the planetary gear. If the apex seals are too close in, the planetary gear will bash into into the stator; if they are too far out, the stator will be close to circular and there will be little change in pressure from one part of the combustion cycle to another, losing engine efficiency. The choice made in actual engines is not the one that places the apex seals as close as possible, but seems to involve more careful optimization that considers the shape and size of the regions formed by the rotor and stator at different stages of the combustion cycle.</p>

<p>Once the stator shape has been determined, one can then proceed to answer the question we started with: what is the shape of the rotor? The main design constraint is that it should touch or at least stay close to the inner bulge of the stator (on its “side seals”), to prevent exhaust gas from flowing back around to the intake. The shape that achieves this can be understood by a thought experiment in which we imagine the rotor as somehow being fixed in space while the vehicle containing it rotates around it, rather than vice versa. As the vehicle rotates, its stator passes through parts of the space that cannot be occupied by the rotor. The parts of space that remain untouched by the rotating stator are available to be used by the rotor, and should be used by it if we want a rotor that stays in contact with the stator on its side seals. Mathematically, this is described as an “envelope” of the positions of the rotating stator with respect to the fixed rotor. This envelope is a curved triangle, but not a Reuleaux triangle. Its curves are flatter than a Reuleaux triangle’s arcs, but also they are not circular arcs. As an envelope of algebraic curves, they are presumably algebraic themselves, but of higher order; trigonometric formulas are given by Shung and Pennock.<sup id="fnref:sp"><a class="footnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fn:sp">2</a></sup></p>

<p>In practice, the rotor shape varies from its ideal envelope-of-epitrochoid form, in a couple of different ways. First, as Drogosz explains,<sup id="fnref:drogosz"><a class="footnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fn:drogosz">3</a></sup> for ease of manufacturing it is often approximated by circular arcs rather than exactly following the envelope shape. As long as the approximation stays within the envelope, the rotor will avoid colliding with the stator, and the side seal contact is not so important near the corners of the triangle, so that’s where the approximation is most noticeable. Second, real Wankel rotors often have scoops taken out from the middles of their sides, to form mini-combustion chambers that guide and shape the combustion gases within the engine.</p>

<p>For more details of all this, see:</p>

<div class="footnotes">
  <ol>
    <li id="fn:nash">
      <p>Nash, David H. (1977), “Rotary engine geometry”, <em>Mathematics Magazine</em> 2: 87–89, <a href="https://doi.org/doi:10.1080/0025570X.1977.11976621">doi:10.1080/0025570X.1977.11976621</a>, <a href="https://www.jstor.org/stable/2689731">JSTOR:2689731</a> <a class="reversefootnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fnref:nash">↩</a></p>
    </li>
    <li id="fn:sp">
      <p>Shung, J. B. &amp; Pennock, G. R. (1994), “Geometry for trochoidal-type machines with conjugate envelopes”, <em>Mechanism and Machine Theory</em> 29 (1): 25–42, <a href="https://doi.org/10.1016/0094-114X(94)90017-5">doi:10.1016/0094-114X(94)90017-5</a> <a class="reversefootnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fnref:sp">↩</a></p>
    </li>
    <li id="fn:drogosz">
      <p>Drogosz, P. (2010), “Geometry of the Wankel rotary engine”, <em>Journal of KONES</em> 17 (3): 69–74, <a href="http://yadda.icm.edu.pl/yadda/element/bwmeta1.element.baztech-article-BUJ5-0031-0018">http://yadda.icm.edu.pl/yadda/element/bwmeta1.element.baztech-article-BUJ5-0031-0018</a> <a class="reversefootnote" href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html#fnref:drogosz">↩</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/104464015428969365">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-07-05T14:59:00Z</updated>
    <published>2020-07-05T14:59:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-07-06T00:35:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/098</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/098" rel="alternate" type="text/html"/>
    <title>TR20-098 |  Impossibility of Derandomizing the Isolation Lemma for all Families | 

	Rohit Gurjar, 

	Thomas Thierauf, 

	Manindra Agrawal</title>
    <summary>The Isolation Lemma states that when random weights are assigned to the elements of a finite set $E$, then in any given family of subsets of $E$, exactly one set has the minimum weight, with high probability. In this note, we present two proofs for the fact that it is impossible to efficiently derandomize the Isolation Lemma for arbitrary families.

The first proof is from Chari, Rohatgi and Srinivasan and uses the potential method. An alternate proof is due to the first author of this note. It uses the polynomial method. However, it is not written anywhere. The main purpose of this note is to present that proof. Additionally we show that the above lower bounds are almost tight with respect to various parameters.</summary>
    <updated>2020-07-05T06:22:25Z</updated>
    <published>2020-07-05T06:22:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-12T10:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17257</id>
    <link href="https://rjlipton.wordpress.com/2020/07/04/intellectual-fireworks/" rel="alternate" type="text/html"/>
    <title>Intellectual Fireworks?</title>
    <summary>Some different ideas for marking the Fourth “Founding Frenemies” source John Adams and Thomas Jefferson did not use Zoom. Their correspondence, from 1777 up to their deaths hours apart on July 4, 1826, fills a 600-page book. Today, Independence Day in the US, we consider the kind of intellectual fireworks represented by the correspondence. Jefferson […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Some different ideas for marking the Fourth</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/07/list-coincidence-adams-jefferson-2.jpg"><img alt="" class="alignright wp-image-17259" height="90" src="https://rjlipton.files.wordpress.com/2020/07/list-coincidence-adams-jefferson-2.jpg?w=180&amp;h=90" width="180"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">“Founding Frenemies” <a href="https://www.history.com/news/jefferson-adams-founding-frenemies">source</a></font></td>
</tr>
</tbody>
</table>
<p>
John Adams and Thomas Jefferson did not use Zoom. Their correspondence, from 1777 up to their deaths hours apart on July 4, 1826, fills a 600-page <a href="https://www.amazon.com/Adams-Jefferson-Letters-Complete-Correspondence-Jefferson/dp/0807842303">book</a>. </p>
<p>
Today, Independence Day in the US, we consider the kind of intellectual fireworks represented by the correspondence.</p>
<p><span id="more-17257"/></p>
<p>
Jefferson and Adams were intellectual opposites as well as political rivals. Adams favored a strong central government to bridle human passions, whereas Jefferson’s support for the French Revolution continued beyond its devolution into the Reign of Terror. They debated many other points of politics, philosophy, and culture. </p>
<p>
Abigail Adams, the wife of John, joined in some of the exchanges. Because she often stayed in Massachusetts while he was in Philadelphia or New York or elsewhere, the husband and wife exchanged many letters—over 1,100 in all. His letter to her on July 3, 1776, instituted the use of fireworks to celebrate anniversaries of the Declaration of Independence.</p>
<p>
Today there is not much in the way of fireworks displays. Most have been canceled because we cannot allow crowds to view them. In the Buffalo area, some townships are having small displays with limited access, and some displays are being set on high points for possible area viewing. So we felt we should write about fireworks of a different kind, a kind that is not restricted by the pandemic and might thrive through it. But first we’ll make a point about the history of fireworks.</p>
<p>
</p><p/><h2> Fireworks: Ancient, Early, and Modern </h2><p/>
<p/><p>
Fireworks go back at least 1,100 years to China, where chemists discovered the fun of stuffing volatile compounds into tubes of bamboo or paper and setting them off. Some have pyrotechnics going back another 1,000 years, to about 200 BCE, insofar as bamboo was known to pop with a loud sound when dried and heated. Gunpowder traveled best of the compounds and made its way into Europe at least by the 1200s. The first recorded wide-scale fireworks display in England was in 1486 for the wedding of King Henry VII to Elizabeth of York, which ended the Wars of the Roses. Shakespeare mentions fireworks in <em>Love’s Labours Lost</em>. The Mughals in India from the 1500s to the 1800s made fireworks a diversion for noble women on the Diwali holiday:</p>
<p/><p/>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/07/diwali_570_850.jpg"><img alt="" class="aligncenter size-medium wp-image-17260" height="254" src="https://rjlipton.files.wordpress.com/2020/07/diwali_570_850.jpg?w=300&amp;h=254" width="300"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cleveland Museum of Art <a href="https://www.clevelandart.org/art/1971.82">source</a></font>
</td>
</tr>
</tbody></table>
<p>
Our point is that 1776 isn’t even halfway back to the beginning of using fireworks for celebrations, even just in the West. Can we even call it “Early”? Lavish displays to mark major events were common by the mid-1700s. A royal display in 1749 was accompanied by orchestral music commissioned from George Frideric Handel and went ahead despite rain. Over 12,000 people also paid to attend the main rehearsal six days earlier, many braving an hours-long traffic jam on approaches to the London Bridge. That feels quite modern to us. Adams’s <a href="https://founders.archives.gov/documents/Adams/04-02-02-0016">letter</a> mentioned other social features we know today:</p>
<blockquote><p><b> </b> <em> It ought to be solemnized with Pomp and Parade, with Shews, Games, Sports, Guns, Bells, Bonfires and Illuminations from one End of this Continent to the other from this Time forward forever more. </em>
</p></blockquote>
<p/><p>
The pandemic has curtailed others of these. The major North American team sports have not resumed either. Some parades have been run in “reverse” mode: the floats and performers stay put while spectators drive by slowly in cars.</p>
<p>
Adams’s letter has another, earlier, passage that chills today. The letter begins by saying that the Declaration was supposed to have been made in December, 1775, and enumerates plans the colonies had made contingent on this. He then says that what caused the plans to be aborted was an outbreak of disease:</p>
<blockquote><p><b> </b> <em> All these Causes however in Conjunction would not have disappointed Us, if it had not been for a Misfortune, which could not be foreseen, and perhaps could not have been prevented, I mean the Prevalence of the small Pox among our Troops. . . . This fatal Pestilence compleated our Destruction.—It is a Frown of Providence upon Us, which We ought to lay to heart. </em>
</p></blockquote>
<p/><p>
The ellipsis is in the letter—as Ken’s children have pointed out, trailing off thought with dots in letters or e-mails or Facebook posts or texts is a distinctive habit of us older folk. Thus a specific outbreak of a contagious disease changed our history then as now.</p>
<p>
</p><p/><h2> Ideas: Ancient, Early, and Modern </h2><p/>
<p/><p>
We have <a href="https://rjlipton.wordpress.com/2020/06/21/some-real-and-some-virtual-news/">remarked</a> on how the pandemic has affected opportunities to exchange ideas and how to compensate. One impacted series that both of us intended to visit this spring has been the series of workshops at the Simons Institute in Berkeley. </p>
<p>
Still, the Simons Foundation has continued its other ways to stimulate ideas. Here we offer our congratulations to Venkatesan Guruswami, Omer Reingold, and David Woodruff, who have just been <a href="https://www.simonsfoundation.org/grant/simons-investigators/?tab=awardees&amp;filter_years=2020">appointed</a> as Simons investigators for 2020. </p>
<p>
In briefly talking about their work, we want to make a point about how the pandemic enables <em>taking the long view</em> of ideas—in a way that appointments such as these promote. It is easy to get wrapped up in immediate aspects of a current hot problem and not be aware that it has a history. The history may not involve exactly the same ideas as the problem, but related ideas whose importance was appreciated much earlier. “Early” may not mean the Middle Ages or the 1700s as with fireworks, but it can mean times before any of us were born.</p>
<p>
Venkatesan and Omer and David each have done some stellar research, broadly in various parts of theory. They each have many results, but we thought we would highlight just one result each. We picked a result that we think is representative, is deep, is beautiful, and is one that we personally admire the most.</p>
<p>
</p><p/><h3> “Ancient” Times </h3><p/>
<p/><p>
Venkatesan did important work on a problem that was created before complexity theory existed. Our favorite is his ground-breaking work on list decoding.</p>
<p>
What is the best way to encode data to protect it against various kinds of errors? This is still open. But Venkatesan changed the landscape. </p>
<p>
The questions about error correcting codes go back to the 1940’s. Usually the first results are <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">credited</a> to Richard Hamming in 1947. Soon the notion of list decoding was introduced. The cool idea is that doing not require an answer, but allow a list of possible answers. The hope is that with other information about the message we might be able to select <i>the</i> answer.</p>
<p>
Venkatesan and Ken’s colleague Atri Rudra found explicit <a href="https://en.wikipedia.org/wiki/List_decoding">codes</a> that achieve list-decoding capacity, that is, they have optimal redundancy. </p>
<p>
What we like so much is the model is so natural and so powerful. There are many applications of list decoding to complexity theory. See Madhu Sudan’s <a href="http://people.csail.mit.edu/madhu/papers/noneed/ifip-journ.ps">survey</a> for some additional comments. </p>
<p>
</p><p/><h3> Early Times </h3><p/>
<p/><p>
Omer did his most important work on problems that were first studied in the early days of complexity theory. Our favorite is his beautiful work on small-memory deterministic graph <a href="https://en.wikipedia.org/wiki/SL_(complexity)">walks</a>. </p>
<p>
Is <img alt="{\mathsf{L &lt; NL}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BL+%3C+NL%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{L &lt; NL}}"/>? This is still <a href="https://en.wikipedia.org/wiki/NL_(complexity)">open</a>. But Omer made a huge contribution to our understanding of fundamental complexity classes. Romas Aleliunas, Dick Karp, Laszlo Lovasz, and Charlie Rackoff proved earlier that random small space could navigate undirected graphs provided they could flip coins. In a sense Omer removed the coins to get his result that undirected graph connectivity is in <img alt="{\mathsf{L}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BL%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{L}}"/>. The previous result was easy—I can say that because I (Dick) was a co-author on it—but Omer’s theorem is deep.</p>
<p>
Omer’s <a href="https://omereingold.files.wordpress.com/2014/10/sl.pdf">proof</a> drew heavily on expander graphs and the zig-zag product from his earlier work with Salil Vadhan and Avi Wigderson for creating them. </p>
<p>
</p><p/><h3> Modern Times </h3><p/>
<p/><p>
David did his most important work on problems that were only created relatively recently. Our favorite is his work on approximately <a href="http://www.cs.cmu.edu/afs/cs/user/dwoodruf/www/knw10b.pdf">counting</a> distinct elements. This work is joint with Daniel Kane and Jelani Nelson and appeared at PODS 2010. It was the first streaming algorithm with an optimal combination of space usage and update time. Here is the relevant table from their paper (KNW):</p>
<p><a href="https://rjlipton.files.wordpress.com/2020/07/algtable.jpg"><img alt="" class="aligncenter wp-image-17261" height="163" src="https://rjlipton.files.wordpress.com/2020/07/algtable.jpg?w=500&amp;h=163" width="500"/></a></p>
<p>
Streaming algorithms are relatively new and parts of data science are newer. But working with data is old, as old as codes. This finally leads us to pose an outlandish question:</p>
<blockquote><p><b> </b> <em> Can all of this work be usefully interpreted from the standpoint of coding theory? </em>
</p></blockquote>
<p/><p>
This is outlandish, because the word “code” does not even appear in either Reingold’s paper or KNW. But part of holding coding theory to be a paradigm, as both Ken and I experienced in graduate school, is that its perspective should expand. Is this capable of creating intellectual fireworks? We’ll see.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Have a safe and happy fourth of July.</p>
<p>
[some small fixes]</p></font></font></div>
    </content>
    <updated>2020-07-05T00:41:25Z</updated>
    <published>2020-07-05T00:41:25Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="coding theory"/>
    <category term="David Woodruff"/>
    <category term="fireworks"/>
    <category term="Fourth of July"/>
    <category term="John Adams"/>
    <category term="Omer Reingold"/>
    <category term="pandemic"/>
    <category term="Simons Foundation"/>
    <category term="Thomas Jefferson"/>
    <category term="Venkatesan Guruswami"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-07-12T10:20:41Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/07/03/postdoc-in-quantum-computing-at-nagoya-and-mie-universities-apply-by-july-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/07/03/postdoc-in-quantum-computing-at-nagoya-and-mie-universities-apply-by-july-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc in quantum computing at Nagoya and Mie Universities (apply by July 15, 2020)</title>
    <summary>Nagoya and Mie Universities (Japan) are looking for several postdoctoral researchers to work on quantum computing, especially on the following subjects: 1) quantum algorithms, 2) quantum complexity theory, 3) theoretical aspects of quantum programming languages, 4) development of software verification tools for quantum programs, 5) quantum information theory. Website: http://francoislegall.com/jobs.html Email: legall@math.nagoya-u.ac.jp</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Nagoya and Mie Universities (Japan) are looking for several postdoctoral researchers to work on quantum computing, especially on the following subjects:</p>
<p>1) quantum algorithms,<br/>
2) quantum complexity theory,<br/>
3) theoretical aspects of quantum programming languages,<br/>
4) development of software verification tools for quantum programs,<br/>
5) quantum information theory.</p>
<p>Website: <a href="http://francoislegall.com/jobs.html">http://francoislegall.com/jobs.html</a><br/>
Email: legall@math.nagoya-u.ac.jp</p></div>
    </content>
    <updated>2020-07-03T11:18:55Z</updated>
    <published>2020-07-03T11:18:55Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-12T10:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4888</id>
    <link href="https://www.scottaaronson.com/blog/?p=4888" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4888#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4888" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Scott’s Zoom tip: Email the link!</title>
    <summary xml:lang="en-US">Like many academics, I’ve now been regularly “attending” conferences and giving talks via Zoom for four months. Naturally, I’ve learned a lot about how to use this platform—one that, despite numerous quirks and flaws, actually works well enough that it could probably replace at least 2/3 of in-person talks and meetings after the covid crisis […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>Like many academics, I’ve now been regularly “attending” conferences and giving talks via Zoom for four months.  Naturally, I’ve learned a lot about how to use this platform—one that, despite numerous quirks and flaws, <em>actually works</em> well enough that it could probably replace at least 2/3 of in-person talks and meetings after the covid crisis is over.  But one particular lesson is so important that I thought I’d make a public service announcement of it.  So without further ado:</p>



<p><strong>Email the link.</strong></p>



<p>You know, the thing like</p>



<p>https://us02web.zoom.us/jblahblah</p>



<p>that you actually click to get to the actual conversation.  <em>Definitely</em> email the link to the speaker (!).  But also email it to whomever said they plan to attend.  Resend the link between a day and an hour in advance, so that it doesn’t get buried, but turns up right away when people search their inboxes.  If possible, put the link in <em>every single email</em> about the meeting or lecture.  Even if you already sent the link for previous iterations of the meeting and it hasn’t changed, send it again.  Don’t assume people will find the link on the web.  Don’t make them click through five other links or open an attached PDF for it.  Don’t send ten emails that explain every possible detail of the meeting except how to get to it.  Just <strong>email the link.</strong>  That’s all.  Thanks!</p></div>
    </content>
    <updated>2020-07-03T06:43:42Z</updated>
    <published>2020-07-03T06:43:42Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-07-07T18:40:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7759</id>
    <link href="https://windowsontheory.org/2020/07/02/crowdsourcing-masters-program/" rel="alternate" type="text/html"/>
    <title>Crowdsourcing Masters program</title>
    <summary>Going directly from undergraduate to Ph.D can be a good idea for many students interested in research, but it’s not the only route or the best choice for everyone. As I wrote before, for students that discovered their interest in theoretical CS late in their undergrad, or perhaps after they graduated, a research Masters, can […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Going directly from undergraduate to Ph.D can be a good idea for many students interested in research, but it’s not the only route or the best choice for everyone.</p>



<p>As <a href="https://windowsontheory.org/2018/02/20/research-masters/">I wrote before</a>, for students that discovered their interest in theoretical CS late in their undergrad, or perhaps after they graduated, a research Masters, can be a great option. This is particularly the case if the program is funded (i.e., students get a stipend and don’t need to pay tuition). Such programs are not common in the U.S., but there are some excellent choices around the world.</p>



<p>Since (as far as I know) there is no single source listing such programs, I thought a crowdsourced Google spreadsheet might be useful and so created one here: <a href="http://tiny.cc/tcsmasters" rel="nofollow">http://tiny.cc/tcsmasters</a></p>



<p>If you know of more places, please fill out this form: <a href="https://forms.gle/qfnbEZYYYDtFCDpx9" rel="nofollow">https://forms.gle/qfnbEZYYYDtFCDpx9</a> </p></div>
    </content>
    <updated>2020-07-02T19:26:22Z</updated>
    <published>2020-07-02T19:26:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-07-12T10:20:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/30/postdoc-at-university-of-oxford-apply-by-september-11-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/30/postdoc-at-university-of-oxford-apply-by-september-11-2020/" rel="alternate" type="text/html"/>
    <title>postdoc at University of Oxford (apply by September 11, 2020)</title>
    <summary>All Souls College Oxford are advertising a 5 year postdoctoral research fellowship in theoretical computer science, with a tentative start date 1 Oct 2021. This is an exceptional opportunity for a first-rate early career researcher in theoretical computer science. Website: https://www.asc.ox.ac.uk/post-doctoral-research-fellowships-2020-further-particulars Email: pdrf.admin@all-souls.ox.ac.uk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>All Souls College Oxford are advertising a 5 year postdoctoral research fellowship in theoretical computer science, with a tentative start date 1 Oct 2021. This is an exceptional opportunity for a first-rate early career researcher in theoretical computer science.</p>
<p>Website: <a href="https://www.asc.ox.ac.uk/post-doctoral-research-fellowships-2020-further-particulars">https://www.asc.ox.ac.uk/post-doctoral-research-fellowships-2020-further-particulars</a><br/>
Email: pdrf.admin@all-souls.ox.ac.uk</p></div>
    </content>
    <updated>2020-06-30T16:27:02Z</updated>
    <published>2020-06-30T16:27:02Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-07-12T10:20:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/06/30/linkage</id>
    <link href="https://11011110.github.io/blog/2020/06/30/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>The five bridges puzzle (). Sort of like the bridges of Königsberg, but stochastic. A cute puzzle with a connection to percolation theory and connection games.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://scilogs.spektrum.de/hlf/the-five-bridges-puzzle/">The five bridges puzzle</a> (<a href="https://mathstodon.xyz/@11011110/104357604444143899"/>). Sort of like the bridges of Königsberg, but stochastic. A cute puzzle with a connection to percolation theory and connection games.</p>
  </li>
  <li>
    <p>Dubious journal publisher MDPI provides special-issue editors with some number of no-publication-charge slots, but requires that priority for these slots be given to first-world scholars, because they are the ones with “more abundant scientific research resources” (read: funds to pay publication charges). This didn’t sit well with three environmental health failure researchers, who <a href="https://retractionwatch.com/2020/06/16/failure-fails-as-publisher-privileges-the-privileged/">resigned their guest editorship over it</a> (<a href="https://mathstodon.xyz/@11011110/104363585936972806"/>, <a href="https://wash.leeds.ac.uk/what-the-f-how-we-failed-to-publish-a-journal-special-issue-on-failures/">see also</a>).</p>
  </li>
  <li>
    <p>On today’s edition of <a href="https://11011110.github.io/blog/2018/06/24/la-maddalena-non-reuleaux.html">not the Reuleaux triangle</a>, we have <a href="https://twitter.com/Nukaq/status/1273803547574972416">the logo of Whale Cove, Nunavut</a> (<a href="https://mathstodon.xyz/@11011110/104368587916436396"/>, <a href="https://www.metafilter.com/187552/Nunavut-Aesthetics">via</a>).  The sides of the triangle are straighter than a Reuleaux triangle would be, and its corners are slightly narrower than equilateral. Cool logo, though.</p>

    <p style="text-align: center;"><img alt="Logo of Whale Cove, Nunavut" src="https://11011110.github.io/blog/assets/2020/beluga-reuleaux.png"/></p>
  </li>
  <li>
    <p><a href="https://computerhistory.org/blog/discovering-dennis-ritchies-lost-dissertation/">Discovering Dennis Ritchie’s lost dissertation</a> (<a href="https://mathstodon.xyz/@11011110/104375200069651123"/>, <a href="https://news.ycombinator.com/item?id=23582070">via</a>). Ritchie’s doctoral committee signed off in 1968, but the Harvard Library wanted a bound copy and he was unwilling to pay the binding costs so he never officially received his Ph.D. According to the post, the thesis defines a simple model of computation characterizing primitive recursion, within which one can prove that the complexity and growth rates of primitive recursive functions are equal.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@tpfto/104376254903441351">J.M. redraws the xkcd golden spiral in Mathematica</a>. The thing that annoys me about it is the non-monotonic curvature, but that appears to be unavoidable.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/playlist?list=PLn0nrSd4xjjadfcMd5xvmJ_GNSLDi1ATn">Playlist of talk videos from this year’s Symposium on Theory of Computing</a> (<a href="https://mathstodon.xyz/@11011110/104389387469883738"/>).</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=wujEE3PRVUo">Video on the projective geometry of sidewalk trompe-l’oeil chalk art</a> (<a href="https://mathstodon.xyz/@11011110/104397742913356589"/>), and <a href="https://www.youtube.com/watch?v=L95cNBEfi5I">another one with less mathematics, more flying pigs and cute space aliens</a>.</p>
  </li>
  <li>
    <p><a href="https://www.makeuseof.com/tag/reduce-video-file-size-without-sacrificing-quality/">Some advice I needed on how to reduce video file size</a> (<a href="https://mathstodon.xyz/@11011110/104402114011362297"/>). Their suggestion of Handbrake worked well on its default settings and easily reached the file size I needed to reach, without sacrificing quality. (This was for a video of voice over still slides, so it should have been easy to compress, but iMovie couldn’t do it.)</p>
  </li>
  <li>
    <p><a href="https://blogs.ams.org/beyondreviews/2020/06/29/the-mathematics-genealogy-project-moves-to-the-cloud/">The Mathematics Genealogy Project rises into the clouds</a> (<a href="https://mathstodon.xyz/@11011110/104407629370705734"/>) like a phoenix from the flames of its dead former server. Or maybe not quite as poetically as that, but I use this resource daily in Wikipedia biography editing, so it’s a relief to learn that it’s back after its recent outage.</p>
  </li>
  <li>
    <p><a href="https://dl.acm.org/doi/10.1145/3357713.3384232">QCSP monsters and the demise of the Chen conjecture</a> (<a href="https://mathstodon.xyz/@11011110/104414859746330563"/>, <a href="https://www.youtube.com/watch?v=c2HjFlcTjQ0">talk video</a>). In STOC’20, Zhuk and Martin show that <a href="https://en.wikipedia.org/wiki/Schaefer%27s_dichotomy_theorem">dichotomy for constraint satisfaction</a> gets messier for quantified CSP. Chen conjectured that QCSP problems are either in NP or PSPACE-complete, but this new paper shows that coNP-completeness can happen for 3 elements and more elements lead to even more classes. Relatedly, <a href="http://eatcs.org/index.php/component/content/article/1-news/2849-the-eatcs-bestows-the-presburger-award-2020">Zhuk just won the Presburger Award</a>.</p>
  </li>
  <li>
    <p>I learned while writing <a href="https://en.wikipedia.org/wiki/Doyle_spiral">a Wikipedia article on Doyle spirals</a> (<a href="https://mathstodon.xyz/@11011110/104418935123493700"/>) that although the pure-mathematics work in this area dates to Coxeter in 1968 and the work of Thurston and his followers in the 1980s and 1990s, the use of spiral patterns of tangent circles to model plant growth can be traced back much earlier, to Gerrit van Iterson in 1907. The image below, which I used as the lead for the article, is an illustration of phylogeny from <a href="https://archive.org/details/popularsciencemo79newy/page/450/mode/2up">a 1911 <em>Popular Science</em> story about mathematical patterns in nature</a>.</p>

    <p style="text-align: center;"><img alt="Doyle spiral from _Popular Science_, 1911" src="https://11011110.github.io/blog/assets/2020/Doyle.png"/></p>
  </li>
  <li>
    <p><a href="https://www.lms.ac.uk/news-entry/26062020-1657/lms-prize-winners-2020">This year’s London Math Soc. prizewinners</a> (<a href="https://mathstodon.xyz/@11011110/104431647996227722"/>, <a href="https://twitter.com/hollykrieger/status/1276590144628416512">via</a>). For some reason they keep the <a href="https://www.lms.ac.uk/prizes/louisbachelierprize">Louis Bachelier Prize in a separate listing</a>. These results have already led me to add to Wikipedia brief articles on <a href="https://en.wikipedia.org/wiki/Maria_Bruna">Maria Bruna</a> (a Whitehead Prize winner) and <a href="https://en.wikipedia.org/wiki/Pauline_Barrieu">Pauline Barrieu</a> (Bachelier 2018).</p>
  </li>
  <li>
    <p><a href="https://www.chronicle.com/article/georgia-s-top-down/249095">A power struggle between the Georgia state university system and state government blocks Georgia Tech and other campuses from enacting any coronavirus safety rules</a> (<a href="https://mathstodon.xyz/@11011110/104435200227063842"/>).</p>
  </li>
</ul></div>
    </content>
    <updated>2020-06-30T16:06:00Z</updated>
    <published>2020-06-30T16:06:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-07-06T00:35:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/097</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/097" rel="alternate" type="text/html"/>
    <title>TR20-097 |  6-Uniform Maker-Breaker Game Is PSPACE-Complete | 

	Md Lutfar Rahman, 

	Thomas Watson</title>
    <summary>In a STOC 1976 paper, Schaefer proved that it is PSPACE-complete to determine the winner of the so-called Maker-Breaker game on a given set system, even when every set has size at most 11. Since then, there has been no improvement on this result. We prove that the game remains PSPACE-complete even when every set has size 6.</summary>
    <updated>2020-06-30T15:23:11Z</updated>
    <published>2020-06-30T15:23:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-07-12T10:20:32Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://kamathematics.wordpress.com/?p=188</id>
    <link href="https://kamathematics.wordpress.com/2020/06/30/virtual-stoc-2020-behind-the-screens/" rel="alternate" type="text/html"/>
    <title>Virtual STOC 2020 – Behind the Screens</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">In order to assist organizers of other virtual conferences, the general chairs of STOC 2020 (myself, Konstantin Makarychev, Yury Makarychev and Madhur Tulsiani, with input from PC chair Julia Chuzhoy) wrote a detailed document describing the design and execution of the conference. I personally felt the conference went about as well as it could have … <a class="more-link" href="https://kamathematics.wordpress.com/2020/06/30/virtual-stoc-2020-behind-the-screens/">Continue reading<span class="screen-reader-text"> "Virtual STOC 2020 – Behind the Screens"</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In order to assist organizers of other virtual conferences, the general chairs of STOC 2020 (myself, Konstantin Makarychev, Yury Makarychev and Madhur Tulsiani, with input from PC chair Julia Chuzhoy) wrote a detailed document describing the design and execution of the conference. I personally felt the conference went about as well as it could have gone, and despite many moving parts, there were minimal technical difficulties.</p>



<p>The guide is available here: <a href="https://docs.google.com/document/d/1nzyvfdsXLzqYXxxdjw1y_OHAYwGolHCZUkRVmlxG9BE/edit?ts=5efa758c" rel="noreferrer noopener" target="_blank">Virtual STOC 2020 – Behind the Screens</a>.</p>



<p>If you have any questions or comments, feel free to comment below, or join in the conversation on <a href="https://twitter.com/thegautamkamath/status/1277959908168695808">Twitter</a>.</p></div>
    </content>
    <updated>2020-06-30T13:13:16Z</updated>
    <published>2020-06-30T13:13:16Z</published>
    <category term="Events"/>
    <author>
      <name>Gautam</name>
    </author>
    <source>
      <id>https://kamathematics.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://kamathematics.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://kamathematics.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://kamathematics.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://kamathematics.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Kamathematics</title>
      <updated>2020-07-12T10:21:41Z</updated>
    </source>
  </entry>
</feed>
