<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-02-27T06:21:42Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.10051</id>
    <link href="http://arxiv.org/abs/1902.10051" rel="alternate" type="text/html"/>
    <title>Plane Hop Spanners for Unit Disk Graphs: Simpler and Better</title>
    <feedworld_mtime>1551225600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Biniaz:Ahmad.html">Ahmad Biniaz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10051">PDF</a><br/><b>Abstract: </b>The unit disk graph (UDG) is a widely employed model for the study of
wireless networks. In this model, wireless nodes are represented by points in
the plane and there is an edge between two points if and only if their
Euclidean distance is at most one. A hop spanner for the UDG is a spanning
subgraph $H$ such that for every edge $(p,q)$ in the UDG the topological
shortest path between $p$ and $q$ in $H$ has a constant number of edges. The
hop stretch factor of $H$ is the maximum number of edges of these paths. A hop
spanner is plane (i.e. embedded planar) if its edges do not cross each other.
</p>
<p>The problem of constructing hop spanners for the UDG has received
considerable attention in both computational geometry and wireless ad hoc
networks. Despite this attention, there has not been significant progress on
getting hop spanners that (i) are plane, and (ii) have low hop stretch factor.
Previous constructions either do not ensure the planarity or have high hop
stretch factor. The only construction that satisfies both conditions is due to
Catusse, Chepoi, and Vax\`{e}s (2010); their plane hop spanner has hop stretch
factor at most 449.
</p>
<p>Our main result is a simple algorithm that constructs a plane hop spanner for
the UDG. In addition to the simplicity, the hop stretch factor of the
constructed spanner is at most 341. Even though the algorithm itself is simple,
its analysis is rather involved. Several results on the plane geometry are
established in the course of the proof. These results are of independent
interest.
</p></div>
    </summary>
    <updated>2019-02-27T02:28:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.10046</id>
    <link href="http://arxiv.org/abs/1902.10046" rel="alternate" type="text/html"/>
    <title>Arithmetic Progressions of Length Three in Multiplicative Subgroups of $\mathbb{F}_p$</title>
    <feedworld_mtime>1551225600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jeremy F Alm <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10046">PDF</a><br/><b>Abstract: </b>In this paper, we give an algorithm for detecting non-trivial 3-APs in
multiplicative subgroups of $\mathbb{F}_p^\times$ that is substantially more
efficient than the naive approach. It follows that certain Var der Waerden-like
numbers can be computed in polynomial time.
</p></div>
    </summary>
    <updated>2019-02-27T02:28:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09959</id>
    <link href="http://arxiv.org/abs/1902.09959" rel="alternate" type="text/html"/>
    <title>Shapes from Echoes: Uniqueness from Point-to-Plane Distance Matrices</title>
    <feedworld_mtime>1551225600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krekovic:Miranda.html">Miranda Krekovic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dokmanic:Ivan.html">Ivan Dokmanic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vetterli:Martin.html">Martin Vetterli</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09959">PDF</a><br/><b>Abstract: </b>We study the problem of localizing a configuration of points and planes from
the collection of point-to-plane distances. This problem models simultaneous
localization and mapping from acoustic echoes as well as the notable "structure
from sound" approach to microphone localization with unknown sources. In our
earlier work we proposed computational methods for localization from
point-to-plane distances and noted that such localization suffers from various
ambiguities beyond the usual rigid body motions; in this paper we provide a
complete characterization of uniqueness. We enumerate equivalence classes of
configurations which lead to the same distance measurements as a function of
the number of planes and points, and algebraically characterize the related
transformations in both 2D and 3D. Here we only discuss uniqueness;
computational tools and heuristics for practical localization from
point-to-plane distances using sound will be addressed in a companion paper.
</p></div>
    </summary>
    <updated>2019-02-27T02:35:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09958</id>
    <link href="http://arxiv.org/abs/1902.09958" rel="alternate" type="text/html"/>
    <title>An Automatic Speedup Theorem for Distributed Problems</title>
    <feedworld_mtime>1551225600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brandt:Sebastian.html">Sebastian Brandt</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09958">PDF</a><br/><b>Abstract: </b>Recently, Brandt et al. [STOC'16] proved a lower bound for the distributed
Lov\'asz Local Lemma, which has been conjectured to be tight for sufficiently
relaxed LLL criteria by Chang and Pettie [FOCS'17]. At the heart of their
result lies a speedup technique that, for graphs of girth at least $2t+2$,
transforms any $t$-round algorithm for one specific LLL problem into a
$(t-1)$-round algorithm for the same problem. We substantially improve on this
technique by showing that such a speedup exists for any locally checkable
problem $\Pi$, with the difference that the problem $\Pi_1$ the inferred
$(t-1)$-round algorithm solves is not (necessarily) the same problem as $\Pi$.
Our speedup is automatic in the sense that there is a fixed procedure that
transforms a description for $\Pi$ into a description for $\Pi_1$ and
reversible in the sense that any $(t-1)$-round algorithm for $\Pi_1$ can be
transformed into a $t$-round algorithm for $\Pi$. In particular, for any
locally checkable problem $\Pi$ with exact deterministic time complexity $T(n,
\Delta) \leq t$ on graphs with $n$ nodes, maximum node degree $\Delta$, and
girth at least $2t+2$, there is a sequence of problems $\Pi_1, \Pi_2, \dots$
with time complexities $T(n, \Delta)-1, T(n, \Delta)-2, \dots$, that can be
inferred from $\Pi$.
</p>
<p>As a first application of our generalized speedup, we solve a long-standing
open problem of Naor and Stockmeyer [STOC'93]: we show that weak $2$-coloring
in odd-degree graphs cannot be solved in $o(\log^* \Delta)$ rounds, thereby
providing a matching lower bound to their upper bound.
</p></div>
    </summary>
    <updated>2019-02-27T02:27:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09953</id>
    <link href="http://arxiv.org/abs/1902.09953" rel="alternate" type="text/html"/>
    <title>Cellular morphogenesis of three-dimensional tensegrity structures</title>
    <feedworld_mtime>1551225600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aloui:Omar.html">Omar Aloui</a>, Jessica Flores, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Orden:David.html">David Orden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rhode=Barbarigos:Landolf.html">Landolf Rhode-Barbarigos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09953">PDF</a><br/><b>Abstract: </b>The topology and form finding of tensegrity structures have been studied
extensively since the introduction of the tensegrity concept. However, most of
these studies address topology and form separately, where the former
represented a research focus of rigidity theory and graph theory, while the
latter attracted the attention of structural engineers. In this paper, a
biomimetic approach for the combined topology and form finding of spatial
tensegrity systems is introduced. Tensegrity cells, elementary infinitesimally
rigid self-stressed structures that have been proven to compose any tensegrity,
are used to generate more complex tensegrity structures through the
morphogenesis mechanisms of adhesion and fusion. A methodology for constructing
a basis to describe the self-stress space is also provided. Through the
definition of self-stress, the cellular morphogenesis method can integrate
design considerations, such as a desired shape or number of nodes and members,
providing great flexibility and control over the tensegrity structure
generated.
</p></div>
    </summary>
    <updated>2019-02-27T02:28:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09841</id>
    <link href="http://arxiv.org/abs/1902.09841" rel="alternate" type="text/html"/>
    <title>A new lower bound on the maximum number of plane graphs using production matrices</title>
    <feedworld_mtime>1551225600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huemer:Clemens.html">Clemens Huemer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pilz:Alexander.html">Alexander Pilz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Silveira:Rodrigo_I=.html">Rodrigo I. Silveira</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09841">PDF</a><br/><b>Abstract: </b>We use the concept of production matrices to show that there exist sets of
$n$ points in the plane that admit $\Omega(42.11^n)$ crossing-free geometric
graphs. This improves the previously best known bound of $\Omega(41.18^n)$ by
Aichholzer et al. (2007).
</p></div>
    </summary>
    <updated>2019-02-27T02:40:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09733</id>
    <link href="http://arxiv.org/abs/1902.09733" rel="alternate" type="text/html"/>
    <title>Towards Real-time 3D Reconstruction using Consumer UAVs</title>
    <feedworld_mtime>1551225600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Qiaosong.html">Qiaosong Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09733">PDF</a><br/><b>Abstract: </b>We present a near real-time solution for 3D reconstruction from aerial images
captured by consumer UAVs. Our core idea is to simplify the multi-view stereo
problem into a series of two-view stereo matching problems. Our method applies
to UAVs equipped with only one camera and does not require special stereo
capturing setups. We found that the neighboring two video frames taken by UAVs
flying at a mid-to-high cruising altitude can be approximated as left and right
views from a virtual stereo camera. Leveraging GPU-accelerated real-time stereo
estimation and efficient PnP correspondence solving algorithms, our system
simultaneously predicts scene geometry and camera position/orientation from the
virtual stereo cameras. Also, this method allows user-selection of varying
baseline lengths, which provides more flexibility given the trade-off between
camera resolution, effective measuring distance, flight altitude and mapping
accuracy. Our method outputs dense point clouds at a constant speed of 25
frames per second and is validated on a variety of real-world datasets with
satisfactory results.
</p></div>
    </summary>
    <updated>2019-02-27T02:29:09Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09702</id>
    <link href="http://arxiv.org/abs/1902.09702" rel="alternate" type="text/html"/>
    <title>A Unifying Framework for Spectrum-Preserving Graph Sparsification and Coarsening</title>
    <feedworld_mtime>1551225600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Gecia Bravo Hermsdorff, Lee M. Gunderson <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09702">PDF</a><br/><b>Abstract: </b>How might one "reduce" a graph? That is, generate a smaller graph that
preserves the global structure at the expense of discarding local details?
There has been extensive work on both graph sparsification (removing edges) and
graph coarsening (merging nodes, often by edge contraction); however, these
operations are currently treated separately. Interestingly, for a planar graph,
edge deletion corresponds to edge contraction in its planar dual (and more
generally, for a graphical matroid and its dual). Moreover, with respect to the
dynamics induced by the graph Laplacian (e.g., diffusion), deletion and
contraction are physical manifestations of two reciprocal limits: edge weights
of $0$ and $\infty$, respectively. In this work, we provide a unifying
framework that captures both of these operations, allowing one to
simultaneously coarsen and sparsify a graph, while preserving its large-scale
structure. Using synthetic models and real-world datasets, we validate our
algorithm and compare it with existing methods for graph coarsening and
sparsification. While modern spectral schemes focus on the Laplacian (indeed,
an important operator), our framework preserves its inverse, allowing one to
quantitatively compare the effect of edge deletion with the (now finite) effect
of edge contraction.
</p></div>
    </summary>
    <updated>2019-02-27T02:28:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09597</id>
    <link href="http://arxiv.org/abs/1902.09597" rel="alternate" type="text/html"/>
    <title>On reachability problems for low dimensional matrix semigroups</title>
    <feedworld_mtime>1551225600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Colcombet:Thomas.html">Thomas Colcombet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ouaknine:Jo=euml=l.html">Joël Ouaknine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Semukhin:Pavel.html">Pavel Semukhin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Worrell:James.html">James Worrell</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09597">PDF</a><br/><b>Abstract: </b>We consider the Membership and the Half-space Reachability Problems for
matrices in dimensions two and three. Our first main result is that the
Membership Problem is decidable for fintely generated sub-semigroups of the
Heisenberg group over integer numbers. Furthermore, we prove two decidability
results for the Half-space reachability problem. Namely, we show that this
problem is decidable for sub-semigroups of $\mathrm{GL}(2,\mathbb{Z})$ and of
the Heisenberg group over rational numbers.
</p></div>
    </summary>
    <updated>2019-02-27T02:25:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09565</id>
    <link href="http://arxiv.org/abs/1902.09565" rel="alternate" type="text/html"/>
    <title>Dynamic Maintenance of the Lower Envelope of Pseudo-Lines</title>
    <feedworld_mtime>1551225600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Agarwal:Pankaj_K=.html">Pankaj K. Agarwal</a>, Ravid Cohen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Halperin:Dan.html">Dan Halperin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mulzer:Wolfgang.html">Wolfgang Mulzer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09565">PDF</a><br/><b>Abstract: </b>We present a fully dynamic data structure for the maintenance of lower
envelopes of pseudo-lines. The structure has $O(\log^2 n)$ update time and
$O(\log n)$ vertical ray shooting query time. To achieve this performance, we
devise a new algorithm for finding the intersection between two lower envelopes
of pseudo-lines in $O(\log n)$ time, using \emph{tentative} binary search; the
lower envelopes are special in that at $x=-\infty$ any pseudo-line contributing
to the first envelope lies below every pseudo-line contributing to the second
envelope. The structure requires $O(n)$ storage space.
</p></div>
    </summary>
    <updated>2019-02-27T02:29:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09523</id>
    <link href="http://arxiv.org/abs/1902.09523" rel="alternate" type="text/html"/>
    <title>Characterizing PSPACE with shallow non-confluent P systems</title>
    <feedworld_mtime>1551225600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leporati:Alberto.html">Alberto Leporati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manzoni:Luca.html">Luca Manzoni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mauri:Giancarlo.html">Giancarlo Mauri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Porreca:Antonio_E=.html">Antonio E. Porreca</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zandron:Claudio.html">Claudio Zandron</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09523">PDF</a><br/><b>Abstract: </b>In P systems with active membranes, the question of understanding the power
of non-confluence within a polynomial time bound is still an open problem. It
is known that, for shallow P systems, that is, with only one level of nesting,
non-confluence allows them to solve conjecturally harder problems than
confluent P systems, thus reaching PSPACE. Here we show that PSPACE is not only
a bound, but actually an exact characterization. Therefore, the power endowed
by non-confluence to shallow P systems is equal to the power gained by
confluent P systems when non-elementary membrane division and polynomial depth
are allowed, thus suggesting a connection between the roles of non-confluence
and nesting depth.
</p></div>
    </summary>
    <updated>2019-02-27T02:20:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.07785</id>
    <link href="http://arxiv.org/abs/1902.07785" rel="alternate" type="text/html"/>
    <title>Counting basic-irreducible factors mod $p^k$ in deterministic poly-time and $p$-adic applications</title>
    <feedworld_mtime>1551225600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dwivedi:Ashish.html">Ashish Dwivedi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mittal:Rajat.html">Rajat Mittal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saxena:Nitin.html">Nitin Saxena</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07785">PDF</a><br/><b>Abstract: </b>Finding an irreducible factor, of a polynomial $f(x)$ modulo a prime $p$, is
not known to be in deterministic polynomial time. Though there is such a
classical algorithm that {\em counts} the number of irreducible factors of
$f\bmod p$. We can ask the same question modulo prime-powers $p^k$. The
irreducible factors of $f\bmod p^k$ blow up exponentially in number; making it
hard to describe them. Can we count those irreducible factors $\bmod~p^k$ that
remain irreducible mod $p$? These are called {\em basic-irreducible}. A simple
example is in $f=x^2+px \bmod p^2$; it has $p$ many basic-irreducible factors.
Also note that, $x^2+p \bmod p^2$ is irreducible but not basic-irreducible!
</p>
<p>We give an algorithm to count the number of basic-irreducible factors of
$f\bmod p^k$ in deterministic poly(deg$(f),k\log p$)-time. This solves the open
questions posed in (Cheng et al, ANTS'18 \&amp; Kopp et al, Math.Comp.'19). In
particular, we are counting roots $\bmod\ p^k$; which gives the first
deterministic poly-time algorithm to compute Igusa zeta function of $f$. Also,
our algorithm efficiently partitions the set of all basic-irreducible factors
(possibly exponential) into merely deg$(f)$-many disjoint sets, using a compact
tree data structure and {\em split} ideals.
</p></div>
    </summary>
    <updated>2019-02-27T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1901.06628</id>
    <link href="http://arxiv.org/abs/1901.06628" rel="alternate" type="text/html"/>
    <title>Efficiently factoring polynomials modulo $p^4$</title>
    <feedworld_mtime>1551225600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dwivedi:Ashish.html">Ashish Dwivedi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mittal:Rajat.html">Rajat Mittal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saxena:Nitin.html">Nitin Saxena</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1901.06628">PDF</a><br/><b>Abstract: </b>Polynomial factoring has famous practical algorithms over fields-- finite,
rational \&amp; $p$-adic. However, modulo prime powers it gets hard as there is
non-unique factorization and a combinatorial blowup ensues. For example, $x^2+p
\bmod p^2$ is irreducible, but $x^2+px \bmod p^2$ has exponentially many
factors! We present the first randomized poly(deg $f, \log p$) time algorithm
to factor a given univariate integral $f(x)$ modulo $p^k$, for a prime $p$ and
$k \leq 4$. Thus, we solve the open question of factoring modulo $p^3$ posed in
(Sircana, ISSAC'17).
</p>
<p>Our method reduces the general problem of factoring $f(x) \bmod p^k$ to that
of {\em root finding} in a related polynomial $E(y) \bmod\langle p^k,
\varphi(x)^\ell \rangle$ for some irreducible $\varphi \bmod p$. We could
efficiently solve the latter for $k\le4$, by incrementally transforming $E(y)$.
Moreover, we discover an efficient and strong generalization of Hensel lifting
to lift factors of $f(x) \bmod p$ to those $\bmod\ p^4$ (if possible). This was
previously unknown, as the case of repeated factors of $f(x) \bmod p$ forbids
classical Hensel lifting.
</p></div>
    </summary>
    <updated>2019-02-27T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-25562705.post-2251645165874378750</id>
    <link href="http://aaronsadventures.blogspot.com/feeds/2251645165874378750/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=25562705&amp;postID=2251645165874378750" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/2251645165874378750" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/25562705/posts/default/2251645165874378750" rel="self" type="application/atom+xml"/>
    <link href="http://aaronsadventures.blogspot.com/2019/02/impossibility-results-in-fairness-as.html" rel="alternate" type="text/html"/>
    <title>Impossibility Results in Fairness as Bayesian Inference</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">One of the most striking results about fairness in machine learning is the impossibility result that <a href="https://www.liebertpub.com/doi/full/10.1089/big.2016.0047">Alexandra Chouldechova</a>, and separately<a href="https://arxiv.org/abs/1609.05807"> Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan</a> discovered a few years ago. These papers say something very crisp. I'll focus here on the binary classification setting that Alex studies because it is much simpler. There are (at least) three reasonable properties you would want your "fair" classifiers to have. They are:<br/><div><ol><li><b>False Positive Rate Balance</b>: The rate at which your classifier makes errors in the positive direction (i.e. labels negative examples positive) should be the same across groups.</li><li><b>False Negative Rate Balance</b>:  The rate at which your classifier makes errors in the negative direction (i.e. labels positive examples negative) should be the same across groups.</li><li><b>Predictive Parity</b>: The statistical "meaning" of a positive classification should be the same across groups (we'll be more specific about what this means in a moment)</li></ol><div>What Chouldechova and KMR show is that if you want all three, you are out of luck --- unless you are in one of two very unlikely situations: Either you have a <i>perfect</i> classifier that never errs, or the <i>base rate</i> is exactly the same for both populations --- i.e. both populations have exactly the same frequency of positive examples. If you don't find yourself in one of these two unusual situations, then you have to give up on properties 1, 2, or 3. </div></div><div><br/></div><div>This is discouraging, because there are good reasons to want each of properties 1, 2, and 3. And these aren't measures made up in order to formulate an impossibility result --- they have their root in the <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Propublica/COMPASS controversy</a>. Roughly speaking, Propublica discovered that the COMPASS recidivism prediction algorithm violated false positive and negative rate balance, and they took the position that this made the classifier <i>unfair</i>. Northpointe (the creators of the COMPASS algorithm) responded by saying that their algorithm satisfied predictive parity, and took the position that this made the classifier fair. They were seemingly talking past each other by using two different definitions of what "fair" should mean. What the impossibility result says is that there is no way to satisfy both sides of this debate. </div><div><br/></div><div>So why is this result true? The proof in Alex's paper can't be made simpler --- its already a one liner, following from an algebraic identity. But the first time I read it I didn't have a great intuition for <i>why</i> it held. Viewing the statement through the lens of Bayesian inference made the result very intuitive (at least for me). With this viewpoint, all the impossibility result is saying is: "If you have different <i>priors</i> about some event (say that a released inmate will go on to commit a crime) for two different populations, and you receive evidence of the same strength for both populations, then you will have different posteriors as well". This is now bordering on obvious --- because your posterior belief about an event is a combination of your prior belief and the new evidence you have received, weighted by the strength of that evidence.  </div><div><br/></div><div>Lets walk through this. Suppose we have two populations, call them $A$s and $B$s. Individuals $x$ from these populations have some true binary label $\ell(x) \in \{0,1\}$ which we are trying to predict. Individuals from the two populations are drawn from different distributions, which we'll call $D_A$ and $D_B$. We have some classifier that predicts labels $\hat\ell(x)$, and we would like it to satisfy the three fairness criteria defined above. First, lets define some terms:<br/><br/>The <i>base rate</i> for a population $i$ is just the frequency of positive labels:<br/>$$p_i = \Pr_{x \sim D_i}[\ell(x) = 1].$$<br/>The <i>false positive </i>and <i>false negative </i>rates of the classifier are:<br/>$$FPR_i = \Pr_{x \sim D_i}[\hat\ell(x) = 1 | \ell(x) = 0] \ \ \ \ FNR_i = \Pr_{x \sim D_i}[\hat\ell(x) = 0 | \ell(x) = 1].$$<br/>And the <i>positive predictive value</i> of the classifier is:<br/>$$PPV_i = \Pr_{x \sim D_i}[\ell(x) = 1 | \hat\ell(x)=1].$$</div><div>Satisfying all three fairness constraints just means finding a classifier such that $FPR_A = FPR_B$, $FNR_A = FNR_B$, and $PPV_A = PPV_B$.<br/><br/>How should we prove that this is impossible? All three of these quantities are conditional probabilities, so we are essentially obligated to apply Bayes Rule:<br/>$$PPV_i =  \Pr_{x \sim D_i}[\ell(x) = 1 | \hat\ell(x)=1] = \frac{ \Pr_{x \sim D_i}[\hat\ell(x)=1 | \ell(x) = 1]\cdot \Pr_{x \sim D_i} [\ell(x) = 1]}{ \Pr_{x \sim D_i}[\hat \ell(x) = 1]}$$<br/>But now these quantities on the right hand side are things we have names for. Substituting in, we get:<br/>$$PPV_i  = \frac{p_i(1-FNR_i)}{p_i(1-FNR_i) + (1-p_i)FPR_i}$$<br/><br/>And so now we see the problem. Suppose we have $FNR_A = FNR_B$ and $FPR_A = FPR_B$. Can we have $PPV_A = PPV_B$? There are only two ways. If $p_A = p_B$, then we are done, because the right hand side is the same for either $i \in \{A,B\}$. But if the base rates are different, then the only way to make these two quantities equal is if $FNR_i = FPR_i = 0$ --- i.e. if our classifier is perfect.<br/><br/>The piece of intuition here is that the base rate is our prior belief that $\ell(x) = 1$, before we see the output of the classifier. The positive predictive value is our <i>posterior</i> belief that $\ell(x) = 1$, after we see the output of the classifier. And all we need to know about the classifier in order to apply Bayes rule to derive our posterior from our prior is its false positive rate and its false negative rate --- these fully characterize the "strength of the evidence." Hence: "If our prior probabilities differ, and we see evidence of a positive label of the same strength, then our posterior probabilities will differ as well."<br/><br/>Once you realize this, then you can generalize the fairness impossibility result to other settings by making equally obvious statements about probability elsewhere. :-)<br/><br/>For example, suppose we generalize the labels to be real valued instead of binary --- so when making decisions, we can model individuals using shades of gray. (e.g. in college admissions, we don't have to model individuals as "qualified" or not, but rather can model talent as a real value.) Lets fix a model for concreteness, but the particulars are not important. (The model here is related to my paper with <a href="https://www.cis.upenn.edu/~kannan/">Sampath Kannan</a> and<a href="http://www.its.caltech.edu/~jziani/"> Juba Ziani </a>on <a href="https://arxiv.org/abs/1808.09004">the downstream effects of affirmative action</a>)<br/><br/>Suppose that in population $i$, labels are distributed according to a Gaussian distribution with mean $\mu_i$: $\ell(x) \sim N(\mu_i, 1)$. For an individual from group $i$, we have a test that gives an unbiased estimator of their label, with some standard deviation $\sigma_i$: $\hat \ell(x) \sim N(\ell(x), \sigma_i)$.<br/><br/>In a model like this, we have analogues of our fairness desiderata in the binary case:<br/><br/><ul><li><b>Analogue of Error Rate Balance</b><i style="font-weight: bold;">: </i>We would like our test to be equally informative about both populations: $\sigma_A = \sigma_B$. </li><li><b>Analogue of Predictive Parity</b>: Any test score $t$ should induce the same posterior expectation on true labels across populations: $$E_{D_A}[\ell(x) | \hat \ell(x) = t] = E_{D_B}[\ell(x) | \hat \ell(x) = t]$$ </li></ul><div>Can we satisfy both of these conditions at the same time? Because the normal distribution is <i>self conjugate</i> (that's why we chose it!) Bayes Rule simplifies to have a nice closed form, and we can compute our posteriors as follows:</div><div>$$E_{D_i}[\ell(x) | \hat \ell(x) = t] = \frac{\sigma_i^2}{\sigma_i^2 + 1}\cdot \mu_i + \frac{1}{\sigma_i^2 + 1}\cdot t$$</div><div>So there are only two ways we can achieve both properties:</div><div><ol><li>We can of course satisfy both conditions if the prior distributions are the same for both groups: $\mu_A = \mu_B$. Then we can set $\sigma_A = \sigma_B$ and observe that the right hand side of the above expression is identical for $i \in \{A, B\}$.</li><li>We can also satisfy both conditions if the prior means are different, but the signal is perfect: i.e. $\sigma_A = \sigma_B = 0$. (Then both posterior means are just $t$, independent of the prior means). </li></ol></div>But we can see from inspection these are the only two cases. If $\sigma_A = \sigma_B$, but the prior means are different, then the posterior means will be different for every $t$. This is really the same impossibility result as in the binary case: all it is saying is that if I have different priors about different groups, but the evidence I receive has the same strength, then my posteriors will also be different.<br/><br/>So the mathematical fact is simple --- but its implications remain deep. It means we have to choose between equalizing a decision maker's posterior about the label of an individual, or providing an equally accurate signal about each individual, and that we cannot have both. Unfortunately, living without either one of these conditions can lead to real harm.<br/><br/></div><div><br/></div></div>
    </content>
    <updated>2019-02-26T20:41:00Z</updated>
    <published>2019-02-26T20:41:00Z</published>
    <author>
      <name>Aaron Roth</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/111805394598997130229</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-25562705</id>
      <category term="game theory"/>
      <category term="news"/>
      <author>
        <name>Aaron Roth</name>
        <email>noreply@blogger.com</email>
      </author>
      <link href="http://aaronsadventures.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://aaronsadventures.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/25562705/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <title>Adventures in Computation</title>
      <updated>2019-02-26T22:41:27Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4283341625722054774</id>
    <link href="https://blog.computationalcomplexity.org/feeds/4283341625722054774/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/problems-with-point-exploring-math-and.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4283341625722054774" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4283341625722054774" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/problems-with-point-exploring-math-and.html" rel="alternate" type="text/html"/>
    <title>Problems with a Point: Exploring Math and Computer Science</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
As you can see from Lance's tweet<br/>
<br/>
<br/>
               Problems with a Point: Exploring Math and Computer Science<br/>
               by Gasarch and Kruskal<br/>
<br/>
(ADDED LATER- the World scientific website has more info than amazon and has a table of contents, so here it is: <a href="https://www.worldscientific.com/worldscibooks/10.1142/11261#t=toc">here</a>)<br/>
<br/>
is now available! The tweet says its $68.00 but that's hardcover- paperback is $38.00 (are covers that expensive) and if you like your books already broken in, there are some used copies for $89.00. Makes sense to me (no it doesn't!). Could be the topic of a blog post (probably already was).<br/>
<br/>
Okay, so whats in the book?  One of my favorite types of blog posts is when I make a point ABOUT math and then do some math to underscore that point.  I went through all of my blogs (all? No, I doubt I did that) and picked out blogs of that type. With Clyde's help we EXPANDED and POLISHED and GOT THE MATH RIGHT (in some cases I didn't have any math so we had to supply it).<br/>
<br/>
When I first got a copy (about a month ago) I just couldn't stop reading it. I really like it! This is a non-trivial remark -- often authors get tired of their book, or after a while and wonder things like ``why did I write 300 page on the muffin problem? What was I thinking?'' So the fact that I am very pleased with it is not obvious. Does it mean you will?<br/>
<br/>
If you ever thought `I wish bill would clean up his posts spelling and grammar AND expand on the math AND make it a more cohesive whole' then buy the book!<br/>
<br/>
I will in future posts describe more about writing the book, but this is probably my last post where I plug the book.<br/>
<br/>
bill g.</div>
    </content>
    <updated>2019-02-26T17:20:00Z</updated>
    <published>2019-02-26T17:20:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-27T05:22:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09465</id>
    <link href="http://arxiv.org/abs/1902.09465" rel="alternate" type="text/html"/>
    <title>Adaptive Estimation for Approximate k-Nearest-Neighbor Computations</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/LeJeune:Daniel.html">Daniel LeJeune</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Baraniuk:Richard_G=.html">Richard G. Baraniuk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heckel:Reinhard.html">Reinhard Heckel</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09465">PDF</a><br/><b>Abstract: </b>Algorithms often carry out equally many computations for "easy" and "hard"
problem instances. In particular, algorithms for finding nearest neighbors
typically have the same running time regardless of the particular problem
instance. In this paper, we consider the approximate k-nearest-neighbor
problem, which is the problem of finding a subset of O(k) points in a given set
of points that contains the set of k nearest neighbors of a given query point.
We propose an algorithm based on adaptively estimating the distances, and show
that it is essentially optimal out of algorithms that are only allowed to
adaptively estimate distances. We then demonstrate both theoretically and
experimentally that the algorithm can achieve significant speedups relative to
the naive method.
</p></div>
    </summary>
    <updated>2019-02-26T23:25:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09407</id>
    <link href="http://arxiv.org/abs/1902.09407" rel="alternate" type="text/html"/>
    <title>Polynomially Ambiguous Probabilistic Automata on Restricted Languages</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bell:Paul_C=.html">Paul C. Bell</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09407">PDF</a><br/><b>Abstract: </b>We consider the computability and complexity of decision questions for
Probabilistic Finite Automata (PFA) with sub-exponential ambiguity. We show
that the emptiness problem for non strict cutpoints of polynomially ambiguous
PFA remains undecidable even when the input word is over a bounded language and
all PFA transition matrices are commutative. In doing so, we introduce a new
technique based upon the Turakainen construction of a PFA from a Weighted
Finite Automata which can be used to generate PFA of lower dimensions and of
subexponential ambiguity. We also study freeness problems for polynomially
ambiguous PFA and study the border of decidability and tractability for various
cases.
</p></div>
    </summary>
    <updated>2019-02-26T23:24:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09377</id>
    <link href="http://arxiv.org/abs/1902.09377" rel="alternate" type="text/html"/>
    <title>Optimal Distributed Covering Algorithms</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ben=Basat:Ran.html">Ran Ben-Basat</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Even:Guy.html">Guy Even</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kawarabayashi:Ken=ichi.html">Ken-ichi Kawarabayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schwartzman:Gregory.html">Gregory Schwartzman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09377">PDF</a><br/><b>Abstract: </b>We present a time-optimal deterministic distributed algorithm for
approximating a minimum weight vertex cover in hypergraphs of rank $f$. This
problem is equivalent to the Minimum Weight Set Cover problem in which the
frequency of every element is bounded by $f$. The approximation factor of our
algorithm is $(f+\epsilon)$. Our algorithm runs in the CONGEST model and
requires $O(\log\Delta/ \log\log\Delta)$ rounds, for constants
$\epsilon\in(0,1]$ and $f\in N^+$. This is the first distributed algorithm for
this problem whose running time does not depend on the vertex weights nor the
number of vertices. For constant values of $f$ and $\epsilon$, our algorithm
improves over the $(f+\epsilon)$-approximation algorithm of KMW06 whose running
time is $O(\log \Delta + \log W)$, where $W$ is the ratio between the largest
and smallest vertex weights in the graph. Our algorithm also achieves an
$f$-approximation for the problem in $O(f\log n)$ rounds, improving over the
classical result of KVY94 that achieves a running time of $O(f\log^2 n)$.
Finally, for weighted vertex cover ($f=2$) our algorithm achieves a
\emph{deterministic} running time of $O(\log n)$, matching the
\emph{randomized} previously best result of KY11. We also show that integer
covering-programs can be reduced to the Minimum Weight Set Cover problem in the
distributed setting. This allows us to achieve an $(f+\epsilon)$-approximate
integral solution in $O(\frac{\log\Delta}{\log\log\Delta}+(f\cdot\log
M)^{1.01}\log\epsilon^{-1}(\log\Delta)^{0.01})$ rounds, where $f$ bounds the
number of variables in a constraint, $\Delta$ bounds the number of constraints
a variable appears in, and $M=\max \{1, 1/a_{\min}\}$, where $a_{min}$ is the
smallest normalized constraint coefficient. This improves over the results of
KMW06 for the integral case, which runs in $O(\epsilon^{-4}\cdot f^4\cdot \log
f\cdot\log(M\cdot\Delta))$ rounds.
</p></div>
    </summary>
    <updated>2019-02-26T23:28:43Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09234</id>
    <link href="http://arxiv.org/abs/1902.09234" rel="alternate" type="text/html"/>
    <title>On One-Round Discrete Voronoi Games</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berg:Mark_de.html">Mark de Berg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kisfaludi=Bak:S=aacute=ndor.html">Sándor Kisfaludi-Bak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mehr:Mehran.html">Mehran Mehr</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09234">PDF</a><br/><b>Abstract: </b>Let $V$ be a multiset of $n$ points in $\mathbb{R}^d$, which we call voters,
and let $k\geq 1$ and $\ell\geq 1$ be two given constants. We consider the
following game, where two players $\mathcal{P}$ and $\mathcal{Q}$ compete over
the voters in $V$: First, player $\mathcal{P}$ selects $k$ points in
$\mathbb{R}^d$, and then player $\mathcal{Q}$ selects $\ell$ points in
$\mathbb{R}^d$. Player $\mathcal{P}$ wins a voter $v\in V$ iff
$\mathrm{dist}(v,P) \leq \mathrm{dist}(v,Q)$, where $\mathrm{dist}(v,P) :=
\min_{p\in P} \mathrm{dist}(v,p)$ and $\mathrm{dist}(v,Q)$ is defined
similarly. Player $\mathcal{P}$ wins the game if he wins at least half the
voters. The algorithmic problem we study is the following: given $V$, $k$, and
$\ell$, how efficiently can we decide if player $\mathcal{P}$ has a winning
strategy, that is, if $\mathcal{P}$ can select his $k$ points such that he wins
the game no matter where $\mathcal{Q}$ places her points.
</p>
<p>Banik et al. devised a singly-exponential algorithm for the game in
$\mathbb{R}^1$, for the case $k=\ell$. We improve their result by presenting
the first polynomial-time algorithm for the game in $\mathbb{R}^1$. Our
algorithm can handle arbitrary values of $k$ and $\ell$. We also show that if
$d\geq 2$, deciding if player $\mathcal{P}$ has a winning strategy is
$\Sigma_2^P$-hard when $k$ and $\ell$ are part of the input. Finally, we prove
that for any dimension $d$, the problem is contained in the complexity class
$\exists\forall \mathbb{R}$, and we give an algorithm that works in polynomial
time for fixed $k$ and $\ell$.
</p></div>
    </summary>
    <updated>2019-02-26T23:38:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09228</id>
    <link href="http://arxiv.org/abs/1902.09228" rel="alternate" type="text/html"/>
    <title>Succinct Data Structures for Families of Interval Graphs</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Acan:H=uuml=seyin.html">Hüseyin Acan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakraborty:Sankardeep.html">Sankardeep Chakraborty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jo:Seungbum.html">Seungbum Jo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Satti:Srinivasa_Rao.html">Srinivasa Rao Satti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09228">PDF</a><br/><b>Abstract: </b>We consider the problem of designing succinct data structures for interval
graphs with $n$ vertices while supporting degree, adjacency, neighborhood and
shortest path queries in optimal time in the $\Theta(\log n)$-bit word RAM
model. The degree query reports the number of incident edges to a given vertex
in constant time, the adjacency query returns true if there is an edge between
two vertices in constant time, the neighborhood query reports the set of all
adjacent vertices in time proportional to the degree of the queried vertex, and
the shortest path query returns a shortest path in time proportional to its
length, thus the running times of these queries are optimal. Towards showing
succinctness, we first show that at least $n\log{n} - 2n\log\log n - O(n)$ bits
are necessary to represent any unlabeled interval graph $G$ with $n$ vertices,
answering an open problem of Yang and Pippenger [Proc. Amer. Math. Soc. 2017].
This is augmented by a data structure of size $n\log{n} +O(n)$ bits while
supporting not only the aforementioned queries optimally but also capable of
executing various combinatorial algorithms (like proper coloring, maximum
independent set etc.) on the input interval graph efficiently. Finally, we
extend our ideas to other variants of interval graphs, for example, proper/unit
interval graphs, k-proper and k-improper interval graphs, and circular-arc
graphs, and design succinct/compact data structures for these graph classes as
well along with supporting queries on them efficiently.
</p></div>
    </summary>
    <updated>2019-02-26T23:24:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09102</id>
    <link href="http://arxiv.org/abs/1902.09102" rel="alternate" type="text/html"/>
    <title>Circuit Transformations for Quantum Architectures</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Childs:Andrew_M=.html">Andrew M. Childs</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schoute:Eddie.html">Eddie Schoute</a>, Cem M. Unsal <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09102">PDF</a><br/><b>Abstract: </b>Quantum computer architectures impose restrictions on qubit interactions. We
propose efficient circuit transformations that modify a given quantum circuit
to fit an architecture, allowing for any initial and final mapping of circuit
qubits to architecture qubits. To achieve this, we first consider the qubit
movement subproblem and use the routing via matchings framework to prove
tighter bounds on parallel routing. In practice, we only need to perform
partial permutations, so we generalize routing via matchings to that setting.
We give new routing procedures for common architecture graphs and for the
generalized hierarchical product of graphs, which produces subgraphs of the
Cartesian product. Secondly, for serial routing, we consider the token swapping
framework and extend a 4-approximation algorithm for general graphs to support
partial permutations. We apply these routing procedures to give several circuit
transformations, using various heuristic qubit placement subroutines. We
implement these transformations in software and compare their performance for
large quantum circuits on grid and modular architectures, identifying
strategies that work well in practice.
</p></div>
    </summary>
    <updated>2019-02-26T23:36:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09015</id>
    <link href="http://arxiv.org/abs/1902.09015" rel="alternate" type="text/html"/>
    <title>Generation of Tree-Child phylogenetic networks</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cardona:Gabriel.html">Gabriel Cardona</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pons:Joan_Carles.html">Joan Carles Pons</a>, Celine Scornavacca <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09015">PDF</a><br/><b>Abstract: </b>Phylogenetic networks generalize phylogenetic trees by allowing the
modelization of events of reticulate evolution. Among the different kinds of
phylogenetic networks that have been proposed in the literature, the subclass
of binary tree-child networks is one of the most studied ones. However, very
little is known about the combinatorial structure of these networks. In this
paper we address the problem of generating all possible binary tree-child
networks with a given number of leaves in an efficient way via
reduction/augmentation operations that extend and generalize analogous
operations for phylogenetic trees and are biologically relevant. Since our
solution is recursive, this also provides us with a recurrence relation giving
an upper bound on the number of such networks.
</p></div>
    </summary>
    <updated>2019-02-26T23:35:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.09009</id>
    <link href="http://arxiv.org/abs/1902.09009" rel="alternate" type="text/html"/>
    <title>Efficient Private Algorithms for Learning Halfspaces</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nguyen:Huy_L=.html">Huy L. Nguyen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Ullman:Jonathan.html">Jonathan Ullman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zakynthinou:Lydia.html">Lydia Zakynthinou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09009">PDF</a><br/><b>Abstract: </b>We present new differentially private algorithms for learning a large-margin
halfspace. In contrast to previous algorithms, which are based on either
differentially private simulations of the statistical query model or on private
convex optimization, the sample complexity of our algorithms depends only on
the margin of the data, and not on the dimension.
</p></div>
    </summary>
    <updated>2019-02-26T23:36:02Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.08815</id>
    <link href="http://arxiv.org/abs/1902.08815" rel="alternate" type="text/html"/>
    <title>Near neighbor preserving dimension reduction for doubling subsets of $\ell_1$</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Emiris:Ioannis_Z=.html">Ioannis Z. Emiris</a>, Vasilis Margonis, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Psarros:Ioannis.html">Ioannis Psarros</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.08815">PDF</a><br/><b>Abstract: </b>Randomized dimensionality reduction has been recognized as one of the
fundamental techniques in handling high-dimensional data. Starting with the
celebrated Johnson-Lindenstrauss Lemma, such reductions have been studied in
depth for the Euclidean $(\ell_2)$ metric and, much less, for the Manhattan
$(\ell_1)$ metric.
</p>
<p>Our primary motivation is the approximate nearest neighbor problem in
$\ell_1$. We exploit its reduction to the decision-with-witness version, called
approximate \textit{near} neighbor, which incurs a roughly logarithmic
overhead. In 2007, Indyk and Naor, in the context of approximate nearest
neighbors, introduced the notion of nearest neighbor-preserving embeddings.
These are randomized embeddings between two metric spaces with guaranteed
bounded distortion only for the distances between a query point and a point
set. Such embeddings are known to exist for both $\ell_2$ and $\ell_1$ metrics,
as well as for doubling subsets of $\ell_2$.
</p>
<p>In this paper, we propose a dimension reduction, \textit{near}
neighbor-preserving embedding for doubling subsets of $\ell_1$. Our approach is
to represent the point set with a carefully chosen covering set, and then apply
a random projection to that covering set. We study two cases of covering sets:
$c$-approximate $r$-nets and randomly shifted grids, and we discuss the
tradeoff between them in terms of preprocessing time and target dimension.
</p></div>
    </summary>
    <updated>2019-02-26T23:51:05Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.08809</id>
    <link href="http://arxiv.org/abs/1902.08809" rel="alternate" type="text/html"/>
    <title>Faster and simpler algorithms for finding large patterns in permutations</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kozma:L=aacute=szl=oacute=.html">László Kozma</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.08809">PDF</a><br/><b>Abstract: </b>Permutation patterns and pattern avoidance have been intensively studied in
combinatorics and computer science, going back at least to the seminal work of
Knuth on stack-sorting (1968). Perhaps the most natural algorithmic question in
this area is deciding whether a given permutation of length $n$ contains a
given pattern of length $k$.
</p>
<p>In this work we give two new algorithms for this well-studied problem, one
whose running time is $n^{0.44k+o(k)}$, and one whose running time is the
better of $O(1.415^n)$ and $n^{k/2+o(k)}$. These results improve the earlier
best bounds of Ahal and Rabinovich (2000), and Bruner and Lackner (2012), and
are the fastest algorithms for the problem when $k = \Omega(\log n)$. When $k =
o(\log n)$, the parameterized algorithm of Guillemot and Marx (2013) dominates.
</p>
<p>Our second algorithm uses polynomial space and is significantly simpler than
all previous approaches with comparable running times, including an
$n^{k/2+o(k)}$ algorithm proposed by Guillemot and Marx. Our approach can be
summarized as follows: "for every matching of the even-valued entries of the
pattern, try to match all odd-valued entries left-to-right". For the special
case of patterns that are Jordan-permutations, we show an improved,
subexponential running time.
</p></div>
    </summary>
    <updated>2019-02-26T23:32:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.08767</id>
    <link href="http://arxiv.org/abs/1902.08767" rel="alternate" type="text/html"/>
    <title>VoroCrust: Voronoi Meshing Without Clipping</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abdelkader:Ahmed.html">Ahmed Abdelkader</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bajaj:Chandrajit_L=.html">Chandrajit L. Bajaj</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ebeida:Mohamed_S=.html">Mohamed S. Ebeida</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahmoud:Ahmed_H=.html">Ahmed H. Mahmoud</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitchell:Scott_A=.html">Scott A. Mitchell</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Owens:John_D=.html">John D. Owens</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rushdi:Ahmad_A=.html">Ahmad A. Rushdi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.08767">PDF</a><br/><b>Abstract: </b>Polyhedral meshes are increasingly becoming an attractive option with
particular advantages over traditional meshes for certain applications. What
has been missing is a robust polyhedral meshing algorithm that can handle broad
classes of domains exhibiting arbitrary curved boundaries and sharp features.
In addition, the power of primal-dual mesh pairs, exemplified by
Voronoi-Delaunay meshes, has been recognized as an important ingredient in
numerous formulations. The VoroCrust algorithm is the first provably correct
algorithm for conforming Voronoi meshing for non-convex and possibly
non-manifold domains with guarantees on the quality of both surface and volume
elements. A robust refinement process estimates a suitable sizing field that
enables the careful placement of Voronoi seeds across the surface circumventing
the need for clipping and avoiding its many drawbacks. The algorithm has the
flexibility of filling the interior by either structured or random samples,
while all sharp features are preserved in the output mesh. We demonstrate the
capabilities of the algorithm on a variety of models and compare against
state-of-the-art polyhedral meshing methods based on clipped Voronoi cells
establishing the clear advantage of VoroCrust output.
</p></div>
    </summary>
    <updated>2019-02-26T23:51:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.08744</id>
    <link href="http://arxiv.org/abs/1902.08744" rel="alternate" type="text/html"/>
    <title>On Greedy Algorithms for Binary de Bruijn Sequences</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chang:Zuling.html">Zuling Chang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ezerman:Martianus_Frederic.html">Martianus Frederic Ezerman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fahreza:Adamas_Aqsa.html">Adamas Aqsa Fahreza</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.08744">PDF</a><br/><b>Abstract: </b>We propose a general greedy algorithm for binary de Bruijn sequences, called
Generalized Prefer-Opposite (GPO) Algorithm, and its modifications. By
identifying specific feedback functions and initial states, we demonstrate that
most previously-known greedy algorithms that generate binary de Bruijn
sequences are particular cases of our new algorithm.
</p></div>
    </summary>
    <updated>2019-02-26T23:32:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.08742</id>
    <link href="http://arxiv.org/abs/1902.08742" rel="alternate" type="text/html"/>
    <title>Optimal Algorithm to Reconstruct a Tree from a Subtree Distance</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maehara:Takanori.html">Takanori Maehara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ando:Kazutoshi.html">Kazutoshi Ando</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.08742">PDF</a><br/><b>Abstract: </b>This paper addresses the problem of finding a representation of a subtree
distance, which is an extension of the tree metric. We show that a minimal
representation is uniquely determined by a given subtree distance, and give a
linear time algorithm that finds such a representation. This algorithm achieves
the optimal time complexity.
</p></div>
    </summary>
    <updated>2019-02-26T23:38:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.08723</id>
    <link href="http://arxiv.org/abs/1902.08723" rel="alternate" type="text/html"/>
    <title>Slightly Superexponential Parameterized Problems</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lokshtanov:Daniel.html">Daniel Lokshtanov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marx:Daniel.html">Daniel Marx</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Saket.html">Saket Saurabh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.08723">PDF</a><br/><b>Abstract: </b>A central problem in parameterized algorithms is to obtain algorithms
</p>
<p>with running time $f(k)\cdot n^{O(1)}$ such that $f$ is as slow growing
function of the parameter $k$ as possible. In particular, a large number of
basic parameterized problems admit parameterized algorithms where $f(k)$ is
single-exponential, that is, $c^k$ for some constant $c$, which makes aiming
for such a running time a natural goal for other problems as well. However
there are still plenty of problems where the $f(k)$ appearing in the best known
running time is worse than single-exponential and it remained ``slightly
superexponential'' even after serious attempts to bring it down. A natural
question to ask is whether the $f(k)$ appearing in the running time of the
best-known algorithms is optimal for any of these problems.
</p>
<p>In this paper, we examine parameterized problems where $f(k)$ is
$k^{O(k)}=2^{O(k\log k)}$ in the best known running time and for a number of
such problems, we show that the dependence on $k$ in the running time cannot be
improved to single exponential. (See paper for the longer abstract.)
</p></div>
    </summary>
    <updated>2019-02-26T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.08698</id>
    <link href="http://arxiv.org/abs/1902.08698" rel="alternate" type="text/html"/>
    <title>$\ell_1$-sparsity Approximation Bounds for Packing Integer Programs</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chekuri:Chandra.html">Chandra Chekuri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Quanrud:Kent.html">Kent Quanrud</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Torres:Manuel_R=.html">Manuel R. Torres</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.08698">PDF</a><br/><b>Abstract: </b>We consider approximation algorithms for packing integer programs (PIPs) of
the form $\max\{\langle c, x\rangle : Ax \le b, x \in \{0,1\}^n\}$ where $c$,
$A$, and $b$ are nonnegative. We let $W = \min_{i,j} b_i / A_{i,j}$ denote the
width of $A$ which is at least $1$. Previous work by Bansal et al.
\cite{bansal-sparse} obtained an $\Omega(\frac{1}{\Delta_0^{1/\lfloor W
\rfloor}})$-approximation ratio where $\Delta_0$ is the maximum number of
nonzeroes in any column of $A$ (in other words the $\ell_0$-column sparsity of
$A$). They raised the question of obtaining approximation ratios based on the
$\ell_1$-column sparsity of $A$ (denoted by $\Delta_1$) which can be much
smaller than $\Delta_0$. Motivated by recent work on covering integer programs
(CIPs) \cite{cq,chs-16} we show that simple algorithms based on randomized
rounding followed by alteration, similar to those of Bansal et al.
\cite{bansal-sparse} (but with a twist), yield approximation ratios for PIPs
based on $\Delta_1$. First, following an integrality gap example from
\cite{bansal-sparse}, we observe that the case of $W=1$ is as hard as maximum
independent set even when $\Delta_1 \le 2$. In sharp contrast to this negative
result, as soon as width is strictly larger than one, we obtain positive
results via the natural LP relaxation. For PIPs with width $W = 1 + \epsilon$
where $\epsilon \in (0,1]$, we obtain an
$\Omega(\epsilon^2/\Delta_1)$-approximation. In the large width regime, when $W
\ge 2$, we obtain an $\Omega((\frac{1}{1 +
\Delta_1/W})^{1/(W-1)})$-approximation. We also obtain a
$(1-\epsilon)$-approximation when $W = \Omega(\frac{\log
(\Delta_1/\epsilon)}{\epsilon^2})$.
</p></div>
    </summary>
    <updated>2019-02-26T23:36:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1902.08679</id>
    <link href="http://arxiv.org/abs/1902.08679" rel="alternate" type="text/html"/>
    <title>Spatial Analysis Made Easy with Linear Regression and Kernels</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Philip Milton, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Giorgi:Emanuele.html">Emanuele Giorgi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhatt:Samir.html">Samir Bhatt</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1902.08679">PDF</a><br/><b>Abstract: </b>Kernel methods are an incredibly popular technique for extending linear
models to non-linear problems via a mapping to an implicit, high-dimensional
feature space. While kernel methods are computationally cheaper than an
explicit feature mapping, they are still subject to cubic cost on the number of
points. Given only a few thousand locations, this computational cost rapidly
outstrips the currently available computational power. This paper aims to
provide an overview of kernel methods from first-principals (with a focus on
ridge regression), before progressing to a review of random Fourier features
(RFF), a set of methods that enable the scaling of kernel methods to big
datasets. At each stage, the associated R code is provided. We begin by
illustrating how the dual representation of ridge regression relies solely on
inner products and permits the use of kernels to map the data into
high-dimensional spaces. We progress to RFFs, showing how only a few lines of
code provides a significant computational speed-up for a negligible cost to
accuracy. We provide an example of the implementation of RFFs on a simulated
spatial data set to illustrate these properties. Lastly, we summarise the main
issues with RFFs and highlight some of the advanced techniques aimed at
alleviating them.
</p></div>
    </summary>
    <updated>2019-02-26T23:24:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1609.04771</id>
    <link href="http://arxiv.org/abs/1609.04771" rel="alternate" type="text/html"/>
    <title>Formula of Volume of Revolution with Integration by Parts and Extension</title>
    <feedworld_mtime>1551139200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Yi.html">Yi Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Jingwei.html">Jingwei Liu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1609.04771">PDF</a><br/><b>Abstract: </b>A calculation formula of volume of revolution with integration by parts of
definite integral is derived based on monotone function, and extended to a
general case that curved trapezoids is determined by continuous, piecewise
strictly monotone and differential function. And, two examples are given, ones
curvilinear trapezoids is determined by Kepler equation, and the other
curvilinear trapezoids is a function transmuted from Kepler equation.
</p></div>
    </summary>
    <updated>2019-02-26T23:40:57Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-02-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/023</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/023" rel="alternate" type="text/html"/>
    <title>TR19-023 |  Smooth and Strong PCPs | 

	Orr Paradise</title>
    <summary>Probabilistically checkable proofs (PCPs) can be verified based only on a constant amount of random queries, such that any correct claim has a proof that is always accepted, and incorrect claims are rejected with high probability (regardless of the given alleged proof). We consider two possible features of PCPs:
- A PCP is *strong* if it rejects an alleged proof of a correct claim with probability proportional to its distance from some correct proof of that claim.
- A PCP is *smooth* if each location in a proof is queried with equal probability.

We prove that all sets in $\mathcal{NP}$ have a smooth and strong PCP of polynomial length that can be verified based on a constant number of queries. We do so by following the proof of the PCP theorem of Arora, Lund, Motwani, Sudan and Szegedy (JACM, 1998), providing a stronger analysis of the Hadamard and Reed--Muller based PCPs and a refined PCP composition theorem. In fact, we show that any set in $\mathcal{NP}$ has a smooth strong *canonical* PCP of Proximity (PCPP), meaning that there is an efficiently computable bijection of $\mathcal{NP}$ witnesses to correct proofs.
	
This improves on the recent result of Dinur, Gur and Goldreich (ITCS, 2019) that constructs strong canonical PCPPs that are inherently non-smooth. Our result implies the hardness of approximating the satisfiability of "stable" 3CNF formulae with bounded variable occurrence, proving a hypothesis used in the work of Friggstad, Khodamoradi and Salavatipour (SODA, 2019). Here *stability* means that the number of clauses violated by an assignment is proportional to its distance from a satisfying assignment (in the relative Hamming metric).</summary>
    <updated>2019-02-25T22:38:50Z</updated>
    <published>2019-02-25T22:38:50Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-27T06:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16934</id>
    <link href="https://gilkalai.wordpress.com/2019/02/23/karim-adiprasito-the-g-conjecture-for-vertex-decomposible-spheres/" rel="alternate" type="text/html"/>
    <title>Karim Adiprasito: The g-Conjecture for Vertex Decomposible Spheres</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">J Scott Provan (site) The following post was kindly contributed by Karim Adiprasito. (Here is the link to Karim’s paper.) So, Gil asked me to say a little bit about my proof of the g-conjecture (and some other conjectures in … <a href="https://gilkalai.wordpress.com/2019/02/23/karim-adiprasito-the-g-conjecture-for-vertex-decomposible-spheres/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/02/scott_provan.jpg"><img alt="" class="alignnone size-full wp-image-16958" src="https://gilkalai.files.wordpress.com/2019/02/scott_provan.jpg?w=640"/></a></p>
<p><strong><span style="color: #ff0000;">J Scott Provan </span></strong><span style="color: #ff0000;"><a href="https://stat-or.unc.edu/people/emeritus/j-scott-provan">(site)</a></span></p>
<p><em>The following post was kindly contributed by Karim Adiprasito. (Here is<a href="https://arxiv.org/abs/1812.10454"> the link to Karim’s paper</a>.)</em></p>
<p>So, Gil asked me to say a little bit about my <a href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/">proof of the <em>g</em>-conjecture</a> (and some other conjectures in discrete geometry) on his blog, and since he bought me <a href="https://gilkalai.files.wordpress.com/2018/05/cubring.png">many</a>  <a href="https://gilkalai.wordpress.com/2018/06/20/beyond-the-g-conjecture-algebraic-combinatorics-of-cellular-spaces-i/">coffees </a>to explain it to him (or if he is to be believed, the department paid), I am happy to oblige.</p>
<p>So, I want to explain a special, but critical case to the proof. It contains the some shadow of the core ideas necessary, but needs some more tricks I will remark on afterwards.</p>
<p>Also, I wanted to take this opportunity to mention something marvelous that I learned from <a href="https://www.ccny.cuny.edu/profiles/leonid-gurvits">Leonid Gurvits</a> recently that increased my own understanding of one of the key tricks used indefinitely. That trick is the following cool lemma.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/image.png"><img alt="" class="alignnone size-full wp-image-16959" src="https://gilkalai.files.wordpress.com/2019/02/image.png?w=640"/></a></p>
<p><span style="color: #ff0000;"><strong>Leonid Gurvits</strong></span></p>
<h2>Perturbation lemma</h2>
<p><strong>PERTURBATION LEMMA:</strong> Consider two linear maps</p>
<p style="text-align: center;"><img alt="\alpha, \beta: X\ \longrightarrow\ Y" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha%2C+%5Cbeta%3A+X%5C+%5Clongrightarrow%5C+Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha, \beta: X\ \longrightarrow\ Y"/></p>
<p>of two real vector spaces <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/>. Assume that</p>
<p><img alt="\beta (\ker \alpha ) \cap \rm{im}~ \alpha =\{0\} \subset Y." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta+%28%5Cker+%5Calpha+%29+%5Ccap+%5Crm%7Bim%7D%7E+%5Calpha+%3D%5C%7B0%5C%7D+%5Csubset+Y.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta (\ker \alpha ) \cap \rm{im}~ \alpha =\{0\} \subset Y."/></p>
<p>Then a generic linear combination <img alt="\alpha ``+&quot;\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha+%60%60%2B%22%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha ``+&quot;\beta"/> of <img alt="\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha"/> and <img alt="\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta"/>  has kernel<br/>
<img alt="\ker (\alpha&#xA0; ``+&quot; \beta )= \ker \alpha \cap \ker \beta." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cker+%28%5Calpha%C2%A0+%60%60%2B%22+%5Cbeta+%29%3D+%5Cker+%5Calpha+%5Ccap+%5Cker+%5Cbeta.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ker (\alpha&#xA0; ``+&quot; \beta )= \ker \alpha \cap \ker \beta."/></p>
<p>Cool, no? <strong>Proof, then:</strong> Find a subspace <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> of <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> such that</p>
<p><img alt="\alpha A\ =\ \alpha X\quad \text{and}\ \quad X\ \cong\ A \oplus \ker\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha+A%5C+%3D%5C+%5Calpha+X%5Cquad+%5Ctext%7Band%7D%5C+%5Cquad+X%5C+%5Ccong%5C+A+%5Coplus+%5Cker%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha A\ =\ \alpha X\quad \text{and}\ \quad X\ \cong\ A \oplus \ker\alpha"/></p>
<p>so that in particular <img alt="\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha"/> is injective on <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>. Then, for <img alt="\epsilon \ge 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon \ge 0"/> small enough, the image of</p>
<p><img alt="\alpha\ +\ \epsilon \beta{:}\ X\ \longrightarrow\ Y" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha%5C+%2B%5C+%5Cepsilon+%5Cbeta%7B%3A%7D%5C+X%5C+%5Clongrightarrow%5C+Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha\ +\ \epsilon \beta{:}\ X\ \longrightarrow\ Y"/></p>
<p>is</p>
<p><img alt="(\alpha\ +\ \epsilon \beta)(A)\ +\ \beta\ker\alpha\ \subset\ Y." class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Calpha%5C+%2B%5C+%5Cepsilon+%5Cbeta%29%28A%29%5C+%2B%5C+%5Cbeta%5Cker%5Calpha%5C+%5Csubset%5C+Y.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\alpha\ +\ \epsilon \beta)(A)\ +\ \beta\ker\alpha\ \subset\ Y."/></p>
<p>But if we norm <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> in any way, then <img alt="(\alpha+\epsilon \beta)(A)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Calpha%2B%5Cepsilon+%5Cbeta%29%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\alpha+\epsilon \beta)(A)"/> approximates <img alt="\alpha A" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha+A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha A"/> as <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/> tends to zero, which is linearly independent from <img alt="\beta\, \ker\alpha" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta%5C%2C+%5Cker%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta\, \ker\alpha"/> by assumption. <span style="color: #993366;"><strong>WALLA</strong></span></p>
<p>Now, how is this used.</p>
<h2>Face rings</h2>
<p>Let me set up some of the basic objects.</p>
<p>If <img alt="\Delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta"/> is an abstract simplicial complex on ground-set <img alt="[n]:= \{1,\cdots,n\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bn%5D%3A%3D+%5C%7B1%2C%5Ccdots%2Cn%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[n]:= \{1,\cdots,n\}"/>, let <img alt="I_\Delta := \langle \textbf{x}^{\textbf{a}}: supp (\textbf{a})\notin\Delta\rangle" class="latex" src="https://s0.wp.com/latex.php?latex=I_%5CDelta+%3A%3D+%5Clangle+%5Ctextbf%7Bx%7D%5E%7B%5Ctextbf%7Ba%7D%7D%3A+supp+%28%5Ctextbf%7Ba%7D%29%5Cnotin%5CDelta%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I_\Delta := \langle \textbf{x}^{\textbf{a}}: supp (\textbf{a})\notin\Delta\rangle"/> denote the nonface ideal in <img alt="\mathbb{R}[\mathbf{x}]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5B%5Cmathbf%7Bx%7D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}[\mathbf{x}]"/>, where <img alt="\mathbb{R}[\mathbf{x}]=\mathbb{R}[x_1,\cdots,x_n]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5B%5Cmathbf%7Bx%7D%5D%3D%5Cmathbb%7BR%7D%5Bx_1%2C%5Ccdots%2Cx_n%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}[\mathbf{x}]=\mathbb{R}[x_1,\cdots,x_n]"/>.</p>
<p>Let <img alt="\mathbb{R}^\ast[\Delta]:= \mathbb{R}[\mathbf{x}]/I_\Delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D%3A%3D+%5Cmathbb%7BR%7D%5B%5Cmathbf%7Bx%7D%5D%2FI_%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}^\ast[\Delta]:= \mathbb{R}[\mathbf{x}]/I_\Delta"/> denote the face ring of <img alt="\Delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Delta"/>. A collection of linear forms <img alt="\Theta=(\theta_1,\cdots,\theta_l)" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta%3D%28%5Ctheta_1%2C%5Ccdots%2C%5Ctheta_l%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Theta=(\theta_1,\cdots,\theta_l)"/> in the polynomial ring <img alt="\mathbb{R}[\textbf{x}]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5B%5Ctextbf%7Bx%7D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}[\textbf{x}]"/> is a <strong>partial linear system of parameters</strong> if</p>
<p><img alt="\dim_{\rm{Krull}} {\mathbb{R}^\ast[\Delta]}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdim_%7B%5Crm%7BKrull%7D%7D+%7B%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\dim_{\rm{Krull}} {\mathbb{R}^\ast[\Delta]}"/> <img alt="{\Theta \mathbb{R}^\ast[\Delta]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CTheta+%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="{\Theta \mathbb{R}^\ast[\Delta]}"/> <img alt="=\dim_{\rm{Krull}} \mathbb{R}^\ast[\Delta]-l," class="latex" src="https://s0.wp.com/latex.php?latex=%3D%5Cdim_%7B%5Crm%7BKrull%7D%7D+%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D-l%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="=\dim_{\rm{Krull}} \mathbb{R}^\ast[\Delta]-l,"/></p>
<p>for <img alt="\dim_{\rm{Krull}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdim_%7B%5Crm%7BKrull%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\dim_{\rm{Krull}}"/> the Krull dimension. If <img alt="l=\dim_{\rm{Krull}} \mathbb{R}^\ast[\Delta] = \dim \Delta +1" class="latex" src="https://s0.wp.com/latex.php?latex=l%3D%5Cdim_%7B%5Crm%7BKrull%7D%7D+%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D+%3D+%5Cdim+%5CDelta+%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="l=\dim_{\rm{Krull}} \mathbb{R}^\ast[\Delta] = \dim \Delta +1"/>, then <img alt="\Theta" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Theta"/> is simply a <strong>linear system of parameters</strong>, and the corresponding quotient <img alt="A(\Delta)={\mathbb{R}^\ast[\Delta]}/{\Theta \mathbb{R}^\ast[\Delta]}" class="latex" src="https://s0.wp.com/latex.php?latex=A%28%5CDelta%29%3D%7B%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D%7D%2F%7B%5CTheta+%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(\Delta)={\mathbb{R}^\ast[\Delta]}/{\Theta \mathbb{R}^\ast[\Delta]}"/> is called an <strong>Artinian reduction</strong> of <img alt="\mathbb{R}^\ast[\Delta]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}^\ast[\Delta]"/>.</p>
<h2>The <em>g</em>-conjecture</h2>
<p>The <em>g</em>-conjecture (as <a href="https://gilkalai.wordpress.com/2009/04/02/eran-nevo-the-g-conjecture-i/">described</a> <a href="https://gilkalai.wordpress.com/2009/04/04/how-the-g-conjecture-came-about/">earlier</a> <a href="https://gilkalai.wordpress.com/tag/g-conjecture/"> in Gil’s blog</a>) is implied by the following property:</p>
<p><strong>(HL)</strong> For every sphere <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> of even dimension <img alt="d-1=2k" class="latex" src="https://s0.wp.com/latex.php?latex=d-1%3D2k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d-1=2k"/>, there is an Artinian reduction <img alt="A(S)" class="latex" src="https://s0.wp.com/latex.php?latex=A%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(S)"/> and a degree one element <img alt="\ell" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell"/> such that the map</p>
<p><img alt="A^k(S) \ \xrightarrow{\ \cdot \ell\ }\ A^{k+1}(S) " class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5C+%5Cxrightarrow%7B%5C+%5Ccdot+%5Cell%5C+%7D%5C+A%5E%7Bk%2B1%7D%28S%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^k(S) \ \xrightarrow{\ \cdot \ell\ }\ A^{k+1}(S) "/></p>
<p>is an isomorphism.</p>
<p>This is quite a reasonable demand. Indeed, Graebe proved that <img alt="A^d(S) \cong \mathbb{R}" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ed%28S%29+%5Ccong+%5Cmathbb%7BR%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^d(S) \cong \mathbb{R}"/> and that the resulting pairing</p>
<p><img alt="A^k(S) \times A^{k+1}(S)\rightarrow \mathbb{R} " class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5Ctimes+A%5E%7Bk%2B1%7D%28S%29%5Crightarrow+%5Cmathbb%7BR%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^k(S) \times A^{k+1}(S)\rightarrow \mathbb{R} "/></p>
<p>is perfect, so <img alt="A^k(S)" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^k(S)"/> and <img alt="A^{k+1}(S)" class="latex" src="https://s0.wp.com/latex.php?latex=A%5E%7Bk%2B1%7D%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^{k+1}(S)"/> are isomorphic as vector spaces. We shall call this property <strong>(PD)</strong>, because it is a special case of Poincaré pairing.</p>
<p>(HL) is a special case of the Hard Lefschetz Theorem I prove in my paper, and we will prove it for a subset of all triangulated spheres here. Proving it for all spheres implies the <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/>-conjecture (and other conjectures, such as the Grünbaum conjecture), and proving the hard Lefschetz theorem in full generality is not much harder.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/image-1.png"><img alt="" class="alignnone size-full wp-image-16960" src="https://gilkalai.files.wordpress.com/2019/02/image-1.png?w=640"/></a></p>
<p><span style="color: #ff0000;"><strong>Lou Billera</strong></span></p>
<h2>Vertex-decomposable spheres</h2>
<p>Lets recall a cool notion due to Provan and Billera: A pure simplicial <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-complex is <strong>vertex decomposable</strong> if it is a simplex, or there exists a vertex whose link is vertex decomposable of dimension <img alt="d-1" class="latex" src="https://s0.wp.com/latex.php?latex=d-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d-1"/> and its deletion is vertex decomposable of dimension <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>.</p>
<p>We restrict our attention to vertex decomposable spheres and disks and assume the boundary of the link is vertex decomposable as well in every step.</p>
<p><strong>THEOREM:</strong> Vertex decomposable spheres satisfy (HL).</p>
<p>We prove this theorem by induction on dimension, the base case of zero-dimensional spheres <img alt="(k=0)" class="latex" src="https://s0.wp.com/latex.php?latex=%28k%3D0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(k=0)"/> being clear.</p>
<p>Lets label the vertices of <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> in order of their vertex decomposition, from <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> to <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>. Now, <img alt="\ell" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell"/> will be a linear combination of indeterminates, so lets assume we have constructed an element <img alt="\ell_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_i"/> that uses just the first <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> of them, and such that <img alt="\ell_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_i"/> itself is as close to a Lefschetz element as possible for its kind, that is, the kernel of</p>
<p><img alt="A^k(S) \ \xrightarrow{\ \cdot \ell_i\ }\ A^{k+1}(S) " class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5C+%5Cxrightarrow%7B%5C+%5Ccdot+%5Cell_i%5C+%7D%5C+A%5E%7Bk%2B1%7D%28S%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^k(S) \ \xrightarrow{\ \cdot \ell_i\ }\ A^{k+1}(S) "/></p>
<p>is the intersection of kernels of the maps</p>
<p><img alt="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) " class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5C+%5Cxrightarrow%7B%5C+%5Ccdot+x_j%5C+%7D%5C+A%5E%7Bk%2B1%7D%28S%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) "/></p>
<p>where <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> ranges from <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> to <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>.</p>
<p>We want to construct a map <img alt="\ell_{i+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_%7Bi%2B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_{i+1}"/> with this property (which I call the <strong>transversal prime property</strong>}. To this effect, we want to apply the perturbation lemma to the maps <img alt="\beta x_{i+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta+x_%7Bi%2B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta x_{i+1}"/>, <img alt="\alpha=\ell_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha%3D%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha=\ell_i"/>, and with respect to the spaces <img alt="X=A^k(S)" class="latex" src="https://s0.wp.com/latex.php?latex=X%3DA%5Ek%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X=A^k(S)"/> and <img alt="Y=A^{k+1}(S)" class="latex" src="https://s0.wp.com/latex.php?latex=Y%3DA%5E%7Bk%2B1%7D%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y=A^{k+1}(S)"/>. Let us denote by <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D"/> the ball given as the union of neighborhoods of the first <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> vertices.</p>
<p>For this, we have to find out the kernel of <img alt="\ell_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_i"/>. But this is the the ideal in <img alt="A(S)" class="latex" src="https://s0.wp.com/latex.php?latex=A%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(S)"/> generated by the monomials of faces which are not in the neighborhood of any of the first <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> vertices. Lets call it <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/>. Lets also look at the image <img alt="I" class="latex" src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="I"/> of <img alt="\ell_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_i"/>, which by Graebe’s theorem is exactly the span of the images of the maps the maps</p>
<p><img alt="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) " class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5C+%5Cxrightarrow%7B%5C+%5Ccdot+x_j%5C+%7D%5C+A%5E%7Bk%2B1%7D%28S%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) "/></p>
<p>where <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> ranges from <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> to <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>.</p>
<p>But then, <img alt="x_{i+1}K \cap I" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%2B1%7DK+%5Ccap+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i+1}K \cap I"/> is <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/> in degree <img alt="k+1" class="latex" src="https://s0.wp.com/latex.php?latex=k%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k+1"/> if and only if <img alt="A(st_{i+1} \partial D)" class="latex" src="https://s0.wp.com/latex.php?latex=A%28st_%7Bi%2B1%7D+%5Cpartial+D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(st_{i+1} \partial D)"/> is <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/> in degree <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>. Why is that? Because with respect to the Poincaré pairing, <img alt="x_{i+1}K \cap I" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%2B1%7DK+%5Ccap+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i+1}K \cap I"/> (in degree <img alt="k+1" class="latex" src="https://s0.wp.com/latex.php?latex=k%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k+1"/>) and <img alt="A(st_{i+1} \partial D)" class="latex" src="https://s0.wp.com/latex.php?latex=A%28st_%7Bi%2B1%7D+%5Cpartial+D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(st_{i+1} \partial D)"/> (in degree <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>) are dual.<br/>
The ring <img alt="A(st_{i+1} \partial D)" class="latex" src="https://s0.wp.com/latex.php?latex=A%28st_%7Bi%2B1%7D+%5Cpartial+D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(st_{i+1} \partial D)"/> is obtained by taking <img alt="\mathbb{R}[st_{i+1} \partial D]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Bst_%7Bi%2B1%7D+%5Cpartial+D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}[st_{i+1} \partial D]"/>, seen as a quotient of <img alt="\mathbb{R}[S]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5BS%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}[S]"/> and modding out by the ideal generated by the linear system <img alt="\Theta" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Theta"/>. But that is of length <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>, even though <img alt="st_{i+1} \partial D" class="latex" src="https://s0.wp.com/latex.php?latex=st_%7Bi%2B1%7D+%5Cpartial+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="st_{i+1} \partial D"/> is only of dimension <img alt="d-2" class="latex" src="https://s0.wp.com/latex.php?latex=d-2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d-2"/>. We can remove the vertex <img alt="i+1" class="latex" src="https://s0.wp.com/latex.php?latex=i%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i+1"/> for the price of removing one of the linear forms, but then we have the same issue, having a <img alt="(d-3)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-3%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(d-3)"/>-sphere <img alt="st_{i+1} \partial D" class="latex" src="https://s0.wp.com/latex.php?latex=st_%7Bi%2B1%7D+%5Cpartial+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="st_{i+1} \partial D"/> and a system <img alt="\Theta'" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Theta'"/> of length <img alt="d-1" class="latex" src="https://s0.wp.com/latex.php?latex=d-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d-1"/>. Still, one too many! Taking a subsystem of length <img alt="d-2" class="latex" src="https://s0.wp.com/latex.php?latex=d-2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d-2"/>, we obtain an Artinian reduction for <img alt="\mathbb{R}[lk_{i+1} \partial D]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Blk_%7Bi%2B1%7D+%5Cpartial+D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}[lk_{i+1} \partial D]"/> via a linear system <img alt="\Theta''" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta%27%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Theta''"/>, but what happens to the additional linear form of <img alt="\Theta'" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Theta'"/> not in <img alt="\Theta''" class="latex" src="https://s0.wp.com/latex.php?latex=%5CTheta%27%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Theta''"/>? It has to act as a Lefschetz element on <img alt="\mathbb{R}[lk_{i+1} \partial D]/\Theta''\mathbb{R}[lk_{i+1} \partial D]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Blk_%7Bi%2B1%7D+%5Cpartial+D%5D%2F%5CTheta%27%27%5Cmathbb%7BR%7D%5Blk_%7Bi%2B1%7D+%5Cpartial+D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{R}[lk_{i+1} \partial D]/\Theta''\mathbb{R}[lk_{i+1} \partial D]"/> if we want</p>
<p><img alt="A(st_{i+1} \partial D)\ \cong\ \mathbb{R}[lk_{i+1} \partial D]/\Theta'\mathbb{R}[lk_{i+1} \partial D]" class="latex" src="https://s0.wp.com/latex.php?latex=A%28st_%7Bi%2B1%7D+%5Cpartial+D%29%5C+%5Ccong%5C+%5Cmathbb%7BR%7D%5Blk_%7Bi%2B1%7D+%5Cpartial+D%5D%2F%5CTheta%27%5Cmathbb%7BR%7D%5Blk_%7Bi%2B1%7D+%5Cpartial+D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(st_{i+1} \partial D)\ \cong\ \mathbb{R}[lk_{i+1} \partial D]/\Theta'\mathbb{R}[lk_{i+1} \partial D]"/></p>
<p>to be trivial in degree <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>. But we may assume so by induction! Hence, we can choose <img alt="\ell_{i+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_%7Bi%2B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_{i+1}"/> as the generic sum of <img alt="\ell_i" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_i"/> and <img alt="x_{i+1}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%2B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i+1}"/> by the perturbation lemma.</p>
<p>So, ultimately, we can construct a map <img alt="\ell_n" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell_n"/> with the transversal prime property. But then its kernel is the intersection of the kernels of</p>
<p><img alt="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) " class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5C+%5Cxrightarrow%7B%5C+%5Ccdot+x_j%5C+%7D%5C+A%5E%7Bk%2B1%7D%28S%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) "/>,</p>
<p>where <img alt="j" class="latex" src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="j"/> ranges from <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> to <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>. But that is <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/>.  <strong><span style="color: #993366;">SABABA</span>.</strong></p>
<h2>And beyond?</h2>
<p>Now, we have the Lefschetz theorem for a special class, but that is less than what we want in the end, since vertex decomposable spheres are few and in between (do you see a reason why? there are many). So, what do we do? For a long time, I tried to extend the perturbation lemma to combine more than two maps.<br/>
Recently (depending on when Gil puts this post on the blog), I met Leonid Gurvits for the first time on a marvelous little conference at the Simons Institute. I knew that the problem is related to Hall’s Marriage Theorem for operators (I explain this connection a bit further in my paper), but Leonid enlightened this further by pointing me towards several nice papers, starting with <a href="https://arxiv.org/abs/quant-ph/0201022">his work on Quantum Matching Theory</a>. Indeed, finding a good extension to three and more maps would essentially mean that we could also find Hall Marriage Type Theorems for 3-regular hypergraphs, which we know for complexity reasons to be unlikely.</p>
<p>So what can we do instead? Well, it turns out that I only really needed to look at the <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-skeleton of <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/> above, and there is no need to be vertex decomposable. It is enough to find another nicely decomposable <img alt="d-1" class="latex" src="https://s0.wp.com/latex.php?latex=d-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d-1"/>-manifold that contains it the <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-skeleton of <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S"/>, and then use some technical topological tricks to connect the local picture to global homological properties.</p>
<p> </p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-02-23T16:19:11Z</updated>
    <published>2019-02-23T16:19:11Z</published>
    <category term="Combinatorics"/>
    <category term="Convex polytopes"/>
    <category term="Geometry"/>
    <category term="Guest blogger"/>
    <category term="g-conjecture"/>
    <category term="J Scott Provan"/>
    <category term="Karim Adiprasito"/>
    <category term="Leonid Gurvits"/>
    <category term="Lou Billera"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-02-27T06:20:46Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=15657</id>
    <link href="https://rjlipton.wordpress.com/2019/02/22/making-a-mapping-injective/" rel="alternate" type="text/html"/>
    <title>Making A Mapping Injective</title>
    <summary>Finding a set of nearly independent objects Wikipedia bio source Giuseppe Vitali was the mathematician who famously used the Axiom of Choice, in 1905, to give the first example of a non-measurable subset of the real numbers. Today I want to discuss another of his results that is a powerful tool. The existence of a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Finding a set of nearly independent objects</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/02/330px-giuseppe_vitali.jpg"><img alt="" class="alignright size-thumbnail wp-image-15658" height="150" src="https://rjlipton.files.wordpress.com/2019/02/330px-giuseppe_vitali.jpg?w=118&amp;h=150" width="118"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Wikipedia bio <a href="https://en.wikipedia.org/wiki/Giuseppe_Vitali">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Giuseppe Vitali was the mathematician who famously used the Axiom of Choice, in 1905, to give the first example of a non-measurable subset of the real numbers.</p>
<p>
Today I want to discuss another of his results that is a powerful tool.</p>
<p>
The existence of a set that cannot properly be assigned a measure was a surprise at the time, and still is a surprise. It is a wonderful example of the power of the Axiom of Choice. See <a href="https://en.wikipedia.org/wiki/Vitali_set">this</a> for details. </p>
<p>
We are interested in another of his results that is more a theorem about coverings. It is the Vitali covering theorem–see <a href="https://en.wikipedia.org/wiki/Vitali_covering_lemma">this</a>. The theorem shows that a certain type of covering—ah, we will explain the theorem in a moment.</p>
<p>
The power of this theorem is that it can be used to construct various objects in analysis. There are now many applications of this theorem. It is a powerful tool that can be used to prove many nice results. I do not know of any—many?—applications of the existence of a non-measurable set. Do you know any?</p>
<p>
</p><p/><h2> Making A Mapping Injective </h2><p/>
<p/><p>
Let’s look at an application of the Vitali theorem that may be new. But in any case it may help explain what the Vitali theorem is all about.</p>
<p>
Suppose that <img alt="{F:X \rightarrow Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%3AX+%5Crightarrow+Y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F:X \rightarrow Y}"/>. We can make the map surjective if we restrict <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> to be equal to <img alt="{F(X)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(X)}"/>. It is not so simple to make the map injective, but we can in general do that also. </p>
<blockquote><p><b>Theorem 1</b> <em><a name="choice"/> Let <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> be a surjective function from <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{X}"/> to <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{Y}"/>. Then there is a subset <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{X}"/> so that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> is injective from <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> to <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{Y}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  For each <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> in <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> select one <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> from the set <img alt="{F^{-1}(y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%5E%7B-1%7D%28y%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F^{-1}(y)}"/> and place it into <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. Recall <img alt="{F^{-1}(y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%5E%7B-1%7D%28y%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F^{-1}(y)}"/> is the set of <img alt="{z}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{z}"/> so that <img alt="{F(z)=y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28z%29%3Dy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(z)=y}"/>.This of course uses the Axiom of Choice to make the choices of which <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> to choose. Then clearly <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> is the required set. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
The difficulty with this trivial theorem is that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> cannot be controlled easily if it is constructed via the Axiom of Choice. It could be a very complicated set. Our goal is to see how well we can control <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> if we assume that the mapping <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is smooth. </p>
<p>
How can we do better? The answer is quite a bit better if we assume that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is a “nice” function. We give up surjectivity onto <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/> but only by a null set.</p>
<blockquote><p><b>Theorem 2</b> <em><a name="injective"/> Suppose that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> is a surjective smooth map from <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{X}"/> to <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{Y}"/> where <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{X}"/> and <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{Y}"/> are open subsets of <img alt="{{\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\mathbb R}}"/>. Also suppose that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> locally is invertible. Then there is a subset <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> of <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{X}"/> so that </em></p><em>
<ol>
<li>
The complement of <img alt="{F(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28S%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F(S)}"/> is a null set. <p/>
</li><li>
The map <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F}"/> is injective from <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> to <img alt="{F(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28S%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F(S)}"/>.
</li></ol>
</em><p><em>That is that for all distinct points <img alt="{\boldsymbol{a}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cboldsymbol%7Ba%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\boldsymbol{a}}"/> and <img alt="{\boldsymbol{b}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cboldsymbol%7Bb%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\boldsymbol{b}}"/> in <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/>, <img alt="{F(\boldsymbol{a}) \neq F(\boldsymbol{b})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28%5Cboldsymbol%7Ba%7D%29+%5Cneq+F%28%5Cboldsymbol%7Bb%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F(\boldsymbol{a}) \neq F(\boldsymbol{b})}"/>. Moreover the map from <img alt="{F(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28S%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{F(S)}"/> to <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{S}"/> is smooth. </em>
</p></blockquote>
<p>
</p><p/><h2> Set Coverings </h2><p/>
<p/><p>
How can we prove this theorem? An obvious idea is to do the following. Pick an open interval <img alt="{U=[a,b]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%3D%5Ba%2Cb%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U=[a,b]}"/> in <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/> so that <img alt="{F(U) = V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28U%29+%3D+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(U) = V}"/> for an open set in <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/> and so that <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is injective from <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> to <img alt="{V}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V}"/>. Setting <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> to <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> clearly works: the map <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is injective on <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. This is far from the large set that we wish to have, but it is a start. The intuition is to select another open interval <img alt="{U'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U'}"/> that is disjoint from <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U}"/> so that again <img alt="{F}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F}"/> is injective from <img alt="{U'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U'}"/> to <img alt="{V'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BV%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{V'}"/>. We can then add <img alt="{U'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{U'}"/> to our <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. </p>
<p>
We can continue in this way and collect many open sets that we add to <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/>. Can we arrange that the union of these sets yield a <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> so that <img alt="{F(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BF%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{F(S)}"/> is most of <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>? In general the answer is no. Suppose that the intervals are the following: 	</p>
<p align="center"><img alt="\displaystyle  [k,k+1.1] " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Bk%2Ck%2B1.1%5D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  [k,k+1.1] "/></p>
<p>for <img alt="{k=0,1,2,\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D0%2C1%2C2%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k=0,1,2,\dots}"/> Roughly we can only get about half of the space that the intervals cover and keep the chosen intervals disjoint. If we select <img alt="{ [k,k+1.1] }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B+%5Bk%2Ck%2B1.1%5D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{ [k,k+1.1] }"/> then we cannot select <img alt="{[k+1,k+1+1.1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bk%2B1%2Ck%2B1%2B1.1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[k+1,k+1+1.1]}"/> since 	</p>
<p align="center"><img alt="\displaystyle  [k,k+1.1] \cap [k+1,k+1+1.1] \neq \emptyset. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Bk%2Ck%2B1.1%5D+%5Ccap+%5Bk%2B1%2Ck%2B1%2B1.1%5D+%5Cneq+%5Cemptyset.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  [k,k+1.1] \cap [k+1,k+1+1.1] \neq \emptyset. "/></p>
<p>Vitali’s theorem comes to the rescue. It allows us to avoid his problem, by insisting that intervals have an additional property.</p>
<p>
</p><p/><h2> The Vitali Covering Theorem </h2><p/>
<p/><p>
The trick is to use a refinement of a set cover that allows a disjoint cover to exist for almost all of the target set. The next definition is critical to the Vitali covering theorem. </p>
<blockquote><p><b>Definition 3</b> <em> Let <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> be a subset of <img alt="{{\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\mathbb R}}"/>. Let <img alt="{[a_{\lambda},b_{\lambda}]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ba_%7B%5Clambda%7D%2Cb_%7B%5Clambda%7D%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{[a_{\lambda},b_{\lambda}]}"/> be intervals over <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\lambda}"/> in some index set <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{I}"/>. We say these intervals are a <b>cover</b> of <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> proved <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> is a subset of the union of all the intervals. Say the intervals also are a <b>Vitali</b> cover of <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> provided for all points <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x}"/> in <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> and all <img alt="{\epsilon &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\epsilon &gt; 0}"/>, there is an interval <img alt="{[c,d]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bc%2Cd%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{[c,d]}"/> that contains <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{0 &lt; d-c &lt; \epsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0+%3C+d-c+%3C+%5Cepsilon%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{0 &lt; d-c &lt; \epsilon}"/>. </em>
</p></blockquote>
<p/><p>
The Vitali theorem is the following: </p>
<blockquote><p><b>Theorem 4</b> <em> Let <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> be a subset of <img alt="{{\mathbb R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{{\mathbb R}}"/>. Let <img alt="{[a_{\lambda},b_{\lambda}]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ba_%7B%5Clambda%7D%2Cb_%7B%5Clambda%7D%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{[a_{\lambda},b_{\lambda}]}"/> be intervals for <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\lambda}"/> in some index set <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{I}"/>. Assume that the family is a Vitali cover of <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/>. Then there is a countable subfamily of disjoints intervals in the family so that they cover all of <img alt="{U}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{U}"/> except for possibly a null set. </em>
</p></blockquote>
<p/><p>
The Vitali theorem can be extended to any finite dimensional space <img alt="{{\mathbb R}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{{\mathbb R}^{n}}"/>. Then intervals become disks and so on.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Do you see how to prove Theorem <a href="https://rjlipton.wordpress.com/feed/#injective">2</a> from Vitali’s theorem? The insight is now one can set up a Vitali covering of the space <img alt="{Y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Y}"/>. </p></font></font></div>
    </content>
    <updated>2019-02-23T04:58:34Z</updated>
    <published>2019-02-23T04:58:34Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Proofs"/>
    <category term="analysis"/>
    <category term="axiom of choice"/>
    <category term="Giuseppe Vitali"/>
    <category term="set coverings"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-02-27T06:20:50Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/022</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/022" rel="alternate" type="text/html"/>
    <title>TR19-022 |  Circuit Lower Bounds for MCSP from Local Pseudorandom Generators | 

	Valentine Kabanets, 

	Mahdi Cheraghchi, 

	Zhenjian Lu, 

	Dimitrios Myrisiotis</title>
    <summary>The Minimum Circuit Size Problem (MCSP) asks if a given truth table of a Boolean function $f$ can be computed by a Boolean circuit of size at most $\theta$, for a given parameter $\theta$. We improve several circuit lower bounds for MCSP, using pseudorandom generators (PRGs) that are local; a PRG is called local if its output bit strings, when viewed as the truth table of a Boolean function, can be computed by a Boolean circuit of small size. We get new and improved lower bounds for MCSP that almost match the best-known lower bounds against several circuit models. 

Specifically, we show that computing MCSP, on functions with a truth table of length $N$, requires

   $N^{3-o(1)}$-size de Morgan formulas, improving the recent $N^{2-o(1)}$ lower bound by Hirahara and Santhanam (CCC, 2017),
 $N^{2-o(1)}$-size formulas over an arbitrary basis or general branching programs (no non-trivial lower bound was known for MCSP against these models), and 
    $2^{\Omega\left(N^{1/(d+2.01)}\right)}$-size depth-$d$ $AC^0$ circuits, improving the superpolynomial lower bound by Allender et al. (SICOMP, 2006).

 
    	The $AC^0$ lower bound stated above matches the best-known $AC^0$ lower bound (for PARITY) up to a small additive constant in the depth. Also, for the special case of depth-$2$ circuits (i.e., CNFs or DNFs), we get an almost optimal lower bound of \(2^{N^{1-o(1)}}\) for MCSP.</summary>
    <updated>2019-02-23T01:22:32Z</updated>
    <published>2019-02-23T01:22:32Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-27T06:20:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors</id>
    <link href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html" rel="alternate" type="text/html"/>
    <title>Mutual nearest neighbors versus closest pairs</title>
    <summary>In the 1990s I published a series of papers on data structures for closest pairs. As long as you already know how to maintain dynamic sets of objects of some type, and answer nearest-neighbor queries among them, you can also keep track of the closest pair, and this can be used as a subroutine in many other computational geometry algorithms. But it turns out that many of those algorithms can now be simplified and sped up by using mutual nearest neighbors (pairs of objects that are each other’s nearest neighbors) instead of closest pairs.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>In the 1990s I published a series of papers on data structures for closest pairs. As long as you already know how to maintain dynamic sets of objects of some type, and answer nearest-neighbor queries among them, you can also keep track of the closest pair, and this can be used as a subroutine in many other
computational geometry algorithms. But it turns out that many of those algorithms can now be simplified and sped up by using mutual nearest neighbors (pairs of objects that are each other’s nearest neighbors) instead of closest pairs.</p>

<p>My original motivation for studying these types of problems was to maintain minimum spanning trees of dynamic point sets, using closest red-blue pairs of Euclidean points,<sup id="fnref:aem"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:aem">1</a></sup> <sup id="fnref:ebf"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:ebf">2</a></sup> and I later found more applications in hierarchical clustering, greedy matching, traveling salesperson heuristics,<sup id="fnref:fhc"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:fhc">3</a></sup> <sup id="fnref:lazy"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:lazy">4</a></sup> and (with Jeff Erickson) motorcycle graphs and <a href="https://en.wikipedia.org/wiki/Straight_skeleton">straight skeletons</a>.<sup id="fnref:ee"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:ee">5</a></sup> But to use these closest pair data structures, you have to pay two logarithmic factors in time complexity over the time for the underlying nearest-neighbor data structure. So they’re not competitive with (uncolored) Euclidean closest pair data structures, which take only logarithmic time in any fixed dimension. Instead they make more sense to use with other distances than Euclidean, with objects more complicated than single points, or with variations like the red-blue closest pair for which the logarithmic-time solution doesn’t work.</p>

<p>For several variations of hierarchical clustering, an alternative and simpler technique has been known for quite a bit longer, based on finding mutual nearest neighbors (pairs of objects that are nearer to each other than to anything else) rather than closest pairs.<sup id="fnref:ben"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:ben">6</a></sup> <sup id="fnref:juan"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:juan">7</a></sup> It’s called the <a href="https://en.wikipedia.org/wiki/Nearest-neighbor_chain_algorithm">nearest neighbor chain algorithm</a>, but really it’s a data structure rather than an algorithm, one that allows you to maintain a dynamic point set and find pairs of mutual nearest neighbors, again based on calls to an underlying nearest neighbor data structure. The idea is to maintain a stack of shorter and shorter pairs of nearest neighbors, until the two objects whose distance is on the top of the stack have nothing nearer – they are mutual nearest neighbors. Whenever you want a pair of neighbors, you look at the top pair, an object  and its nearest neighbor , and ask whether ’s nearest neighbor is . If so, you have found a mutual nearest neighbor pair, and if not you have a new shorter distance to push onto the stack.</p>

<p>One can this in a hierarchical clustering algorithm that repeatedly finds and merges the nearest two clusters, whenever the distance between clusters has a special property: a merged cluster is never closer to other clusters than the closer of the two clusters that was merged. This property implies both that the stack of distances remains valid after the merge, and that mutual nearest neighbors are always safe to merge. If two clusters are mutual nearest neighbors, then the closest-pair clustering algorithm will eventually merge them, because none of its actions can cause them to stop being mutual nearest neighbors. So we might as well merge them immediately once we discover them to be mutual nearest neighbors. (One way to formulate this mathematically is that the set of mutual nearest neighbor pairs merged by the clustering algorithm forms an <a href="https://en.wikipedia.org/wiki/Antimatroid">antimatroid</a>). When this works, you get a clustering algorithm that uses a linear number of nearest neighbor queries, instead of the  queries that you would get using my closest-pair data structures.</p>

<p>In more recent research with UCI student Nil Mamano (finishing his doctorate this year; hire him for a postdoc, he’s good!) we noticed that the nearest neighbor chain algorithm can also be applied to certain <a href="https://11011110.github.io/blog/2017/04/11/stable-grid-matching.html">stable marriage problems with preferences coming from geometric distances</a>.<sup id="fnref:egm"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:egm">8</a></sup> Our latest preprint, “Euclidean TSP, Motorcycle Graphs, and Other New Applications of Nearest-Neighbor Chains” (with Efrat, Frishberg, Goodrich, Kobourov, Mamano, Matias, and Polishchuk, <a href="https://arxiv.org/abs/1902.06875">arXiv:1902.06875</a>) extends this to a much broader set of applications. As well as simplifying and speeding up my previous work on motorcycle graphs and TSP heuristics, we also use nearest neighbor chains in a bigger class of stable matching problems and in an approximate geometric set cover problem. In each case, we need to show either that the problem has an antimatroid-like property (so using mutual nearest neighbors produces the same solution as closest pairs) or that, even when varying from the same solution, it achieves the same quality. It’s not quite true that anything closest pairs can do, mutual nearest neighbors can do better, but it’s close.</p>

<p>Another idea in the paper is that to find (exact!) mutual nearest neighbor pairs one can sometimes get away with using approximate near neighbor structures. This is important if you’re using Euclidean distance, because the time bounds for exact nearest neighbors have the form  for constants  that get very small as  gets large, while approximate nearest neighbors are logarithmic in all dimensions. The idea is to build the stack of shorter distances by asking for a constant number of approximate near neighbors, the th of which is within a constant factor of the distance to the actual th nearest neighbor. By a packing argument for points in Euclidean space, either some two of these points are closer to each other than the distance on the current stack top (in which case you can build the stack one more level) or these approximate neighbors are guaranteed to contain the actual nearest neighbor (in which case you can either detect a mutual nearest neighbor pair or again build the stack).
This idea leads, for instance, to an algorithm for the <a href="https://en.wikipedia.org/wiki/Multi-fragment_algorithm">multi-fragment TSP heuristic</a> that takes time  in Euclidean spaces of any bounded dimension; the best previous time appears to be an -time algorithm (valid in any metric space) from one of my previous papers.<sup id="fnref:fhc:1"><a class="footnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:fhc">3</a></sup></p>

<div class="footnotes">
  <ol>
    <li id="fn:aem">
      <p>Agarwal, P. K., Eppstein, D., and Matoušek, J., “<a href="https://www.ics.uci.edu/~eppstein/pubs/AgaEppMat-FOCS-92.pdf">Dynamic algorithms for half-space reporting, proximity problems, and geometric minimum spanning trees</a>”, <em>FOCS</em>, 1992, pp. 80–89. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:aem">↩</a></p>
    </li>
    <li id="fn:ebf">
      <p>Eppstein, D., “<a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-DCG-95.pdf">Dynamic Euclidean minimum spanning trees and extrema of binary functions</a>”, <em>Discrete Comput. Geom.</em> 13: 111–122, 1995. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:ebf">↩</a></p>
    </li>
    <li id="fn:fhc">
      <p>Eppstein, D., “Fast hierarchical clustering and other applications of dynamic closest pairs”, <em>SODA</em>, 1998, pp. 619–628, <a href="https://arxiv.org/abs/cs.DS/9912014">arXiv:cs.DS/9912014</a>, <em>J. Experimental Algorithmics</em> 5 (1): 1–23, 2000. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:fhc">↩</a> <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:fhc:1">↩<sup>2</sup></a></p>
    </li>
    <li id="fn:lazy">
      <p>Cardinal, J., and Eppstein, D., “<a href="https://www.siam.org/meetings/alenex04/abstacts/JCardinal.pdf">Lazy algorithms for dynamic closest pair with arbitrary distance measures</a>”, <em>ALENEX</em>, 2004, pp. 112–119. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:lazy">↩</a></p>
    </li>
    <li id="fn:ee">
      <p>Eppstein, D., and Erickson, J., “<a href="http://jeffe.cs.illinois.edu/pubs/pdf/cycles.pdf">Raising roofs, crashing cycles, and playing pool: applications of a data structure for finding pairwise interactions</a>”, <em>SoCG</em>, 1998, pp. 58–67, <em>Discrete Comput. Geom.</em> 22 (4): 569–592, 1999. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:ee">↩</a></p>
    </li>
    <li id="fn:ben">
      <p>Benzécri, J.-P. (1982), “<a href="http://www.numdam.org/item?id=CAD_1982__7_2_209_0">Construction d’une classification ascendante hiérarchique par la recherche en chaîne des voisins réciproques</a>”, Les Cahiers de l’Analyse des Données, 7 (2): 209–218. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:ben">↩</a></p>
    </li>
    <li id="fn:juan">
      <p>Juan, J. (1982), “<a href="http://www.numdam.org/item?id=CAD_1982__7_2_219_0">Programme de classification hiérarchique par l’algorithme de la recherche en chaîne des voisins réciproques</a>”, <em>Les Cahiers de l’Analyse des Données</em>, 7 (2): 219–225. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:juan">↩</a></p>
    </li>
    <li id="fn:egm">
      <p>Eppstein, D., Goodrich, M. T., and Mamano, N., “Algorithms for stable matching and clustering in a grid”, <a href="https://arxiv.org/abs/1704.02303">arXiv:1704.02303</a>, <em>IWCIA</em> 2017, LNCS 10256 (2017), pp. 117–131. <a class="reversefootnote" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:egm">↩</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/101634032916499158">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-02-21T21:06:00Z</updated>
    <published>2019-02-21T21:06:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-02-22T05:13:03Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4944416293302133989</id>
    <link href="https://blog.computationalcomplexity.org/feeds/4944416293302133989/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/extra-extra-read-all-about-it.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4944416293302133989" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4944416293302133989" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/02/extra-extra-read-all-about-it.html" rel="alternate" type="text/html"/>
    <title>Extra! Extra! Read all about it!</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Last weekend I saw the documentary <a href="https://www.imdb.com/title/tt7428030/">Joseph Pulitzer: Voice of the People</a>. Pulitzer, as you probably know from the prize named after him, was a major newspaper publisher in the late 19th and early 20th century. He ran two papers, the St. Louis Post-Dispatch and The New York World. The World at one point took on massive proportions, including sheet music of the latest tunes and dress patterns of new fashion that one could make at home. The World was the Internet of the turn of the 20th century.<br/>
<br/>
The movie mentioned the many editions of the paper during the day, including the extra edition. An extra edition came out because of some major breaking news story. Back then newspapers would drum up minor stories to sell extra editions but they tended to disappear over time.<br/>
<br/>
Which brings me to Monday, August 19, 1991. Hard-line members of the communist party of the USSR <a href="https://en.wikipedia.org/wiki/1991_Soviet_coup_d%27%C3%A9tat_attempt">attempted a coup</a> to take over the government from Mikhail Gorbachev. To us in the US, this seemed like the cold war which appeared to be coming to an end might rekindle. At the time I lived in Chicago and on that Monday the Chicago Tribune ran an extra afternoon edition talking about the coup. The return to the cold war didn't happen. Within a couple of days the coup failed and if anything hastened the dissolution of the Soviet Republic.<br/>
<br/>
That was probably the last of the extra editions. By the time of the next major historical event, ten years and twenty-three days later, we had the Internet and cell phones and one no longer needed a newspaper to tell you the world has changed.</div>
    </content>
    <updated>2019-02-21T12:42:00Z</updated>
    <published>2019-02-21T12:42:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>https://plus.google.com/101693130490639305932</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>https://plus.google.com/101693130490639305932</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-02-27T05:22:54Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/021</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/021" rel="alternate" type="text/html"/>
    <title>TR19-021 |  $AC^0[p]$ Lower Bounds and NP-Hardness for Variants of MCSP | 

	Rahul Ilango</title>
    <summary>The Minimum Circuit Size Problem (MCSP) asks whether a (given) Boolean function has a circuit of at most a (given) size. Despite over a half-century of study, we know relatively little about the computational complexity of MCSP. We do know that questions about the complexity of MCSP have significant ramifications on longstanding open problems. In a recent development, Golovnev et al. [11] improves the status of unconditional lower bounds for MCSP, showing that MCSP is not in $AC^0[p]$ for any prime $p$. While their results generalize to most "typical" circuit classes, it fails to generalize to the circuit minimization problem for depth-d formulas, denoted ($AC^0_d$)-MCSP. In particular, their result relies on a Lipchitz hypothesis that is unknown (and possibly false) in the case of ($AC^0_d$)-MCSP. Despite this, we show that ($AC^0_d$)-MCSP is not in $AC^0[p]$ by proving even the failure of the Lipchitzness for $AC^0_d$ formulas implies that MAJORITY reduces to ($AC^0_d$)-MCSP under $AC^0$ truth table reductions. Somewhat remarkably, our proof (in the case of non-Lipchitzness) uses completely different techniques than [11]. To our knowledge, this is the first MCSP reduction that uses modular properties of a function's circuit complexity.

We also define MOCSP, an oracle version of MCSP that takes as input a Boolean function $f$, a size threshold $s$, and oracle Boolean functions $f_1, ..., f_t$, and determines whether there is an oracle circuit of size at most $s$ that computes $f$ when given access to $f_1, ... , f_t$. We prove that MOCSP is $NP$-complete under non-uniform $AC^0$ many-one reductions as well as (uniform) $ZPP$ truth table reductions. We also observe that improving this $ZPP$ reduction to a deterministic polynomial-time reduction requires showing $EXP \neq ZPP$ (using theorems of Hitchcock and Pavan [17] and Murray and Williams [22]). Optimistically, these MOCSP results could be a first step towards $NP$-hardness results for MCSP. At the very least, we believe MOCSP clarifies the barriers towards proving hardness for MCSP and provides a useful "testing ground" for questions about MCSP.</summary>
    <updated>2019-02-19T18:24:23Z</updated>
    <published>2019-02-19T18:24:23Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-27T06:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/020</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/020" rel="alternate" type="text/html"/>
    <title>TR19-020 |  On Tseitin formulas, read-once branching programs and treewidth | 

	Ludmila Glinskih, 

	Dmitry Itsykson</title>
    <summary>We show that any nondeterministic read-once branching program that computes a satisfiable Tseitin formula based on an $n\times n$ grid graph has size at least $2^{\Omega(n)}$. Then using the Excluded Grid Theorem by Robertson and Seymour we show that for arbitrary graph $G(V,E)$ any nondeterministic read-once branching program that computes a satisfiable Tseitin formula based on $G$ has size at least $2^{\Omega(tw(G)^\delta)}$ for all $\delta &lt;1/36$, where $tw(G)$ is the treewidth of $G$ (for planar graphs and some other classes of graphs the statement holds for $\delta=1$). We also show an upper bound $O(|E| 2^{pw(G)})$, where $pw(G)$ is the pathwidth of $G$.

We apply the mentioned results in the analysis of the complexity of derivation in the proof system $OBDD(\land, reordering)$ and show that any $OBDD(\land, reordering)$-refutation of an unsatisfiable Tseitin formula based on a graph $G$ has size at least $2^{\Omega(tw(G)^\delta)}$.</summary>
    <updated>2019-02-19T18:23:06Z</updated>
    <published>2019-02-19T18:23:06Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-02-27T06:20:42Z</updated>
    </source>
  </entry>
</feed>
