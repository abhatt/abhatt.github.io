<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-07-28T23:41:03Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/098</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/098" rel="alternate" type="text/html"/>
    <title>TR19-098 |  Domain Compression and its Application to Randomness-Optimal Distributed Goodness-of-Fit | 

	Clement Canonne, 

	Jayadev Acharya, 

	Himanshu Tyagi, 

	Ziteng Sun, 

	Yanjun Han</title>
    <summary>We study goodness-of-fit of discrete distributions in the distributed setting, where samples are divided between multiple users who can only release a limited amount of information about their samples due to various information constraints. Recently, a subset of the authors showed that having access to a common random seed (i.e., shared randomness) leads to a significant reduction in the sample complexity of this problem. In this work, we provide a complete understanding of the interplay between the amount of shared randomness available, the stringency of information constraints, and the sample complexity of the testing problem by characterizing a tight trade-off between these three parameters. We provide a general distributed goodness-of-fit protocol that as a function of the amount of shared randomness interpolates smoothly between the private- and public-coin sample complexities. We complement our upper bound with a general framework to prove lower bounds on the sample complexity of this testing problems under limited shared randomness. Finally, we instantiate our bounds for the two archetypal information constraints of communication and local privacy, and show that our sample complexity bounds are optimal as a function of all the parameters of the problem, including the amount of shared randomness.

A key component of our upper bounds is a new primitive of domain compression, a tool that allows us to map distributions to a much smaller domain size while preserving their pairwise distances, using a limited amount of randomness.</summary>
    <updated>2019-07-28T10:17:48Z</updated>
    <published>2019-07-28T10:17:48Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-28T23:38:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11209</id>
    <link href="http://arxiv.org/abs/1907.11209" rel="alternate" type="text/html"/>
    <title>Integrality Gap of the Vertex Cover Linear Programming Relaxation</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singh:Mohit.html">Mohit Singh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11209">PDF</a><br/><b>Abstract: </b>We give a characterization result for the integrality gap of the natural
linear programming relaxation for the vertex cover problem. We show that
integrality gap of the standard linear programming relaxation for any graph G
equals $\left(2-\frac{2}{\chi^f(G)}\right)$ where $\chi^f(G)$ denotes the
fractional chromatic number of G.
</p></div>
    </summary>
    <updated>2019-07-28T23:32:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11206</id>
    <link href="http://arxiv.org/abs/1907.11206" rel="alternate" type="text/html"/>
    <title>The Strong 3SUM-INDEXING Conjecture is False</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kopelowitz:Tsvi.html">Tsvi Kopelowitz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Porat:Ely.html">Ely Porat</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11206">PDF</a><br/><b>Abstract: </b>In the 3SUM-Indexing problem the goal is to preprocess two lists of elements
from $U$, $A=(a_1,a_2,\ldots,a_n)$ and $B=(b_1,b_2,...,b_n)$, such that given
an element $c\in U$ one can quickly determine whether there exists a pair
$(a,b)\in A \times B$ where $a+b=c$. Goldstein et al.~[WADS'2017] conjectured
that there is no algorithm for 3SUM-Indexing which uses $n^{2-\Omega(1)}$ space
and $n^{1-\Omega(1)}$ query time.
</p>
<p>We show that the conjecture is false by reducing the 3SUM-Indexing problem to
the problem of inverting functions, and then applying an algorithm of Fiat and
Naor [SICOMP'1999] for inverting functions.
</p></div>
    </summary>
    <updated>2019-07-28T23:34:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11078</id>
    <link href="http://arxiv.org/abs/1907.11078" rel="alternate" type="text/html"/>
    <title>Approximating APSP without Scaling: Equivalence of Approximate Min-Plus and Exact Min-Max</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bringmann:Karl.html">Karl Bringmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/K=uuml=nnemann:Marvin.html">Marvin Künnemann</a>, Karol Węgrzycki <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11078">PDF</a><br/><b>Abstract: </b>Zwick's $(1+\varepsilon)$-approximation algorithm for the All Pairs Shortest
Path (APSP) problem runs in time $\widetilde{O}(\frac{n^\omega}{\varepsilon}
\log{W})$, where $\omega \le 2.373$ is the exponent of matrix multiplication
and $W$ denotes the largest weight. This can be used to approximate several
graph characteristics including the diameter, radius, median, minimum-weight
triangle, and minimum-weight cycle in the same time bound.
</p>
<p>Since Zwick's algorithm uses the scaling technique, it has a factor $\log W$
in the running time. In this paper, we study whether APSP and related problems
admit approximation schemes avoiding the scaling technique. That is, the number
of arithmetic operations should be independent of $W$; this is called strongly
polynomial. Our main results are as follows.
</p>
<p>- We design approximation schemes in strongly polynomial time
$O(\frac{n^\omega}{\varepsilon} \text{polylog}(\frac{n}{\varepsilon}))$ for
APSP on undirected graphs as well as for the graph characteristics diameter,
radius, median, minimum-weight triangle, and minimum-weight cycle on directed
or undirected graphs.
</p>
<p>- For APSP on directed graphs we design an approximation scheme in strongly
polynomial time $O(n^{\frac{\omega + 3}{2}} \varepsilon^{-1}
\text{polylog}(\frac{n}{\varepsilon}))$. This is significantly faster than the
best exact algorithm.
</p>
<p>- We explain why our approximation scheme for APSP on directed graphs has a
worse exponent than $\omega$: Any improvement over our exponent $\frac{\omega +
3}{2}$ would improve the best known algorithm for Min-Max Product In fact, we
prove that approximating directed APSP and exactly computing the Min-Max
Product are equivalent.
</p></div>
    </summary>
    <updated>2019-07-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11015</id>
    <link href="http://arxiv.org/abs/1907.11015" rel="alternate" type="text/html"/>
    <title>A new approach (extra vertex) and generalization of Shoelace Algorithm usage in convex polygon (Point-in-Polygon)</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Ochilbek Rakhmanov <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11015">PDF</a><br/><b>Abstract: </b>In this paper we aim to bring new approach into usage of Shoelace Algorithm
for area calculation in convex polygons on Cartesian coordinate system, with
concentration on point in polygon concept. Generalization of usage of the
concept will be proposed for line segment and polygons. Testing of new method
will be done using Python language. Results of tests show that the new approach
is more effective than the current one.
</p></div>
    </summary>
    <updated>2019-07-28T23:38:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11010</id>
    <link href="http://arxiv.org/abs/1907.11010" rel="alternate" type="text/html"/>
    <title>Deciding Fast Termination for Probabilistic VASS with Nondeterminism</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Tomáš Brázdil, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chatterjee:Krishnendu.html">Krishnendu Chatterjee</a>, Antonín Kučera, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Novotn=yacute=:Petr.html">Petr Novotný</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Velan:Dominik.html">Dominik Velan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11010">PDF</a><br/><b>Abstract: </b>A probabilistic vector addition system with states (pVASS) is a finite state
Markov process augmented with non-negative integer counters that can be
incremented or decremented during each state transition, blocking any behaviour
that would cause a counter to decrease below zero. The pVASS can be used as
abstractions of probabilistic programs with many decidable properties. The use
of pVASS as abstractions requires the presence of nondeterminism in the model.
In this paper, we develop techniques for checking fast termination of pVASS
with nondeterminism.
</p>
<p>That is, for every initial configuration of size n, we consider the worst
expected number of transitions needed to reach a configuration with some
counter negative (the expected termination time). We show that the problem
whether the asymptotic expected termination time is linear is decidable in
polynomial time for a certain natural class of pVASS with nondeterminism.
Furthermore, we show the following dichotomy: if the asymptotic expected
termination time is not linear, then it is at least quadratic, i.e., in
$\Omega(n^2)$.
</p></div>
    </summary>
    <updated>2019-07-28T23:21:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10984</id>
    <link href="http://arxiv.org/abs/1907.10984" rel="alternate" type="text/html"/>
    <title>Enumerating Range Modes</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sumigawa:Kentaro.html">Kentaro Sumigawa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakraborty:Sankardeep.html">Sankardeep Chakraborty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sadakane:Kunihiko.html">Kunihiko Sadakane</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Satti:Srinivasa_Rao.html">Srinivasa Rao Satti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10984">PDF</a><br/><b>Abstract: </b>We consider the range mode problem where given a sequence and a query range
in it, we want to find items with maximum frequency in the range. We give time-
and space- efficient algorithms for this problem. Our algorithms are efficient
for small maximum frequency cases. We also consider a natural generalization of
the problem: the range mode enumeration problem, for which there has been no
known efficient algorithms. Our algorithms have query time complexities which
is linear to the output size plus small terms.
</p></div>
    </summary>
    <updated>2019-07-28T23:36:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10937</id>
    <link href="http://arxiv.org/abs/1907.10937" rel="alternate" type="text/html"/>
    <title>Polylogarithmic-Time Deterministic Network Decomposition and Distributed Derandomization</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Václav Rozhoň, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghaffari:Mohsen.html">Mohsen Ghaffari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10937">PDF</a><br/><b>Abstract: </b>We present a simple polylogarithmic-time deterministic distributed algorithm
for network decomposition. This improves on a celebrated $2^{O(\sqrt{\log
n})}$-time algorithm of Panconesi and Srinivasan [STOC'93] and settles one of
the long-standing and central questions in distributed graph algorithms. It
also leads to the first polylogarithmic-time deterministic distributed
algorithms for numerous other graph problems, hence resolving several open
problems, including Linial's well-known question about the deterministic
complexity of maximal independent set [FOCS'87].
</p>
<p>Put together with the results of Ghaffari, Kuhn, and Maus [STOC'17] and
Ghaffari, Harris, and Kuhn [FOCS'18], we get a general distributed
derandomization result that implies $\mathsf{P}$-$\mathsf{RLOCAL}$ =
$\mathsf{P}$-$\mathsf{LOCAL}$. That is, for any distributed problem whose
solution can be checked in polylogarithmic-time, any polylogarithmic-time
randomized algorithm can be derandomized to a polylogarithmic-time
deterministic algorithm.
</p>
<p>By known connections, our result leads also to substantially faster
randomized algorithms for a number of fundamental problems including
$(\Delta+1)$-coloring, MIS, and Lov\'{a}sz Local Lemma.
</p></div>
    </summary>
    <updated>2019-07-28T23:31:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10930</id>
    <link href="http://arxiv.org/abs/1907.10930" rel="alternate" type="text/html"/>
    <title>GAMA: A Novel Algorithm for Non-Convex Integer Programs</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alghassi:Hedayat.html">Hedayat Alghassi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dridi:Raouf.html">Raouf Dridi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tayur:Sridhar.html">Sridhar Tayur</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10930">PDF</a><br/><b>Abstract: </b>Inspired by the decomposition in the hybrid quantum-classical optimization
algorithm we introduced in <a href="http://export.arxiv.org/abs/1902.04215">arXiv:1902.04215</a>, we propose here a new (fully
classical) approach to solving certain non-convex integer programs using Graver
bases. This method is well suited when (a) the constraint matrix $A$ has a
special structure so that its Graver basis can be computed systematically, (b)
several feasible solutions can also be constructed easily and (c) the objective
function can be viewed as many convex functions quilted together. Classes of
problems that satisfy these conditions include Cardinality Boolean Quadratic
Problems (CBQP), Quadratic Semi-Assignment Problems (QSAP) and Quadratic
Assignment Problems (QAP). Our Graver Augmented Multi-seed Algorithm (GAMA)
utilizes augmentation along Graver basis elements (the improvement direction is
obtained by comparing objective function values) from these multiple initial
feasible solutions. We compare our approach with a best-in-class commercially
available solver (Gurobi). Sensitivity analysis indicates that the rate at
which GAMA slows down as the problem size increases is much lower than that of
Gurobi. We find that for several instances of practical relevance, GAMA not
only vastly outperforms in terms of time to find the optimal solution (by two
or three orders of magnitude), but also finds optimal solutions within minutes
when the commercial solver is not able to do so in 4 or 10 hours (depending on
the problem class) in several cases.
</p></div>
    </summary>
    <updated>2019-07-28T23:31:13Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10895</id>
    <link href="http://arxiv.org/abs/1907.10895" rel="alternate" type="text/html"/>
    <title>Fast Deterministic Constructions of Linear-Size Spanners and Skeletons</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Elkin:Michael.html">Michael Elkin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Matar:Shaked.html">Shaked Matar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10895">PDF</a><br/><b>Abstract: </b>In the distributed setting, the only existing constructions of \textit{sparse
skeletons}, (i.e., subgraphs with $O(n)$ edges) either use randomization or
large messages, or require $\Omega(D)$ time, where $D$ is the hop-diameter of
the input graph $G$. We devise the first deterministic distributed algorithm in
the CONGEST model (i.e., uses small messages) for constructing linear-size
skeletons in time $2^{O(\sqrt{{\log n}\cdot{\log{\log n}}})}$. We can also
compute a linear-size spanner with stretch $polylog(n)$ in low deterministic
polynomial time, i.e., $O(n^\rho)$ for an arbitrarily small constant $\rho &gt;0$,
in the CONGEST model. Yet another algorithm that we devise runs in $O({\log
n})^{\kappa-1}$ time, for a parameter $\kappa=1,2,\dots,$ and constructs an
$O({\log n})^{\kappa-1}$ spanner with $O(n^{1+1/\kappa})$ edges. All our
distributed algorithms are lightweight from the computational perspective,
i.e., none of them employs any heavy computations.
</p></div>
    </summary>
    <updated>2019-07-28T23:28:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10874</id>
    <link href="http://arxiv.org/abs/1907.10874" rel="alternate" type="text/html"/>
    <title>How to Store a Random Walk</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Viola:Emanuele.html">Emanuele Viola</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weinstein:Omri.html">Omri Weinstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Huacheng.html">Huacheng Yu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10874">PDF</a><br/><b>Abstract: </b>Motivated by storage applications, we study the following data structure
problem: An encoder wishes to store a collection of jointly-distributed files
$\overline{X}:=(X_1,X_2,\ldots, X_n) \sim \mu$ which are \emph{correlated}
($H_\mu(\overline{X}) \ll \sum_i H_\mu(X_i)$), using as little (expected)
memory as possible, such that each individual file $X_i$ can be recovered
quickly with few (ideally constant) memory accesses.
</p>
<p>In the case of independent random files, a dramatic result by \Pat (FOCS'08)
and subsequently by Dodis, \Pat and Thorup (STOC'10) shows that it is possible
to store $\overline{X}$ using just a \emph{constant} number of extra bits
beyond the information-theoretic minimum space, while at the same time decoding
each $X_i$ in constant time. However, in the (realistic) case where the files
are correlated, much weaker results are known, requiring at least
$\Omega(n/poly\lg n)$ extra bits for constant decoding time, even for "simple"
joint distributions $\mu$.
</p>
<p>We focus on the natural case of compressing\emph{Markov chains}, i.e.,
storing a length-$n$ random walk on any (possibly directed) graph $G$. Denoting
by $\kappa(G,n)$ the number of length-$n$ walks on $G$, we show that there is a
succinct data structure storing a random walk using $\lg_2 \kappa(G,n) + O(\lg
n)$ bits of space, such that any vertex along the walk can be decoded in $O(1)$
time on a word-RAM. For the harder task of matching the \emph{point-wise}
optimal space of the walk, i.e., the empirical entropy $\sum_{i=1}^{n-1} \lg
(deg(v_i))$, we present a data structure with $O(1)$ extra bits at the price of
$O(\lg n)$ decoding time, and show that any improvement on this would lead to
an improved solution on the long-standing Dictionary problem. All of our data
structures support the \emph{online} version of the problem with constant
update and query time.
</p></div>
    </summary>
    <updated>2019-07-28T23:29:53Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10779</id>
    <link href="http://arxiv.org/abs/1907.10779" rel="alternate" type="text/html"/>
    <title>Improved Girth Approximation and Roundtrip Spanners</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chechik:Shiri.html">Shiri Chechik</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Yang_P=.html">Yang P. Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rotem:Omer.html">Omer Rotem</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidford:Aaron.html">Aaron Sidford</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10779">PDF</a><br/><b>Abstract: </b>In this paper we provide improved algorithms for approximating the girth and
producing roundtrip spanners of $n$-node $m$-edge directed graphs with
non-negative edge lengths. First, for any integer $k \ge 1$, we provide a
deterministic $\tilde{O}(m^{1+ 1/k})$ time algorithm which computes a
$O(k\log\log n)$ multiplicative approximation of the girth and a $O(k\log\log
n)$ multiplicative roundtrip spanner with $\tilde{O}(n^{1+1/k})$ edges. Second,
we provide a randomized $\tilde{O}(m\sqrt{n})$ time algorithm that with high
probability computes a 3-multiplicative approximation to the girth. Third, we
show how to combine these algorithms to obtain for any integer $k \ge 1$ a
randomized algorithm which in $\tilde{O}(m^{1+ 1/k})$ time computes a $O(k\log
k)$ multiplicative approximation of the girth and $O(k \log k)$ multiplicative
roundtrip spanner with high probability.
</p>
<p>The previous fastest algorithms for these problems either ran in All-Pairs
Shortest Paths (APSP) time, i.e. $\tilde{O}(mn)$, or were due Pachocki et al
(SODA 2018) which provided a randomized algorithm that for any integer $k \ge
1$ in time $\tilde{O}(m^{1+1/k})$ computed with high probability a $O(k\log n)$
multiplicative approximation of the girth and a $O(k\log n)$ multiplicative
roundtrip spanners with $\tilde{O}(n^{1+1/k})$ edges. Our first algorithm
removes the need for randomness and improves the approximation factor in
Pachocki et al (SODA 2018), our second is constitutes the first sub-APSP-time
algorithm for approximating the girth to constant accuracy with high
probability, and our third is the first time versus quality trade-offs for
obtaining constant approximations.
</p></div>
    </summary>
    <updated>2019-07-28T23:32:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10707</id>
    <link href="http://arxiv.org/abs/1907.10707" rel="alternate" type="text/html"/>
    <title>Real-time Deformation of Soft Tissue Internal Structure with Surface Profile Variations using Particle System</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Haoyin.html">Haoyin Zhou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gombos:Eva.html">Eva Gombos</a>, Mehra Golshan, Jayender Jagadeesan <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10707">PDF</a><br/><b>Abstract: </b>Intraoperative observation of tissue internal structure is often difficult.
Hence, real-time soft tissue deformation is essential for the localization of
tumor and other internal structures. We propose a method to simulate the
internal structural deformations in a soft tissue with surface profile
variations. The deformation simulation utilizes virtual physical particles that
receive interaction forces from the surface and other particles and adjust
their positions accordingly. The proposed method involves two stages. In the
initialization stage, the three-dimensional internal structure of the surface
mesh is uniformly sampled using the particle expansion and attracting-repelling
force models whilst simultaneously building the internal particle connections.
In the simulation stage, under surface profile variations, we simulate the
internal structural deformation based on a deformation force model that uses
the internal particle connections. The main advantage of this method is that it
greatly reduces the computational burden as it only involves simplified
calculations and also does not require generating three-dimensional meshes.
Preliminary experimental results show that the proposed method can handle up to
10,000 particles in 0.3s.
</p></div>
    </summary>
    <updated>2019-07-28T23:38:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4251</id>
    <link href="https://lucatrevisan.wordpress.com/2019/07/27/three-stories-about-u-c-administration/" rel="alternate" type="text/html"/>
    <title>Three stories about U.C. administration</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A few months ago, I was delighted to see the University of California holding on to its demands in its negotiations with Elsevier. The U.C. wanted to renegotiate its contract so that, in addition to having access to the subscribed … <a href="https://lucatrevisan.wordpress.com/2019/07/27/three-stories-about-u-c-administration/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A few months ago, I was delighted to see the University of California <a href="https://www.theatlantic.com/science/archive/2019/03/uc-elsevier-publisher/583909/">holding on to its demands</a> in its negotiations with Elsevier. The U.C. wanted to renegotiate its contract so that, in addition to having access to the subscribed journals, U.C. scholars could publish in them with open access (that is, so that anybody in the world would have free access to the articles written by U.C. scholars).</p>
<p>This seemed like a reasonable model to balance profitability for publishers and open access, but there was no way to agree on it with Elsevier. Meanwhile, U.C. has not renewed its Elsevier subscriptions and Elsevier has cut off access to U.C. libraries.</p>
<p>I was very impressed to see the University of California central administration do something right, so I wondered if this was the kind of portent that is a harbinger of the apocalypse, or just a fluke. Subsequent events suggest the latter.</p>
<p>The University of California has spent a lot of time and money to build a centralized system for job applications and for job applicant review. I was first made aware of this when I chaired the recruiting committee for the Simons Director position. At first we were told that we could solicit applications through the (vastly superior) EECS-built system for job applications and reviews. After the application deadline passed, we were told that, in fact, we could <i>not</i> use the EECS system, and so the already overworked EECS faculty HR person had to manually copy all the data in the central campus system. </p>
<p>The American Mathematical Society has created a wonderfully functional system, called <a href="https://www.mathjobs.org/jobs">Mathjobs</a> where applicants for academic mathematics jobs (ranging from postdocs to professorship) can upload their application material once, and their recommenders can upload their letters once, and then all the universities that the candidate applies to have access to this material. Furthermore, if needed, both applicants and recommenders can tailor-make their material for a particular university or universities, if they want to.</p>
<p>Everybody was living happily, but not ever after, because the U.C. central campus administration decided that <i>everybody</i> in the University of California had to use the centralized system for <i>all</i> jobs. Both the AMS and U.C. mathematicians tried to find a reasonable accommodation, such as allowing the U.C. system to access the letters posted on mathjobs. The campus administration reasoned response was roughly “sucks to be you.” There is more of the story in an <a href="https://www.ams.org/journals/notices/201907/rnoti-p1085.pdf">AMS notices article</a> by the chair of math at U.C. Davis.</p>
<p>Finally, this year <a href="https://www.sfchronicle.com/nation/article/UC-Berkeley-booted-from-U-S-News-World-Report-14189464.php">U.C. Berkeley</a> will not be listed in the US News and World Report rankings because it has submitted wrong data in the past.</p></div>
    </content>
    <updated>2019-07-27T22:06:35Z</updated>
    <published>2019-07-27T22:06:35Z</published>
    <category term="Berkeley"/>
    <category term="things that are terrible"/>
    <category term="University of California"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2019-07-28T23:20:18Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7683541918979097623</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7683541918979097623/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/the-advisoradvisee-relationship.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7683541918979097623" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7683541918979097623" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/the-advisoradvisee-relationship.html" rel="alternate" type="text/html"/>
    <title>The Advisor/Advisee Relationship</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">I've always felt a strong advisor/advisee relationship is the single most important factor in a successful PhD career. At its best, the advisor works closely with the student to successful research agenda and help mentor them through their graduate career and beyond. The advisor/advisee relationship can feel like a parent/child relationship that lasts an entire career. Nothing gives me more pleasure as an academic than to see the success of my current and former students.<br/>
<br/>
Take your time when picking an advisor. Don't choose an advisor based solely on research area or because they are "famous". Pick the advisor that will best guide you to a successful academic career.<br/>
<br/>
At its worst, a bad advisor/advisee relationship will destroy your graduate career, making you feel miserable, perhaps dropping out of graduate school or worse, particularly if a student doesn't feel like they are being treated fairly.<br/>
<br/>
Two incidents prompted this post. On TCS-Stack Exchange, a student has <a href="https://cstheory.stackexchange.com/questions/42704/single-author-papers-against-my-advisors-will/42711">authorship issues</a> with their advisor. Unfortunately these kinds of incidents happen more often than one suspects. If you can't work it out with the advisor, go talk to someone about it, another faculty, the graduate or department chair, a grad student ombudsperson if your institution has one. We care about our students, and will work hard to resolve problems.<br/>
<br/>
In a much more <a href="https://medium.com/@huixiangvoice/the-hidden-story-behind-the-suicide-phd-candidate-huixiang-chen-236cd39f79d3">tragic event</a>, a student felt it easier to take his own life than feeling that he had to cover up potential academic misconduct. Again, if you ever find yourself in such a situation please reach out. Giving up is never the answer.</div>
    </content>
    <updated>2019-07-25T20:39:00Z</updated>
    <published>2019-07-25T20:39:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-28T12:43:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16124</id>
    <link href="https://rjlipton.wordpress.com/2019/07/25/discrepancy-games-and-sensitivity/" rel="alternate" type="text/html"/>
    <title>Discrepancy Games and Sensitivity</title>
    <summary>Can we connect the talks that closed this month’s Random Structures and Algorithms conference? Cropped from NYU homepage Joel Spencer gave the closing talk of last week’s Random Structures and Algorithms conference at ETH Zurich. Today we discuss his talk and the one that preceded it, which was by Hao Huang on his proof this […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Can we connect the talks that closed this month’s Random Structures and Algorithms conference?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/07/joelspencerhomepageinrussia.jpg"><img alt="" class="alignright wp-image-16126" height="200" src="https://rjlipton.files.wordpress.com/2019/07/joelspencerhomepageinrussia.jpg?w=137&amp;h=200" width="137"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from NYU <a href="https://cs.nyu.edu/spencer/">homepage</a></font></td>
</tr>
</tbody>
</table>
<p>
Joel Spencer gave the closing talk of last week’s Random Structures and Algorithms <a href="https://math.ethz.ch/fim/conferences/19th-int-conf-random-structures-algorithms/schedule.html">conference</a> at ETH Zurich.</p>
<p>
Today we discuss his talk and the one that preceded it, which was by Hao Huang on his proof this month of the Boolean sensitivity conjecture.</p>
<p>
Spencer’s <a href="https://ethz.ch/content/dam/ethz/special-interest/math/mathematical-research/fim-dam/Conferences/2019/19th Int Conf on Random Structures and Algorithms/Abstracts/Spencer_Joel.pdf">talk</a> was titled “Four Discrepancies” and based on a joint <a href="https://arxiv.org/pdf/1903.06898.pdf">paper</a> with Nikhil Bhansal. The main new result in the talk was a case where a bound of <img alt="{O(\sqrt{n\log n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt%7Bn%5Clog+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\sqrt{n\log n})}"/> arising from reasoning about normal distribution can, surprisingly, be improved to a sharp <img alt="{O(\sqrt{n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\sqrt{n})}"/>. </p>
<p>
We will talk about this first, but then progress to the talk that preceded Spencer’s. It was by Hao Huang, who was extended an invitation right after his announced <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">proof</a> of the Boolean Sensitivity Conjecture earlier this month. Our ulterior purpose is to ask whether any concrete connections can be found besides both talks addressing problems on the <img alt="{\{-1,+1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B-1%2C%2B1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{-1,+1\}^n}"/> hypercube.</p>
<p>
</p><p/><h2> Discrepancy Games </h2><p/>
<p/><p>
First suppose you get a stream of single bits <img alt="{v_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v_t}"/>, each <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> or <img alt="{+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+1}"/>. For each bit, you can say “Keep it” or “Flip it.” In the latter case, your bit <img alt="{w_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w_t}"/> is <img alt="{-v_t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-v_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-v_t}"/>. Your goal is to keep the sum <img alt="{\sum_{k=1}^t w_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bk%3D1%7D%5Et+w_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sum_{k=1}^t w_k}"/> within a bounded range. OK, this is easy: you can make the sum always be <img alt="{+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+1}"/> when <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> is odd and <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> when <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> is even by flipping when needed.</p>
<p>
Now suppose the bits come in pairs <img alt="{(v_{t,1},v_{t,2})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28v_%7Bt%2C1%7D%2Cv_%7Bt%2C2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(v_{t,1},v_{t,2})}"/> and your goal is to keep the sum in each coordinate bounded. Again there is a simple strategy: There are four kinds of vectors. For each kind, every time you see it for the second time, flip it. That keeps the contribution of each kind within <img alt="{-1 \ldots +1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1+%5Cldots+%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1 \ldots +1}"/> in each coordinate. Thus simple reasoning says each coordinate stays within <img alt="{-4 \ldots +4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-4+%5Cldots+%2B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-4 \ldots +4}"/>. </p>
<p>
The trouble with extending this idea to vectors of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is that the number of kinds is <img alt="{2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^n}"/> and our simple-minded bounds, while constant in terms of the number <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> of vectors given, are exponential in <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>. Well, we can certainly do better. Going back to the <img alt="{n = 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 2}"/> case, we can maintain a policy of never letting both coordinates become <img alt="{+2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+2}"/> or both become <img alt="{-2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-2}"/>. This keeps both sums within <img alt="{-2 \ldots +2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-2+%5Cldots+%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-2 \ldots +2}"/> regardless of the sequence of the vectors. But for larger vector lengths <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, how large can the <em>discrepancy</em> among the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> coordinate sums—relative to zero or to each other—become?</p>
<p>
A final help is if we know the number <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> of vectors in any sequence we might be given is bounded. In fact, Spencer’s paper with Bhansal first considers the case <img alt="{T = n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT+%3D+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T = n}"/>. There are two main questions about randomness:</p>
<ol>
<li>
Does it matter whether the sequence of vectors given is random or worst-case? <p/>
</li><li>
Can you do better than choosing “keep” or “flip” randomly?
</li></ol>
<p>
Long back, Spencer <a href="https://cs.nyu.edu/spencer/sixsigma.pdf">proved</a> that if you can see the whole sequence of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> vectors in advance, then you can always keep the sums within <img alt="{-5.32 \sqrt{n} \ldots +5.32\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-5.32+%5Csqrt%7Bn%7D+%5Cldots+%2B5.32%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-5.32 \sqrt{n} \ldots +5.32\sqrt{n}}"/>, whatever the sequence. If not—if you must decide “keep” or “flip” for each vector before seeing the next—then Spencer had also <a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=HTxo3kP7_5gC&amp;oi=fnd&amp;pg=PP2&amp;dq=Ten+Lectures+on+the+Probabilistic+Method+Spencer&amp;ots=hGDS5tiCgB&amp;sig=qP53Ty3AQgVJF2J4wzcmT948mmY#v=onepage&amp;q=Ten Lectures on the Probabilistic Method Spencer&amp;f=false">proved</a>:</p>
<blockquote><p><b>Theorem 1</b> <em> If an adversary can choose the next vector based on your current sums, then the best bound <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B}"/> such that you can keep all your sums within absolute value <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B}"/> grows as <img alt="{\Theta(\sqrt{n\log n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CTheta%28%5Csqrt%7Bn%5Clog+n%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\Theta(\sqrt{n\log n})}"/>. Moreover, up to the constant in the “<img alt="{\Theta,}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CTheta%2C%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\Theta,}"/>” with high probability you cannot do any better than choosing the sign for each vector randomly. </em>
</p></blockquote>
<p/><p>
See also his famous <a href="https://www.wiley.com/en-us/The+Probabilistic+Method/+4th+Edition-p-9781119061953">book</a>, <em>The Probabilistic Method</em>, with Noga Alon. The new theorem is:</p>
<blockquote><p><b>Theorem 2</b> <em> If the adversary presents vectors uniformly at random, then you <b>can</b> achieve <img alt="{B = O(\sqrt{n})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%3D+O%28%5Csqrt%7Bn%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B = O(\sqrt{n})}"/> with high probability—and not by choosing the signs randomly. </em>
</p></blockquote>
<p/><p>
The algorithm defines a kind of <em>potential function</em> and has you play “keep” or “flip” according to which has the lesser growth in potential. The analysis is quite complicated. As usual we refer to the <a href="https://arxiv.org/pdf/1903.06898.pdf">paper</a> for details. Instead we ask: are there insights to mine here for further advances on the Boolean sensitivity problem?</p>
<p>
</p><p/><h2> Boolean Sensitivity </h2><p/>
<p/><p>
We didn’t talk about Boolean sensitivity in our previous <a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/">post</a> on it. Our purpose now is to convey how many concepts are related, hence how they might connect to discrepancy on the hypercube. </p>
<p>
To get the idea of sensitivity, first consider the parity function <img alt="{f_{\oplus}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Coplus%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\oplus}}"/>. If you change one bit of any argument <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> you change the value of <img alt="{f_{\oplus}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Coplus%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\oplus}(x)}"/>. Define <img alt="{x^i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5Ei%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^i}"/> to mean <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> with bit <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> flipped. Then for any <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> and <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, <img alt="{f_{\oplus}(x^i) \neq f_{\oplus}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Coplus%7D%28x%5Ei%29+%5Cneq+f_%7B%5Coplus%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\oplus}(x^i) \neq f_{\oplus}(x)}"/>. This means parity is extremely sensitive.</p>
<p>
The OR function <img alt="{f_{\vee}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Cvee%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\vee}}"/> is intuitively less sensitive, but it too has an argument <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> such that <img alt="{f_{\vee}(x^i) \neq f_{\vee}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Cvee%7D%28x%5Ei%29+%5Cneq+f_%7B%5Cvee%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_{\vee}(x^i) \neq f_{\vee}(x)}"/> for all <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/>, namely <img alt="{x = 0^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%3D+0%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x = 0^n}"/>. For any Boolean function <img alt="{f: \{0,1\}^n \rightarrow \{0,1\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%3A+%5C%7B0%2C1%5C%7D%5En+%5Crightarrow+%5C%7B0%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f: \{0,1\}^n \rightarrow \{0,1\}}"/> define its <em>sensitivity</em> (at <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>) by </p>
<p align="center"><img alt="\displaystyle  s(f) = s_n(f) = \max_{x \in \{0,1\}^n} ||\{i: f(x^i) \neq f(x)\}||. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s%28f%29+%3D+s_n%28f%29+%3D+%5Cmax_%7Bx+%5Cin+%5C%7B0%2C1%5C%7D%5En%7D+%7C%7C%5C%7Bi%3A+f%28x%5Ei%29+%5Cneq+f%28x%29%5C%7D%7C%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  s(f) = s_n(f) = \max_{x \in \{0,1\}^n} ||\{i: f(x^i) \neq f(x)\}||. "/></p>
<p>The OR-of-AND function <img alt="{f_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2}"/> is less sensitive. Say it is an OR of <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> blocks, each of <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> variables, and the blocks use disjoint variables so <img alt="{n = km}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+km%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = km}"/>. If <img alt="{f_2(x) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%28x%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2(x) = 1}"/>, then some block is all <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>, so flipping any other bit makes no difference, and the most sensitive we can get is <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>. If <img alt="{f_2(x) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%28x%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2(x) = 0}"/> then the most sensitive case is when all blocks have exactly one 0. So <img alt="{s(f_2) = \max\{k,m\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%28f_2%29+%3D+%5Cmax%5C%7Bk%2Cm%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s(f_2) = \max\{k,m\}}"/>. When <img alt="{k = m = \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+m+%3D+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k = m = \sqrt{n}}"/>, <img alt="{s_n(f) = \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs_n%28f%29+%3D+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s_n(f) = \sqrt{n}}"/>.</p>
<p>
If we make each block of <img alt="{f_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_2}"/> return <em>true</em> if exactly one bit is <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>, then we again get sensitivity <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> on the all-<img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> assignment. Now, however, consider the related function <img alt="{f'_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%27_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f'_2}"/> (with <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> even, <img alt="{k = 2\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+2%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k = 2\ell}"/>) that is still an OR over blocks, but each block is true when some consecutive pair <img alt="{x_{2\ell - 1},x_{2\ell}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7B2%5Cell+-+1%7D%2Cx_%7B2%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{2\ell - 1},x_{2\ell}}"/> are both <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> with all other pairs being both <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>. Then we can’t do the same trick with the all-<img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> assignment changing just one bit. So when <img alt="{n = 4\ell^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+4%5Cell%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 4\ell^2}"/> and <img alt="{m = k = 2\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+k+%3D+2%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = k = 2\ell}"/> we again get sensitivity (no more than) <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. </p>
<p>
We can, however, consider <img alt="{f'_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%27_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f'_2}"/> to be more sensitive if we can flip more than one bit at a time. Partition <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/> into <em>blocks</em> <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/> of two consecutive bit-places each, and given any <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>, define <img alt="{x^B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%5EB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x^B}"/> to be the result of flipping the bits in <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B}"/>. We get <img alt="{n/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n/2}"/> blocks, and the all-<img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/> assignment becomes a <em>true</em> case of <img alt="{f'_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%27_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f'_2}"/> if any block is flipped. Generally define the <em>block sensitivity</em> by considering any partitions <img alt="{\mathcal{B} = \{B_j\}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BB%7D+%3D+%5C%7BB_j%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathcal{B} = \{B_j\}}"/> of <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/> into disjoint subsets and writing </p>
<p align="center"><img alt="\displaystyle  bs(f) = \max_{x,\mathcal{B}} ||\{j: f(x^{B_j}) \neq f(x)\}||. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++bs%28f%29+%3D+%5Cmax_%7Bx%2C%5Cmathcal%7BB%7D%7D+%7C%7C%5C%7Bj%3A+f%28x%5E%7BB_j%7D%29+%5Cneq+f%28x%29%5C%7D%7C%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  bs(f) = \max_{x,\mathcal{B}} ||\{j: f(x^{B_j}) \neq f(x)\}||. "/></p>
<p>Note that not every member of the partition has to flip the function—we can discard the ones that don’t flip and count only the disjoint subsets that do flip the value. So back to our example, we have </p>
<p align="center"><img alt="\displaystyle  bs(f'_2) = \frac{n}{2} = \frac{1}{2}s(f'_2)^2. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++bs%28f%27_2%29+%3D+%5Cfrac%7Bn%7D%7B2%7D+%3D+%5Cfrac%7B1%7D%7B2%7Ds%28f%27_2%29%5E2.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  bs(f'_2) = \frac{n}{2} = \frac{1}{2}s(f'_2)^2. "/></p>
<p>Andris Ambainis and Xiaoming Sun <a href="https://arxiv.org/abs/1108.3494">improved</a> the constant from <img alt="{\frac{1}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{1}{2}}"/> asymptotically to <img alt="{\frac{2}{3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B2%7D%7B3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{2}{3}}"/>, but their relation is still quadratic.</p>
<p>
</p><p/><h2> Some Boolean Complexity Connections </h2><p/>
<p/><p>
This <a href="https://link.springer.com/article/10.1007/BF01200762">example</a> of quadratic discrepancy is still the best known lower bound on <img alt="{bs(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bbs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{bs(f)}"/> in terms of <img alt="{s(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s(f)}"/>. But no one had proved anything better than an exponential upper bound until Huang’s result, from which it follows that:</p>
<blockquote><p><b>Theorem 3</b> <em><a name="Huang"/> For all Boolean functions <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f}"/>, <img alt="{bs(f) \leq 2s(f)^4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bbs%28f%29+%5Cleq+2s%28f%29%5E4%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{bs(f) \leq 2s(f)^4}"/>. </em>
</p></blockquote>
<p/><p>
This bound is concrete, not just asymptotic. It still leaves a gap between quadratic and quartic. It is, however, the combination of two quadratic upper bounds. One was shown by Nisan and Szegedy in their <a href="https://www.researchgate.net/publication/2508255_On_the_Degree_of_Boolean_Functions_as_Real_Polynomials">paper</a>: </p>
<p align="center"><img alt="\displaystyle  bs(f) \leq 2\deg(f)^2, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++bs%28f%29+%5Cleq+2%5Cdeg%28f%29%5E2%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  bs(f) \leq 2\deg(f)^2, "/></p>
<p>where <img alt="{\deg(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdeg%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\deg(f)}"/> means the degree of the unique multi-linear real polynomial that agrees with <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> on the cube <img alt="{\{-1,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B-1%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{-1,1\}^n}"/> with <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> for <em>true</em>. The other is the conjecture </p>
<p align="center"><img alt="\displaystyle  \deg(f) \leq s(f)^2 " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cdeg%28f%29+%5Cleq+s%28f%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \deg(f) \leq s(f)^2 "/></p>
<p>in a 1992 <a href="https://www.sciencedirect.com/science/article/pii/0097316592900608">paper</a> by Craig Gotsman and Nati Linial. Huang proved this by exploiting a connection to graphs that was also shown by Gotsman and Linial. Consider any red-or-white coloring of the <img alt="{2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^n}"/> nodes of the hypercube, let <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> be the graph induced by the red nodes, and define <img alt="{g(x) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x) = 1}"/> if node <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> is red, <img alt="{g(x) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%28x%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g(x) = 0}"/> otherwise. Now if the maximum degree <img alt="{d(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(G)}"/> of a node in <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is small then every red node has many white neighbors, so the Boolean function <img alt="{g}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g}"/> is very sensitive. However, going to each neighbor in the hypercube flips the parity. Hence the function </p>
<p align="center"><img alt="\displaystyle  g'(x) = g(x) \oplus f_{\oplus}(x) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++g%27%28x%29+%3D+g%28x%29+%5Coplus+f_%7B%5Coplus%7D%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  g'(x) = g(x) \oplus f_{\oplus}(x) "/></p>
<p>is <b>not</b> very sensitive. Moreover, it has the same sensitivity as the function <img alt="{h'(x) = h(x) \oplus f_{\oplus}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%27%28x%29+%3D+h%28x%29+%5Coplus+f_%7B%5Coplus%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h'(x) = h(x) \oplus f_{\oplus}(x)}"/> where <img alt="{h(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h(x)}"/> is true on the white nodes. This nice duality between <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> and the graph <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H}"/> induced by the white nodes enables us to fix “<img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>” to mean whichever of the two has more nodes in the following theorem statement: </p>
<blockquote><p><b>Theorem 4</b> <em> Provided <img alt="{m &gt; 2^{n-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3E+2%5E%7Bn-1%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{m &gt; 2^{n-1}}"/>, every graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> induced by <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{m}"/> nodes of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>-cube has <img alt="{d(G) \geq \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29+%5Cgeq+%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{d(G) \geq \sqrt{n}}"/> if and only if every Boolean function <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f}"/> has <img alt="{\deg(f) \leq s(f)^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdeg%28f%29+%5Cleq+s%28f%29%5E2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\deg(f) \leq s(f)^2}"/>. </em>
</p></blockquote>
<p/><p>
The proof uses some Fourier analysis with <img alt="{f = g'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%3D+g%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f = g'}"/> as above. It, too, takes only one page of a really short paper. </p>
<p>
The main open question now is whether the 4th-power upper bound in Huang’s theorem <a href="https://rjlipton.wordpress.com/feed/#Huang">3</a> can be improved to quadratic. It is possible that a deeper application of Fourier analysis may show that cases of quadratic separation from <em>block-sensitivity</em> to <em>degree</em> and <em>degree</em> to <em>sensitivity</em> cannot “amplify” any more than quadratic. This is where there might be some commonality with discrepancy. </p>
<p>
There is a much wider suite of Boolean complexity measures besides <img alt="{s(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s(f)}"/>, <img alt="{bs(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bbs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{bs(f)}"/>, and <img alt="{\deg(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdeg%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\deg(f)}"/> discussed here. For example, consider how many bits of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> you need to fix in order to preserve the value <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/>. That is, define <img alt="{C(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(f)}"/> to be the maximum over <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> of the minimum size of a set <img alt="{I \subseteq [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI+%5Csubseteq+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{I \subseteq [n]}"/> such that whenever <img alt="{x'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x'}"/> agrees with <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> on <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{I}"/>, <img alt="{f(x') = f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%27%29+%3D+f%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x') = f(x)}"/>. Clearly <img alt="{I}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{I}"/> needs to include at least one bit from each <img alt="{B_j.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB_j.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B_j.}"/> This proves <img alt="{C(f) \geq bs(f)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28f%29+%5Cgeq+bs%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(f) \geq bs(f)}"/>. There are many other relations that might be improved. We end by considering ways of broadening Huang’s techniques.</p>
<p>
</p><p/><h2> Weak Adjacency Matrices </h2><p/>
<p/><p>
We—that is Ken and I—have been thinking about how to build on Huang’s proof. We take a somewhat more-general approach compared to the paper and Ken’s <a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/">post</a>.</p>
<blockquote><p><b>Definition 5</b> <em> Let <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> be a graph on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> vertices. The <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> by <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> matrix <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> is a <b>weak adjacency</b> matrix of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> provided </em></p><em>
<ol>
<li>
Every entry <img alt="{A_{x,y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bx%2Cy%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A_{x,y}}"/> is bounded by <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{1}"/> in absolute value; <p/>
</li><li>
For all <img alt="{x,y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x,y}"/> if <img alt="{x \rightarrow y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Crightarrow+y%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x \rightarrow y}"/> is not an edge in <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/>, then <img alt="{A_{x,y}=0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bx%2Cy%7D%3D0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A_{x,y}=0}"/>.
</li></ol>
</em><p><em/>
</p></blockquote>
<p/><p>
As usual the maximum degree of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is denoted by <img alt="{\deg(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdeg%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\deg(G)}"/>. The following is almost the same proof as the classic result on adjacency matrices. </p>
<blockquote><p><b>Lemma 6 (H-Lemma)</b> <em> Suppose that <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> is a weak adjacency matrix of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/>. Then if <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\lambda}"/> is an eigenvalue of <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/>, 	</em></p><em>
<p align="center"><img alt="\displaystyle  | \lambda | \le \deg(G). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C+%5Clambda+%7C+%5Cle+%5Cdeg%28G%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  | \lambda | \le \deg(G). "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
<em>Proof:</em>  By the definition of eigenvalue, there is some non-zero vector <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> so that <img alt="{Av = \lambda v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAv+%3D+%5Clambda+v%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Av = \lambda v}"/>. Let <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> be an index so that <img alt="{|v_{k}|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_%7Bk%7D%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_{k}|}"/> maximum. Then 	</p>
<p align="center"><img alt="\displaystyle  |\lambda v_{k}| =|(A v)_{k}|= \left|\sum_{y=1}^{n} A_{k,y}v_{y} \right| \leq \sum_{y=1}^{n} |A_{k,y}| \cdot |v_{k}|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5Clambda+v_%7Bk%7D%7C+%3D%7C%28A+v%29_%7Bk%7D%7C%3D+%5Cleft%7C%5Csum_%7By%3D1%7D%5E%7Bn%7D+A_%7Bk%2Cy%7Dv_%7By%7D+%5Cright%7C+%5Cleq+%5Csum_%7By%3D1%7D%5E%7Bn%7D+%7CA_%7Bk%2Cy%7D%7C+%5Ccdot+%7Cv_%7Bk%7D%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |\lambda v_{k}| =|(A v)_{k}|= \left|\sum_{y=1}^{n} A_{k,y}v_{y} \right| \leq \sum_{y=1}^{n} |A_{k,y}| \cdot |v_{k}|. "/></p>
<p>But then the last sum is upper bounded by 	</p>
<p align="center"><img alt="\displaystyle  D|v_{k}|, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%7Cv_%7Bk%7D%7C%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  D|v_{k}|, "/></p>
<p>where <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is the number of <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/> so that <img alt="{A_{k,y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bk%2Cy%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{k,y}}"/> is not zero. This uses property (1) of the definition of a weak adjacency matrix. Property (2) implies that <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is at most the degree of vertex <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> is <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>. Thus 	</p>
<p align="center"><img alt="\displaystyle  |\lambda v_{k}| \leq D |v_{k}| \leq \deg(G) |v_{k}|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5Clambda+v_%7Bk%7D%7C+%5Cleq+D+%7Cv_%7Bk%7D%7C+%5Cleq+%5Cdeg%28G%29+%7Cv_%7Bk%7D%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |\lambda v_{k}| \leq D |v_{k}| \leq \deg(G) |v_{k}|. "/></p>
<p>Dividing by <img alt="{|v_{k}|&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_%7Bk%7D%7C%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_{k}|&gt;0}"/> yields the lemma. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p>
Let <img alt="{G-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G-k}"/> be the graph that results after we delete the vertex <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> from <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>. Let <img alt="{A-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A-k}"/> be the matrix that results after we delete the column and row <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> from <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/>. </p>
<blockquote><p><b>Lemma 7</b> <em> Suppose that <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> is a weak adjacency matrix of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/>. Then for any vertex <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{k}"/>, <img alt="{A-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA-k%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A-k}"/> is a weak adjacency matrix of <img alt="{G-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG-k%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G-k}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  The bound on the entries of <img alt="{A-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A-k}"/> is immediate. Whenever <img alt="{G-k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG-k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G-k}"/> has no edge from <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> to <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/>, then <img alt="{(A-k)_{x,y}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28A-k%29_%7Bx%2Cy%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(A-k)_{x,y}}"/> must be zero. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<blockquote><p><b>Lemma 8</b> <em> Suppose that <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> a <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>-graph has a real symmetric weak adjacency matrix <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> with <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{m}"/> of the top eigenvalues greater than <img alt="{B \ge 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB+%5Cge+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B \ge 0}"/>. Then every induced subgraph <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{H}"/> of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{G}"/> with at least <img alt="{n-m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-m%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n-m}"/> vertices has degree at least <img alt="{B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{B}"/>. </em>
</p></blockquote>
<p>
</p><blockquote><p><b>Definition 9</b> <em> The <b>hypercube</b> <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C_{n}}"/> is the graph on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> bit vectors so that two vertices are adjacent if they differ in one bit position. </em>
</p></blockquote>
<p>
</p><blockquote><p><b>Theorem 10</b> <em> The hypercube <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C_{n}}"/> has a real symmetric weak adjacency matrix with all its eigenvalues <img alt="{\pm \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\pm \sqrt{n}}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Let <img alt="{A_{1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{1}}"/> be 	</p>
<p align="center"><img alt="\displaystyle  \begin{bmatrix}   0 &amp; 1 \\   1 &amp; 0  \end{bmatrix}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Bbmatrix%7D+%09%090+%26+1+%5C%5C+%09%091+%26+0+%09%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{bmatrix}   0 &amp; 1 \\   1 &amp; 0  \end{bmatrix}. "/></p>
<p>and <img alt="{A_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}}"/> be 	</p>
<p align="center"><img alt="\displaystyle  \begin{bmatrix}   A_{n-1} &amp; I \\   I &amp; -A_{n-1}  \end{bmatrix}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Bbmatrix%7D+%09%09A_%7Bn-1%7D+%26+I+%5C%5C+%09%09I+%26+-A_%7Bn-1%7D+%09%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{bmatrix}   A_{n-1} &amp; I \\   I &amp; -A_{n-1}  \end{bmatrix}. "/></p>
<p>
Induction shows that <img alt="{A_{n}^{2} = nI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%5E%7B2%7D+%3D+nI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}^{2} = nI}"/>. It follows that 	</p>
<p align="center"><img alt="\displaystyle  A_{n}x = \lambda x, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A_%7Bn%7Dx+%3D+%5Clambda+x%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  A_{n}x = \lambda x, "/></p>
<p>implies that 	</p>
<p align="center"><img alt="\displaystyle  nx = \lambda Ax. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++nx+%3D+%5Clambda+Ax.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  nx = \lambda Ax. "/></p>
<p>Thus 	</p>
<p align="center"><img alt="\displaystyle  nx = \lambda^{2}x. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++nx+%3D+%5Clambda%5E%7B2%7Dx.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  nx = \lambda^{2}x. "/></p>
<p>So the eigenvalues are <img alt="{\pm \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\pm \sqrt{n}}"/> and by trace same number of each.</p>
<p>
The upper-left and lower-right blocks of <img alt="{A_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}}"/> correspond to the two <img alt="{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n-1}"/> dimensional subcubes of <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{n}}"/>, and the two identity blocks correspond to the perfect matching connecting these two subcubes. So <img alt="{A_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{n}}"/> is a weak adjacency matrix for <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_{n}}"/>. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<blockquote><p><b>Corollary 11</b> <em> Every induced subgraph <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{H}"/> of <img alt="{C_{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C_{n}}"/> with at least <img alt="{2^{n-1}+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn-1%7D%2B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{2^{n-1}+1}"/> vertices has degree at least <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. </em>
</p></blockquote>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Can the last two talks at the conference be further connected?</p>
<p/></font></font></div>
    </content>
    <updated>2019-07-25T20:35:29Z</updated>
    <published>2019-07-25T20:35:29Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="algoritrhms"/>
    <category term="Boolean functions"/>
    <category term="Boolean sensitivity conjecture"/>
    <category term="discrepancy"/>
    <category term="Hao Huang"/>
    <category term="hypercube"/>
    <category term="Joel Spencer"/>
    <category term="Nihkil Bhansal"/>
    <category term="randomized algorithms"/>
    <category term="randomness"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-07-28T23:39:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17669</id>
    <link href="https://gilkalai.wordpress.com/2019/07/25/tyi-39-can-a-coalition-of-children-guarantees-being-in-the-same-class/" rel="alternate" type="text/html"/>
    <title>TYI 39 : Can a coalition of children guarantees all being in the same class?</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">There is a class of children that have just finished elementary school. Now they all move from elementary school to high school and classes are reshuffled. Each child lists three friends, and the assignment of children into classes ensures that … <a href="https://gilkalai.wordpress.com/2019/07/25/tyi-39-can-a-coalition-of-children-guarantees-being-in-the-same-class/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a href="https://gilkalai.files.wordpress.com/2019/07/class_school.jpg"><img alt="" class="alignnone size-medium wp-image-17676" height="213" src="https://gilkalai.files.wordpress.com/2019/07/class_school.jpg?w=300&amp;h=213" width="300"/></a></p>
<p>There is a class of children that have just finished elementary school. Now they all move from elementary school to high school and classes are reshuffled. Each child lists three friends, and the assignment of children into classes ensures that each child will have at least one of these three friends in his class.</p>
<p>One of the children heard from five of his schoolmates that they found that they can make their selections in a way that will ensure that all five will be assigned to the same class!</p>
<h3><span style="color: #993366;">Test your intuition: Is there a strategy for five of the children that will ensure that all five will be assigned to the same class?</span></h3>
<p>Can a larger group of children coordinate their choices to ensure that they will all necessarily be assigned to the same class?</p>
<a name="pd_a_10371327"/><div class="CSS_Poll PDS_Poll" id="PDI_container10371327" style="display: inline-block;"/><div id="PD_superContainer"/><noscript>&lt;a href="https://polldaddy.com/p/10371327" target="_blank"&gt;Take Our Poll&lt;/a&gt;</noscript>
<p><span id="more-17669"/></p>
<p><strong>Bonus question:</strong> In case that every child lists only two friends and one of them is guaranteed to be in the same class. Is there a strategy of five children that will ensure they are in the same class?</p>
<p><strong>Answer to Bonus question</strong>: Yes. For three children you let every one choose the other two. For the remaining children you let each one choose two among the three.</p></div>
    </content>
    <updated>2019-07-25T12:59:05Z</updated>
    <published>2019-07-25T12:59:05Z</published>
    <category term="Combinatorics"/>
    <category term="Economics"/>
    <category term="Mathematics to the rescue"/>
    <category term="Test your intuition"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-28T23:39:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/097</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/097" rel="alternate" type="text/html"/>
    <title>TR19-097 |  Reversible Pebble Games and the Relation Between Tree-Like and General Resolution Space | 

	Florian Wörz, 

	Jacobo Toran</title>
    <summary>We show a new connection between the space measure in tree-like resolution and the reversible pebble game in graphs. Using this connection we provide several formula classes for which there is a logarithmic factor separation between the space complexity measure in tree-like and general resolution. We show that these separations are almost optimal by proving upper bounds for tree-like resolution space in terms of general resolution clause and variable space. In particular we show that for any formula F, its tree-like resolution is upper bounded by space(?)log time(?) where ? is any general resolution refutation of F. This holds considering as space(?) the clause space of the refutation as well as considering its variable space. For the concrete case of Tseitin formulas we are able to improve this bound to the optimal bound space(?)log(n), where n is the number of vertices of the corresponding graph.</summary>
    <updated>2019-07-24T12:09:27Z</updated>
    <published>2019-07-24T12:09:27Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-28T23:38:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/096</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/096" rel="alternate" type="text/html"/>
    <title>TR19-096 |  On the $\text{AC}^0[\oplus]$ complexity of Andreev&amp;#39;s Problem | 

	Aditya Potukuchi</title>
    <summary>Andreev's Problem asks the following: Given an integer $d$ and a subset of $S \subseteq \mathbb{F}_q \times \mathbb{F}_q$, is there a polynomial $y = p(x)$ of degree at most $d$ such that  for every $a \in \mathbb{F}_q$, $(a,p(a)) \in S$? We show an $\text{AC}^0[\oplus]$ lower bound for this problem. 

This problem appears to be similar to the list recovery problem for degree $d$-Reed-Solomon codes over $\mathbb{F}_q$ which asks the following: Given subsets $A_1,\ldots,A_q$ of $\mathbb{F}_q$, output all (if any) Reed-Solomon codewords contained in $A_1\times \cdots \times A_q$. For our purpose, we study this problem when $A_1, \ldots, A_q$ are random subsets of a given size, which may be of independent interest.</summary>
    <updated>2019-07-23T17:29:25Z</updated>
    <published>2019-07-23T17:29:25Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-28T23:38:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17642</id>
    <link href="https://gilkalai.wordpress.com/2019/07/23/matan-harel-frank-mousset-and-wojciech-samotij-and-the-the-infamous-upper-tail-problem/" rel="alternate" type="text/html"/>
    <title>Matan Harel, Frank Mousset, and Wojciech Samotij and the “the infamous upper tail” problem</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Let me report today on a major breakthrough in random graph theory and probabilistic combinatorics. Congratulations to Matan, Frank, and Vojtek! Artist: Heidi Buck. “Catch a Dragon by the Tail 2” ( source ) Upper tails via high moments and entropic … <a href="https://gilkalai.wordpress.com/2019/07/23/matan-harel-frank-mousset-and-wojciech-samotij-and-the-the-infamous-upper-tail-problem/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Let me report today on a major breakthrough in random graph theory and probabilistic combinatorics. Congratulations to Matan, Frank, and Vojtek!</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/dragon_tail_2_web.png"><img alt="" class="alignnone size-full wp-image-17644" height="496" src="https://gilkalai.files.wordpress.com/2019/07/dragon_tail_2_web.png?w=640&amp;h=496" width="640"/></a></p>
<p>Artist: Heidi Buck.<strong><span style="color: #ff0000;"> “Catch a Dragon by the Tail 2”</span></strong> ( <a href="https://www.hbdragon.com/main/content/catch-dragon-tail-2">source</a> )</p>
<p class="title mathjax"><a href="https://arxiv.org/abs/1904.08212">Upper tails via high moments and entropic stability</a> by Matan Harel, Frank Mousset, and Wojciech Samotij</p>
<p><strong>Abstract:</strong></p>
<p>Suppose that <em>X</em> is a bounded-degree polynomial with nonnegative coefficients on the <em>p</em>-biased discrete hypercube. Our main result gives sharp estimates on the logarithmic upper tail probability of X whenever an associated extremal problem satisfies a certain entropic stability property. We apply this result to solve two long-standing open problems in probabilistic combinatorics: the upper tail problem for the number of arithmetic progressions of a fixed length in the <em>p</em>-random subset of the integers and the upper tail problem for the number of cliques of a fixed size in the random graph <img alt="G_{n,p}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7Bn%2Cp%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_{n,p}"/>. We also make significant progress on the upper tail problem for the number of copies of a fixed regular graph <em>H</em> in <img alt="G_{n,p}." class="latex" src="https://s0.wp.com/latex.php?latex=G_%7Bn%2Cp%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_{n,p}."/> To accommodate readers who are interested in learning the basic method, we include a short, self-contained solution to the upper tail problem for the number of triangles in <img alt="G_{n,p}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7Bn%2Cp%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G_{n,p}"/> for all <em>p=p(n)</em> satisfying <img alt="\frac {\log n}{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cfrac+%7B%5Clog+n%7D%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\frac {\log n}{n}"/> <img alt="\ll" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cll&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ll"/> <img alt="p \ll 1" class="latex" src="https://s0.wp.com/latex.php?latex=p+%5Cll+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="p \ll 1"/>.</p>
<p>The introduction does a very nice job of presenting the rich history of the problem.  Here is a 2002 paper by Svante Janson and Andrzej Ruciński on <a href="https://onlinelibrary.wiley.com/doi/pdf/10.1002/rsa.10031?casa_token=7FoHUVq0w5IAAAAA:AqmK_4tpjDzXErWnGh4qnE2kn4NTupyoW27eSXW7Uwr5l0JgpBP5SG7PaVnJ6Lvr4JhCaSIH2HPv-QTsUg">the infamous upper tail</a>.  (And a lot has happened since then with regard to this problem and on non linear large deviation theory). Following, there is a lovely section with a short solution for the case of triangles.</p>
<p>Forthcoming reference [48] talks about lower tails! Stay tuned!</p></div>
    </content>
    <updated>2019-07-23T06:51:02Z</updated>
    <published>2019-07-23T06:51:02Z</published>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Frank Mousset"/>
    <category term="Matan Harel"/>
    <category term="Wojciech Samotij"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-28T23:39:02Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7828284719883166611</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7828284719883166611/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/answer-to-both-infinite-hats-problems.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7828284719883166611" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7828284719883166611" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/answer-to-both-infinite-hats-problems.html" rel="alternate" type="text/html"/>
    <title>Answer to both Infinite Hats Problems from the last post</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
(This is a joint post with David Marcus. You'll see why later.)<br/>
<br/>
In a prior  I posed two infinite hat problems. Today I post the solutions. Actually this is a copy of my last post with the solutions added, so it is self contained.<br/>
<br/>
A Hat Problem that you have probably seen:<br/>
<br/>
1) There are an infinite number of people, numbered 1,2,3,...  There are 2 colors of hats. They can all see everyone's hat but their own. <br/>
<br/>
2) The adversary is going to put hats on all the people. They will guess their own hat color<i> at the same time</i>. <br/>
<br/>
3) The people can discuss strategy ahead of time, but must use a deterministic strategy and the adversary knows the strategy.<br/>
<br/>
4) The people want to minimize how many they get wrong. <br/>
<br/>
5) The adversary puts on hats to maximize how many they get wrong.<br/>
<br/>
I ask two questions (the answers are in a document I point to) and one meta-question:<br/>
<br/>
Q1: Is there a solution where they get all but a finite number of the guesses right? (If you have read my prior post on hat puzzles, <a href="https://blog.computationalcomplexity.org/2017/07/two-hat-problems-you-may-or-may-not.html">here</a> then you can do this one.) <br/>
<br/>
Q2: Is there a solution where they get all but at most (say) 18 wrong.<br/>
<br/>
<br/>
Answers to Q1 and Q2 are <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/infinitehats.pdf">here</a>.<br/>
<br/>
How did I get into this problem? I was looking at hat problems a while back. Then  I began discussing Q1 and Q2 by email  (Does the term <i>discussing</i> have as a default that it is by email?) with David Marcus who had just read the chapter of <a href="https://www.amazon.com/Problems-Point-Exploring-Computer-Science/dp/9813279974">Problems with a Point</a> on hat puzzles. After a few emails back and fourth, he began looking on the web for answers. He found one. There is a website of hat puzzles! It was MY website papers on  Hat Puzzles! It is  <a href="https://www.cs.umd.edu/users/gasarch/TOPICS/hats/hats.html">here</a>. And on it was a relevant paper <a href="https://www.cs.umd.edu/users/gasarch/TOPICS/hats/infinite-hats-and-ac.pdf">here</a>. We did not find any other source of the problem or its solution. <br/>
<br/>
Q3: How well known is problem Q2 and the solution?  I've seen Q1 around but the only source on Q2 that I know of is that paper, and now this blog post. So, please leave a comment telling me if you have seen Q2 and/or the solution someplace else, and if so where.<br/>
<br/>
The responses to my last post indicated that YES the problem was out there, but the proof that you could not get all-but-18 was not well known. <br/>
<br/>
I THINK that all of the proofs that you can't do all-but-18 in the comment of the last post were essentially the same as the solution I pointed to in this blog. I would be interested if there is an alternative proof. <br/></div>
    </content>
    <updated>2019-07-22T03:00:00Z</updated>
    <published>2019-07-22T03:00:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-28T12:43:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/095</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/095" rel="alternate" type="text/html"/>
    <title>TR19-095 |  Unambiguous Catalytic Computation | 

	Chetan Gupta, 

	Rahul Jain, 

	Vimal Raj Sharma, 

	Raghunath Tewari</title>
    <summary>The catalytic Turing machine is a model of computation defined by Buhrman, Cleve,
Kouck, Loff, and Speelman (STOC 2014). Compared to the classical space-bounded Turing
machine, this model has an extra space which is filled with arbitrary content in addition
to the clean space. In such a model we study if this additional filled space can be used to
increase the power of computation or not, with the condition that the initial content of this
extra filled space must be restored at the end of the computation.
In this paper, we define the notion of unambiguous catalytic Turing machine and prove
that under a standard derandomization assumption, the class of problems solved by an
unambiguous catalytic Turing machine is same as the class of problems solved by a general
nondeterministic catalytic Turing machine in the logspace setting.</summary>
    <updated>2019-07-21T11:21:02Z</updated>
    <published>2019-07-21T11:21:02Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-28T23:38:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17574</id>
    <link href="https://gilkalai.wordpress.com/2019/07/20/isabella-novik-and-hailun-zheng-neighborly-centrally-symmetric-spheres-exist-in-all-dimensions/" rel="alternate" type="text/html"/>
    <title>Isabella Novik and Hailun Zheng: Neighborly centrally symmetric spheres exist in all dimensions!</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">A tweet-long summary: The cyclic polytope is wonderful and whenever we construct an analogous object we are happy. Examples: Neighborly cubic polytopes; The amplituhedron; and as of last week, the Novik-Zheng new construction of neighborly centrally symmetric spheres! At last: … <a href="https://gilkalai.wordpress.com/2019/07/20/isabella-novik-and-hailun-zheng-neighborly-centrally-symmetric-spheres-exist-in-all-dimensions/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><span style="color: #0000ff;">A tweet-long summary: The cyclic polytope is wonderful and whenever we construct an analogous object we are happy. Examples: Neighborly cubic polytopes; The amplituhedron; and as of last week, the Novik-Zheng new construction of neighborly centrally symmetric spheres!</span></p>
<h2>At last: Neighborly CS spheres!</h2>
<p>The news: Isabella Novik and Hailun Zheng’ paper  <a href="https://arxiv.org/abs/1907.06115">Highly neighborly centrally symmetric spheres</a>, resolves an old standing problem in this field.</p>
<p>Here is the abstract:</p>
<blockquote><p>In 1995, Jockusch constructed an infinite family of centrally symmetric 3-dimensional simplicial spheres that are cs-<em>2</em>-neighborly. Here we generalize his construction and show that for all d ≥ 4 and n ≥ d, there exists a centrally symmetric (d − 1)-dimensional simplicial sphere with <em>2n</em> vertices that is cs-[d/2]-neighborly. This result combined with work of Adin and Stanley completely resolves the upper bound problem for centrally symmetric simplicial spheres.</p></blockquote>
<p>Congratulations to Isabella and Hailun!</p>
<h2>Some background to the Novik and Zheng breakthrough</h2>
<p><strong>Centrally symmetric bodies:</strong> A centrally symmetric (cs) polytope convex body in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/> satisfies <img alt="x \in P" class="latex" src="https://s0.wp.com/latex.php?latex=x+%5Cin+P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x \in P"/> implies <img alt="-x \in P" class="latex" src="https://s0.wp.com/latex.php?latex=-x+%5Cin+P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="-x \in P"/>. Centrally symmetric bodies are the unit balls of normed spaces.</p>
<p><strong>Centrally symmetric simplicial spheres:</strong> A triangulation <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> of a  <img alt="(d-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(d-1)"/>-dimensional sphere with a set <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> of vertices is centrally symmetric if there is an involution <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi"/> on <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> that <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi"/> maps a face of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> to a face of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> and for every vertex <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/>, <img alt="\phi(v) \ne v" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28v%29+%5Cne+v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi(v) \ne v"/> and <img alt="\{v , \phi (v)\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Bv+%2C+%5Cphi+%28v%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{v , \phi (v)\}"/> is not an edge of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/>.  The boundary complex of a cs <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-polytopes is a cs triangulation of <img alt="S^{d-1}" class="latex" src="https://s0.wp.com/latex.php?latex=S%5E%7Bd-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S^{d-1}"/>.</p>
<p><strong>Neighborliness.</strong> A simplicial complex <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/>  is <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>-neighborly of every set of <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> vertices of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> form a face.  (The definition was first considered  for simplicial <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-polytopes <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>.) The cyclic <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-polytope with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> vertices is <img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>-neighborly. (The only (<img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>+1)-neighborly simplicial <img alt="(d-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(d-1)"/>-sphere is the simplex. There are many other <img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>-neighborly simplicial <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>-polytopes and <img alt="(d-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(d-1)"/>-spheres.</p>
<p><strong>cs-Neighborliness. </strong>Let <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> be a simplicial complex with an involution <img alt="\phi" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi"/> on its vertices which acts on <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> (maps faces to faces) and has the property that <img alt="\phi(v)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi%28v%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi(v)"/> is not adjacent to <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> (and <img alt="\phi (v) \ne v" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi+%28v%29+%5Cne+v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi (v) \ne v"/>). We will call <img alt="v" class="latex" src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v"/> and <img alt="\phi (v)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cphi+%28v%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\phi (v)"/> <strong>antipodal</strong>. <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/> is cs-<img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>-neighborly if every set of <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/> vertices that contains no pair of antipodal vertices is a face of <img alt="K" class="latex" src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="K"/>. The only cs-<img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="m"/>-neighborly simplicial sphere is the boundary complex of the cross polytope.</p>
<p><strong>The existence of cs-<img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>-neighborly spheres. </strong>It was an important open question whether  cs <img alt="[d/2]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[d/2]"/>-neighborly simplicial spheres exist. (The only cs-<img alt="([d/2]+1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Bd%2F2%5D%2B1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="([d/2]+1)"/>-neighborly spheres is the boundary complex of the cross polytope.)  The first example (which is not a cross polytope) was given by Grünbaum in 1969 in his paper “The importance of being straight(?).” In 1995  Jockusch constructed an infinite family cs-2-neighborly centrally symmetric 3-dimensional simplicial spheres. This problem has now been solved by Novik and Zheng.</p>
<p><strong>Neighborly centrally symmetric polytopes.  </strong>In the 1960s Grünbaum noted the big difference between neighborly centrally symmetric spheres and centrally symmetric polytopes. He proved (This is Theorem 4.1 in his book “Convex polytopes”) that no cs-2-neighborly 4 polytope with 12 vertices exists.  This is an example of the important themes of “straightening” or “linearizing” combimatorial objects and  of extending theorems from the “straight” or “linear” case to more general combinatorial settings.)</p>
<p>This result by Grünbaum was extended in various directions. Let me mention two major results in the field:</p>
<p><strong>Theorem</strong> McMullen and Shephard (1968): A cs <em>d</em>-dimensional polytope with <em>2(d + 2)</em> vertices cannot be more than cs-<em>⌊(d + 1)/3⌋</em>-neighborly.</p>
<p><strong>Theorem</strong> <a href="https://arxiv.org/abs/math/0507280">Linial and Novik (2006):</a> A cs-2-neighborly <em>d</em>-dimensional polytope has at most  <img alt="2^d" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^d"/>;</p>
<p>Novik (2017) <a href="https://arxiv.org/abs/1712.09489">constructed</a>  cs-2-neighborly d polytopes with <img alt="2^{d-1}+1" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bd-1%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{d-1}+1"/> vertices. She used a 2017 <a href="https://arxiv.org/abs/1709.03411">breakthrough construction</a> by Gerencsér–Harang of an acute set of size <img alt="2^{d-1}+1" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bd-1%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{d-1}+1"/> in <img alt="\mathbb R^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R^d"/>. (A set <em>S</em> is <em>acute</em> if every three points from <em>S </em>determine an acute triangle.)</p>
<p><strong>Face numbers of centrally-symmetric polytopes and spheres. </strong>As the abstract asserts the new construction is related to questions about face numbers of centrally symmetric polytopes, spheres and other cellular objects. In fact, this was the next item in our planned posts on algebraic combinatorics of cellular objects. (The first and only post so far<a href="https://gilkalai.wordpress.com/2018/06/20/beyond-the-g-conjecture-algebraic-combinatorics-of-cellular-spaces-i/"> is here</a>.) Here is a recent survey by Isabella Novik  <a href="https://arxiv.org/abs/1711.09310">A tale on centrally symmetric  polytopes and spheres</a>.</p>
<p><strong>Upper bound theorems.</strong> Neighborly polytopes and spheres are the equality cases of the upper bound theorem (proved by McMullen for polytopes and by Stanley for spheres). A version of the upper bound inequality for centrally symmetric spheres was proved by Adin and Stanley and the new construction shows that the Adin-Stanley inequality is tight. For more on the upper bound theorem and neighborliness see Section 2 of my 2000 survey  <a href="http://www.ma.huji.ac.il/~kalai/VIS.pdf">Combinatorics with geometric flavor. </a> See also the post <a href="https://gilkalai.wordpress.com/2009/04/04/how-the-g-conjecture-came-about/">How the g-conjecture came about</a> and  the post <a href="https://gilkalai.wordpress.com/2013/09/10/how-the-proof-of-the-upper-bound-theorem-for-spheres-was-found/" rel="bookmark">Richard Stanley: How the Proof of the Upper Bound Theorem (for spheres) was Found.</a></p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-07-20T18:33:03Z</updated>
    <published>2019-07-20T18:33:03Z</published>
    <category term="Combinatorics"/>
    <category term="Convexity"/>
    <category term="Hailun Zheng"/>
    <category term="Isabella Novik"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-28T23:39:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4267</id>
    <link href="https://www.scottaaronson.com/blog/?p=4267" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4267#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4267" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Fake it till you make it (to the moon)</title>
    <summary xml:lang="en-US">While I wait to board a flight at my favorite location on earth—Philadelphia International Airport—I figured I might as well blog something to mark the 50th anniversary of Apollo 11. (Thanks also to Joshua Zelinsky for a Facebook post that inspired this.) I wasn’t alive for Apollo, but I’ve been alive for 3/4 of the […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>While I wait to board a flight at my favorite location on earth—Philadelphia International Airport—I figured I might as well blog something to mark the 50<sup>th</sup> anniversary of Apollo 11.  (Thanks also to Joshua Zelinsky for a Facebook post that inspired this.)</p>



<p>I wasn’t alive for Apollo, but I’ve been alive for 3/4 of the time <em>after</em> it, even though it now seems like ancient history—specifically, like a Roman cathedral being gawked at by a medieval peasant, like an achievement by some vanished, more cohesive civilization that we can’t even replicate today, let alone surpass.</p>



<p>Which brings me to a depressing mystery: why do so many people now deny that humans walked on the moon at all?  Like, why <em>that</em> specifically?  While they’re at it, why don’t they also deny that WWII happened, or that the Beatles existed?</p>



<p>Surprisingly, skepticism of the reality of Apollo seems to have gone all the way back to the landings themselves.  One of my favorite stories growing up was of my mom, as a teenager, working as a waitress at an Israeli restaurant in Philadelphia, on the night of Apollo 11 landing.  My mom asked for a few minutes off to listen to news of the landing on the radio.  The owners wouldn’t grant it—explaining that it was all Hollywood anyway, just some actors in spacesuits on a sound stage, and obviously my mom wasn’t so naïve as to think anyone was <em>actually</em> walking to the moon?</p>



<p>Alas, as we get further and further from the event, with no serious prospect of ever replicating it past the stage of announcing an optimistic timetable (nor, to be honest, any scientific <em>reason</em> to replicate it), as the people involved die off, and as our civilization becomes ever more awash in social-media-fueled paranoid conspiracies, I fear that moon-landing denalism will become more common.</p>



<p>Because here’s the thing: Apollo could happen, but <em>only</em> because of a wildly improbable, once-in-history confluence of social and geopolitical factors.  It was economically insane, taking 100,000 people and 4% of the US federal budget for some photo-ops, a flag-planting, some data and returned moon rocks that had genuine scientific value but could’ve been provided much more cheaply by robots.  It was dismantled immediately afterwards like a used movie set, rather than leading to any greater successes. Indeed, manned spaceflight severely <em>regressed</em> afterwards, surely mocking the expectations of every last science fiction fan and techno-utopian who was alive at that time.</p>



<p>One could summarize the situation by saying that, in certain respects, the Apollo program really <strong>was</strong> “faked.”  It’s just that the way they “faked” it, involved actually landing people on the moon!</p></div>
    </content>
    <updated>2019-07-19T21:40:43Z</updated>
    <published>2019-07-19T21:40:43Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Procrastination"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-19T23:00:05Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://blogs.princeton.edu/imabandit/?p=1397</id>
    <link href="https://blogs.princeton.edu/imabandit/2019/07/17/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-ii/" rel="alternate" type="text/html"/>
    <title>Guest post by Julien Mairal: A Kernel Point of View on Convolutional Neural Networks, part II</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This is a continuation of Julien Mairal‘s guest post on CNNs, see part I here. Stability to deformations of convolutional neural networks In their ICML paper Zhang et al. introduce a functional space for CNNs with one layer, by noticing … <a href="https://blogs.princeton.edu/imabandit/2019/07/17/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-ii/">Continue reading <span class="meta-nav">→</span></a></p></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="liimagelink" href="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/Mairal2.jpg?ssl=1"><img alt="" class="alignnone wp-image-1399" height="324" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/Mairal2.jpg?resize=639%2C324&amp;ssl=1" width="639"/></a></p>
<p>This is a continuation of <a class="liinternal" href="https://lear.inrialpes.fr/people/mairal/">Julien Mairal</a>‘s guest post on CNNs, see <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/">part I here.</a></p>
<p><strong>Stability to deformations of convolutional neural networks</strong></p>
<p>In their <a class="lipdf" href="http://proceedings.mlr.press/v70/zhang17f/zhang17f.pdf">ICML paper</a> Zhang et al. introduce a functional space for CNNs with one layer, by noticing that for some dot-product kernels, smoothed variants of rectified linear unit activation functions (ReLU) live in the corresponding RKHS, see also <a class="lipdf" href="http://proceedings.mlr.press/v48/zhangd16.pdf">this paper</a> and <a class="lipdf" href="https://www.cs.cornell.edu/~sridharan/sicomp.pdf">that one</a>. By following a similar reasoning with multiple layers, it is then possible to show that the functional space described in <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/">part I</a> <img alt="\{ f_w: x \mapsto \langle w , \Phi_n(x_0) \rangle; w \in L^2(\Omega,\mathcal{H}_n) \}" class="ql-img-inline-formula " height="20" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3e321e5f0406c9879f25b6b1d69a5fc3_l3.png?resize=298%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="298"/> contains CNNs with such smoothed ReLU, and that the norm <img alt="\|f_w\|" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-62e1a48032624994ba16c4e26421676e_l3.png?resize=34%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="34"/> of such networks can be controlled by the spectral norms of filter matrices. This is consistent with previous measures of complexity for CNNs, see <a class="lipdf" href="https://papers.nips.cc/paper/7204-spectrally-normalized-margin-bounds-for-neural-networks.pdf">this paper</a> by Bartlett et al.</p>
<p>A perhaps more interesting finding is that the abstract representation <img alt="\Phi_n(x)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ca9a5351b772e88bebe85e7e4a13632_l3.png?resize=45%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="45"/>, which only depends on the network architecture, may provide near-translation invariance and stability to small image deformations while preserving information—that is, <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> can be recovered from <img alt="\Phi_n(x)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ca9a5351b772e88bebe85e7e4a13632_l3.png?resize=45%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="45"/>. The original characterization we use was introduced by Mallat in <a class="lipdf" href="https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf">his paper</a> on the scattering transform—a multilayer architecture akin to CNNs based on wavelets, and was extended to <img alt="\Phi_n" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/> by Alberto Bietti, who should be credited for all the hard work here.</p>
<p>Our goal is to understand under which conditions it is possible to obtain a representation that (i) is near-translation invariant, (ii) is stable to deformations, (iii) preserves signal information. Given a <img alt="C^1" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-2e9ea203bbd77c5cd8bee967e2729d8b_l3.png?resize=20%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="20"/>-diffeomorphism <img alt="\tau: \mathbb{R}^2 \to \mathbb{R}^2" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c6f8f1dde2ee4682653c2a6b37d8a42d_l3.png?resize=93%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="93"/> and denoting by <img alt="L_\tau x(u) = x(u-\tau(u))" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-835d9f864f712213ee317332b3f3675a_l3.png?resize=167%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="167"/> its action operator (for an image defined on the continuous domain <img alt="\mathbb{R}^2" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d5abe0f29e8cc710ae26f4f0af5a0859_l3.png?resize=20%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="20"/>), the main stability bound we obtain is the following one, see Theorem 7 in <a class="lipdf" href="https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf">Mallat’s paper</a> if <img alt="\|\nabla \tau\|_\infty \leq 1/2" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-758b3cac273166048ed1879acf427860_l3.png?resize=104%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="104"/>, for all <img alt="x" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/>,</p>
<p class="ql-center-displayed-equation" style="line-height: 43px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \| \Phi_n(L_\tau x) - \Phi_n(x)\| \leq \left ( C_1 (1+n) \|\nabla \tau\|_\infty + \frac{C_2}{\sigma_n} \|\tau\|_\infty \right) \|x\|, \]" class="ql-img-displayed-equation " height="43" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-51041d0067a72066938e31b1f00529fa_l3.png?resize=455%2C43&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="455"/></p>
<p>where <img alt="C_1, C_2" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-08d1f29fa9c0981e916619b6c6bc7eee_l3.png?resize=48%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="48"/> are universal constants, <img alt="\sigma_n" class="ql-img-inline-formula " height="11" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c0142846a2999e170f7beec7be1523f2_l3.png?resize=18%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="18"/> is the scale parameter of the pooling operator <img alt="A_n" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e1872c7d7a65e0dc92f8a4a04608b88a_l3.png?resize=21%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/> corresponding to the “amount of pooling” performed up to the last layer, <img alt="\|\tau\|_\infty" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c1a5effb150d36de3c7074eaa980c357_l3.png?resize=39%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="39"/> is the maximum pixel displacement and <img alt="\|\nabla \tau\|_\infty" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ab4c5d3fe8fd25af25beb4f58a55c938_l3.png?resize=53%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="53"/> represents the maximum amount of deformation, see <a class="lipdf" href="https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf">the paper</a> for the precise definitions of all these quantities. Note that when <img alt="C_2/\sigma_n \to 0" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b732bf857c5f04c7d10dda247f1a5022_l3.png?resize=85%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="85"/>, the representation <img alt="\Phi_n" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/> becomes translation invariant: indeed, consider the particular case of <img alt="\tau" class="ql-img-inline-formula " height="8" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3af6c51247895b176bb502f0ee0857ee_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> being a translation, then <img alt="\nabla \tau=0" class="ql-img-inline-formula " height="14" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-aa1278a7149925a4f299de0dbb85cec0_l3.png?resize=57%2C14&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="57"/> and <img alt="\|\Phi_n(L_\tau x) - \Phi_n(x)\| \to 0" class="ql-img-inline-formula " height="19" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cd1d650abd9970e357384c0653960577_l3.png?resize=186%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="186"/>.</p>
<p>The stability bound and a few additional results tell us a few things about the network architecture: (a) small patches lead to more stable representations (the dependency is hidden in <img alt="C_1" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-782c65cbd411fb8862688afc92bc1eea_l3.png?resize=19%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="19"/>); (b) signal preservation for discrete signals requires small subsampling factors (and thus small pooling) between layers. In such a setting, the scale parameter <img alt="\sigma_n" class="ql-img-inline-formula " height="11" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c0142846a2999e170f7beec7be1523f2_l3.png?resize=18%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="18"/> still grows exponentially with <img alt="n" class="ql-img-inline-formula " height="8" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a63eb5ff0272d3119fa684be6e7acce8_l3.png?resize=11%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/> and near translation invariance may be achieved with several layers.</p>
<p>Interestingly, we may now come back to the Cauchy-Schwarz inequality from part 1, and note that if <img alt="\Phi_n" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="21"/> is stable, the RKHS norm <img alt="\|f\|" class="ql-img-inline-formula " height="19" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-afe70184469e7e3a14405a7193eedf29_l3.png?resize=24%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="24"/> is then a natural quantity that provides stability to deformations to the prediction function <img alt="f" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="10"/>, in addition to measuring model complexity in a traditional sense.</p>
<p><strong>Feature learning in RKHSs and convolutional kernel networks</strong></p>
<p>The previous paragraph is devoted to the characterization of convolutional architectures such as CNNs but the previous kernel construction can in fact be used to derive more traditional kernel methods. After all, why should one spend efforts defining a kernel between images if not to use it?</p>
<p>This can be achieved by considering finite-dimensional approximations of the previous feature maps. In order to shorten the presentation, we simply describe the main idea based on the Nystrom approximation and refer to <a class="lipdf" href="http://papers.nips.cc/paper/6184-end-to-end-kernel-learning-with-supervised-convolutional-kernel-networks.pdf">the paper</a> for more details. Approximating the infinite-dimensional feature maps <img alt="x_k" class="ql-img-inline-formula " height="11" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ad23c5c360c3f33031a5d000d37416f_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> (see the figure at the top of <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/">part I</a>) can be done by projecting each point in <img alt="\mathcal{H}_k" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc26f0de4084a72b9e625a080bd5d674_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/> onto a <img alt="p_k" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5c72bc331dc0008f57d454e7071dc39e_l3.png?resize=17%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/>-dimensional subspace <img alt="\mathcal{F}_k" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b08b176c0bf0adbd9cbe41b31147e1f7_l3.png?resize=20%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> leading to a finite-dimensional feature map <img alt="\tilde{x}_k" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5f55b75318f3b8da67917ee0b0e190ce_l3.png?resize=17%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> akin to CNNs, see the figure at the top of the post.</p>
<p>By parametrizing <img alt="\mathcal{F}_k=\text{span}(\varphi_k(z_1),\varphi_k(z_2),\ldots,\varphi_k(z_{p_k}))" class="ql-img-inline-formula " height="20" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5dd8802df8efddb9acc5056af47339d7_l3.png?resize=297%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="297"/> with <img alt="p_k" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5c72bc331dc0008f57d454e7071dc39e_l3.png?resize=17%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> anchor points <img alt="Z=[z_1,\ldots,z_{p_k}]" class="ql-img-inline-formula " height="19" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4614e1cdba47dc6a6db7957fb1d82632_l3.png?resize=123%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="123"/>, and using a dot-product kernel, a patch <img alt="z" class="ql-img-inline-formula " height="8" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d9d772a59543419785ce66946592259a_l3.png?resize=9%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/> from <img alt="\tilde{x}_{k-1}" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-6419748397a324cd2a2ebc3f119b7f80_l3.png?resize=35%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/> is encoded through the mapping function</p>
<p class="ql-center-displayed-equation" style="line-height: 43px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \psi_k(z) = \|z\| \kappa_k( Z^\top Z)^{-1/2} \kappa_k\left( Z^\top \frac{z}{\|z\|} \right), \]" class="ql-img-displayed-equation " height="43" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cc43da382f024d96cb50e3dc3f051d6f_l3.png?resize=306%2C43&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="306"/></p>
<p>where <img alt="\kappa_k" class="ql-img-inline-formula " height="11" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-684fcf23472c51919624049fb4e0129a_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> is applied pointwise. Then, computing <img alt="\tilde{x}_k" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5f55b75318f3b8da67917ee0b0e190ce_l3.png?resize=17%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="17"/> from <img alt="\tilde{x}_{k-1}" class="ql-img-inline-formula " height="16" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-6419748397a324cd2a2ebc3f119b7f80_l3.png?resize=35%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="35"/> admits a CNN interpretation, where only the normalization and the matrix multiplication by <img alt="\kappa_k( Z^\top Z)^{-1/2}" class="ql-img-inline-formula " height="21" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a74cffbbd51922298a13f864fbedaa98_l3.png?resize=103%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="103"/> are not standard operations. It remains now to choose the anchor points:</p>
<ul>
<li><strong>kernel approximation:</strong> a first approach consists of using a variant of the Nystrom method, see <a class="lipdf" href="https://papers.nips.cc/paper/1866-using-the-nystrom-method-to-speed-up-kernel-machines.pdf">this paper</a> and <a class="lipdf" href="http://home.cse.ust.hk/~twinsen/nystrom.pdf">that one</a>. When plugging the corresponding image representation in a linear classifier, the resulting approach behaves as a classical kernel machine. Empirically, we observe that the higher the number of anchor points, the better the kernel approximation, and the higher the accuracy. For instance, a two-layer network with a <img alt="300k" class="ql-img-inline-formula " height="13" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-81a4466abb5fecba81f8a3aa055a1a14_l3.png?resize=36%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="36"/>-dimensional representations achieves about <img alt="86\%" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0eea28372ada596bc618b4b94fee69ec_l3.png?resize=32%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="32"/> accuracy on CIFAR-10 without data augmentation (see <a class="liinternal" href="https://gitlab.inria.fr/mairal/ckn-cudnn-matlab">here</a>).</li>
<li><strong>back-propagation, feature selection</strong>: learning the anchor points <img alt="Z" class="ql-img-inline-formula " height="12" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cc9f8fff9fd24060bc054e78f01d5bfb_l3.png?resize=12%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="12"/> can also be done as in a traditional CNN, by optimizing them end-to-end. This allows using deeper lower-dimensional architectures and empirically seems to perform better when enough data is available, e.g., <img alt="92\%" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-659ab3cccda2422f955af880d20646cf_l3.png?resize=32%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="32"/> accuracy on CIFAR-10 with simple data augmentation. There, the subspaces <img alt="\mathcal{F}_k" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b08b176c0bf0adbd9cbe41b31147e1f7_l3.png?resize=20%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="20"/> are not learned anymore to provide the best kernel approximation, but the model seems to perform a sort of feature selection in each layer’s RKHS <img alt="\mathcal{H}_k" class="ql-img-inline-formula " height="15" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc26f0de4084a72b9e625a080bd5d674_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="22"/>, which is not well understood yet (This feature selection interpretation is due to my collaborator Laurent Jacob).</li>
</ul>
<p>Note that the first CKN model published <a class="lipdf" href="https://papers.nips.cc/paper/5348-convolutional-kernel-networks.pdf">here</a> was based on a different approximation principle, which was not compatible with end-to-end training. We found this to be less scalable and effective.</p>
<p><strong>Other links between neural networks and kernel methods</strong></p>
<p>Finally, other links between kernels and infinitely-wide neural networks with random weights are classical, but they were not the topic of this blog post (they should be the topic of another one!). In a nutshell, for a large collection of weights distributions and nonlinear functions <img alt="s: \mathbb{R} \to \mathbb{R}" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b4680e3f9e8274687d2d04f0a262ed00_l3.png?resize=76%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="76"/>, the following quantity admits an analytical form</p>
<p class="ql-center-displayed-equation" style="line-height: 22px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ K(x,x') = \E_{w}[ s(w^\top x) s(w^\top x')], \]" class="ql-img-displayed-equation " height="22" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9144f2d0b847adb69db90629ed805148_l3.png?resize=229%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="229"/></p>
<p>where the terms <img alt="s(w^\top x)" class="ql-img-inline-formula " height="19" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-da82e444bbc3a5e594b7edbf0b1ba3a0_l3.png?resize=56%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="56"/> may be seen as an infinitely-wide single-layer neural network. The first time such a relation appears is likely to be in <a class="liexternal" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.9306&amp;rep=rep1&amp;type=pdf">the PhD thesis</a> of Radford Neal with a Gaussian process interpretation, and it was revisited later by <a class="lipdf" href="http://proceedings.mlr.press/v2/leroux07a/leroux07a.pdf">Le Roux and Bengio</a> and by <a class="lipdf" href="http://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf">Cho and Saul</a> with multilayer models.</p>
<p>In particular, when <img alt="s" class="ql-img-inline-formula " height="8" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3bcfb3f0b6b04be3b598743cd774dd78_l3.png?resize=8%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="8"/> is the rectified linear unit and <img alt="w" class="ql-img-inline-formula " height="8" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78d46af3f19bae0d88ac0cabd450a296_l3.png?resize=13%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="13"/> follows a Gaussian distribution, it is known that we recover the arc-cosine kernel. We may also note that <a class="lipdf" href="http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf">random Fourier features</a> also yield a similar interpretation.</p>
<p>Other important links have also been drawn recently between kernel regression and strongly over-parametrized neural networks, see <a class="lipdf" href="http://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">this paper</a> and <a class="lipdf" href="https://arxiv.org/pdf/1812.07956.pdf">that one</a>, which is another exciting story.</p></div>
    </content>
    <updated>2019-07-17T16:02:03Z</updated>
    <published>2019-07-17T16:02:03Z</published>
    <category term="Machine learning"/>
    <author>
      <name>Sebastien Bubeck</name>
    </author>
    <source>
      <id>https://blogs.princeton.edu/imabandit</id>
      <link href="https://blogs.princeton.edu/imabandit/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://blogs.princeton.edu/imabandit" rel="alternate" type="text/html"/>
      <subtitle>Random topics in optimization, probability, and statistics. By Sébastien Bubeck</subtitle>
      <title>I’m a bandit</title>
      <updated>2019-07-28T23:40:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://minimizingregret.wordpress.com/?p=207</id>
    <link href="https://minimizingregret.wordpress.com/2019/07/17/boosting-for-dynamical-systems/" rel="alternate" type="text/html"/>
    <title>Boosting for Dynamical Systems</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">by Nataly Brukhim, Naman Agarwal and Elad Hazan, based on this paper  In a famous 1906 competition at a local fair in Plymouth, England, participants were asked to guess the weight of an ox. Out of a crowd of hundreds, no one came close to the ox’s actual weight, but the average of all guesses was … <a class="more-link" href="https://minimizingregret.wordpress.com/2019/07/17/boosting-for-dynamical-systems/">Continue reading <span class="screen-reader-text">Boosting for Dynamical Systems</span> <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>by Nataly Brukhim, Naman Agarwal and Elad Hazan, based on <a href="https://arxiv.org/abs/1906.08720">this paper</a> </em></p>
<p>In a famous 1906 competition at a local fair in Plymouth, England, participants were asked to guess the weight of an ox. Out of a crowd of hundreds, no one came close to the ox’s actual weight, but the average of all guesses was almost correct. How is it that combining the opinions of laymen can somehow arrive at highly reasoned decisions, despite the weak judgment of individual members? This concept of harnessing wisdom from weak rules of thumb to form a highly accurate prediction rule, is the basis of ensemble methods and <b>boosting</b>. Boosting is a theoretically sound methodology that has transformed machine learning across a variety of applications; in classification and regression tasks, online learning, and many more.</p>
<p>In the case of online learning, examples for training a predictor are not available in advance, but are revealed one at a time. Online boosting combines a set of online prediction rules, or <i>weak learners. </i>At every time step, each weak learner outputs a prediction, suffers some loss and is then updated accordingly. The performance of an online learner is measured using the <i>regret</i> criterion, which compares the accumulated loss over time with that of the best fixed decision in hindsight. A <i>Boosting</i> algorithm can choose which examples are fed to each of the weak learners, as well as the losses they incur. Intuitively, the online booster can encourage some weak learners to become really good in predicting certain common cases, while allowing others to focus on edge cases that are harder to predict. Overall, the <a href="http://proceedings.mlr.press/v37/beygelzimer15.pdf">online</a> <a href="https://arxiv.org/abs/1506.04820">boosting</a> framework can achieve low regret guarantees based on the learners’ individual regret values.</p>
<p>However, online learning can become more challenging when our actions have consequences on the environment. This can be illustrated with the following experiment: imagine learning to balance a long pole on your hand. When you move your hand slightly, the pole tilts. You then move your hand in the opposite direction, and it bounces back and tilts to the other side. One jerk the wrong way might have you struggling for a good few seconds to rebalance. In other words, a <u>sequence of decisions</u> you made earlier determines whether or not the pole is balanced at any given time, rather than the single decision you make at that point.<img alt="" class=" aligncenter" height="129" src="https://minimizingregret.files.wordpress.com/2019/07/image.jpeg?w=136&amp;h=129" title="" width="136"/></p>
<p>More generally, consider cases when our environment has a <b>state, </b>and is in some sense “remembering” our past choices. A stateful framework, able to model a wide range of such phenomena, is a <i>dynamical system</i>. A dynamical system can be thought of as a function that determines, given the current state, what the state of the system will be in the next time step. Think of the physical dynamics that determines our pole’s position based on sequential hand movements. Other intuitive examples are the fluctuations of stock prices in the stock market, or the local weather temperatures; these can all be modeled with dynamical systems.</p>
<p>So how can boosting help us make better predictions for a dynamical system? In <a href="https://arxiv.org/abs/1906.08720">recent work</a> we propose an algorithm, which we refer to as DynaBoost, that achieves this goal. In the paper we provide theoretical regret bounds, as well as an empirical evaluation in a variety of applications, such as online control and time-series prediction.</p>
<p><b>Learning for Online Control</b></p>
<p>Control theory is a field of applied mathematics that deals with the control of various physical processes and engineering systems. The objective is to design an action rule, or <i>controller</i>, for a dynamical system such that steady state values are achieved quickly, and the system maintains stability.</p>
<p>Consider a simple Linear Dynamical System (LDS):</p>
<p style="text-align: center;"><img alt="x_{t+1} = A x_t + B u_t + w_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bt%2B1%7D+%3D+A+x_t+%2B+B+u_t+%2B+w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_{t+1} = A x_t + B u_t + w_t"/></p>
<p>where <img alt="x_t,u_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_t%2Cu_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_t,u_t"/> are the state and control values at time t, respectively. Assume a known transition dynamics specified by the matrices A and B, and an arbitrary disturbance to the system given by <img alt="w_t" class="latex" src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w_t"/>. The goal of the controller is to minimize a convex cost function <img alt="c_t(x_t,u_t)" class="latex" src="https://s0.wp.com/latex.php?latex=c_t%28x_t%2Cu_t%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="c_t(x_t,u_t)"/>.</p>
<p>A provably optimal controller for the Gaussian noise case (where <img alt="w_t" class="latex" src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w_t"/> are normally distributed) and when the cost functions are quadratic, is the Linear Quadratic Regulator (LQR). LQR computes a pre-fixed matrix K such that <img alt="u_t^{LQR} = K x_t" class="latex" src="https://s0.wp.com/latex.php?latex=u_t%5E%7BLQR%7D+%3D+K+x_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_t^{LQR} = K x_t"/>. In other words, LQR computes a linear controller – which linearly maps the state into a control at every time step.</p>
<p>A <a href="http://proceedings.mlr.press/v97/agarwal19c/agarwal19c.pdf">recent advancement</a> in online control considers <i>arbitrary</i> disturbances, as opposed to normally distributed noise. In this more general setting, there is no closed form for the optimal controller. Instead, it is proposed to use a weighted sum of previously observed noises, i.e., <img alt="u_t^{WL} = K x_t + \sum_{i=1}^H M_i w_{t-i} " class="latex" src="https://s0.wp.com/latex.php?latex=u_t%5E%7BWL%7D+%3D+K+x_t+%2B+%5Csum_%7Bi%3D1%7D%5EH+M_i+w_%7Bt-i%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_t^{WL} = K x_t + \sum_{i=1}^H M_i w_{t-i} "/> , where <img alt="M_1,...,M_H" class="latex" src="https://s0.wp.com/latex.php?latex=M_1%2C...%2CM_H&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="M_1,...,M_H"/> are learned parameters, updated in an online fashion. This method is shown to attain vanishing average regret compared to the best fixed linear controller in hindsight, and is applicable for general convex cost functions as opposed to only quadratics.</p>
<p>Crucially, the state-dependent term <img alt="Kx_t" class="latex" src="https://s0.wp.com/latex.php?latex=Kx_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="Kx_t"/> is not learned. Since the learned parameters of the above controller therefore considers only a fixed number of recent disturbances, we can apply existing <a href="http://ocobook.cs.princeton.edu/">online convex optimization</a> techniques developed for <a href="https://papers.nips.cc/paper/6025-online-learning-for-adversaries-with-memory-price-of-past-mistakes">learning with loss functions that have bounded memory</a>.</p>
<p><strong>Boosting for Online Control</strong></p>
<p>Using the insights described above to remove state in online control, we can now use techniques from online boosting. DynaBoost maintains multiple copies of the base-controller above, with each copy corresponding to one stage in boosting. At every time step, the control <img alt="u_t" class="latex" src="https://s0.wp.com/latex.php?latex=u_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_t"/> is obtained from a convex combination of the base-controllers’ outputs <img alt="u_t^{WL(1)},...,u_t^{WL(N)}" class="latex" src="https://s0.wp.com/latex.php?latex=u_t%5E%7BWL%281%29%7D%2C...%2Cu_t%5E%7BWL%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="u_t^{WL(1)},...,u_t^{WL(N)}"/>. To update each base-controller’s parameters, DynaBoost feeds each controller with a <i>residual</i> <i>proxy </i>cost function, and seeks to obtain a minimizing point in the direction of the residual loss function’s gradient. Stability ensures that minimizing regret over the proxy costs (which have finite memory) suffices to minimize overall regret. See <a href="https://arxiv.org/abs/1906.08720">our paper</a> for the detailed description of the algorithm and its regret guarantees.</p>
<p><strong>Sanity check experiment</strong></p>
<p>We first conducted experiments for the standard LQR setting with i.i.d. Gaussian noise and known dynamics. We applied our boosting method to the non-optimal controller with learned parameters (Control-WL), and we observe that boosting improves its loss and achieves near-optimal performance (here the optimal controller is given by the fixed LQR solution). We have tested an LDS of different dimensions <img alt="d = 1,10,100" class="latex" src="https://s0.wp.com/latex.php?latex=d+%3D+1%2C10%2C100&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="d = 1,10,100"/>, and averaged results over multiple runs.</p>
<p><img alt="" height="182" src="https://minimizingregret.files.wordpress.com/2019/07/null.png?w=624&amp;h=182" title="" width="624"/></p>
<p><strong>Correlated noise experiment</strong></p>
<p>When the disturbances are not independently drawn, the LQR controller is not guaranteed to perform optimally. We experimented with two LDS settings with correlated disturbances in which (a) the disturbances <img alt="w_t" class="latex" src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w_t"/> are generated from a Gaussian random-walk, and (b) where they are generated by a sine function applied to the time index. In these cases, boosted controllers perform better compared to the “weak” learned controller, and can also outperform the fixed LQR solution. We have also tested a Recurrent Neural Network, and observed that boosting is effective for RNNs as well.</p>
<p><img alt="" height="266" src="https://minimizingregret.files.wordpress.com/2019/07/null-1.png?w=624&amp;h=266" title="" width="624"/></p>
<p><strong>Inverted Pendulum experiment</strong></p>
<p>A more challenging experiment with a non-linear dynamical system is the Inverted Pendulum experiment. This is very similar to the pole balancing example we discussed above, and is a standard benchmark for control methods. The goal is to balance the inverted pendulum by applying torque that will stabilize it in a vertically upright position, in the presence of noise. In our experiments, we used correlated disturbances from a Gaussian random-walk. We follow the dynamics implemented in <a href="https://gym.openai.com/">OpenAI Gym</a>, and test the performance of different controllers: LQR, a learned controller, and boosting. The video below visualizes this experiment:</p>
<div class="jetpack-video-wrapper"/>
<p>When averaging the loss value over multiple experiment runs, we get the following plot:</p>
<p style="text-align: center;"><img alt="" height="276" src="https://minimizingregret.files.wordpress.com/2019/07/null-2.png?w=369&amp;h=276" title="" width="369"/></p>
<p>It can be seen that the learned controller performs much better than the LQR in the presence of correlated noise, and that boosting can improve its stability and achieve lower average loss.</p>
<p><b>Boosting for Time-Series Prediction</b></p>
<p>Similarly to the control setting, in time-series prediction tasks it is sufficient to use fixed horizons, and online boosting can be efficiently applied here as well. In time-series prediction, the data is often assumed to be generated from an autoregressive moving average (ARMA) model:</p>
<p style="text-align: center;"><img alt="x_{t} = \sum_{i=1}^k \alpha_i x_{t-i} + \sum_{j=1}^q \beta_j w_j + w_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bt%7D+%3D+%5Csum_%7Bi%3D1%7D%5Ek+%5Calpha_i+x_%7Bt-i%7D+%2B+%5Csum_%7Bj%3D1%7D%5Eq+%5Cbeta_j+w_j+%2B+w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_{t} = \sum_{i=1}^k \alpha_i x_{t-i} + \sum_{j=1}^q \beta_j w_j + w_t"/></p>
<p>In words, each data point <img alt="x_t" class="latex" src="https://s0.wp.com/latex.php?latex=x_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_t"/> is given by a weighted sum of previous points, previous noises and a new noise term <img alt="w_t" class="latex" src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="w_t"/>, where <img alt="\alpha,\beta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha%2C%5Cbeta&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\alpha,\beta"/> are the coefficients vectors.</p>
<p>To test our boosting method, We experimented with 4 simulated settings: 1) normally distributed noises, 2) coefficients of the dynamical system slowly change over time, 3) a single, abrupt, change of the coefficients, and, 4) correlated noise: Gaussian random walk.</p>
<p>The weak learners tested here are the ARMA-ONS (online newton step) and ARMA-OGD (online gradient descent) algorithms for time-series prediction (See <a href="http://proceedings.mlr.press/v30/Anava13.pdf">this</a> paper for more details). We applied our boosting method, as well as a fast version of it, which applies to quadratic loss functions (we used squared difference in this case).</p>
<p><i><b>1) Gaussian Noise </b></i> <i><b>2) Changing Coefficients</b></i></p>
<p><img alt="" height="217" src="https://minimizingregret.files.wordpress.com/2019/07/null-3.png?w=289&amp;h=217" title="" width="289"/><img alt="" height="217" src="https://minimizingregret.files.wordpress.com/2019/07/null-4.png?w=289&amp;h=217" title="" width="289"/><img alt="" height="218" src="https://minimizingregret.files.wordpress.com/2019/07/null-5.png?w=292&amp;h=218" title="" width="292"/><img alt="" height="217" src="https://minimizingregret.files.wordpress.com/2019/07/null-6.png?w=290&amp;h=217" title="" width="290"/></p>
<p><i><b>3) Abrupt Change </b></i> <i><b>4) Correlated Noise</b></i></p>
<p>We can see in the plots above that all weak learners’ loss values (red) can be improved by online boosting methods (blue). A similar observation arises when experimenting with real-world data; we experimented with the Air Quality dataset from the <a href="https://archive.ics.uci.edu/ml/index.php">UCI Machine Learning repository</a>, that contains hourly averaged measurements of air quality properties from an Italian city throughout one year, as measured by chemical sensors. We apply similar weak learners to this task, as well as our boosting algorithms. Here we again obtain better averaged losses for boosted methods (blue) compared to the baselines (red).</p>
<p style="text-align: center;"><img alt="" height="373" src="https://minimizingregret.files.wordpress.com/2019/07/null-7.png?w=498&amp;h=373" title="" width="498"/></p></div>
    </content>
    <updated>2019-07-17T14:24:42Z</updated>
    <published>2019-07-17T14:24:42Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Elad Hazan</name>
    </author>
    <source>
      <id>https://minimizingregret.wordpress.com</id>
      <logo>https://minimizingregret.files.wordpress.com/2017/08/cropped-pu1.png?w=32</logo>
      <link href="https://minimizingregret.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://minimizingregret.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://minimizingregret.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://minimizingregret.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Google Princeton AI and Hazan Lab @ Princeton University</subtitle>
      <title>Minimizing Regret</title>
      <updated>2019-07-28T23:40:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=17564</id>
    <link href="https://gilkalai.wordpress.com/2019/07/17/dan-romik-on-the-riemann-zeta-function/" rel="alternate" type="text/html"/>
    <title>Dan Romik on the Riemann zeta function</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This post, about the Riemann zeta function, which is among the most important and mysterious mathematical objects was kindly written by Dan Romik. It is related to his paper Orthogonal polynomial expansions for the Riemann xi function,  that we mentioned … <a href="https://gilkalai.wordpress.com/2019/07/17/dan-romik-on-the-riemann-zeta-function/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>This post, about the Riemann zeta function, which is among the most important and mysterious mathematical objects was kindly written by Dan Romik. It is related to his paper <a href="https://arxiv.org/abs/1902.06330">Orthogonal polynomial expansions for the Riemann xi function</a>,  that we mentioned in <a href="https://gilkalai.wordpress.com/2019/02/28/dan-romik-studies-the-riemanns-zeta-function-and-other-zeta-news/">this post</a>.</em></p>
<h2>Dan Romik on the Riemann zeta function</h2>
<p>Recently when I was thinking about the Riemann zeta function, I had the double thrill of discovering some new results about it, and then later finding out that my new ideas were closely related to some very classical ideas due to two icons of twentieth-century mathematics, George Pólya and Pál Turán. When you are trying to stand on the shoulders of giants, it’s nice to see other giants right there beside you trying to do the same!</p>
<p>It all goes back to one of the most famous problems in mathematics, the Riemann Hypothesis (RH). Both Pólya and Turán were rather enamored with this problem and published about it extensively; Pólya was said to have been preoccupied with the problem to the very end of his life.(1) And they both recognized that an important first step in trying to prove something about the zeros of the zeta function is having a good representation<br/>
for the Riemann zeta function. After all, there are many different formulas that can be used to define or compute the zeta function. If you don’t choose the right one, you probably won’t get very far with your analysis.</p>
<p>Pólya in one of his famous attacks on the problem considered the representation of the zeta function (or more precisely of the Riemann xi function, which is a symmetrized and better-behaved version of the zeta function; see below) as a Fourier transform—a standard representation due (essentially) to Riemann. I’ll have more to say about that later.</p>
<p>Turán also looked at the Riemann xi function, and instead of working with one of the standard “named” representations such as the Fourier transform or Taylor series, looked around a bit more intentionally for a representation of the function that seemed particularly suited to answering the specific question of whether the zeros all lie on a line. In a 1950 address to the Hungarian Academy of Sciences, he put forward his ideas about what he thought was the correct representation to look at: the infinite series expansion of the xi function in the Hermite polynomials. About eighty years after Turán’s discovery, my own investigations led me to discover [5] that the Hermite polynomials are not the only polynomials in which it’s interesting to expand the Riemann xi function. It turns out that there are at least two other families of polynomials for which the respective expansions are no less (and, in some ways, more) well-behaved. My motto for these polynomial families, which are known to experts in special functions but have until now been somewhat esoteric (though I hope that is about to change), is that they are “the coolest polynomials that you never heard of.”</p>
<p>Let’s look at some of the technical details so that I can explain why these new expansions are interesting, and how they relate to Turán’s work and ultimately back to Pólya’s ideas and one of the particular threads that grew out of them. First, define the Riemann xi function as</p>
<p><img alt="\displaystyle \xi(s) = \frac12 s(s-1) \pi^{-s/2} \Gamma\left(\frac{s}{2}\right) \zeta(s) \qquad (s\in\mathbb{C}), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cxi%28s%29+%3D+%5Cfrac12+s%28s-1%29+%5Cpi%5E%7B-s%2F2%7D+%5CGamma%5Cleft%28%5Cfrac%7Bs%7D%7B2%7D%5Cright%29+%5Czeta%28s%29+%5Cqquad+%28s%5Cin%5Cmathbb%7BC%7D%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \xi(s) = \frac12 s(s-1) \pi^{-s/2} \Gamma\left(\frac{s}{2}\right) \zeta(s) \qquad (s\in\mathbb{C}), "/></p>
<p>where <img alt="{\Gamma(z)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CGamma%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Gamma(z)}"/> is the Euler gamma function and <img alt="{\zeta(s)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Czeta%28s%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\zeta(s)}"/> is the Riemann zeta function. It’s also common to denote<br/>
<img alt="\displaystyle \Xi(t) = \xi\left(\frac12+it\right) \qquad (t\in\mathbb{C}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Cxi%5Cleft%28%5Cfrac12%2Bit%5Cright%29+%5Cqquad+%28t%5Cin%5Cmathbb%7BC%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \Xi(t) = \xi\left(\frac12+it\right) \qquad (t\in\mathbb{C}). "/></p>
<p>This is Riemann’s “capital xi” function, which is still usually referred to as Riemann’s xi function. (This seems reasonable: the two functions are the same up to a trivial linear change of variables.) The main point of these definitions is that <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/> is an entire function of the complex variable <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/>, and that RH can now be reformulated as the statement that the zeros of <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/> all lie on the real line. Moreover, the famous functional equation satisfied by the Riemann zeta function maps to the statement that <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/> is an even function.<br/>
Now consider the following four ways of representing the xi function:</p>
<p><img alt="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n a_{2n} t^{2n},~~~~~(1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+a_%7B2n%7D+t%5E%7B2n%7D%2C%7E%7E%7E%7E%7E%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n a_{2n} t^{2n},~~~~~(1)"/></p>
<p><img alt="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n b_{2n} H_{2n}(t),~~~~~(2)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+b_%7B2n%7D+H_%7B2n%7D%28t%29%2C%7E%7E%7E%7E%7E%282%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n b_{2n} H_{2n}(t),~~~~~(2)"/></p>
<p><img alt="\displaystyle\Xi(t) = \sum_{n=0}^\infty (-1)^n c_{2n} f_{2n}\left(\frac{t}{2}\right),~~~~~(3)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+c_%7B2n%7D+f_%7B2n%7D%5Cleft%28%5Cfrac%7Bt%7D%7B2%7D%5Cright%29%2C%7E%7E%7E%7E%7E%283%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle\Xi(t) = \sum_{n=0}^\infty (-1)^n c_{2n} f_{2n}\left(\frac{t}{2}\right),~~~~~(3)"/></p>
<p><img alt="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n d_{2n} g_{2n}\left(\frac{t}{2}\right).~~~~~(4)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+d_%7B2n%7D+g_%7B2n%7D%5Cleft%28%5Cfrac%7Bt%7D%7B2%7D%5Cright%29.%7E%7E%7E%7E%7E%284%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n d_{2n} g_{2n}\left(\frac{t}{2}\right).~~~~~(4)"/></p>
<p>Here, the first representation (1) is simply the Taylor expansion of <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/>, which contains only even terms since <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/> is an even function. The numbers <img alt="{a_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_{2n}}"/> are (up to the <img alt="{(-1)^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1)^n}"/> sign factor) the Taylor coefficients. Some attempts have been made to understand them, and one interesting and fairly trivial observation (again going back to facts already known to Riemann) is that they are all positive. Some additional and less trivial things can be said—see for example Section 6.1 of my paper [5], and the recent paper by Griffin, Ono, Rolen and Zagier [2]. But at the end of the day, no one has yet succeeded in using the Taylor expansion to prove anything new about the location of the zeros.</p>
<p>The second representation (2) is the infinite series expansion of <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/> in the classical sequence of Hermite polynomials, defined by the well-known formula</p>
<p><img alt="\displaystyle H_n(t) = (-1)^n e^{t^2} \frac{d^n}{dt^n} \left( e^{-t^2} \right). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+H_n%28t%29+%3D+%28-1%29%5En+e%5E%7Bt%5E2%7D+%5Cfrac%7Bd%5En%7D%7Bdt%5En%7D+%5Cleft%28+e%5E%7B-t%5E2%7D+%5Cright%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle H_n(t) = (-1)^n e^{t^2} \frac{d^n}{dt^n} \left( e^{-t^2} \right). "/></p>
<p>This is the representation whose use was advocated by Turán. His reasoning was that expanding a function of a complex variable (for example, in the simplest case, a polynomial) in monomials <img alt="{t^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t^n}"/> doesn’t provide useful information to easily decide if the function has only real zeros, because the monomials have, roughly speaking, radial symmetry: their level curves are concentric circles. The Hermite polynomials on the other hand, at least heuristically, have level curves that are closer to being straight lines parallel to the real axis, Turán argued; thus, they are more suited to the geometry of the problem we are trying to solve.</p>
<p>Turán’s case for supporting the Hermite polynomials as the right basis to use is quite detailed—you can read about it in his papers [6,7,8] (and no, he was not able to actually prove anything about the zeros of <img alt="{\Xi(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi(t)}"/>; this is a common theme in most of the attacks on RH to date…). I’ll simply mention that again one interesting and fairly easy observation is that the coefficients <img alt="{b_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b_{2n}}"/> in the expansion (2)—adjusted through the introduction of the sign factor <img alt="{(-1)^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1)^n}"/>—end up being positive numbers. Their asymptotic behavior can also be analyzed: I prove a result about this in my paper (though it’s not particularly pretty).</p>
<p>Now comes the part that to me seems the most exciting, involving the expansions (3) and (4). These are the expansions in the more exotic families of polynomials</p>
<p><img alt="\displaystyle f_n(x)=(-i)^n \sum_{k=0}^n 2^k\binom{n+\frac12}{n-k}\binom{-\frac34+ix}{k}," class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f_n%28x%29%3D%28-i%29%5En+%5Csum_%7Bk%3D0%7D%5En+2%5Ek%5Cbinom%7Bn%2B%5Cfrac12%7D%7Bn-k%7D%5Cbinom%7B-%5Cfrac34%2Bix%7D%7Bk%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle f_n(x)=(-i)^n \sum_{k=0}^n 2^k\binom{n+\frac12}{n-k}\binom{-\frac34+ix}{k},"/></p>
<p><img alt="\displaystyle g_n(x)= (-i)^n \sum_{k=0}^n \frac{(n+k+1)!}{(n-k)!(3/2)_k^2} \binom{-\frac34+ix}{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+g_n%28x%29%3D+%28-i%29%5En+%5Csum_%7Bk%3D0%7D%5En+%5Cfrac%7B%28n%2Bk%2B1%29%21%7D%7B%28n-k%29%21%283%2F2%29_k%5E2%7D+%5Cbinom%7B-%5Cfrac34%2Bix%7D%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle g_n(x)= (-i)^n \sum_{k=0}^n \frac{(n+k+1)!}{(n-k)!(3/2)_k^2} \binom{-\frac34+ix}{k}"/></p>
<p>(where <img alt="{(3/2)_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%283%2F2%29_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(3/2)_n}"/> is a <a href="https://en.wikipedia.org/wiki/Falling_and_rising_factorials">Pochhammer symbol</a>), mildly rescaled by replacing <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>  with <img alt="{t/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t/2}"/>. In the terminology of the theory of orthogonal polynomials, the family <img alt="{f_n(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_n(x)}"/> is a special case of a two-parameter family <img alt="{P_n^{(\lambda)}(x;\phi)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP_n%5E%7B%28%5Clambda%29%7D%28x%3B%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{P_n^{(\lambda)}(x;\phi)}"/> known as the Meixner-Pollaczek polynomials, with the parameters taking the particular values <img alt="{\phi=\frac{\pi}{2}, \lambda=\frac{3}{4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%3D%5Cfrac%7B%5Cpi%7D%7B2%7D%2C+%5Clambda%3D%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\phi=\frac{\pi}{2}, \lambda=\frac{3}{4}}"/>. Similarly, the family <img alt="{g_n(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g_n(x)}"/> is a special case of the four-parameter family <img alt="{p_n(x;a,b,c,d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp_n%28x%3Ba%2Cb%2Cc%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p_n(x;a,b,c,d)}"/> known as the continuous Hahn polynomials, with the parameters taking the particular values <img alt="{a=b=c=d=\frac{3}{4}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba%3Db%3Dc%3Dd%3D%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a=b=c=d=\frac{3}{4}}"/>. Their main characterizing property is that they are orthogonal sequences of polynomials for two specific weight functions on <img alt="{\mathbb{R}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{R}}"/>: the <img alt="{f_n(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_n(x)}"/> are orthogonal with respect to the weight function <img alt="{w_1(x)=\left|\Gamma\left(\frac34+ix\right)\right|^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_1%28x%29%3D%5Cleft%7C%5CGamma%5Cleft%28%5Cfrac34%2Bix%5Cright%29%5Cright%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w_1(x)=\left|\Gamma\left(\frac34+ix\right)\right|^2}"/>, and the <img alt="{g_n(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g_n(x)}"/> are orthogonal with respect to <img alt="{w_2(x)=\left|\Gamma\left(\frac34+ix\right)\right|^4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw_2%28x%29%3D%5Cleft%7C%5CGamma%5Cleft%28%5Cfrac34%2Bix%5Cright%29%5Cright%7C%5E4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w_2(x)=\left|\Gamma\left(\frac34+ix\right)\right|^4}"/>. Again, fairly esoteric. But interesting!</p>
<p>There are several things that make the expansions (3)–(4) well-behaved. First, the coefficients <img alt="{c_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_{2n}}"/>, <img alt="{d_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_{2n}}"/> are again positive. This actually seems pretty relevant for questions like RH: for example, if we consider “toy” versions of (1)–(3) in which the coefficient sequences <img alt="{a_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Ba_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{a_n}"/>, <img alt="{b_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b_n}"/> and <img alt="{c_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_n}"/> are replaced by the sequence <img alt="{\alpha^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^n}"/> for fixed <img alt="{0&lt;\alpha&lt;1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%3C%5Calpha%3C1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0&lt;\alpha&lt;1}"/>, all three expansions sum up to rescaled cosines, which are entire functions that of course have only real zeros. (Without the <img alt="{(-1)^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1)^n}"/> factor, we would get a hyperbolic cosine, which has imaginary zeros.)</p>
<p>Second, one can derive asymptotics for <img alt="{c_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_{2n}}"/> and <img alt="{d_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_{2n}}"/>, and they are quite a bit nicer than the asymptotic formulas for the Taylor and Hermite expansion coefficients. In my paper, I proved that <img alt="\displaystyle c_{2n} \sim A \sqrt{n} e^{-B \sqrt{n}}, \qquad d_{2n} \sim C n^{4/3} e^{-D n^{2/3}} \qquad \textrm{as }n\rightarrow\infty, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+c_%7B2n%7D+%5Csim+A+%5Csqrt%7Bn%7D+e%5E%7B-B+%5Csqrt%7Bn%7D%7D%2C+%5Cqquad+d_%7B2n%7D+%5Csim+C+n%5E%7B4%2F3%7D+e%5E%7B-D+n%5E%7B2%2F3%7D%7D+%5Cqquad+%5Ctextrm%7Bas+%7Dn%5Crightarrow%5Cinfty%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle c_{2n} \sim A \sqrt{n} e^{-B \sqrt{n}}, \qquad d_{2n} \sim C n^{4/3} e^{-D n^{2/3}} \qquad \textrm{as }n\rightarrow\infty, "/> where <img alt="{A,B,C,D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%2CD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B,C,D}"/> are the constants <img alt="\displaystyle A = 16\sqrt{2}\pi^{3/2}, \qquad B = 4\sqrt{\pi}, \qquad C = \frac{128 \times 2^{1/3} \pi^{2/3} e^{-2\pi /3}}{\sqrt{3}}, \qquad D = 3 (4\pi)^{1/3}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+A+%3D+16%5Csqrt%7B2%7D%5Cpi%5E%7B3%2F2%7D%2C+%5Cqquad+B+%3D+4%5Csqrt%7B%5Cpi%7D%2C+%5Cqquad+C+%3D+%5Cfrac%7B128+%5Ctimes+2%5E%7B1%2F3%7D+%5Cpi%5E%7B2%2F3%7D+e%5E%7B-2%5Cpi+%2F3%7D%7D%7B%5Csqrt%7B3%7D%7D%2C+%5Cqquad+D+%3D+3+%284%5Cpi%29%5E%7B1%2F3%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle A = 16\sqrt{2}\pi^{3/2}, \qquad B = 4\sqrt{\pi}, \qquad C = \frac{128 \times 2^{1/3} \pi^{2/3} e^{-2\pi /3}}{\sqrt{3}}, \qquad D = 3 (4\pi)^{1/3}. "/></p>
<p>Third, the expansions have some conceptual meaning: (3) turns out to be equivalent to the expansion of the elementary function <img alt="{\frac{d^2}{du^2} (u \coth(\pi u))}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bd%5E2%7D%7Bdu%5E2%7D+%28u+%5Ccoth%28%5Cpi+u%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{d^2}{du^2} (u \coth(\pi u))}"/>, <img alt="{u&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u&gt;0}"/>, in an orthogonal basis of functions related to the Laguerre polynomials <img alt="{L_n^{1/2}(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BL_n%5E%7B1%2F2%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{L_n^{1/2}(x)}"/>. And analogously, (4) arises out of the expansion of a certain auxiliary function <img alt="{\tilde{\nu}(u)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7B%5Cnu%7D%28u%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde{\nu}(u)}"/> (I won’t define it here) in yet another classical family of orthogonal polynomials, the Chebyshev polynomials of the second kind.</p>
<p>Fourth (and fifth, sixth, …): the expansions are just… nice, in the sense that they arise in a way that seems natural when one asks certain questions, that they have excellent convergence properties, and that the coefficients <img alt="{c_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bc_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{c_{2n}}"/> and <img alt="{d_{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d_{2n}}"/> have several elegant formulas, each revealing something interesting about them. Read the paper to understand more.</p>
<p>I said I will get back to Pólya’s work on RH. This post is already quite long so I will say only a little bit about this. One of Pólya’s major discoveries was that there are operations on entire functions that (under certain mild assumptions) preserve the property of the function having only real zeros. Specifically this is the case for the operation of multiplying the Fourier transform of the function by the factor <img alt="{e^{\lambda u^2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Be%5E%7B%5Clambda+u%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{e^{\lambda u^2}}"/> for <img alt="{\lambda&gt;0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda&gt;0}"/>  (where <img alt="{u}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{u}"/> is the frequency variable). This opens the way to defining a family of deformations <img alt="{\Xi_\lambda(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi_%5Clambda%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi_\lambda(t)}"/> of the Riemann xi function arising out of this operation, and trying to generalize RH by asking for which values of <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda}"/> it is the case that <img alt="{\Xi_\lambda(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi_%5Clambda%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi_\lambda(t)}"/> has only real zeros. Since Pólya’s work, and important later extensions of it by De Bruijn and Newman, this has become a very active topic of research, nowadays referred to under the name of the De Bruijn-Newman constant.<br/>
See the recent survey of Newman and Wu [3], a 2018 paper by Rodgers and Tao [4] proving a major conjecture of Newman, and the recent paper [9] by the <a href="https://terrytao.wordpress.com/2018/12/28/polymath-15-eleventh-thread-writing-up-the-results-and-exploring-negative-t/">Polymath15 project</a> (mentioned by Gil in his <a href="https://gilkalai.wordpress.com/2019/02/28/dan-romik-studies-the-riemanns-zeta-function-and-other-zeta-news/">earlier post</a>), for the latest on this subject.</p>
<p>The connection I found between this topic and the idea of expanding the Riemann xi function in families of orthogonal polynomials is the following: expansions such as (2)–(4) suggest yet another natural way of “deforming” the Riemann xi function by adding a parameter <img alt="{\alpha}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha}"/>: simply multiply the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>th term in the expansion by <img alt="{\alpha^{2n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\alpha^{2n}}"/> (the linear operator that does this is called the Poisson kernel, and generalizes the standard Poisson kernel from complex analysis and the theory of harmonic functions). It turns out—and is actually easy to prove, and really isn’t terribly surprising in the grand scheme of things—that in the case of the Hermite expansion (2), this family of deformations is the same, up to some trivial reparametrization, as the family of deformations <img alt="{\Xi_\lambda(t)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5CXi_%5Clambda%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\Xi_\lambda(t)}"/> that was studied in connection with the work of Pólya, De Bruijn, Newman and their successors. A nice connection between two threads of research that were not previously recognized as being related to each other, I think. Furthermore, this suggests that the Poisson kernel and associated deformations may yet have an important role to play in the context of the new expansions in the orthogonal polynomial families <img alt="{f_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f_n}"/> and <img alt="{g_n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bg_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{g_n}"/>, where we get genuinely new families of deformations of the Riemann xi function. I explore this idea in my paper and it leads to some interesting things.</p>
<p>So let’s summarize. The key questions you are no doubt wondering about are: where does any of this lead? And do these new ideas say anything really useful or especially relevant for the Riemann hypothesis? The answer is that I don’t know (and I’m wondering about the same things). That being said, these orthogonal polynomial expansions seem quite interesting in their own right. The Riemann zeta function is a mysterious object, and there are <a href="https://en.wikipedia.org/wiki/Lindel%C3%B6f_hypothesis">other things</a> we wish to understand about it beside where its zeros are, so it’s always good to have additional points of view from which to approach it. Moreover, even on the question of the zeros there are reasons to be cautiously optimistic that this approach may have something useful to offer; see Chapter 7 of my paper for a brief discussion of why that is the case.</p>
<h2/>
<h2>References</h2>
<p>[1] D. Albers and G. L. Alexanderson, editors. Mathematical People: Profiles and Interviews. A K Peters, 2008.</p>
<p>[2] M. Griffin, K. Ono, L. Rolen and D. Zagier. Jensen polynomials for the Riemann zeta function and other sequences. Preprint (2019), <a href="https://arxiv.org/abs/1902.07321">arXiv:1902.07321</a>.</p>
<p>[3] C. M. Newman. Constants of de Bruijn-Newman type in analytic number theory and statistical physics. To appear in Bull. Amer. Math. Soc.</p>
<p>[4] B. Rodgers and T. Tao. The De Bruijn-Newman constant is nonnegative. Preprint (2018), <a href="https://arxiv.org/abs/1801.05914">arXiv:1801.05914</a>.</p>
<p>[5] D. Romik. <a href="https://arxiv.org/abs/1902.06330">Orthogonal polynomial expansions for the Riemann xi function</a>. Preprint (2019), <a href="https://arxiv.org/abs/1902.06330">arXiv:1902.06330</a>.</p>
<p>[6] P. Turán. Sur l’algèbre fonctionelle. Pages 279–290 in: Comptes Rendus du Premier Congrès des Mathématiciens Hongrois, 27 Août–2 Septembre 1950. Akadémiai Kiadó, 1952. Reprinted in Collected Papers of Paul Turán, Ed. P. Erdos, Vol. 1, pp. 677–688. Akadémiai Kiadó, 1990. An English translation of the paper by Dan Romik <a href="http://math.ucdavis.edu/~romik/data/uploads/misc/turan1952-english.pdf">On functional algebra</a>.</p>
<p>[7] P. Turán. Hermite-expansion and strips for zeros of polynomials. Arch. Math. 5 (1954), 148–152. Reprinted in Collected Papers of Paul Turán, Ed. P. Erdos, Vol. 1, pp. 738–742. Akadémiai Kiadó, 1990.</p>
<p>[8]  P. Turán. To the analytical theory of algebraic equations. Bulgar. Akad. Nauk. Otd. Mat. Fiz. Nauk. Izv. Mat. Inst. 3 (1959), 123–137. Reprinted in Collected Papers of Paul Turán, Ed. P. Erdos, Vol. 2, pp. 1080–1090. Akadémiai Kiadó, 1990.</p>
<p>[9] D.H.J. Polymath. Effective approximation of heat flow evolution of the Riemann ξ function, and a new upper bound for the de Bruijn-Newman constant. Preprint (2019), <a href="https://arxiv.org/abs/1904.12438">arXiv:1904.12438</a>.</p>
<h2>Notes:</h2>
<p>(1) Alexanderson writes in [1, p. 259]: “A week or so before he died, Pólya asked me to look on his desk at home for some papers on which he said he had written down some interesting ideas he had for proving RH. Of course I could find no such notes, but until the day he died he was thinking about that famous problem.”</p>
<p> </p>
<p>(2) Turán’s Hungarian Academy of Sciences talk was published in a rather obscure French-language paper [6] that seems to have been largely forgotten. It’s an interesting read nonetheless, and to make it more accessible to anyone who may be interested, I recently translated it to English.</p>
<p> </p>
<p>(3) Turán mentions in [8] that he discovered the results on the Hermite expansion in 1938–39, but they were not published until much later. Clearly this was not a convenient time in history for publishing such discoveries; Turán, a Hungarian Jew, spent much of World War II interned in labor camps in Hungary.</p></div>
    </content>
    <updated>2019-07-17T06:22:33Z</updated>
    <published>2019-07-17T06:22:33Z</published>
    <category term="Combinatorics"/>
    <category term="Guest blogger"/>
    <category term="Number theory"/>
    <category term="Dan Romik"/>
    <category term="George Polya"/>
    <category term="Paul Turan"/>
    <category term="Riemann Hypothesis"/>
    <category term="Riemann zeta function"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-28T23:39:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16114</id>
    <link href="https://rjlipton.wordpress.com/2019/07/16/summer-reading-in-theory/" rel="alternate" type="text/html"/>
    <title>Summer Reading in Theory</title>
    <summary>Some formative books in mathematics and computing theory LSE source: “Calculus on Clay?” Norman Biggs is the author of the wonderful book Algebraic Graph Theory. Both Ken and I read it long ago, and both of us have it out now because of its relevance to Hao Huang’s beautiful short proof of the Boolean Sensitivity […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Some formative books in mathematics and computing theory</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/07/biggs-norman-150x150.jpg"><img alt="" class="alignright size-full wp-image-16115" src="https://rjlipton.files.wordpress.com/2019/07/biggs-norman-150x150.jpg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">LSE <a href="https://blogs.lse.ac.uk/maths/2016/04/15/norman-biggs-calculus-on-clay/">source</a>: <i>“Calculus on Clay?”</i></font></td>
</tr>
</tbody>
</table>
<p>
Norman Biggs is the author of the wonderful <a href="https://www.cambridge.org/core/books/algebraic-graph-theory/6C70471342F19680068C35EF174075DC">book</a> <em>Algebraic Graph Theory</em>. Both Ken and I read it long ago, and both of us have it out now because of its relevance to Hao Huang’s beautiful short <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">proof</a> of the Boolean Sensitivity Conjecture. </p>
<p>
Today we wish to ask, <i>What are your top five favorite books on mathematics and theory for summer reading?</i><br/>
<span id="more-16114"/></p>
<p>
There’s an <a href="https://en.wikipedia.org/wiki/Aporia">aporia</a> in that question. A working definition of aporia is: “a self-contradiction that isn’t.” The point is that books for summer reading should be new, so how would you already know which are your favorites? Well, we are thinking of books that are so rich you can always find new things in them—and that also played formative roles earlier in our careers.</p>
<p>
Ken knew Biggs during his first year at Oxford when Biggs was visiting there from London. He took part in a weekly sitting-room seminar organized by Peter Neumann. Biggs’s book was a central reference for Ken’s undergraduate senior thesis at Princeton, and both he and Ken presented material based on it. </p>
<p>
</p><p/><h2> Best Five Books—Dick </h2><p/>
<p/><p>
Here are my votes for all-time best books in mathematics and in computer science theory.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <a href="https://www.cambridge.org/core/books/algebraic-graph-theory/6C70471342F19680068C35EF174075DC"><i>Algebraic Graph Theory</i></a>, by Norman Biggs. A wonderful book. First appeared in 1974.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <a href="https://www.amazon.com/Introduction-Probability-Theory-Applications-Vol/dp/0471257087/ref=sr_1_1?keywords=William+Feller&amp;qid=1563190401&amp;s=books&amp;sr=1-1"><i> An Introduction to Probability Theory and Its Applications, Vol. 1</i></a>, by William Feller. This is the book I used to learn probability theory.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <a href="https://www.amazon.com/gp/product/0199219869/ref=as_li_tl?ie=UTF8&amp;tag=mathblog05-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0199219869&amp;linkId=a71963a143733e948f50588526d624c0"><i> An Introduction to the Theory of Numbers</i></a>, by Godfrey Hardy and Edward Wright. Now updated by Andrew Wiles, Roger Heath-Brown, and Joseph Silverman. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <a href="https://www.amazon.com/Elements-Number-Theory-Dover-Mathematics/dp/0486781658/ref=sr_1_1?keywords=Vinogradov&amp;qid=1563190340&amp;s=books&amp;sr=1-1"><i>Elements of Number Theory</i></a>, by Ivan Vinogradov. Another small book that is loaded with ideas. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> <a href="https://www.abebooks.com/Paul-Erds-Art-Counting-Erdos-Joel/13380002114/bd"><i>The Art of Counting</i></a>, by Paul Erdős and Joel Spencer. This book changed my life. Today the book is of course <a href="https://www.amazon.com/dp/0470170204/?tag=stackoverfl08-20"><i>The Probabilistic Method</i></a>, by Noga Alon and Joel Spencer. </p>
<p>
</p><p/><h2> Best Five Books—Ken </h2><p/>
<p/><p>
Ken reaches back to his teen years but it’s still the same span of years as my list. Here he tells it:</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> All books by Martin Gardner—in particular, the books of collections of his “Mathematical Games” columns in <em>Scientific American</em>. Here is an <a href="https://blogs.scientificamerican.com/guest-blog/the-top-10-martin-gardner-scientific-american-articles/">overview</a>.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <a href="https://www.lybrary.com/scarne-on-dice-p-655.html"><i>Scarne on Dice</i></a> and <a href="https://www.lybrary.com/scarne-on-cards-p-759.html"><i> Scarne on Cards</i></a>. Originally it was neither of these books—nor John Scarne’s <em>Complete Guide to Gambling</em>—but a different book on in which both Scarne and Gardner figured prominently. Alas I, Ken, cannot trace it. That’s what I used to learn probability theory.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <a href="https://www.amazon.com/Spectra-Graphs-Application-Applied-Mathematics/dp/0121951502"><i>Spectra of Graphs</i></a>, by Dragoš Cvetković, Michael Doob, and Horst Sachs. I could put Biggs’s book here, but this is the one that got me on to the whole subject just before my senior year at Princeton. It was fresh out in 1980—I recall the tactile sensation of the dark green spanking new cover in the Fine Hall Library’s copy. A great book with pictures and algebra. </p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <a href="https://www.amazon.com/Ideals-Varieties-Algorithms-Computational-Undergraduate/dp/0387356509"><i> Ideals, Varieties, and Algorithms</i></a>, by David Cox, John Little, and Donal O’Shea. Fast forward to 1997. Having realized that techniques from algebraic geometry could surmount the “Natural Proofs” <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">barrier</a> (see also <a href="https://en.wikipedia.org/wiki/Geometric_complexity_theory">GCT</a>), I went whole-hog after it. See “Manic Monomials” in this <a href="https://rjlipton.wordpress.com/2012/07/04/july-fourth-sale-of-ideas/">post</a> for one thing that tripped it up. The book remains incredibly stimulating. It has a <a href="https://www.amazon.com/Using-Algebraic-Geometry-Graduate-Mathematics/dp/0387984879/">sequel</a>, <em>Using Algebraic Geometry</em>.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <a href="https://en.wikipedia.org/wiki/Quantum_Computation_and_Quantum_Information"><i>Quantum Computation and Quantum Information</i></a> by Michael Nielsen and Isaac Chuang. As with Hardy and Wright, it has its own Wikipedia page. Dick and I can say this is nominating a competitor, but Chaung &amp; Nielsen is really in a class by itself for the sheer richness and writing style. One odd mark of its influence: In 2006 when I reacted to the sensational and frightening accusations of cheating at the world championship <a href="https://en.wikipedia.org/wiki/World_Chess_Championship_2006">match</a>, my first thought was to apply distributional distance measures of the kind used in its later chapters. Among such measures is (quantum) <a href="https://en.wikipedia.org/wiki/Fidelity_of_quantum_states">fidelity</a>, and although I focused more on Jensen-Shannon divergence before deciding on simpler stuff, my chess research <a href="https://cse.buffalo.edu/~regan/chess/fidelity/">website</a> retains “fidelity” in its name as part of a multi-way reference to <a href="https://en.wikipedia.org/wiki/FIDE">FIDE</a>, faith, and playing in good faith.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
What books most influenced you? What are your votes for the best books that might influence others?	 </p></font></font></div>
    </content>
    <updated>2019-07-17T04:26:38Z</updated>
    <published>2019-07-17T04:26:38Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Oldies"/>
    <category term="Teaching"/>
    <category term="algebraic"/>
    <category term="books"/>
    <category term="Hao Huang"/>
    <category term="Norman Biggs"/>
    <category term="probabilistic"/>
    <category term="spectral graph theory"/>
    <category term="summer reading"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-07-28T23:39:10Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6069637759837834972</id>
    <link href="https://blog.computationalcomplexity.org/feeds/6069637759837834972/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/guest-post-by-samir-khuller-on.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6069637759837834972" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/6069637759837834972" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/guest-post-by-samir-khuller-on.html" rel="alternate" type="text/html"/>
    <title>Guest post by Samir Khuller on attending The TCS Women 2019 meeting</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
(I will post the solution to the problem in the last blog later in the week---probably Thursday. Meanwhile, enjoy these thoughts from Samir Khuller on the TCS Women 2019 meeting.)<br/>
<br/>
Guest Post by Samir Khuller:<br/>
<br/>
Am I even allowed here?” was the first thought that crossed my mind when I entered the room. It was packed with women (over 95%), however a few minutes later, several men had trickled in. I was at the TCS Women spotlight workshop on the day before STOC. Kudos to Barna Saha, Sofya Raskhodnikova, and Virginia Vassilevska Williams for putting this grand (and long needed) event together, which serves as a role model and showcases some of the recent work by rising stars. In addition to the Sun afternoon workshop, the event was followed by both an all women panel and a poster session (which I sadly did not attend).<br/>
<br/>
<br/>
The rising stars talks were given by Naama Ben-David (CMU), Andrea Lincoln (MIT), Debarati Das (Charles University) and Oxana Poburinnaya (Boston U). After a short break the inspirational talk was by Ronitt Rubinfeld from MIT.  Ronitt’s talk was on the topic of Program Checking, but she made it inspirational by putting us in her shoes as a young graduate student, three decades back, trying to make a dent in research by working on something that her advisor Manuel Blum, and his senior graduate student Sampath Kannan had been working on, and I must say she made a pretty big dent in the process! She also related those ideas to other pieces of work done since in a really elegant manner and how these pieces of work lead to work on property testing.<br/>
<br/>
<br/>
I am delighted to say that NSF supported the workshop along with companies such as Amazon, Akamai, Google and Microsoft. SIGACT plans to be a major sponsor next year.<br/>
<br/>
<br/>
The Full program for the workshop is at the following URL<a href="https://sigact.org/tcswomen/tcs-women-2019/">here.</a><br/>
<br/></div>
    </content>
    <updated>2019-07-16T23:38:00Z</updated>
    <published>2019-07-16T23:38:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-28T12:43:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/094</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/094" rel="alternate" type="text/html"/>
    <title>TR19-094 |  Rainbow coloring hardness via low sensitivity polymorphisms | 

	Venkatesan Guruswami, 

	Sai Sandeep</title>
    <summary>A $k$-uniform hypergraph is said to be $r$-rainbow colorable if there is an $r$-coloring of its vertices such that every hyperedge intersects all $r$ color classes. Given as input such a hypergraph, finding a $r$-rainbow coloring of it is NP-hard for all $k \ge 3$ and $r \ge 2$. Therefore, one settles for finding a rainbow coloring with fewer colors (which is an easier task).  When $r=k$ (the maximum possible value), i.e., the hypergraph is $k$-partite, one can efficiently $2$-rainbow color the hypergraph, i.e., $2$-color its vertices so that there are no monochromatic edges. In this work we consider the next smaller value of $r=k-1$, and prove that in this case it is NP-hard to rainbow color the hypergraph with $q :=  \lceil \frac{k-2}{2} \rceil$ colors. In particular, for $k \le 6$, it is NP-hard to $2$-color $(k-1)$-rainbow colorable $k$-uniform hypergraphs.

Our proof follows the algebraic approach to promise constraint satisfaction problems. It proceeds by characterizing the polymorphisms associated with the approximate rainbow coloring problem, which are rainbow colorings of some product hypergraphs on vertex set $[r]^n$. We prove that any such polymorphism $f: [r]^n \to [q]$ must be $C$-fixing, i.e., there is a small subset $S$ of $C$ coordinates and a setting $a \in [q]^S$ such that fixing $x_{|S} = a$ determines the value of $f(x)$. The key step in our proof is bounding the sensitivity of certain rainbow colorings, thereby arguing that they must be juntas. Armed with the $C$-fixing characterization, our NP-hardness is obtained via a reduction from smooth Label Cover.</summary>
    <updated>2019-07-16T01:19:56Z</updated>
    <published>2019-07-16T01:19:56Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-28T23:38:48Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/093</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/093" rel="alternate" type="text/html"/>
    <title>TR19-093 |  Improved 3LIN Hardness via Linear Label Cover | 

	Euiwoong Lee, 

	Subhash Khot, 

	Prahladh Harsha, 

	Devanathan Thiruvenkatachari</title>
    <summary>We prove that for every constant $c$ and $\epsilon = (\log n)^{-c}$, there is no polynomial time algorithm that when given an instance of 3LIN with $n$ variables where an $(1 - \epsilon)$-fraction of the clauses are satisfiable, finds an assignment that satisfies at least $(\frac{1}{2} + \epsilon)$-fraction of clauses unless $\mathbf{NP} \subseteq \mathbf{BPP}$. The previous best hardness using a polynomial time reduction achieves $\epsilon = (\log \log n)^{-c}$, which is obtained by the Label Cover hardness of Moshkovitz and Raz [J. ACM, 57(5), 2010] followed by the reduction from Label Cover to 3LIN of Hastad [J. ACM, 48(4):798--859, 2001].

Our main idea is to prove a hardness result for Label Cover similar to Moshkovitz and Raz where each projection has a linear structure. This linear structure of Label Cover allows us to use Hadamard codes instead of long codes, making the reduction more efficient. For the hardness of Linear Label Cover, we follow the work of Dinur and Harsha [SIAM J. Comput., 42(6):2452--2486, 2013] that simplified the construction of Moshkovitz and Raz, and observe that running their reduction from a hardness of the problem LIN (of unbounded arity) instead of the more standard problem of solving quadratic equations ensures the linearity of the resultant Label Cover.</summary>
    <updated>2019-07-16T01:10:59Z</updated>
    <published>2019-07-16T01:10:59Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-28T23:38:48Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/07/15/linkage</id>
    <link href="https://11011110.github.io/blog/2019/07/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Turkey has charged over 700 academics with terrorism for signing a peace petition (). Among the most severely penalized is Tuna Altınel, a mathematician in France who was arrested visiting family in Turkey, and who has now been imprisoned for over 50 days (via).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://www.insidehighered.com/news/2019/07/01/about-700-academics-have-been-criminally-charged-turkey-their-signatures-petition">Turkey has charged over 700 academics with terrorism for signing a peace petition</a> (<a href="https://mathstodon.xyz/@11011110/102367088461002886"/>). Among the most severely penalized is <a href="https://en.wikipedia.org/wiki/Tuna_Alt%C4%B1nel">Tuna Altınel</a>, a mathematician in France who was arrested visiting family in Turkey, and who <a href="http://math.univ-lyon1.fr/SoutienTunaAltinel/?lang=en">has now been imprisoned for over 50 days</a> (<a href="https://cameroncounts.wordpress.com/2019/05/31/tuna-altnel/">via</a>).</p>
  </li>
  <li>
    <p><a href="http://web.cs.elte.hu/~lovasz/bookxx/geomgraphbook/geombook2019.01.11.pdf">László Lovász’s book “Graphs and Geometry”, on geometric representations of graphs</a> (<a href="https://mathstodon.xyz/@11011110/102374639115017977"/>, <a href="https://news.ycombinator.com/item?id=20317825">via</a>). <a href="https://bookstore.ams.org/coll-65">The print version</a> should appear in a month or so from the AMS.</p>
  </li>
  <li>
    <p><a href="https://www.insidehighered.com/quicktakes/2019/06/28/huge-budget-cut-university-alaska">University of Alaska budget gutted by 40%</a> (<a href="https://mathstodon.xyz/@11011110/102381510293748063"/>, <a href="https://www.metafilter.com/181768/We-dont-need-no-stinkin-edumaction">see also</a>). The total amount cut over the past five years (including this new biggest cut) is <a href="https://www.chronicle.com/article/Unprecedented-in-Our/246596">more like 63%, from $522M to $192M</a>. And <a href="https://www.npr.org/2019/07/03/738569508/university-of-alaska-readies-for-budget-slash-we-may-likely-never-recover">the likely response is to close one of its three main campuses and all 13 smaller community campuses</a>. Ironically, the cause is right-wing insistence on a universal basic income of $3000/person from fuel extraction revenues.</p>
  </li>
  <li>
    <p><a href="https://aperiodical.com/category/the-big-internet-math-off/">The annual Big Internet Math-off — view and vote on your favorites!</a> (<a href="https://mathstodon.xyz/@11011110/102385386477969762"/>). 
The first few matches include <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-1-alex-corner-vs-lucy-rycroft-smith/">commutativity of log-exponentiation vs weather infovis</a>, the <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-2-marianne-rachel-vs-vincent-pantaloni/">geometry of the Sydney Opera House vs straight lines on a donut</a>, <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-3-vicky-neale-vs-jim-propp/">multiplication tables and muffins</a> and <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-4-colin-beveridge-vs-kyle-d-evans/">a video on shapes in La Sagrada Familia (shot on location?!) vs an introduction to fractals</a>. More daily for roughly a month.</p>
  </li>
  <li>
    <p><a href="https://www.scmp.com/magazines/post-magazine/long-reads/article/3016267/chinese-scientists-guilty-researching-while">Chinese scientists guilty of “researching while Asian” in Trump’s America</a> (<a href="https://mathstodon.xyz/@11011110/102390640744960409"/>, <a href="https://news.ycombinator.com/item?id=20319936">via</a>, <a href="https://www.bloomberg.com/news/features/2019-06-13/the-u-s-is-purging-chinese-americans-from-top-cancer-research">see also</a>). The story focuses on star cancer researcher <a href="https://en.wikipedia.org/wiki/Xifeng_Wu">Xifeng Wu</a>, forced to resign from the University of Texas, apparently because she fostered collaboration with Chinese cancer research institutions at the behest of her higher administration.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@ccppurcell/102133405425258779">Chris Purcell thinks about graphs with degree sequence </a>. They have to have at least one cycle of each parity.</p>
  </li>
  <li>
    <p><a href="https://petapixel.com/2019/07/05/goodbye-aberration-physicist-solves-2000-year-old-optical-problem/">A formula for designing lenses with no spherical aberration</a> (<a href="https://mathstodon.xyz/@11011110/102401888807980335"/>, <a href="https://news.ycombinator.com/item?id=20369960">via</a>). This seems to have little practical value as there was already a numerical solution, and I don’t think it handles chromatic aberration, but it’s interesting that there is an analytic formula for these shapes.</p>
  </li>
  <li>
    <p>Last week I traveled to Milan for the <a href="https://sgp2019.di.unimi.it/">Symposium on Geometry Processing</a> (<a href="https://mathstodon.xyz/@11011110/102407039766140849"/>). They also have an <a href="https://twitter.com/geometryprocess">official twitter stream</a>, mostly consisting of event photos. The sightseeing highlight of my trip was seeing pages of <a href="https://www.ambrosiana.it/en/discover/codex-atlanticus/">Da Vinci’s Codex Atlanticus at the Ambrosian Library</a>.</p>
  </li>
  <li>
    <p><a href="https://boingboing.net/2019/07/08/check-out-this-cool-synthesize.html">Evoboxx</a> (<a href="https://mathstodon.xyz/@11011110/102412280507996705"/>), a retro-styled portable device that does only two things: run Conway’s Game of Life and generate sounds from it. Not very practical in these days of cell phones but then maybe that’s what makes it a fun project.</p>
  </li>
  <li>
    <p><a href="http://jdh.hamkins.org/modal-model-theory/">Modal model theory</a> (<a href="https://mathstodon.xyz/@11011110/102418646790775178"/>). For graphs, this extends first order logic (where the only quantification is over vertices and the only predicate is adjacency) with operators  and .  is true when all supergraphs model  and  is true when at least one supergraph models . This can express nontrivial graph properties like -colorability, and comes in two variants depending on whether you can quantify outside the operators.</p>
  </li>
  <li>
    <p><a href="https://www.instagram.com/p/ByH-R4Ql-NA/">Very quick video tutorial on how to make the Miura-ori fold</a>, by Polly Verity (<a href="https://mathstodon.xyz/@11011110/102429787082169299"/>, <a href="https://www.thisiscolossal.com/2019/07/new-polly-verity/">via</a>).</p>
  </li>
  <li>
    <p><a href="http://jtra.cz/stuff/essays/math-self-reference-smooth/index.html">Trávník’s smooth self-referential formula</a> (<a href="https://mathstodon.xyz/@11011110/102435762025301458"/>, <a href="https://twitter.com/johncarlosbaez/status/1141376710551601152">via</a>). It is actually a linked set of formulas, described in a typeset image, that when plotted as described in the image produces the image itself. It follows the same ideas as earlier self-referential formulas like <a href="https://en.wikipedia.org/wiki/Tupper%27s_self-referential_formula">Tupper’s self-referential formula</a> but unlike them describes a smooth vector image based on splines instead of a pixelated bitmap.</p>
  </li>
  <li>
    <p><a href="http://muurformules.nl/">Leiden wall formulas</a> (<a href="https://mathstodon.xyz/@11011110/102444110227078604"/>). The last time I was in Leiden they were decorating the exterior walls of all their buildings with poems of many different languages. Now they’ve moved on to the language of mathematics.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=eYfpSAxGakI">Numberphile video on Dehn invariants</a> (15-minutes; <a href="https://mathstodon.xyz/@11011110/102448538574760818"/>). The Dehn invariant is a value derived from a polyhedron that doesn’t change if you cut up the polyhedron into smaller polyhedral pieces and rearrange them into a different polyhedron. It’s 0 for the cube and nonzero for other Platonic solids, proving that they can’t be cut and rearranged into a cube. See <a href="https://en.wikipedia.org/wiki/Dehn_invariant">the Wikipedia article</a> for more technical details.</p>
  </li>
</ul></div>
    </content>
    <updated>2019-07-15T21:57:00Z</updated>
    <published>2019-07-15T21:57:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-07-16T04:58:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=16778</id>
    <link href="https://gilkalai.wordpress.com/2019/07/15/itai-benjamini-and-jeremie-brieussel-noise-sensitivity-meets-group-theory/" rel="alternate" type="text/html"/>
    <title>Itai Benjamini and Jeremie Brieussel: Noise Sensitivity Meets Group Theory</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The final  version of my ICM 2018 paper Three puzzles on mathematics computation and games has been available for some time. (This proceedings’ version, unlike the arXived version has a full list of references.)  In this post I would like to … <a href="https://gilkalai.wordpress.com/2019/07/15/itai-benjamini-and-jeremie-brieussel-noise-sensitivity-meets-group-theory/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The final  version of my ICM 2018 paper <a href="https://gilkalai.files.wordpress.com/2019/07/main-pf.pdf">Three puzzles on mathematics computation and games</a> has been available for some time. (This proceedings’ version, unlike the arXived version has a full list of references.)  In this post I would like to advertise one problem that I mentioned in the paper. You can read more about it in the paper  by Itai Benjamini and  Jeremie Brieussel  <a href="https://arxiv.org/abs/1901.03617">Noise sensitivity of random walks on groups</a> and learn about it also from the videotaped lecture by Jeremie. BTW, the name of my ICM paper is a tribute to Avi Wigdeson’s great book <strong><a href="https://www.math.ias.edu/files/Website03-25-19.pdf#page=1" target="&#x201D;_blank&#x201D;">Mathematics and Computation</a> </strong>(see <a href="https://gilkalai.wordpress.com/2017/10/27/must-read-book-by-avi-wigderson/">this post</a>). Click on the title for an  almost final draft of Avi’s book (March, 25, 2019) soon to be published by Princeton University Press<strong>. </strong>(We are negotiating with Avi on showing here first what the cover of his book will look like.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/friends-of-noise.png"><img alt="" class="alignnone size-full wp-image-17590" height="381" src="https://gilkalai.files.wordpress.com/2019/07/friends-of-noise.png?w=640&amp;h=381" width="640"/></a></p>
<p><a href="http://friendsofnoise.org/about/">source</a></p>
<h2>The problem of Benjamini and Brieussel and their conjecture</h2>
<p> </p>
<p/>
<p>Consider an <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-step simple random walk (SRW) <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/> on a Cayley graph of a finitely generated infinite group <img alt="\Gamma" class="latex" src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Gamma"/>. Refresh independently each step with probability <img alt="\epsilon" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon"/>, to get <img alt="Y_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_n"/> from <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/>. Are there groups for which at time <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/> the positions <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/> and <img alt="Y_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_n"/> are asymptotically independent? That is, does the <img alt="l_1" class="latex" src="https://s0.wp.com/latex.php?latex=l_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="l_1"/> (total variation) distance between the chain <img alt="(X_n, Y_n)" class="latex" src="https://s0.wp.com/latex.php?latex=%28X_n%2C+Y_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(X_n, Y_n)"/> and two independent copies <img alt="(X'_n, X''_n)" class="latex" src="https://s0.wp.com/latex.php?latex=%28X%27_n%2C+X%27%27_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(X'_n, X''_n)"/> go to 0, as <img alt="n \to \infty" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cto+%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n \to \infty"/>?</p>
<p>Note that on the line <img alt="\mathbb Z" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb Z"/>, they are uniformally correlated, and therefore also on any group with a nontrivial homomorphism to <img alt="\mathbb R" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R"/>, or on any group that has a finite index subgroup with a nontrivial homomorphism to <img alt="\mathbb R" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb R"/>. On the free group and for any non-Liouville group, <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/> and <img alt="Y_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_n"/> are correlated as well, but for a different reason: both <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/> and <img alt="Y_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y_n"/> have a nontrivial correlation with <img alt="X_1" class="latex" src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_1"/>.</p>
<p>Itai Benjamini and Jeremie Brieussel conjecture that these are the only ways not to be noise sensitive. That is, if a Cayley graph is Liouville and the group does not have a finite index subgroup with a homomorphism to the reals, then the Cayley graph is noise sensitive for the simple random walk. In particular, the Grigorchuk group is noise sensitive for the simple random walk!</p>
<h3>A paragraph of philosophical nature from Benjamini and Brieussel’s paper.</h3>
<p>“Physically, an <em>ℓ</em><img alt="^1" class="latex" src="https://s0.wp.com/latex.php?latex=%5E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="^1"/>-noise sensitive process can somewhat not be observed, since the observation <img alt="Y^\rho_n" class="latex" src="https://s0.wp.com/latex.php?latex=Y%5E%5Crho_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y^\rho_n"/> does not provide any significant information on the actual output <img alt="X_n" class="latex" src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_n"/>. Speculatively, this could account for the rarity of Liouville groups in natural science. Indeed besides virtually nilpotent ones, all known Liouville groups are genuinely mathematical objects .”</p>
<h3>Polytope integrality gap: An update</h3>
<p>An update on polytope integrality gap:  In my ICM paper and also in <a href="https://gilkalai.wordpress.com/2018/01/21/hardness-of-approximating-vertex-cover-polytope-integrality-gap-the-alswede-kachaterian-theorem-and-more/">this post</a>  I posed the beautiful problem that I learned from Anna Karlin if for vertex cover for every graph G and every vector of weights, there is an efficient algorithm achieving the “polytope integrality gap”.  Anna Karlin kindly informed me that <a href="https://www2.isye.gatech.edu/~msingh94/publications.html">Mohit Singh</a> got in touch with her after seeing the conjecture on my blog and pointed out that the hope for approximating the polytope integrality gap for vertex cover is unlikely to be possible because of its relationship to fractional chromatic number. Mohit noted that fractional chromatic number is hard to approximate even when it is constant assuming UGC. I still think that  the notion of polytope integrality gap for vertex cover as well as for more general problems is important and worth further study.</p>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-07-15T08:13:08Z</updated>
    <published>2019-07-15T08:13:08Z</published>
    <category term="Algebra"/>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Itai Benjamini"/>
    <category term="Jeremie Brieussel"/>
    <category term="Noise-sensitivity"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2019-07-28T23:39:02Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-4254868758435665114</id>
    <link href="https://blog.computationalcomplexity.org/feeds/4254868758435665114/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/two-infinite-hat-problem-and-question.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4254868758435665114" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/4254868758435665114" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/two-infinite-hat-problem-and-question.html" rel="alternate" type="text/html"/>
    <title>Two infinite hat problem and a question about what is ``well known''</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
This is a joint post with David Marcus. You will see how he is involved in my next post.<br/>
<br/>
Two infinite hat problems based on one scenario. I am also curious if they are well known.<br/>
<br/>
1) There are an infinite number of people, numbered 1,2,3,...  There are 2 colors of hats. They can all see everyone's hat but their own. <br/>
<br/>
2) The adversary is going to put hats on all the people. They will guess their own hat color<i> at the same time</i>. <br/>
<br/>
3) The people can discuss strategy ahead of time, but must use a deterministic strategy and the adversary knows the strategy.<br/>
<br/>
4) The people want to minimize how many they get wrong. <br/>
<br/>
5) The adversary puts on hats to maximize how many they get wrong.<br/>
<br/>
I ask two questions  and one meta-question:<br/>
<br/>
Q1: Is there a solution where they get all but a finite number of the guesses right? (I have blogged about a variant of this one a while back.)<br/>
<br/>
Q2: Is there a solution where they get all but at most (say) 18 wrong. (My students would say <i>the answer has to be YES or he</i> <i>wouldn't ask it</i>. They don't realize that I work on upper AND lower bounds!)<br/>
<br/>
Q3: How well known is problem Q1 and the solution?  Q2 and the solution? I've seen Q1 and its solution around (not sure where), but the only source on Q2 that I know of is CAN'T TELL YOU IN THIS POST, WILL IN THE NEXT POST. So, please leave a comment telling me if you have seen Q1 or Q2 and solutions. And if so then where.<br/>
<br/>
Feel free to leave any comments you want; however, I warn readers who want to solve it themselves to not look at the comments, or at my next post.<br/></div>
    </content>
    <updated>2019-07-15T03:12:00Z</updated>
    <published>2019-07-15T03:12:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-28T12:43:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4253</id>
    <link href="https://www.scottaaronson.com/blog/?p=4253" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4253#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4253" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">On two blog posts of Jerry Coyne</title>
    <summary xml:lang="en-US">A few months ago, I got to know Jerry Coyne, the recently-retired biologist at the University of Chicago who writes the blog “Why Evolution Is True.” The interaction started when Jerry put up a bemused post about my thoughts on predictability and free will, and if I pointed out that if he wanted to engage […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>A few months ago, I got to know <a href="https://en.wikipedia.org/wiki/Jerry_Coyne">Jerry Coyne</a>, the recently-retired biologist at the University of Chicago who writes the blog <a href="https://whyevolutionistrue.wordpress.com/">“Why Evolution Is True.”</a>  The interaction started when Jerry put up a <a href="https://whyevolutionistrue.wordpress.com/2019/01/15/a-computer-scientist-finds-the-question-of-free-will-uninteresting-for-bad-reasons/">bemused post about my thoughts on predictability and free will</a>, and if I pointed out that if he wanted to engage me on those topics, there was <a href="https://www.scottaaronson.com/papers/giqtm3.pdf">more to go on</a> than an 8-minute YouTube video.  I told Coyne that it would be a shame to get off on the wrong foot with him, since perusal of his blog made it obvious that whatever he and I disputed, it was dwarfed by our areas of agreement.  He and I exchanged more emails and had lunch in Chicago.</p>



<p>By way of explaining how he hadn’t read <a href="https://www.scottaaronson.com/papers/giqtm3.pdf">“The Ghost in the Quantum Turing Machine,”</a> Coyne emphasized the difference in my and his turnaround times: while these days I update my blog only a couple times per month, Coyne often updates multiple times per <em>day</em>.  Indeed the sheer volume of material he posts, on subjects from biology to culture wars to <a href="https://whyevolutionistrue.wordpress.com/2019/02/27/the-chicago-hot-dog-museum-and-our-wonderful-hot-dogs/">Chicago hot dogs</a>, would take months to absorb.</p>



<p>Today, though, I want to comment on just two posts of Jerry’s.</p>



<p>The <a href="https://whyevolutionistrue.wordpress.com/2019/05/17/computer-scientist-david-gelertner-drinks-the-academic-kool-aid-buys-into-intelligent-design/">first post</a>, from back in May, concerns <a href="https://en.wikipedia.org/wiki/David_Gelernter">David Gelernter</a>, the computer science professor at Yale who was infamously injured in a 1993 attack by the Unabomber, and who’s now mainly known as a right-wing commentator.  I don’t know Gelernter, though I did once attend a small interdisciplinary workshop in the south of France that Gelernter also attended, wherein I gave a talk about quantum computing and computational complexity in which Gelernter showed no interest.  Anyway, Gelernter, in an <a href="https://www.claremont.org/crb/article/giving-up-darwin/">essay in May for the <em>Claremont Review of Books</em></a>, argued that recent work has definitively disproved Darwinism as a mechanism for generating new species, and until something better comes along, Intelligent Design is the best available alternative.</p>



<p>Curiously, I think that Gelernter’s argument falls flat not for detailed reasons of biology, but mostly just because it indulges in <em>bad math and computer science</em>—in fact, in precisely the sorts of arguments that I was trying to answer in <a href="https://www.scottaaronson.com/blog/?p=1487">my segment on Morgan Freeman’s </a><em><a href="https://www.scottaaronson.com/blog/?p=1487">Through the Wormhole</a></em> (see also Section 3.2 of <a href="https://www.scottaaronson.com/papers/philos.pdf">Why Philosophers Should Care About Computational Complexity</a>).  Gelernter says that</p>



<ol><li>a random change to an amino acid sequence will pretty much always make it worse,</li><li>the probability of finding a useful new such sequence by picking one at random is at most ~1 in 10<sup>77</sup>, and</li><li>there have only been maybe ~10<sup>40</sup> organisms in earth’s history.</li></ol>



<p>Since 10<sup>77</sup> &gt;&gt; 10<sup>40</sup>, Darwinism is thereby refuted—not in principle, but as an explanation for life on earth.  QED. </p>



<p>The most glaring hole in the above argument, it seems to me, is that it simply ignores <em>intermediate</em> possible numbers of mutations.  How hard would it be to change, not 1 or 100, but 5 amino acids in a given protein to get a usefully different one—as might happen, for example, with local optimization methods like simulated annealing run at nonzero temperature?  And how many chances were there for <em>that</em> kind of mutation in the earth’s history?</p>



<p>Gelernter can’t personally see how a path could cut through the exponentially large solution space in a polynomial amount of time, so he asserts that it’s impossible.  Many of the would-be P≠NP provers who email me every week do the same.  But this particular kind of “argument from incredulity” has an abysmal track record: it would’ve applied equally well, for example, to problems like maximum matching that turned out to have efficient algorithms.  This is why, in CS, we demand better evidence of hardness—like completeness results or black-box lower bounds—neither of which seem however to apply to the case at hand.  Surely Gelernter understands all this, but had he not, he could’ve learned it from my lecture at the workshop in France!</p>



<p>Alas, online debate, as it’s wont to do, focused less on Gelernter’s actual arguments and the problems with them, than on the tiresome questions of “standing” and “status.”  In particular: does Gelernter’s authority, as a noted computer science professor, somehow lend new weight to Intelligent Design?  Or conversely: does the very fact that a computer scientist endorsed ID prove that computer science itself isn’t a real science at all, and that its practitioners should never be taken seriously in any statements about the real world?</p>



<p>It’s hard to say which of these two questions makes me want to bury my face deeper into my hands.  <a href="https://en.wikipedia.org/wiki/Serge_Lang">Serge Lang</a>, the famous mathematician and textbook author, spent much of his later life fervently denying the connection between HIV and AIDS.  <a href="https://en.wikipedia.org/wiki/Lynn_Margulis">Lynn Margulis</a>, the discoverer of the origin of mitochondria (and Carl Sagan’s first wife), died a 9/11 truther.  What broader lesson should we draw from any of this?  And anyway, what percentage of computer scientists actually do doubt evolution, and how does it compare to the percentage in other academic fields and other professions?  Isn’t the question of how divorced we computer scientists are from the real world an … ahem … <strong>empirical</strong> matter, one hard to answer on the basis of armchair certainties and anecdotes?</p>



<p>Speaking of empiricism, if you check Gelernter’s <a href="https://dblp.uni-trier.de/pers/hd/g/Gelernter:David">publication list on DBLP</a> and his <a href="https://scholar.google.ca/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=david+gelernter&amp;btnG=&amp;oq=david+geler">Google Scholar page</a>, you’ll find that he did influential work in programming languages, parallel computing, and other areas from 1981 through 1997, and then in the past 22 years published a grand total of … <strong>two</strong> papers in computer science.  One with four coauthors, the other a review/perspective piece about his earlier work.  So it seems fair to say that, some time after receiving tenure in a CS department, Gelernter pivoted (to put it mildly) away from CS and toward conservative punditry.  His recent offerings, in case you’re curious, include the book <a href="https://www.amazon.com/America-Lite-Imperial-Academia-Dismantled-Obamacrats/dp/1594036063/ref=sr_1_1?keywords=david+gelernter&amp;qid=1563047627&amp;s=gateway&amp;sr=8-1">America-Lite: How Imperial Academia Dismantled Our Culture (and Ushered In the Obamacrats)</a>.</p>



<p>Some will claim that this case underscores what’s wrong with the tenure system itself, while others will reply that it’s precisely what tenure was designed for, even if in this instance you happen to disagree with what Gelernter uses his tenured freedom to say.  The point I wanted to make is different, though.  It’s that the question “what kind of a field is computer science, anyway, that a guy can do high-level CS research on Monday, and then on Tuesday reject Darwinism and unironically use the word ‘Obamacrat’?”—well, even if I accepted the immense weight this question places on one atypical example (which I don’t), and even if I dismissed the power of compartmentalization (which I again don’t), the question <em>still</em> wouldn’t arise in Gelernter’s case, since getting from “Monday” to “Tuesday” seems to have taken him 15+ years.</p>



<p>Anyway, the second post of Coyne’s that I wanted to talk about is <a href="https://whyevolutionistrue.wordpress.com/2019/07/12/tarring-steve-pinker-and-others-with-jeffrey-epstein/">from just yesterday</a>, and is about Jeffrey Epstein—the financier, science philanthropist, and confessed sex offender, whose appalling crimes you’ll have read all about this week if you weren’t on a long sea voyage without Internet or something.</p>



<p>For the benefit of my many fair-minded friends on Twitter, I should clarify that I’ve never met Jeffrey Epstein, let alone accepted any private flights to his sex island or whatever.  I doubt he has any clue who I am either—even if he did once claim to be <a href="https://web.archive.org/web/20101112131000/http://www.jeffreyepsteinscience.com/2010/10/the-value-of-quantum-computing-to-jeffrey-epstein/">“intrigued”</a> by quantum information.</p>



<p>I do know a few of the scientists who Epstein once hung out with, including Seth Lloyd and Steven Pinker.  Pinker, in particular, is now facing vociferous attacks on Twitter, similar in magnitude perhaps to what I faced in the comment-171 affair, for having been photographed next to Epstein at a 2014 luncheon that was hosted by Lawrence Krauss (a physicist who later faced sexual harassment allegations of his own).  By the evidentiary standards of social media, this photo suffices to convict Pinker as basically a child molester himself, and is <em>also</em> a devastating refutation of any data that Pinker might have adduced in his books about the Enlightenment’s contributions to human flourishing.</p>



<p>From my standpoint, what’s surprising is not that Pinker is up against this, but that it <em>took this long</em> to happen, given that Pinker’s pro-Enlightenment, anti-blank-slate views have had the effect of painting a giant red target on his back.  Despite the near-inevitability, though, you can’t blame Pinker for wanting to defend himself, as I did when it was my turn for the struggle session.</p>



<p>Thus, in response to an emailed inquiry by Jerry Coyne, Pinker shared some detailed reflections about Epstein; Pinker then gave Coyne permission to post those reflections on his blog (though they were originally meant for Coyne only).  Like everything Pinker writes, they’re <a href="https://whyevolutionistrue.wordpress.com/2019/07/12/tarring-steve-pinker-and-others-with-jeffrey-epstein/">worth reading in full</a>.  Here’s the opening paragraph:</p>



<blockquote class="wp-block-quote"><p>The annoying irony is that I could never stand the guy [Epstein], never took research funding from him, and always tried to keep my distance. Friends and colleagues described him to me as a quantitative genius and a scientific sophisticate, and they invited me to salons and coffee klatches at which he held court. But I found him to be a kibitzer and a dilettante — he would abruptly change the subject ADD style, dismiss an observation with an adolescent wisecrack, and privilege his own intuitions over systematic data.</p></blockquote>



<p>Pinker goes on to discuss his record of celebrating, and extensively documenting, the forces of modernity that led to dramatic reductions in violence against women and that have the power to continue doing so.  On Twitter, Pinker had <a href="https://twitter.com/sapinker/status/1149154274787627010">already written</a>: “Needless to say I condemn Epstein’s crimes in the strongest terms.”</p>



<p>I probably should’ve predicted that Pinker would then be attacked again—this time, for having prefaced his condemnation with the phrase “needless to say.”  The argument, as best I can follow, runs like this: given all the isms of which woke Twitter has already convicted Pinker—scientism, neoliberalism, biological determinism, etc.—how could Pinker’s being against Epstein’s crimes (which we recently learned probably include the <a href="https://www.cnn.com/videos/us/2019/07/10/jeffrey-epstein-accuser-speaks-out-today-show-nbc-intv-sot-newday-vpx.cnn">rape</a>, and not only statutorily, of a 15-year-old) <em>possibly</em> be assumed as a given?</p>



<p>For the record, just as Epstein’s friends and enablers weren’t confined to one party or ideology, so the public condemnation of Epstein strikes me as a matter that is (or should be) beyond ideology, with all reasonable dispute now confined to the space between “very bad” and “extremely bad,” between “lock away for years” and “lock away for life.”</p>



<p>While I didn’t need Pinker to tell me <em>that</em>, one reason I personally appreciated his comments is that they helped to answer a question that had bugged me, and that none of the mountains of other condemnations of Epstein had given me a clear sense about.  Namely: supposing, hypothetically, that I’d met Epstein around 2002 or so—without, of course, knowing about his crimes—would I have been as taken with him as many other academics seem to have been?  (Would <em>you</em> have been?  How sure are you?)</p>



<p>Over the last decade, I’ve had the opportunity to meet some titans and semi-titans of finance and business, to discuss quantum computing and other nerdy topics.  For a few (by no means all) of these titans, my overriding impression was <em>precisely</em> their unwillingness to concentrate on any one point for more than about 20 seconds—as though they wanted the crust of a deep intellectual exchange without the meat filling.  My experience with them fit Pinker’s description of Epstein to a T (though I hasten to add that, as far as I know, none of these others ran teenage sex rings).</p>



<p>Anyway, given all the anger at Pinker for having intersected with Epstein, it’s ironic that I could easily imagine Pinker’s comments rattling Epstein the most of anyone’s, if Epstein hears of them from his prison cell.  It’s like: Epstein must have developed a skin like a rhinoceros’s by this point about being called a child abuser, a creep, and a thousand similar (and similarly deserved) epithets.  But “a kibitzer and a dilettante” who merely lured famous intellectuals into his living room, with wads of cash not entirely unlike the ones used to lure teenage girls to his massage table?  Ouch!</p>



<p>OK, but what about Alan Dershowitz—the man who apparently used to be Epstein’s close friend, who still is Pinker’s friend, and who played a crucial role in securing Epstein’s 2008 plea bargain, the one now condemned as a travesty of justice?  I’m not sure how I feel about Dershowitz.  It’s like: I understand that our system requires attorneys willing to mount a vociferous defense even for clients who they privately know or believe to be guilty—and even to get those clients off on technicalities or bargaining whenever they can.  I’m also incredibly grateful that I chose CS rather than law school, because I don’t think I could last an hour advocating causes that I knew to be unjust.  Just like my fellow CS professor, the intelligent design advocate David Gelernter, I have the privilege and the burden of speaking only for myself.</p></div>
    </content>
    <updated>2019-07-13T23:33:12Z</updated>
    <published>2019-07-13T23:33:12Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Nerd Interest"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Obviously I'm Not Defending Aaronson"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2019-07-19T23:00:05Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/07/13/connectivity-finiteness-modal</id>
    <link href="https://11011110.github.io/blog/2019/07/13/connectivity-finiteness-modal.html" rel="alternate" type="text/html"/>
    <title>Connectivity and finiteness in modal graph logic</title>
    <summary>I read with interest Joel David Hamkins’ recent blog post on modal model theory. This week, on a long plane flight home from Italy, I was inspired to play with the modal logic of graphs, in which one describes properties of graphs by simpler properties of their (induced) supergraphs. My interest is less in what this says about set theory and model theory, and more in how expressive this language is: which graph properties can it describe? Joel showed in his post how to describe -colorability in this theory, but I thought it would be of interest to start with something simpler than an -complete problem. And what could be simpler for graphs than testing whether a graph is connected or finite?</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I read with interest Joel David Hamkins’ recent blog post on <a href="http://jdh.hamkins.org/modal-model-theory/">modal model theory</a>.
This week, on a long plane flight home from Italy, I was inspired to play with the modal logic of graphs, in which one describes properties of graphs by simpler properties of their (induced) supergraphs. My interest is less in what this says about set theory and model theory, and more in how expressive this language is: which graph properties can it describe? Joel showed in his post how to describe -colorability in this theory, but I thought it would be of interest to start with something simpler than an -complete problem. And what could be simpler for graphs than testing whether a graph is connected or finite?</p>

<h1 id="the-basics-of-modal-graph-logic">The basics of modal graph logic</h1>

<p><a href="https://en.wikipedia.org/wiki/Modal_logic">Modal logic</a> is a logic of “possible worlds” with two operators on formulas,  (it is possible for  to be true, in at least one possible world) and  (it is necessary for  to be true, in all possible worlds).
Modal graph logic applies this idea to the first-order <a href="https://en.wikipedia.org/wiki/Logic_of_graphs">logic of graphs</a>, in which one can quantify over variables that represent graph vertices and use a binary predicate  representing adjacency of pairs of vertices. I’ll assume here that all graphs are simple and undirected (i.e.,  is irreflexive and commutative). A given graph  models a given first-order formula  (written as ) if the formula becomes true when you evaluate it in the obvious way for the given graph. In the modal logic of graphs, the possible worlds are graphs containing  as an induced subgraph. So  means that it is possible for  to be modeled by one of these larger graphs and  means that it is necessary for  to be modeled by all of these larger graphs. If we apply a modal operator to a formula  that is itself modal, the possible worlds of the modal operators within  are supergraphs of these larger graphs, in the same way (in modal logic terminology, we are assuming S4 accessibility of possible worlds).</p>

<p>In some ways this is enormously powerful: the class of all graphs containing  is so big that it’s not even a set, and it can encode arbitrarily complicated structures. In other ways this is more highly constrained than other graph logics like monadic second-order logic (in which one can describe and quantify sets of vertices or edges, but not more complicated structures like sequences of vertices or strategy trees over games defined on the graph). The issue is that in a possible world, one can’t tell the vertices that were part of the base graph apart from the ones that were added later, except possibly for a finite set of vertices named in variables outside the modal operator. So while the possible worlds that model a given formula can be very large and complicated, it can be difficult to anchor these castles in the air to the base graph that you started with.</p>

<p>Joel’s description of how to express -colorability suggests a path around this difficulty: Suppose we want to test a hereditary property  of graphs (one that extends from any graph to its induced subgraphs) such as colorability. Then we should look for a family of self-verifyingly- graphs: a family of graphs with property  such that membership in the family can be tested by a first-order formula  and such that every graph with property  is an induced subgraph of a larger graph in this family. If we can find such a family and first-order formula , then  will describe property  itself. For instance, for colorability, the self-verifyingly--colorable graphs are graphs in which each color class has a universal vertex, every vertex is adjacent to all but one of the universal vertices, and no two adjacent vertices are both non-adjacent to the same universal vertex.</p>

<p>Similar ideas can also work when the property is not hereditary (for instance, a graph has chromatic number 3 when it is 3-colorable but not 2-colorable) or when checking membership in the family of self-verifying graphs itself involves modal logic (as we’ll see for testing finiteness).</p>

<h1 id="connectivity">Connectivity</h1>

<p>Connectivity is not hereditary: every connected graph is part of a larger disconnected graph and vice versa. But the property that some particular pair of vertices  is separated is hereditary: if  is separated from , the two vertices remain separated in any induced subgraph that contains them both. And while it’s not possible to verify this directly in a first order formula, for all graphs, it is possible in a special family of disconnected graphs, the ones containing a <em>transitive vertex</em>, one whose neighborhood forms a connected component of the graph. We can define a formula</p>



<p>which characterizes these transitive vertices. (Here I am using  to mean syntactic equivalence of formulas or definition of the name of a formula, rather than its meaning in Joel’s post, equivalence of models.) Then we can test whether  is separated from  by the formula</p>



<p>(Here, the instance of “transitive” on the right hand side is not a unary predicate, even though it looks like one; it should be expanded by the definition of the “transitive” formula to produce the resulting “separated” formula. Think of it as being like a C preprocessor macro.)
If  is indeed separated from , there is a possible world modeling the formula, in which we add an extra vertex  to the starting graph, adjacent to everything in the connected component of . And in any possible world modeling the formula,  is separated from , and this must remain true in every induced subgraph of this possible world, including the base graph. Finally, a graph is connected if and only if it has no separated pair:</p>



<p>In MSO logic, one of the standard tools is the <em>method of syntactic interpretations</em>. This allows you to modify your base graph  to form a different graph  (for any of certain standard types of modification) and test whether the resulting graph models a given formula . To do this, you instead modify the formula (in certain purely mechanical ways derived from how you were modifying ) and test whether your original graph models the modified formula . The same thing works in first-order logic and in modal logic, and allows such modifications as adding or removing an edge between given vertices, removing any given vertex, restricting to a logically-specified induced subgraph, or adding a new vertex with a logically-specified adjacency relation. I’ll write  for the modified formula that simulates formula  on the modified graph . We can use this idea to extend connectedness to other properties; for instance, a graph is a forest if it has no cycle, and this is true if every edge removal disconnects it:</p>



<h1 id="finiteness">Finiteness</h1>

<p>Following the earlier outline,
I’d like to find a simple family of finite graphs for which their finiteness is
so obvious that it can be tested by a simple logical formula, and then embed
every finite graph into one of these simple finite graphs.</p>

<p>The first natural choice of such a family is the family of paths.
We can define a path to be a connected graph with exactly two degree-one vertices in which all remaining vertices have degree two. Checking the degrees is first order, but I’ll spare you the messy details of the formula. All such graphs are finite, because a graph is connected if and only if every two vertices are a finite distance apart, and when the endpoints of a path are a finite distance apart there can be only finitely many other degree-two vertices between them. Any other vertices outside of this finite set must belong to a different component.</p>

<p>Not every finite graph can be embedded into a path. However, every finite graph has a perfect matching to the vertices of a path. To check the existence of an induced perfect matching between two sets of vertices in a graph, it’s helpful to have an extra vertex  that is not part of the matching, but that distinguishes one side of the matching (the neighbors of ) from the other side:</p>



<p>Here,  is shorthand for the <a href="https://en.wikipedia.org/wiki/Uniqueness_quantification">existence of exactly one thing</a>. With this test for an induced perfect matching in hand, we can check for a perfect matching to a finite path by</p>



<p>where  denotes the open neighborhood of , the graph induced by the vertices adjacent to .</p>

<p>I don’t think it’s possible to test finiteness in the same way in MSO.
We can define paths in MSO, and force them to have a perfect induced matching to the remaining vertices. But the recipe above breaks down at the point where it embeds the given graph into a supergraph, not generally possible in MSO. More generally I don’t think it’s possible in MSO to distinguish the family of finite complete graphs from their limit, the countable complete graph.</p>

<h1 id="additional-properties">Additional properties</h1>

<p>The same technology of paths and matchings can also be used to formulate not-very-natural properties of finite graphs that are definitely not expressible in MSO. For instance, we can check whether a graph  is the disjoint union of two equal-length paths, by first checking that it is a forest with four degree-one vertices and the rest degree-two, and then checking that both paths can be simultaneously perfectly matched to a third path of remaining vertices (with an additional vertex used to distinguish the sides of the matching as above). When this structure exists, the whole graph forms a polyhedron in the form of a  grid with the sides of the grid connected to the distinguishing vertex, and this polyhedral structure can be used to prove that we cannot trick the formula by adding new paths connecting the original path endpoints. In contrast, MSO cannot express equality of path lengths, because (per <a href="https://en.wikipedia.org/wiki/Courcelle%27s_theorem">Courcelle’s theorem</a>) it can only express properties of path-like graphs that can be expressed as regular languages (over bounded-width path-decompositions of the graph), and equality of length is context-free but not regular for path-decompositions that concatenate the two paths separately.</p>

<p>It’s also possible to express that the <a href="https://en.wikipedia.org/wiki/Degeneracy_(graph_theory)">degeneracy of a graph</a> is at most some constant  in modal logic. As special cases, the graphs of degeneracy zero are the independent sets (first-order expressible) and the graphs of degeneracy one are the forests, which we’ve already seen how to express. Otherwise, we can represent sequences of vertices by <em>ladders</em>, paths of degree-three vertices matched to independent sets of degree-two vertices, with the represented sequence being the other endpoints of these degree-two vertices. Adding a ladder to a graph of degeneracy at least two doesn’t change its degeneracy, and we can express the existence of a degeneracy ordering of a finite graph (a sequence of the vertices such that all vertices have at most  neighbors that are later in the sequence) by the addition of a ladder with a designated starting vertex that touches all non-ladder vertices.
Each non-ladder vertex  should have at most  neighbors with the property that, within the ladder, the ladder vertex nearest  separates the top of the ladder from the ladder vertices nearest these neighbors.</p>

<p>We can <a href="https://11011110.github.io/blog/2019/01/17/orientations-infinite-graphs.html">extend the concept of degeneracy from finite to infinite graphs</a>
by requiring that every finite subgraph have degeneracy at most .
With this definition, we can identify a finite subgraph as the neighbors of a ladder, and then use the formula for finite-graph degeneracy on these neighbors.
This leads to a modal logic expression for infinite graph degeneracy in which the overall structure of the formula is that it is necessary that, whenever a vertex  forms the start of a ladder, it should be possible for there to exist another ladder defining a degeneracy ordering for ’s ladder and its neighbors.</p>

<p>I suspect, although I haven’t worked out all the details, that planarity testing is also expressible in modal logic. Here’s the outline of an idea for proving this. First, we can check that the graph is finite, to avoid complications of which infinite graphs should be considered to be planar or what a drawing of an infinite planar graph might look like. Next, a graph is planar if and only if it is an induced subgraph of a maximal planar graph, one in which all edges belong to exactly two <a href="https://en.wikipedia.org/wiki/Peripheral_cycle">peripheral triangles</a>. A graph with this two-peripheral-triangle property is planar if and only if one can partition its edges into two subsets, one of which forms a spanning tree for the graph and the other of which forms a spanning tree for the dual graph of the peripheral cycles. (The two-peripheral-triangle property defines a surface embedding which, if non-planar, would have some leftover edges that are neither part of a spanning tree nor a complementary dual spanning tree; see my paper “<a href="https://www.ics.uci.edu/~eppstein/pubs/p-dyngen.html">Dynamic generators of topologically embedded graphs</a>”.) And it should be possible to describe this partition in a planarity-preserving way by decorating the edges on one side of the partition by additional small planar graphs (maybe even just attaching a triangle to each decorated edge). So all we need to check is that it’s possible for the given graph to be part of a larger graph
that looks like a maximal planar graph with some decorated edges (ignoring the decorations, each edge belongs to two peripheral triangles) and that the decorations describe a spanning tree and a dual spanning tree. We already know how to describe spanning trees and dual spanning trees should also be possible using similar logic.</p>

<p>One natural and simple property that I don’t see how to express in modal logic is regularity. One can ask: do each two vertices have the same degree? And equality of sets of vertices can be checked by the existence of perfect matchings, as in the two-equal-paths example. But how do we know, in a possible world, which neighbors of two given vertices are original and which are added? For the same reason, the property of having a perfect matching seems difficult to express in modal logic, even though it is easy in MSO. Again, it seems difficult to impose any extra structure on a supergraph without losing too much information about which parts of the graph are original.</p>

<h1 id="standard-and-nonstandard-models">Standard and nonstandard models</h1>

<p>I have been (deliberately) naive here about what kind of set theory I am using to define my graphs, what “all induced supergraphs” means (do I consider graphs only over some set of candidate vertices, or the proper class of all graphs in some set theory), and whether there is always a “correct” value of  that our models of modal graph logic should produce for a given graph and formula. If these naive assumptions are not valid, the description of what these formulas express may be inaccurate.</p>

<p>In particular, the claim that a graph is connected if and only if every two vertices are a finite distance apart uses concepts of distance that go beyond the first-order theory of graphs. In non-standard models of set theory, or in standard models of set theory but with non-standard collections of possible worlds that are not really the collection of all induced supergraphs of a given graph, that claim may fail to be true. In such cases, the finiteness formula may determine that an infinite graph (one that models the first-order logical formulas stating that there exist at least  distinct vertices, for every finite integer ) is finite. It’s not a bug in the formula, just an indication that you need to be careful about your models. Or in computer science terms, <a href="https://en.wikipedia.org/wiki/Garbage_in,_garbage_out">GIGO</a>.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102438063877916451">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-07-13T21:57:00Z</updated>
    <published>2019-07-13T21:57:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-07-16T04:58:02Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16085</id>
    <link href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/" rel="alternate" type="text/html"/>
    <title>Tools and Sensitivity</title>
    <summary>Cutting right through a 30-year-old conjecture Cropped from Emory homepage Hao Huang is a mathematician and computer scientist at Emory University. Last week he released a paper of only six pages that solves the Boolean Sensitivity Conjecture, which goes back at least to a 1992 paper by Noam Nisan and Mario Szegedy. Today we discuss […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>Cutting right through a 30-year-old conjecture</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/haohuangcropped/" rel="attachment wp-att-16086"><img alt="" class="alignright wp-image-16086" height="212" src="https://rjlipton.files.wordpress.com/2019/07/haohuangcropped.jpg?w=148&amp;h=212" width="148"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Emory <a href="http://www.mathcs.emory.edu/~hhuan30/">homepage</a></font></td>
</tr>
</tbody>
</table>
<p>
Hao Huang is a mathematician and computer scientist at Emory University. Last week he released a <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">paper</a> of only six pages that solves the Boolean Sensitivity Conjecture, which goes back at least to a 1992 <a href="https://www.researchgate.net/publication/2508255_On_the_Degree_of_Boolean_Functions_as_Real_Polynomials">paper</a> by Noam Nisan and Mario Szegedy.</p>
<p>
Today we discuss his brilliant proof and what it means for sensitivity of the <em>tools</em> one employs.<br/>
<span id="more-16085"/></p>
<p>
Several of our blogging friends have <a href="https://www.scottaaronson.com/blog/?p=4229">covered</a> this <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">news</a> in <a href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html">posts</a> <a href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/">already</a>, and Ryan O’Donnell even summarized the proof in one <a href="https://twitter.com/BooleanAnalysis/status/1145837576487612416">tweet</a>. Scott Aaronson’s thread includes a <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813116">comment</a> by Huang on how he came by his proof. </p>
<p>
We will try to draw implications for the related matter of how <em>you</em> might come by proofs of <em>other</em> conjectures. We have previously <a href="https://rjlipton.wordpress.com/2016/04/09/missing-mate-in-ten/">discussed</a> the possibility of overlooking short solutions to major problems. Here we will discuss how to <em>find</em> them.</p>
<p>
</p><p/><h2> A Graph Puzzle </h2><p/>
<p/><p>
To get a flavor of what Huang proved, consider the graph of an ordinary <a href="https://commons.wikimedia.org/wiki/File:Cube_graph.png">cube</a>:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph/" rel="attachment wp-att-16087"><img alt="" class="aligncenter wp-image-16087" height="181" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph.png?w=192&amp;h=181" width="192"/></a></p>
<p/><p><br/>
The question is, <em>can you color 5 vertices red so that no red node has 3 red neighbors?</em> Your first impulse might be to color 4 nodes red according to parity so that none has a red neighbor, per below left:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph_tries/" rel="attachment wp-att-16088"><img alt="" class="aligncenter wp-image-16088" height="175" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph_tries.png?w=450&amp;h=175" width="450"/></a></p>
<p/><p><br/>
But then any 5th node will have 3 red neighbors. Another “greedy” idea is to pack a subgraph of the allowed degree 2 into half the cube, as at right. Any 5th node will again create a degree-3 vertex in the subgraph induced by the red nodes.</p>
<p>
The answer is that actually one can pack 6 nodes that induce a simple cycle:</p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph_solved/" rel="attachment wp-att-16089"><img alt="" class="aligncenter wp-image-16089" height="181" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph_solved.png?w=192&amp;h=181" width="192"/></a></p>
<p/><p><br/>
Now let’s up the dimension by one—that is, take <img alt="{n = 4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = 4}"/> and <img alt="{N = 2^n = 16}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+2%5En+%3D+16%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N = 2^n = 16}"/>. How many nodes can we color red and keep the induced degree 2? </p>
<p/><p><br/>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/hypercube_graph/" rel="attachment wp-att-16091"><img alt="" class="aligncenter wp-image-16091" height="230" src="https://rjlipton.files.wordpress.com/2019/07/hypercube_graph-1.png?w=300&amp;h=230" width="300"/></a></p>
<p/><p><br/>
Again the parity trick gives us degree 0 with 8 nodes, but then we can’t add a 9th. We can greedily try to pack the outer cube with our 6-node solution, but then—perhaps surprisingly—we can add only 2 more red nodes from the inner cube. So we can only do 5 from the outer cube. We can get 9 overall by:</p>
<p><a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/hypercube_graph_try10/" rel="attachment wp-att-16092"><img alt="" class="aligncenter wp-image-16092" height="230" src="https://rjlipton.files.wordpress.com/2019/07/hypercube_graph_try10.png?w=300&amp;h=230" width="300"/></a></p>
<p/><p><br/>
The fact that one red node is isolated seems to give room to improve, but there is no way to make 10. </p>
<p>
</p><p/><h2> The Theorem </h2><p/>
<p/><p>
The calculations have left an interesting jump from degree 0 with eight red nodes and degree 2 with nine. How about degree 1? Can we do that with 9 nodes? We can pack four disjoint edges but then there is nowhere to stick an isolated node. </p>
<p>
So for 9 nodes, which is <img alt="{\frac{N}{2} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2} + 1}"/>, the best we can do is degree 2, which is <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. This is what Huang proved:</p>
<blockquote><p><b>Theorem 1</b> <em><a name="graphs"/> Every subgraph induced by <img alt="{\frac{N}{2} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\frac{N}{2} + 1}"/> nodes of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>-dimensional hypercube graph has a node of degree at least <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. </em>
</p></blockquote>
<p/><p>
This is completely tight. When <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is a perfect square there is a way to achieve <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/> as the maximum degree (shown <a href="https://pdfs.semanticscholar.org/3917/3e0cb4e028c94328f1355bf02febea132127.pdf">here</a>). Otherwise the least integer above <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/> is best. Thus every subgraph of the <img alt="{5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{5}"/>-cube induced by 17 nodes has a node with three neighbors, but you can go as high as 257 nodes in the <img alt="{9}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B9%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{9}"/>-cube while keeping the maximum degree to 3.</p>
<p>
We will mention the relation to Boolean sensitivity only briefly. The nodes of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube correspond to truth assignments in <img alt="{\{0,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{0,1\}^n}"/>. Since every red node <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> has <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> neighbors in the cube but at most <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/> red neighbors, the color function is highly sensitive to bitflips. But every flip also changes the parity of <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>. Hence the <em>exclusive-or</em> of the color function with the parity function has <em>low</em> sensitivity. </p>
<p>
But not too low: Huang proved it is at least <img alt="{\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sqrt{n}}"/>. That was enough to prove the conjecture. I’ve cut two sections on Boolean sensitivity from this post’s <a href="https://cse.buffalo.edu/~regan/cse705/wsensitivity.pdf">original draft</a>—let’s just say the connection to the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube and graph degree was known since this 1992 <a href="https://www.sciencedirect.com/science/article/pii/0097316592900608">paper</a>. Here we’ll focus on what it took to prove this theorem.</p>
<p>
</p><p/><h2> The Proof </h2><p/>
<p/><p>
From my undergrad days I’ve kept an interest in spectral graph theory. One of the basic facts is that the degree <img alt="{d(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d(G)}"/> of a graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is always at least as great as the largest eigenvalue <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda}"/> of its adjacency matrix <img alt="{A_G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_G}"/>. For a <img alt="{d}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{d}"/>-regular graph they are equal. Huang’s first trick is to note that the classic proof of this also allows <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> values on edges:</p>
<blockquote><p><b>Lemma 2</b> <em> Let <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A}"/> be a symmetric matrix obtained from <img alt="{A_G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_G%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A_G}"/> by multiplying some entries by <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{-1}"/> and <img alt="{\lambda}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{\lambda}"/> any of its eigenvalues. Then <img alt="{d(G) \geq |\lambda|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29+%5Cgeq+%7C%5Clambda%7C%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{d(G) \geq |\lambda|}"/>. </em>
</p></blockquote>
<p/><p>
<em>Proof:</em>  Choose an eigenvector <img alt="{v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{v}"/> such that <img alt="{Av = \lambda v}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAv+%3D+%5Clambda+v%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{Av = \lambda v}"/> and take an index <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> that maximizes <img alt="{|v_i|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_i%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_i|}"/>. Then </p>
<p align="center"><img alt="\displaystyle  |\lambda v_i| = |(A v)_i| = |\sum_j A_{i,j} v_j| \leq |\sum_j A_{i,j}| \cdot |v_i| \leq \sum_{(i,j) \in E(G)} |A_{i,j}|\cdot |v_i| \leq d(G)|v_i|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5Clambda+v_i%7C+%3D+%7C%28A+v%29_i%7C+%3D+%7C%5Csum_j+A_%7Bi%2Cj%7D+v_j%7C+%5Cleq+%7C%5Csum_j+A_%7Bi%2Cj%7D%7C+%5Ccdot+%7Cv_i%7C+%5Cleq+%5Csum_%7B%28i%2Cj%29+%5Cin+E%28G%29%7D+%7CA_%7Bi%2Cj%7D%7C%5Ccdot+%7Cv_i%7C+%5Cleq+d%28G%29%7Cv_i%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |\lambda v_i| = |(A v)_i| = |\sum_j A_{i,j} v_j| \leq |\sum_j A_{i,j}| \cdot |v_i| \leq \sum_{(i,j) \in E(G)} |A_{i,j}|\cdot |v_i| \leq d(G)|v_i|. "/></p>
<p>Dividing out <img alt="{|v_i|}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7Cv_i%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{|v_i|}"/> gives the lemma. <img alt="\Box" class="latex" src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Box"/></p>
<p/><p><br/>
So now what we want to do is find conditions that force <img alt="{\lambda = \sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda+%3D+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda = \sqrt{n}}"/> when <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is a <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/>-vertex subgraph of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube with <img alt="{m \geq \frac{N}{2} + 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%5Cgeq+%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m \geq \frac{N}{2} + 1}"/>, where <img alt="{N = 2^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N = 2^n}"/>. The trick that Huang realized is that he could do this by making <img alt="{A}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A}"/> sit inside a matrix <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/> with at least <img alt="{\frac{N}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2}}"/> eigenvalues of <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/>. </p>
<p>
To see how, form <img alt="{A_{N-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{N-1}}"/> by knocking out the last row and column of <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>. Since <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/> and <img alt="{A_{N-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_{N-1}}"/> are both real and symmetric, their eigenvalues are real, so we can order them <img alt="{\lambda_1,\dots,\lambda_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1%2C%5Cdots%2C%5Clambda_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_1,\dots,\lambda_N}"/> and <img alt="{\mu_1,\dots,\mu_{N-1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmu_1%2C%5Cdots%2C%5Cmu_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mu_1,\dots,\mu_{N-1}}"/> in nonincreasing order. The basic fact is that they always <em>interlace</em>: </p>
<p align="center"><img alt="\displaystyle  \lambda_1 \geq \mu_1 \geq \lambda_2 \geq \mu_2 \geq \lambda_3 \geq \cdots \geq \mu_{N-1} \geq \lambda_N. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_1+%5Cgeq+%5Cmu_1+%5Cgeq+%5Clambda_2+%5Cgeq+%5Cmu_2+%5Cgeq+%5Clambda_3+%5Cgeq+%5Ccdots+%5Cgeq+%5Cmu_%7BN-1%7D+%5Cgeq+%5Clambda_N.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \lambda_1 \geq \mu_1 \geq \lambda_2 \geq \mu_2 \geq \lambda_3 \geq \cdots \geq \mu_{N-1} \geq \lambda_N. "/></p>
<p>See <a href="https://arxiv.org/pdf/math/0502408.pdf">this</a> for a one-page proof. The neat point is that you can repeat this: if you get <img alt="{A''}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A''}"/> by knocking out another row and corresponding column, and <img alt="{[\nu_i]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B%5Cnu_i%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[\nu_i]}"/> are its eigenvalues in order, then </p>
<p align="center"><img alt="\displaystyle  \mu_1 \geq \nu_1 \geq \mu_2 \geq \nu_2 \geq \mu_3 \cdots. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmu_1+%5Cgeq+%5Cnu_1+%5Cgeq+%5Cmu_2+%5Cgeq+%5Cnu_2+%5Cgeq+%5Cmu_3+%5Ccdots.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mu_1 \geq \nu_1 \geq \mu_2 \geq \nu_2 \geq \mu_3 \cdots. "/></p>
<p>It follows that <img alt="{\lambda_1 \geq \nu_1 \geq \lambda_3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1+%5Cgeq+%5Cnu_1+%5Cgeq+%5Clambda_3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_1 \geq \nu_1 \geq \lambda_3}"/>. If you do this again, you get a matrix whose leading eigenvalue is still at least as big as <img alt="{\lambda_4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_4}"/>. Do it <img alt="{\frac{N}{2} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2} - 1}"/> times inside <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>, and you’re still above <img alt="{\lambda_{N/2}(A_N)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_%7BN%2F2%7D%28A_N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\lambda_{N/2}(A_N)}"/>, which we just said we will arrange to be <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/>. Thus if we knock out the <img alt="{\frac{N}{2} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{N}{2} - 1}"/> white nodes, we will get the graph on the red nodes with adjacency matrix <img alt="{A_m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_m}"/> and conclude: </p>
<p align="center"><img alt="\displaystyle  \lambda_1(A_N) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_1%28A_N%29+%5Cgeq+%5Clambda_1%28A_m%29+%5Cgeq+%5Clambda_%7BN%2F2%7D%28A_N%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \lambda_1(A_N) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) "/></p>
<p>Plugging into the lemma gives: </p>
<p align="center"><img alt="\displaystyle  d(G) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) = \sqrt{n}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d%28G%29+%5Cgeq+%5Clambda_1%28A_m%29+%5Cgeq+%5Clambda_%7BN%2F2%7D%28A_N%29+%3D+%5Csqrt%7Bn%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  d(G) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) = \sqrt{n}. "/></p>
<p>(In fact, as also <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813084">noted</a> on Scott’s blog, this case of interlacing can be inferred from simpler reasoning—but our point is that the interlacing theorem was in Huang’s bag of tricks.) </p>
<p>
</p><p/><h2> Building the Matrix </h2><p/>
<p/><p>
Finally, how do we lay hands on <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>? We want a matrix of trace zero such that <img alt="{A_N^2 = nI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%5E2+%3D+nI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N^2 = nI}"/>. Then all its eigenvalues are <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/> and <img alt="{-\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-\sqrt{n}}"/>.  They come in equal numbers because they sum to the trace which is zero. So we will have <img alt="{N/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N/2}"/> eigenvalues of <img alt="{+\sqrt{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{+\sqrt{n}}"/>, as needed. And we would want <img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/> to be the matrix of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube but that doesn’t work: each <img alt="{i,j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i,j}"/> entry of its square counts all paths of length 2 from node <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> to node <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> and that number can be nonzero.</p>
<p>
This is where the trick of putting <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> on edges comes in, and we can explain it in a way familiar from quantum. We arrange that every 4-cycle of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube has exactly one edge with <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/>. Then the pairs of paths from one corner to the opposite corner will always <em>cancel</em>, leaving <img alt="{A^2_{i,j} = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E2_%7Bi%2Cj%7D+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^2_{i,j} = 0}"/> whenever <img alt="{i \neq j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%5Cneq+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i \neq j}"/>. And <img alt="{A^2_{i,j} = n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%5E2_%7Bi%2Cj%7D+%3D+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A^2_{i,j} = n}"/> because there are <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> ways to go out and come back along the same edge, always contributing <img alt="{1\cdot 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%5Ccdot+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1\cdot 1}"/> or <img alt="{(-1)\cdot(-1) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5Ccdot%28-1%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(-1)\cdot(-1) = 1}"/> either way. Huang defines the needed labeling explicitly by the recursion: </p>
<p align="center"><img alt="\displaystyle  A_2 = \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix},\quad\text{and for } N &gt; 2,\quad A_N = \begin{bmatrix} A_{N/2} &amp; I \\ I &amp; -A_{N/2} \end{bmatrix}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A_2+%3D+%5Cbegin%7Bbmatrix%7D+0+%26+1+%5C%5C+1+%26+0+%5Cend%7Bbmatrix%7D%2C%5Cquad%5Ctext%7Band+for+%7D+N+%3E+2%2C%5Cquad+A_N+%3D+%5Cbegin%7Bbmatrix%7D+A_%7BN%2F2%7D+%26+I+%5C%5C+I+%26+-A_%7BN%2F2%7D+%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  A_2 = \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix},\quad\text{and for } N &gt; 2,\quad A_N = \begin{bmatrix} A_{N/2} &amp; I \\ I &amp; -A_{N/2} \end{bmatrix}. "/></p>
<p>This puts a <img alt="{-}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-}"/> sign on exactly one-fourth of the entries in the needed way. OK, we changed Huang’s subscripts for consistency with “<img alt="{A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N}"/>” above and also to note that the basis could be <img alt="{A_1 = [0]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_1+%3D+%5B0%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_1 = [0]}"/>.  Anyway, he verifies <img alt="{A_N^2 = nI}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_N%5E2+%3D+nI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_N^2 = nI}"/> directly by simple algebra and induction.  That’s it—that’s the proof.</p>
<p>
Why was it hard to spot? Dick and I believe it was the <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> trick. In the 1980s, I thought about ways to convert undirected graphs into directed ones by putting arrows on the edges, but not <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> signs. The chance of thinking of it maybe rises with knowing quantum ideas such as interference and amplification. Now we can see, OK, <img alt="{A_2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_2}"/> is the quantum NOT gate and the recursion treats signs in similar fashion to the recursion defining Hadamard matrices.  The matrix <img alt="{\frac{1}{\sqrt{n}}A_N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7DA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{1}{\sqrt{n}}A_N}"/> is unitary, so it defines a quantum operator. This all goes to our main point about having tools at one’s command—the more tools, the better. </p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Huang’s theorem still leaves a gap between a quadratic lower bound and his 4th-power upper bound (my longer <a href="https://cse.buffalo.edu/~regan/cse705/wsensitivity.pdf">draft</a> lays this out).  Can this gap be closed?  In discussing this, Huang notes that his spectral methods need not be confined to sub-matrices of the <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>-cube, and our thoughts of involving quantum are similar. Can quantum tools improve the results even further?</p>
<p/></font></font></div>
    </content>
    <updated>2019-07-12T10:51:42Z</updated>
    <published>2019-07-12T10:51:42Z</published>
    <category term="algorithms"/>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="Teaching"/>
    <category term="trick"/>
    <category term="Boolean functions"/>
    <category term="Boolean sensitivity conjecture"/>
    <category term="complexity"/>
    <category term="concrete complexity"/>
    <category term="eigenvalues"/>
    <category term="Hao Huang"/>
    <category term="linear algebra"/>
    <category term="matrices"/>
    <category term="quantum"/>
    <category term="spectral methods"/>
    <category term="tricks"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2019-07-28T23:39:11Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1705625191398821823</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1705625191398821823/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/degree-and-sensitivity.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1705625191398821823" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1705625191398821823" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/degree-and-sensitivity.html" rel="alternate" type="text/html"/>
    <title>Degree and Sensitivity</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Hao Huang's <a href="https://arxiv.org/abs/1907.00847">proof of the sensitivity conjecture</a> that I <a href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html">posted on last week</a> relied on a 1992 <a href="https://doi.org/10.1016/0097-3165(92)90060-8">result of Gotsman and Linial</a>. Let's talk about that result.<br/>
<br/>
Consider the set S={-1,1}<sup>n</sup>. The hypercube of dimension n is the graph with vertex set S and an edge between x = (x<sub>1</sub>,…,x<sub>n</sub>) and y = (y<sub>1</sub>,…,y<sub>n</sub>) in S if there is exactly one i such that x<sub>i</sub> ≠ y<sub>i</sub>. Every vertex has degree n.<br/>
<br/>
We say a vertex x is odd if x has an odd number of -1 coordinates, even otherwise. Every edge joins an odd and even vertex.<br/>
<br/>
Let f be a function mapping S to {-1,1}. The sensitivity of f on x is the number of i such that f(x<sub>1</sub>,…,x<sub>i</sub>,…,x<sub>n</sub>) ≠ f(x<sub>1</sub>,…,-x<sub>i</sub>,…,x<sub>n</sub>). The sensitivity of f is the maximum over all x in S of the sensitivity of f on x.<br/>
<br/>
Let g be the same function as f except that we flip the value on all odd vertices. Notice now that the sensitivity of f on x is the number of i such that g(x<sub>1</sub>,…,x<sub>i</sub>,…,x<sub>n</sub>) = g(x<sub>1</sub>,…,-x<sub>i</sub>,…,x<sub>n</sub>).<br/>
<br/>
Let G be the induced subgraph of vertices of x such that g(x)=-1 and H be induced subgraph on the set of x such that g(x)=1. The sensitivity of f is the maximum number of neighbors of any vertex in G or H.<br/>
<br/>
Consider f as a multilinear polynomial over the reals. The sensitivity conjecture states there is some α&gt;0 such that if f has degree n then f has sensitivity at least n<sup>α</sup>.<br/>
<br/>
Note g(x<sub>1</sub>,…,x<sub>n</sub>)=f(x<sub>1</sub>,…,x<sub>n</sub>)x<sub>1</sub>⋯x<sub>n</sub>. If f has a degree n term, the variables in that term cancel out on S (since x<sub>i</sub><sup>2</sup>=1) and the constant of the degree n term of f becomes the constant term of g. The constant term is just the expected value, so f has full degree iff g is unbalanced.<br/>
<br/>
GL Assumption: Suppose you have a partition of the hypercube into sets A and B with |A| ≠ |B|, and let G and H be the induced subgraphs of A and B. Then there is some constant α&gt;0 such that there is a node of A or B with at least n<sup>α</sup> neighbors.<br/>
<br/>
The above argument, due to Gotsman and Linial, shows that the GL assumption is equivalent to the sensitivity conjecture.<br/>
<br/>
Huang proved that given any subset A of the vertices of a hypercube with |A|&gt;2<sup>n</sup>/2 the induced subgraph has a node of degree at least n<sup>1/2</sup>. Since either A or B in the GL assumption has size greater than 2<sup>n</sup>/2, Huang's result gives the sensitivity conjecture.</div>
    </content>
    <updated>2019-07-11T17:54:00Z</updated>
    <published>2019-07-11T17:54:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-28T12:43:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=656</id>
    <link href="https://emanueleviola.wordpress.com/2019/07/10/non-abelian-combinatorics-and-communication-complexity/" rel="alternate" type="text/html"/>
    <title>Non-abelian combinatorics and communication complexity</title>
    <summary>Below and here in pdf is a survey I am writing for SIGACT, due next week.  Comments would be very helpful. Finite groups provide an amazing wealth of problems of interest to complexity theory. And complexity theory also provides a useful viewpoint of group-theoretic notions, such as what it means for a group to be […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Below and <a href="http://www.ccs.neu.edu/home/viola/papers/viola-sigact-snafu.pdf">here in pdf</a> is a survey I am writing for SIGACT, due next week.  Comments would be very helpful.</p>
<hr/>
<p style="text-align: justify;">Finite groups provide an amazing wealth of problems of interest to complexity theory. And complexity theory also provides a useful viewpoint of group-theoretic notions, such as what it means for a group to be “far from abelian.” The general problem that we consider in this survey is that of computing a <em>group product</em> <img alt="g=x_{1}\cdot x_{2}\cdot \cdots \cdot x_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3Dx_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+%5Ccdots+%5Ccdot+x_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=x_{1}\cdot x_{2}\cdot \cdots \cdot x_{n}"/> over a finite group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. Several variants of this problem are considered in this survey and in the literature, including in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XKrohnMR66">KMR66</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBarrington89">Bar89</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBen-OrC92">BC92</a>, <a href="https://emanueleviola.wordpress.com/feed/#XImmermanL95">IL95</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBGKL03">BGKL03</a>, <a href="https://emanueleviola.wordpress.com/feed/#XPRS97">PRS97</a>, <a href="https://emanueleviola.wordpress.com/feed/#XAmbainis96">Amb96</a>, <a href="https://emanueleviola.wordpress.com/feed/#XAmbainisL00">AL00</a>, <a href="https://emanueleviola.wordpress.com/feed/#XRaz00">Raz00</a>, <a href="https://emanueleviola.wordpress.com/feed/#XMilesV-leak">MV13</a>, <a href="https://emanueleviola.wordpress.com/feed/#XMiles14">Mil14</a>, <a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>.</p>
<p style="text-align: justify;">Some specific, natural computational problems related to <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> are, from hardest to easiest:</p>
<p style="text-align: justify;">(1) Computing <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/>,</p>
<p style="text-align: justify;">(2) Deciding if <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/>, where <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/> is the identity element of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>, and</p>
<p style="text-align: justify;">(3) Deciding if <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/> under the promise that either <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/> or <img alt="g=h" class="latex" src="https://s0.wp.com/latex.php?latex=g%3Dh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=h"/> for a fixed <img alt="h\ne 1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cne+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\ne 1_{G}"/>.</p>
<p style="text-align: justify;">Problem (3) is from <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMilesV-leak">MV13</a>]</span>. The focus of this survey is on (2) and (3).</p>
<p style="text-align: justify;">We work in the model of <em>communication complexity </em><span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XYao79">Yao79</a>]</span>, with which we assume familiarity. For background see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XKuN97">KN97</a>, <a href="https://emanueleviola.wordpress.com/feed/#XRaoY2019">RY19</a>]</span>. Briefly, the terms <img alt="x_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i}"/> in a product <img alt="x_{1}\cdot x_{2}\cdot \cdots \cdot x_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+%5Ccdots+%5Ccdot+x_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot x_{2}\cdot \cdots \cdot x_{n}"/> will be partitioned among collaborating parties – in several ways – and we shall bound the number of bits that the parties need to exchange to solve the problem.</p>
<p style="text-align: justify;"><b>Organization</b>.</p>
<p style="text-align: justify;">We begin in Section <a href="https://emanueleviola.wordpress.com/feed/#x1-20002">2<!--tex4ht:ref: sec:Two-parties --></a> with two-party communication complexity. In Section <a href="https://emanueleviola.wordpress.com/feed/#x1-30003">3<!--tex4ht:ref: sec:Proof-of-Gowers-Viola --></a> we give a streamlined proof, except for a step that is only sketched, of a result of Gowers and the author <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int">GV15</a>, <a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-2">GVb</a>]</span> about interleaved group products. In particular we present an alternative proof, communicated to us by Will Sawin, of a lemma from <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. We then consider two models of three-party communication. In Section <a href="https://emanueleviola.wordpress.com/feed/#x1-70004">4<!--tex4ht:ref: sec:Three-parties,-number-in-hand --></a> we consider number-in-hand protocols, and we relate the communication complexity to so-called <em>quasirandom groups</em> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBabaiNP08">BNP08</a>]</span>. In Section <a href="https://emanueleviola.wordpress.com/feed/#x1-140006">6<!--tex4ht:ref: sec:Three-parties,-number-on-forehea --></a> we consider number-in-hand protocols, and specifically the problem of separating deterministic and randomized communication. In Section <a href="https://emanueleviola.wordpress.com/feed/#x1-150007">7<!--tex4ht:ref: sec:The-corners-theorem --></a> we give an exposition of a result by Austin <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAustin2016">Aus16</a>]</span>, and show that it implies a separation that matches the state-of-the-art <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XBeameDPW10">BDPW10</a>]</span> but applies to a different problem.</p>
<p style="text-align: justify;">Some of the sections follow closely a set of lectures by the author <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#Xviola-special-topics17">Vio17</a>]</span>; related material can also be found in the blog posts <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#Xviola-blog-mixing-in-groups">Vioa</a>, <a href="https://emanueleviola.wordpress.com/feed/#Xviola-blog-mixing-in-groups-ii">Viob</a>]</span>. One of the goals of this survey is to present this material in a more organized matter, in addition to including new material.</p>
<h3 class="sectionHead"><span class="titlemark">2 </span> <a id="x1-20002"/>Two parties</h3>
<p style="text-align: justify;">Let <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> be a group and let us start by considering the following basic communication task. Alice gets an element <img alt="x\in G" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in G"/> and Bob gets an element <img alt="y\in G" class="latex" src="https://s0.wp.com/latex.php?latex=y%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y\in G"/> and their goal is to check if <img alt="x\cdot y=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y=1_{G}"/>. How much communication do they need? Well, <img alt="x\cdot y=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y=1_{G}"/> is equivalent to <img alt="x=y^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Dy%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=y^{-1}"/>. Because Bob can compute <img alt="y^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=y%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y^{-1}"/> without communication, this problem is just a rephrasing of the <em>equality</em> problem, which has a randomized protocol with constant communication. This holds for any group.</p>
<p style="text-align: justify;">The same is true if Alice gets two elements <img alt="x_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}"/> and <img alt="x_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{2}"/> and they need to check if <img alt="x_{1}\cdot y\cdot x_{2}=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y%5Ccdot+x_%7B2%7D%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot y\cdot x_{2}=1_{G}"/>. Indeed, it is just checking equality of <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> and <img alt="x_{1}^{-1}\cdot x_{2}^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5E%7B-1%7D%5Ccdot+x_%7B2%7D%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}^{-1}\cdot x_{2}^{-1}"/>, and again Alice can compute the latter without communication.</p>
<p style="text-align: justify;">Things get more interesting if both Alice and Bob get two elements and they need to check if the <em>interleaved product</em> of the elements of Alice and Bob equals <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/>, that is, if</p>
<div style="text-align: center;"><img alt="\begin{aligned} x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}=1_{G}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D%3D1_%7BG%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}=1_{G}. \end{aligned}"/></div>
<p style="text-align: justify;">Now the previous transformations don’t help anymore. In fact, the complexity depends on the group. If it is abelian then the elements can be reordered and the problem is equivalent to checking if <img alt="(x_{1}\cdot x_{2})\cdot (y_{1}\cdot y_{2})=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%28x_%7B1%7D%5Ccdot+x_%7B2%7D%29%5Ccdot+%28y_%7B1%7D%5Ccdot+y_%7B2%7D%29%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x_{1}\cdot x_{2})\cdot (y_{1}\cdot y_{2})=1_{G}"/>. Again, Alice can compute <img alt="x_{1}\cdot x_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+x_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot x_{2}"/> without communication, and Bob can compute <img alt="y_{1}\cdot y_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B1%7D%5Ccdot+y_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{1}\cdot y_{2}"/> without communication. So this is the same problem as before and it has a constant communication protocol.</p>
<p style="text-align: justify;">For non-abelian groups this reordering cannot be done, and the problem seems hard. This can be formalized for a class of groups that are “far from abelian” – or we can take this result as a definition of being far from abelian. One of the groups that works best in this sense is the following, first constructed by Galois in the 1830’s.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-2001r1"/> Definition 1. </span>The<em> special linear group </em><img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/> is the group of <img alt="2\times 2" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ctimes+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2\times 2"/> invertible matrices over the field <img alt="\mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{F} _{q}"/> with determinant <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">The following result was asked in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMilesV-leak">MV13</a>]</span> and was proved in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. <a id="x1-2002r1"/></p>
<p style="text-align: justify;"><b>Theorem 1.</b> Let <img alt="G=SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DSL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=SL(2,q)"/> and let <img alt="h\ne 1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cne+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\ne 1_{G}"/>. Suppose Alice receives <img alt="x_{1},x_{2}\in G" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1},x_{2}\in G"/> and Bob receives <img alt="y_{1},y_{2}\in G" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B1%7D%2Cy_%7B2%7D%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{1},y_{2}\in G"/>. They are promised that <img alt="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}"/> either equals <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/> or <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/>. Deciding which case it is requires randomized communication <img alt="\Omega (\log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log |G|)"/>.</p>
<p style="text-align: justify;">This bound is tight as Alice can send her input, taking <img alt="O(\log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\log |G|)"/> bits. We present the proof of this theorem in the next section.</p>
<p style="text-align: justify;">Similar results are known for other groups as well, see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span> and <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XShalev16">Sha16</a>]</span>. For example, one group that is “between” abelian groups and <img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/> is the following.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-2003r2"/> Definition 2. </span>The<em> alternating group</em> <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/> is the group of even permutations of <img alt="1,2,\ldots ,n" class="latex" src="https://s0.wp.com/latex.php?latex=1%2C2%2C%5Cldots+%2Cn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1,2,\ldots ,n"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">If we work over <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/> instead of <img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/> in Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a> then the communication complexity is <img alt="\Omega (\log \log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log \log |G|)"/> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XShalev16">Sha16</a>]</span>. The latter bound is tight <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMilesV-leak">MV13</a>]</span>: with knowledge of <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/>, the parties can agree on an element <img alt="a\in {1,2,\ldots ,n}" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Cin+%7B1%2C2%2C%5Cldots+%2Cn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\in {1,2,\ldots ,n}"/> such that <img alt="h(a)\ne a" class="latex" src="https://s0.wp.com/latex.php?latex=h%28a%29%5Cne+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h(a)\ne a"/>. Hence they only need to keep track of the image <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/>. This takes communication <img alt="O(\log n)=O(\log \log |A_{n}|)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clog+n%29%3DO%28%5Clog+%5Clog+%7CA_%7Bn%7D%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\log n)=O(\log \log |A_{n}|)"/> because <img alt="|A_{n}|=n!/2." class="latex" src="https://s0.wp.com/latex.php?latex=%7CA_%7Bn%7D%7C%3Dn%21%2F2.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|A_{n}|=n!/2."/> In more detail, the protocol is as follows. First Bob sends <img alt="y_{2}(a)" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B2%7D%28a%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{2}(a)"/>. Then Alice sends <img alt="x_{2}y_{2}(a)" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B2%7Dy_%7B2%7D%28a%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{2}y_{2}(a)"/>. Then Bob sends <img alt="y_{1}x_{2}y_{2}(a)" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B1%7Dx_%7B2%7Dy_%7B2%7D%28a%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{1}x_{2}y_{2}(a)"/> and finally Alice can check if <img alt="x_{1}y_{1}x_{2}y_{2}(a)=a" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7Dy_%7B1%7Dx_%7B2%7Dy_%7B2%7D%28a%29%3Da&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}y_{1}x_{2}y_{2}(a)=a"/>.</p>
<p style="text-align: justify;">Interestingly, to decide if <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/> without the promise a stronger lower bound can be proved for many groups, including <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/>, see Corollary <a href="https://emanueleviola.wordpress.com/feed/#x1-2006r3">3<!--tex4ht:ref: cor:A_n-bound --></a> below.</p>
<p style="text-align: justify;">In general, it seems an interesting open problem to try to understand for which groups Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a> applies. For example, is the communication large for every quasirandom group <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>]</span>?</p>
<p style="text-align: justify;">Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a> and the corresponding results for other groups also scale with the length of the product: for example deciding if <img alt="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}\cdots x_{n}\cdot y_{n}=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D%5Ccdots+x_%7Bn%7D%5Ccdot+y_%7Bn%7D%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}\cdots x_{n}\cdot y_{n}=1_{G}"/> over <img alt="G=SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DSL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=SL(2,q)"/> requires communication <img alt="\Omega (n\log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n\log |G|)"/> which is tight.</p>
<p style="text-align: justify;">A strength of the above results is that they hold for any choice of <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> in the promise. This makes them equivalent to certain <img alt="mixing" class="latex" src="https://s0.wp.com/latex.php?latex=mixing&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="mixing"/> results, discussed below in Section <a href="https://emanueleviola.wordpress.com/feed/#x1-120005.0.1">5.0.1<!--tex4ht:ref: subsec:-mixing --></a>. Next we prove two other lower bounds that do not have this property and can be obtained by reduction from <em>disjointness</em>. First we show that for any non-abelian group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> there exists an element <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> such that deciding if <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/> or <img alt="g=h" class="latex" src="https://s0.wp.com/latex.php?latex=g%3Dh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=h"/> requires communication linear in the length of the product. Interestingly, the proof works for any non-abelian group. The choice of <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> is critical, as for some <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> and <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> the problem is easy. For example: take any group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> and consider <img alt="H:=G\times \mathbb {Z}_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=H%3A%3DG%5Ctimes+%5Cmathbb+%7BZ%7D_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H:=G\times \mathbb {Z}_{2}"/> where <img alt="\mathbb {Z}_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BZ%7D_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {Z}_{2}"/> is the group of integers with addition modulo <img alt="2" class="latex" src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2"/>. Distinguishing between <img alt="1_{H}=(1_{G},0)" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BH%7D%3D%281_%7BG%7D%2C0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{H}=(1_{G},0)"/> and <img alt="h=(1_{G},1)" class="latex" src="https://s0.wp.com/latex.php?latex=h%3D%281_%7BG%7D%2C1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h=(1_{G},1)"/> amounts to computing the parity of (the <img alt="\mathbb {Z}_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BZ%7D_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {Z}_{2}"/> components of) the input, which takes constant communication. <a id="x1-2004r2"/></p>
<p style="text-align: justify;"><b>Theorem 2.</b> Let <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> be a non-abelian group. There exists <img alt="h\in G" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\in G"/> such that the following holds. Suppose Alice receives <img alt="x_{1},x_{2},\ldots ,x_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1},x_{2},\ldots ,x_{n}"/> and receives <img alt="y_{1},y_{2},\ldots ,y_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B1%7D%2Cy_%7B2%7D%2C%5Cldots+%2Cy_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{1},y_{2},\ldots ,y_{n}"/>. They are promised that <img alt="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}\cdot \cdots \cdot x_{n}\cdot y_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D%5Ccdot+%5Ccdots+%5Ccdot+x_%7Bn%7D%5Ccdot+y_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}\cdot \cdots \cdot x_{n}\cdot y_{n}"/> either equals <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/> or <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/>. Deciding which case it is requires randomized communication <img alt="\Omega (n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n)"/>.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We reduce from <em>unique set-disjointness</em>, defined below. For the reduction we encode the And of two bits <img alt="s,t\in \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=s%2Ct%5Cin+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s,t\in \{0,1\}"/> as a group product. This encoding is similar to the famous puzzle that asks to hang a picture on a wall with two nails in such a way that the picture falls if either one of the nails is removed. Since <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> is non-abelian, there exist <img alt="a,b\in G" class="latex" src="https://s0.wp.com/latex.php?latex=a%2Cb%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a,b\in G"/> such that <img alt="a\cdot b\neq b\cdot a" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+b%5Cneq+b%5Ccdot+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot b\neq b\cdot a"/>, and in particular <img alt="a\cdot b\cdot a^{-1}\cdot b^{-1}=h" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+b%5Ccdot+a%5E%7B-1%7D%5Ccdot+b%5E%7B-1%7D%3Dh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot b\cdot a^{-1}\cdot b^{-1}=h"/> with <img alt="h\neq 1" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cneq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\neq 1"/>. We can use this fact to encode the And of <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> and <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> as</p>
<div style="text-align: center;"><img alt="\begin{aligned} a^{s}\cdot b^{t}\cdot a^{-s}\cdot b^{-t}=\begin {cases} 1~~\text {if And\ensuremath {(s,t)=0}}\\ h~~\text {otherwise} \end {cases}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a%5E%7Bs%7D%5Ccdot+b%5E%7Bt%7D%5Ccdot+a%5E%7B-s%7D%5Ccdot+b%5E%7B-t%7D%3D%5Cbegin+%7Bcases%7D+1%7E%7E%5Ctext+%7Bif+And%5Censuremath+%7B%28s%2Ct%29%3D0%7D%7D%5C%5C+h%7E%7E%5Ctext+%7Botherwise%7D+%5Cend+%7Bcases%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} a^{s}\cdot b^{t}\cdot a^{-s}\cdot b^{-t}=\begin {cases} 1~~\text {if And\ensuremath {(s,t)=0}}\\ h~~\text {otherwise} \end {cases}. \end{aligned}"/></div>
<p style="text-align: justify;">In the disjointness problem Alice and Bob get inputs <img alt="x,y\in \{0,1\}^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in \{0,1\}^{n}"/> respectively, and they wish to check if there exists an <img alt="i\in [n]" class="latex" src="https://s0.wp.com/latex.php?latex=i%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i\in [n]"/> such that <img alt="x_{i}\land y_{i}=1" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D%5Cland+y_%7Bi%7D%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i}\land y_{i}=1"/>. If you think of <img alt="x,y" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y"/> as characteristic vectors of sets, this problem is asking if the sets have a common element or not. The communication of this problem is <img alt="\Omega (n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n)"/> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XKalyanasundaramS92">KS92</a>, <a href="https://emanueleviola.wordpress.com/feed/#XRazborov92">Raz92</a>]</span>. Moreover, in the “unique” variant of this problem where the number of such <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>’s is 0 or 1, the same lower bound <img alt="\Omega (n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n)"/> still applies. This follows from <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XKalyanasundaramS92">KS92</a>, <a href="https://emanueleviola.wordpress.com/feed/#XRazborov92">Raz92</a>]</span> – see also Proposition 3.3 in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAMS99">AMS99</a>]</span>. For more on disjointness see the surveys <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XSherstov14-35years">She14</a>, <a href="https://emanueleviola.wordpress.com/feed/journals/sigact/ChattopadhyayP10">CP10</a>]</span>.</p>
<p style="text-align: justify;">We will reduce unique disjointness to group products. For <img alt="x,y\in \{0,1\}^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in \{0,1\}^{n}"/> we produce inputs for the group problem as follows:</p>
<div style="text-align: center;"><img alt="\begin{aligned} x &amp; \rightarrow (a^{x_{1}},a^{-x_{1}},\ldots ,a^{x_{n}},a^{-x_{n}})\\ y &amp; \rightarrow (b^{y_{1}},b^{-y_{1}},\ldots ,b^{y_{n}},b^{-y_{n}}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x+%26+%5Crightarrow+%28a%5E%7Bx_%7B1%7D%7D%2Ca%5E%7B-x_%7B1%7D%7D%2C%5Cldots+%2Ca%5E%7Bx_%7Bn%7D%7D%2Ca%5E%7B-x_%7Bn%7D%7D%29%5C%5C+y+%26+%5Crightarrow+%28b%5E%7By_%7B1%7D%7D%2Cb%5E%7B-y_%7B1%7D%7D%2C%5Cldots+%2Cb%5E%7By_%7Bn%7D%7D%2Cb%5E%7B-y_%7Bn%7D%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x &amp; \rightarrow (a^{x_{1}},a^{-x_{1}},\ldots ,a^{x_{n}},a^{-x_{n}})\\ y &amp; \rightarrow (b^{y_{1}},b^{-y_{1}},\ldots ,b^{y_{n}},b^{-y_{n}}). \end{aligned}"/></div>
<p style="text-align: justify;">The group product becomes</p>
<div style="text-align: center;"><img alt="\begin{aligned} \underbrace {a^{x_{1}}\cdot b^{y_{1}}\cdot a^{-x_{1}}\cdot b^{-y_{1}}}_{\text {1 bit}}\cdots \cdots a^{x_{n}}\cdot b^{y_{n}}\cdot a^{-x_{n}}\cdot b^{-y_{n}}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cunderbrace+%7Ba%5E%7Bx_%7B1%7D%7D%5Ccdot+b%5E%7By_%7B1%7D%7D%5Ccdot+a%5E%7B-x_%7B1%7D%7D%5Ccdot+b%5E%7B-y_%7B1%7D%7D%7D_%7B%5Ctext+%7B1+bit%7D%7D%5Ccdots+%5Ccdots+a%5E%7Bx_%7Bn%7D%7D%5Ccdot+b%5E%7By_%7Bn%7D%7D%5Ccdot+a%5E%7B-x_%7Bn%7D%7D%5Ccdot+b%5E%7B-y_%7Bn%7D%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \underbrace {a^{x_{1}}\cdot b^{y_{1}}\cdot a^{-x_{1}}\cdot b^{-y_{1}}}_{\text {1 bit}}\cdots \cdots a^{x_{n}}\cdot b^{y_{n}}\cdot a^{-x_{n}}\cdot b^{-y_{n}}. \end{aligned}"/></div>
<p style="text-align: justify;">If there isn’t an <img alt="i\in [n]" class="latex" src="https://s0.wp.com/latex.php?latex=i%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i\in [n]"/> such that <img alt="x_{i}\land y_{i}=1" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D%5Cland+y_%7Bi%7D%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i}\land y_{i}=1"/>, then for each <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> the term <img alt="a^{x_{i}}\cdot b^{y_{i}}\cdot a^{-x_{i}}\cdot b^{-y_{i}}" class="latex" src="https://s0.wp.com/latex.php?latex=a%5E%7Bx_%7Bi%7D%7D%5Ccdot+b%5E%7By_%7Bi%7D%7D%5Ccdot+a%5E%7B-x_%7Bi%7D%7D%5Ccdot+b%5E%7B-y_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a^{x_{i}}\cdot b^{y_{i}}\cdot a^{-x_{i}}\cdot b^{-y_{i}}"/> is <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/>, and thus the whole product is 1.</p>
<p style="text-align: justify;">Otherwise, there exists a unique <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> such that <img alt="x_{i}\land y_{i}=1" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D%5Cland+y_%7Bi%7D%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i}\land y_{i}=1"/> and thus the product will be <img alt="1\cdots 1\cdot h\cdot 1\cdots 1=h" class="latex" src="https://s0.wp.com/latex.php?latex=1%5Ccdots+1%5Ccdot+h%5Ccdot+1%5Ccdots+1%3Dh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1\cdots 1\cdot h\cdot 1\cdots 1=h"/>, with <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> being in the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>-th position. If Alice and Bob can check if the above product is equal to 1, they can also solve the unique set disjointness problem, and thus the lower bound applies for the former. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">We required the uniqueness property, because otherwise we might get a product <img alt="h^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=h%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h^{c}"/> that could be equal to 1 in some groups.</p>
<p style="text-align: justify;">Next we prove a result for products of length just <img alt="4" class="latex" src="https://s0.wp.com/latex.php?latex=4&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="4"/>; it applies to non-abelian groups of the form <img alt="G=H^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DH%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=H^{n}"/> and not with the promise. <a id="x1-2005r3"/></p>
<p style="text-align: justify;"><b>Theorem 3.</b> Let <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="H"/> be a non-abelian group and consider <img alt="G=H^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DH%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=H^{n}"/>. Suppose Alice receives <img alt="x_{1},x_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1},x_{2}"/> and Bob receives <img alt="y_{1},y_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=y_%7B1%7D%2Cy_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y_{1},y_{2}"/>. Deciding if <img alt="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}=1_{G}"/> requires randomized communication <img alt="\Omega (n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n)"/>.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>The proof is similar to the proof of Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2004r2">2<!--tex4ht:ref: thm:for-every-non-abelian --></a>. We use coordinate <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> to encode bit <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> of the disjointness instance. If there is no intersection in the latter, the product will be <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/>. Otherwise, at least some coordinate will be <img alt="\ne 1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cne+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ne 1_{G}"/>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">As a corollary we can prove a lower bound for <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/>.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-2006r3"/> Corollary 3. </span>Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2005r3">3<!--tex4ht:ref: thm:G-to-the-n-hard --></a> holds for <img alt="G=A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DA_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=A_{n}"/>.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Note that <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/> contains <img alt="(A_{4})^{\lfloor n/4\rfloor }" class="latex" src="https://s0.wp.com/latex.php?latex=%28A_%7B4%7D%29%5E%7B%5Clfloor+n%2F4%5Crfloor+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(A_{4})^{\lfloor n/4\rfloor }"/> and that <img alt="A_{4}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{4}"/> is not abelian. Apply Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2005r3">3<!--tex4ht:ref: thm:G-to-the-n-hard --></a>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2005r3">3<!--tex4ht:ref: thm:G-to-the-n-hard --></a> is tight for constant-size <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. We do not know if Corollary <a href="https://emanueleviola.wordpress.com/feed/#x1-2006r3">3<!--tex4ht:ref: cor:A_n-bound --></a> is tight. The trivial upper bound is <img alt="O(\log |A_{n}|)=O(n\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Clog+%7CA_%7Bn%7D%7C%29%3DO%28n%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\log |A_{n}|)=O(n\log n)"/>.</p>
<h3 class="sectionHead"><span class="titlemark">3 </span> <a id="x1-30003"/>Proof of Theorem 1</h3>
<p style="text-align: justify;">Several related proofs of this theorem exist, see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int">GV15</a>, <a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>, <a href="https://emanueleviola.wordpress.com/feed/#XShalev16">Sha16</a>]</span>. As in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>, the proof that we present can be broken down in three steps. First we reduce the problem to a statement about conjugacy classes. Second we reduce this to a statement about trace maps. Third we prove the latter. We present the first step in a way that is similar but slightly different from the presentation in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. The second step is only sketched, but relies on classical results about <img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/> and can be found in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. For the third we present a proof that was communicated to us by Will Sawin. We thank him for his permission to include it here.</p>
<h4 class="subsectionHead"><span class="titlemark">3.1 </span> <a id="x1-40003.1"/>Step 1</h4>
<p style="text-align: justify;">We would like to rule out randomized protocols, but it is hard to reason about them directly. Instead, we are going to rule out deterministic protocols on random inputs. First, for any group element <img alt="g\in G" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\in G"/> we define the distribution on quadruples <img alt="D_{g}:=(x_{1},y_{1},x_{2},(x_{1}\cdot y_{1}\cdot x_{2})^{-1}g)" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7Bg%7D%3A%3D%28x_%7B1%7D%2Cy_%7B1%7D%2Cx_%7B2%7D%2C%28x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%29%5E%7B-1%7Dg%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{g}:=(x_{1},y_{1},x_{2},(x_{1}\cdot y_{1}\cdot x_{2})^{-1}g)"/>, where <img alt="x,y\in G" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in G"/> are uniformly random elements. Note the product of the elements in <img alt="D_{g}" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7Bg%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{g}"/> is always <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/>.</p>
<p style="text-align: justify;">Towards a contradiction, suppose we have a randomized protocol <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> such that</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb{P} [P(D_{1})=1]\geq \mathbb{P} [P(D_{h})=1]+\frac {1}{10}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb%7BP%7D+%5BP%28D_%7B1%7D%29%3D1%5D%5Cgeq+%5Cmathbb%7BP%7D+%5BP%28D_%7Bh%7D%29%3D1%5D%2B%5Cfrac+%7B1%7D%7B10%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb{P} [P(D_{1})=1]\geq \mathbb{P} [P(D_{h})=1]+\frac {1}{10}. \end{aligned}"/></div>
<p>This implies a deterministic protocol with the same gap, by fixing the randomness.</p>
<p style="text-align: justify;">We reach a contradiction by showing that for every deterministic protocol <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> using little communication, we have</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\Pr [P(D_{1})=1]-\Pr [P(D_{h})=1]|\leq \frac {1}{100}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5CPr+%5BP%28D_%7B1%7D%29%3D1%5D-%5CPr+%5BP%28D_%7Bh%7D%29%3D1%5D%7C%5Cleq+%5Cfrac+%7B1%7D%7B100%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\Pr [P(D_{1})=1]-\Pr [P(D_{h})=1]|\leq \frac {1}{100}. \end{aligned}"/></div>
<p style="text-align: justify;">We start with the following standard lemma, which describes a protocol using product sets.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-4001r4"/> Lemma 4. </span>(The set of accepted inputs of) A deterministic <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>-bit protocol for a function <img alt="f:X\times Y\to Z" class="latex" src="https://s0.wp.com/latex.php?latex=f%3AX%5Ctimes+Y%5Cto+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:X\times Y\to Z"/> can be written as a disjoint union of <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> rectangles, where a rectangle is a set of the form <img alt="A\times B" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\times B"/> with <img alt="A\subseteq X" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Csubseteq+X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\subseteq X"/> and <img alt="B\subseteq Y" class="latex" src="https://s0.wp.com/latex.php?latex=B%5Csubseteq+Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B\subseteq Y"/> and where <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> is constant.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>(sketch) For every communication transcript <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>, let <img alt="S_{t}\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=S_%7Bt%7D%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S_{t}\subseteq G^{2}"/> be the set of inputs giving transcript <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/>. The sets <img alt="S_{t}" class="latex" src="https://s0.wp.com/latex.php?latex=S_%7Bt%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S_{t}"/> are disjoint since an input gives only one transcript, and their number is <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/>: one for each communication transcript of the protocol. The rectangle property can be proven by induction on the protocol tree. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">Next, we show that any rectangle <img alt="A\times B" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\times B"/> cannot distinguish <img alt="D_{1},D_{h}" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7B1%7D%2CD_%7Bh%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{1},D_{h}"/>. The way we achieve this is by showing that for every <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> the probability that <img alt="(A\times B)(D_{g})=1" class="latex" src="https://s0.wp.com/latex.php?latex=%28A%5Ctimes+B%29%28D_%7Bg%7D%29%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(A\times B)(D_{g})=1"/> is roughly the same for every <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/>, and is roughly the density of the rectangle. (Here we write <img alt="A\times B" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\times B"/> for the characteristic function of the set <img alt="A\times B" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\times B"/>.) Without loss of generality we set <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/>. Let <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> have density <img alt="\alpha " class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha "/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> have density <img alt="\beta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbeta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\beta "/>. We aim to bound above</p>
<div style="text-align: center;"><img alt="\begin{aligned} \left |\mathbb{E} _{a_{1},b_{1},a_{2},b_{2}:a_{1}b_{1}a_{2}b_{2}=1}A(a_{1},a_{2})B(b_{1},b_{2})-\alpha \beta \right |, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb%7BE%7D+_%7Ba_%7B1%7D%2Cb_%7B1%7D%2Ca_%7B2%7D%2Cb_%7B2%7D%3Aa_%7B1%7Db_%7B1%7Da_%7B2%7Db_%7B2%7D%3D1%7DA%28a_%7B1%7D%2Ca_%7B2%7D%29B%28b_%7B1%7D%2Cb_%7B2%7D%29-%5Calpha+%5Cbeta+%5Cright+%7C%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left |\mathbb{E} _{a_{1},b_{1},a_{2},b_{2}:a_{1}b_{1}a_{2}b_{2}=1}A(a_{1},a_{2})B(b_{1},b_{2})-\alpha \beta \right |, \end{aligned}"/></div>
<p>where note the distribution of <img alt="a_{1},b_{1},a_{2},b_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=a_%7B1%7D%2Cb_%7B1%7D%2Ca_%7B2%7D%2Cb_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_{1},b_{1},a_{2},b_{2}"/> is the same as <img alt="D_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{1}"/>.</p>
<p style="text-align: justify;">Because the distribution of <img alt="(b_{1},b_{2})" class="latex" src="https://s0.wp.com/latex.php?latex=%28b_%7B1%7D%2Cb_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(b_{1},b_{2})"/> is uniform in <img alt="G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G^{2}"/>, the above can be rewritten as</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; \left |\mathbb{E} _{b_{1},b_{2}}B(b_{1},b_{2})\mathbb{E} _{a_{1},a_{2}:a_{1}b_{1}a_{2}b_{2}=1}(A(a_{1},a_{2})-\alpha )\right |\\ &amp; \le \sqrt {\mathbb{E} _{b_{1},b_{2}}B(b_{1},b_{2})^{2}}\sqrt {\mathbb{E} _{b_{1},b_{2}}\mathbb{E} _{a_{1},a_{2}:a_{1}b_{1}a_{2}b_{2}=1}^{2}(A(a_{1},a_{2})-\alpha )}.\\ &amp; =\sqrt {\beta }\sqrt {\mathbb{E} _{b_{1},b_{2},a_{1},a_{2},a_{1}',a_{2}':a_{1}b_{1}a_{2}b_{2}=a_{1}'b_{1}a_{2}'b_{2}=1}A(a_{1},a_{2})A(a_{1}',a_{2}')-\alpha ^{2}}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Cleft+%7C%5Cmathbb%7BE%7D+_%7Bb_%7B1%7D%2Cb_%7B2%7D%7DB%28b_%7B1%7D%2Cb_%7B2%7D%29%5Cmathbb%7BE%7D+_%7Ba_%7B1%7D%2Ca_%7B2%7D%3Aa_%7B1%7Db_%7B1%7Da_%7B2%7Db_%7B2%7D%3D1%7D%28A%28a_%7B1%7D%2Ca_%7B2%7D%29-%5Calpha+%29%5Cright+%7C%5C%5C+%26+%5Cle+%5Csqrt+%7B%5Cmathbb%7BE%7D+_%7Bb_%7B1%7D%2Cb_%7B2%7D%7DB%28b_%7B1%7D%2Cb_%7B2%7D%29%5E%7B2%7D%7D%5Csqrt+%7B%5Cmathbb%7BE%7D+_%7Bb_%7B1%7D%2Cb_%7B2%7D%7D%5Cmathbb%7BE%7D+_%7Ba_%7B1%7D%2Ca_%7B2%7D%3Aa_%7B1%7Db_%7B1%7Da_%7B2%7Db_%7B2%7D%3D1%7D%5E%7B2%7D%28A%28a_%7B1%7D%2Ca_%7B2%7D%29-%5Calpha+%29%7D.%5C%5C+%26+%3D%5Csqrt+%7B%5Cbeta+%7D%5Csqrt+%7B%5Cmathbb%7BE%7D+_%7Bb_%7B1%7D%2Cb_%7B2%7D%2Ca_%7B1%7D%2Ca_%7B2%7D%2Ca_%7B1%7D%27%2Ca_%7B2%7D%27%3Aa_%7B1%7Db_%7B1%7Da_%7B2%7Db_%7B2%7D%3Da_%7B1%7D%27b_%7B1%7Da_%7B2%7D%27b_%7B2%7D%3D1%7DA%28a_%7B1%7D%2Ca_%7B2%7D%29A%28a_%7B1%7D%27%2Ca_%7B2%7D%27%29-%5Calpha+%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; \left |\mathbb{E} _{b_{1},b_{2}}B(b_{1},b_{2})\mathbb{E} _{a_{1},a_{2}:a_{1}b_{1}a_{2}b_{2}=1}(A(a_{1},a_{2})-\alpha )\right |\\ &amp; \le \sqrt {\mathbb{E} _{b_{1},b_{2}}B(b_{1},b_{2})^{2}}\sqrt {\mathbb{E} _{b_{1},b_{2}}\mathbb{E} _{a_{1},a_{2}:a_{1}b_{1}a_{2}b_{2}=1}^{2}(A(a_{1},a_{2})-\alpha )}.\\ &amp; =\sqrt {\beta }\sqrt {\mathbb{E} _{b_{1},b_{2},a_{1},a_{2},a_{1}',a_{2}':a_{1}b_{1}a_{2}b_{2}=a_{1}'b_{1}a_{2}'b_{2}=1}A(a_{1},a_{2})A(a_{1}',a_{2}')-\alpha ^{2}}. \end{aligned}"/></div>
<p style="text-align: justify;">The inequality is Cauchy-Schwarz, and the step after that is obtained by expanding the square and noting that <img alt="(a_{1},a_{2})" class="latex" src="https://s0.wp.com/latex.php?latex=%28a_%7B1%7D%2Ca_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a_{1},a_{2})"/> is uniform in <img alt="G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G^{2}"/>, so that the expectation of the term <img alt="A(a_{1},a_{2})\alpha " class="latex" src="https://s0.wp.com/latex.php?latex=A%28a_%7B1%7D%2Ca_%7B2%7D%29%5Calpha+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(a_{1},a_{2})\alpha "/> is <img alt="\alpha ^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Calpha+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\alpha ^{2}"/>.</p>
<p style="text-align: justify;">Now we do several transformations to rewrite the distribution in the last expectation in a convenient form. First, right-multiplying by <img alt="b_{2}^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=b_%7B2%7D%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b_{2}^{-1}"/> we can rewrite the distribution as the uniform distribution on tuples such that</p>
<div style="text-align: center;"><img alt="\begin{aligned} a_{1}b_{1}a_{2}=a_{1}'b_{1}a_{2}'. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7B1%7Db_%7B1%7Da_%7B2%7D%3Da_%7B1%7D%27b_%7B1%7Da_%7B2%7D%27.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} a_{1}b_{1}a_{2}=a_{1}'b_{1}a_{2}'. \end{aligned}"/></div>
<p style="text-align: justify;">The last equation is equivalent to <img alt="b_{1}^{-1}(a_{1}')^{-1}a_{1}b_{1}a_{2}=a_{2}'" class="latex" src="https://s0.wp.com/latex.php?latex=b_%7B1%7D%5E%7B-1%7D%28a_%7B1%7D%27%29%5E%7B-1%7Da_%7B1%7Db_%7B1%7Da_%7B2%7D%3Da_%7B2%7D%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b_{1}^{-1}(a_{1}')^{-1}a_{1}b_{1}a_{2}=a_{2}'"/>.</p>
<p style="text-align: justify;">We can now do a transformation setting <img alt="a_{1}'" class="latex" src="https://s0.wp.com/latex.php?latex=a_%7B1%7D%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_{1}'"/> to be <img alt="a_{1}x^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=a_%7B1%7Dx%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_{1}x^{-1}"/> to rewrite the distribution of the four-tuple as</p>
<div style="text-align: center;"><img alt="\begin{aligned} (a_{1},a_{2},a_{1}x^{-1},C(x)a_{2}) \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28a_%7B1%7D%2Ca_%7B2%7D%2Ca_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (a_{1},a_{2},a_{1}x^{-1},C(x)a_{2}) \end{aligned}"/></div>
<p>where we use <img alt="C(x)" class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x)"/> to denote a uniform element from the conjugacy class of <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, that is <img alt="b^{-1}xb" class="latex" src="https://s0.wp.com/latex.php?latex=b%5E%7B-1%7Dxb&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b^{-1}xb"/> for a uniform <img alt="b\in G" class="latex" src="https://s0.wp.com/latex.php?latex=b%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b\in G"/>.</p>
<p style="text-align: justify;">Hence it is sufficient to bound</p>
<div style="text-align: center;"><img alt="\begin{aligned} \left |\mathbb{E} A(a_{1},a_{2})A(a_{1}x^{-1},C(x)a_{2})-\alpha ^{2}\right |, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb%7BE%7D+A%28a_%7B1%7D%2Ca_%7B2%7D%29A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29-%5Calpha+%5E%7B2%7D%5Cright+%7C%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left |\mathbb{E} A(a_{1},a_{2})A(a_{1}x^{-1},C(x)a_{2})-\alpha ^{2}\right |, \end{aligned}"/></div>
<p>where all the variables are uniform and independent.</p>
<p style="text-align: justify;">With a similar derivation as above, this can be rewritten as</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; \left |\mathbb{E} A(a_{1},a_{2})\mathbb{E} (A(a_{1}x^{-1},C(x)a_{2})-\alpha )\right |\\ &amp; \le \sqrt {\mathbb{E} A(a_{1},a{}_{2})^{2}}\sqrt {\mathbb{E} _{a_{1},a_{2}}\mathbb{E} _{x}^{2}(A(a_{1}x^{-1},C(x)a_{2})-\alpha )}.\\ &amp; =\sqrt {\alpha }\sqrt {\mathbb{E} A(a_{1}x^{-1},C(x)a_{2})A(a_{1}x'^{-1},C(x')a_{2})-\alpha ^{2}}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Cleft+%7C%5Cmathbb%7BE%7D+A%28a_%7B1%7D%2Ca_%7B2%7D%29%5Cmathbb%7BE%7D+%28A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29-%5Calpha+%29%5Cright+%7C%5C%5C+%26+%5Cle+%5Csqrt+%7B%5Cmathbb%7BE%7D+A%28a_%7B1%7D%2Ca%7B%7D_%7B2%7D%29%5E%7B2%7D%7D%5Csqrt+%7B%5Cmathbb%7BE%7D+_%7Ba_%7B1%7D%2Ca_%7B2%7D%7D%5Cmathbb%7BE%7D+_%7Bx%7D%5E%7B2%7D%28A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29-%5Calpha+%29%7D.%5C%5C+%26+%3D%5Csqrt+%7B%5Calpha+%7D%5Csqrt+%7B%5Cmathbb%7BE%7D+A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29A%28a_%7B1%7Dx%27%5E%7B-1%7D%2CC%28x%27%29a_%7B2%7D%29-%5Calpha+%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; \left |\mathbb{E} A(a_{1},a_{2})\mathbb{E} (A(a_{1}x^{-1},C(x)a_{2})-\alpha )\right |\\ &amp; \le \sqrt {\mathbb{E} A(a_{1},a{}_{2})^{2}}\sqrt {\mathbb{E} _{a_{1},a_{2}}\mathbb{E} _{x}^{2}(A(a_{1}x^{-1},C(x)a_{2})-\alpha )}.\\ &amp; =\sqrt {\alpha }\sqrt {\mathbb{E} A(a_{1}x^{-1},C(x)a_{2})A(a_{1}x'^{-1},C(x')a_{2})-\alpha ^{2}}. \end{aligned}"/></div>
<p style="text-align: justify;">Here each occurrence of <img alt="C" class="latex" src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C"/> denotes a uniform and independent conjugate. Hence it is sufficient to bound</p>
<div style="text-align: center;"><img alt="\begin{aligned} \left |\mathbb{E} A(a_{1}x^{-1},C(x)a_{2})A(a_{1}x'^{-1},C(x')a_{2})-\alpha ^{2}\right |. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb%7BE%7D+A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29A%28a_%7B1%7Dx%27%5E%7B-1%7D%2CC%28x%27%29a_%7B2%7D%29-%5Calpha+%5E%7B2%7D%5Cright+%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left |\mathbb{E} A(a_{1}x^{-1},C(x)a_{2})A(a_{1}x'^{-1},C(x')a_{2})-\alpha ^{2}\right |. \end{aligned}"/></div>
<p style="text-align: justify;">We can now replace <img alt="a_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=a_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_{2}"/> with <img alt="C(x)^{-1}a_{2}." class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%29%5E%7B-1%7Da_%7B2%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x)^{-1}a_{2}."/> Because <img alt="C(x)^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%29%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x)^{-1}"/> has the same distribution of <img alt="C(x^{-1})" class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%5E%7B-1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x^{-1})"/>, it is sufficient to bound</p>
<div style="text-align: center;"><img alt="\begin{aligned} \left |\mathbb{E} A(a_{1}x^{-1},a_{2})A(a_{1}x'^{-1},C(x')C(x^{-1})a_{2})-\alpha ^{2}\right |. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb%7BE%7D+A%28a_%7B1%7Dx%5E%7B-1%7D%2Ca_%7B2%7D%29A%28a_%7B1%7Dx%27%5E%7B-1%7D%2CC%28x%27%29C%28x%5E%7B-1%7D%29a_%7B2%7D%29-%5Calpha+%5E%7B2%7D%5Cright+%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left |\mathbb{E} A(a_{1}x^{-1},a_{2})A(a_{1}x'^{-1},C(x')C(x^{-1})a_{2})-\alpha ^{2}\right |. \end{aligned}"/></div>
<p style="text-align: justify;">For this, it is enough to show that with high probability <img alt="1-1/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=1-1%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1-1/|G|^{\Omega (1)}"/> over <img alt="x'" class="latex" src="https://s0.wp.com/latex.php?latex=x%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x'"/> and <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, the distribution of <img alt="C(x')C(x^{-1})" class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%27%29C%28x%5E%7B-1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x')C(x^{-1})"/>, over the choice of the two independent conjugates, has statistical distance <img alt="\le 1/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cle+1%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\le 1/|G|^{\Omega (1)}"/> from uniform.</p>
<h4 class="subsectionHead"><span class="titlemark">3.2 </span> <a id="x1-50003.2"/>Step 2</h4>
<p style="text-align: justify;">In this step we use information on the conjugacy classes of the group to reduce the latter task to one about the equidistribution of the trace map. Let <img alt="Tr" class="latex" src="https://s0.wp.com/latex.php?latex=Tr&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Tr"/> be the Trace map:</p>
<div style="text-align: center;"><img alt="\begin{aligned} Tr\begin {pmatrix}a_{1} &amp; a_{2}\\ a_{3} &amp; a_{4} \end {pmatrix}=a_{1}+a_{4}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+Tr%5Cbegin+%7Bpmatrix%7Da_%7B1%7D+%26+a_%7B2%7D%5C%5C+a_%7B3%7D+%26+a_%7B4%7D+%5Cend+%7Bpmatrix%7D%3Da_%7B1%7D%2Ba_%7B4%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} Tr\begin {pmatrix}a_{1} &amp; a_{2}\\ a_{3} &amp; a_{4} \end {pmatrix}=a_{1}+a_{4}. \end{aligned}"/></div>
<p style="text-align: justify;">We state the lemma that we want to show.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-5001r5"/> Lemma 5. </span>Let <img alt="a:=\begin {pmatrix}0 &amp; 1\\ 1 &amp; w \end {pmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=a%3A%3D%5Cbegin+%7Bpmatrix%7D0+%26+1%5C%5C+1+%26+w+%5Cend+%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a:=\begin {pmatrix}0 &amp; 1\\ 1 &amp; w \end {pmatrix}"/> and <img alt="b:=\begin {pmatrix}v &amp; 1\\ 1 &amp; 0 \end {pmatrix}" class="latex" src="https://s0.wp.com/latex.php?latex=b%3A%3D%5Cbegin+%7Bpmatrix%7Dv+%26+1%5C%5C+1+%26+0+%5Cend+%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b:=\begin {pmatrix}v &amp; 1\\ 1 &amp; 0 \end {pmatrix}"/>. For all but <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> values of <img alt="w\in \mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=w%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w\in \mathbb{F} _{q}"/> and <img alt="v\in \mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=v%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v\in \mathbb{F} _{q}"/>, the distribution of</p>
<div style="text-align: center;"><img alt="\begin{aligned} Tr\left (au^{-1}bu\right ) \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+Tr%5Cleft+%28au%5E%7B-1%7Dbu%5Cright+%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} Tr\left (au^{-1}bu\right ) \end{aligned}"/></div>
<p>is <img alt="O(1/q)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2Fq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1/q)"/> close to uniform over <img alt="\mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{F} _{q}"/> in statistical distance.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">To give some context, in <img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/> the conjugacy class of an element is essentially determined by the trace. Moreover, we can think of <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> and <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b"/> as generic elements in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. So the lemma can be interpreted as saying that for typical <img alt="a,b\in G" class="latex" src="https://s0.wp.com/latex.php?latex=a%2Cb%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a,b\in G"/>, taking a uniform element from the conjugacy class of <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b"/> and multiplying it by <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> yields an element whose conjugacy class is uniform among the classes of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. Using that essentially all conjugacy classes are equal, and some of the properties of the trace map, one can show that the above lemma implies that for typical <img alt="x,x'" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cx%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,x'"/> the distribution of <img alt="C(x')C(x^{-1})" class="latex" src="https://s0.wp.com/latex.php?latex=C%28x%27%29C%28x%5E%7B-1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C(x')C(x^{-1})"/> is close to uniform. For more on how this fits we refer the reader to <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>.</p>
<h4 class="subsectionHead"><span class="titlemark">3.3 </span> <a id="x1-60003.3"/>Step 3</h4>
<p style="text-align: justify;">We now present a proof of Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-5001r5">5<!--tex4ht:ref: lem:trace --></a>. The high-level argument of the proof is the same as in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span> (Lemma 5.5), but the details may be more accessible and in particular the use of the Lang-Weil theorem <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XLangWeil54">LW54</a>]</span> from algebraic geometry is replaced by a more elementary argument. For simplicity we shall only cover the case where <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> is prime. We will show that for all but <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> values of <img alt="v,w,c\in \mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=v%2Cw%2Cc%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v,w,c\in \mathbb{F} _{q}"/>, the probability over <img alt="u" class="latex" src="https://s0.wp.com/latex.php?latex=u&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="u"/> that <img alt="Tr(au^{-1}bu)=c" class="latex" src="https://s0.wp.com/latex.php?latex=Tr%28au%5E%7B-1%7Dbu%29%3Dc&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Tr(au^{-1}bu)=c"/> is within <img alt="O(1/q^{2})" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2Fq%5E%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1/q^{2})"/> of <img alt="1/q" class="latex" src="https://s0.wp.com/latex.php?latex=1%2Fq&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/q"/>, and for the others it is at most <img alt="O(1/q)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%2Fq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1/q)"/>. Summing over <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/> gives the result.</p>
<p style="text-align: justify;">We shall consider elements <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b"/> whose trace is unique to the conjugacy class of <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b"/>. (This holds for all but <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> conjugacy classes – see for example <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span> for details.) This means that the distribution of <img alt="u^{-1}bu" class="latex" src="https://s0.wp.com/latex.php?latex=u%5E%7B-1%7Dbu&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="u^{-1}bu"/> is that of a uniform element in <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> conditioned on having trace <img alt="b" class="latex" src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="b"/>. Hence, we can write the probability that <img alt="Tr(au^{-1}bu)=c" class="latex" src="https://s0.wp.com/latex.php?latex=Tr%28au%5E%7B-1%7Dbu%29%3Dc&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Tr(au^{-1}bu)=c"/> as the number of solutions in <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> to the following three equations (divided by the size of the group, which is <img alt="q^{3}-q" class="latex" src="https://s0.wp.com/latex.php?latex=q%5E%7B3%7D-q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q^{3}-q"/>):</p>
<div style="text-align: center;"><img alt="\begin{aligned} x_{3}+x_{2}+wx_{4} &amp; =c &amp; \hspace {1cm}(Tr(ax)=c),\\ x_{1}+x_{4} &amp; =v &amp; \hspace {1cm}(Tr(x)=Tr(b)),\\ x_{1}x_{4}-x_{3}x_{3} &amp; =1 &amp; \hspace {1cm}(Det(x)=1). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x_%7B3%7D%2Bx_%7B2%7D%2Bwx_%7B4%7D+%26+%3Dc+%26+%5Chspace+%7B1cm%7D%28Tr%28ax%29%3Dc%29%2C%5C%5C+x_%7B1%7D%2Bx_%7B4%7D+%26+%3Dv+%26+%5Chspace+%7B1cm%7D%28Tr%28x%29%3DTr%28b%29%29%2C%5C%5C+x_%7B1%7Dx_%7B4%7D-x_%7B3%7Dx_%7B3%7D+%26+%3D1+%26+%5Chspace+%7B1cm%7D%28Det%28x%29%3D1%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x_{3}+x_{2}+wx_{4} &amp; =c &amp; \hspace {1cm}(Tr(ax)=c),\\ x_{1}+x_{4} &amp; =v &amp; \hspace {1cm}(Tr(x)=Tr(b)),\\ x_{1}x_{4}-x_{3}x_{3} &amp; =1 &amp; \hspace {1cm}(Det(x)=1). \end{aligned}"/></div>
<p style="text-align: justify;">We use the second one to remove <img alt="x_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{1}"/> and the first one to remove <img alt="x_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{2}"/> from the last equation. This gives</p>
<div style="text-align: center;"><img alt="\begin{aligned} (v-x_{4})x_{4}-(c-x_{3}-wx_{4})x_{3}=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28v-x_%7B4%7D%29x_%7B4%7D-%28c-x_%7B3%7D-wx_%7B4%7D%29x_%7B3%7D%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (v-x_{4})x_{4}-(c-x_{3}-wx_{4})x_{3}=1. \end{aligned}"/></div>
<p style="text-align: justify;">This is an equation in two variables. Write <img alt="x=x_{3}" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Dx_%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=x_{3}"/> and <img alt="y=x_{4}" class="latex" src="https://s0.wp.com/latex.php?latex=y%3Dx_%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y=x_{4}"/> and use distributivity to rewrite the equation as</p>
<div style="text-align: center;"><img alt="\begin{aligned} -y^{2}+vy-cx+x^{2}+wxy=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+-y%5E%7B2%7D%2Bvy-cx%2Bx%5E%7B2%7D%2Bwxy%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} -y^{2}+vy-cx+x^{2}+wxy=1. \end{aligned}"/></div>
<p style="text-align: justify;">At least since Lagrange it has been known how to reduce this to a Pell equation <img alt="x^{2}+dy^{2}=e" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D%2Bdy%5E%7B2%7D%3De&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{2}+dy^{2}=e"/>. This is done by applying an invertible affine transformation, which does not change the number of solutions. First set <img alt="x=x-wy/2" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Dx-wy%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=x-wy/2"/>. Then the equation becomes</p>
<div style="text-align: center;"><img alt="\begin{aligned} -y^{2}+vy-c(x-wy/2)+(x-wy/2)^{2}+w(x-wy/2)y=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+-y%5E%7B2%7D%2Bvy-c%28x-wy%2F2%29%2B%28x-wy%2F2%29%5E%7B2%7D%2Bw%28x-wy%2F2%29y%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} -y^{2}+vy-c(x-wy/2)+(x-wy/2)^{2}+w(x-wy/2)y=1. \end{aligned}"/></div>
<p style="text-align: justify;">Equivalently, the cross-term has disappeared and we have</p>
<div style="text-align: center;"><img alt="\begin{aligned} y^{2}(-1-w^{2}/4)+y(v+cw/2)+x^{2}-cx=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+y%5E%7B2%7D%28-1-w%5E%7B2%7D%2F4%29%2By%28v%2Bcw%2F2%29%2Bx%5E%7B2%7D-cx%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} y^{2}(-1-w^{2}/4)+y(v+cw/2)+x^{2}-cx=1. \end{aligned}"/></div>
<p style="text-align: justify;">Now one can add constants to <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> to remove the linear terms, changing the constant term. Specifically, let <img alt="h:=(v+cw/2)/2" class="latex" src="https://s0.wp.com/latex.php?latex=h%3A%3D%28v%2Bcw%2F2%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h:=(v+cw/2)/2"/> and set <img alt="y=y-h" class="latex" src="https://s0.wp.com/latex.php?latex=y%3Dy-h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y=y-h"/> and <img alt="x=x+c/2" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Dx%2Bc%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=x+c/2"/>. The equation becomes</p>
<div style="text-align: center;"><img alt="\begin{aligned} (y-h)^{2}(-1-w^{2}/4)+(y-h)2h+(x+c/2)^{2}-c(x+c/2)=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28y-h%29%5E%7B2%7D%28-1-w%5E%7B2%7D%2F4%29%2B%28y-h%292h%2B%28x%2Bc%2F2%29%5E%7B2%7D-c%28x%2Bc%2F2%29%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (y-h)^{2}(-1-w^{2}/4)+(y-h)2h+(x+c/2)^{2}-c(x+c/2)=1. \end{aligned}"/></div>
<p style="text-align: justify;">The linear terms disappear, the coefficients of <img alt="x^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{2}"/> and <img alt="y^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=y%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y^{2}"/> do not change and the equation can be rewritten as</p>
<div style="text-align: center;"><img alt="\begin{aligned} y^{2}(-1-w^{2}/4)+h^{2}(-1-w^{2}/4)-2h^{2}+x^{2}+(c/2)^{2}-c^{2}/2=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+y%5E%7B2%7D%28-1-w%5E%7B2%7D%2F4%29%2Bh%5E%7B2%7D%28-1-w%5E%7B2%7D%2F4%29-2h%5E%7B2%7D%2Bx%5E%7B2%7D%2B%28c%2F2%29%5E%7B2%7D-c%5E%7B2%7D%2F2%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} y^{2}(-1-w^{2}/4)+h^{2}(-1-w^{2}/4)-2h^{2}+x^{2}+(c/2)^{2}-c^{2}/2=1. \end{aligned}"/></div>
<p style="text-align: justify;">So this is now a Pell equation</p>
<div style="text-align: center;"><img alt="\begin{aligned} x^{2}+dy^{2}=e \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5E%7B2%7D%2Bdy%5E%7B2%7D%3De+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x^{2}+dy^{2}=e \end{aligned}"/></div>
<p style="text-align: justify;">where <img alt="d:=(-1-w^{2}/4)" class="latex" src="https://s0.wp.com/latex.php?latex=d%3A%3D%28-1-w%5E%7B2%7D%2F4%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d:=(-1-w^{2}/4)"/> and</p>
<div style="text-align: center;"><img alt="\begin{aligned} e:=1+h^{2}(3+w^{2}/4)+(c/2)^{2}=1+(v^{2}+(cw/2)^{2}+cvw)(1/4)(3+w^{2}/4)+(c/2)^{2}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+e%3A%3D1%2Bh%5E%7B2%7D%283%2Bw%5E%7B2%7D%2F4%29%2B%28c%2F2%29%5E%7B2%7D%3D1%2B%28v%5E%7B2%7D%2B%28cw%2F2%29%5E%7B2%7D%2Bcvw%29%281%2F4%29%283%2Bw%5E%7B2%7D%2F4%29%2B%28c%2F2%29%5E%7B2%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} e:=1+h^{2}(3+w^{2}/4)+(c/2)^{2}=1+(v^{2}+(cw/2)^{2}+cvw)(1/4)(3+w^{2}/4)+(c/2)^{2}. \end{aligned}"/></div>
<p style="text-align: justify;">For all but <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> values of <img alt="w" class="latex" src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w"/> we have that <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> is non-zero. Moreover, for all but <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> values of <img alt="v,w" class="latex" src="https://s0.wp.com/latex.php?latex=v%2Cw&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v,w"/> the term <img alt="e" class="latex" src="https://s0.wp.com/latex.php?latex=e&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e"/> is a non-zero polynomial in <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>. (Specifically, for any <img alt="v\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=v%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="v\ne 0"/> and any <img alt="w" class="latex" src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="w"/> such that <img alt="3+w^{2}/4\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=3%2Bw%5E%7B2%7D%2F4%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="3+w^{2}/4\ne 0"/>.) So we only consider the values of <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/> that make it non-zero. Those where <img alt="e=0" class="latex" src="https://s0.wp.com/latex.php?latex=e%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e=0"/> give <img alt="O(q)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(q)"/> solutions, which is fine. We conclude with the following lemma.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-6001r6"/> Lemma 6. </span>For <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> and <img alt="e" class="latex" src="https://s0.wp.com/latex.php?latex=e&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e"/> non-zero, and prime <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/>, the number of solutions over <img alt="\mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{F} _{q}"/> to the Pell equation</p>
<div style="text-align: center;"><img alt="\begin{aligned} x^{2}+dy^{2}=e \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5E%7B2%7D%2Bdy%5E%7B2%7D%3De+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x^{2}+dy^{2}=e \end{aligned}"/></div>
<p style="text-align: justify;">is within <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> of <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">This is a basic result from algebraic geometry that can be proved from first principles.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>If <img alt="d=-f^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=d%3D-f%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d=-f^{2}"/> for some <img alt="f\in \mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=f%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f\in \mathbb{F} _{q}"/>, then we can replace <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/> with <img alt="fy" class="latex" src="https://s0.wp.com/latex.php?latex=fy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="fy"/> and we can count instead the solutions to the equation</p>
<div style="text-align: center;"><img alt="\begin{aligned} x^{2}-y^{2}=e. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5E%7B2%7D-y%5E%7B2%7D%3De.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x^{2}-y^{2}=e. \end{aligned}"/></div>
<p style="text-align: justify;">Because <img alt="x^{2}-y^{2}=(x-y)(x+y)" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D-y%5E%7B2%7D%3D%28x-y%29%28x%2By%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{2}-y^{2}=(x-y)(x+y)"/> we can set <img alt="x':=x-y" class="latex" src="https://s0.wp.com/latex.php?latex=x%27%3A%3Dx-y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x':=x-y"/> and <img alt="y':=x+y" class="latex" src="https://s0.wp.com/latex.php?latex=y%27%3A%3Dx%2By&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y':=x+y"/>, which preserves the number of solutions, and rewrite the equation as</p>
<div style="text-align: center;"><img alt="\begin{aligned} x'y'=e. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%27y%27%3De.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} x'y'=e. \end{aligned}"/></div>
<p style="text-align: justify;">Because <img alt="e\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=e%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e\ne 0"/>, this has <img alt="q-1" class="latex" src="https://s0.wp.com/latex.php?latex=q-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q-1"/> solutions: for every non-zero <img alt="y'" class="latex" src="https://s0.wp.com/latex.php?latex=y%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y'"/> we have <img alt="x'=e/y'" class="latex" src="https://s0.wp.com/latex.php?latex=x%27%3De%2Fy%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x'=e/y'"/>.</p>
<p style="text-align: justify;">So now we can assume that <img alt="d\ne -f^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cne+-f%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\ne -f^{2}"/> for any <img alt="f\in \mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=f%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f\in \mathbb{F} _{q}"/>. Because the number of squares is <img alt="(q+1)/2" class="latex" src="https://s0.wp.com/latex.php?latex=%28q%2B1%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(q+1)/2"/>, the range of <img alt="x^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{2}"/> has size <img alt="(q+1)/2" class="latex" src="https://s0.wp.com/latex.php?latex=%28q%2B1%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(q+1)/2"/>. Similarly, the range of <img alt="e-dy^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=e-dy%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="e-dy^{2}"/> also has size <img alt="(q+1)/2" class="latex" src="https://s0.wp.com/latex.php?latex=%28q%2B1%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(q+1)/2"/>. Hence these two ranges intersect, and there is a solution <img alt="(a,b)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)"/>.</p>
<p style="text-align: justify;">We take a line passing through <img alt="(a,b)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)"/>: for parameters <img alt="s,t\in \mathbb{F} " class="latex" src="https://s0.wp.com/latex.php?latex=s%2Ct%5Cin+%5Cmathbb%7BF%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s,t\in \mathbb{F} "/> we consider pairs <img alt="(a+t,b+st)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Bt%2Cb%2Bst%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a+t,b+st)"/>. There is a bijection between such pairs with <img alt="t\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=t%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t\ne 0"/> and the points <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/> with <img alt="x\ne a" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cne+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\ne a"/>. Because the number of solutions with <img alt="x=a" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Da&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=a"/> is <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/>, using that <img alt="d\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\ne 0"/>, it suffices to count the solutions with <img alt="t\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=t%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t\ne 0"/>.</p>
<p style="text-align: justify;">The intuition is that this line has two intersections with the curve <img alt="x^{2}+dy^{2}=e" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D%2Bdy%5E%7B2%7D%3De&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{2}+dy^{2}=e"/>. Because one of them, <img alt="(a,b)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)"/>, lies in <img alt="\mathbb{F} _{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{F} _{q}"/>, the other has to lie as well there. Algebraically, we can plug the pair in the expression to obtain the equivalent equation</p>
<div style="text-align: center;"><img alt="\begin{aligned} a^{2}+t^{2}+2at+d(b^{2}+s^{2}t^{2}+2bst)=e. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a%5E%7B2%7D%2Bt%5E%7B2%7D%2B2at%2Bd%28b%5E%7B2%7D%2Bs%5E%7B2%7Dt%5E%7B2%7D%2B2bst%29%3De.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} a^{2}+t^{2}+2at+d(b^{2}+s^{2}t^{2}+2bst)=e. \end{aligned}"/></div>
<p style="text-align: justify;">Using that <img alt="(a,b)" class="latex" src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(a,b)"/> is a solution this becomes</p>
<div style="text-align: center;"><img alt="\begin{aligned} t^{2}+2at+ds^{2}t^{2}+2dbst=0 \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%5E%7B2%7D%2B2at%2Bds%5E%7B2%7Dt%5E%7B2%7D%2B2dbst%3D0+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} t^{2}+2at+ds^{2}t^{2}+2dbst=0 \end{aligned}"/></div>
<p style="text-align: justify;">We can divide by <img alt="t\ne 0" class="latex" src="https://s0.wp.com/latex.php?latex=t%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t\ne 0"/>. Obtaining</p>
<div style="text-align: center;"><img alt="\begin{aligned} t(1+ds^{2})+2a+2dbs=0. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%281%2Bds%5E%7B2%7D%29%2B2a%2B2dbs%3D0.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} t(1+ds^{2})+2a+2dbs=0. \end{aligned}"/></div>
<p style="text-align: justify;">We can now divide by <img alt="1+ds^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2Bds%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1+ds^{2}"/> which is non-zero by the assumption <img alt="d\ne -f^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cne+-f%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\ne -f^{2}"/>. This yields</p>
<div style="text-align: center;"><img alt="\begin{aligned} t=(-2a-2dbs)/(1+ds^{2}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%3D%28-2a-2dbs%29%2F%281%2Bds%5E%7B2%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} t=(-2a-2dbs)/(1+ds^{2}). \end{aligned}"/></div>
<p style="text-align: justify;">Hence for every value of <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> there is a unique <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t"/> giving a solution. This gives <img alt="q" class="latex" src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="q"/> solutions. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<h3 class="sectionHead"><span class="titlemark">4 </span> <a id="x1-70004"/>Three parties, number-in-hand</h3>
<p style="text-align: justify;">In this section we consider the following three-party number-in-hand problem: Alice gets <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, Bob gets <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/>, Charlie gets <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z"/>, and they want to know if <img alt="x\cdot y\cdot z=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%5Ccdot+z%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y\cdot z=1_{G}"/>. The communication depends on the group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. We present next two efficient protocols for abelian groups, and then a communication lower bound for other groups.</p>
<h4 class="subsectionHead"><span class="titlemark">4.1 </span> <a id="x1-80004.1"/>A randomized protocol for the hypercube</h4>
<p style="text-align: justify;">We begin with the simplest setting. Let <img alt="G=(\mathbb {Z}_{2})^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=G%3D%28%5Cmathbb+%7BZ%7D_%7B2%7D%29%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=(\mathbb {Z}_{2})^{n}"/>, that is <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>-bit strings with bit-wise addition modulo 2. The parties want to check if <img alt="x+y+z=0^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x+y+z=0^{n}"/>. They can do so as follows. First, they pick a hash function <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> that is linear: <img alt="h(x+y)=h(x)+h(y)" class="latex" src="https://s0.wp.com/latex.php?latex=h%28x%2By%29%3Dh%28x%29%2Bh%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h(x+y)=h(x)+h(y)"/>. Specifically, for a uniformly random <img alt="a\in \{0,1\}^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\in \{0,1\}^{n}"/> define <img alt="h_{a}(x):=\sum a_{i}x_{i}\mod 2" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%3A%3D%5Csum+a_%7Bi%7Dx_%7Bi%7D%5Cmod+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x):=\sum a_{i}x_{i}\mod 2"/>. Then, the protocol is as follows.</p>
<ul class="itemize1">
<li class="itemize">Alice sends <img alt="h_{a}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)"/>,</li>
<li class="itemize">Bob send <img alt="h_{a}(y)" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(y)"/>,</li>
<li class="itemize">Charlie accepts if and only if <img alt="h_{a}(x)+h_{a}(y)+h_{a}(z)=0s" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%2Bh_%7Ba%7D%28y%29%2Bh_%7Ba%7D%28z%29%3D0s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)+h_{a}(y)+h_{a}(z)=0s"/>.</li>
</ul>
<p style="text-align: justify;">The hash function outputs 1 bit, so the communication is constant. By linearity, the protocol accepts iff <img alt="h_{a}(x+y+z)=0" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%2Bz%29%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y+z)=0"/>. If <img alt="x+y+z=0" class="latex" src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x+y+z=0"/> this is always the case, otherwise it happens with probability <img alt="1/2" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/2"/>.</p>
<h4 class="subsectionHead"><span class="titlemark">4.2 </span> <a id="x1-90004.2"/>A randomized protocol for <img alt="\mathbb {Z}_{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BZ%7D_%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {Z}_{N}"/></h4>
<p style="text-align: justify;">This protocol is from <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XViola-ccsum">Vio14</a>]</span>. For simplicity we only consider the case <img alt="N=2^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=N%3D2%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N=2^{n}"/> here – the protocol for general <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/> is in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XViola-ccsum">Vio14</a>]</span>. Again, the parties want to check if <img alt="x+y+z=0\mod N" class="latex" src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0%5Cmod+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x+y+z=0\mod N"/>. For this group, there is no 100% linear hash function but there are almost linear hash functions <img alt="h:\mathbb {Z}_{N}\rightarrow \mathbb {Z}_{2^{\ell }}" class="latex" src="https://s0.wp.com/latex.php?latex=h%3A%5Cmathbb+%7BZ%7D_%7BN%7D%5Crightarrow+%5Cmathbb+%7BZ%7D_%7B2%5E%7B%5Cell+%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h:\mathbb {Z}_{N}\rightarrow \mathbb {Z}_{2^{\ell }}"/> that satisfy the following properties. Note that the inputs to <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> are interpreted modulo <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="N"/> and the outputs modulo <img alt="2^{\ell }" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B%5Cell+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{\ell }"/>.</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-9002x1">for all <img alt="a,x,y" class="latex" src="https://s0.wp.com/latex.php?latex=a%2Cx%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a,x,y"/> there is <img alt="c\in \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cin+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\in \{0,1\}"/> such that <img alt="h_{a}(x+y)=h_{a}(x)+h_{a}(y)+c" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%29%3Dh_%7Ba%7D%28x%29%2Bh_%7Ba%7D%28y%29%2Bc&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y)=h_{a}(x)+h_{a}(y)+c"/>,</li>
<li class="enumerate" id="x1-9004x2">for all <img alt="x\neq 0" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cneq+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\neq 0"/> we have <img alt="\mathbb{P} _{a}[h_{a}(x)\in \{-2,-1,0,1,2\}]\leq O(1/2^{\ell })" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+_%7Ba%7D%5Bh_%7Ba%7D%28x%29%5Cin+%5C%7B-2%2C-1%2C0%2C1%2C2%5C%7D%5D%5Cleq+O%281%2F2%5E%7B%5Cell+%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} _{a}[h_{a}(x)\in \{-2,-1,0,1,2\}]\leq O(1/2^{\ell })"/>,</li>
<li class="enumerate" id="x1-9006x3"><img alt="h_{a}(0)=0" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%280%29%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(0)=0"/>.</li>
</ol>
<p style="text-align: justify;">Assuming some random hash function <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> that satisfies the above properties the protocol works similarly to the previous one:</p>
<ul class="itemize1">
<li class="itemize">Alice sends <img alt="h_{a}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)"/>,</li>
<li class="itemize">Bob sends <img alt="h_{a}(y)" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(y)"/>,</li>
<li class="itemize">Charlie accepts if and only if <img alt="h_{a}(x)+h_{a}(y)+h_{a}(z)\in \{-2,-1,0\}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%2Bh_%7Ba%7D%28y%29%2Bh_%7Ba%7D%28z%29%5Cin+%5C%7B-2%2C-1%2C0%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)+h_{a}(y)+h_{a}(z)\in \{-2,-1,0\}"/>.</li>
</ul>
<p style="text-align: justify;">We can set <img alt="\ell =O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell+%3DO%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell =O(1)"/> to achieve constant communication and constant error.</p>
<p style="text-align: justify;">To prove correctness of the protocol, first note that <img alt="h_{a}(x)+h_{a}(y)+h_{a}(z)=h_{a}(x+y+z)-c" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%2Bh_%7Ba%7D%28y%29%2Bh_%7Ba%7D%28z%29%3Dh_%7Ba%7D%28x%2By%2Bz%29-c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)+h_{a}(y)+h_{a}(z)=h_{a}(x+y+z)-c"/> for some <img alt="c\in \{0,1,2\}" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cin+%5C%7B0%2C1%2C2%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\in \{0,1,2\}"/>. Then consider the following two cases:</p>
<ul class="itemize1">
<li class="itemize">if <img alt="x+y+z=0" class="latex" src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x+y+z=0"/> then <img alt="h_{a}(x+y+z)-c=h_{a}(0)-c=-c," class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%2Bz%29-c%3Dh_%7Ba%7D%280%29-c%3D-c%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y+z)-c=h_{a}(0)-c=-c,"/> and the protocol is always correct.</li>
<li class="itemize">if <img alt="x+y+z\neq 0" class="latex" src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%5Cneq+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x+y+z\neq 0"/> then the probability that <img alt="h_{a}(x+y+z)-c\in \{-2,-1,0\}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%2Bz%29-c%5Cin+%5C%7B-2%2C-1%2C0%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y+z)-c\in \{-2,-1,0\}"/> for some <img alt="c\in \{0,1,2\}" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cin+%5C%7B0%2C1%2C2%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\in \{0,1,2\}"/> is at most the probability that <img alt="h_{a}(x+y+z)\in \{-2,-1,0,1,2\}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%2Bz%29%5Cin+%5C%7B-2%2C-1%2C0%2C1%2C2%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y+z)\in \{-2,-1,0,1,2\}"/> which is <img alt="\leq 2^{-\Omega (\ell )}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cleq+2%5E%7B-%5COmega+%28%5Cell+%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\leq 2^{-\Omega (\ell )}"/>; so the protocol is correct with high probability.</li>
</ul>
<p style="text-align: justify;"><b>The hash function.</b>.</p>
<p style="text-align: justify;">For the hash function we can use a function analyzed in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XDietzfelbingerHKP97">DHKP97</a>]</span>. Let <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> be a random odd number modulo <img alt="2^{n}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{n}"/>. Define</p>
<div style="text-align: center;"><img alt="\begin{aligned} h_{a}(x):=(a\cdot x\gg n-\ell )\mod 2^{\ell } \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+h_%7Ba%7D%28x%29%3A%3D%28a%5Ccdot+x%5Cgg+n-%5Cell+%29%5Cmod+2%5E%7B%5Cell+%7D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} h_{a}(x):=(a\cdot x\gg n-\ell )\mod 2^{\ell } \end{aligned}"/></div>
<p>where the product <img alt="a\cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot x"/> is integer multiplication, and <img alt="\gg " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgg+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\gg "/> is bit-shift. In other words we output the bits <img alt="n-\ell +1,n-\ell +2,\ldots ,n" class="latex" src="https://s0.wp.com/latex.php?latex=n-%5Cell+%2B1%2Cn-%5Cell+%2B2%2C%5Cldots+%2Cn&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n-\ell +1,n-\ell +2,\ldots ,n"/> of the integer product <img alt="a\cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot x"/>.</p>
<p style="text-align: justify;">We now verify that the above hash function family satisfies the three properties we required above.</p>
<p style="text-align: justify;">Property (3) is trivially satisfied.</p>
<p style="text-align: justify;">For property (1) we have the following. Let <img alt="s=a\cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=s%3Da%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s=a\cdot x"/> and <img alt="t=a\cdot y" class="latex" src="https://s0.wp.com/latex.php?latex=t%3Da%5Ccdot+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="t=a\cdot y"/> and <img alt="u=n-\ell " class="latex" src="https://s0.wp.com/latex.php?latex=u%3Dn-%5Cell+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="u=n-\ell "/>. To recap, by definition we have:</p>
<ul class="itemize1">
<li class="itemize"><img alt="h_{a}(x+y)=((s+t)\gg u)\mod 2^{\ell }," class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%29%3D%28%28s%2Bt%29%5Cgg+u%29%5Cmod+2%5E%7B%5Cell+%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x+y)=((s+t)\gg u)\mod 2^{\ell },"/></li>
<li class="itemize"><img alt="h_{a}(x)=(s\gg u)\mod 2^{\ell }" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%3D%28s%5Cgg+u%29%5Cmod+2%5E%7B%5Cell+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)=(s\gg u)\mod 2^{\ell }"/>,</li>
<li class="itemize"><img alt="h_{a}(x)=(t\gg u)\mod 2^{\ell }" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%3D%28t%5Cgg+u%29%5Cmod+2%5E%7B%5Cell+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{a}(x)=(t\gg u)\mod 2^{\ell }"/>.</li>
</ul>
<p style="text-align: justify;">Notice that if in the addition <img alt="s+t" class="latex" src="https://s0.wp.com/latex.php?latex=s%2Bt&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s+t"/> the carry into the <img alt="u+1" class="latex" src="https://s0.wp.com/latex.php?latex=u%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="u+1"/> bit is <img alt="0" class="latex" src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="0"/>, then</p>
<div style="text-align: center;"><img alt="\begin{aligned} (s\gg u)+(t\gg u)=(s+t)\gg u \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28s%5Cgg+u%29%2B%28t%5Cgg+u%29%3D%28s%2Bt%29%5Cgg+u+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (s\gg u)+(t\gg u)=(s+t)\gg u \end{aligned}"/></div>
<p>otherwise</p>
<div style="text-align: center;"><img alt="\begin{aligned} (s\gg u)+(t\gg u)+1=(s+t)\gg u \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28s%5Cgg+u%29%2B%28t%5Cgg+u%29%2B1%3D%28s%2Bt%29%5Cgg+u+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (s\gg u)+(t\gg u)+1=(s+t)\gg u \end{aligned}"/></div>
<p>which concludes the proof for property (1).</p>
<p style="text-align: justify;">Finally, we prove property (2). We start by writing <img alt="x=s\cdot 2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Ds%5Ccdot+2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=s\cdot 2^{c}"/> where <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> is odd. So the binary representation of <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> looks like</p>
<div style="text-align: center;"><img alt="\begin{aligned} (\cdots \cdots 1\underbrace {0\cdots 0}_{c~\textrm {bits}}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28%5Ccdots+%5Ccdots+1%5Cunderbrace+%7B0%5Ccdots+0%7D_%7Bc%7E%5Ctextrm+%7Bbits%7D%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (\cdots \cdots 1\underbrace {0\cdots 0}_{c~\textrm {bits}}). \end{aligned}"/></div>
<p>The binary representation of the product <img alt="a\cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot x"/> for a uniformly random <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> looks like</p>
<div style="text-align: center;"><img alt="\begin{aligned} (\textit {uniform}~1\underbrace {0\cdots 0}_{c~\textrm {bits}}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28%5Ctextit+%7Buniform%7D%7E1%5Cunderbrace+%7B0%5Ccdots+0%7D_%7Bc%7E%5Ctextrm+%7Bbits%7D%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (\textit {uniform}~1\underbrace {0\cdots 0}_{c~\textrm {bits}}). \end{aligned}"/></div>
<p>We consider the two following cases for the product <img alt="a\cdot x" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot x"/>:</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-9008x1">If <img alt="a\cdot x=(\underbrace {\textit {uniform}~1\overbrace {00}^{2~bits}}_{\ell ~bits}\cdots 0)" class="latex" src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x%3D%28%5Cunderbrace+%7B%5Ctextit+%7Buniform%7D%7E1%5Coverbrace+%7B00%7D%5E%7B2%7Ebits%7D%7D_%7B%5Cell+%7Ebits%7D%5Ccdots+0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a\cdot x=(\underbrace {\textit {uniform}~1\overbrace {00}^{2~bits}}_{\ell ~bits}\cdots 0)"/>, or equivalently <img alt="c\geq n-\ell +2" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cgeq+n-%5Cell+%2B2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\geq n-\ell +2"/>, the output never lands in the bad set <img alt="\{-2,-1,0,1,2\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B-2%2C-1%2C0%2C1%2C2%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{-2,-1,0,1,2\}"/>;</li>
<li class="enumerate" id="x1-9010x2">Otherwise, the hash function output has <img alt="\ell -O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell+-O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ell -O(1)"/> uniform bits. For any set <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/>, the probability that the output lands in <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> is at most <img alt="|B|\cdot 2^{-\ell +O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CB%7C%5Ccdot+2%5E%7B-%5Cell+%2BO%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|B|\cdot 2^{-\ell +O(1)}"/>.</li>
</ol>
<h4 class="subsectionHead"><span class="titlemark">4.3 </span> <a id="x1-100004.3"/>Quasirandom groups</h4>
<p style="text-align: justify;">What happens in other groups? The hash function used in the previous result was fairly non-trivial. Do we have an almost linear hash function for <img alt="2\times 2" class="latex" src="https://s0.wp.com/latex.php?latex=2%5Ctimes+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2\times 2"/> matrices? The answer is negative. For <img alt="SL_{2}(q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL_%7B2%7D%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL_{2}(q)"/> and <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/> the problem is hard, even under the promise. For a group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> the complexity can be expressed in terms of a parameter <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> which comes from representation theory. We will not formally define this parameter here, but several qualitatively equivalent formulations can be found in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>]</span>. Instead the following table shows the <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>’s for the groups we’ve introduced.</p>
<div style="text-align: center;">
<div class="tabular">
<table cellpadding="0" cellspacing="0" class="tabular" id="TBL-1">
<colgroup id="TBL-1-1g">
<col id="TBL-1-1"/></colgroup>
<colgroup id="TBL-1-2g">
<col id="TBL-1-2"/></colgroup>
<colgroup id="TBL-1-3g">
<col id="TBL-1-3"/></colgroup>
<colgroup id="TBL-1-4g">
<col id="TBL-1-4"/></colgroup>
<colgroup id="TBL-1-5g">
<col id="TBL-1-5"/></colgroup>
<tbody>
<tr class="hline">
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
</tr>
<tr id="TBL-1-1-" style="vertical-align: baseline;">
<td class="td11" id="TBL-1-1-1" style="white-space: nowrap; text-align: center;"><img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/></td>
<td class="td11" id="TBL-1-1-2" style="white-space: nowrap; text-align: center;">:</td>
<td class="td11" id="TBL-1-1-3" style="white-space: nowrap; text-align: center;">abelian</td>
<td class="td11" id="TBL-1-1-4" style="white-space: nowrap; text-align: center;"><img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/></td>
<td class="td11" id="TBL-1-1-5" style="white-space: nowrap; text-align: center;"><img alt="SL_{2}(q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL_%7B2%7D%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL_{2}(q)"/></td>
</tr>
<tr class="hline">
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
</tr>
<tr id="TBL-1-2-" style="vertical-align: baseline;">
<td class="td11" id="TBL-1-2-1" style="white-space: nowrap; text-align: center;"><img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/></td>
<td class="td11" id="TBL-1-2-2" style="white-space: nowrap; text-align: center;">:</td>
<td class="td11" id="TBL-1-2-3" style="white-space: nowrap; text-align: center;"><img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/></td>
<td class="td11" id="TBL-1-2-4" style="white-space: nowrap; text-align: center;"><img alt="\Omega (\frac {\log |G|}{\log \log |G|})" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Cfrac+%7B%5Clog+%7CG%7C%7D%7B%5Clog+%5Clog+%7CG%7C%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\frac {\log |G|}{\log \log |G|})"/></td>
<td class="td11" id="TBL-1-2-5" style="white-space: nowrap; text-align: center;"><img alt="|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|G|^{\Omega (1)}"/></td>
</tr>
<tr class="hline">
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
<td>
<hr/>
</td>
</tr>
<tr id="TBL-1-3-" style="vertical-align: baseline;">
<td class="td11" id="TBL-1-3-1" style="white-space: nowrap; text-align: center;"/>
</tr>
</tbody>
</table>
</div>
<p>.</p>
</div>
<p> </p>
<p style="text-align: justify;"><b>Theorem 1.</b> Let <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> be a group, and let <img alt="h\in G" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\in G"/>. Let <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> be the minimum dimension of any irreducible representation of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>. Suppose Alice, Bob, and Charlie receive <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, y, and <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z"/> respectively. They are promised that <img alt="x\cdot y\cdot z" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%5Ccdot+z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y\cdot z"/> either equals <img alt="1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1_{G}"/> or <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/>. Deciding which case it is requires randomized communication complexity <img alt="\Omega (\log d)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+d%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log d)"/>.</p>
<p style="text-align: justify;">This result is tight for the groups we have discussed so far. The arguments are the same as before. Specifically, for <img alt="SL_{2}(q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL_%7B2%7D%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL_{2}(q)"/> the communication is <img alt="\Omega (\log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log |G|)"/>. This is tight up to constants, because Alice and Bob can send their elements. For <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/> the communication is <img alt="\Omega (\log \log |G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log \log |G|)"/>. This is tight as well, as the parties can again just communicate the images of an element <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/> such that <img alt="h(a)\ne a" class="latex" src="https://s0.wp.com/latex.php?latex=h%28a%29%5Cne+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h(a)\ne a"/>, as discussed in Section <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a>. This also gives a computational proof that <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> cannot be too large for <img alt="A_{n}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A_{n}"/>, i.e., it is at most <img alt="(\log |G|)^{O(1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Clog+%7CG%7C%29%5E%7BO%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\log |G|)^{O(1)}"/>. For abelian groups we get nothing, matching the efficient protocols given above.</p>
<h3 class="sectionHead"><span class="titlemark">5 </span> <a id="x1-110005"/>Proof of Theorem 1</h3>
<p style="text-align: justify;">First we discuss several “mixing” lemmas for groups, then we come back to protocols and see how to apply one of them there.</p>
<h5 class="subsubsectionHead"><span class="titlemark">5.0.1 </span> <a id="x1-120005.0.1"/><img alt="XY" class="latex" src="https://s0.wp.com/latex.php?latex=XY&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="XY"/> mixing</h5>
<p style="text-align: justify;">We want to consider “high entropy” distributions over <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>, and state a fact showing that the multiplication of two such distributions “mixes” or in other words increases the entropy. To define entropy we use the norms <img alt="\lVert A\rVert _{c}=\left (\sum _{x}A(x)^{c}\right )^{\frac {1}{c}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+A%5CrVert+_%7Bc%7D%3D%5Cleft+%28%5Csum+_%7Bx%7DA%28x%29%5E%7Bc%7D%5Cright+%29%5E%7B%5Cfrac+%7B1%7D%7Bc%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert A\rVert _{c}=\left (\sum _{x}A(x)^{c}\right )^{\frac {1}{c}}"/>. Our notion of (non-)entropy will be <img alt="\lVert A\rVert _{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+A%5CrVert+_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert A\rVert _{2}"/>. Note that <img alt="\lVert A\rVert _{2}^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert A\rVert _{2}^{2}"/> is exactly the <em>collision probability</em> <img alt="\mathbb{P} [A=A']" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5BA%3DA%27%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [A=A']"/> where <img alt="A'" class="latex" src="https://s0.wp.com/latex.php?latex=A%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A'"/> is independent and identically distributed to <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>. The smaller this quantity, the higher the entropy of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>. For the uniform distribution <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> we have <img alt="\lVert U\rVert _{2}^{2}=\frac {1}{|G|}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+U%5CrVert+_%7B2%7D%5E%7B2%7D%3D%5Cfrac+%7B1%7D%7B%7CG%7C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert U\rVert _{2}^{2}=\frac {1}{|G|}"/> and so we can think of <img alt="1/|G|" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|"/> as maximum entropy. If <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> is uniform over <img alt="\Omega (|G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (|G|)"/> elements, we have <img alt="\lVert A\rVert _{2}^{2}=O(1/|G|)" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D%3DO%281%2F%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert A\rVert _{2}^{2}=O(1/|G|)"/> and we think of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> as having “high” entropy.</p>
<p style="text-align: justify;">Because the entropy of <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> is small, we can think of the distance between <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> in the 2-norm as being essentially the entropy of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>:</p>
<div style="text-align: center;"><img alt="\begin{aligned} \lVert A-U\rVert _{2}^{2} &amp; =\sum _{x\in G}\left (A(x)-\frac {1}{|G|}\right )^{2}\\ &amp; =\sum _{x\in G}A(x)^{2}-2A(x)\frac {1}{|G|}+\frac {1}{|G|^{2}}\\ &amp; =\lVert A\rVert _{2}^{2}-\frac {1}{|G|}\\ &amp; =\lVert A\rVert _{2}^{2}-\lVert U\rVert _{2}^{2}\\ &amp; \approx \lVert A\rVert _{2}^{2}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5ClVert+A-U%5CrVert+_%7B2%7D%5E%7B2%7D+%26+%3D%5Csum+_%7Bx%5Cin+G%7D%5Cleft+%28A%28x%29-%5Cfrac+%7B1%7D%7B%7CG%7C%7D%5Cright+%29%5E%7B2%7D%5C%5C+%26+%3D%5Csum+_%7Bx%5Cin+G%7DA%28x%29%5E%7B2%7D-2A%28x%29%5Cfrac+%7B1%7D%7B%7CG%7C%7D%2B%5Cfrac+%7B1%7D%7B%7CG%7C%5E%7B2%7D%7D%5C%5C+%26+%3D%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D-%5Cfrac+%7B1%7D%7B%7CG%7C%7D%5C%5C+%26+%3D%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D-%5ClVert+U%5CrVert+_%7B2%7D%5E%7B2%7D%5C%5C+%26+%5Capprox+%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \lVert A-U\rVert _{2}^{2} &amp; =\sum _{x\in G}\left (A(x)-\frac {1}{|G|}\right )^{2}\\ &amp; =\sum _{x\in G}A(x)^{2}-2A(x)\frac {1}{|G|}+\frac {1}{|G|^{2}}\\ &amp; =\lVert A\rVert _{2}^{2}-\frac {1}{|G|}\\ &amp; =\lVert A\rVert _{2}^{2}-\lVert U\rVert _{2}^{2}\\ &amp; \approx \lVert A\rVert _{2}^{2}. \end{aligned}"/></div>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-12001r7"/> Lemma 7. </span><span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBabaiNP08">BNP08</a>]</span> If <img alt="X,Y" class="latex" src="https://s0.wp.com/latex.php?latex=X%2CY&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X,Y"/> are independent over <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>, then</p>
<div style="text-align: center;"><img alt="\begin{aligned} \lVert X\cdot Y-U\rVert _{2}\leq \lVert X\rVert _{2}\lVert Y\rVert _{2}\sqrt {\frac {|G|}{d}}, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5ClVert+X%5Ccdot+Y-U%5CrVert+_%7B2%7D%5Cleq+%5ClVert+X%5CrVert+_%7B2%7D%5ClVert+Y%5CrVert+_%7B2%7D%5Csqrt+%7B%5Cfrac+%7B%7CG%7C%7D%7Bd%7D%7D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \lVert X\cdot Y-U\rVert _{2}\leq \lVert X\rVert _{2}\lVert Y\rVert _{2}\sqrt {\frac {|G|}{d}}, \end{aligned}"/></div>
<p>where <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> is the minimum dimension of an irreducible representation of <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">By this lemma, for high entropy distributions <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/>, we get <img alt="\lVert X\cdot Y-U\rVert _{2}\leq \frac {O(1)}{\sqrt {|G|d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+X%5Ccdot+Y-U%5CrVert+_%7B2%7D%5Cleq+%5Cfrac+%7BO%281%29%7D%7B%5Csqrt+%7B%7CG%7Cd%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert X\cdot Y-U\rVert _{2}\leq \frac {O(1)}{\sqrt {|G|d}}"/>. The factor <img alt="1/\sqrt {|G|}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Csqrt+%7B%7CG%7C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/\sqrt {|G|}"/> allows us to pass to <em>statistical distance </em><img alt="\lVert .\rVert _{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+.%5CrVert+_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert .\rVert _{1}"/> using Cauchy-Schwarz:</p>
<div style="text-align: center;"><img alt="\begin{aligned} \lVert X\cdot Y-U\rVert _{1}\leq \sqrt {|G|}\lVert X\cdot Y-U\rVert _{2}\leq \frac {O(1)}{\sqrt {d}}.~~~~(1) \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5ClVert+X%5Ccdot+Y-U%5CrVert+_%7B1%7D%5Cleq+%5Csqrt+%7B%7CG%7C%7D%5ClVert+X%5Ccdot+Y-U%5CrVert+_%7B2%7D%5Cleq+%5Cfrac+%7BO%281%29%7D%7B%5Csqrt+%7Bd%7D%7D.%7E%7E%7E%7E%281%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \lVert X\cdot Y-U\rVert _{1}\leq \sqrt {|G|}\lVert X\cdot Y-U\rVert _{2}\leq \frac {O(1)}{\sqrt {d}}.~~~~(1) \end{aligned}"/></div>
<p style="text-align: justify;">This is the way in which we will use the lemma.</p>
<p style="text-align: justify;">Another useful consequence of this lemma, which however we will not use directly, is this. Suppose now you have <img alt="three" class="latex" src="https://s0.wp.com/latex.php?latex=three&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="three"/> independent, high-entropy variables <img alt="X,Y,Z" class="latex" src="https://s0.wp.com/latex.php?latex=X%2CY%2CZ&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X,Y,Z"/>. Then for every <img alt="g\in G" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\in G"/> we have</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb{P} [X\cdot Y\cdot Z=g]-1/|G||\le \lVert X\rVert _{2}\lVert Y\rVert _{2}\lVert Z\rVert _{2}\sqrt {\frac {|G|}{d}}.~~~~(2) \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb%7BP%7D+%5BX%5Ccdot+Y%5Ccdot+Z%3Dg%5D-1%2F%7CG%7C%7C%5Cle+%5ClVert+X%5CrVert+_%7B2%7D%5ClVert+Y%5CrVert+_%7B2%7D%5ClVert+Z%5CrVert+_%7B2%7D%5Csqrt+%7B%5Cfrac+%7B%7CG%7C%7D%7Bd%7D%7D.%7E%7E%7E%7E%282%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb{P} [X\cdot Y\cdot Z=g]-1/|G||\le \lVert X\rVert _{2}\lVert Y\rVert _{2}\lVert Z\rVert _{2}\sqrt {\frac {|G|}{d}}.~~~~(2) \end{aligned}"/></div>
<p style="text-align: justify;">To show this, set <img alt="g=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g=1_{G}"/> without loss of generality and rewrite the left-hand-side as</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\sum _{h\in G}\mathbb{P} [X=h](\mathbb{P} [YZ=h^{-1}]-1/|G|)|. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Csum+_%7Bh%5Cin+G%7D%5Cmathbb%7BP%7D+%5BX%3Dh%5D%28%5Cmathbb%7BP%7D+%5BYZ%3Dh%5E%7B-1%7D%5D-1%2F%7CG%7C%29%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\sum _{h\in G}\mathbb{P} [X=h](\mathbb{P} [YZ=h^{-1}]-1/|G|)|. \end{aligned}"/></div>
<p>By Cauchy-Schwarz this is at most</p>
<div style="text-align: center;"><img alt="\begin{aligned} \sqrt {\sum _{h}\mathbb{P} ^{2}[X=h]}\sqrt {\sum _{h}(\mathbb{P} [YZ=h^{-1}]-1/|G|)^{2}}=\lVert X\lVert _{2}\lVert YZ-U\lVert _{2} \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Csqrt+%7B%5Csum+_%7Bh%7D%5Cmathbb%7BP%7D+%5E%7B2%7D%5BX%3Dh%5D%7D%5Csqrt+%7B%5Csum+_%7Bh%7D%28%5Cmathbb%7BP%7D+%5BYZ%3Dh%5E%7B-1%7D%5D-1%2F%7CG%7C%29%5E%7B2%7D%7D%3D%5ClVert+X%5ClVert+_%7B2%7D%5ClVert+YZ-U%5ClVert+_%7B2%7D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \sqrt {\sum _{h}\mathbb{P} ^{2}[X=h]}\sqrt {\sum _{h}(\mathbb{P} [YZ=h^{-1}]-1/|G|)^{2}}=\lVert X\lVert _{2}\lVert YZ-U\lVert _{2} \end{aligned}"/></div>
<p>and we can conclude by Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7<!--tex4ht:ref: lem:XY-mixing --></a>. Hence the product of three high-entropy distributions is close to uniform in a point-wise sense: each group element is obtained with roughly probability <img alt="1/|G|" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|"/>.</p>
<p style="text-align: justify;">At least over <img alt="SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="SL(2,q)"/>, there exists an alternative proof of this fact that does not mention representation theory (see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span> and <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#Xviola-blog-mixing-in-groups">Vioa</a>, <a href="https://emanueleviola.wordpress.com/feed/#Xviola-blog-mixing-in-groups-ii">Viob</a>]</span>).</p>
<p style="text-align: justify;">With this notation in hand, we conclude by stating a “mixing” version of Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-20002">2<!--tex4ht:ref: sec:Two-parties --></a>. For more on this perspective we refer the reader to <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. <a id="x1-12002r1"/></p>
<p style="text-align: justify;"><b>Theorem 1.</b> Let <img alt="G=SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DSL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=SL(2,q)"/>. Let <img alt="X=(X_{1},X_{2})" class="latex" src="https://s0.wp.com/latex.php?latex=X%3D%28X_%7B1%7D%2CX_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X=(X_{1},X_{2})"/> and <img alt="Y=(Y_{1},Y_{2})" class="latex" src="https://s0.wp.com/latex.php?latex=Y%3D%28Y_%7B1%7D%2CY_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y=(Y_{1},Y_{2})"/> be two distributions over <img alt="G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G^{2}"/>. Suppose <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> is independent from <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/>. Let <img alt="g\in G" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\in G"/>. We have</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb{P} [X_{1}Y_{1}X_{2}Y_{2}=g]-1/|G||\le |G|^{1-\Omega (1)}\lVert X\rVert _{2}\lVert Y\rVert _{2}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb%7BP%7D+%5BX_%7B1%7DY_%7B1%7DX_%7B2%7DY_%7B2%7D%3Dg%5D-1%2F%7CG%7C%7C%5Cle+%7CG%7C%5E%7B1-%5COmega+%281%29%7D%5ClVert+X%5CrVert+_%7B2%7D%5ClVert+Y%5CrVert+_%7B2%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb{P} [X_{1}Y_{1}X_{2}Y_{2}=g]-1/|G||\le |G|^{1-\Omega (1)}\lVert X\rVert _{2}\lVert Y\rVert _{2}. \end{aligned}"/></div>
<p style="text-align: justify;">For example, when <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X"/> and <img alt="Y" class="latex" src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Y"/> have high entropy over <img alt="G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G^{2}"/> (that is, are uniform over <img alt="\Omega (|G|^{2})" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%7CG%7C%5E%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (|G|^{2})"/> pairs), we have <img alt="\lVert X\rVert _{2}\le \sqrt {O(1)/|G|^{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+X%5CrVert+_%7B2%7D%5Cle+%5Csqrt+%7BO%281%29%2F%7CG%7C%5E%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert X\rVert _{2}\le \sqrt {O(1)/|G|^{2}}"/>, and so <img alt="|G|^{1-\Omega (1)}\lVert X\rVert _{2}\lVert Y\rVert _{2}\le 1/|G|^{1+\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CG%7C%5E%7B1-%5COmega+%281%29%7D%5ClVert+X%5CrVert+_%7B2%7D%5ClVert+Y%5CrVert+_%7B2%7D%5Cle+1%2F%7CG%7C%5E%7B1%2B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|G|^{1-\Omega (1)}\lVert X\rVert _{2}\lVert Y\rVert _{2}\le 1/|G|^{1+\Omega (1)}"/>. In particular, <img alt="X_{1}Y_{1}X_{2}Y_{2}" class="latex" src="https://s0.wp.com/latex.php?latex=X_%7B1%7DY_%7B1%7DX_%7B2%7DY_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_{1}Y_{1}X_{2}Y_{2}"/> is <img alt="1/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|^{\Omega (1)}"/> close to uniform over <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> in statistical distance.</p>
<h5 class="subsubsectionHead"><span class="titlemark">5.0.2 </span> <a id="x1-130005.0.2"/>Back to protocols</h5>
<p style="text-align: justify;">As in the beginning of Section <a href="https://emanueleviola.wordpress.com/feed/#x1-30003">3<!--tex4ht:ref: sec:Proof-of-Gowers-Viola --></a>, for any group element <img alt="g\in G" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\in G"/> we define the distribution on triples <img alt="D_{g}:=(x,y,(x\cdot y)^{-1}g)" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7Bg%7D%3A%3D%28x%2Cy%2C%28x%5Ccdot+y%29%5E%7B-1%7Dg%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{g}:=(x,y,(x\cdot y)^{-1}g)"/>, where <img alt="x,y\in G" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y\in G"/> are uniform and independent. Note the product of the elements in <img alt="D_{g}" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7Bg%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{g}"/> is always <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/>. Again as in Section <a href="https://emanueleviola.wordpress.com/feed/#x1-30003">3<!--tex4ht:ref: sec:Proof-of-Gowers-Viola --></a>, it suffices to show that for every <em>deterministic</em> protocols <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> using little communication we have</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\Pr [P(D_{1})=1]-\Pr [P(D_{h})=1]|\leq \frac {1}{100}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5CPr+%5BP%28D_%7B1%7D%29%3D1%5D-%5CPr+%5BP%28D_%7Bh%7D%29%3D1%5D%7C%5Cleq+%5Cfrac+%7B1%7D%7B100%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\Pr [P(D_{1})=1]-\Pr [P(D_{h})=1]|\leq \frac {1}{100}. \end{aligned}"/></div>
<p style="text-align: justify;">Analogously to Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-4001r4">4<!--tex4ht:ref: lem:prot-rect --></a>, the following lemma describes a protocol using rectangles. The proof is nearly identical and is omitted.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-13001r8"/> Lemma 8. </span>(The set of accepted inputs of) A deterministic <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>-bit number-in-hand protocol with three parties can be written as a disjoint union of <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> “rectangles,” that is sets of the form <img alt="A\times B\times C" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B%5Ctimes+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\times B\times C"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">Next we show that these product sets cannot distinguish these two distributions <img alt="D_{1},D_{h}" class="latex" src="https://s0.wp.com/latex.php?latex=D_%7B1%7D%2CD_%7Bh%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D_{1},D_{h}"/>, via a straightforward application of lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7<!--tex4ht:ref: lem:XY-mixing --></a>.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-13002r9"/> Lemma 9. </span>For all <img alt="A,B,C\subseteq G" class="latex" src="https://s0.wp.com/latex.php?latex=A%2CB%2CC%5Csubseteq+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A,B,C\subseteq G"/> we have <img alt="|\mathbb{P} (A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\leq 1/d^{\Omega (1)}." class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb%7BP%7D+%28A%5Ctimes+B%5Ctimes+C%29%28D_%7B1%7D%29%3D1%5D-%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7Bh%7D%29%3D1%5D%7C%5Cleq+1%2Fd%5E%7B%5COmega+%281%29%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathbb{P} (A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\leq 1/d^{\Omega (1)}."/></p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Pick any <img alt="h\in G" class="latex" src="https://s0.wp.com/latex.php?latex=h%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h\in G"/> and let <img alt="x,y,z" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%2Cz&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y,z"/> be the inputs of Alice, Bob, and Charlie respectively. Then</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb{P} [(A\times B\times C)(D_{h})=1]=\mathbb{P} [(x,y)\in A\times B]\cdot \mathbb{P} [(x\cdot y)^{-1}\cdot h\in C|(x,y)\in A\times B],~~~~(3) \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7Bh%7D%29%3D1%5D%3D%5Cmathbb%7BP%7D+%5B%28x%2Cy%29%5Cin+A%5Ctimes+B%5D%5Ccdot+%5Cmathbb%7BP%7D+%5B%28x%5Ccdot+y%29%5E%7B-1%7D%5Ccdot+h%5Cin+C%7C%28x%2Cy%29%5Cin+A%5Ctimes+B%5D%2C%7E%7E%7E%7E%283%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb{P} [(A\times B\times C)(D_{h})=1]=\mathbb{P} [(x,y)\in A\times B]\cdot \mathbb{P} [(x\cdot y)^{-1}\cdot h\in C|(x,y)\in A\times B],~~~~(3) \end{aligned}"/></div>
<p>where <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/> is uniform in <img alt="G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G^{2}"/>. If either <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> or <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> is small, that is <img alt="\mathbb{P} [x\in A]\leq \epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5Bx%5Cin+A%5D%5Cleq+%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [x\in A]\leq \epsilon "/> or <img alt="\mathbb{P} [y\in B]\leq \epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5By%5Cin+B%5D%5Cleq+%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [y\in B]\leq \epsilon "/>, then also <img alt="\mathbb{P} [(x,y)\in A\times B]\le \epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5B%28x%2Cy%29%5Cin+A%5Ctimes+B%5D%5Cle+%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [(x,y)\in A\times B]\le \epsilon "/> and hence (??) is at most <img alt="\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon "/> as well. This holds for every <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/>, so we also have <img alt="|\mathbb{P} (A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\leq \epsilon ." class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb%7BP%7D+%28A%5Ctimes+B%5Ctimes+C%29%28D_%7B1%7D%29%3D1%5D-%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7Bh%7D%29%3D1%5D%7C%5Cleq+%5Cepsilon+.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathbb{P} (A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\leq \epsilon ."/> We will choose <img alt="\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon "/> later.</p>
<p style="text-align: justify;">Otherwise, <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B"/> are large: <img alt="\mathbb{P} [x\in A]&gt;\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5Bx%5Cin+A%5D%3E%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [x\in A]&gt;\epsilon "/> and <img alt="\mathbb{P} [y\in B]&gt;\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5By%5Cin+B%5D%3E%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} [y\in B]&gt;\epsilon "/>. Let <img alt="(x',y')" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%27%2Cy%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x',y')"/> be the distribution of <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/> conditioned on <img alt="(x,y)\in A\times B" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29%5Cin+A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)\in A\times B"/>. We have that <img alt="x'" class="latex" src="https://s0.wp.com/latex.php?latex=x%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x'"/> and <img alt="y'" class="latex" src="https://s0.wp.com/latex.php?latex=y%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y'"/> are independent and each is uniform over at least <img alt="\epsilon |G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon |G|"/> elements. By Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7<!--tex4ht:ref: lem:XY-mixing --></a> this implies <img alt="\lVert x'\cdot y'-U\rVert _{2}\leq \lVert x'\rVert _{2}\cdot \lVert y'\rVert _{2}\cdot \sqrt {\frac {|G|}{d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+x%27%5Ccdot+y%27-U%5CrVert+_%7B2%7D%5Cleq+%5ClVert+x%27%5CrVert+_%7B2%7D%5Ccdot+%5ClVert+y%27%5CrVert+_%7B2%7D%5Ccdot+%5Csqrt+%7B%5Cfrac+%7B%7CG%7C%7D%7Bd%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert x'\cdot y'-U\rVert _{2}\leq \lVert x'\rVert _{2}\cdot \lVert y'\rVert _{2}\cdot \sqrt {\frac {|G|}{d}}"/>, where <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> is the uniform distribution. As mentioned after the lemma, by Cauchy–Schwarz we obtain</p>
<div style="text-align: center;"><img alt="\begin{aligned} \lVert x'\cdot y'-U\rVert _{1}\leq |G|\cdot \lVert x'\rVert _{2}\cdot \lVert y'\rVert _{2}\cdot \sqrt {\frac {1}{d}}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5ClVert+x%27%5Ccdot+y%27-U%5CrVert+_%7B1%7D%5Cleq+%7CG%7C%5Ccdot+%5ClVert+x%27%5CrVert+_%7B2%7D%5Ccdot+%5ClVert+y%27%5CrVert+_%7B2%7D%5Ccdot+%5Csqrt+%7B%5Cfrac+%7B1%7D%7Bd%7D%7D%5Cleq+%5Cfrac+%7B1%7D%7B%5Cepsilon+%7D%5Ccdot+%5Cfrac+%7B1%7D%7B%5Csqrt+%7Bd%7D%7D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \lVert x'\cdot y'-U\rVert _{1}\leq |G|\cdot \lVert x'\rVert _{2}\cdot \lVert y'\rVert _{2}\cdot \sqrt {\frac {1}{d}}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}, \end{aligned}"/></div>
<p>where the last inequality follows from the fact that <img alt="\lVert x\rVert _{2},\lVert y\rVert _{2}\leq \sqrt {\frac {1}{\epsilon |G|}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+x%5CrVert+_%7B2%7D%2C%5ClVert+y%5CrVert+_%7B2%7D%5Cleq+%5Csqrt+%7B%5Cfrac+%7B1%7D%7B%5Cepsilon+%7CG%7C%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert x\rVert _{2},\lVert y\rVert _{2}\leq \sqrt {\frac {1}{\epsilon |G|}}"/>.</p>
<p style="text-align: justify;">This implies that <img alt="\lVert (x'\cdot y')^{-1}-U\rVert _{1}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+%28x%27%5Ccdot+y%27%29%5E%7B-1%7D-U%5CrVert+_%7B1%7D%5Cleq+%5Cfrac+%7B1%7D%7B%5Cepsilon+%7D%5Ccdot+%5Cfrac+%7B1%7D%7B%5Csqrt+%7Bd%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert (x'\cdot y')^{-1}-U\rVert _{1}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}"/> and <img alt="\lVert (x'\cdot y')^{-1}\cdot h-U\rVert _{1}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}" class="latex" src="https://s0.wp.com/latex.php?latex=%5ClVert+%28x%27%5Ccdot+y%27%29%5E%7B-1%7D%5Ccdot+h-U%5CrVert+_%7B1%7D%5Cleq+%5Cfrac+%7B1%7D%7B%5Cepsilon+%7D%5Ccdot+%5Cfrac+%7B1%7D%7B%5Csqrt+%7Bd%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lVert (x'\cdot y')^{-1}\cdot h-U\rVert _{1}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}"/>, because taking inverses and multiplying by <img alt="h" class="latex" src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h"/> does not change the distance to uniform. These two last inequalities imply that</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb{P} [(x'\cdot y')^{-1}\in C]-\mathbb{P} [(x'\cdot y')^{-1}\cdot h\in C]|\le O(\frac {1}{\epsilon \sqrt {d}}); \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb%7BP%7D+%5B%28x%27%5Ccdot+y%27%29%5E%7B-1%7D%5Cin+C%5D-%5Cmathbb%7BP%7D+%5B%28x%27%5Ccdot+y%27%29%5E%7B-1%7D%5Ccdot+h%5Cin+C%5D%7C%5Cle+O%28%5Cfrac+%7B1%7D%7B%5Cepsilon+%5Csqrt+%7Bd%7D%7D%29%3B+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb{P} [(x'\cdot y')^{-1}\in C]-\mathbb{P} [(x'\cdot y')^{-1}\cdot h\in C]|\le O(\frac {1}{\epsilon \sqrt {d}}); \end{aligned}"/></div>
<p>and thus we get that</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb{P} [(A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\le O(\frac {1}{\epsilon \sqrt {d}}). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7B1%7D%29%3D1%5D-%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7Bh%7D%29%3D1%5D%7C%5Cle+O%28%5Cfrac+%7B1%7D%7B%5Cepsilon+%5Csqrt+%7Bd%7D%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb{P} [(A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\le O(\frac {1}{\epsilon \sqrt {d}}). \end{aligned}"/></div>
<p>Picking <img alt="\epsilon =1/d^{1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1%2Fd%5E%7B1%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon =1/d^{1/4}"/> completes the proof. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">Returning to arbitrary deterministic protocols <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> (as opposed to rectangles), write <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> as a union of <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> disjoint rectangles by Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-13001r8">8<!--tex4ht:ref: lem:prot-nih-rect --></a>. Applying Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-13002r9">9<!--tex4ht:ref: lem:NIH-rect --></a> and summing over all rectangles we get that the distinguishing advantage of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> is at most <img alt="2^{c}/d^{1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D%2Fd%5E%7B1%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}/d^{1/4}"/>. For <img alt="c\leq (1/100)\log d" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cleq+%281%2F100%29%5Clog+d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\leq (1/100)\log d"/> the advantage is at most <img alt="1/100" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F100&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/100"/>, concluding the proof.</p>
<h3 class="sectionHead"><span class="titlemark">6 </span> <a id="x1-140006"/>Three parties, number-on-forehead</h3>
<p style="text-align: justify;">In number-on-forehead (NOH) communication complexity <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XCFL83">CFL83</a>]</span> with <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/> parties, the input is a <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k"/>-tuple <img alt="(x_{1},\dotsc ,x_{k})" class="latex" src="https://s0.wp.com/latex.php?latex=%28x_%7B1%7D%2C%5Cdotsc+%2Cx_%7Bk%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x_{1},\dotsc ,x_{k})"/> and each party <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/> sees all of it except <img alt="x_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x_{i}"/>. For background, it is not known how to prove negative results for <img alt="k\ge \log n" class="latex" src="https://s0.wp.com/latex.php?latex=k%5Cge+%5Clog+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k\ge \log n"/> parties.</p>
<p style="text-align: justify;">We mention that Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a> can be extended to the multiparty setting, see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. Several questions arise here, such as whether this problem remains hard for <img alt="k\ge \log n" class="latex" src="https://s0.wp.com/latex.php?latex=k%5Cge+%5Clog+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k\ge \log n"/>, and what is the minimum length of an interleaved product that is hard for <img alt="k=3" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k=3"/> parties (the proof in <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1<!--tex4ht:ref: thm:GV-interleaved --></a> gives a large constant).</p>
<p style="text-align: justify;">However in this survey we shall instead focus on the problem of separating deterministic and randomized communication. For <img alt="k=2" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k=2"/>, we know the optimal separation: The equality function requires <img alt="\Omega (n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (n)"/> communication for deterministic protocols, but can be solved using <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> communication if we allow the protocols to use public coins. For <img alt="k=3" class="latex" src="https://s0.wp.com/latex.php?latex=k%3D3&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="k=3"/>, the best known separation between deterministic and randomized protocol is <img alt="\Omega (\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log n)"/> vs <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XBeameDPW10">BDPW10</a>]</span>. In the following we give a new proof of this result, for a different function: <img alt="f(x,y,z)=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%2Cz%29%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x,y,z)=1_{G}"/> if and only if <img alt="x\cdot y\cdot z=1" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%5Ccdot+z%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y\cdot z=1"/> for <img alt="x,y,z\in SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%2Cz%5Cin+SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y,z\in SL(2,q)"/>. As is true for some functions in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XBeameDPW10">BDPW10</a>]</span>, a stronger separation could hold for <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>. For context, let us state and prove the upper bound for randomized communication.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-14001r10"/> Claim 10. </span><img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> has randomized communication complexity <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(1)"/>.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>In the number-on-forehead model, computing <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> reduces to two-party equality with no additional communication: Alice computes <img alt="y\cdot z=:w" class="latex" src="https://s0.wp.com/latex.php?latex=y%5Ccdot+z%3D%3Aw&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y\cdot z=:w"/> privately, then Alice and Bob check if <img alt="x=w^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=x%3Dw%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x=w^{-1}"/>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">To prove the lower bound for deterministic protocols we reduce the communication problem to a combinatorial problem.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-14002r11"/> Definition 11. </span>A <em>corner</em> in a group <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> is a set <img alt="\{(x,y),(xz,y),(x,zy)\}\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%29%2C%28xz%2Cy%29%2C%28x%2Czy%29%5C%7D%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(x,y),(xz,y),(x,zy)\}\subseteq G^{2}"/>, where <img alt="x,y" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y"/> are arbitrary group elements and <img alt="z\neq 1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=z%5Cneq+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z\neq 1_{G}"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">For intuition, if <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> is the abelian group of real numbers with addition, a corner becomes <img alt="\{(x,y),(x+z,y),(x,y+z)\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%29%2C%28x%2Bz%2Cy%29%2C%28x%2Cy%2Bz%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(x,y),(x+z,y),(x,y+z)\}"/> for <img alt="z\neq 0" class="latex" src="https://s0.wp.com/latex.php?latex=z%5Cneq+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z\neq 0"/>, which are the coordinates of an isosceles triangle. We now state the theorem that connects corners and lower bounds.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-14003r12"/> Lemma 12. </span>Let <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/> be a group and <img alt="\delta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta "/> a real number. Suppose that every subset <img alt="A\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\subseteq G^{2}"/> with <img alt="|A|/|G^{2}|\ge \delta " class="latex" src="https://s0.wp.com/latex.php?latex=%7CA%7C%2F%7CG%5E%7B2%7D%7C%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|A|/|G^{2}|\ge \delta "/> contains a corner. Then the deterministic communication complexity of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> (defined as <img alt="f(x,y,z)=1\iff x\cdot y\cdot z=1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%2Cz%29%3D1%5Ciff+x%5Ccdot+y%5Ccdot+z%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f(x,y,z)=1\iff x\cdot y\cdot z=1_{G}"/>) is <img alt="\Omega (\log (1/\delta ))" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%281%2F%5Cdelta+%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log (1/\delta ))"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">It is known that <img alt="\delta \ge 1/\mathrm {polyloglog}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cge+1%2F%5Cmathrm+%7Bpolyloglog%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta \ge 1/\mathrm {polyloglog}|G|"/> implies a corner for certain abelian groups <img alt="G" class="latex" src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G"/>, see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMR2289954">LM07</a>]</span> for the best bound and pointers to the history of the problem. For <img alt="G=SL(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3DSL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=SL(2,q)"/> a stronger result is known: <img alt="\delta \ge 1/\mathrm {polylog}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cge+1%2F%5Cmathrm+%7Bpolylog%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta \ge 1/\mathrm {polylog}|G|"/> implies a corner <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAustin2016">Aus16</a>]</span>. This in turn implies communication <img alt="\Omega (\log \log |G|)=\Omega (\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%5Clog+%7CG%7C%29%3D%5COmega+%28%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Omega (\log \log |G|)=\Omega (\log n)"/>.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We saw already twice that a number-in-hand <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>-bit protocol can be written as a disjoint union of <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> rectangles (Lemmas <a href="https://emanueleviola.wordpress.com/feed/#x1-4001r4">4<!--tex4ht:ref: lem:prot-rect --></a>, <a href="https://emanueleviola.wordpress.com/feed/#x1-13001r8">8<!--tex4ht:ref: lem:prot-nih-rect --></a>). Likewise, a number-on-forehead <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>-bit protocol <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> can be written as a disjoint union of <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> cylinder intersections <img alt="C_{i}:=\{(x,y,z):f_{i}(y,z)g_{i}(x,z)h_{i}(x,y)=1\}" class="latex" src="https://s0.wp.com/latex.php?latex=C_%7Bi%7D%3A%3D%5C%7B%28x%2Cy%2Cz%29%3Af_%7Bi%7D%28y%2Cz%29g_%7Bi%7D%28x%2Cz%29h_%7Bi%7D%28x%2Cy%29%3D1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C_{i}:=\{(x,y,z):f_{i}(y,z)g_{i}(x,z)h_{i}(x,y)=1\}"/> for some <img alt="f_{i},g_{i},h_{i}\colon G^{2}\to \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f_%7Bi%7D%2Cg_%7Bi%7D%2Ch_%7Bi%7D%5Ccolon+G%5E%7B2%7D%5Cto+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f_{i},g_{i},h_{i}\colon G^{2}\to \{0,1\}"/>:</p>
<div style="text-align: center;"><img alt="\begin{aligned} P(x,y,z)=\sum _{i=1}^{2^{c}}f_{i}(y,z)g_{i}(x,z)h_{i}(x,y). \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+P%28x%2Cy%2Cz%29%3D%5Csum+_%7Bi%3D1%7D%5E%7B2%5E%7Bc%7D%7Df_%7Bi%7D%28y%2Cz%29g_%7Bi%7D%28x%2Cz%29h_%7Bi%7D%28x%2Cy%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} P(x,y,z)=\sum _{i=1}^{2^{c}}f_{i}(y,z)g_{i}(x,z)h_{i}(x,y). \end{aligned}"/></div>
<p>The proof idea of the above fact is to consider the <img alt="2^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{c}"/> transcripts of <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/>, then one can see that the inputs giving a fixed transcript are a cylinder intersection.</p>
<p style="text-align: justify;">Let <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> be a <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>-bit protocol. Consider the inputs <img alt="\{(x,y,(xy)^{-1})\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%2C%28xy%29%5E%7B-1%7D%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(x,y,(xy)^{-1})\}"/> on which <img alt="P" class="latex" src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="P"/> accepts. Note that at least <img alt="2^{-c}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7B-c%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{-c}"/> fraction of them are accepted by some cylinder intersection <img alt="C=f\cdot g\cdot h" class="latex" src="https://s0.wp.com/latex.php?latex=C%3Df%5Ccdot+g%5Ccdot+h&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="C=f\cdot g\cdot h"/>. Let <img alt="A:=\{(x,y):(x,y,(xy)^{-1})\in C\}\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=A%3A%3D%5C%7B%28x%2Cy%29%3A%28x%2Cy%2C%28xy%29%5E%7B-1%7D%29%5Cin+C%5C%7D%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A:=\{(x,y):(x,y,(xy)^{-1})\in C\}\subseteq G^{2}"/>. Since the first two elements in the tuple determine the last, we have <img alt="|A|/|G^{2}|\ge 2^{-c}" class="latex" src="https://s0.wp.com/latex.php?latex=%7CA%7C%2F%7CG%5E%7B2%7D%7C%5Cge+2%5E%7B-c%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|A|/|G^{2}|\ge 2^{-c}"/>.</p>
<p style="text-align: justify;">Now suppose <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> contains a corner <img alt="\{(x,y),(xz,y),(x,zy)\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%29%2C%28xz%2Cy%29%2C%28x%2Czy%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(x,y),(xz,y),(x,zy)\}"/>. Then</p>
<div style="text-align: center;"><img alt="\begin{aligned} (x,y)\in A &amp; \implies (x,y,(xy)^{-1})\in C &amp; &amp; \implies h(x,y)=1,\\ (xz,y)\in A &amp; \implies (xz,y,(xzy)^{-1})\in C &amp; &amp; \implies f(y,(xyz)^{-1})=1,\\ (x,zy)\in A &amp; \implies (x,zy,(xzy)^{-1})\in C &amp; &amp; \implies g(x,(xyz)^{-1})=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2Cy%29%5Cin+A+%26+%5Cimplies+%28x%2Cy%2C%28xy%29%5E%7B-1%7D%29%5Cin+C+%26+%26+%5Cimplies+h%28x%2Cy%29%3D1%2C%5C%5C+%28xz%2Cy%29%5Cin+A+%26+%5Cimplies+%28xz%2Cy%2C%28xzy%29%5E%7B-1%7D%29%5Cin+C+%26+%26+%5Cimplies+f%28y%2C%28xyz%29%5E%7B-1%7D%29%3D1%2C%5C%5C+%28x%2Czy%29%5Cin+A+%26+%5Cimplies+%28x%2Czy%2C%28xzy%29%5E%7B-1%7D%29%5Cin+C+%26+%26+%5Cimplies+g%28x%2C%28xyz%29%5E%7B-1%7D%29%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} (x,y)\in A &amp; \implies (x,y,(xy)^{-1})\in C &amp; &amp; \implies h(x,y)=1,\\ (xz,y)\in A &amp; \implies (xz,y,(xzy)^{-1})\in C &amp; &amp; \implies f(y,(xyz)^{-1})=1,\\ (x,zy)\in A &amp; \implies (x,zy,(xzy)^{-1})\in C &amp; &amp; \implies g(x,(xyz)^{-1})=1. \end{aligned}"/></div>
<p>This implies <img alt="(x,y,(xzy)^{-1})\in C" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%2C%28xzy%29%5E%7B-1%7D%29%5Cin+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y,(xzy)^{-1})\in C"/>, which is a contradiction because <img alt="z\neq 1" class="latex" src="https://s0.wp.com/latex.php?latex=z%5Cneq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z\neq 1"/> and so <img alt="x\cdot y\cdot (xzy)^{-1}\neq 1_{G}" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%5Ccdot+%28xzy%29%5E%7B-1%7D%5Cneq+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\cdot y\cdot (xzy)^{-1}\neq 1_{G}"/>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<h3 class="sectionHead"><span class="titlemark">7 </span> <a id="x1-150007"/>The corners theorem for quasirandom groups</h3>
<p style="text-align: justify;">In this section we prove the corners theorem for quasirandom groups, following Austin <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAustin2016">Aus16</a>]</span>. Our exposition has several minor differences with that in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAustin2016">Aus16</a>]</span>, which may make it more computer-science friendly. Possibly a proof can also be obtained via certain local modifications and simplifications of Green’s exposition <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGre04-finite">Gre05b</a>, <a href="https://emanueleviola.wordpress.com/feed/#XGreen-supplement">Gre05a</a>]</span> of an earlier proof for the abelian case. We focus on the case <img alt="G=\textit {SL}(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3D%5Ctextit+%7BSL%7D%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=\textit {SL}(2,q)"/> for simplicity, but the proof immediately extends to other quasirandom groups (with corresponding parameters). <a id="x1-15001r1"/></p>
<p style="text-align: justify;"><b>Theorem 1.</b> Let <img alt="G=\textit {SL}(2,q)" class="latex" src="https://s0.wp.com/latex.php?latex=G%3D%5Ctextit+%7BSL%7D%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G=\textit {SL}(2,q)"/>. Every subset <img alt="A\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\subseteq G^{2}"/> of density <img alt="|A|/|G|^{2}\geq 1/\log ^{a}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%7CA%7C%2F%7CG%7C%5E%7B2%7D%5Cgeq+1%2F%5Clog+%5E%7Ba%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|A|/|G|^{2}\geq 1/\log ^{a}|G|"/> contains a corner <img alt="\{(x,y),(xz,y),(x,zy)~|~z\neq 1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%29%2C%28xz%2Cy%29%2C%28x%2Czy%29%7E%7C%7Ez%5Cneq+1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{(x,y),(xz,y),(x,zy)~|~z\neq 1\}"/>.</p>
<h4 class="subsectionHead"><span class="titlemark">7.1 </span> <a id="x1-160007.1"/>Proof idea</h4>
<p style="text-align: justify;">For intuition, suppose <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> is a product set, i.e., <img alt="A=B\times C" class="latex" src="https://s0.wp.com/latex.php?latex=A%3DB%5Ctimes+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A=B\times C"/> for <img alt="B,C\subseteq G" class="latex" src="https://s0.wp.com/latex.php?latex=B%2CC%5Csubseteq+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="B,C\subseteq G"/>. Let’s look at the quantity</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}_{x,y,z\leftarrow G}[A(x,y)A(xz,y)A(x,zy)] \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cz%5Cleftarrow+G%7D%5BA%28x%2Cy%29A%28xz%2Cy%29A%28x%2Czy%29%5D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}_{x,y,z\leftarrow G}[A(x,y)A(xz,y)A(x,zy)] \end{aligned}"/></div>
<p>where <img alt="A(x,y)=1" class="latex" src="https://s0.wp.com/latex.php?latex=A%28x%2Cy%29%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A(x,y)=1"/> iff <img alt="(x,y)\in A" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29%5Cin+A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)\in A"/>. Note that the random variable in the expectation is equal to <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> exactly when <img alt="x,y,z" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy%2Cz&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y,z"/> form a corner in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/>. We’ll show that this quantity is greater than <img alt="1/|G|" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|"/>, which implies that <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> contains a corner (where <img alt="z\neq 1" class="latex" src="https://s0.wp.com/latex.php?latex=z%5Cneq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z\neq 1"/>). Since we are taking <img alt="A=B\times C" class="latex" src="https://s0.wp.com/latex.php?latex=A%3DB%5Ctimes+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A=B\times C"/>, we can rewrite the above quantity as</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(xz)C(y)B(x)C(zy)] &amp; =\mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(xz)C(zy)]\\ &amp; =\mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(z)C(x^{-1}zy)] \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cz%5Cleftarrow+G%7D%5BB%28x%29C%28y%29B%28xz%29C%28y%29B%28x%29C%28zy%29%5D+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cz%5Cleftarrow+G%7D%5BB%28x%29C%28y%29B%28xz%29C%28zy%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cz%5Cleftarrow+G%7D%5BB%28x%29C%28y%29B%28z%29C%28x%5E%7B-1%7Dzy%29%5D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(xz)C(y)B(x)C(zy)] &amp; =\mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(xz)C(zy)]\\ &amp; =\mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(z)C(x^{-1}zy)] \end{aligned}"/></div>
<p>where the last line follows by replacing <img alt="z" class="latex" src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z"/> with <img alt="x^{-1}z" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B-1%7Dz&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{-1}z"/> in the uniform distribution. If <img alt="|A|/|G|^{2}\ge \delta " class="latex" src="https://s0.wp.com/latex.php?latex=%7CA%7C%2F%7CG%7C%5E%7B2%7D%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|A|/|G|^{2}\ge \delta "/>, then both |B|/|G|<img alt="\ge \delta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ge \delta "/> and <img alt="|B|/|G|\ge \delta " class="latex" src="https://s0.wp.com/latex.php?latex=%7CB%7C%2F%7CG%7C%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|B|/|G|\ge \delta "/>. Condition on <img alt="x\in B" class="latex" src="https://s0.wp.com/latex.php?latex=x%5Cin+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x\in B"/>, <img alt="y\in C" class="latex" src="https://s0.wp.com/latex.php?latex=y%5Cin+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y\in C"/>, <img alt="z\in B" class="latex" src="https://s0.wp.com/latex.php?latex=z%5Cin+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="z\in B"/>. Then the distribution <img alt="x^{-1}zy" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B-1%7Dzy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{-1}zy"/> is a product of three independent distributions, each uniform on a set of density <img alt="\ge \delta " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ge \delta "/>. (In fact, two distributions would suffice for this.) By Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7<!--tex4ht:ref: lem:XY-mixing --></a>, <img alt="x^{-1}zy" class="latex" src="https://s0.wp.com/latex.php?latex=x%5E%7B-1%7Dzy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x^{-1}zy"/> is <img alt="\delta ^{-1}/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5E%7B-1%7D%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta ^{-1}/|G|^{\Omega (1)}"/> close to uniform in statistical distance. This implies that the above expectation equals</p>
<div style="text-align: center;"><img alt="\begin{aligned} \frac {|A|}{|G|^{2}}\cdot \frac {|B|}{|G|}\cdot \left (\frac {|C|}{|G|}\pm \frac {\delta ^{-1}}{|G|^{\Omega (1)}}\right ) &amp; \geq \delta ^{2}\left (\delta -\frac {1}{|G|^{\Omega (1)}}\right )\geq \delta ^{3}/2&gt;1/|G|, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac+%7B%7CA%7C%7D%7B%7CG%7C%5E%7B2%7D%7D%5Ccdot+%5Cfrac+%7B%7CB%7C%7D%7B%7CG%7C%7D%5Ccdot+%5Cleft+%28%5Cfrac+%7B%7CC%7C%7D%7B%7CG%7C%7D%5Cpm+%5Cfrac+%7B%5Cdelta+%5E%7B-1%7D%7D%7B%7CG%7C%5E%7B%5COmega+%281%29%7D%7D%5Cright+%29+%26+%5Cgeq+%5Cdelta+%5E%7B2%7D%5Cleft+%28%5Cdelta+-%5Cfrac+%7B1%7D%7B%7CG%7C%5E%7B%5COmega+%281%29%7D%7D%5Cright+%29%5Cgeq+%5Cdelta+%5E%7B3%7D%2F2%3E1%2F%7CG%7C%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \frac {|A|}{|G|^{2}}\cdot \frac {|B|}{|G|}\cdot \left (\frac {|C|}{|G|}\pm \frac {\delta ^{-1}}{|G|^{\Omega (1)}}\right ) &amp; \geq \delta ^{2}\left (\delta -\frac {1}{|G|^{\Omega (1)}}\right )\geq \delta ^{3}/2&gt;1/|G|, \end{aligned}"/></div>
<p style="text-align: justify;">for <img alt="\delta &gt;1/|G|^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E1%2F%7CG%7C%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta &gt;1/|G|^{c}"/> for a small enough constant <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/>. Hence, product sets of density polynomial in <img alt="1/|G|" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|"/> contain corners.</p>
<p style="text-align: justify;">Given the above, it is natural to try to decompose an arbitrary set <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> into product sets. We will make use of a more general result.</p>
<h4 class="subsectionHead"><span class="titlemark">7.2 </span> <a id="x1-170007.2"/>Weak Regularity Lemma</h4>
<p style="text-align: justify;">Let <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> be some universe (we will take <img alt="U=G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=U%3DG%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U=G^{2}"/>) and let <img alt="f:U\rightarrow [-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=f%3AU%5Crightarrow+%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:U\rightarrow [-1,1]"/> be a function (for us, <img alt="f=1_{A}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3D1_%7BA%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f=1_{A}"/>). Let <img alt="D\subseteq \{d:U\rightarrow [-1,1]\}" class="latex" src="https://s0.wp.com/latex.php?latex=D%5Csubseteq+%5C%7Bd%3AU%5Crightarrow+%5B-1%2C1%5D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D\subseteq \{d:U\rightarrow [-1,1]\}"/> be some set of functions, which can be thought of as “easy functions” or “distinguishers” (these will be rectangles or closely related to them). The next theorem shows how to decompose <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> into a linear combination <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> of the <img alt="d_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=d_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d_{i}"/> up to an error which is polynomial in the length of the combination. More specifically, <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> will be indistinguishable from <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> by the <img alt="d_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=d_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d_{i}"/>.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-17001r13"/> Lemma 13. </span>Let <img alt="f:U\rightarrow [-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=f%3AU%5Crightarrow+%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:U\rightarrow [-1,1]"/> be a function and <img alt="D\subseteq \{d:U\rightarrow [-1,1]\}" class="latex" src="https://s0.wp.com/latex.php?latex=D%5Csubseteq+%5C%7Bd%3AU%5Crightarrow+%5B-1%2C1%5D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D\subseteq \{d:U\rightarrow [-1,1]\}"/> a set of functions. For all <img alt="\epsilon &gt;0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon &gt;0"/>, there exists a function <img alt="g:=\sum _{i\le s}c_{i}\cdot d_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=g%3A%3D%5Csum+_%7Bi%5Cle+s%7Dc_%7Bi%7D%5Ccdot+d_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g:=\sum _{i\le s}c_{i}\cdot d_{i}"/> where <img alt="d_{i}\in D" class="latex" src="https://s0.wp.com/latex.php?latex=d_%7Bi%7D%5Cin+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d_{i}\in D"/>, <img alt="c_{i}\in \mathbb {R}" class="latex" src="https://s0.wp.com/latex.php?latex=c_%7Bi%7D%5Cin+%5Cmathbb+%7BR%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c_{i}\in \mathbb {R}"/> and <img alt="s=1/\epsilon ^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=s%3D1%2F%5Cepsilon+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s=1/\epsilon ^{2}"/> such that for all <img alt="d\in D" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cin+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\in D"/></p>
<div style="text-align: center;"><img alt="\begin{aligned} \left |\mathbb {E}_{x\leftarrow U}[f(x)\cdot d(x)]-\mathbb {E}_{x\leftarrow U}[g(x)\cdot d(x)]\right |\le \epsilon . \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb+%7BE%7D_%7Bx%5Cleftarrow+U%7D%5Bf%28x%29%5Ccdot+d%28x%29%5D-%5Cmathbb+%7BE%7D_%7Bx%5Cleftarrow+U%7D%5Bg%28x%29%5Ccdot+d%28x%29%5D%5Cright+%7C%5Cle+%5Cepsilon+.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \left |\mathbb {E}_{x\leftarrow U}[f(x)\cdot d(x)]-\mathbb {E}_{x\leftarrow U}[g(x)\cdot d(x)]\right |\le \epsilon . \end{aligned}"/></div>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">A different way to state the conclusion, which we will use, is to say that we can write <img alt="f=g+h" class="latex" src="https://s0.wp.com/latex.php?latex=f%3Dg%2Bh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f=g+h"/> so that <img alt="\mathbb{E} [h(x)\cdot d(x)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D+%5Bh%28x%29%5Ccdot+d%28x%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{E} [h(x)\cdot d(x)]"/> is small.</p>
<p style="text-align: justify;">The lemma is due to Frieze and Kannan <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/conf/focs/FriezeK96">FK96</a>]</span>. It is called “weak” because it came after Szemerédi’s regularity lemma, which has a stronger distinguishing conclusion. However, the lemma is also “strong” in the sense that Szemerédi’s regularity lemma has <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> as a tower of <img alt="1/\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/\epsilon "/> whereas here we have <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> polynomial in <img alt="1/\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/\epsilon "/>. The weak regularity lemma is also simpler. There also exists a proof <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XTao2017-szemerediproof">Tao17</a>]</span> of Szemerédi’s theorem (on arithmetic progressions), which uses weak regularity as opposed to the full regularity lemma used initially.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We will construct the approximation <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> through an iterative process producing functions <img alt="g_{0},g_{1},\dots ,g" class="latex" src="https://s0.wp.com/latex.php?latex=g_%7B0%7D%2Cg_%7B1%7D%2C%5Cdots+%2Cg&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g_{0},g_{1},\dots ,g"/>. We will show that <img alt="||f-g_{i}||_{2}^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7Cf-g_%7Bi%7D%7C%7C_%7B2%7D%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="||f-g_{i}||_{2}^{2}"/> decreases by <img alt="\ge \epsilon ^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cge+%5Cepsilon+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ge \epsilon ^{2}"/> each iteration.</p>
<p style="text-align: justify;"><b>Start</b>: Define <img alt="g_{0}=0" class="latex" src="https://s0.wp.com/latex.php?latex=g_%7B0%7D%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g_{0}=0"/> (which can be realized setting <img alt="c_{0}=0" class="latex" src="https://s0.wp.com/latex.php?latex=c_%7B0%7D%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c_{0}=0"/>).</p>
<p style="text-align: justify;"><b>Iterate</b>: If not done, there exists <img alt="d\in D" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cin+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\in D"/> such that <img alt="|\mathbb {E}[(f-g)\cdot d]|&gt;\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb+%7BE%7D%5B%28f-g%29%5Ccdot+d%5D%7C%3E%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathbb {E}[(f-g)\cdot d]|&gt;\epsilon "/>. Assume without loss of generality <img alt="\mathbb {E}[(f-g)\cdot d]&gt;\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5B%28f-g%29%5Ccdot+d%5D%3E%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}[(f-g)\cdot d]&gt;\epsilon "/>.</p>
<p style="text-align: justify;"><b>Update</b>: <img alt="g':=g+\lambda d" class="latex" src="https://s0.wp.com/latex.php?latex=g%27%3A%3Dg%2B%5Clambda+d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g':=g+\lambda d"/> where <img alt="\lambda \in \mathbb {R}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda+%5Cin+%5Cmathbb+%7BR%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda \in \mathbb {R}"/> shall be picked later.</p>
<p style="text-align: justify;">Let us analyze the progress made by the algorithm.</p>
<div style="text-align: center;"><img alt="\begin{aligned} ||f-g'||_{2}^{2} &amp; =\mathbb {E}_{x}[(f-g')^{2}(x)]\\ &amp; =\mathbb {E}_{x}[(f-g-\lambda d)^{2}(x)]\\ &amp; =\mathbb {E}_{x}[(f-g)^{2}]+\mathbb {E}_{x}[\lambda ^{2}d^{2}(x)]-2\mathbb {E}_{x}[(f-g)\cdot \lambda d(x)]\\ &amp; \leq ||f-g||_{2}^{2}+\lambda ^{2}-2\lambda \mathbb {E}_{x}[(f-g)d(x)]\\ &amp; \leq ||f-g||_{2}^{2}+\lambda ^{2}-2\lambda \epsilon \\ &amp; \leq ||f-g||_{2}^{2}-\epsilon ^{2} \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%7Cf-g%27%7C%7C_%7B2%7D%5E%7B2%7D+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g%27%29%5E%7B2%7D%28x%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g-%5Clambda+d%29%5E%7B2%7D%28x%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g%29%5E%7B2%7D%5D%2B%5Cmathbb+%7BE%7D_%7Bx%7D%5B%5Clambda+%5E%7B2%7Dd%5E%7B2%7D%28x%29%5D-2%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g%29%5Ccdot+%5Clambda+d%28x%29%5D%5C%5C+%26+%5Cleq+%7C%7Cf-g%7C%7C_%7B2%7D%5E%7B2%7D%2B%5Clambda+%5E%7B2%7D-2%5Clambda+%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g%29d%28x%29%5D%5C%5C+%26+%5Cleq+%7C%7Cf-g%7C%7C_%7B2%7D%5E%7B2%7D%2B%5Clambda+%5E%7B2%7D-2%5Clambda+%5Cepsilon+%5C%5C+%26+%5Cleq+%7C%7Cf-g%7C%7C_%7B2%7D%5E%7B2%7D-%5Cepsilon+%5E%7B2%7D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} ||f-g'||_{2}^{2} &amp; =\mathbb {E}_{x}[(f-g')^{2}(x)]\\ &amp; =\mathbb {E}_{x}[(f-g-\lambda d)^{2}(x)]\\ &amp; =\mathbb {E}_{x}[(f-g)^{2}]+\mathbb {E}_{x}[\lambda ^{2}d^{2}(x)]-2\mathbb {E}_{x}[(f-g)\cdot \lambda d(x)]\\ &amp; \leq ||f-g||_{2}^{2}+\lambda ^{2}-2\lambda \mathbb {E}_{x}[(f-g)d(x)]\\ &amp; \leq ||f-g||_{2}^{2}+\lambda ^{2}-2\lambda \epsilon \\ &amp; \leq ||f-g||_{2}^{2}-\epsilon ^{2} \end{aligned}"/></div>
<p>where the last line follows by taking <img alt="\lambda =\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Clambda+%3D%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\lambda =\epsilon "/>. Therefore, there can only be <img alt="1/\epsilon ^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/\epsilon ^{2}"/> iterations because <img alt="||f-g_{0}||_{2}^{2}=||f||_{2}^{2}\leq 1" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%7Cf-g_%7B0%7D%7C%7C_%7B2%7D%5E%7B2%7D%3D%7C%7Cf%7C%7C_%7B2%7D%5E%7B2%7D%5Cleq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="||f-g_{0}||_{2}^{2}=||f||_{2}^{2}\leq 1"/>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<h4 class="subsectionHead"><span class="titlemark">7.3 </span> <a id="x1-180007.3"/>Getting more for rectangles</h4>
<p style="text-align: justify;">Returning to the main proof, we will use the weak regularity lemma to approximate the indicator function for arbitrary <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> by rectangles. That is, we take <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="D"/> to be the collection of indicator functions for all sets of the form <img alt="S\times T" class="latex" src="https://s0.wp.com/latex.php?latex=S%5Ctimes+T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S\times T"/> for <img alt="S,T\subseteq G" class="latex" src="https://s0.wp.com/latex.php?latex=S%2CT%5Csubseteq+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S,T\subseteq G"/>. The weak regularity lemma shows how to decompose <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> into a linear combination of rectangles. These rectangles may overlap. However, we ideally want <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> to be a linear combination of <em>non-overlapping</em> rectangles. In other words, we want a <em>partition </em>of rectangles. It is possible to achieve this at the price of exponentiating the number of rectangles. Note that an exponential loss is necessary even if <img alt="S=G" class="latex" src="https://s0.wp.com/latex.php?latex=S%3DG&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S=G"/> in every <img alt="S\times T" class="latex" src="https://s0.wp.com/latex.php?latex=S%5Ctimes+T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S\times T"/> rectangle; or in other words in the uni-dimensional setting. This is one step where the terminology “rectangle” may be misleading – the set <img alt="T" class="latex" src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="T"/> is not necessarily an interval. If it was, a polynomial rather than exponential blow-up would have sufficed to remove overlaps.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-18001r14"/> Claim 14. </span>Given a decomposition of <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> into rectangles from the weak regularity lemma with <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="s"/> functions, there exists a decomposition with <img alt="2^{O(s)}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BO%28s%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{O(s)}"/> rectangles which don’t overlap.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Exercise. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">In the above decomposition, note that it is natural to take the coefficients of rectangles to be the density of points in <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A"/> that are in the rectangle. This gives rise to the following claim.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-18002r15"/> Claim 15. </span>The weights of the rectangles in the above claim can be the average of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> in the rectangle, at the cost of doubling the error.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">Consequently, we have that <img alt="f=g+h" class="latex" src="https://s0.wp.com/latex.php?latex=f%3Dg%2Bh&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f=g+h"/>, where <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> is the sum of <img alt="2^{O(s)}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BO%28s%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{O(s)}"/> non-overlapping rectangles <img alt="S\times T" class="latex" src="https://s0.wp.com/latex.php?latex=S%5Ctimes+T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S\times T"/> with coefficients <img alt="\mathbb{P} _{(x,y)\in S\times T}[f(x,y)=1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+_%7B%28x%2Cy%29%5Cin+S%5Ctimes+T%7D%5Bf%28x%2Cy%29%3D1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{P} _{(x,y)\in S\times T}[f(x,y)=1]"/>.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Let <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> be a partition decomposition with arbitrary weights. Let <img alt="g'" class="latex" src="https://s0.wp.com/latex.php?latex=g%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g'"/> be a partition decomposition with weights being the average of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>. It is enough to show that for all rectangle distinguishers <img alt="d\in D" class="latex" src="https://s0.wp.com/latex.php?latex=d%5Cin+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d\in D"/></p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq |\mathbb {E}[(f-g)d]|. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb+%7BE%7D%5B%28f-g%27%29d%5D%7C%5Cleq+%7C%5Cmathbb+%7BE%7D%5B%28f-g%29d%5D%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq |\mathbb {E}[(f-g)d]|. \end{aligned}"/></div>
<p>By the triangle inequality, we have that</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq |\mathbb {E}[(f-g)d]|+|\mathbb {E}[(g-g')d]|. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb+%7BE%7D%5B%28f-g%27%29d%5D%7C%5Cleq+%7C%5Cmathbb+%7BE%7D%5B%28f-g%29d%5D%7C%2B%7C%5Cmathbb+%7BE%7D%5B%28g-g%27%29d%5D%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq |\mathbb {E}[(f-g)d]|+|\mathbb {E}[(g-g')d]|. \end{aligned}"/></div>
<p>To bound <img alt="\mathbb {E}[(g-g')d]|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5B%28g-g%27%29d%5D%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}[(g-g')d]|"/>, note that the error is maximized for a <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> that respects the decomposition in non-overlapping rectangles, i.e., <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/> is the union of some non-overlapping rectangles from the decomposition. This can be argued using that, unlike <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/>, the value of <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> and <img alt="g'" class="latex" src="https://s0.wp.com/latex.php?latex=g%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g'"/> on a rectangle <img alt="S\times T" class="latex" src="https://s0.wp.com/latex.php?latex=S%5Ctimes+T&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="S\times T"/> from the decomposition is fixed. But, from the point of “view” of such <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="d"/>, <img alt="g'=f" class="latex" src="https://s0.wp.com/latex.php?latex=g%27%3Df&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g'=f"/>! More formally, <img alt="\mathbb {E}[(g-g')d]=\mathbb {E}[(g-f)d]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5B%28g-g%27%29d%5D%3D%5Cmathbb+%7BE%7D%5B%28g-f%29d%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}[(g-g')d]=\mathbb {E}[(g-f)d]"/>. This gives</p>
<div style="text-align: center;"><img alt="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq 2|\mathbb {E}[(f-g)d]| \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb+%7BE%7D%5B%28f-g%27%29d%5D%7C%5Cleq+2%7C%5Cmathbb+%7BE%7D%5B%28f-g%29d%5D%7C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq 2|\mathbb {E}[(f-g)d]| \end{aligned}"/></div>
<p>and concludes the proof. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">We need to get still a little more from this decomposition. In our application of the weak regularity lemma above, we took the set of distinguishers to be characteristic functions of rectangles. That is, distinguishers that can be written as <img alt="U(x)\cdot V(y)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28x%29%5Ccdot+V%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(x)\cdot V(y)"/> where <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> and <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> map <img alt="G\to \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=G%5Cto+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="G\to \{0,1\}"/>. We will use that the same guarantee holds for <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> and <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> with range <img alt="[-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-1,1]"/>, up to a constant factor loss in the error. Indeed, let <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> and <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> have range <img alt="[-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-1,1]"/>. Write <img alt="U=U_{+}-U_{-}" class="latex" src="https://s0.wp.com/latex.php?latex=U%3DU_%7B%2B%7D-U_%7B-%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U=U_{+}-U_{-}"/> where <img alt="U_{+}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B%2B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{+}"/> and <img alt="U_{-}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B-%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{-}"/> have range <img alt="[0,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[0,1]"/>, and the same for <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/>. The error for distinguisher <img alt="U\cdot V" class="latex" src="https://s0.wp.com/latex.php?latex=U%5Ccdot+V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U\cdot V"/> is at most the sum of the errors for distinguishers <img alt="U_{+}\cdot V_{+}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B%2B%7D%5Ccdot+V_%7B%2B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{+}\cdot V_{+}"/>, <img alt="U_{+}\cdot V_{-}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B%2B%7D%5Ccdot+V_%7B-%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{+}\cdot V_{-}"/>, <img alt="U_{-}\cdot V_{+}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B-%7D%5Ccdot+V_%7B%2B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{-}\cdot V_{+}"/>, and <img alt="U_{-}\cdot V_{-}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B-%7D%5Ccdot+V_%7B-%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{-}\cdot V_{-}"/>. So we can restrict our attention to distinguishers <img alt="U(x)\cdot V(y)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28x%29%5Ccdot+V%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(x)\cdot V(y)"/> where <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> and <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> have range <img alt="[0,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[0,1]"/>. In turn, a function <img alt="U(x)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(x)"/> with range <img alt="[0,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[0,1]"/> can be written as an expectation <img alt="\mathbb{E} _{a}U_{a}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D+_%7Ba%7DU_%7Ba%7D%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb{E} _{a}U_{a}(x)"/> for functions <img alt="U_{a}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7Ba%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{a}"/> with range <img alt="\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\}"/>, and the same for <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/>. We conclude by observing that</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb{E} _{x,y}[(f-g)(x,y)\mathbb{E} _{a}U_{a}(x)\cdot \mathbb{E} _{b}V_{b}(y)]\le \max _{a,b}\mathbb{E} _{x,y}[(f-g)(x,y)U_{a}(x)\cdot V_{b}(y)]. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb%7BE%7D+_%7Bx%2Cy%7D%5B%28f-g%29%28x%2Cy%29%5Cmathbb%7BE%7D+_%7Ba%7DU_%7Ba%7D%28x%29%5Ccdot+%5Cmathbb%7BE%7D+_%7Bb%7DV_%7Bb%7D%28y%29%5D%5Cle+%5Cmax+_%7Ba%2Cb%7D%5Cmathbb%7BE%7D+_%7Bx%2Cy%7D%5B%28f-g%29%28x%2Cy%29U_%7Ba%7D%28x%29%5Ccdot+V_%7Bb%7D%28y%29%5D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb{E} _{x,y}[(f-g)(x,y)\mathbb{E} _{a}U_{a}(x)\cdot \mathbb{E} _{b}V_{b}(y)]\le \max _{a,b}\mathbb{E} _{x,y}[(f-g)(x,y)U_{a}(x)\cdot V_{b}(y)]. \end{aligned}"/></div>
<h4 class="subsectionHead"><span class="titlemark">7.4 </span> <a id="x1-190007.4"/>Proof</h4>
<p style="text-align: justify;">Let us now finish the proof by showing a corner exists for sufficiently dense sets <img alt="A\subseteq G^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=A%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="A\subseteq G^{2}"/>. We’ll use three types of decompositions for <img alt="f:G^{2}\rightarrow \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3AG%5E%7B2%7D%5Crightarrow+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f:G^{2}\rightarrow \{0,1\}"/>, with respect to the following three types of distinguishers, where <img alt="U_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{i}"/> and <img alt="V_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=V_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V_{i}"/> have range <img alt="\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\}"/>:</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-19002x1"><img alt="U_{1}(x)\cdot V_{1}(y)" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B1%7D%28x%29%5Ccdot+V_%7B1%7D%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{1}(x)\cdot V_{1}(y)"/>,</li>
<li class="enumerate" id="x1-19004x2"><img alt="U_{2}(xy)\cdot V_{2}(y)" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B2%7D%28xy%29%5Ccdot+V_%7B2%7D%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{2}(xy)\cdot V_{2}(y)"/>,</li>
<li class="enumerate" id="x1-19006x3"><img alt="U_{3}(x)\cdot V_{3}(xy)" class="latex" src="https://s0.wp.com/latex.php?latex=U_%7B3%7D%28x%29%5Ccdot+V_%7B3%7D%28xy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U_{3}(x)\cdot V_{3}(xy)"/>.</li>
</ol>
<p style="text-align: justify;">The first type is just rectangles, what we have been discussing until now. The distinguishers in the last two classes can be visualized over <img alt="\mathbb {R}^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BR%7D%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {R}^{2}"/> as parallelograms with a 45-degree angle. The same extra properties we discussed for rectangles can be verified hold for them too.</p>
<p style="text-align: justify;">Recall that we want to show</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}_{x,y,g}[f(x,y)f(xg,y)f(x,gy)]&gt;\frac {1}{|G|}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%7D%5Bf%28x%2Cy%29f%28xg%2Cy%29f%28x%2Cgy%29%5D%3E%5Cfrac+%7B1%7D%7B%7CG%7C%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}_{x,y,g}[f(x,y)f(xg,y)f(x,gy)]&gt;\frac {1}{|G|}. \end{aligned}"/></div>
<p>We’ll decompose the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>-th occurrence of <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> via the <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="i"/>-th decomposition listed above. We’ll write this decomposition as <img alt="f=g_{i}+h_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=f%3Dg_%7Bi%7D%2Bh_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f=g_{i}+h_{i}"/>. We apply this in a certain order to produce sums of products of three functions. The inputs to the functions don’t change, so to avoid clutter we do not write them, and it is understood that in each product of three functions the inputs are, in order <img alt="(x,y),(xg,y),(x,gy)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29%2C%28xg%2Cy%29%2C%28x%2Cgy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y),(xg,y),(x,gy)"/>. The decomposition is:</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; fff\\ = &amp; ffg_{3}+ffh_{3}\\ = &amp; fg_{2}g_{3}+fh_{2}g_{3}+ffh_{3}\\ = &amp; g_{1}g_{2}g_{3}+h_{1}g_{2}g_{3}+fh_{2}g_{3}+ffh_{3}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+fff%5C%5C+%3D+%26+ffg_%7B3%7D%2Bffh_%7B3%7D%5C%5C+%3D+%26+fg_%7B2%7Dg_%7B3%7D%2Bfh_%7B2%7Dg_%7B3%7D%2Bffh_%7B3%7D%5C%5C+%3D+%26+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%2Bh_%7B1%7Dg_%7B2%7Dg_%7B3%7D%2Bfh_%7B2%7Dg_%7B3%7D%2Bffh_%7B3%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; fff\\ = &amp; ffg_{3}+ffh_{3}\\ = &amp; fg_{2}g_{3}+fh_{2}g_{3}+ffh_{3}\\ = &amp; g_{1}g_{2}g_{3}+h_{1}g_{2}g_{3}+fh_{2}g_{3}+ffh_{3}. \end{aligned}"/></div>
<p style="text-align: justify;">We first show that the expectation of the first term is big. This takes the next two claims. Then we show that the expectations of the other terms are small.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-19007r16"/> Claim 16. </span>For all <img alt="g\in G" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\in G"/>, the expectations <img alt="\mathbb {E}_{x,y}[g_{1}(x,y)g_{2}(xg,y)g_{3}(x,gy)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Bg_%7B1%7D%28x%2Cy%29g_%7B2%7D%28xg%2Cy%29g_%7B3%7D%28x%2Cgy%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}_{x,y}[g_{1}(x,y)g_{2}(xg,y)g_{3}(x,gy)]"/> are the same up to an error of <img alt="2^{O(s)}/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7BO%28s%29%7D%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{O(s)}/|G|^{\Omega (1)}"/>.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We just need to get error <img alt="1/|G|^{\Omega (1)}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|^{\Omega (1)}"/> for any product of three functions for the three decomposition types. We have:</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; \mathbb {E}_{x,y}[c_{1}U_{1}(x)V_{1}(y)\cdot c_{2}U_{2}(xgy)V_{2}(y)\cdot c_{3}U_{3}(x)V_{3}(xgy)]\\ = &amp; c_{1}c_{2}c_{3}\mathbb {E}_{x,y}[(U_{1}\cdot U_{3})(x)(V_{1}\cdot V_{2})(y)(U_{2}\cdot V_{3})(xgy)]\\ = &amp; c_{1}c_{2}c_{3}\cdot \mathbb {E}_{x}[(U_{1}\cdot U_{3})(x)]\cdot \mathbb {E}_{y}[(V_{1}\cdot V_{2})(y)]\cdot \mathbb {E}_{z}[(U_{2}\cdot V_{3})(z)]\pm \frac {1}{|G|^{\Omega (1)}}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Bc_%7B1%7DU_%7B1%7D%28x%29V_%7B1%7D%28y%29%5Ccdot+c_%7B2%7DU_%7B2%7D%28xgy%29V_%7B2%7D%28y%29%5Ccdot+c_%7B3%7DU_%7B3%7D%28x%29V_%7B3%7D%28xgy%29%5D%5C%5C+%3D+%26+c_%7B1%7Dc_%7B2%7Dc_%7B3%7D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5B%28U_%7B1%7D%5Ccdot+U_%7B3%7D%29%28x%29%28V_%7B1%7D%5Ccdot+V_%7B2%7D%29%28y%29%28U_%7B2%7D%5Ccdot+V_%7B3%7D%29%28xgy%29%5D%5C%5C+%3D+%26+c_%7B1%7Dc_%7B2%7Dc_%7B3%7D%5Ccdot+%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28U_%7B1%7D%5Ccdot+U_%7B3%7D%29%28x%29%5D%5Ccdot+%5Cmathbb+%7BE%7D_%7By%7D%5B%28V_%7B1%7D%5Ccdot+V_%7B2%7D%29%28y%29%5D%5Ccdot+%5Cmathbb+%7BE%7D_%7Bz%7D%5B%28U_%7B2%7D%5Ccdot+V_%7B3%7D%29%28z%29%5D%5Cpm+%5Cfrac+%7B1%7D%7B%7CG%7C%5E%7B%5COmega+%281%29%7D%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; \mathbb {E}_{x,y}[c_{1}U_{1}(x)V_{1}(y)\cdot c_{2}U_{2}(xgy)V_{2}(y)\cdot c_{3}U_{3}(x)V_{3}(xgy)]\\ = &amp; c_{1}c_{2}c_{3}\mathbb {E}_{x,y}[(U_{1}\cdot U_{3})(x)(V_{1}\cdot V_{2})(y)(U_{2}\cdot V_{3})(xgy)]\\ = &amp; c_{1}c_{2}c_{3}\cdot \mathbb {E}_{x}[(U_{1}\cdot U_{3})(x)]\cdot \mathbb {E}_{y}[(V_{1}\cdot V_{2})(y)]\cdot \mathbb {E}_{z}[(U_{2}\cdot V_{3})(z)]\pm \frac {1}{|G|^{\Omega (1)}}. \end{aligned}"/></div>
<p style="text-align: justify;">This is similar to what we discussed in the overview, and is where we use mixing. Specifically, if <img alt="\mathbb {E}_{x}[(U_{1}\cdot U_{3})(x)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28U_%7B1%7D%5Ccdot+U_%7B3%7D%29%28x%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}_{x}[(U_{1}\cdot U_{3})(x)]"/> or <img alt="\mathbb {E}_{y}[(V_{1}\cdot V_{2})(y)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7By%7D%5B%28V_%7B1%7D%5Ccdot+V_%7B2%7D%29%28y%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}_{y}[(V_{1}\cdot V_{2})(y)]"/> are at most <img alt="1/|G|^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|^{c}"/> for a small enough constant <img alt="c" class="latex" src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c"/> than we are done. Otherwise, conditioned on <img alt="(U_{1}\cdot U_{3})(x)=1" class="latex" src="https://s0.wp.com/latex.php?latex=%28U_%7B1%7D%5Ccdot+U_%7B3%7D%29%28x%29%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(U_{1}\cdot U_{3})(x)=1"/>, the distribution on <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/> is uniform over a set of density <img alt="1/|G|^{c}" class="latex" src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1/|G|^{c}"/>, and the same holds for <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="y"/>, and the result follows by Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7<!--tex4ht:ref: lem:XY-mixing --></a>. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">Recall that we start with a set of density <img alt="\ge 1/\log ^{a}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cge+1%2F%5Clog+%5E%7Ba%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\ge 1/\log ^{a}|G|"/>.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-19008r17"/> Claim 17. </span><img alt="\mathbb {E}_{x,y}[g_{1}(x,y)g_{2}(x,y)g_{3}(x,y)]&gt;1/\log ^{4a}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Bg_%7B1%7D%28x%2Cy%29g_%7B2%7D%28x%2Cy%29g_%7B3%7D%28x%2Cy%29%5D%3E1%2F%5Clog+%5E%7B4a%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}_{x,y}[g_{1}(x,y)g_{2}(x,y)g_{3}(x,y)]&gt;1/\log ^{4a}|G|"/>.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We will relate the expectation over <img alt="x,y" class="latex" src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x,y"/> to <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> using the Hölder inequality: For random variables <img alt="X_{1},X_{2},\ldots ,X_{k}" class="latex" src="https://s0.wp.com/latex.php?latex=X_%7B1%7D%2CX_%7B2%7D%2C%5Cldots+%2CX_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X_{1},X_{2},\ldots ,X_{k}"/>,</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}[X_{1}\dots X_{k}]\leq \prod _{i=1}^{k}\mathbb {E}[X_{i}^{c_{i}}]^{1/c_{i}}\text { such that }\sum 1/c_{i}=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D%5BX_%7B1%7D%5Cdots+X_%7Bk%7D%5D%5Cleq+%5Cprod+_%7Bi%3D1%7D%5E%7Bk%7D%5Cmathbb+%7BE%7D%5BX_%7Bi%7D%5E%7Bc_%7Bi%7D%7D%5D%5E%7B1%2Fc_%7Bi%7D%7D%5Ctext+%7B+such+that+%7D%5Csum+1%2Fc_%7Bi%7D%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}[X_{1}\dots X_{k}]\leq \prod _{i=1}^{k}\mathbb {E}[X_{i}^{c_{i}}]^{1/c_{i}}\text { such that }\sum 1/c_{i}=1. \end{aligned}"/></div>
<p style="text-align: justify;">To apply this inequality in our setting, write</p>
<div style="text-align: center;"><img alt="\begin{aligned} f=(f\cdot g_{1}g_{2}g_{3})^{1/4}\cdot \left (\frac {f}{g_{1}}\right )^{1/4}\cdot \left (\frac {f}{g_{2}}\right )^{1/4}\cdot \left (\frac {f}{g_{3}}\right )^{1/4}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%3D%28f%5Ccdot+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%29%5E%7B1%2F4%7D%5Ccdot+%5Cleft+%28%5Cfrac+%7Bf%7D%7Bg_%7B1%7D%7D%5Cright+%29%5E%7B1%2F4%7D%5Ccdot+%5Cleft+%28%5Cfrac+%7Bf%7D%7Bg_%7B2%7D%7D%5Cright+%29%5E%7B1%2F4%7D%5Ccdot+%5Cleft+%28%5Cfrac+%7Bf%7D%7Bg_%7B3%7D%7D%5Cright+%29%5E%7B1%2F4%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} f=(f\cdot g_{1}g_{2}g_{3})^{1/4}\cdot \left (\frac {f}{g_{1}}\right )^{1/4}\cdot \left (\frac {f}{g_{2}}\right )^{1/4}\cdot \left (\frac {f}{g_{3}}\right )^{1/4}. \end{aligned}"/></div>
<p>By the Hölder inequality the expectation of the right-hand side is</p>
<div style="text-align: center;"><img alt="\begin{aligned} \leq \mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}\mathbb {E}\left [\frac {f}{g_{1}}\right ]^{1/4}\mathbb {E}\left [\frac {f}{g_{2}}\right ]^{1/4}\mathbb {E}\left [\frac {f}{g_{3}}\right ]^{1/4}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleq+%5Cmathbb+%7BE%7D%5Bf%5Ccdot+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%5D%5E%7B1%2F4%7D%5Cmathbb+%7BE%7D%5Cleft+%5B%5Cfrac+%7Bf%7D%7Bg_%7B1%7D%7D%5Cright+%5D%5E%7B1%2F4%7D%5Cmathbb+%7BE%7D%5Cleft+%5B%5Cfrac+%7Bf%7D%7Bg_%7B2%7D%7D%5Cright+%5D%5E%7B1%2F4%7D%5Cmathbb+%7BE%7D%5Cleft+%5B%5Cfrac+%7Bf%7D%7Bg_%7B3%7D%7D%5Cright+%5D%5E%7B1%2F4%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \leq \mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}\mathbb {E}\left [\frac {f}{g_{1}}\right ]^{1/4}\mathbb {E}\left [\frac {f}{g_{2}}\right ]^{1/4}\mathbb {E}\left [\frac {f}{g_{3}}\right ]^{1/4}. \end{aligned}"/></div>
<p>The last three terms equal to <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="1"/> because</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}_{x,y}\frac {f(x,y)}{g_{i}(x,y)} &amp; =\mathbb {E}_{x,y}\frac {f(x,y)}{\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}=\mathbb {E}_{x,y}\frac {\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}{\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}=1. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Cfrac+%7Bf%28x%2Cy%29%7D%7Bg_%7Bi%7D%28x%2Cy%29%7D+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Cfrac+%7Bf%28x%2Cy%29%7D%7B%5Cmathbb+%7BE%7D_%7Bx%27%2Cy%27%5Cin+%5Ctextit+%7BCell%7D%28x%2Cy%29%7D%5Bf%28x%27%2Cy%27%29%5D%7D%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Cfrac+%7B%5Cmathbb+%7BE%7D_%7Bx%27%2Cy%27%5Cin+%5Ctextit+%7BCell%7D%28x%2Cy%29%7D%5Bf%28x%27%2Cy%27%29%5D%7D%7B%5Cmathbb+%7BE%7D_%7Bx%27%2Cy%27%5Cin+%5Ctextit+%7BCell%7D%28x%2Cy%29%7D%5Bf%28x%27%2Cy%27%29%5D%7D%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}_{x,y}\frac {f(x,y)}{g_{i}(x,y)} &amp; =\mathbb {E}_{x,y}\frac {f(x,y)}{\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}=\mathbb {E}_{x,y}\frac {\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}{\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}=1. \end{aligned}"/></div>
<p>where <img alt="\textit {Cell}(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctextit+%7BCell%7D%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\textit {Cell}(x,y)"/> is the set in the partition that contains <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/>. Putting the above together we obtain</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}[f]\leq \mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D%5Bf%5D%5Cleq+%5Cmathbb+%7BE%7D%5Bf%5Ccdot+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%5D%5E%7B1%2F4%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}[f]\leq \mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}. \end{aligned}"/></div>
<p>Finally, because the functions are positive, we have that <img alt="\mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}\leq \mathbb {E}[g_{1}g_{2}g_{3}]^{1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5Bf%5Ccdot+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%5D%5E%7B1%2F4%7D%5Cleq+%5Cmathbb+%7BE%7D%5Bg_%7B1%7Dg_%7B2%7Dg_%7B3%7D%5D%5E%7B1%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}\leq \mathbb {E}[g_{1}g_{2}g_{3}]^{1/4}"/>. This concludes the proof. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">It remains to show the other terms are small. Let <img alt="\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon "/> be the error in the weak regularity lemma with respect to distinguishers with range <img alt="\{0,1\} " class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\} "/>. Recall that this implies error <img alt="O(\epsilon )" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Cepsilon+%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="O(\epsilon )"/> with respect to distinguishers with range <img alt="[-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-1,1]"/>. We give the proof for one of the terms and then we say little about the other two.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-19009r18"/> Claim 18. </span><img alt="|\mathbb {E}[f(x,y)f(xg,y)h_{3}(x,gy)]|\leq O(\epsilon )^{1/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb+%7BE%7D%5Bf%28x%2Cy%29f%28xg%2Cy%29h_%7B3%7D%28x%2Cgy%29%5D%7C%5Cleq+O%28%5Cepsilon+%29%5E%7B1%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\mathbb {E}[f(x,y)f(xg,y)h_{3}(x,gy)]|\leq O(\epsilon )^{1/4}"/>.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">The proof involves changing names of variables and doing Cauchy-Schwarz to remove the terms with <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> and bound the expectation above by <img alt="\mathbb {E}[h_{3}(x,g)U(x)V(xg)]" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5Bh_%7B3%7D%28x%2Cg%29U%28x%29V%28xg%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\mathbb {E}[h_{3}(x,g)U(x)V(xg)]"/>, which is small by the regularity lemma.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Replace <img alt="g" class="latex" src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g"/> with <img alt="gy^{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=gy%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="gy^{-1}"/> in the uniform distribution to get</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; \mathbb {E}_{x,y,g}^{4}[f(x,y)f(xg,y)h_{3}(x,gy)]\\ &amp; =\mathbb {E}_{x,y,g}^{4}[f(x,y)f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; =\mathbb {E}_{x,y}^{4}[f(x,y)\mathbb {E}_{g}[f(xgy^{-1},y)h_{3}(x,g)]]\\ &amp; \leq \mathbb {E}_{x,y}^{2}[f^{2}(x,y)]\mathbb {E}_{x,y}^{2}\mathbb {E}_{g}^{2}[f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; \leq \mathbb {E}_{x,y}^{2}\mathbb {E}_{g}^{2}[f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; =\mathbb {E}_{x,y,g,g'}^{2}[f(xgy^{-1},y)h_{3}(x,g)f(xg'y^{-1},y)h_{3}(x,g')], \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%7D%5E%7B4%7D%5Bf%28x%2Cy%29f%28xg%2Cy%29h_%7B3%7D%28x%2Cgy%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%7D%5E%7B4%7D%5Bf%28x%2Cy%29f%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5E%7B4%7D%5Bf%28x%2Cy%29%5Cmathbb+%7BE%7D_%7Bg%7D%5Bf%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29%5D%5D%5C%5C+%26+%5Cleq+%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5E%7B2%7D%5Bf%5E%7B2%7D%28x%2Cy%29%5D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5E%7B2%7D%5Cmathbb+%7BE%7D_%7Bg%7D%5E%7B2%7D%5Bf%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29%5D%5C%5C+%26+%5Cleq+%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5E%7B2%7D%5Cmathbb+%7BE%7D_%7Bg%7D%5E%7B2%7D%5Bf%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%2Cg%27%7D%5E%7B2%7D%5Bf%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29f%28xg%27y%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%27%29%5D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; \mathbb {E}_{x,y,g}^{4}[f(x,y)f(xg,y)h_{3}(x,gy)]\\ &amp; =\mathbb {E}_{x,y,g}^{4}[f(x,y)f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; =\mathbb {E}_{x,y}^{4}[f(x,y)\mathbb {E}_{g}[f(xgy^{-1},y)h_{3}(x,g)]]\\ &amp; \leq \mathbb {E}_{x,y}^{2}[f^{2}(x,y)]\mathbb {E}_{x,y}^{2}\mathbb {E}_{g}^{2}[f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; \leq \mathbb {E}_{x,y}^{2}\mathbb {E}_{g}^{2}[f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; =\mathbb {E}_{x,y,g,g'}^{2}[f(xgy^{-1},y)h_{3}(x,g)f(xg'y^{-1},y)h_{3}(x,g')], \end{aligned}"/></div>
<p>where the first inequality is by Cauchy-Schwarz.</p>
<p style="text-align: justify;">Now replace <img alt="g\rightarrow x^{-1}g,g'\rightarrow x^{-1}g" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Crightarrow+x%5E%7B-1%7Dg%2Cg%27%5Crightarrow+x%5E%7B-1%7Dg&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\rightarrow x^{-1}g,g'\rightarrow x^{-1}g"/> and reason in the same way:</p>
<div style="text-align: center;"><img alt="\begin{aligned} &amp; =\mathbb {E}_{x,y,g,g'}^{2}[f(gy^{-1},y)h_{3}(x,x^{-1}g)f(g'y^{-1},y)h_{3}(x,x^{-1}g')]\\ &amp; =\mathbb {E}_{g,g',y}^{2}[f(gy^{-1},y)\cdot f(g'y^{-1},y)\mathbb {E}_{x}[h_{3}(x,x^{-1}g)\cdot h_{3}(x,x^{-1}g')]]\\ &amp; \leq \mathbb {E}_{x,x',g,g'}[h_{3}(x,x^{-1}g)h_{3}(x,x^{-1}g')h_{3}(x',x'^{-1}g)h_{3}(x',x'^{-1}g')]. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%2Cg%27%7D%5E%7B2%7D%5Bf%28gy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%29f%28g%27y%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%27%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bg%2Cg%27%2Cy%7D%5E%7B2%7D%5Bf%28gy%5E%7B-1%7D%2Cy%29%5Ccdot+f%28g%27y%5E%7B-1%7D%2Cy%29%5Cmathbb+%7BE%7D_%7Bx%7D%5Bh_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%29%5Ccdot+h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%27%29%5D%5D%5C%5C+%26+%5Cleq+%5Cmathbb+%7BE%7D_%7Bx%2Cx%27%2Cg%2Cg%27%7D%5Bh_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%29h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%27%29h_%7B3%7D%28x%27%2Cx%27%5E%7B-1%7Dg%29h_%7B3%7D%28x%27%2Cx%27%5E%7B-1%7Dg%27%29%5D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} &amp; =\mathbb {E}_{x,y,g,g'}^{2}[f(gy^{-1},y)h_{3}(x,x^{-1}g)f(g'y^{-1},y)h_{3}(x,x^{-1}g')]\\ &amp; =\mathbb {E}_{g,g',y}^{2}[f(gy^{-1},y)\cdot f(g'y^{-1},y)\mathbb {E}_{x}[h_{3}(x,x^{-1}g)\cdot h_{3}(x,x^{-1}g')]]\\ &amp; \leq \mathbb {E}_{x,x',g,g'}[h_{3}(x,x^{-1}g)h_{3}(x,x^{-1}g')h_{3}(x',x'^{-1}g)h_{3}(x',x'^{-1}g')]. \end{aligned}"/></div>
<p style="text-align: justify;">Replace <img alt="g\rightarrow xg" class="latex" src="https://s0.wp.com/latex.php?latex=g%5Crightarrow+xg&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="g\rightarrow xg"/> to rewrite the expectation as</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}[h_{3}(x,g)h_{3}(x,x^{-1}g')h_{3}(x',x'^{-1}xg)h_{3}(x',x'^{-1}g')]. \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D%5Bh_%7B3%7D%28x%2Cg%29h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%27%29h_%7B3%7D%28x%27%2Cx%27%5E%7B-1%7Dxg%29h_%7B3%7D%28x%27%2Cx%27%5E%7B-1%7Dg%27%29%5D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}[h_{3}(x,g)h_{3}(x,x^{-1}g')h_{3}(x',x'^{-1}xg)h_{3}(x',x'^{-1}g')]. \end{aligned}"/></div>
<p style="text-align: justify;">We want to view the last three terms as a distinguisher <img alt="U(x)\cdot V(xg)" class="latex" src="https://s0.wp.com/latex.php?latex=U%28x%29%5Ccdot+V%28xg%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U(x)\cdot V(xg)"/>. First, note that <img alt="h_{3}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{3}"/> has range <img alt="[-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-1,1]"/>. This is because <img alt="h_{3}(x,y)=f(x,y)-\mathbb{E} _{x',y'\in \textit {Cell}(x,y)}f(x',y')" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7B3%7D%28x%2Cy%29%3Df%28x%2Cy%29-%5Cmathbb%7BE%7D+_%7Bx%27%2Cy%27%5Cin+%5Ctextit+%7BCell%7D%28x%2Cy%29%7Df%28x%27%2Cy%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{3}(x,y)=f(x,y)-\mathbb{E} _{x',y'\in \textit {Cell}(x,y)}f(x',y')"/> and <img alt="f" class="latex" src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="f"/> has range <img alt="\{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\{0,1\}"/>, where recall that <img alt="Cell(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=Cell%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="Cell(x,y)"/> is the set in the partition that contains <img alt="(x,y)" class="latex" src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(x,y)"/>. Fix <img alt="x',g'" class="latex" src="https://s0.wp.com/latex.php?latex=x%27%2Cg%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x',g'"/>. The last term in the expectation becomes a constant <img alt="c\in [-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=c%5Cin+%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="c\in [-1,1]"/>. The second term only depends on <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="x"/>, and the third only on <img alt="xg" class="latex" src="https://s0.wp.com/latex.php?latex=xg&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="xg"/>. Hence for appropriate functions <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="U"/> and <img alt="V" class="latex" src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="V"/> with range <img alt="[-1,1]" class="latex" src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="[-1,1]"/> this expectation can be rewritten as</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}[h_{3}(x,g)U(x)V(xg)], \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D%5Bh_%7B3%7D%28x%2Cg%29U%28x%29V%28xg%29%5D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}[h_{3}(x,g)U(x)V(xg)], \end{aligned}"/></div>
<p>which concludes the proof. <img alt="\square " class="latex" src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\square "/></p>
</div>
<p style="text-align: justify;">There are similar proofs to show the remaining terms are small. For <img alt="fh_{2}g_{3}" class="latex" src="https://s0.wp.com/latex.php?latex=fh_%7B2%7Dg_%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="fh_{2}g_{3}"/>, we can perform simple manipulations and then reduce to the above case. For <img alt="h_{1}g_{2}g_{3}" class="latex" src="https://s0.wp.com/latex.php?latex=h_%7B1%7Dg_%7B2%7Dg_%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="h_{1}g_{2}g_{3}"/>, we have a slightly easier proof than above.</p>
<h5 class="subsubsectionHead"><span class="titlemark">7.4.1 </span> <a id="x1-200007.4.1"/>Parameters</h5>
<p style="text-align: justify;">Suppose our set has density <img alt="\delta \ge 1/\log ^{a}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cge+1%2F%5Clog+%5E%7Ba%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\delta \ge 1/\log ^{a}|G|"/>, and the error in the regularity lemma is <img alt="\epsilon " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon "/>. By the above results we can bound</p>
<div style="text-align: center;"><img alt="\begin{aligned} \mathbb {E}_{x,y,g}[f(x,y)f(xg,y)f(x,gy)]\ge 1/\log ^{4a}|G|-2^{O(1/\epsilon ^{2})}/|G|^{\Omega (1)}-\epsilon ^{\Omega (1)}, \end{aligned}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%7D%5Bf%28x%2Cy%29f%28xg%2Cy%29f%28x%2Cgy%29%5D%5Cge+1%2F%5Clog+%5E%7B4a%7D%7CG%7C-2%5E%7BO%281%2F%5Cepsilon+%5E%7B2%7D%29%7D%2F%7CG%7C%5E%7B%5COmega+%281%29%7D-%5Cepsilon+%5E%7B%5COmega+%281%29%7D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\begin{aligned} \mathbb {E}_{x,y,g}[f(x,y)f(xg,y)f(x,gy)]\ge 1/\log ^{4a}|G|-2^{O(1/\epsilon ^{2})}/|G|^{\Omega (1)}-\epsilon ^{\Omega (1)}, \end{aligned}"/></div>
<p>where the terms in the right-hand size come, left-to-right from Claim <a href="https://emanueleviola.wordpress.com/feed/#x1-19008r17">17<!--tex4ht:ref: claim:austin-g1 --></a>, <a href="https://emanueleviola.wordpress.com/feed/#x1-19007r16">16<!--tex4ht:ref: claim:austin-same-for-every-g --></a>, and <a href="https://emanueleviola.wordpress.com/feed/#x1-19009r18">18<!--tex4ht:ref: claim:austin-h-error --></a>. Picking <img alt="\epsilon =1/\log ^{1/3}|G|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1%2F%5Clog+%5E%7B1%2F3%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon =1/\log ^{1/3}|G|"/> the proof is completed for sufficiently small <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/>.</p>
<h3 class="likesectionHead"><a id="x1-210007.4.1"/>References</h3>
<div class="thebibliography">
<p class="bibitem"><span class="biblabel"> [AL00] <span class="bibsp">   </span></span><a id="XAmbainisL00"/>Andris Ambainis and Satyanarayana V. Lokam. Imroved upper bounds on the simultaneous messages complexity of the generalized addressing function. In Latin American Symposium on Theoretical Informatics (LATIN), pages 207–216, 2000.</p>
<p class="bibitem"><span class="biblabel"> [Amb96] <span class="bibsp">   </span></span><a id="XAmbainis96"/>Andris Ambainis. Upper bounds on multiparty communication complexity of shifts. In Symp. on Theoretical Aspects of Computer Science (STACS), pages 631–642, 1996.</p>
<p class="bibitem"><span class="biblabel"> [AMS99] <span class="bibsp">   </span></span><a id="XAMS99"/>Noga Alon, Yossi Matias, and Mario Szegedy. The space complexity of approximating the frequency moments. J. of Computer and System Sciences, 58(1, part 2):137–147, 1999.</p>
<p class="bibitem"><span class="biblabel"> [Aus16] <span class="bibsp">   </span></span><a id="XAustin2016"/>Tim Austin. Ajtai-Szemerédi theorems over quasirandom groups. In Recent trends in combinatorics, volume 159 of IMA Vol. Math. Appl., pages 453–484. Springer, [Cham], 2016.</p>
<p class="bibitem"><span class="biblabel"> [Bar89] <span class="bibsp">   </span></span><a id="XBarrington89"/>David A. Mix Barrington. Bounded-width polynomial-size branching programs recognize exactly those languages in NC<img alt="^1" class="latex" src="https://s0.wp.com/latex.php?latex=%5E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="^1"/>. J. of Computer and System Sciences, 38(1):150–164, 1989.</p>
<p class="bibitem"><span class="biblabel"> [BC92] <span class="bibsp">   </span></span><a id="XBen-OrC92"/>Michael Ben-Or and Richard Cleve. Computing algebraic formulas using a constant number of registers. SIAM J. on Computing, 21(1):54–58, 1992.</p>
<p class="bibitem"><span class="biblabel"> [BDPW10]<span class="bibsp">   </span></span><a id="XBeameDPW10"/>Paul Beame, Matei David, Toniann Pitassi, and Philipp Woelfel. Separating deterministic from randomized multiparty communication complexity. Theory of Computing, 6(1):201–225, 2010.</p>
<p class="bibitem"><span class="biblabel"> [BGKL03] <span class="bibsp">   </span></span><a id="XBGKL03"/>László Babai, Anna Gál, Peter G. Kimmel, and Satyanarayana V. Lokam. Communication complexity of simultaneous messages. SIAM J. on Computing, 33(1):137–166, 2003.</p>
<p class="bibitem"><span class="biblabel"> [BNP08] <span class="bibsp">   </span></span><a id="XBabaiNP08"/>László Babai, Nikolay Nikolov, and László Pyber. Product growth and mixing in finite groups. In ACM-SIAM Symp. on Discrete Algorithms (SODA), pages 248–257, 2008.</p>
<p class="bibitem"><span class="biblabel"> [CFL83] <span class="bibsp">   </span></span><a id="XCFL83"/>Ashok K. Chandra, Merrick L. Furst, and Richard J. Lipton. Multi-party protocols. In 15th ACM Symp. on the Theory of Computing (STOC), pages 94–99, 1983.</p>
<p class="bibitem"><span class="biblabel"> [CP10] <span class="bibsp">   </span></span><a id="XDBLP:journals/sigact/ChattopadhyayP10"/>Arkadev Chattopadhyay and Toniann Pitassi. The story of set disjointness. SIGACT News, 41(3):59–85, 2010.</p>
<p class="bibitem"><span class="biblabel"> [DHKP97] <span class="bibsp">   </span></span><a id="XDietzfelbingerHKP97"/>Martin Dietzfelbinger, Torben Hagerup, Jyrki Katajainen, and Martti Penttonen. A reliable randomized algorithm for the closest-pair problem. J. Algorithms, 25(1):19–51, 1997.</p>
<p class="bibitem"><span class="biblabel"> [FK96] <span class="bibsp">   </span></span><a id="XDBLP:conf/focs/FriezeK96"/>Alan M. Frieze and Ravi Kannan. The regularity lemma and approximation schemes for dense problems. In IEEE Symp. on Foundations of Computer Science (FOCS), pages 12–20, 1996.</p>
<p class="bibitem"><span class="biblabel"> [Gow08] <span class="bibsp">   </span></span><a id="XGowers08"/>W. T. Gowers. Quasirandom groups. Combinatorics, Probability &amp; Computing, 17(3):363–387, 2008.</p>
<p class="bibitem"><span class="biblabel"> [Gre05a] <span class="bibsp">   </span></span><a id="XGreen-supplement"/>Ben Green. An argument of Shkredov in the finite field setting, 2005. Available at people.maths.ox.ac.uk/greenbj/papers/corners.pdf.</p>
<p class="bibitem"><span class="biblabel"> [Gre05b] <span class="bibsp">   </span></span><a id="XGre04-finite"/>Ben Green. Finite field models in additive combinatorics. Surveys in Combinatorics, London Math. Soc. Lecture Notes 327, 1-27, 2005.</p>
<p class="bibitem"><span class="biblabel"> [GVa] <span class="bibsp">   </span></span><a id="XGowersV-cc-int-journal"/>W. T. Gowers and Emanuele Viola. Interleaved group products. SIAM J. on Computing.</p>
<p class="bibitem"><span class="biblabel"> [GVb] <span class="bibsp">   </span></span><a id="XGowersV-cc-int-2"/>W. T. Gowers and Emanuele Viola. The multiparty communication complexity of interleaved group products. SIAM J. on Computing.</p>
<p class="bibitem"><span class="biblabel"> [GV15] <span class="bibsp">   </span></span><a id="XGowersV-cc-int"/>W. T. Gowers and Emanuele Viola. The communication complexity of interleaved group products. In ACM Symp. on the Theory of Computing (STOC), 2015.</p>
<p class="bibitem"><span class="biblabel"> [IL95] <span class="bibsp">   </span></span><a id="XImmermanL95"/>Neil Immerman and Susan Landau. The complexity of iterated multiplication. Inf. Comput., 116(1):103–116, 1995.</p>
<p class="bibitem"><span class="biblabel"> [KMR66] <span class="bibsp">   </span></span><a id="XKrohnMR66"/>Kenneth Krohn, W. D. Maurer, and John Rhodes. Realizing complex Boolean functions with simple groups. Information and Control, 9:190–195, 1966.</p>
<p class="bibitem"><span class="biblabel"> [KN97] <span class="bibsp">   </span></span><a id="XKuN97"/>Eyal Kushilevitz and Noam Nisan. Communication complexity. Cambridge University Press, 1997.</p>
<p class="bibitem"><span class="biblabel"> [KS92] <span class="bibsp">   </span></span><a id="XKalyanasundaramS92"/>Bala Kalyanasundaram and Georg Schnitger. The probabilistic communication complexity of set intersection. SIAM J. Discrete Math., 5(4):545–557, 1992.</p>
<p class="bibitem"><span class="biblabel"> [LM07] <span class="bibsp">   </span></span><a id="XMR2289954"/>Michael T. Lacey and William McClain. On an argument of Shkredov on two-dimensional corners. Online J. Anal. Comb., (2):Art. 2, 21, 2007.</p>
<p class="bibitem"><span class="biblabel"> [LW54] <span class="bibsp">   </span></span><a id="XLangWeil54"/>Serge Lang and André Weil. Number of points of varieties in finite fields. American Journal of Mathematics, 76:819–827, 1954.</p>
<p class="bibitem"><span class="biblabel"> [Mil14] <span class="bibsp">   </span></span><a id="XMiles14"/>Eric Miles. Iterated group products and leakage resilience against <img alt="NC^1" class="latex" src="https://s0.wp.com/latex.php?latex=NC%5E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="NC^1"/>. In ACM Innovations in Theoretical Computer Science conf. (ITCS), 2014.</p>
<p class="bibitem"><span class="biblabel"> [MV13] <span class="bibsp">   </span></span><a id="XMilesV-leak"/>Eric Miles and Emanuele Viola. Shielding circuits with groups. In ACM Symp. on the Theory of Computing (STOC), 2013.</p>
<p class="bibitem"><span class="biblabel"> [PRS97] <span class="bibsp">   </span></span><a id="XPRS97"/>Pavel Pudlák, Vojtěch Rödl, and Jiří Sgall. Boolean circuits, tensor ranks, and communication complexity. SIAM J. on Computing, 26(3):605–633, 1997.</p>
<p class="bibitem"><span class="biblabel"> [Raz92] <span class="bibsp">   </span></span><a id="XRazborov92"/>Alexander A. Razborov. On the distributional complexity of disjointness. Theor. Comput. Sci., 106(2):385–390, 1992.</p>
<p class="bibitem"><span class="biblabel"> [Raz00] <span class="bibsp">   </span></span><a id="XRaz00"/>Ran Raz. The BNS-Chung criterion for multi-party communication complexity. Computational Complexity, 9(2):113–122, 2000.</p>
<p class="bibitem"><span class="biblabel"> [RY19] <span class="bibsp">   </span></span><a id="XRaoY2019"/>Anup Rao and Amir Yehudayoff. Communication complexity. 2019. <a href="https://homes.cs.washington.edu/&#xA0;anuprao/pubs/book.pdf" rel="nofollow">https://homes.cs.washington.edu/ anuprao/pubs/book.pdf</a>.</p>
<p class="bibitem"><span class="biblabel"> [Sha16] <span class="bibsp">   </span></span><a id="XShalev16"/>Aner Shalev. Mixing, communication complexity and conjectures of Gowers and Viola. Combinatorics, Probability and Computing, pages 1–13, 6 2016. arXiv:1601.00795.</p>
<p class="bibitem"><span class="biblabel"> [She14] <span class="bibsp">   </span></span><a id="XSherstov14-35years"/>Alexander A. Sherstov. Communication complexity theory: Thirty-five years of set disjointness. In Symp. on Math. Foundations of Computer Science (MFCS), pages 24–43, 2014.</p>
<p class="bibitem"><span class="biblabel"> [Tao17] <span class="bibsp">   </span></span><a id="XTao2017-szemerediproof"/>Terence Tao. Szemerédiâs proof of Szemerédiâs theorem, 2017. <a href="https://terrytao.files.wordpress.com/2017/09/szemeredi-proof1.pdf" rel="nofollow">https://terrytao.files.wordpress.com/2017/09/szemeredi-proof1.pdf</a>.</p>
<p class="bibitem"><span class="biblabel"> [Vioa] <span class="bibsp">   </span></span><a id="Xviola-blog-mixing-in-groups"/>Emanuele Viola. Thoughts: Mixing in groups. <a href="https://emanueleviola.wordpress.com/2016/10/21/mixing-in-groups/" rel="nofollow">https://emanueleviola.wordpress.com/2016/10/21/mixing-in-groups/</a>.</p>
<p class="bibitem"><span class="biblabel"> [Viob] <span class="bibsp">   </span></span><a id="Xviola-blog-mixing-in-groups-ii"/>Emanuele Viola. Thoughts: Mixing in groups ii. <a href="https://emanueleviola.wordpress.com/2016/11/15/mixing-in-groups-ii/" rel="nofollow">https://emanueleviola.wordpress.com/2016/11/15/mixing-in-groups-ii/</a>.</p>
<p class="bibitem"><span class="biblabel"> [Vio14] <span class="bibsp">   </span></span><a id="XViola-ccsum"/>Emanuele Viola. The communication complexity of addition. Combinatorica, pages 1–45, 2014.</p>
<p class="bibitem"><span class="biblabel"> [Vio17] <span class="bibsp">   </span></span><a id="Xviola-special-topics17"/>Emanuele Viola. Special topics in complexity theory. Lecture notes of the class taught at Northeastern University. Available at <a href="http://www.ccs.neu.edu/home/viola/classes/spepf17.html" rel="nofollow">http://www.ccs.neu.edu/home/viola/classes/spepf17.html</a>, 2017.</p>
<p class="bibitem"><span class="biblabel"> [Yao79] <span class="bibsp">   </span></span><a id="XYao79"/>Andrew Chi-Chih Yao. Some complexity questions related to distributive computing. In 11th ACM Symp. on the Theory of Computing (STOC), pages 209–213, 1979.</p>
</div>
<p> </p>
<p> </p></div>
    </content>
    <updated>2019-07-10T17:00:32Z</updated>
    <published>2019-07-10T17:00:32Z</published>
    <category term="Uncategorized"/>
    <category term="lecture"/>
    <category term="lower bounds"/>
    <author>
      <name>Emanuele</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2019-07-28T23:39:54Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2019/07/10/trajectories-linear-nets/</id>
    <link href="http://offconvex.github.io/2019/07/10/trajectories-linear-nets/" rel="alternate" type="text/html"/>
    <title>Understanding implicit regularization in deep learning by analyzing trajectories of gradient descent</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Sanjeev’s <a href="http://www.offconvex.org/2019/06/03/trajectories/">recent blog post</a> suggested that the conventional view of optimization is insufficient for understanding deep learning, as the value of the training objective does not reliably capture generalization.
He argued that instead, we need to consider the <em>trajectories</em> of optimization.
One of the illustrative examples given was our <a href="https://arxiv.org/abs/1905.13655">new paper with Sanjeev Arora and Yuping Luo</a>, which studies the use of deep linear neural networks for solving <a href="https://en.wikipedia.org/wiki/Matrix_completion"><em>matrix completion</em></a> more accurately than the classic convex programming approach. 
The current post provides more details on this result.</p>

<p>Recall that in matrix completion we are given some entries $\{ M_{i, j} : (i, j) \in \Omega \}$ of an unknown <em>ground truth</em> matrix $M$, and our goal is to recover the remaining entries.
This can be thought of as a supervised learning (regression) problem, where the training examples are the observed entries of $M$, the model is a matrix $W$ trained with the loss:
[
L(W) = \sum\nolimits_{(i, j) \in \Omega} (W_{i, j} - M_{i, j})^2 ~,
]
and generalization corresponds to how similar $W$ is to $M$ in the unobserved locations.
Obviously the problem is ill-posed if we assume nothing about $M$ $-$ the loss $L(W)$ is underdetermined, i.e. has multiple optima, and it would be impossible to tell (without access to unobserved entries) if one solution is better than another.
The standard assumption (which has many <a href="https://en.wikipedia.org/wiki/Matrix_completion#Applications">practical applications</a>) is that the ground truth matrix $M$ is low-rank, and thus the goal is to find, from among all global minima of the loss $L(W)$, one with minimal rank. 
The classic algorithm for achieving this is to find the matrix with minimum <a href="https://en.wikipedia.org/wiki/Matrix_norm#Schatten_norms"><em>nuclear norm</em></a>. 
This is a convex program, which <em>given enough observed entries</em> (and under mild technical assumptions $-$ “incoherence”) recovers the ground truth exactly (cf. <a href="https://statweb.stanford.edu/~candes/papers/MatrixCompletion.pdf">Candes and Recht</a>). 
We’re interested in the regime where the number of revealed entries is too small for the classic algorithm to succeed.
There it can be beaten by a simple deep learning approach, as described next.</p>

<h2 id="linear-neural-networks-lnn">Linear Neural Networks (LNN)</h2>

<p>A linear neural network (LNN) is a fully-connected neural network with linear activation (i.e. no non-linearity).
If $W_j$ is the weight matrix in layer $j$ of a depth $N$ network, the <em>end-to-end matrix</em> is given by $W = W_N W_{N-1} \cdots W_1$.
Our method for solving matrix completion involves minimizing the loss $L(W)$ by running gradient descent (GD) on this (over-)parameterization, with depth $N \geq 2$ and hidden dimensions that do not constrain rank.
This can be viewed as a deep learning problem with $\ell_2$ loss, and GD can be implemented through the chain rule as usual.
Note that the training objective does not include any regularization term controlling the individual layer matrices $\{ W_j \}_j$.</p>

<p>At first glance our algorithm seems naive, since parameterization by an LNN (that does not constrain rank) is equivalent to parameterization by a single matrix $W$, and obviously running GD on $L(W)$ directly with no regularization is not a good approach (nothing will be learned in the unobserved locations).
However, since matrix completion is an underdetermined problem (has multiple optima), the optimum reached by GD can vary depending on the chosen parameterization.
Our setup isolates the role of over-parameterization in implicitly biasing GD towards certain optima (that hopefully generalize well).</p>

<p>Note that in the special case of depth $N = 2$ our method reduces to a traditional approach for matrix completion,  named <em>matrix factorization</em>. 
By analogy, we refer to the case $N \geq 3$ as <em>deep matrix factorization</em>. 
The table below shows reconstruction errors (generalization) on a matrix completion task where the number of observed entries is too small for nuclear norm minimization to succeed.
As can be seen, it is outperformed by matrix factorization, which itself is outperformed by deep matrix factorization.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/trajectories-linear-nets-exp-reconst-errs.png" style="width: 700px;"/>
<br/>
<b>Table 1:</b> Results for matrix completion with small number of observations.
</div>
<p><br/>
The main focus of our paper is on developing a theoretical understanding of this phenomenon.</p>

<h2 id="trajectory-analysis-implicit-regularization-towards-low-rank">Trajectory Analysis: Implicit Regularization Towards Low Rank</h2>

<p>We are interested in understanding what end-to-end matrix $W$ emerges when we run GD on an LNN to minimize a general convex loss $L(W)$, and in particular the matrix completion loss given above. 
Note that $L(W)$ is convex, but the objective obtained by over-parameterizing with an LNN is not.
We analyze the trajectories of $W$, and specifically the dynamics of its singular value decomposition.
Denote the singular values by $\{ \sigma_r \}_r$, and the corresponding left and right singular vectors by $\{ \mathbf{u}_r \}_r$ and $\{ \mathbf{v}_r \}_r$ respectively.</p>

<p>We start by considering GD applied to $L(W)$ directly (no over-parameterization).</p>

<blockquote>
  <p><strong>Known result:</strong>
Minimizing $L(W)$ directly by GD (with small learning rate $\eta$) leads the singular values of $W$ to evolve by:
[
\sigma_r(t + 1) \leftarrow \sigma_r(t) - \eta \cdot \langle \nabla L(W(t)) , \mathbf{u}_r(t) \mathbf{v}_r^\top(t) \rangle ~.
\qquad (1)
]</p>
</blockquote>

<p>This statement implies that the movement of a singular value is proportional to the projection of the gradient onto the corresponding singular component.</p>

<p>Now suppose that we parameterize $W$ with an $N$-layer LNN, i.e. as $W = W_N W_{N-1} \cdots W_1$.
In previous work (described in <a href="http://www.offconvex.org/2018/03/02/acceleration-overparameterization/">Nadav’s earlier blog post</a>) we have shown that running GD on the LNN, with small learning rate $\eta$ and initialization close to the origin, leads the end-to-end matrix $W$ to evolve by:</p>



<p>In the new paper we rely on this result to prove the following:</p>

<blockquote>
  <p><strong>Theorem:</strong>
Minimizing $L(W)$ by running GD (with small learning rate $\eta$ and initialization close to the origin) on an $N$-layer LNN leads the singular values of $W$ to evolve by:
[ \sigma_r(t + 1) \leftarrow \sigma_r(t) - \eta \cdot \langle \nabla L(W(t)) , \mathbf{u}_r(t) \mathbf{v}_r^\top(t) \rangle \cdot \color{purple}{N \cdot (\sigma_r(t))^{2 - 2 / N}} ~.
]</p>
</blockquote>

<p>Comparing this to Equation $(1)$, we see that over-parameterizing the loss $L(W)$ with an $N$-layer LNN introduces the multiplicative factors $\color{purple}{N \cdot (\sigma_r(t))^{2 - 2 / N}}$ to the evolution of singular values.
While the constant $N$ does not change relative dynamics (can be absorbed into the learning rate $\eta$), the terms $(\sigma_r(t))^{2 - 2 / N}$ do $-$ they enhance movement of large singular values, and on the hand attenuate that of small ones.
Moreover, the enhancement/attenuation becomes more significant as $N$ (network depth) grows.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/trajectories-linear-nets-thm-dynamics.png" style="width: 900px;"/>
<br/>
<b>Figure 1:</b> Over-parameterizing with LNN modifies dynamics of singular values.
</div>
<p><br/></p>

<p>The enhancement/attenuation effect induced by an LNN (factors $\color{purple}{N \cdot (\sigma_r(t))^{2 - 2 / N}}$) leads each singular value to progress very slowly after initialization, when close to zero, and then, upon reaching a certain threshold, move rapidly, with the transition from slow to rapid movement being sharper in case of a deeper network (larger $N$).
If the loss $L(W)$ is underdetermined (has multiple optima) these dynamics promote solutions that have a few large singular values and many small ones (that have yet to reach the phase transition between slow to rapid movement), with a gap that is more extreme the deeper the network is. 
This is an implicit regularization towards low rank, which intensifies with depth.
In the paper we support the intuition with empirical evaluations and theoretical illustrations, demonstrating how adding depth to an LNN can lead GD to produce solutions closer to low-rank.
For example, the following plots, corresponding to a task of matrix completion, show evolution of singular values throughout training of networks with varying depths $-$ as can be seen, adding layers indeed admits a final solution whose spectrum is closer to low-rank, thereby improving generalization.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/trajectories-linear-nets-exp-dynamics.png" style="width: 900px;"/>
<br/>
<b>Figure 2:</b> Dynamics of singular values in training matrix factorizations (LNN).
</div>

<h2 id="do-the-trajectories-minimize-some-regularized-objective">Do the Trajectories Minimize Some Regularized Objective?</h2>

<p>In recent years, researchers have come to realize the importance of implicit regularization induced by the choice of optimization algorithm.
The strong gravitational pull of the conventional view on optimization (see <a href="http://www.offconvex.org/2019/06/03/trajectories/">Sanjeev’s post</a>) has led most papers on this line to try and capture the effect in the language of regularized objectives. 
For example, it is known that over linear models, i.e. depth $1$ networks, GD finds the solution with minimal Frobenius norm (cf. Section 5 in <a href="https://openreview.net/pdf?id=Sy8gdB9xx">Zhang et al.</a>), and a common hypothesis is that this persists over more elaborate neural networks, with Frobenius norm potentially replaced by some other norm (or quasi-norm) that depends on network architecture.
<a href="https://papers.nips.cc/paper/7195-implicit-regularization-in-matrix-factorization.pdf">Gunasekar et al.</a> explicitly conjectured:</p>

<blockquote>
  <p><strong>Conjecture (by <a href="https://papers.nips.cc/paper/7195-implicit-regularization-in-matrix-factorization.pdf">Gunasekar et al.</a>, informally stated):</strong>
GD (with small learning rate and near-zero initialization) training a matrix factorization finds a solution with minimum <a href="https://en.wikipedia.org/wiki/Matrix_norm#Schatten_norms">nuclear norm</a>.</p>
</blockquote>

<p>This conjecture essentially states that matrix factorization (i.e. $2$-layer LNN) trained by GD is equivalent to the famous method of nuclear norm minimization.
Gunasekar et al. motivated the conjecture with some empirical evidence, as well as mathematical evidence in the form of a proof for a (very) restricted setting.</p>

<p>Given the empirical observation by which adding depth to a matrix factorization can improve results in matrix completion, it would be natural to extend the conjecture of Gunasekar et al., and assert that the implicit regularization with depth $3$ or higher corresponds to minimizing some other norm (or quasi-norm) that approximates rank better than nuclear norm does.
For example, a natural candidate would be a <a href="https://en.wikipedia.org/wiki/Schatten_norm">Schatten-$p$ quasi-norm</a> with some $0 &lt; p &lt; 1$.</p>

<p>Our investigation began with this approach, but ultimately, we became skeptical of the entire “implicit regularization as norm minimization” line of reasoning, and in particular of the conjecture by Gunasekar et al.</p>

<blockquote>
  <p><strong>Theorem (mathematical evidence against the conjecture):</strong>
In the same restricted setting for which Gunasekar et al. proved their conjecture, nuclear norm is minimized by GD over matrix factorization not only with depth $2$, but with any depth $\geq 3$ as well.</p>
</blockquote>

<p>This theorem disqualifies Schatten quasi-norms as the implicit regularization in deep matrix factorizations, and instead suggests that all depths correspond to nuclear norm.
However, empirically we found a notable difference in performance between different depths, so the conceptual leap from a proof in the restricted setting to a general conjecture, as done by Gunasekar et al., seems questionable.</p>

<p>In the paper we conduct a systematic set of experiments to empirically evaluate the conjecture.
We find that in the regime where nuclear norm minimization is suboptimal (few observed entries), matrix factorizations consistently outperform it (see for example Table 1).
This holds in particular with depth $2$, in contrast to the conjecture’s prediction.
Together, our theory and experiments lead us to believe that it may not be possible to capture the implicit regularization in LNN with a single mathematical norm (or quasi-norm).</p>

<p>Full details behind our results on “implicit regularization as norm minimization” can be found in Section 2 of <a href="https://arxiv.org/abs/1905.13655">the paper</a>.
The trajectory analysis we discussed earlier appears in Section 3 there.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The <a href="http://www.offconvex.org/2019/06/03/trajectories/">conventional view of optimization</a> has been integral to the theory of machine learning. 
Our study suggests that the associated vocabulary may not suffice for understanding generalization in deep learning, and one should instead analyze trajectories of optimization, taking into account that speed of convergence does not necessarily correlate with generalization.
We hope this work will motivate development of a new vocabulary for analyzing deep learning.</p></div>
    </summary>
    <updated>2019-07-10T17:00:00Z</updated>
    <published>2019-07-10T17:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2019-07-28T23:40:23Z</updated>
    </source>
  </entry>
</feed>
