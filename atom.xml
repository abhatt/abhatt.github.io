<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2019-07-30T12:22:12Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.12443</id>
    <link href="http://arxiv.org/abs/1907.12443" rel="alternate" type="text/html"/>
    <title>Distributed Dense Subgraph Detection and Low Outdegree Orientation</title>
    <feedworld_mtime>1564444800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Su:Hsin=Hao.html">Hsin-Hao Su</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vu:Hoa_T=.html">Hoa T. Vu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.12443">PDF</a><br/><b>Abstract: </b>The maximum density subgraph problem, introduced in the 80s by Picard and
Queyranne as well as Goldberg, is a classic problem in combinatorial
optimization with a wide range of applications. The lowest outdegree
orientation problem is known to be its dual problem. We study both the problem
of finding dense subgraphs and the problem of computing a low outdegree
orientation in the distributed settings.
</p>
<p>Suppose $G=(V,E)$ is the underlying network as well as the input graph. Let
$D$ denote the density of the maximum density subgraph of $G$. We give the
following results:
</p>
<p>Given a value $\tilde{D} \leq D$ and $0 &lt; \epsilon &lt; 1$, we show that a
subgraph of density at least $(1-\epsilon)\tilde{D}$ can be identified
deterministically in $O((\log n) / \epsilon)$ rounds in the \textsf{LOCAL}
model. Using randomization, we show that such subgraph can be identified in
$O((\log^3 n) / \epsilon^3)$ rounds in the \textsf{CONGEST} model with high
probability. We also give a $\Omega(1/\epsilon)$-round lower bound which shows
that our result for the \textsf{LOCAL} model is tight up to a $O(\log n)$
factor. Moreover, our result can be extended to solve the directed version of
the problem introduced by Kannan and Vinay \cite{KV99}.
</p>
<p>Given an integer $\tilde{D} \geq D$ and $\Omega(1/\tilde{D}) &lt; \epsilon &lt;
1/4$, we give an $O(\log^2 n \cdot (\log^{2.71} \Delta) /\epsilon^2)$-round
deterministic algorithm in the \textsf{CONGEST} model that computes an
orientation where the outdegree of every vertex is upper bounded by
$(1+\epsilon)\tilde{D}$. Previously, the best deterministic algorithm for this
problem is by Harris \cite{Harris19} that runs in $\tilde{O}((\log^6 n) /
\epsilon^4)$ rounds in the \local model.
</p></div>
    </summary>
    <updated>2019-07-30T02:52:37Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.12383</id>
    <link href="http://arxiv.org/abs/1907.12383" rel="alternate" type="text/html"/>
    <title>The Operational Cost of Ethereum Airdrops</title>
    <feedworld_mtime>1564444800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fr=ouml=wis:Michael.html">Michael Fröwis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/B=ouml=hme:Rainer.html">Rainer Böhme</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.12383">PDF</a><br/><b>Abstract: </b>Efficient transfers to many recipients present a host of issues on Ethereum.
First, accounts are identified by long and incompressible constants. Second,
these constants have to be stored and communicated for each payment. Third, the
standard interface for token transfers does not support lists of recipients,
adding repeated communication to the overhead. Since Ethereum charges resource
usage, even small optimizations translate to cost savings. Airdrops, a popular
marketing tool used to boost coin uptake, present a relevant example for the
value of optimizing bulk transfers. Therefore, we review technical solutions
for airdrops of Ethereum-based tokens, discuss features and prerequisites, and
compare the operational costs by simulating 35 scenarios. We find that cost
savings of factor two are possible, but require specific provisions in the
smart contract implementing the token system. Pull-based approaches, which use
on-chain interaction with the recipients, promise moderate savings for the
distributor while imposing a disproportional cost on each recipient. Total
costs are broadly linear in the number of recipients independent of the
technical approach. We publish the code of the simulation framework for
reproducibility, to support future airdrop decisions, and to benchmark
innovative bulk payment solutions.
</p></div>
    </summary>
    <updated>2019-07-30T02:57:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.12343</id>
    <link href="http://arxiv.org/abs/1907.12343" rel="alternate" type="text/html"/>
    <title>Blue-Noise Dithered QMC Hierarchical Russian Roulette</title>
    <feedworld_mtime>1564444800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pantaleoni:Jacopo.html">Jacopo Pantaleoni</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.12343">PDF</a><br/><b>Abstract: </b>In order to efficiently sample specular-diffuse-glossy and
glossy-diffuse-glossy transport phenomena, Tokuyoshi and Harada introduced
hierarchical Russian roulette, a smart algorithm that allows to compute the
minimum of the random numbers associated to leaves of a tree at each internal
node. The algorithm is used to efficiently cull the connections between the
product set of eye and light vertices belonging to large caches of eye and
light subpaths produced through bidirectional path tracing. The original
version of the algorithm is entirely based on the generation of semi-stratified
pseudo-random numbers. Our paper proposes a novel variant based on
deterministic blue-noise dithered Quasi Monte Carlo samples.
</p></div>
    </summary>
    <updated>2019-07-30T02:23:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.12335</id>
    <link href="http://arxiv.org/abs/1907.12335" rel="alternate" type="text/html"/>
    <title>A Join-Based Hybrid Parameter for Constraint Satisfaction</title>
    <feedworld_mtime>1564444800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ganian:Robert.html">Robert Ganian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ordyniak:Sebastian.html">Sebastian Ordyniak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Szeider:Stefan.html">Stefan Szeider</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.12335">PDF</a><br/><b>Abstract: </b>We propose joinwidth, a new complexity parameter for the Constraint
Satisfaction Problem (CSP). The definition of joinwidth is based on the
arrangement of basic operations on relations (joins, projections, and pruning),
which inherently reflects the steps required to solve the instance. We use
joinwidth to obtain polynomial-time algorithms (if a corresponding
decomposition is provided in the input) as well as fixed-parameter algorithms
(if no such decomposition is provided) for solving the CSP.
</p>
<p>Joinwidth is a hybrid parameter, as it takes both the graphical structure as
well as the constraint relations that appear in the instance into account. It
has, therefore, the potential to capture larger classes of tractable instances
than purely structural parameters like hypertree width and the more general
fractional hypertree width (fhtw). Indeed, we show that any class of instances
of bounded fhtw also has bounded joinwidth, and that there exist classes of
instances of bounded joinwidth and unbounded fhtw, so bounded joinwidth
properly generalizes bounded fhtw.
</p>
<p>We further show that bounded joinwidth also properly generalizes several
other known hybrid restrictions, such as fhtw with degree constraints and
functional dependencies. In this sense, bounded joinwidth can be seen as a
unifying principle that explains the tractability of several seemingly
unrelated classes of CSP instances.
</p></div>
    </summary>
    <updated>2019-07-30T02:52:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.12287</id>
    <link href="http://arxiv.org/abs/1907.12287" rel="alternate" type="text/html"/>
    <title>Parameterized Valiant's Classes</title>
    <feedworld_mtime>1564444800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Markus Blaeser, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Engels:Christian.html">Christian Engels</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.12287">PDF</a><br/><b>Abstract: </b>We define a theory of parameterized algebraic complexity classes in analogy
to parameterized Boolean counting classes. We define the classes VFPT and
VW[t], which mirror the Boolean counting classes #FPT and #W[t], and define
appropriate reductions and completeness notions. Our main contribution is the
VW[1]-completeness proof of the parameterized clique family. This proof is far
more complicated than in the Boolean world. It requires some new concepts like
composition theorems for bounded exponential sums and Boolean-arithmetic
formulas. In addition, we also look at two polynomials linked to the permanent
with vastly different parameterized complexity.
</p></div>
    </summary>
    <updated>2019-07-30T02:20:48Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.12130</id>
    <link href="http://arxiv.org/abs/1907.12130" rel="alternate" type="text/html"/>
    <title>Towards Optimizing Reiter's HS-Tree for Sequential Diagnosis</title>
    <feedworld_mtime>1564444800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rodler:Patrick.html">Patrick Rodler</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.12130">PDF</a><br/><b>Abstract: </b>Reiter's HS-Tree is one of the most popular diagnostic search algorithms due
to its desirable properties and general applicability. In sequential diagnosis,
where the addressed diagnosis problem is subject to successive change through
the acquisition of additional knowledge about the diagnosed system, HS-Tree is
used in a stateless fashion. That is, the existing search tree is discarded
when new knowledge is obtained, albeit often large parts of the tree are still
relevant and have to be rebuilt in the next iteration, involving redundant
operations and costly reasoner calls. As a remedy to this, we propose
DynamicHS, a variant of HS-Tree that avoids these redundancy issues by
maintaining state throughout sequential diagnosis while preserving all
desirable properties of HS-Tree. Preliminary results of ongoing evaluations in
a problem domain where HS-Tree is the state-of-the-art diagnostic method
suggest significant time savings achieved by DynamicHS by reducing expensive
reasoner calls.
</p></div>
    </summary>
    <updated>2019-07-30T02:22:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.12119</id>
    <link href="http://arxiv.org/abs/1907.12119" rel="alternate" type="text/html"/>
    <title>A Fast Minimum Degree Algorithm and Matching Lower Bound</title>
    <feedworld_mtime>1564444800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cummings:Robert.html">Robert Cummings</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fahrbach:Matthew.html">Matthew Fahrbach</a>, Animesh Fatehpuria <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.12119">PDF</a><br/><b>Abstract: </b>The minimum degree algorithm is one of the most widely-used heuristics for
reducing the cost of solving large sparse systems of linear equations. It has
been studied for nearly half a century and has rich history of bridging
techniques from data structures, graph algorithms, and direct methods in
scientific computing. We present a simple but novel combinatorial algorithm for
computing minimum degree elimination orderings in $O(nm)$ time that relies on a
careful amortized analysis. Furthermore, we show that there cannot exist an
algorithm for this problem that runs in $O(nm^{1-\varepsilon})$ time, for any
$\varepsilon &gt; 0$, assuming the strong exponential time hypothesis.
</p></div>
    </summary>
    <updated>2019-07-30T02:51:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.12106</id>
    <link href="http://arxiv.org/abs/1907.12106" rel="alternate" type="text/html"/>
    <title>A Lower Bound on Cycle-Finding in Sparse Digraphs</title>
    <feedworld_mtime>1564444800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Xi.html">Xi Chen</a>, Tim Randolph, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Servedio:Rocco_A=.html">Rocco A. Servedio</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Timothy.html">Timothy Sun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.12106">PDF</a><br/><b>Abstract: </b>We consider the problem of finding a cycle in a sparse directed graph $G$
that is promised to be far from acyclic, meaning that the smallest feedback arc
set in $G$ is large. We prove an information-theoretic lower bound, showing
that for $N$-vertex graphs with constant outdegree any algorithm for this
problem must make $\tilde{\Omega}(N^{5/9})$ queries to an adjacency list
representation of $G$. In the language of property testing, our result is an
$\tilde{\Omega}(N^{5/9})$ lower bound on the query complexity of one-sided
algorithms for testing whether sparse digraphs with constant outdegree are far
from acyclic. This is the first improvement on the $\Omega(\sqrt{N})$ lower
bound, implicit in Bender and Ron, which follows from a simple birthday paradox
argument.
</p></div>
    </summary>
    <updated>2019-07-30T02:23:55Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.12061</id>
    <link href="http://arxiv.org/abs/1907.12061" rel="alternate" type="text/html"/>
    <title>Parameterized Pre-coloring Extension and List Coloring Problems</title>
    <feedworld_mtime>1564444800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Gregory Gutin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Majumdar:Diptapriyo.html">Diptapriyo Majumdar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ordyniak:Sebastian.html">Sebastian Ordyniak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wahlstr=ouml=m:Magnus.html">Magnus Wahlström</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.12061">PDF</a><br/><b>Abstract: </b>Golovach, Paulusma and Song (Inf. Comput. 2014) asked to determine the
parameterized complexity of the following problems parameterized by $k$: (1)
Given a graph $G$, a clique modulator $D$ (a clique modulator is a set of
vertices, whose removal results in a clique) of size $k$ for $G$, and a list
$L(v)$ of colors for every $v\in V(G)$, decide whether $G$ has a proper list
coloring; (2) Given a graph $G$, a clique modulator $D$ of size $k$ for $G$,
and a pre-coloring $\lambda_P: X \rightarrow Q$ for $X \subseteq V(G),$ decide
whether $\lambda_P$ can be extended to a proper coloring of $G$ using only
colors from $Q.$ For Problem 1 we design an $O^*(2^k)$-time randomized
algorithm and for Problem 2 we obtain a kernel with at most $3k$ vertices.
Banik et al. (IWOCA 2019) proved the the following problem is fixed-parameter
tractable and asked whether it admits a polynomial kernel: Given a graph $G$,
an integer $k$, and a list $L(v)$ of exactly $n-k$ colors for every $v \in
V(G),$ decide whether there is a proper list coloring for $G.$ We obtain a
kernel with $O(k^2)$ vertices and colors and a compression to a variation of
the problem with $O(k)$ vertices and $O(k^2)$ colors.
</p></div>
    </summary>
    <updated>2019-07-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.12034</id>
    <link href="http://arxiv.org/abs/1907.12034" rel="alternate" type="text/html"/>
    <title>Minimal Absent Words in Rooted and Unrooted Trees</title>
    <feedworld_mtime>1564444800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fici:Gabriele.html">Gabriele Fici</a>, Paweł Gawrychowski <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.12034">PDF</a><br/><b>Abstract: </b>We extend the theory of minimal absent words to (rooted and unrooted) trees,
having edges labeled by letters from an alphabet $\Sigma$ of cardinality
$\sigma$. We show that the set $\text{MAW}(T)$ of minimal absent words of a
rooted (resp. unrooted) tree $T$ with $n$ nodes has cardinality $O(n\sigma)$
(resp. $O(n^{2}\sigma)$), and we show that these bounds are realized. Then, we
exhibit algorithms to compute all minimal absent words in a rooted (resp.
unrooted) tree in output-sensitive time $O(n+|\text{MAW}(T)|)$ (resp.
$O(n^{2}+|\text{MAW}(T)|)$ assuming an integer alphabet of size polynomial in
$n$.
</p></div>
    </summary>
    <updated>2019-07-30T02:52:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.12028</id>
    <link href="http://arxiv.org/abs/1907.12028" rel="alternate" type="text/html"/>
    <title>Spartan: Sparse Robust Addressable Networks</title>
    <feedworld_mtime>1564444800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Augustine:John.html">John Augustine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sivasubramaniam:Sumathi.html">Sumathi Sivasubramaniam</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.12028">PDF</a><br/><b>Abstract: </b>We present an overlay design called Sparse Robust Addressable Network
(Spartan) that can tolerate heavy adversarial churn. We show that Spartan can
be built efficiently in a fully distributed manner within $O(\log n)$ rounds.
Furthermore, the Spartan overlay structure can be maintained, again, in a fully
distributed manner despite adversarially controlled churn (i.e., nodes joining
and leaving) and significant variation in the number of nodes. When the number
of nodes in the network lies in $[n, fn]$ for any fixed $f\ge 1$ the adversary
can remove up to $\epsilon n$ nodes and add up to $\epsilon n$ nodes (for some
small but fixed $\epsilon &gt; 0$) within {\em any} period of $P$ rounds for some
$P \in O(\log \log n)$. Moreover, the adversary can add or remove nodes from
the network at will and without any forewarning.
</p>
<p>Despite such uncertainty in the network, Spartan maintains $\Theta(n/\log n)$
committees that are stable and addressable collections of $\Theta(\log n)$
nodes each. Any node that enters the network will be able to gain membership in
one of these committees within $O(1)$ rounds. The committees are also capable
of performing sustained computation and passing messages between each other.
Thus, any protocol designed for static networks can be simulated on Spartan
with minimal overhead. This makes Spartan an ideal platform for developing
applications. All our results hold with high probability.
</p></div>
    </summary>
    <updated>2019-07-30T02:23:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11797</id>
    <link href="http://arxiv.org/abs/1907.11797" rel="alternate" type="text/html"/>
    <title>PingPong: Packet-Level Signatures for Smart Home Device Events</title>
    <feedworld_mtime>1564444800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Trimananda:Rahmadi.html">Rahmadi Trimananda</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Varmarken:Janus.html">Janus Varmarken</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Markopoulou:Athina.html">Athina Markopoulou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demsky:Brian.html">Brian Demsky</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11797">PDF</a><br/><b>Abstract: </b>Smart home devices are vulnerable to passive inference attacks based on
network traffic, even in the presence of encryption. In this paper, we present
PingPong, a tool that can automatically extract packet-level signatures (i.e.,
simple sequences of packet lengths and directions) from the network traffic of
smart home devices, and use those signatures to detect occurrences of specific
device events (e.g., light bulb turning ON/OFF). We evaluated PingPong on
popular smart home devices ranging from smart plugs to thermostats and home
security systems. We have successfully: (1) extracted packet-level signatures
from 18 devices (11 of which are the most popular smart home devices on Amazon)
from 15 popular vendors, (2) used those signatures to detect occurrences of
specific device events with an average recall of more than 97%, and (3) shown
that the signatures are unique among tens of millions of packets of real world
network traffic.
</p></div>
    </summary>
    <updated>2019-07-30T02:56:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11705</id>
    <link href="http://arxiv.org/abs/1907.11705" rel="alternate" type="text/html"/>
    <title>Low-Rank Matrix Completion: A Contemporary Survey</title>
    <feedworld_mtime>1564444800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nguyen:Luong_Trung.html">Luong Trung Nguyen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kim:Junhan.html">Junhan Kim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shim:Byonghyo.html">Byonghyo Shim</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11705">PDF</a><br/><b>Abstract: </b>As a paradigm to recover unknown entries of a matrix from partial
observations, low-rank matrix completion (LRMC) has generated a great deal of
interest. Over the years, there have been lots of works on this topic but it
might not be easy to grasp the essential knowledge from these studies. This is
mainly because many of these works are highly theoretical or a proposal of new
LRMC technique. In this paper, we give a contemporary survey on LRMC. In order
to provide better view, insight, and understanding of potentials and
limitations of LRMC, we present early scattered results in a structured and
accessible way. Specifically, we classify the state-of-the-art LRMC techniques
into two main categories and then explain each category in detail. We next
discuss issues to be considered when one considers using LRMC techniques. These
include intrinsic properties required for the matrix recovery and how to
exploit a special structure in LRMC design. We also discuss the convolutional
neural network (CNN) based LRMC algorithms exploiting the graph structure of a
low-rank matrix. Further, we present the recovery performance and the
computational complexity of the state-of-the-art LRMC techniques. Our hope is
that this survey article will serve as a useful guide for practitioners and
non-experts to catch the gist of LRMC.
</p></div>
    </summary>
    <updated>2019-07-30T02:22:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/07/29/zipless-polycube</id>
    <link href="https://11011110.github.io/blog/2019/07/29/zipless-polycube.html" rel="alternate" type="text/html"/>
    <title>A zipless polycube</title>
    <summary>My latest arXiv preprint is “Some polycubes have no edge-unzipping” (arXiv:1907.08433, with Erik and Marty Demaine and Joe O’Rourke). It’s about polyhedral unfolding, the problem of cutting a polyhedron along some of its edges into a surface that unfolds into a flat polygon in the plane (a “net”). Although it dates back to the work of Albrecht Dürer, we still don’t know a lot about this problem, in general. We don’t know whether every convex polyhedron has an unfolding, and we don’t know whether every polycube has a folding (allowing cuts in the middle of flat faces as long as they are on boundary edges of the cubes making up the polycube).</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>My latest arXiv preprint is “Some polycubes have no edge-unzipping” (<a href="https://arxiv.org/abs/1907.08433">arXiv:1907.08433</a>, with Erik and Marty Demaine and Joe O’Rourke). It’s about <a href="https://en.wikipedia.org/wiki/Net_(polyhedron)">polyhedral unfolding</a>, the problem of cutting a polyhedron along some of its edges into a surface that unfolds into a flat polygon in the plane (a “net”). Although it dates back to the work of Albrecht Dürer, we still don’t know a lot about this problem, in general. We don’t know whether every convex polyhedron has an unfolding, and we don’t know whether every polycube has a folding (allowing cuts in the middle of flat faces as long as they are on boundary edges of the cubes making up the polycube).</p>

<p>The preprint is about a variation of unfolding in which the cut has to form a path through the graph of vertices and edges. If the polyhedron has the topology of a sphere and there are no flat vertices (with a full  total angle of surrounding faces) then all vertices must be touched by a cut, and it’s the same thing to ask for an unfolding that forms a Hamiltonian path. These zipper-unfoldings have previously been studied, notably in joint work by two parent-child groups, <a href="https://11011110.github.io/blog/2010/08/12/more-from-cccg.html">Marty and his son Erik, and Anna Lubiw and her two sons Arlo and Jonah from CCCG 2010</a>. The new preprint shows that they don’t always exist for (topologically spherical) polycubes. In particular, the following shape has no flat vertices, but its graph is bipartite and unbalanced enough that it also has no Hamiltonian path.</p>

<p style="text-align: center;"><img alt="A zipless polycube" src="https://11011110.github.io/blog/assets/2019/zipless.png"/></p>

<p>It does have an unfolding, though (figure made by Erik using <a href="https://github.com/amandaghassaei/OrigamiSimulator">OrigamiSimulator</a>):</p>

<p style="text-align: center;"><img alt="Unfolding a zipless polycube" src="https://11011110.github.io/blog/assets/2019/zipless.gif"/></p>

<p>The paper also has a smaller example that’s a little tricker to prove zipless. It’s a small enough advance that we probably won’t bother trying to turn it into a conference or journal paper. (If it were just me, I’d probably have just made a blog post about it. And here we are!)</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102528987575312068">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-07-29T23:11:00Z</updated>
    <published>2019-07-29T23:11:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-07-30T06:31:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/099</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/099" rel="alternate" type="text/html"/>
    <title>TR19-099 |  Nearly Optimal Pseudorandomness From Hardness | 

	Dean Doron, 

	David Zuckerman, 

	Dana Moshkovitz, 

	Justin Oh</title>
    <summary>Existing proofs that deduce $\mathbf{BPP}=\mathbf{P}$ from circuit lower bounds convert randomized algorithms into deterministic algorithms with a large polynomial slowdown. We convert randomized algorithms into deterministic ones with little slowdown. Specifically, assuming exponential lower bounds against nondeterministic circuits, we convert any randomized algorithm over inputs of length $n$ running in time $t \ge n$ to a deterministic one running in time $t^{2+\alpha}$ for an arbitrarily small constant $\alpha &gt; 0$. Such a slowdown is nearly optimal, as, under complexity-theoretic assumptions, there are problems with an inherent quadratic derandomization slowdown. We also convert any randomized algorithm that errs rarely into a deterministic algorithm having a similar running time (with pre-processing).

Our results follow from a new, nearly optimal, explicit pseudorandom generator fooling circuits of size $s$ with seed length $(1+\alpha)\log s$, under the assumption that there exists a function $f \in \mathbf{E}$ that requires nondeterministic circuits of size at least $2^{(1-\alpha')n}$, where $\alpha = O(\alpha')$. The construction uses, among other ideas, a new connection between pseudoentropy generators and locally list recoverable codes.</summary>
    <updated>2019-07-29T19:55:04Z</updated>
    <published>2019-07-29T19:55:04Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-30T12:20:42Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5104220537083628124</id>
    <link href="https://blog.computationalcomplexity.org/feeds/5104220537083628124/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/turing-to-be-on-bank-of-england-50.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5104220537083628124" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/5104220537083628124" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/07/turing-to-be-on-bank-of-england-50.html" rel="alternate" type="text/html"/>
    <title>Turing to be on the Bank of England 50 pound note, giving me an excuse to talk about Turing</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">BILL: Darling, guess who is soon going to be on the Bank of England 50 pound note?<br/>
<br/>
DARLING: Alan Turing. <br/>
<br/>
BILL: How did you deduce that? (She is right, see  <a href="https://www.bbc.com/news/business-48962557">here</a>.)<br/>
<br/>
DARLING: Since you asked it, it couldn't be a member of the Royal Family (you don't care about that) or some British Politician (you don't care about that either). It had to be a mathematician or computer scientist.<br/>
<br/>
BILL: It could have been Hardy. I wonder if Ramanujan could qualify---do they need to be British? At <a href="https://www.bankofengland.co.uk/banknotes/banknote-characters">this website</a> it says<br/>
<br/>
<br/>
<br/>
<i>Of course, banknotes need to be universally accepted. We therefore look for UK characters who have made an important contribution to our society and culture through their innovation, leadership or values. We do not include fictional characters, or people who are still living (except the monarch on the front of the note). Finally, we need to have a suitable portrait of the person which will be easy to recognise.</i><br/>
<br/>
(They spell <i>recognise</i> with an s instead of a z, so spellcheck flagged it, but I won't change it.) <br/>
<br/>
Note that people on the banknotes have to be <i>UK characters</i>. I honestly don't know if that means they must be citizens.<br/>
<br/>
OKAY, so here are a few thoughts on Turing.<br/>
<br/>
1) When I visited Bletchley Park there was a booklet that bragged about the fact that Bletchley Park was much better at cracking codes than Germany because  they allowed people to work there based only on ability (unlike Germany) - women worked there, Turing who was Gay worked there. I think this is simplistic. Did any Jews work there (anti-semitism was widespread in England, and the world, at the time)? I doubt any blacks worked there since if they did that would be well known by now (if I am wrong let me know). Women DID work there but was their work respected and used? (I honestly don't know). Did Germany also use women at their codebreaking centers? Was Turing known to be gay (if not then Bletchley gets no points for tolerating him). Was JUST having Turing the reason they could crack codes. Plus I am sure there were other factors aside from merit-only.<br/>
<br/>
2) Turing was given a Pardon for his ``crimes'' in August 2014. When I see things like this I wonder who was against it and why and if they were an obstacle.<br/>
<br/>
a) Human Rights Advocate Peter Tatchell noted that its wrong to just single out Turing. Other people prosecuted under that law who did not help beat the German's in WW II should also be pardoned. The government later DID such a pardon in 2017.<br/>
<br/>
b) Judge Minister Lord McNally objected to the pardon:<br/>
<br/>
<i>A posthumous pardon was not considered appropriate as Alan Turing was properly convicted of what at the time was a criminal offence. He would have known that his offence was against the law and that he would be prosecuted. It is tragic that Alan Turing was convicted of an offence that now seems both cruel and absurd—particularly poignant given his outstanding contribution to the war effort. However, the law at the time required a prosecution and, as such, long-standing policy has been to accept that such convictions took place and, rather than trying to alter the historical context and to put right what cannot be put right, ensure instead that we never again return to those times.<br/>
</i><br/>
<br/>
While I disagree with him, I do note that, based on what he wrote and his general record, I think he is not saying this from being anti-gay.  There is  a hard general question here: how does a society right past wrongs? I think pardoning and apologizing is certainly fine, but frankly it seems to weak. What else could a society due? Financial renumeration to living relatives? I don't think giving Inagh Payne (Turing's niece, who I think is still alive) would really help here.<br/>
<br/>
c) <i>At the bill's second reading in the House of Commons on 29 November 2013, Conservative MP Christopher Chope objected to the bill, delaying its passage<br/>
</i><br/>
<br/>
I couldn't find Chope's reasons. On the one hand, they may be similar to McNally's. On the other hand he is against same sex marriage so its possible (though I do not know this) that he anti-gay and that is why he is against the pardon. If someone can find what his explanation for blocking the Turing bill is, or other evidence that he is anti-gay, please leave it in the comments.<br/>
<br/>
3) Did the delay matter? I was surprised to find out---Yes. Here is the full passage from Wikipedia:<br/>
<br/>
<br/>
<i>At the bill's second reading in the House of Commons on 29 November 2013, Conservative MP Christopher Chope objected to the bill, delaying its passage. The bill was due to return to the House of Commons on 28 February 2014,[175] but before the bill could be debated in the House of Commons,[176] the government elected to proceed under the royal prerogative of mercy. On 24 December 2013, Queen Elizabeth II signed a pardon for Turing's conviction for "gross indecency", with immediate effect.[17] Announcing the pardon, Lord Chancellor Chris Grayling said Turing deserved to be "remembered and recognised for his fantastic contribution to the war effort" and not for his later criminal conviction.[16][18] The Queen officially pronounced Turing pardoned in August 2014.[177] The Queen's action is only the fourth royal pardon granted since the conclusion of the Second World War.[178] Pardons are normally granted only when the person is technically innocent, and a request has been made by the family or other interested party; neither condition was met in regard to Turing's conviction.[179]</i><br/>
<br/>
This amazed me! I thought the Queen had NO power (too bad--- I wish she could just say NO BREXIT). Or that she formally has power but if she ever used it, it might be blocked somehow and  taken away. So I am surprised she has a power she can use at all.<br/>
<br/>
4) I wonder if the Pardon had to happen before they put him on the Banknote. I have been told that this is a very American Question--- England has no Constitution and operates more on Custom and Tradition than on written rules. <br/>
<br/>
5) I had always assumed that Turing committed suicide. Without going into detail, the Wikipedia site on Turing does give intelligent counterarguments to this. See <a href="https://en.wikipedia.org/wiki/Alan_Turing#Death">here</a><br/></div>
    </content>
    <updated>2019-07-29T00:46:00Z</updated>
    <published>2019-07-29T00:46:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2019-07-30T11:53:52Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11686</id>
    <link href="http://arxiv.org/abs/1907.11686" rel="alternate" type="text/html"/>
    <title>A Tight Degree 4 Sum-of-Squares Lower Bound for the Sherrington-Kirkpatrick Hamiltonian</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kunisky:Dmitriy.html">Dmitriy Kunisky</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bandeira:Afonso_S=.html">Afonso S. Bandeira</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11686">PDF</a><br/><b>Abstract: </b>We show that, if $\mathbf{W} \in \mathbb{R}^{N \times N}_{\mathsf{sym}}$ is
drawn from the gaussian orthogonal ensemble, then with high probability the
degree 4 sum-of-squares relaxation cannot certify an upper bound on the
objective $N^{-1} \cdot \mathbf{x}^\top \mathbf{W} \mathbf{x}$ under the
constraints $x_i^2 - 1 = 0$ (i.e. $\mathbf{x} \in \{ \pm 1 \}^N$) that is
asymptotically smaller than $\lambda_{\max}(\mathbf{W}) \approx 2$. We also
conjecture a proof technique for lower bounds against sum-of-squares
relaxations of any degree held constant as $N \to \infty$, by proposing an
approximate pseudomoment construction.
</p></div>
    </summary>
    <updated>2019-07-29T01:25:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11669</id>
    <link href="http://arxiv.org/abs/1907.11669" rel="alternate" type="text/html"/>
    <title>Subtour Elimination Constraints Imply a Matrix-Tree Theorem SDP Constraint for the TSP</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gutekunst:Samuel_C=.html">Samuel C. Gutekunst</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Williamson:David_P=.html">David P. Williamson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11669">PDF</a><br/><b>Abstract: </b>De Klerk, Pasechnik, and Sotirov give a semidefinite programming constraint
for the Traveling Salesman Problem (TSP) based on the matrix-tree Theorem. This
constraint says that the aggregate weight of all spanning trees in a solution
to a TSP relaxation is at least that of a cycle graph. In this note, we show
that the semidefinite constraint holds for any weighted 2-edge-connected graph
and, in particular, is implied by the subtour elimination constraints of the
subtour elimination linear program. Hence, this semidefinite constraint is
implied by a finite set of linear inequality constraints.
</p></div>
    </summary>
    <updated>2019-07-29T01:25:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11662</id>
    <link href="http://arxiv.org/abs/1907.11662" rel="alternate" type="text/html"/>
    <title>Adventures in Abstraction: Reachability in Hierarchical Drawings</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lionakis:Panagiotis.html">Panagiotis Lionakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ortali:Giacomo.html">Giacomo Ortali</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tollis:Ioannis_G=.html">Ioannis G. Tollis</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11662">PDF</a><br/><b>Abstract: </b>We present algorithms and experiments for the visualization of directed
graphs that focus on displaying their reachability information. Our algorithms
are based on the concepts of the path and channel decomposition as proposed in
the framework presented in GD 2018 (pp. 579-592) and focus on showing the
existence of paths clearly. In this paper we customize these concepts and
present experimental results that clearly show the interplay between bends,
crossings and clarity. Additionally, our algorithms have direct applications to
the important problem of showing and storing transitivity information of very
large graphs and databases. Only a subset of the edges is drawn, thus reducing
the visual complexity of the resulting drawing, and the memory requirements for
storing the transitivity information. Our algorithms require almost linear
time, $O(kn+m)$, where $k$ is the number of paths/channels, $n$ and $m$ is the
number of vertices and edges, respectively. They produce progressively more
abstract drawings of the input graph. No dummy vertices are introduced and the
vertices of each path/channel are vertically aligned.
</p></div>
    </summary>
    <updated>2019-07-29T01:26:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11636</id>
    <link href="http://arxiv.org/abs/1907.11636" rel="alternate" type="text/html"/>
    <title>Notes on Computational Hardness of Hypothesis Testing: Predictions using the Low-Degree Likelihood Ratio</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kunisky:Dmitriy.html">Dmitriy Kunisky</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wein:Alexander_S=.html">Alexander S. Wein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bandeira:Afonso_S=.html">Afonso S. Bandeira</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11636">PDF</a><br/><b>Abstract: </b>These notes survey and explore an emerging method, which we call the
low-degree method, for predicting and understanding
statistical-versus-computational tradeoffs in high-dimensional inference
problems. In short, the method posits that a certain quantity -- the second
moment of the low-degree likelihood ratio -- gives insight into how much
computational time is required to solve a given hypothesis testing problem,
which can in turn be used to predict the computational hardness of a variety of
statistical inference tasks. While this method originated in the study of the
sum-of-squares (SoS) hierarchy of convex programs, we present a self-contained
introduction that does not require knowledge of SoS. In addition to showing how
to carry out predictions using the method, we include a discussion
investigating both rigorous and conjectural consequences of these predictions.
</p>
<p>These notes include some new results, simplified proofs, and refined
conjectures. For instance, we point out a formal connection between spectral
methods and the low-degree likelihood ratio, and we give a sharp low-degree
lower bound against subexponential-time algorithms for tensor PCA.
</p></div>
    </summary>
    <updated>2019-07-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11635</id>
    <link href="http://arxiv.org/abs/1907.11635" rel="alternate" type="text/html"/>
    <title>Subexponential-Time Algorithms for Sparse PCA</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Yunzi Ding, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kunisky:Dmitriy.html">Dmitriy Kunisky</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wein:Alexander_S=.html">Alexander S. Wein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bandeira:Afonso_S=.html">Afonso S. Bandeira</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11635">PDF</a><br/><b>Abstract: </b>We study the computational cost of recovering a unit-norm sparse principal
component $x \in \mathbb{R}^n$ planted in a random matrix, in either the Wigner
or Wishart spiked model (observing either $W + \lambda xx^\top$ with $W$ drawn
from the Gaussian orthogonal ensemble, or $N$ independent samples from
$\mathcal{N}(0, I_n + \beta xx^\top)$, respectively). Prior work has shown that
when the signal-to-noise ratio ($\lambda$ or $\beta\sqrt{N/n}$, respectively)
is a small constant and the fraction of nonzero entries in the planted vector
is $\|x\|_0 / n = \rho$, it is possible to recover $x$ in polynomial time if
$\rho \lesssim 1/\sqrt{n}$. While it is possible to recover $x$ in exponential
time under the weaker condition $\rho \ll 1$, it is believed that
polynomial-time recovery is impossible unless $\rho \lesssim 1/\sqrt{n}$. We
investigate the precise amount of time required for recovery in the "possible
but hard" regime $1/\sqrt{n} \ll \rho \ll 1$ by exploring the power of
subexponential-time algorithms, i.e., algorithms running in time
$\exp(n^\delta)$ for some constant $\delta \in (0,1)$. For any $1/\sqrt{n} \ll
\rho \ll 1$, we give a recovery algorithm with runtime roughly $\exp(\rho^2
n)$, demonstrating a smooth tradeoff between sparsity and runtime. Our family
of algorithms interpolates smoothly between two existing algorithms: the
polynomial-time diagonal thresholding algorithm and the $\exp(\rho n)$-time
exhaustive search algorithm. Furthermore, by analyzing the low-degree
likelihood ratio, we give rigorous evidence suggesting that the tradeoff
achieved by our algorithms is optimal.
</p></div>
    </summary>
    <updated>2019-07-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11632</id>
    <link href="http://arxiv.org/abs/1907.11632" rel="alternate" type="text/html"/>
    <title>On maximal isolation sets in the uniform intersection matrix</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parnas:Michal.html">Michal Parnas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shraibman:Adi.html">Adi Shraibman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11632">PDF</a><br/><b>Abstract: </b>Let $A_{k,t}$ be the matrix that represents the adjacency matrix of the
intersection bipartite graph of all subsets of size $t$ of $\{1,2,...,k\}$. We
give constructions of large isolation sets in $A_{k,t}$, where, for a large
enough $k$, our constructions are the best possible.
</p>
<p>We first prove that the largest identity submatrix in $A_{k,t}$ is of size
$k-2t+2$. Then we provide constructions of isolations sets in $A_{k,t}$ for any
$t\geq 2$, as follows: \begin{itemize} \item If $k = 2t+r$ and $0 \leq r \leq
2t-3$, there exists an isolation set of size $2r+3 = 2k-4t+3$. \item If $k \geq
4t-3$, there exists an isolation set of size $k$. \end{itemize} The
construction is maximal for $k\geq 4t-3$, since the Boolean rank of $A_{k,t}$
is $k$ in this case. As we prove, the construction is maximal also for $k = 2t,
2t+1$.
</p>
<p>Finally, we consider the problem of the maximal triangular isolation
submatrix of $A_{k,t}$ that has ones in every entry on the main diagonal and
below it, and zeros elsewhere. We give an optimal construction of such a
submatrix of size $({2t \choose t}-1) \times ({2t \choose t}-1)$, for any $t
\geq 1$ and a large enough $k$. This construction is tight, as there is a
matching upper bound, which can be derived from a theorem of Frankl about skew
matrices.
</p></div>
    </summary>
    <updated>2019-07-29T01:21:03Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11525</id>
    <link href="http://arxiv.org/abs/1907.11525" rel="alternate" type="text/html"/>
    <title>Rational Motions with Generic Trajectories of Low Degree</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Johannes Siegele, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scharler:Daniel_F=.html">Daniel F. Scharler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schr=ouml=cker:Hans=Peter.html">Hans-Peter Schröcker</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11525">PDF</a><br/><b>Abstract: </b>The trajectories of a rational motion given by a polynomial of degree n in
the dual quaternion model of rigid body displacements are generically of degree
2n. In this article we study those exceptional motions whose trajectory degree
is lower. An algebraic criterion for this drop of degree is existence of
certain right factors, a geometric criterion involves one of two families of
rulings on an invariant quadric. Our characterizations allow the systematic
construction of rational motions with exceptional degree reduction and explain
why the trajectory degrees of a rational motion and its inverse motion can be
different.
</p></div>
    </summary>
    <updated>2019-07-29T01:27:56Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11422</id>
    <link href="http://arxiv.org/abs/1907.11422" rel="alternate" type="text/html"/>
    <title>Almost Shortest Paths and PRAM Distance Oracles in Weighted Graphs</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Elkin:Michael.html">Michael Elkin</a>, Yuval Gitlitz, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Neiman:Ofer.html">Ofer Neiman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11422">PDF</a><br/><b>Abstract: </b>Let $G=(V,E)$ be a weighted undirected graph with $n$ vertices and $m$ edges,
and fix a set of $s$ sources $S\subseteq V$. For any pair $u,v\in V$, let
$W(u,v)$ denote the weight of the heaviest edge on the $u$ to $v$ shortest
path. For any constant $0&lt;\epsilon&lt;1$, we compute
$(1+\epsilon,\beta(\cdot,\cdot))$-approximate shortest paths from all sources
in $S$ in near linear (in $m+ns$) time, where $\beta(u,v)=O(W(u,v))$. That is,
the multiplicative stretch is $1+\epsilon$, and the additive stretch for any
$u\in S$, $v\in V$ is $\beta(u,v)$. Previous results of this type were only
able to compute distance estimates and not paths, and had far inferior additive
terms. We also introduce distance oracles for parallel models of computation
(PRAM). Specifically, for any parameter $\delta&gt;0$, we preprocess a given
weighted graph in poly-logarithmic time and near linear work, and store a data
structure of size $O(n^{1+\delta})$. Given any query $u\in V$, we return a
$(1+\epsilon,\beta(\cdot,\cdot))$-approximation to all distances $u\times V$ in
$O_\delta(1)$ time, where $\beta(u,v)=O_\delta(W(u,v))$. Moreover, the
dependence of both $\beta$ and the query time on $\delta$ can be made
$\text{poly}(1/\delta)$, by increasing the multiplicative stretch (to some
constant larger than 9). Our algorithms are based on new constructions of
spanners, emulators and hopsets for weighted graphs. We devise a
$(1+\epsilon,\beta(\cdot,\cdot))$-spanner for weighted graphs of size
$O(n^{1+1/t}+\log t\cdot n)$ and $\beta(u,v)=W(u,v)\cdot \left(\frac{\log
t}{\epsilon}\right)^{O(\log t)}$. We can have an improved $\beta=W(u,v)\cdot
t^{O(1)}$ at the cost of increasing the multiplicative stretch to a constant
larger than 3. In addition, we devise a $(c,t^{O(1)})$-hopset of size
$O(n^{1+1/t}+\log t\cdot n)$ for any constant $c&gt;3$.
</p></div>
    </summary>
    <updated>2019-07-29T01:22:39Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11416</id>
    <link href="http://arxiv.org/abs/1907.11416" rel="alternate" type="text/html"/>
    <title>Generalized Liar's Dominating Set in Graphs</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jena:Sangram_K=.html">Sangram K. Jena</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jallu:Ramesh_K=.html">Ramesh K. Jallu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Das:Gautam_K=.html">Gautam K. Das</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11416">PDF</a><br/><b>Abstract: </b>In this article, we study generalized liar's dominating set problem in
graphs. Let $G=(V,E)$ be a simple undirected graph. The generalized liar's
dominating set, called as the distance-$d$ $(m,\ell)$-liar's dominating set, is
a subset $L\subseteq V$ such that (i) each vertex in $V$ is distance-$d$
dominated by at least $m$ vertices in $L$, and (ii) each pair of distinct
vertices in $V$ is distance-$d$ dominated by at least $\ell$ vertices in $L$,
where $m,\ell,d$ are positive integers and $m &lt; \ell$. Here, a vertex $v$ is
distance-$d$ dominated by another vertex $u$ means the shortest path distance
between $u$ and $v$ is at most $d$ in $G$.
</p>
<p>We first consider distance-1 $(m,\ell)$-liar's dominating set problem and
prove that it is NP-complete. Next, we consider distance-$d$ $(m,\ell)$-liar's
dominating set problem and show that it is also NP-complete. These liar's
dominating set problems are generalized version of liar's dominating set
problem as researcher studied only distance-$1$ $(2,3)$-liar's dominating set
problem in literature. We also prove that (i) distance-1 $(m,\ell)$-liar's
dominating set problem cannot be approximated within a factor of $(\frac{1}{2}-
\varepsilon)\ln |V|$ for any $\varepsilon&gt;0$, unless NP $\subseteq$
DTIME$(|V|^{O(\log\log|V|)})$, and (ii) distance-$d$ $(m,\ell)$-liar's
dominating set problem cannot be approximated within a factor of $(\frac{1}{4}-
\varepsilon)\ln |V|$ for any $\varepsilon&gt;0$, unless NP $\subseteq$
DTIME$(|V|^{O(\log\log|V|)})$.
</p></div>
    </summary>
    <updated>2019-07-29T01:21:41Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11404</id>
    <link href="http://arxiv.org/abs/1907.11404" rel="alternate" type="text/html"/>
    <title>Tight Approximation for Variants of Directed Steiner Tree via State-Tree Decomposition and Linear Programming Rounding</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Xiangyu.html">Xiangyu Guo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Laekhanukit:Bundit.html">Bundit Laekhanukit</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Shi.html">Shi Li</a>, Jiayi Xian <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11404">PDF</a><br/><b>Abstract: </b>Directed Steiner Tree (DST) is a central problem in combinatorial
optimization and theoretical computer science. Recently, Grandoni, Laekhanukit
and Li and independently Ghuge and Nagarajan gave quasi-polynomial time
$O(\log^2k/\log \log k)$-approximation algorithms for the problem, which is
tight under popular complexity assumptions.
</p>
<p>In this paper, we show a general framework that achieves $O(\log n \log
k)$-approximation for many variants of DST. We show that if the problem has the
property that the validity of the tree and its cost can be checked and computed
using a bottom-to-top procedure, then the general framework can be used to
produce a small-cost {multi-tree}: a tree that may contain multiple copies of a
vertex or an edge.
</p>
<p>Using the framework, we show that two prominent variants of DST, namely
Length-Bounded DST (LB-DST) and Buy-at-Bulk DST with Concave Cost Functions
(BaB-DST-Concave), admit $O(\log n \log k)$-approximation algorithms. In the
Length-Bounded Directed Steiner Tree (LB-DST) problem, there are bounds on
lengths of paths from the root to vertices in the output tree. In the
Buy-at-Bulk DST problem with Concave Functions (BaB-DST-Concave), each terminal
needs to receive a flow from the root and the cost of each edge is a concave
function on the total amount of flow that it carries. Our results almost match
the best known $O(\log ^2k/\log \log k)$ algorithm that have recently been
discovered by Ghuge and Nagarajan.
</p>
<p>Another variant that fits into the framework is the Degree-Bounded DST
(DB-DST) problem. In this problem, we are additionally given a degree bound
$d_v$ on each vertex $v \in V$, which imposes the constraint that $v$ is
allowed to have at most $d_v$ children in the output tree. In this case, our
framework gives an $O(\log^3n \log k, \log n\log k)$-bicritiera approximation,
which is the first non-trivial result for the problem.
</p></div>
    </summary>
    <updated>2019-07-29T01:24:16Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11402</id>
    <link href="http://arxiv.org/abs/1907.11402" rel="alternate" type="text/html"/>
    <title>New $(\alpha,\beta)$ Spanners and Hopsets</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Uri Ben-Levy, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parter:Merav.html">Merav Parter</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11402">PDF</a><br/><b>Abstract: </b>An $f(d)$-spanner of an unweighted $n$-vertex graph $G=(V,E)$ is a subgraph
$H$ satisfying that $dist_H(u, v)$ is at most $f(dist_G(u, v))$ for every $u,v
\in V$. We present new spanner constructions that achieve a nearly optimal
stretch of $O(\lceil k /d \rceil)$ for any distance value $d \in
[1,k^{1-o(1)}]$, and $d \geq k^{1+o(1)}$. We show the following:
</p>
<p>1. There exists an $f(d)$-spanner $H \subseteq G$ with $f(d)\leq 7k$ for any
$d \in [1,\sqrt{k}/2]$ with expected size $O_{k}(n^{1+1/k})$. This in
particular gives $(\alpha,\beta)$ spanners with $\alpha=O(\sqrt{k})$ and
$\beta=O(k)$.
</p>
<p>2. For any $\epsilon \in (0,1/2]$, there exists an $(\alpha,\beta)$-spanner
with $\alpha=O(k^{\epsilon})$, $\beta=O_{\epsilon}(k)$ and of expected size
$O_{k}(n^{1+1/k})$. This implies a stretch of $O(\lceil k/d \rceil)$ for any $d
\in [\sqrt{k}/2, k^{1-\epsilon}]$, and for every $d\geq k^{1+\epsilon}$. In
particular, it provides a constant stretch already for vertex pairs at distance
$k^{1+o(1)}$ (improving upon $d=(\log k)^{\log k}$ that was known before). Up
to the $o(1)$ factor in the exponent, and the constant factor in the stretch,
this is the best possible by the girth argument.
</p>
<p>3. For any $\epsilon \in (0,1)$, there is a $(3+\epsilon, \beta)$-spanner
with $\beta=O_{\epsilon}(k^{\log(3+8/\epsilon)})$.
</p>
<p>We also consider the related graph concept of hopsets introduced by [Cohen,
J. ACM '00]. We present a new family of $(\alpha,\beta)$ hopsets with
$\widetilde{O}(k \cdot n^{1+1/k})$ edges and $\alpha \cdot \beta=O(k)$. Most
notably, we show a construction of $(3+\epsilon,\beta)$ hopset with
$\widetilde{O}_{\epsilon}(n)$ edges and hop-bound of $\beta=O_{\epsilon}((\log
n)^{\log(3+9/\epsilon)})$, improving upon the state-of-the-art hop-bound of
$\beta=O(\log\log n)^{\log \log n}$ by [Elkin-Neiman, '17] and [Huang-Pettie,
'17]
</p></div>
    </summary>
    <updated>2019-07-29T01:25:08Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11368</id>
    <link href="http://arxiv.org/abs/1907.11368" rel="alternate" type="text/html"/>
    <title>On the relationships between Z-, C-, and H-local unitaries</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cook:Jeremy.html">Jeremy Cook</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11368">PDF</a><br/><b>Abstract: </b>Quantum walk algorithms can speed up search of physical regions of space in
both the discrete-time [<a href="http://export.arxiv.org/abs/quant-ph/0402107">arXiv:quant-ph/0402107</a>] and continuous-time setting
[<a href="http://export.arxiv.org/abs/quant-ph/0306054">arXiv:quant-ph/0306054</a>], where the physical region of space being searched is
modeled as a connected graph. In such a model, Aaronson and Ambainis
[<a href="http://export.arxiv.org/abs/quant-ph/0303041">arXiv:quant-ph/0303041</a>] provide three different criteria for a unitary matrix
to act locally with respect to a graph, called $Z$-local, $C$-local, and
$H$-local unitaries, and left the open question of relating these three
locality criteria. Using a correspondence between continuous- and discrete-time
quantum walks by Childs [<a href="http://export.arxiv.org/abs/0810.0312">arXiv:0810.0312</a>], we provide a way to approximate
$N\times N$ $H$-local unitaries with error $\delta$ using
$O(1/\sqrt{\delta},\sqrt{N})$ $C$-local unitaries, where the comma denotes the
maximum of the two terms.
</p></div>
    </summary>
    <updated>2019-07-29T01:20:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11232</id>
    <link href="http://arxiv.org/abs/1907.11232" rel="alternate" type="text/html"/>
    <title>Exhaustive Exact String Matching: The Analysis of the Full Human Genome</title>
    <feedworld_mtime>1564358400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xylogiannopoulos:Konstantinos_F=.html">Konstantinos F. Xylogiannopoulos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11232">PDF</a><br/><b>Abstract: </b>Exact string matching has been a fundamental problem in computer science for
decades because of many practical applications. Some are related to common
procedures, such as searching in files and text editors, or, more recently, to
more advanced problems such as pattern detection in Artificial Intelligence and
Bioinformatics. Tens of algorithms and methodologies have been developed for
pattern matching and several programming languages, packages, applications and
online systems exist that can perform exact string matching in biological
sequences. These techniques, however, are limited to searching for specific and
predefined strings in a sequence. In this paper a novel methodology (called
Ex2SM) is presented, which is a pipeline of execution of advanced data
structures and algorithms, explicitly designed for text mining, that can detect
every possible repeated string in multivariate biological sequences. In
contrast to known algorithms in literature, the methodology presented here is
string agnostic, i.e., it does not require an input string to search for it,
rather it can detect every string that exists at least twice, regardless of its
attributes such as length, frequency, alphabet, overlapping etc. The complexity
of the problem solved and the potential of the proposed methodology is
demonstrated with the experimental analysis performed on the entire human
genome. More specifically, all repeated strings with a length of up to 50
characters have been detected, an achievement which is practically impossible
using other algorithms due to the exponential number of possible permutations
of such long strings.
</p></div>
    </summary>
    <updated>2019-07-29T01:22:07Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2019/07/28/any-order-puzzle</id>
    <link href="https://11011110.github.io/blog/2019/07/28/any-order-puzzle.html" rel="alternate" type="text/html"/>
    <title>Any-order puzzle deduction</title>
    <summary>I recently wrote here about a complication in puzzle-solving where, in using deductive rules based on the assumption that the puzzle has a unique solution, the ordering of the rules could make a difference in how far you get in the solution. And avoiding this ordering issue by keeping track of more information than just the state of the partially solved puzzle leads to its own difficulties. It seemed like keeping this information could lose you in a maze of undecidable modal logic. For instance in the map coloring puzzle described in that post, we might record information about a partial solution like “I don’t know that this cell is forced to be red, but it is necessary for it to be red in order to prevent a non-unique solution”, with the complexity of these statements growing as the solution progressed. Instead, what I wanted was a way to make decisions without worrying about the order of deduction while only remembering a finite amount of state for each puzzle cell. In the ensuing discussion, @axiom suggested that the extra information should be the order of deductions. That’s not a constant amount of information per cell, but as we’ll see below it works to simplify this even more and remember only which cells were the initial givens and which were deduced later.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I recently wrote here about a complication in puzzle-solving where, in using deductive rules based on the assumption that the puzzle has a unique solution, <a href="https://11011110.github.io/blog/2019/06/07/little-knowledge-can.html">the ordering of the rules could make a difference in how far you get in the solution</a>. And avoiding this ordering issue by keeping track of more information than just the state of the partially solved puzzle leads to its own difficulties. It seemed like keeping this information could lose you in a maze of undecidable <a href="https://11011110.github.io/blog/2019/07/13/connectivity-finiteness-modal.html">modal logic</a>. For instance in the map coloring puzzle described in that post, we might record information about a partial solution like “I don’t know that this cell is forced to be red, but it is necessary for it to be red in order to prevent a non-unique solution”, with the complexity of these statements growing as the solution progressed. Instead, what I wanted was a way to make decisions without worrying about the order of deduction while only remembering a finite amount of state for each puzzle cell. In <a href="https://mathstodon.xyz/@11011110/102234384857906663">the ensuing discussion</a>, @axiom suggested that the extra information should be the order of deductions.
That’s not a constant amount of information per cell, but as we’ll see below it works to simplify this even more and remember only which cells were the initial givens and which were deduced later.</p>

<p>To clarify the intuition that deduction order should not matter, I want to formalize the state of a partially-solved puzzle as a collection of bits, initially all true. In map coloring, each bit could represent the possibility that a given cell is a particular color, and we want to eventually have one true bit per cell and the rest false. A deduction is a change to a single bit. Each deduction is triggered by a rule, which typically searches for certain patterns in the state. For instance, in map coloring, the pattern that one cell has only one remaining color whose bit is true can trigger the deduction that the same color’s bit in a neighboring cell must be false. Any given deduction could be triggered by more than one rule, or by more than one instance of the same rule. Then these rules and deductions should obey some natural properties:</p>

<ul>
  <li>
    <p>The deductions can only go in one direction. If we deduce that a bit is false, we won’t later change it back to true.</p>
  </li>
  <li>
    <p>The deductions are always valid for the intended puzzle. That is, when a puzzle has a unique solution, we won’t ever deduce anything inconsistent with that solution. (However, when that assumption is violated, anything can happen.)</p>
  </li>
  <li>
    <p>It should be possible to efficiently identify all deductions that can be triggered from the current state. Ideally this should take polynomial time.</p>
  </li>
  <li>
    <p>If a deduction is triggered by one of the rules, it remains triggered until that deduction step is performed.</p>
  </li>
</ul>

<p>I’m not assuming that the deduction system is complete, i.e., that it will  reach the intended puzzle solution for all puzzles. For most natural puzzle types and most efficiently-searchable sets of deduction rules, it won’t be complete, and most likely (because of NP-completeness or related complexity issues) cannot be both complete and efficiently searchable. But nevertheless, a system of rules obeying these properties always reaches a unique state, independent of deduction order. It is the last of these properties that enforces this order-invariance. By induction on the values in the triggering patterns, each deduction that could be made by some order of deduction steps will eventually be made by a greedy algorithm that chooses deductions in an arbitrary order until it gets stuck.</p>

<p>The “remains triggered until performed” criterion should sound familiar. It is the defining property of an <a href="https://en.wikipedia.org/wiki/Antimatroid">antimatroid</a>, a collection of orderings of items (here, orderings of deductions that could be made by the greedy algorithm) with the property that once an item becomes available to be added to an ordering, it remains available until it actually is added. The antimatroid name is a bit technical and off-putting, but these structures come up all the time in many different applications. I’ve written here about
<a href="https://11011110.github.io/blog/2006/06/18/reverse-search-for.html">listing all small antimatroids</a>, <a href="https://11011110.github.io/blog/2006/07/20/upright-quad-drawing.html">visualizing their structure</a>, <a href="https://11011110.github.io/blog/2006/08/30/antimatroids-as-algebras.html">algebraic axiomatization</a>, <a href="https://11011110.github.io/blog/2007/02/18/pruning-antimatroids-is.html">hardness of finding weighted feasible sets</a>, the <a href="https://11011110.github.io/blog/2007/02/20/two-partial-cubes.html">swap structure on orderings</a>, <a href="https://11011110.github.io/blog/2011/11/16/which-infinite-graphs.html">infinite antimatroids</a>, <a href="https://11011110.github.io/blog/2013/02/25/antimatroids-and-balanced.html">informative comparisons</a>, <a href="https://11011110.github.io/blog/2015/03/05/nearest-neighbor-in.html">nearest neighbors</a>, and the applications of antimatroids to <a href="https://11011110.github.io/blog/2007/02/17/shelling-and-pseudotriangulation.html">pseudotriangulation</a>, <a href="https://11011110.github.io/blog/2007/12/29/formal-knot-theory.html">knot theory</a>, <a href="https://11011110.github.io/blog/2008/03/30/how-to-implement.html">computerized education</a>, <a href="https://11011110.github.io/blog/2008/12/02/parts-assembly-and.html">parts assembly</a>, <a href="https://11011110.github.io/blog/2009/01/30/antimatroids-from-sorting.html">sorting networks</a>, <a href="https://11011110.github.io/blog/2013/10/26/rhyme-scheme-antimatroid.html">rhyme schemes</a>, <a href="https://11011110.github.io/blog/2016/04/17/local-and-inductive.html">hereditary graph properties</a>, <a href="https://11011110.github.io/blog/2017/01/17/course-prerequisites-are.html">course prerequisites</a>, and <a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html">hierarchical clustering</a>. So why not add puzzle deduction to the list?</p>

<p>A nice side-effect of using deduction rules with these properties is that, if the rules are ordered by difficulty, then a greedy algorithm that always chooses the easiest rule at each step will automatically find a deduction sequence minimizing the difficulty of the hardest rule that it uses. This can be helpful in <a href="http://arxiv.org/abs/cs.DS/0507053">using deduction algorithms to automatically estimate the difficulty of a puzzle for a human solver</a>.</p>

<p>A natural way to achieve the “remains triggered until performed” property for a deduction rule is to use a pattern in the form of a monotonic Boolean combination of state bits (a function that can be expressed using only Boolean and and or operations, without negation) and to trigger a deduction when that combination becomes false. In this way, we achieve a stronger property, that once triggered the deduction remains triggered forever (even after it has already been performed). But as we’ll see below, other kinds of rules can also have the same property.</p>

<p>Now back to map coloring.</p>

<p>We saw in <a href="https://11011110.github.io/blog/2019/06/07/little-knowledge-can.html">my earlier post</a> that it doesn’t work well to use rules like “if one cell has already-colored neighbors of two colors, and only one uncolored neighbor, then that neighbor cannot be either of the same two colors”. These rules are valid (under the assumption that the puzzle solution is unique) but lose information about why the deduction on the neighboring vertex was made, preventing later deductions from being made.</p>

<p>Instead, the insight I ended up using involves <a href="https://en.wikipedia.org/wiki/Kempe_chain">Kempe chains</a>. A Kempe chain, in a colored map, is a maximal connected subset of the cells of two of the colors. If the coloring is to be unique, every Kempe chain must be anchored by one of the original givens of the puzzle, for otherwise we could swap the two colors in the chain without affecting the rest of the graph. So, I’ve started using rules of the form “if this Kempe chain in the partially colored map is not yet anchored, and can reach an anchor only by extending through this other cell, then that cell cannot be a third color”. Here, the Kempe chains that I examine to trigger this rule are maximal connected subsets of the cells whose colors are limited to some set of two colors, allowing cells that are already known to have only one of those two colors. Until we add the extension cell to the chain, the same rule will continue to be triggered, so this passes the any-order requirements above.</p>

<p>This deduction method also fits well into the visualization tools available for manual puzzle-solving in <a href="https://www.chiark.greenend.org.uk/~sgtatham/puzzles/">Simon Tatham’s puzzle collection</a>, where I found the map puzzle. This collection’s implementation of the map puzzle shows the givens and solved cells as solid colors, and allows unsolved cells to be marked by dots of any combination of the four colors. So I’ve been using these dots to indicate the remaining colors available for each cell, in cases when the deductions get complicated enough that I can’t just remember them without marking them. A cell that has dots of only one color rather than a solid color is effectively solved (we know what color it is going to end up being) but might still belong to some unanchored Kempe chains. Once all three Kempe chains through a cell of known color have been anchored, I color that cell as solid. In this way, the parts of the solution that might include unanchored Kempe chains typically remain small and distinctively colored, making the chains easy to spot.</p>

<p style="text-align: center;"><img alt="Screenshot of the map puzzle from Simon Tatham's puzzle collection" src="https://11011110.github.io/blog/assets/2019/map-puzzle-kempe-chain.png"/></p>

<p>The image above shows an example, from one of the hardest built-in difficulty levels of the puzzle (“20x15, 30 regions, Unreasonable”). An orange-brown Kempe chain can be seen in the bottom left, in the two cells colored by orange and brown dots. (Yes, I know these two colors are hard to tell apart; I can’t change them.) Its only escape cell has yellow and brown neighbors, and cannot be green (leaving the orange-brown chain unanchored), so it must be orange. This set of deductions allows us in turn to infer the colors of the other two cells in the chain, and to make them solid (their three Kempe chains all become anchored). The orange escape cell becomes dotted rather than solid, because it is part of a different Kempe chain (colored orange-green) that remains unanchored.</p>

<p style="text-align: center;"><img alt="Screenshot of the map puzzle from Simon Tatham's puzzle collection" src="https://11011110.github.io/blog/assets/2019/map-puzzle-kempe-chain-2.png"/></p>

<p>This extended deduction rule seems to be working well for the puzzles I’ve tried it on. And by obeying the requirement that deductions remain triggered until performed, it gives me confidence that I’m not hiding any usable information by doing my deductions in the wrong order. There is no wrong order: any order in which I make my deductions will eventually lead me to the same state.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102521934491138847">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2019-07-28T17:19:00Z</updated>
    <published>2019-07-28T17:19:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2019-07-30T06:31:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2019/098</id>
    <link href="https://eccc.weizmann.ac.il/report/2019/098" rel="alternate" type="text/html"/>
    <title>TR19-098 |  Domain Compression and its Application to Randomness-Optimal Distributed Goodness-of-Fit | 

	Clement Canonne, 

	Jayadev Acharya, 

	Himanshu Tyagi, 

	Ziteng Sun, 

	Yanjun Han</title>
    <summary>We study goodness-of-fit of discrete distributions in the distributed setting, where samples are divided between multiple users who can only release a limited amount of information about their samples due to various information constraints. Recently, a subset of the authors showed that having access to a common random seed (i.e., shared randomness) leads to a significant reduction in the sample complexity of this problem. In this work, we provide a complete understanding of the interplay between the amount of shared randomness available, the stringency of information constraints, and the sample complexity of the testing problem by characterizing a tight trade-off between these three parameters. We provide a general distributed goodness-of-fit protocol that as a function of the amount of shared randomness interpolates smoothly between the private- and public-coin sample complexities. We complement our upper bound with a general framework to prove lower bounds on the sample complexity of this testing problems under limited shared randomness. Finally, we instantiate our bounds for the two archetypal information constraints of communication and local privacy, and show that our sample complexity bounds are optimal as a function of all the parameters of the problem, including the amount of shared randomness.

A key component of our upper bounds is a new primitive of domain compression, a tool that allows us to map distributions to a much smaller domain size while preserving their pairwise distances, using a limited amount of randomness.</summary>
    <updated>2019-07-28T10:17:48Z</updated>
    <published>2019-07-28T10:17:48Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2019-07-30T12:20:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11209</id>
    <link href="http://arxiv.org/abs/1907.11209" rel="alternate" type="text/html"/>
    <title>Integrality Gap of the Vertex Cover Linear Programming Relaxation</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singh:Mohit.html">Mohit Singh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11209">PDF</a><br/><b>Abstract: </b>We give a characterization result for the integrality gap of the natural
linear programming relaxation for the vertex cover problem. We show that
integrality gap of the standard linear programming relaxation for any graph G
equals $\left(2-\frac{2}{\chi^f(G)}\right)$ where $\chi^f(G)$ denotes the
fractional chromatic number of G.
</p></div>
    </summary>
    <updated>2019-07-28T23:32:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11206</id>
    <link href="http://arxiv.org/abs/1907.11206" rel="alternate" type="text/html"/>
    <title>The Strong 3SUM-INDEXING Conjecture is False</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kopelowitz:Tsvi.html">Tsvi Kopelowitz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Porat:Ely.html">Ely Porat</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11206">PDF</a><br/><b>Abstract: </b>In the 3SUM-Indexing problem the goal is to preprocess two lists of elements
from $U$, $A=(a_1,a_2,\ldots,a_n)$ and $B=(b_1,b_2,...,b_n)$, such that given
an element $c\in U$ one can quickly determine whether there exists a pair
$(a,b)\in A \times B$ where $a+b=c$. Goldstein et al.~[WADS'2017] conjectured
that there is no algorithm for 3SUM-Indexing which uses $n^{2-\Omega(1)}$ space
and $n^{1-\Omega(1)}$ query time.
</p>
<p>We show that the conjecture is false by reducing the 3SUM-Indexing problem to
the problem of inverting functions, and then applying an algorithm of Fiat and
Naor [SICOMP'1999] for inverting functions.
</p></div>
    </summary>
    <updated>2019-07-28T23:34:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11078</id>
    <link href="http://arxiv.org/abs/1907.11078" rel="alternate" type="text/html"/>
    <title>Approximating APSP without Scaling: Equivalence of Approximate Min-Plus and Exact Min-Max</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bringmann:Karl.html">Karl Bringmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/K=uuml=nnemann:Marvin.html">Marvin Künnemann</a>, Karol Węgrzycki <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11078">PDF</a><br/><b>Abstract: </b>Zwick's $(1+\varepsilon)$-approximation algorithm for the All Pairs Shortest
Path (APSP) problem runs in time $\widetilde{O}(\frac{n^\omega}{\varepsilon}
\log{W})$, where $\omega \le 2.373$ is the exponent of matrix multiplication
and $W$ denotes the largest weight. This can be used to approximate several
graph characteristics including the diameter, radius, median, minimum-weight
triangle, and minimum-weight cycle in the same time bound.
</p>
<p>Since Zwick's algorithm uses the scaling technique, it has a factor $\log W$
in the running time. In this paper, we study whether APSP and related problems
admit approximation schemes avoiding the scaling technique. That is, the number
of arithmetic operations should be independent of $W$; this is called strongly
polynomial. Our main results are as follows.
</p>
<p>- We design approximation schemes in strongly polynomial time
$O(\frac{n^\omega}{\varepsilon} \text{polylog}(\frac{n}{\varepsilon}))$ for
APSP on undirected graphs as well as for the graph characteristics diameter,
radius, median, minimum-weight triangle, and minimum-weight cycle on directed
or undirected graphs.
</p>
<p>- For APSP on directed graphs we design an approximation scheme in strongly
polynomial time $O(n^{\frac{\omega + 3}{2}} \varepsilon^{-1}
\text{polylog}(\frac{n}{\varepsilon}))$. This is significantly faster than the
best exact algorithm.
</p>
<p>- We explain why our approximation scheme for APSP on directed graphs has a
worse exponent than $\omega$: Any improvement over our exponent $\frac{\omega +
3}{2}$ would improve the best known algorithm for Min-Max Product In fact, we
prove that approximating directed APSP and exactly computing the Min-Max
Product are equivalent.
</p></div>
    </summary>
    <updated>2019-07-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11015</id>
    <link href="http://arxiv.org/abs/1907.11015" rel="alternate" type="text/html"/>
    <title>A new approach (extra vertex) and generalization of Shoelace Algorithm usage in convex polygon (Point-in-Polygon)</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Ochilbek Rakhmanov <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11015">PDF</a><br/><b>Abstract: </b>In this paper we aim to bring new approach into usage of Shoelace Algorithm
for area calculation in convex polygons on Cartesian coordinate system, with
concentration on point in polygon concept. Generalization of usage of the
concept will be proposed for line segment and polygons. Testing of new method
will be done using Python language. Results of tests show that the new approach
is more effective than the current one.
</p></div>
    </summary>
    <updated>2019-07-28T23:38:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.11010</id>
    <link href="http://arxiv.org/abs/1907.11010" rel="alternate" type="text/html"/>
    <title>Deciding Fast Termination for Probabilistic VASS with Nondeterminism</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Tomáš Brázdil, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chatterjee:Krishnendu.html">Krishnendu Chatterjee</a>, Antonín Kučera, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Novotn=yacute=:Petr.html">Petr Novotný</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Velan:Dominik.html">Dominik Velan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.11010">PDF</a><br/><b>Abstract: </b>A probabilistic vector addition system with states (pVASS) is a finite state
Markov process augmented with non-negative integer counters that can be
incremented or decremented during each state transition, blocking any behaviour
that would cause a counter to decrease below zero. The pVASS can be used as
abstractions of probabilistic programs with many decidable properties. The use
of pVASS as abstractions requires the presence of nondeterminism in the model.
In this paper, we develop techniques for checking fast termination of pVASS
with nondeterminism.
</p>
<p>That is, for every initial configuration of size n, we consider the worst
expected number of transitions needed to reach a configuration with some
counter negative (the expected termination time). We show that the problem
whether the asymptotic expected termination time is linear is decidable in
polynomial time for a certain natural class of pVASS with nondeterminism.
Furthermore, we show the following dichotomy: if the asymptotic expected
termination time is not linear, then it is at least quadratic, i.e., in
$\Omega(n^2)$.
</p></div>
    </summary>
    <updated>2019-07-28T23:21:47Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10984</id>
    <link href="http://arxiv.org/abs/1907.10984" rel="alternate" type="text/html"/>
    <title>Enumerating Range Modes</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sumigawa:Kentaro.html">Kentaro Sumigawa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakraborty:Sankardeep.html">Sankardeep Chakraborty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sadakane:Kunihiko.html">Kunihiko Sadakane</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Satti:Srinivasa_Rao.html">Srinivasa Rao Satti</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10984">PDF</a><br/><b>Abstract: </b>We consider the range mode problem where given a sequence and a query range
in it, we want to find items with maximum frequency in the range. We give time-
and space- efficient algorithms for this problem. Our algorithms are efficient
for small maximum frequency cases. We also consider a natural generalization of
the problem: the range mode enumeration problem, for which there has been no
known efficient algorithms. Our algorithms have query time complexities which
is linear to the output size plus small terms.
</p></div>
    </summary>
    <updated>2019-07-28T23:36:38Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10937</id>
    <link href="http://arxiv.org/abs/1907.10937" rel="alternate" type="text/html"/>
    <title>Polylogarithmic-Time Deterministic Network Decomposition and Distributed Derandomization</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Václav Rozhoň, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghaffari:Mohsen.html">Mohsen Ghaffari</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10937">PDF</a><br/><b>Abstract: </b>We present a simple polylogarithmic-time deterministic distributed algorithm
for network decomposition. This improves on a celebrated $2^{O(\sqrt{\log
n})}$-time algorithm of Panconesi and Srinivasan [STOC'93] and settles one of
the long-standing and central questions in distributed graph algorithms. It
also leads to the first polylogarithmic-time deterministic distributed
algorithms for numerous other graph problems, hence resolving several open
problems, including Linial's well-known question about the deterministic
complexity of maximal independent set [FOCS'87].
</p>
<p>Put together with the results of Ghaffari, Kuhn, and Maus [STOC'17] and
Ghaffari, Harris, and Kuhn [FOCS'18], we get a general distributed
derandomization result that implies $\mathsf{P}$-$\mathsf{RLOCAL}$ =
$\mathsf{P}$-$\mathsf{LOCAL}$. That is, for any distributed problem whose
solution can be checked in polylogarithmic-time, any polylogarithmic-time
randomized algorithm can be derandomized to a polylogarithmic-time
deterministic algorithm.
</p>
<p>By known connections, our result leads also to substantially faster
randomized algorithms for a number of fundamental problems including
$(\Delta+1)$-coloring, MIS, and Lov\'{a}sz Local Lemma.
</p></div>
    </summary>
    <updated>2019-07-28T23:31:27Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10930</id>
    <link href="http://arxiv.org/abs/1907.10930" rel="alternate" type="text/html"/>
    <title>GAMA: A Novel Algorithm for Non-Convex Integer Programs</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alghassi:Hedayat.html">Hedayat Alghassi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dridi:Raouf.html">Raouf Dridi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tayur:Sridhar.html">Sridhar Tayur</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10930">PDF</a><br/><b>Abstract: </b>Inspired by the decomposition in the hybrid quantum-classical optimization
algorithm we introduced in <a href="http://export.arxiv.org/abs/1902.04215">arXiv:1902.04215</a>, we propose here a new (fully
classical) approach to solving certain non-convex integer programs using Graver
bases. This method is well suited when (a) the constraint matrix $A$ has a
special structure so that its Graver basis can be computed systematically, (b)
several feasible solutions can also be constructed easily and (c) the objective
function can be viewed as many convex functions quilted together. Classes of
problems that satisfy these conditions include Cardinality Boolean Quadratic
Problems (CBQP), Quadratic Semi-Assignment Problems (QSAP) and Quadratic
Assignment Problems (QAP). Our Graver Augmented Multi-seed Algorithm (GAMA)
utilizes augmentation along Graver basis elements (the improvement direction is
obtained by comparing objective function values) from these multiple initial
feasible solutions. We compare our approach with a best-in-class commercially
available solver (Gurobi). Sensitivity analysis indicates that the rate at
which GAMA slows down as the problem size increases is much lower than that of
Gurobi. We find that for several instances of practical relevance, GAMA not
only vastly outperforms in terms of time to find the optimal solution (by two
or three orders of magnitude), but also finds optimal solutions within minutes
when the commercial solver is not able to do so in 4 or 10 hours (depending on
the problem class) in several cases.
</p></div>
    </summary>
    <updated>2019-07-28T23:31:13Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/1907.10895</id>
    <link href="http://arxiv.org/abs/1907.10895" rel="alternate" type="text/html"/>
    <title>Fast Deterministic Constructions of Linear-Size Spanners and Skeletons</title>
    <feedworld_mtime>1564272000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Elkin:Michael.html">Michael Elkin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Matar:Shaked.html">Shaked Matar</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/1907.10895">PDF</a><br/><b>Abstract: </b>In the distributed setting, the only existing constructions of \textit{sparse
skeletons}, (i.e., subgraphs with $O(n)$ edges) either use randomization or
large messages, or require $\Omega(D)$ time, where $D$ is the hop-diameter of
the input graph $G$. We devise the first deterministic distributed algorithm in
the CONGEST model (i.e., uses small messages) for constructing linear-size
skeletons in time $2^{O(\sqrt{{\log n}\cdot{\log{\log n}}})}$. We can also
compute a linear-size spanner with stretch $polylog(n)$ in low deterministic
polynomial time, i.e., $O(n^\rho)$ for an arbitrarily small constant $\rho &gt;0$,
in the CONGEST model. Yet another algorithm that we devise runs in $O({\log
n})^{\kappa-1}$ time, for a parameter $\kappa=1,2,\dots,$ and constructs an
$O({\log n})^{\kappa-1}$ spanner with $O(n^{1+1/\kappa})$ edges. All our
distributed algorithms are lightweight from the computational perspective,
i.e., none of them employs any heavy computations.
</p></div>
    </summary>
    <updated>2019-07-28T23:28:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2019-07-26T01:30:00Z</updated>
    </source>
  </entry>
</feed>
