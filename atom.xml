<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2022-05-24T10:38:34Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.10834</id>
    <link href="http://arxiv.org/abs/2205.10834" rel="alternate" type="text/html"/>
    <title>On the Parameterized Complexity of the $s$-Club Cluster Edge Deletion Problem</title>
    <feedworld_mtime>1653350400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Montecchiani:Fabrizio.html">Fabrizio Montecchiani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ortali:Giacomo.html">Giacomo Ortali</a>, Tommaso Piselli, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tappini:Alessandra.html">Alessandra Tappini</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.10834">PDF</a><br/><b>Abstract: </b>We study the parameterized complexity of the $s$-Club Cluster Edge Deletion
problem: Given a graph $G$ and two integers $s \ge 2$ and $k \ge 1$, is it
possible to remove at most $k$ edges from $G$ such that each connected
component of the resulting graph has diameter at most $s$? This problem is
known to be NP-hard already when $s = 2$. We prove that it admits a
fixed-parameter tractable algorithm when parameterized by $s$ and the treewidth
of the input graph.
</p></div>
    </summary>
    <updated>2022-05-24T01:20:22Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.10302</id>
    <link href="http://arxiv.org/abs/2205.10302" rel="alternate" type="text/html"/>
    <title>Individual Fairness in Prophet Inequalities</title>
    <feedworld_mtime>1653350400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arsenis:Makis.html">Makis Arsenis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kleinberg:Robert.html">Robert Kleinberg</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.10302">PDF</a><br/><b>Abstract: </b>Prophet inequalities are performance guarantees for online algorithms (a.k.a.
stopping rules) solving the following "hiring problem": a decision maker
sequentially inspects candidates whose values are independent random numbers
and is asked to hire at most one candidate by selecting it before inspecting
the values of future candidates in the sequence. A classic result in optimal
stopping theory asserts that there exist stopping rules guaranteeing that the
decision maker will hire a candidate whose expected value is at least half as
good as the expected value of the candidate hired by a "prophet", i.e. one who
has simultaneous access to the realizations of all candidates' values.
</p>
<p>Such stopping rules have provably good performance but might treat individual
candidates unfairly in a number of different ways. In this work we identify two
types of individual fairness that might be desirable in optimal stopping
problems. We call them identity-independent fairness (IIF) and time-independent
fairness (TIF) and give precise definitions in the context of the hiring
problem. We give polynomial-time algorithms for finding the optimal IIF/TIF
stopping rules for a given instance with discrete support and we manage to
recover a prophet inequality with factor $1/2$ when the decision maker's
stopping rule is required to satisfy both fairness properties while the prophet
is unconstrained. We also explore worst-case ratios between optimal selection
rules in the presence vs. absence of individual fairness constraints, in both
the online and offline settings. Finally, we consider a framework in which the
decision maker doesn't know the distributions of candidates' values but has
access to independent samples from each distribution. We provide
constant-competitive IIF/TIF algorithms using one sample per distribution in
the offline setting and two samples per distribution in the online setting.
</p></div>
    </summary>
    <updated>2022-05-23T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.10301</id>
    <link href="http://arxiv.org/abs/2205.10301" rel="alternate" type="text/html"/>
    <title>Expander Decomposition with Fewer Inter-Cluster Edges Using a Spectral Cut Player</title>
    <feedworld_mtime>1653350400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Agassy:Daniel.html">Daniel Agassy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dorfman:Dani.html">Dani Dorfman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaplan:Haim.html">Haim Kaplan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.10301">PDF</a><br/><b>Abstract: </b>A $(\phi,\epsilon)$-Expander-decomposition of a graph $G$ is a partition of
$V$ into clusters $V_1,\ldots,V_k$ with conductance $\Phi(G[V_i]) \ge \phi$,
such that there are at most $\epsilon \phi m$ inter-cluster edges. We consider
the problem of computing such a decomposition for a given $G$ and expansion
parameter $\phi$, while minimizing $\epsilon$. Saranurak and Wang [SW19] gave a
randomized $O(m \log^4m/\phi)$ algorithm for computing a $(\phi, \log^3
n)$-expander decomposition. As a main building block, [SW19] use an adaptation
of the algorithm of R\"{a}cke et al. [RST14] for computing an approximate
balanced sparse cut. Both algorithms rely on the cut-matching game of Khandekar
et al. [KRV09]
</p>
<p>Orecchia et al. [OSVV08], using spectral analysis, improved upon [KRV09] by
giving a fast algorithm that computes a sparse cut with better approximation
guarantee. Using the technique of [OSVV08] for computing expander
decompositions or balanced cuts [RST14, SW19], encounters many hurdles since
the graph structure constantly changes, making it difficult to perform spectral
analysis.
</p>
<p>In this paper, we manage to exploit the technique of [OSVV08] to compute an
expander decomposition, hence improving the result by Saranurak and Wang
[SW19]. Specifically, we give a randomized algorithm for computing a $(\phi,
\log^2 {n})$-expander decomposition of a graph, in $O(m\log^7 m + \frac{m
\log^4m}{\phi})$ time. Our new result is achieved by using a novel combination
of a symmetric version of the potential functions of [OSVV08, RST14, SW19] with
a new variation of Cheeger's inequality for the notion of near-expansion.
</p></div>
    </summary>
    <updated>2022-05-23T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.10194</id>
    <link href="http://arxiv.org/abs/2205.10194" rel="alternate" type="text/html"/>
    <title>New compressed cover tree for k-nearest neighbor search</title>
    <feedworld_mtime>1653350400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Elkin:Yury.html">Yury Elkin</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.10194">PDF</a><br/><b>Abstract: </b>This thesis consists of two topics related to computational geometry and one
topic related to topological data analysis (TDA), which combines fields of
computational geometry and algebraic topology for analyzing data. The first
part studies the classical problem of finding k nearest neighbors to m query
points in a larger set of n reference points in any metric space. The second
part is about the construction of a Minimum Spanning Tree (MST) on any finite
metric space. The third part extends the key concept of persistence within
Topological Data Analysis in a new direction.
</p></div>
    </summary>
    <updated>2022-05-23T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2022-05-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.10105</id>
    <link href="http://arxiv.org/abs/2205.10105" rel="alternate" type="text/html"/>
    <title>Parameterized Complexity of Weighted Multicut in Trees</title>
    <feedworld_mtime>1653350400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galby:Esther.html">Esther Galby</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marx:D=aacute=niel.html">D√°niel Marx</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schepper:Philipp.html">Philipp Schepper</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sharma:Roohani.html">Roohani Sharma</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tale:Prafullkumar.html">Prafullkumar Tale</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.10105">PDF</a><br/><b>Abstract: </b>The Edge Multicut problem is a classical cut problem where given an
undirected graph $G$, a set of pairs of vertices $\mathcal{P}$, and a budget
$k$, the goal is to determine if there is a set $S$ of at most $k$ edges such
that for each $(s,t) \in \mathcal{P}$, $G-S$ has no path from $s$ to $t$. Edge
Multicut has been relatively recently shown to be fixed-parameter tractable
(FPT), parameterized by $k$, by Marx and Razgon [SICOMP 2014], and
independently by Bousquet et al. [SICOMP 2018]. In the weighted version of the
problem, called Weighted Edge Multicut one is additionally given a weight
function $\mathtt{wt} : E(G) \to \mathbb{N}$ and a weight bound $w$, and the
goal is to determine if there is a solution of size at most $k$ and weight at
most $w$. Both the FPT algorithms for Edge Multicut by Marx et al. and Bousquet
et al. fail to generalize to the weighted setting. In fact, the weighted
problem is non-trivial even on trees and determining whether Weighted Edge
Multicut on trees is FPT was explicitly posed as an open problem by Bousquet et
al. [STACS 2009]. In this article, we answer this question positively by
designing an algorithm which uses a very recent result by Kim et al. [STOC
2022] about directed flow augmentation as subroutine.
</p>
<p>We also study a variant of this problem where there is no bound on the size
of the solution, but the parameter is a structural property of the input, for
example, the number of leaves of the tree. We strengthen our results by stating
them for the more general vertex deletion version.
</p></div>
    </summary>
    <updated>2022-05-24T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.09961</id>
    <link href="http://arxiv.org/abs/2205.09961" rel="alternate" type="text/html"/>
    <title>Discrete-Convex-Analysis-Based Framework for Warm-Starting Algorithms with Predictions</title>
    <feedworld_mtime>1653350400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sakaue:Shinsaku.html">Shinsaku Sakaue</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Oki:Taihei.html">Taihei Oki</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.09961">PDF</a><br/><b>Abstract: </b>Augmenting algorithms with learned predictions is a promising approach for
going beyond worst-case bounds. Dinitz, Im, Lavastida, Moseley, and
Vassilvitskii~(2021) have demonstrated that a warm start with learned dual
solutions can improve the time complexity of the Hungarian method for weighted
perfect bipartite matching. We extend and improve their framework in a
principled manner via \textit{discrete convex analysis} (DCA), a discrete
analog of convex analysis. We show the usefulness of our DCA-based framework by
applying it to weighted perfect bipartite matching, weighted matroid
intersection, and discrete energy minimization for computer vision. Our
DCA-based framework yields time complexity bounds that depend on the
$\ell_\infty$-distance from a predicted solution to an optimal solution, which
has two advantages relative to the previous $\ell_1$-distance-dependent bounds:
time complexity bounds are smaller, and learning of predictions is more sample
efficient. We also discuss whether to learn primal or dual solutions from the
DCA perspective.
</p></div>
    </summary>
    <updated>2022-05-23T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.09873</id>
    <link href="http://arxiv.org/abs/2205.09873" rel="alternate" type="text/html"/>
    <title>Differentially Private Linear Sketches: Efficient Implementations and Applications</title>
    <feedworld_mtime>1653350400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhao:Fuheng.html">Fuheng Zhao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Qiao:Dan.html">Dan Qiao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Redberg:Rachel.html">Rachel Redberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Agrawal:Divyakant.html">Divyakant Agrawal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abbadi:Amr_El.html">Amr El Abbadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yu=Xiang.html">Yu-Xiang Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.09873">PDF</a><br/><b>Abstract: </b>Linear sketches have been widely adopted to process fast data streams, and
they can be used to accurately answer frequency estimation, approximate top K
items, and summarize data distributions. When data are sensitive, it is
desirable to provide privacy guarantees for linear sketches to preserve private
information while delivering useful results with theoretical bounds. We show
that linear sketches can ensure privacy and maintain their unique properties
with a small amount of noise added at initialization. From the differentially
private linear sketches, we showcase that the state-of-the-art quantile sketch
in the turnstile model can also be private and maintain high performance.
Experiments further demonstrate that our proposed differentially private
sketches are quantitatively and qualitatively similar to noise-free sketches
with high utilization on synthetic and real datasets.
</p></div>
    </summary>
    <updated>2022-05-23T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.09826</id>
    <link href="http://arxiv.org/abs/2205.09826" rel="alternate" type="text/html"/>
    <title>DPER: Dynamic Programming for Exist-Random Stochastic SAT</title>
    <feedworld_mtime>1653350400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Phan:Vu_H=_N=.html">Vu H. N. Phan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vardi:Moshe_Y=.html">Moshe Y. Vardi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.09826">PDF</a><br/><b>Abstract: </b>In Bayesian inference, the maximum a posteriori (MAP) problem combines the
most probable explanation (MPE) and marginalization (MAR) problems. The
counterpart in propositional logic is the exist-random stochastic
satisfiability (ER-SSAT) problem, which combines the satisfiability (SAT) and
weighted model counting (WMC) problems. Both MAP and ER-SSAT have the form
$\operatorname{argmax}_X \sum_Y f(X, Y)$, where $f$ is a real-valued function
over disjoint sets $X$ and $Y$ of variables. These two optimization problems
request a value assignment for the $X$ variables that maximizes the weighted
sum of $f(X, Y)$ over all value assignments for the $Y$ variables. ER-SSAT has
been shown to be a promising approach to formally verify fairness in supervised
learning. Recently, dynamic programming on graded project-join trees has been
proposed to solve weighted projected model counting (WPMC), a related problem
that has the form $\sum_X \max_Y f(X, Y)$. We extend this WPMC framework to
exactly solve ER-SSAT and implement a dynamic-programming solver named DPER.
Our empirical evaluation indicates that DPER contributes to the portfolio of
state-of-the-art ER-SSAT solvers (DC-SSAT and erSSAT) through competitive
performance on low-width problem instances.
</p></div>
    </summary>
    <updated>2022-05-23T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.09804</id>
    <link href="http://arxiv.org/abs/2205.09804" rel="alternate" type="text/html"/>
    <title>Estimation of Entropy in Constant Space with Improved Sample Complexity</title>
    <feedworld_mtime>1653350400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aliakbarpour:Maryam.html">Maryam Aliakbarpour</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/McGregor:Andrew.html">Andrew McGregor</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nelson:Jelani.html">Jelani Nelson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Waingarten:Erik.html">Erik Waingarten</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.09804">PDF</a><br/><b>Abstract: </b>Recent work of Acharya et al. (NeurIPS 2019) showed how to estimate the
entropy of a distribution $\mathcal D$ over an alphabet of size $k$ up to
$\pm\epsilon$ additive error by streaming over $(k/\epsilon^3) \cdot
\text{polylog}(1/\epsilon)$ i.i.d. samples and using only $O(1)$ words of
memory. In this work, we give a new constant memory scheme that reduces the
sample complexity to $(k/\epsilon^2)\cdot \text{polylog}(1/\epsilon)$. We
conjecture that this is optimal up to $\text{polylog}(1/\epsilon)$ factors.
</p></div>
    </summary>
    <updated>2022-05-24T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.09520</id>
    <link href="http://arxiv.org/abs/2205.09520" rel="alternate" type="text/html"/>
    <title>Dynamic SAFFRON: Disease Control Over Time Via Group Testing</title>
    <feedworld_mtime>1653350400</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arasli:Batuhan.html">Batuhan Arasli</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Ulukus:Sennur.html">Sennur Ulukus</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.09520">PDF</a><br/><b>Abstract: </b>We consider the dynamic infection spread model that is based on the discrete
SIR model which assumes infections to be spread over time via infected and
non-isolated individuals. In our system, the main objective is not to minimize
the number of required tests to identify every infection, but instead, to
utilize the available, given testing capacity $T$ at each time instance to
efficiently control the infection spread. We introduce and study a novel
performance metric, which we coin as $\epsilon$-disease control time. This
metric can be used to measure how fast a given algorithm can control the spread
of a disease. We characterize the performance of dynamic individual testing
algorithm and introduce a novel dynamic SAFFRON based group testing algorithm.
We present theoretical results and implement the proposed algorithms to compare
their performances.
</p></div>
    </summary>
    <updated>2022-05-23T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2022-05-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2022/05/23/ideal-workshop-on-high-dimensional-geometry-and-analysis/</id>
    <link href="https://cstheory-events.org/2022/05/23/ideal-workshop-on-high-dimensional-geometry-and-analysis/" rel="alternate" type="text/html"/>
    <title>IDEAL Workshop on High-Dimensional Geometry and Analysis</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">May 27, 2022 Northwestern University Mudd 3514 https://www.ideal.northwestern.edu/events/high-dimensional-analysis/ Speakers Ainesh Bakshi (Carnegie Mellon University), Arnold Filtser (Bar Ilan University), Weiyun Ma (Stanford University), Assaf Naor (Princeton University), Erik Waingarten (Stanford University) Logistics Dates: Friday, May 27 Location: Northwestern University Rooms: Mudd 3514 Streaming: Zoom Registration Link on website- https://www.ideal.northwestern.edu/events/high-dimensional-analysis/ PRELIMINARY Schedule All times are in ‚Ä¶ <a class="more-link" href="https://cstheory-events.org/2022/05/23/ideal-workshop-on-high-dimensional-geometry-and-analysis/">Continue reading <span class="screen-reader-text">IDEAL Workshop on High-Dimensional Geometry and¬†Analysis</span></a></div>
    </summary>
    <updated>2022-05-23T22:38:18Z</updated>
    <published>2022-05-23T22:38:18Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2022-05-24T10:38:04Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8334</id>
    <link href="https://windowsontheory.org/2022/05/23/why-i-am-not-a-longtermist/" rel="alternate" type="text/html"/>
    <title>Why I am not a longtermist</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">[Apologies for yet another ‚Äúphilosophizing‚Äù blog post, hope to get back to posts with more equations soon‚Ä¶ Should also mention that one response to this piece was that ‚Äúanyone who writes a piece called ‚ÄúWhy I am not a longtermist‚Äù is probably more of a longtermist than 90% of the population‚Äù üôÇ ‚ÄìBoaz] ‚ÄúLongtermism‚Äù is ‚Ä¶ <a class="more-link" href="https://windowsontheory.org/2022/05/23/why-i-am-not-a-longtermist/">Continue reading <span class="screen-reader-text">Why I am not a¬†longtermist</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><em>[Apologies for yet another <a href="https://windowsontheory.org/category/philosophizing/">‚Äúphilosophizing‚Äù </a>blog post, hope to get back to posts with more equations soon‚Ä¶ Should also mention that one response to this piece was that ‚Äúanyone who writes a piece called ‚ÄúWhy I am not a longtermist‚Äù is probably more of a longtermist than 90% of the population</em>‚Äù <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/> <em>‚ÄìBoaz]</em></p>



<p>‚Äú<a href="https://en.wikipedia.org/wiki/Longtermism">Longtermism</a>‚Äù is a moral philosophy that places much more weight on the well-being of all future generations than on the current one. It <a href="https://www.effectivealtruism.org/articles/longtermism">holds</a> that ‚Äúpositively influencing the long-term future is a key moral priority of our time,‚Äù where ‚Äúlong term‚Äù can be <em>really</em> long term, e.g., ‚Äúmany thousands of years in the future, or much further still.‚Äù ¬† At its core is the belief that each one of the potential quadrillion or more people that may exist in the future is as important as any single person today.</p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="596" src="https://lh4.googleusercontent.com/JibhteUU2RwXMZCy3FU7bwjTqOYcNds8u29ny_iPP3aK5N-idd1vJtp4RKCi-Lv-7E7u3-nziFPYCNdD8C78f58X3CVM3HPbQoIsrPL3EvdLDNnzgeWuWpahl04cL9QMaG_lZVjcKL0G-r5s4w" width="439"/></figure></div>


<p>Longtermism has recently attracted attention, some of it in <a href="https://www.currentaffairs.org/2021/07/the-dangerous-ideas-of-longtermism-and-existential-risk">alarming tones</a>. The reasoning behind longtermism is natural: if we assume that human society will continue to exist for at least a few millennia, many more people will be born in the future than are alive today. However, since predictions are famously hard to make, especially about the future, longtermism invariably gets wrapped up with probabilities. Once you do these calculations, preventing an infinitely bad outcome, even if it would only happen with tiny probability, will have infinite utility. Hence longtermism tends to focus on so-called ‚Äúexistential risk‚Äù:¬† The risk that humanity will go through in an extinction event, like the one suffered by the Neanderthals or Dinosaurs, or another type of irreversible humanity-wise calamity.<br/></p>



<p>This post explains why I do not subscribe to this philosophy. Let me clarify that I am not saying that all longtermists are bad people. Many ‚Äúlongtermists‚Äù have given generously to improve people‚Äôs lives worldwide, particularly in developing countries. For example, none of the top charities of <a href="https://www.givewell.org/">Givewell</a> (an organization associated with the effective altruism movement, in which many prominent longtermists are members) focus on hypothetical future risks. Instead, they all deal with current pressing issues, including Malaria, childhood vaccinations, and extreme poverty. Overall the effective altruism movement has done much to benefit currently living people. Some of its members <a href="https://www.vox.com/future-perfect/2018/10/15/17962134/future-perfect-podcast-kidney-donation">donated their kidneys to strangers</a>: These are good people- morally better than me. It is hardly fair to fault people that are already contributing more than most others for caring about issues that I think are less significant.</p>


<div class="wp-block-image">
<figure class="aligncenter is-resized"><img alt="" height="496" src="https://lh5.googleusercontent.com/wGuGQ0ly7gKlSuGx80WXjdthvUrDt9ZSOgN5mma-p_dJ0_rQdjlSyAet9g5zLui8K6sw_uG8lzzd1VHb3l32QVEbNbj2wuzwLDi-VsH4Pn24RR-C3u2-9nB5-xWakbNP3tPlmgthzGBRQhsdfQ" width="506"/><a href="https://80000hours.org/2021/08/effective-altruism-allocation-resources-cause-areas/">Benjamin Todd‚Äôs</a> estimates of Effective Altruism resource allocations</figure></div>


<p/>



<p>This post critiques the philosophy of longtermism rather than the particular actions or beliefs of ‚Äúlongtermists.‚Äù In particular, the following are often highly correlated with one another:</p>



<ol><li>Belief in the philosophy of longtermism.</li><li>A belief that existential risk is not just a concern for the far-off future and a low-probability event, but there is a very significant chance of it happening in the near future (next few decades or at most a century).</li><li>A belief that the most significant existential risk could arise from artificial intelligence and that this is a real risk in the near future.</li></ol>



<p>Here I focus on (1) and explain why I disagree with this philosophy. While I might disagree on specific calculations of (2) and (3), I fully agree with the need to think and act regarding near-term risks.¬† Society tends to err on the side of being too myopic. We prepare too little even for risks that are not just predictable but are also predicted, including climate change, pandemics, nuclear conflict, and even software hacks. It is hard to motivate people to spend resources for safety when the outcome (bad event not happening) is invisible. It is also true that over the last decades, humanity‚Äôs technological capacities have grown so much that for the first time in history, we are capable of doing irreversible damage to our planet.¬†</p>



<p>In addition to the above, I agree that we need to think carefully about the risks of any new technology, particularly one that, like artificial intelligence, can be very powerful but not fully understood.¬† Some AI risks are relevant to the shorter term: they are likely over the next decade or are already happening. There <a href="https://www.amazon.com/Weapons-Math-Destruction-Increases-Inequality/dp/0553418815">are</a> <a href="https://www.amazon.com/Ethical-Algorithm-Science-Socially-Design/dp/0190948205">several</a> <a href="https://fairmlbook.org/">books</a> on these challenges. None of my critiques apply to such issues. At some point, I might write a separate blog post about artificial intelligence and its short and long-term risks.¬†</p>



<p>My reasons for not personally being a ‚Äúlongtermist‚Äù are the following:</p>



<p><strong>The probabilities are too small to reason about.</strong></p>



<p>Physicists know that there is no point in writing a measurement up to 3 significant digits if your measurement device has only one-digit accuracy. Our ability to reason about events that are decades or more into the future is severely limited. At best, we could estimate probabilities up to an order of magnitude, and even that may be optimistic. Thus, claims such as <a href="https://www.existential-risk.org/concept.html">Nick Bostrom‚Äôs</a>, that <em>‚Äúthe expected value of reducing existential risk by a mere one billionth of one billionth of one percentage point is worth a hundred billion times as much as a billion human lives‚Äù</em> make no sense to me.¬† This is especially the case since these ‚Äúprobabilities‚Äù are Bayesian, i.e., correspond to degrees of belief. If, for example, you evaluate the existential-risk probability by aggregating the responses of 1000 experts, then what one of these experts had for breakfast is likely to have an impact larger than 0.001 percent (which, according to Bostrom, would correspond to much more than 10¬≤‚Å∞ human lives). To the extent we can quantify existential risks in the far future, we can only say something like ‚Äúextremely likely,‚Äù ‚Äúpossible,‚Äù or ‚Äúcan‚Äôt be ruled out.‚Äù Assigning numbers to such qualitative assessments is an exercise in futility.¬†</p>



<p><strong>I cannot justify sacrificing current living humans for abstract probabilities.</strong></p>



<p>Related to the above, rather than focusing on specific, measurable risks (e.g., earthquakes, climate change), longtermism is often concerned with extremely hard to quantify risks. In truth, we cannot know what will happen 100 years into the future and what would be the impact of any particular technology. Even if our actions will have drastic consequences for future generations, the dependence of the impact on our choices is likely to be chaotic and unpredictable. To put things in perspective, many of the risks we are worried about today, including nuclear war, climate change, and AI safety, only emerged in the last century or decades. It is hard to underestimate our ability to predict even a decade into the future, let alone a century or more.</p>



<p>Given that there is so much suffering and need in the world right now, I cannot accept a philosophy that prioritizes abstract armchair calculations over actual living humans. (This concern is not entirely hypothetical: <a href="https://globalprioritiesinstitute.org/hilary-greaves-william-macaskill-the-case-for-strong-longtermism-2/">Greaves and MacAskill</a> estimate that $100 spent on AI safety would, in expectation, correspond to saving a <em>trillion lives</em> and hence would be ‚Äúfar more than the near-future benefits of bednet distribution [for preventing Malaria],‚Äù and recommend that it is better that individuals ‚Äúfund AI safety rather than developing world poverty reduction.‚Äù)</p>



<p><a href="https://www.effectivealtruism.org/articles/longtermism">Moorhouse</a> compares future humans to ones living far away from us. He says that just like ‚Äúsomething happening far away from us in space isn‚Äôt less intrinsically bad just because it‚Äôs far away,‚Äù we should care about humans in the far-off future as much as we care about present ones. But I think that we <em>should</em> care less about very far away events, especially if it‚Äôs so far away that we cannot observe them. E.g., as far as we know, there may well be trillions of sentient beings in the universe right now whose welfare can somehow be impacted by our actions.¬†</p>



<p><strong>We cannot improve what we cannot measure.</strong></p>



<p>An inherent disadvantage of probabilities is that they are invisible until they occur. We have no direct way to measure whether a probability of an event X has increased or decreased. So, we cannot tell whether our efforts are working or not. The <a href="https://windowsontheory.org/2022/05/03/philosophy-of-science-and-the-blockchain-a-book-review/">scientific revolution</a> involved moving from armchair philosophizing to making measurable predictions. I do not believe we can make meaningful progress without concrete goals. For some risks, we do have quantifiable goals (Carbon emissions, number of nuclear warheads). Still, there are significant challenges to finding a measurable proxy for very low-probability and far-off events. Hence, even if we accept that the risks are real and vital, I do not think we can directly do anything about them before finding such proxies.¬†</p>



<p>Proxies do not have to be perfect: Theoretical computer science made much progress using the imperfect measure of worst-case asymptotic complexity. The same holds for machine learning and artificial benchmarks. It is enough that proxies encourage the generation of new ideas or technologies and achieve gradual improvement. One lesson from modern machine learning is that the objective (aka loss function) doesn‚Äôt have to perfectly match the task for it to be useful.</p>



<p><strong>Long-term risk mitigation can only succeed through short-term progress.</strong></p>



<p>Related to the above, I believe that addressing long-term risks can only be successful if it‚Äôs tied to shorter-term advances that have clear utility. For example, consider the following two extinction scenarios:</p>



<p>1. The actual Neanderthal extinction.<br/>2. A potential human extinction 50 years from now due to total nuclear war.</p>



<p>I argue that the only realistic scenario to avoid extinction in both cases is a sequence of actions that improve some measurable outcome. While sometimes extinction could theoretically be avoided by a society making a huge sacrifice to eliminate a hypothetical scenario, this could never actually happen.</p>



<p>While the reasons for the Neanderthal extinction are not fully known, most researchers believe that Neanderthals were out-competed by our ancestors ‚Äì modern humans ‚Äì who had better tools and ways to organize society. The crucial point is that the approaches to prevent extinction for Neanderthal were the same ones to improve their lives in their current environment. They may not have been capable of doing so, but it wasn‚Äôt because they were working on the wrong problems.</p>



<p>Contrast this with the scenario of human extinction through total nuclear war. In such a case, our conventional approaches for keeping nuclear arms in check, such as international treaties and sanctions, have failed. Perhaps in hindsight, humanity‚Äôs optimum course of action would have been a permanent extension of the middle ages, stopping the scientific revolution from happening through restricting education, religious oppression, and vigorous burning-at-stake of scientists.¬† Or perhaps humanity could even now make a collective decision to go back and delete all traces of post 17th-century science and technology.</p>



<p>I cannot rule out the possibility that, in hindsight, one of those outcomes would have had more aggregate utility than our current trajectory. But even if this is the case, such an outcome is simply not possible. Humanity can not and will not halt its progress, and solutions to significant long-term problems have to arise as a sequence of solutions to shorter-range measurable ones, each of which shows positive progress. Our only hope to avoid a total nuclear war is through piecemeal quantifiable progress.¬† We need to use diplomacy, international cooperation, and monitoring technologies to reduce the world‚Äôs nuclear arsenal one warhead at a time. This piecemeal, incremental approach may or may not work, but it‚Äôs the only one we have.¬†</p>



<p><strong>Summary: think of the long term, but act and measure in the short term.</strong></p>



<p>It is appropriate for philosophers to speculate on hypothetical scenarios centuries into the future and wonder whether actions we take today could influence them. However, I do not believe such an approach will, in practice, lead to a positive impact on humanity and, if taken to the extreme, may even have negative repercussions. We should maintain epistemic humility. Statements about probabilities involving fractions of percentage points, or human lives in the trillions, should raise alarm bells. Such calculations can be particularly problematic since they can lead to a ‚Äúthe end justifies the means‚Äù attitude, which can accept any harm to currently living people in the name of the practically infinite multitudes of future hypothetical beings. </p>



<p>We need to maintain the invariant that, even if motivated by the far-off future, our actions ‚Äúfirst do no harm‚Äù to living, breathing humans. Indeed, as I mentioned, even longtermists don‚Äôt wake up every morning thinking about how to reduce the chance that something terrible happens in the year 1,000,000 AD by 0.001%. Instead, many longtermists care about particular risks because they believe these risks are likely in the near-term future. If you manage to make a convincing case that humanity faces a real chance of near-term total destruction, then most people would agree that this is very very bad, and we should act to prevent it. It doesn‚Äôt matter whether humanity‚Äôs extinction is two times or a zillion times worse than the death of half the world‚Äôs population. Talking about trillions of hypothetical beings thousands of years into the future only turns people off. There is a reason that <a href="https://en.wikipedia.org/wiki/Pascal%27s_wager">Pascal‚Äôs Wager</a> is not such a winning argument, and I have yet to meet someone who converted to a particular religion because it had the grisliest version of hell.</p>



<p>This does not mean that thinking and preparing for longer-term risks is pointless. Maintaining seed banks, monitoring asteroids, researching pathogens, designing vaccine platforms, and working toward nuclear disarmament, are all essential activities that society should take. Whenever a new technology emerges, artificial intelligence included, it is crucial to consider how it can be misused or lead to unintended consequences. By no means do I argue that humanity should spend all of its resources only on actions that have a direct economic benefit. Indeed, the whole enterprise of basic science is built on pursuing directions that, in the short term, increase our knowledge but do not have practical utility. Progress is not measured only in dollars, but it should be measured somehow. Epistemic humility also means that we should be content with working on direct, measurable proxies, even if they are not perfect matches for the risk at hand. For example, the probability of extinction via total nuclear war might not be a direct function of the number of deployed nuclear warheads. However, the latter is still a pretty good proxy for it.</p>



<p>Similarly, even if you are genuinely worried about long-term risk, I suggest you spend most of your time in the present. Try to think of short-term problems whose solutions can be verified, which might advance the long-term goal. A ‚Äúproblem‚Äù does not have to be practical: it can be a mathematical question, a computational challenge, or an empirically verifiable prediction. The advantage is that even if the long-term risk stays hypothetical or the short-term problem turns out to be irrelevant to it, you have still made measurable progress. As <a href="https://windowsontheory.org/2022/05/03/philosophy-of-science-and-the-blockchain-a-book-review/">has happened before</a>, to make actual progress on solving existential risk, the topic needs to move from philosophy books and blog discussions into empirical experiments and concrete measures.</p>



<p><strong>Acknowledgments:</strong> Thanks to Scott Aaronson and Ben Edelman for commenting on an earlier version of this post.</p></div>
    </content>
    <updated>2022-05-23T14:37:36Z</updated>
    <published>2022-05-23T14:37:36Z</published>
    <category term="Philosophizing"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2022-05-24T10:37:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=20050</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/05/23/hilberts-lost-problem/" rel="alternate" type="text/html"/>
    <title>Hilbert‚Äôs Lost Problem</title>
    <summary>Mathematics consists in proving the most obvious thing in the least obvious way‚ÄîP√≥lya. David Hilbert famously presented 23 important open mathematical problems at the International Congress of Mathematicians in Paris in 1900. He intended to include a 24th on the simplicity of proofs. Today we discuss this problem, which was ‚Äúlost‚Äù until the historian R√ºdiger [‚Ä¶]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<i>Mathematics consists in proving the most obvious thing in the least obvious way‚ÄîP√≥lya.</i><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/05/23/hilberts-lost-problem/285px-david_hilbert_1886/" rel="attachment wp-att-20070"><img alt="" class="alignright wp-image-20070" height="170" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/05/285px-David_Hilbert_1886.jpg?resize=130%2C170&amp;ssl=1" width="130"/></a></p>
<p>
David Hilbert famously presented 23 important open mathematical problems at the International Congress of Mathematicians in Paris in 1900. He intended to include a 24th on the simplicity of proofs.</p>
<p>
Today we discuss this problem, which was ‚Äúlost‚Äù until the historian R√ºdiger Thiele discovered it in Hilbert‚Äôs papers in 2000 and brought it to light in a <a href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=C970003BC10AB452B346D45B8AAE14B6?doi=10.1.1.97.7633&amp;rep=rep1&amp;type=pdf">paper</a> for the American Mathematical Monthly.</p>
<p>
I (Ken) have long wondered why Hilbert targeted the number 23 for his list. That some of his <a href="https://en.wikipedia.org/wiki/Hilbert's_problems">problems</a> have broad, vague statements tells me he could have altered their number. To be sure, he discussed only 10 in his actual 1900 lecture; the rest appeared in his long <a href="http://www.ams.org/journals/bull/1902-08-10/S0002-9904-1902-00923-3/S0002-9904-1902-00923-3.pdf">article</a> that year. Until Dick drafted this post and I found Thiele‚Äôs article, I had not known about a No. 24‚Äîa nice factorial number. </p>
<p>
As <a href="https://royalsocietypublishing.org/doi/epdf/10.1098/rsta.2018.0040">discussed</a> by In√™s Hipolito and Reinhard Kahle, in a <a href="https://royalsocietypublishing.org/toc/rsta/2019/377/2140">special issue</a> of the UK Royal Society <em>Philosophical Transactions A</em> devoted to Hilbert‚Äôs 24th, there were only faint traces of it until Thiele‚Äôs discovery. They decline to guess Hilbert‚Äôs motives for leaving it out, but I venture this: Hilbert could not agree with himself on the terms by which to state it, even broadly. How to quantify simplicity was already the subject of Dick‚Äôs draft, into which we blend.</p>
<p>
</p><p/><h2> P√≥lya on Proofs </h2><p/>
<p/><p>
One simple question is whether a human notion of simpler proof would accord with, say, that of a Martian. George P√≥lya was one of a vanguard of Hungarian emigr√© scientists who came to be called <a href="https://en.wikipedia.org/wiki/The_Martians_(scientists)">The Martians</a> after another of them, the physicist Leo Szilard, gave this answer to Enrico Fermi‚Äôs question of why aliens had not been detected when life in the universe should be plentiful:</p>
<blockquote><p>
‚ÄúThey are among us, but they call themselves Hungarians.‚Äù
</p></blockquote>
<p>
Kidding aside, this could set up a <a href="https://en.wikipedia.org/wiki/Linguistic_relativity">Sapir-Whorf</a> type hypothesis that humans from disparate linguistic groups and mathematical cultures could have different values for proofs. Even if so, the joke would be on non-Hungarians, because Paul Erd≈ës, whose idea of ‚ÄúProofs from The Book‚Äù set the internationally recognized standard of proof elegance, was also a ‚ÄúMartian.‚Äù</p>
<p>
P√≥lya‚Äôs quote above hits the nail on the head. For an example, consider the <a href="https://www.math.utah.edu/~alfeld/math/q1.html">theorem</a> that: </p>
<blockquote><p><b>Theorem 1</b> <em> The square root of <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is irrational. </em></p></blockquote>
<p>
The well-known proof begins by supposing not: </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/05/23/hilberts-lost-problem/proof-6/" rel="attachment wp-att-20055"><img alt="" class="aligncenter wp-image-20055" height="460" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/05/proof.png?resize=450%2C460&amp;ssl=1" width="450"/></a></p>
<p>
One might claim that this famous proof is not obvious‚Äîdo you agree?</p>
<p>
</p><p/><h2> A Measure </h2><p/>
<p/><p>
Now consider the general task of proving statements of this form:</p>
<blockquote><p><b>Theorem 2</b> <em><a name="pos"/> For all <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/>, 	</em></p><em>
<p align="center"><img alt="\displaystyle  f(n) &gt; 0. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28n%29+%3E+0.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
</em><p><em> </em></p></blockquote>
<p/><p>
Think this as an encoding of an interesting property: For example, for each <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> there is a prime <img alt="{p&gt;n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%3En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Or for each planar graph <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> there is some four coloring of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Or <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p>
To make this more concrete, let us base proofs on the Peano axioms for arithmetic, and suppose that <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is well-defined in this system. Note that proving <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> to be total computable is not the same as proving that all its values are <em>positive</em> as Theorem <a href="https://rjlipton.wpcomstaging.com/feed/#pos">2</a> asserts. In case Theorem <a href="https://rjlipton.wpcomstaging.com/feed/#pos">2</a> is provable, we have two key parameters:</p>
<li>D: The length of the definition of <img alt="{f(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.
</li><li>P: The length of the full proof of Theorem <a href="https://rjlipton.wpcomstaging.com/feed/#pos">2</a>.
<p/><p><br/>
Our proof simplicity measure is then 	</p>
<p align="center"><img alt="\displaystyle  M=\frac{P}{D} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M%3D%5Cfrac%7BP%7D%7BD%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/></p>
<p/><h2> Some Instances </h2><p/>
<p/><p>
Here are some keys to understanding the value <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> intuitively:</p>
<ol>
<li> For known provable problems we might have that <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is not too large
</li><li> For classic problems like the Four-Color problem we might have that <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is huge. Think of the proof that arises in this case.
</li><li> For many chess positions where one side can win, say checkmate in 30 moves, the proof of that is likewise huge. Crafting chess problems where the proof is both crisp and hard to find is a centuries-old art.
</li><li> For open problems, <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is currently infinite.
</li><li> But for practical software we get something bounded. The trouble here is that <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> is potentially huge and could be the size of <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>.
</li></ol>
<p>
Consider for the last case a program that calculates your tax payment based on the US tax code, for example. The code has wording like:  </p>
<blockquote><p>
An apparently insignificant discrepancy between the wording in the Statutes at Large and the wording in some editions of the U.S. Code with respect to a provision of the Internal Revenue Code (specifically, the words ‚Äúany papers‚Äù in the first sentence of 6104(a)(1)(A) is described by the U.S. Court of Appeals for the District of Columbia in the case of Tax Analysts v. Internal Revenue Serv., 214 F.3d 179 (D.C. Cir. 2000), in footnote 1. According to the Court, some versions of the U.S. Code show the text as ‚Äúany paper‚Äù while the Statutes at Large version shows the text as ‚Äúany papers.‚Äù
</p></blockquote>
<p>
Thus the proof <img alt="{P}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> could be the same size of <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. Thus,</p>
<p>
Case: <img alt="{P &gt;&gt; D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP+%3E%3E+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. This is the usual proof of a classic problem like the four-color problem. Huge proof. </p>
<p>
Case: <img alt="{P \approx D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BP+%5Capprox+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. This is like a simple problem or like a proof of a complex program with tons of bits in its description. </p>
<p>
</p><p/><h2> Proofs and Software </h2><p/>
<p/><p>
My famous‚Äîinfamous?‚Äî<a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/social.pdf">paper</a> with Alan Perlis and Rich de Millo raised the related issue in the first sentence of our abstract:</p>
<blockquote>
<p>
It is argued that formal verifications of programs, no matter how obtained, will not play the same key role in the development of computer science and software engineering as proofs do in mathematics.</p>
</blockquote>
<p>
This argument made over four decades ago has been argued by critics as being wrong. Take a look at <a href="https://blog.computationalcomplexity.org/2021/06/i-went-to-debate-about-program-verif.html">this</a> for comments about the recent <a href="https://scp.cc.gatech.edu/2021/05/26/debate-that-changed-programming-living-history/">debate</a> on the paper moderated by Harry Lewis.</p>
<p>
We claim that we were correct but for a different reason that we made in the original paper. We got it <b>right</b> but for the wrong reason. The real reason is alluded to in this <a href="http://www.cs.ox.ac.uk/publications/publication8316-abstract.html">statement</a> by Tony Hoare, whose programme of proofs for programs partly spurred our paper:</p>
<blockquote>
<p>
Ten years ago, researchers into formal methods (and I was the most mistaken among them) predicted that the programming world would embrace with gratitude every assistance promised by formalisation to solve the problems of reliability that arise when programs get large and more safety-critical. Programs have now got very large and very critical‚Äîwell beyond the scale which can be comfortably tackled by formal methods. ‚Ä¶ It has turned out that the world just does not suffer significantly from the kind of problem that our research was originally intended to solve.
</p></blockquote>
<p>
See also his 1996 <a href="http://176.9.41.242/docs/math/1996-hoare.pdf">position paper</a>, ‚ÄúHow Did Software Get So Reliable Without Proof?‚Äù</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Does this measure <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> shed some light on the problems of program verification? Is it useful? Would it have satisfied Hilbert? Hilbert‚Äôs handwritten note discovered by Thiele showed him thinking in terms of proofs via polynomial invariants and equations‚Äîhence maybe not at a brute level of counting symbols.</p>
<p/><p><br/>
[some format fixes, young Hilbert picture]</p></li></font></font></div>
    </content>
    <updated>2022-05-23T11:20:42Z</updated>
    <published>2022-05-23T11:20:42Z</published>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="David Hilbert"/>
    <category term="open problems"/>
    <category term="proof complexity"/>
    <category term="verification"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>G√∂del's Lost Letter and P=NP</title>
      <updated>2022-05-24T10:37:28Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8785234285731310998</id>
    <link href="http://blog.computationalcomplexity.org/feeds/8785234285731310998/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/05/in-1960s-students-protested-vietnam.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8785234285731310998" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/8785234285731310998" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/05/in-1960s-students-protested-vietnam.html" rel="alternate" type="text/html"/>
    <title>In the 1960's students protested the Vietnam war!/In 1830 students protested... Math?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>¬†I was at SUNY Stonybrook for college 1976-1980.¬†</p><p>I remember one student protest about a change to the calendar that (I think) would have us go home for winter break and then come back for finals.¬† I don't recall how that turned out.¬†</p><p>However I had heard about the protests in the 1960's over the Vietnam war. Recall that there was a draft back then so college students were directly affected.¬†</p><p>I was reading a book `<i>Everything you know is wrong'</i> which noted that some people thought the first time there were student protests was in the 1960's but this is not true. (Not quite as startling as finding out that a ships captain cannot perform weddings.)¬†</p><p>It pointed to <i>The 1830 Conic Section Rebellion. </i>I quote Wikipedia (full entry is¬†<a href="https://en.wikipedia.org/wiki/Conic_Sections_Rebellion">here</a>)</p><p><i>Prior to the introduction of blackboards, Yale students had been allowed to consult diagrams in their textbooks when solving geometry problems pertaining to conic sections ‚Äì even on exams. When the students were no longer allowed to consult the text, but were instead required to draw their own diagrams on the blackboard, they refused to take the final exam. As a result forty-three of the ninety-six students ‚Äì among them, Alfred Stille, and Andrew Calhoun, the son of John C. Calhoun (Vice Pres a the time) ‚Äì were summarily expelled, and Yale authorities warned neighboring universities against admitting them.</i></p><p>Random Thoughts</p><p>1) From my 21st century prospective I am on the students side. It seems analogous to allowing students to use calculators-- which I do allow.¬†</p><p>2) From my 21st century prospective the punishment seems unfair.¬†</p><p>3) The notion of a school telling other schools to not admit student- I do not think this would happen now, and might even be illegal (anti-trust).</p><p>4) I am assuming¬† the students wanted to be able to consult their text out of some principle: we want to learn concepts not busy work.¬† And again, from my prospective I agree that it was busy work.¬†</p><p>5) Since all of my thoughts are from a 21st century prospective, they may be incorrect, or at least not as transferable to the 1830 as I think. (Paradox: My ideas may not be as true as I think. But if I think that...)¬†</p><p>6) I try to avoid giving busy work. When I teach Decidability and Undecidability I NEVER have the students actually write a Turing Machine that does something. In other cases I also try to make sure they never have to do drudge work.¬† And I might not even be right in the 21st century- some of my colleagues tell me its good for the students to get their hands dirty (perhaps just a little) with real TM to get a feel for the fact that they can do anything.¬†</p><p>7) The only student protests I hear about nowadays are on political issues. Do you know of any student protests on issues of how they are tested or what the course requirements are, or something of that ilk? I can imagine my discrete math students marching with signs that say:¬†</p><p>DOWN WITH INDUCTION!</p><p><br/></p><p><br/></p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2022-05-23T02:52:00Z</updated>
    <published>2022-05-23T02:52:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-05-24T09:50:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2205.10348</id>
    <link href="http://arxiv.org/abs/2205.10348" rel="alternate" type="text/html"/>
    <title>General Ramified Recurrence and Polynomial-time Completeness</title>
    <feedworld_mtime>1653264000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Danner:Norman.html">Norman Danner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Royer:James_S=.html">James S. Royer</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2205.10348">PDF</a><br/><b>Abstract: </b>We exhibit a sound and complete implicit-complexity formalism for functions
feasibly computable by structural recursions over inductively defined data
structures. Feasibly computable here means that the structural-recursive
definition runs in time polynomial in the size of the representation of the
inputs where these representations may make use of data sharing. Inductively
defined data structures here includes lists and trees. Soundness here means
that the programs within the implicit-complexity formalism have feasible run
times. Completeness here means that each function computed by a feasible
structural recursion has a program in the implicit-complexity formalism. This
paper is a follow up on the work of Avanzini, Dal Lago, Martini, and Zorzi who
focused on the soundness of such formalisms but did not consider the question
of completeness.
</p></div>
    </summary>
    <updated>2022-05-23T22:37:36Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2022-05-23T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/05/22/professor-in-computer-science-and-mathematics-at-warwick-at-university-of-warwick-apply-by-june-1-2022/</id>
    <link href="https://cstheory-jobs.org/2022/05/22/professor-in-computer-science-and-mathematics-at-warwick-at-university-of-warwick-apply-by-june-1-2022/" rel="alternate" type="text/html"/>
    <title>Professor in Computer Science and Mathematics at Warwick at University of Warwick (apply by June 1, 2022)</title>
    <summary>The Department of Computer Science at the University of Warwick and the Warwick Mathematics Institute invite applications for a full Professor post in the areas on the interface of Computer Science and Mathematics, including Algorithms and Complexity, Theoretical Computer Science, and Discrete Mathematics. Website: https://warwick.ac.uk/dimap/dimap_post_2022/ Email: A.Czumaj@warwick.ac.uk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The Department of Computer Science at the University of Warwick and the Warwick Mathematics Institute invite applications for a full Professor post in the areas on the interface of Computer Science and Mathematics, including Algorithms and Complexity, Theoretical Computer Science, and Discrete Mathematics.</p>
<p>Website: <a href="https://warwick.ac.uk/dimap/dimap_post_2022/">https://warwick.ac.uk/dimap/dimap_post_2022/</a><br/>
Email: A.Czumaj@warwick.ac.uk</p></div>
    </content>
    <updated>2022-05-22T22:55:06Z</updated>
    <published>2022-05-22T22:55:06Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-05-24T10:37:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/076</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/076" rel="alternate" type="text/html"/>
    <title>TR22-076 |  Average-Case Hardness of Proving Tautologies and Theorems | 

	Hunter Monroe</title>
    <summary>We consolidate two widely believed conjectures about tautologies---no optimal proof system exists, and most require superpolynomial size proofs in any system---into a $p$-isomorphism-invariant condition satisfied by all paddable $\textbf{coNP}$-complete languages or none. The condition is: for any Turing machine (TM) $M$ accepting the language, $\textbf{P}$-uniform input families requiring superpolynomial time by $M$ exist (equivalent to the first conjecture) and appear with positive upper density in an enumeration of input families (implies the second). In that case, no such language is easy on average (in $\textbf{AvgP}$) for a distribution applying non-negligible weight to the hard families.

The hardness of proving tautologies and theorems is likely related. Motivated by the fact that arithmetic sentences encoding "string $x$ is Kolmogorov random" are true but unprovable with positive density in a finitely axiomatized theory $\mathcal{T}$ (Calude and J√ºrgensen), we conjecture that any propositional proof system requires superpolynomial size proofs for a dense set of $\textbf{P}$-uniform families of tautologies encoding "there is no $\mathcal{T}$ proof of size $\leq t$ showing that string $x$ is Kolmogorov random". This implies the above condition.

The conjecture suggests that there is no optimal proof system because undecidable theories help prove tautologies and do so more efficiently as axioms are added, and that constructing hard tautologies seems difficult because it is impossible to construct Kolmogorov random strings. Similar conjectures that computational blind spots are manifestations of noncomputability would resolve other open problems.</summary>
    <updated>2022-05-22T05:41:55Z</updated>
    <published>2022-05-22T05:41:55Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-05-24T10:37:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/075</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/075" rel="alternate" type="text/html"/>
    <title>TR22-075 |  Vanishing Spaces of Random Sets and Applications to Reed-Muller Codes | 

	Prahladh Harsha, 

	Siddharth Bhandari, 

	Srikanth Srinivasan, 

	Ramprasad Saptharishi</title>
    <summary>We study the following natural question on random sets of points in $\mathbb{F}_2^m$:
    

Given a random set of $k$ points $Z=\{z_1, z_2, \dots, z_k\} \subseteq \mathbb{F}_2^m$, what is the dimension of the space of degree at most $r$ multilinear polynomials that vanish on all points in $Z$?


We show that, for $r \leq \gamma m$ (where $\gamma &gt; 0$ is a small, absolute constant) and $k = (1-\epsilon) \cdot {m \choose {\leq r}}$ for any constant $\epsilon &gt; 0$, the space of degree at most $r$ multilinear polynomials vanishing on a random set $Z = \{z_1,\ldots, z_k\}$ has dimension exactly ${m \choose {\leq r}} - k$ with probability $1 - o(1)$. This bound shows that random sets have a much smaller space of degree at most $r$ multilinear polynomials vanishing on them, compared to the worst-case bound (due to Wei (IEEE Trans. Inform. Theory, 1991)) of ${m \choose{\leq r}} - {{\log_2 k}\choose {\leq r}} \gg {m\choose{\leq r}} - k$. 

    Using this bound, we show that high-degree Reed-Muller codes ($\text{RM}(m,d)$ with $d &gt; (1-\gamma) m$) ``achieve capacity'' under the Binary Erasure Channel in the sense that, for any $\epsilon &gt; 0$, we can recover from $(1 - \epsilon) \cdot {m\choose {\leq m-d-1}}$ random erasures with probability $1 - o(1)$. This also implies that $\text{RM}(m,d)$ is also efficiently decodable from $\approx {m\choose {\leq m-(d/2)}}$ random errors for the same range of parameters.</summary>
    <updated>2022-05-21T19:53:52Z</updated>
    <published>2022-05-21T19:53:52Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-05-24T10:37:23Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/05/21/congratulations-dr-osegueda</id>
    <link href="https://11011110.github.io/blog/2022/05/21/congratulations-dr-osegueda.html" rel="alternate" type="text/html"/>
    <title>Congratulations, Dr. Osegueda!</title>
    <summary>Martha Osegueda, one of Mike Goodrich‚Äôs students at UC Irvine, successfully defended her doctoral dissertation yesterday. Martha is originally Salvadorean, and came to UCI from an undergraduate degree at the University of Texas El Paso. Her research at UCI has spanned a wide variety of topics in graph drawing, phylogeny, computational geometry, and parallel query complexity:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Martha Osegueda, one of Mike Goodrich‚Äôs students at UC Irvine, successfully defended her doctoral dissertation yesterday. Martha is originally Salvadorean, and came to UCI from an undergraduate degree at the University of Texas El Paso. Her research at UCI has spanned a wide variety of topics in graph drawing, phylogeny, computational geometry, and parallel query complexity:</p>

<ul>
  <li>
    <p>‚ÄúMinimum-width drawings of phylogenetic trees‚Äù from <em>COCOA</em> 2019 (<a href="https://doi.org/10.1007/978-3-030-36412-0_4">doi:10.1007/978-3-030-36412-0_4</a>) is about drawing evolutionary trees compactly. For the version of tree drawing they study, it turns out to be NP-hard when the order of the leaves is unconstrained but linear-time solvable for fixed leaf orderings.</p>
  </li>
  <li>
    <p>‚ÄúReconstructing binary trees in parallel‚Äù from <em>SPAA</em> 2020 (<a href="https://arxiv.org/abs/2006.15259">arXiv:2006.15259</a>) involved the reconstruction of evolutionary trees from queries asking which pair of a triple of species is closest.</p>
  </li>
  <li>
    <p>‚ÄúConcatenation arguments and their applications to polyominoes and polycubes‚Äù, in <em>CGTA</em> 2021 (<a href="https://doi.org/10.1016/j.comgeo.2021.101790">doi:10.1016/j.comgeo.2021.101790</a>) and ‚ÄúOn the number of compositions of two polycubes‚Äù from <em>EuroComb</em> 2021 (<a href="https://doi.org/10.1007/978-3-030-83823-2_12">doi:10.1007/978-3-030-83823-2_12</a>) strengthen the known lower bounds on the growth rates of polyominoes and polycubes, using arguments based on counting ways of gluing pairs of smaller polyforms into larger ones.</p>
  </li>
  <li>
    <p>‚ÄúAngles of arc-polygons and Lombardi drawings of cacti‚Äù, from <em>CCCG</em> 2021 (<a href="https://arxiv.org/abs/2107.03615">arXiv:2107.03615</a>) is my only collaboration with Martha and one <a href="https://11011110.github.io/blog/2021/07/10/angles-arc-triangles.html">I have posted about here</a>. It characterizes the vertex angles that are possible in triangles with circular-arc sides, and uses that characterization to prove the existence of a Lombardi drawing for any cactus graph.</p>
  </li>
  <li>
    <p>‚ÄúParallel network mapping algorithms‚Äù from <em>SPAA</em> 2021 (<a href="https://doi.org/10.1145/3409964.3461822">doi:10.1145/3409964.3461822</a>) and ‚ÄúMapping Networks via parallel \(k\)th-hop traceroute queries‚Äù from <em>STACS</em> 2022 (<a href="https://doi.org/10.4230/LIPIcs.STACS.2022.4">doi:10.4230/LIPIcs.STACS.2022.4</a>) are on traceroute-like problems: mapping the structure of a computer communication network using a small number of parallel rounds of pings to determine distances from nodes on the network.</p>
  </li>
  <li>
    <p>‚ÄúTaming the knight‚Äôs tour: Minimizing turns and crossings‚Äù from <em>FUN</em> 2021 and <em>TCS</em> 2022 (<a href="https://doi.org/10.1016/j.tcs.2021.12.002">doi:10.1016/j.tcs.2021.12.002</a>) shows how to move a chess knight around all of the squares of a chessboard, touching each square once, so that the number of times the knight‚Äôs path crosses itself or deviates from a straight path are both simultaneously approximately minimized.</p>
  </li>
  <li>
    <p>‚ÄúDiamonds are forever in the blockchain: Geometric polyhedral point-set pattern matching‚Äù is her newest work, in submission. It studies problems of aligning a polyhedron to sample points from a similarly-shaped surface, motivated by an application in tracing the provenance of ethically sourced diamonds.</p>
  </li>
</ul>

<p>Despite all of these good publications, Mike tells me that it was difficult to persuade Martha that she had done enough for a doctorate. But she had, easily, and now she‚Äôs moving on to a position at Meta. Congratulations, Martha!</p>

<p>(<a href="https://mathstodon.xyz/@11011110/108342653334960089">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2022-05-21T16:49:00Z</updated>
    <published>2022-05-21T16:49:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-05-22T00:02:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=22620</id>
    <link href="https://gilkalai.wordpress.com/2022/05/20/oliver-janzer-and-benny-sudakov-settled-the-erdos-sauer-problem/" rel="alternate" type="text/html"/>
    <title>Oliver Janzer and  Benny Sudakov Settled the Erd≈ës-Sauer Problem</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Norbert Sauer The news in brief:¬† In the new paper Resolution of the Erd≈ës-Sauer problem on regular subgraphs Oliver Janzer and Benny Sudakov proved that any graph G with vertices and more than edges contains a k-regular subgraph. This bound ‚Ä¶ <a href="https://gilkalai.wordpress.com/2022/05/20/oliver-janzer-and-benny-sudakov-settled-the-erdos-sauer-problem/">Continue reading <span class="meta-nav">‚Üí</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><img alt="Norbert-Sauer" class="alignnone  wp-image-22703" height="243" src="https://gilkalai.files.wordpress.com/2022/05/norbert-sauer.jpg" width="162"/></p>
<p><a href="https://contacts.ucalgary.ca/info/math/profiles/101-152966">Norbert Sauer</a></p>
<p>The news in brief:¬† In the new paper <a href="https://arxiv.org/abs/2204.12455">Resolution of the Erd≈ës-Sauer problem on regular subgraphs</a> Oliver Janzer and Benny Sudakov proved <span class="abstract-full has-text-grey-dark mathjax" id="2204.12455v1-abstract-full"> that any graph G with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> vertices and more than <img alt="C_kn \log \log n" class="latex" src="https://s0.wp.com/latex.php?latex=C_kn+%5Clog+%5Clog+n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> edges contains a <span class="MathJax" id="MathJax-Element-12-Frame"><span class="math" id="MathJax-Span-52"><span class="mrow" id="MathJax-Span-53"><span class="mi" id="MathJax-Span-54">k</span></span></span></span>-regular subgraph. This bound matches the lower bound of Pyber, R√∂dl and Szemer√©di and thus completely resolved the well-known problem of Erd≈ës and Sauer from 1975. The new bound </span><span class="abstract-full has-text-grey-dark mathjax" id="2204.12455v1-abstract-full">substantially improves an 1985 result of Pyber, who showed that <img alt="n \log n " class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Clog+n+&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>¬†<span class="MathJax" id="MathJax-Element-13-Frame"><span class="math" id="MathJax-Span-55"><span class="mrow" id="MathJax-Span-56"><span class="mi" id="MathJax-Span-62"> edges</span></span></span></span> suffice.</span></p>
<h3>The history of the <span class="abstract-full has-text-grey-dark mathjax" id="2204.12455v1-abstract-full">Erd≈ës -Sauer</span> problem 1975-2022</h3>
<p>Erdos and Sauer asked in 1975 how many edges (let‚Äôs denote the minimum number <img alt="f_k(n)" class="latex" src="https://s0.wp.com/latex.php?latex=f_k%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>) for an <em>n</em>-vertex graph guarantee a <em>k</em>-regular subgraph. In 1985 Laszlo Pyber proved that for some <img alt="C_k" class="latex" src="https://s0.wp.com/latex.php?latex=C_k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> every graph with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> edges and <img alt="C_kn \log n" class="latex" src="https://s0.wp.com/latex.php?latex=C_kn+%5Clog+n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> edges contains a <em>k</em>-regular graph. A few years later Pyber, Rodl and Szemeredi found a construction of a graph with<em> n</em> vertices and¬† <img alt="c n \log \log n " class="latex" src="https://s0.wp.com/latex.php?latex=c+n+%5Clog+%5Clog+n+&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> edges that contains no k-regular subgraph for every <img alt="k \ge 3" class="latex" src="https://s0.wp.com/latex.php?latex=k+%5Cge+3&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>. (The paper appeared in 1995 but the result is from the late 80s.)</p>
<p>Paul <span class="abstract-full has-text-grey-dark mathjax" id="2204.12455v1-abstract-full">Erd≈ës¬† mentioned the problem among his favorites in a famous paper in 1980 (Vol 1. Issue 1. of Combinatorica) and mentioned the results of Pyber and of Pyber, Rodl and Szemeredi in his 1989 paper.</span></p>
<p>Oliver and Benny proved an upper bound on the number of edges of k-regular free graphs that matches the Pyber, Rodl and Szemeredi lower bound. <span style="color: #0000ff;"><strong>Congratulations!</strong></span></p>
<h3>AFK84 and the Berge-Sauer problem</h3>
<p><strong>Theorem: </strong>Every graph (or hypergraph) <em>G</em> with <em>n</em>¬†vertices and <em>2n+1</em>¬†edges contains a nontrivial subgraph <em>H</em> with all vertex-degrees divisible by 3.</p>
<p>This is a theorem of Noga Alon, ¬†Shmuel Friedland, and me (AFK) from 1984.)</p>
<p><strong>Before the proof</strong>: If we want to get a subgraph with all vertex degrees even then we need<em> n</em> edges (or <em>n+1</em> edges for hypergraphs). This has a simple linear algebra proof which also gives an efficient algorithm.</p>
<p><strong>From-scratch proof scatch: </strong>Associate to every edge <em>e</em> of the graph a variable <img alt="x_e" class="latex" src="https://s0.wp.com/latex.php?latex=x_e&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>. Consider the two polynomial</p>
<p><em>P=</em> <img alt="\prod_{v \in V(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cprod_%7Bv+%5Cin+V%28G%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> <img alt="((\sum_{e: v \in e}x^2_e)^2-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%28%5Csum_%7Be%3A+v+%5Cin+e%7Dx%5E2_e%29%5E2-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>, and</p>
<p>Q=<img alt="\prod_{e\in E(G)}(x_e^2-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cprod_%7Be%5Cin+E%28G%29%7D%28x_e%5E2-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/></p>
<p>If the theorem is false then <em>P-Q=0, </em>as polynomials over the field with three elements. This is impossible since P is a polynomial of degree <em>4n</em> while Q is a polynomial which has a monomial of degree <em>4n+2</em> with nonzero coefficient.</p>
<p>The theorem follows more directly from a theorem of Chevallay and even more directly from a theorem of Olson.</p>
<p>AFK84 was a necessary ingredients of Pyber 1985 upper bound as well as the Janzer-Sudakov new upper bound. It will be very nice to get rid of this ingredient. AFK84 came a little short of proving the Berge-Sauer conjecture that every 4-regular graph contains a 3-regular subgraph.¬† This conjecture was proved in a 1982 paper by Taskinov.</p>
<h3>Three problems</h3>
<p>A) Is it true that every graph with n vertices and 2n+1 edges with maximum degree 5 contains a 3-regular graph of type I? (Namely a 3-regular 3-edge colorable subgraph.)</p>
<p>B) How many edges for a 3-uniform hypergraph on n vertices guarantees a k-regular sub-hypergraph? (Here we refer to ‚Äú3-regular hypergraph as a hypergraph so that every vertex belongs to three (or zero) edges. You can also demand that every pair of vertices belongs to three or zero edges.)</p>
<p>C) Is there a polynomial-time algorithm to find a<em> r</em>-regular subgraph for a graph with n vertices and <img alt="n^{1.01}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1.01%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> edges.</p>
<h3>Climbing the Turan ladder</h3>
<p>Climbing the Turan ladder refers to unavoidable subgraphs of a graph of n vertices and m edges as m grows. (The Erdos-Renyi ladder is a similar notion for random graphs.)</p>
<p>Problem A) is related to the following:</p>
<p>When <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> is roughly <img alt="2n" class="latex" src="https://s0.wp.com/latex.php?latex=2n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/></p>
<p><strong>a)</strong> (for <img alt="m=2n-2" class="latex" src="https://s0.wp.com/latex.php?latex=m%3D2n-2&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>) you must have a subgraph with all degrees larger than 2</p>
<p><strong>b)</strong> (for <img alt="m= 2n+1" class="latex" src="https://s0.wp.com/latex.php?latex=m%3D+2n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>) you must have a subgraph with all degrees divisible by 3 (AFK84), and</p>
<p><strong>c)</strong> (for <img alt="m=2n+1" class="latex" src="https://s0.wp.com/latex.php?latex=m%3D2n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/>) you also must have a subgraph <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> such that you can color its edges with three colors so that every (non-isolated) vertex have neighbors of the all color.</p>
<p>We don‚Äôt know what <img alt="m" class="latex" src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> guarantees</p>
<p><strong>d)</strong> such an <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> so that for every vertex the number of edges of each color is the same modulo three.</p>
<p>Condition<strong> d)</strong> is stronger than both <strong>b)</strong> and <strong>c)</strong> and each of them is stronger than<strong> a)</strong>. Both<strong> a), b)</strong> and <strong>c)</strong> extend to hypergraphs.</p>
<h3>The relevance of Christos‚Äôs classes and the PME-conjecture.</h3>
<p>The <strong>Probabilistic Method is Efficient (PME)</strong> <strong>Conjecture</strong> asserts: Every mathematical proof based on the probabilistic method can be transformed into an efficient (randomized) algorithm.</p>
<p>This is a vague and controversial conjecture that I mentioned in the post <a href="https://gilkalai.wordpress.com/2013/08/08/poznan-random-structures-and-algorithms-2013/" rel="bookmark">Pozna≈Ñ: Random Structures and Algorithms¬†2013</a>. (There I¬† referred to it as the Kalai-Spencer conjecture.) Now, if we can get rid of AFK84 and find a purely combinatorial/probabilistic¬† proof even just for the fact that every graph with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> vertices and <img alt="n^{1.01}" class="latex" src="https://s0.wp.com/latex.php?latex=n%5E%7B1.01%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002"/> edges contains a 3-regular subgraph, this would be nice on its own and may lead (especially for PME-believers) to an efficient algorithm. AFK84 is not supported by an efficient algorithm and, in fact it is related to one of Christos Papadimitriou‚Äôs classes describing the algorithmic difficulty for finding objects guarantees by mathematical proofs. See Papadimitriou‚Äôs¬† 1994 paper: <a href="https://www.sciencedirect.com/science/article/pii/S0022000005800637" id="OT-8y8wGxeEJ"><span dir="ltr">On the complexity of the parity argument and other inefficient proofs of existence</span>‚Äè.</a></p></div>
    </content>
    <updated>2022-05-20T13:00:53Z</updated>
    <published>2022-05-20T13:00:53Z</published>
    <category term="Combinatorics"/>
    <category term="Benny Sudakov"/>
    <category term="Oliver Janzer"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2022-05-24T10:37:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/074</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/074" rel="alternate" type="text/html"/>
    <title>TR22-074 |  On Randomized Reductions to the Random Strings | 

	Michael Saks, 

	Rahul Santhanam</title>
    <summary>We study the power of randomized polynomial-time non-adaptive reductions to the problem of approximating Kolmogorov complexity and its polynomial-time bounded variants.

As our first main result, we give a sharp dichotomy for randomized non-adaptive reducibility to approximating Kolmogorov complexity. We show that any computable language $L$ that has a randomized polynomial-time non-adaptive reduction (satisfying a natural honesty condition) to $\omega(\log(n))$-approximating the Kolmogorov complexity is in AM $\cap$ coAM. On the other hand, using results of Hirahara [H20], it follows that every language in NEXP has a randomized polynomial-time non-adaptive reduction (satisfying the same honesty condition as before) to $O(\log(n))$-approximating the Kolmogorov complexity.

As our second main result, we give the first negative evidence against the NP-hardness of polynomial-time bounded Kolmogorov complexity with respect to randomized reductions. We show that for every polynomial t', there is a polynomial t such that if there is a randomized time t' non-adaptive reduction (satisfying a natural honesty condition) from SAT to $\omega(\log(n))$-approximating $K^t$ complexity, then either NE = coNE or E has sub-exponential size non-deterministic circuits infinitely often.</summary>
    <updated>2022-05-20T10:27:57Z</updated>
    <published>2022-05-20T10:27:57Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-05-24T10:37:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/073</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/073" rel="alternate" type="text/html"/>
    <title>TR22-073 |  Unbalanced Expanders from Multiplicity Codes | 

	Itay Kalev, 

	Amnon Ta-Shma</title>
    <summary>In 2007 Guruswami, Umans and Vadhan gave an explicit construction of a lossless condenser based on Parvaresh-Vardy codes. This lossless condenser is a basic building block in many constructions, and, in particular, is behind the state of the art extractor constructions.

We give an alternative construction that is based on Multiplicity codes. While the bottom-line result is similar to the GUV result, the analysis is very different. In GUV (and Parvaresh-Vardy codes) the polynomial ring is closed to a finite field, and every polynomial is associated with related elements in the finite field. In our construction a polynomial from the polynomial ring is associated with its iterated derivatives. Our analysis boils down to solving a differential equation over a finite field, and uses previous techniques, introduced by Kopparty for the list-decoding setting.
We also observe that these (and more general) questions were studied in differential algebra, and we use the terminology and result developed there.

We believe these techniques have the potential of getting better constructions and solving the current bottlenecks in the area.</summary>
    <updated>2022-05-18T16:14:05Z</updated>
    <published>2022-05-18T16:14:05Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-05-24T10:37:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=990</id>
    <link href="https://emanueleviola.wordpress.com/2022/05/18/qa/" rel="alternate" type="text/html"/>
    <title>Q&amp;A</title>
    <summary>What led you to academia? Much to the shock of my fellow students, I have wanted to be a professor since my freshman year in Italy. The pursuit of knowledge and the lifestyle freedom really appealed to me. Naturally, I did not have a clue; but I would do it all over again, changing nothing‚Ä¶ [‚Ä¶]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ol><li>What led you to academia?</li></ol>



<p>Much to the shock of my fellow students, I have wanted to be a professor since my freshman year in Italy. The pursuit of knowledge and the lifestyle freedom really appealed to me. Naturally, I did not have a clue; but I would do it all over again, changing nothing‚Ä¶ alright, almost nothing.</p>



<ol start="2"><li>How did you become interested in theoretical computer science?</li></ol>



<p>I was totally hooked to computers since I was eight, and also worked on videogames in my early teens. In high school I didn‚Äôt mind math, but it was not my passion: It was mostly calculus which I thought was ‚Äúonly good for physics.‚Äù In college I had a first glimpse of theoretical computer science, and I was struck. The field was asking the right questions: What is a proof, what is knowledge, what is randomness, <em>when you are short on time?</em></p>



<ol start="3"><li>What are you currently working on?</li></ol>



<p>The most famous open problem in the field is the P vs. NP problem which can be phrased as asking to prove that <em>Super Mario</em> levels, properly constructed, are hard to beat. The general challenge is to exhibit problems that require a lot of time on computers. Much of my research concerns proving such limitations for restricted models of computers, for example computers with no memory. Even understanding such restricted models has proved enormously difficult, and a good reason for that is that they are extremely powerful, much more so than anyone anticipated.</p></div>
    </content>
    <updated>2022-05-18T13:00:50Z</updated>
    <published>2022-05-18T13:00:50Z</published>
    <category term="Uncategorized"/>
    <category term="SpeakMemory"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2022-05-24T10:37:49Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://ptreview.sublinear.info/?p=1673</id>
    <link href="https://ptreview.sublinear.info/2022/05/new-property-testing-book-by-arnab-bhattacharyya-and-yuichi-yoshida/" rel="alternate" type="text/html"/>
    <title>New Property Testing book, by Arnab Bhattacharyya and Yuichi Yoshida</title>
    <summary>More great news: a new textbook on property testing, üìò Property Testing: Problems and Techniques, by two experts in the field, Arnab Bhattacharyya and Yuichi Yoshida, is now available! As the overview below outlines (from the book‚Äôs website), the book covers a wide range of topics, and should give anyone interested a great overview of [‚Ä¶]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><strong>More great news:</strong> a new textbook on property testing, <img alt="&#x1F4D8;" class="wp-smiley" src="https://s.w.org/images/core/emoji/13.1.0/72x72/1f4d8.png" style="height: 1em;"/> <em><a href="https://link.springer.com/book/10.1007/978-981-16-8622-1">Property Testing: Problems and Techniques</a></em>, by two experts in the field,  <a href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</a> and <a href="http://research.nii.ac.jp/~yyoshida/">Yuichi Yoshida</a>, is now available!</p>



<div class="wp-block-image"><figure class="aligncenter size-full"><a href="https://ptreview.sublinear.info/wp-content/uploads/2022/05/book.jpg"><img alt="" class="wp-image-1674" height="406" src="https://ptreview.sublinear.info/wp-content/uploads/2022/05/book.jpg" width="306"/></a><em>Property Testing: Problems and Techniques</em> (Springer, 2022)</figure></div>



<p>As the overview below outlines (from <a href="https://link.springer.com/book/10.1007/978-981-16-8622-1">the book‚Äôs website</a>), the book covers a wide range of topics, and should give anyone interested a great overview of scope, techniques, and results in testing.</p>



<blockquote class="wp-block-quote has-text-align-left"><p>This book introduces important results and techniques in property testing, where the goal is to design algorithms that decide whether their input satisfies a predetermined property in sublinear time, or even in constant time ‚Äì that is, time is independent of the input size.</p><p>This book consists of three parts. The first part provides an introduction to the foundations of property testing. The second part studies the testing of specific properties on strings, graphs, functions, and constraint satisfaction problems. Vectors and matrices over real numbers are also covered. The third part is more advanced and explains general conditions, including full characterizations, under which properties are constant-query testable.</p><p>The first and second parts of the book are intended for first-year graduate students in computer science. They should also be accessible to undergraduate students with the adequate background. The third part can be used by researchers or ambitious graduate students who want to gain a deeper theoretical understanding of property testing.</p><p/></blockquote></div>
    </content>
    <updated>2022-05-18T03:54:06Z</updated>
    <published>2022-05-18T03:54:06Z</published>
    <category term="Announcement"/>
    <category term="Surveys and books"/>
    <author>
      <name>Clement Canonne</name>
    </author>
    <source>
      <id>https://ptreview.sublinear.info</id>
      <link href="https://ptreview.sublinear.info/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://ptreview.sublinear.info" rel="alternate" type="text/html"/>
      <subtitle>The latest in property testing and sublinear time algorithms</subtitle>
      <title>Property Testing Review</title>
      <updated>2022-05-24T01:09:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://nisheethvishnoi.wordpress.com/?p=154</id>
    <link href="https://nisheethvishnoi.wordpress.com/2022/05/17/virtual-dimacs-workshop-on-entropy-and-optimization-on-may-18-19-2022/" rel="alternate" type="text/html"/>
    <title>(Virtual) DIMACS Workshop on Entropy and Optimization on May 18, 19, 2022</title>
    <summary>Mohit Singh and I are organizing a two-day virtual DIMACS Workshop on Entropy and Optimization that starts tomorrow ‚Äî May 18, 19, 2022. We have a stellar lineup of speakers: Nima Anari (Stanford University), Alexander Barvinok (Michigan), Mark Braverman (Princeton), Sebastien Bubeck (Microsoft Research), P√©ter Csikv√°ri (Alfred Renyi Institute of Mathematics), Zongchen Chen (MIT), Ronen [‚Ä¶]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p/>



<p>Mohit Singh and I are organizing a two-day virtual DIMACS Workshop on <strong>Entropy and Optimization</strong> that starts tomorrow ‚Äî May 18, 19, 2022. </p>



<p>We have a stellar lineup of speakers:  </p>



<p><em>Nima Anari (Stanford University), Alexander Barvinok (Michigan), Mark Braverman (Princeton), Sebastien Bubeck (Microsoft Research), P√©ter Csikv√°ri (Alfred Renyi Institute of Mathematics), Zongchen Chen (MIT), Ronen Eldan (Weizmann), Tali Kaufman (Bar-Ilan University), Jon Lee (Michigan), Shayan Oveis-Gharan (U Washington)</em></p>



<p>The goal of this workshop is to explore various connections between entropy, optimization, and sampling. Entropy-maximizing probability distributions have been recently used in interesting ways in applications such as algorithms for counting problems, algorithms for NP-hard optimization problems, and interior-point methods for convex programming</p>



<p>Attendance to the workshop is free but <strong>registration is required</strong>. To see the program of the workshop and register, visit <a href="http://dimacs.rutgers.edu/events/details?eID=318">here</a>.</p>



<p>Looking forward to seeing many of you there!</p>



<p/>



<p/></div>
    </content>
    <updated>2022-05-17T21:01:47Z</updated>
    <published>2022-05-17T21:01:47Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>nisheethvishnoi</name>
    </author>
    <source>
      <id>https://nisheethvishnoi.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://nisheethvishnoi.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://nisheethvishnoi.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://nisheethvishnoi.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Algorithms, Nature, and Society</title>
      <updated>2022-05-24T10:38:11Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=20024</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/05/16/take-wing/" rel="alternate" type="text/html"/>
    <title>Take Wing</title>
    <summary>It is a capital mistake to theorize before one has data‚ÄîSherlock Holmes Jeannette Wing is a Professor of Computer Science at Columbia University. She was recently appointed Executive VP for Research across all of Columbia‚Äôs campuses. She is also an adjunct Professor at Carnegie Mellon University. She stays busy. See this for her CV. Sixteen [‚Ä¶]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i>It is a capital mistake to theorize before one has data‚ÄîSherlock Holmes</i></p>
<p>
Jeannette Wing is a Professor of Computer Science at Columbia University. She was recently <a href="https://president.columbia.edu/news/jeannette-wing-appointed-executive-vice-president-research">appointed</a> Executive VP for Research across all of Columbia‚Äôs campuses. She is also an adjunct Professor at Carnegie Mellon University. She stays busy. See <a href="https://www.cs.columbia.edu/~wing/">this</a> for her CV. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/05/16/take-wing/jw/" rel="attachment wp-att-20028"><img alt="" class="aligncenter size-full wp-image-20028" height="225" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/05/jw.png?resize=225%2C225&amp;ssl=1" width="225"/></a></p>
<p>
Sixteen years ago she wrote a short <a href="http://www.cs.cmu.edu/afs/cs/usr/wing/www/publications/Wing06.pdf">position</a> paper for <em>Communications of the ACM</em> titled ‚ÄúComputational Thinking.‚Äù It begins:</p>
<p>
<em><br/>
 Computational thinking builds on the power and limits of computing processes, whether they are executed by a human or by a machine.<br/>
</em></p>
<p>
This is the first of sixteen sentences of the form ‚ÄúComputational thinking [verb]‚Ä¶,‚Äù plus one that follows a semicolon. The thirteenth prefaces six bulleted paragraphs giving characteristics of computational thinking. They fill page 3 of 3‚Äîthe paper is shorter to read than this post. </p>
<p>
Her 2007 <a href="https://www.cs.cmu.edu/afs/cs/usr/wing/www/Computational_Thinking.pdf">talk</a> on ‚ÄúComputational Thinking‚Äù has oodles of things that aren‚Äôt in the paper: <em>pictures</em>. It also concludes by posing five questions that she put into another famous CACM paper.</p>
<p>
</p><p><b> Five Questions </b></p>
<p/><p>
This second <a href="https://cacm.acm.org/magazines/2008/1/5481-five-deep-questions-in-computing/fulltext">paper</a> appeared in 2008 with the title ‚ÄúFive Deep Questions in Computing.‚Äù They are: </p>
<ol>
<li> P = NP?
</li><li> What is computable?
</li><li> What is intelligence?
</li><li> What is information?
</li><li> (How) can we build complex systems simply?
</li></ol>
<p>
The first is one of the basic questions of theory, of course. </p>
<p>
The next is about what are computations? This question complicates when one includes: <a href="https://en.wikipedia.org/wiki/DNA_computing">DNA</a> or <a href="https://en.wikipedia.org/wiki/Quantum_computing">quantum</a> computers? Also what about man-machine joint computations? Given that humans and machines have different computing capability, now ask: What is computable? Pretty complex.</p>
<p>
Let‚Äôs skip what is intelligence for now.</p>
<p>
What is information? This is a perfect question: Information is not just <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>‚Äòs and <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>‚Äòs. DNA encodes information in a different way and with quantum computing, it‚Äôs not bits but qubits. Amazing. </p>
<p>
Finally we will also skip the last question. </p>
<p>
She ends with:<br/>
<em><br/>
I pose these questions to stimulate deep thinking and further discussion. What deep questions about computing would you want answered? In 50 years, how different will they and their answers be from what we ask and are able to answer today?<br/>
</em></p>
<p>
</p><p><b> Data Science </b></p>
<p/><p>
Wing is a leading expert of <a href="https://en.wikipedia.org/wiki/Data_science">data science</a>. This field is traceable back to 1962 when <a href="https://en.wikipedia.org/wiki/John_Tukey">John Tukey</a> described an area he called ‚Äúdata analysis‚Äù. That is Tukey of Fast Fourier transform fame, who I knew when I was at Princeton. </p>
<p>
Data science combines the scientific method, math and statistics, specialized programming, advanced analytics, AI, and even storytelling to uncover and explain the business insights buried in data.</p>
<p>
Her current research interests are in trustworthy AI. Her areas of research expertise include security and privacy, formal methods, programming languages, and distributed and concurrent systems. She is widely recognized for her intellectual leadership in computer science, and more recently in data science. Wing‚Äôs seminal essay, titled ‚ÄúComputational Thinking,‚Äù was published more than a fifteen years ago and is credited with helping to establish the centrality of computer science to problem-solving in all other disciplines.</p>
<p>
Data can be precious for one of three reasons: the data set is expensive to collect; the data set contains a rare event (low signal-to-noise ratio); or the data set is artisanal‚Äîsmall, task-specific, and/or targets a limited audience. </p>
<ul>
<li> A good example of expensive data comes from large, one-off, expensive scientific instruments, for example, the Large Synoptic Survey Telescope, the Large Hadron Collider, and the IceCube Neutrino Detector at the South Pole.
</li><li> A good example of rare event data is data from sensors on physical infrastructure, such as bridges and tunnels; sensors produce a lot of raw data, but the disastrous event they are used to predict is (thankfully) rare. Rare data can also be expensive to collect.
</li><li> A good example of artisanal data is the tens of millions of court judgments that China has released online to the public since 2014.
</li></ul>
<p>
</p><p><b> Open Problems </b></p>
<p/><p>
Let‚Äôs take a cue from Wing: What other major aspects and objectives of computer science shall we put into crisp bullet points?</p>
<p/></div>
    </content>
    <updated>2022-05-16T12:32:23Z</updated>
    <published>2022-05-16T12:32:23Z</published>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Open Problems"/>
    <category term="P=NP"/>
    <category term="People"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>G√∂del's Lost Letter and P=NP</title>
      <updated>2022-05-24T10:37:28Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-6897620455238922302</id>
    <link href="http://blog.computationalcomplexity.org/feeds/6897620455238922302/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/05/is-kamala-harris-our-first-female-prez.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6897620455238922302" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/6897620455238922302" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/05/is-kamala-harris-our-first-female-prez.html" rel="alternate" type="text/html"/>
    <title>Is Kamala Harris our first female PREZ? No. Do I have a theorem named after me. No. But in both cases...</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>On Nov 19, 2021 Joe Biden got a colonoscopy and hence the 25th amendment was used to make Kamala Harris the president temporarily (this source:¬†<a href="https://nypost.com/2021/11/19/biden-returns-to-white-house-after-physical-colonoscopy/">here</a>¬†says 85 minutes, though I thought I heard a few hours from other sources).¬†</p><p>Does this make Kamala Harris our first female president?</p><p>I would say NO and I suspect you agree. A friend of mine suggested the phrasing <i>Kamala Harris is the</i> <i>first women to assume the powers of the president under the 25th amendment.¬† </i>True.¬† I don't think it means much. She tacked on the <i>under the 25th amendment </i>since Edith Wilson was essentially president when Woodrow Wilson had a stroke (see¬†<a href="https://en.wikipedia.org/wiki/Edith_Wilson#Increased_role_after_husband's_stroke">here</a>).</p><p><br/></p><p>A student asked me <i>Is there a theorem that is referred to as Gasarch's Theorem or something like that?</i></p><p>I will answer YES and NO, but really the answer is NO.</p><p>YES: In 1999 Gasarch and Kruskal had a paper in Mathematics Magazine:¬†</p><p><a href="http://www.cs.umd.edu/~gasarch/papers/dice.pdf">When can one load of Dice so that the sum is uniformly distributed</a>?<br/></p><p>In that paper we have a theorem that gives an exact condition on</p><p>(n_1,...,n_k) for when there is a loaded n_1-sided dice, n_2-sided dice,...,n_k-sided dice so that¬†</p><p>the sums are all equally likely.</p><p>In 2018 Ian Morrison published a paper in the American Math Monthly:</p><p><a href="https://arxiv.org/abs/1411.2272">Sacks of dice with fair totals</a><br/></p><p>which used our work and referred to our main theorem as <b>The Gasarch-Kruskal Theorem.</b></p><p>Hence there is a theorem with my name on it!</p><p>NO: The Gasarch-Kruskal paper has only 8 citations (according to Google Scholar). This is more than I would have thought, but its not a lot. The fact that ONE person calls the main theorem THE GASARCH-KRUSKAL THEOREM hardly makes it a named theorem.¬†</p><p>QUESTION: So what criteria can one use?</p><p>We could say that X has a theorem with their name on it if there is a Wikipedia entry about the theorem, using that name. That works to a point, but might fun afoul of Goodhart's law (if a measure becomes a target it stops being a measure) in that, for example, I could write a Wikipedia entry on The Gasarch-Kruskal Theorem.¬†</p><p>We could say that 10 people need to refer to the theorem by the name of its authors. Why 10? Any number seems arbitrary.¬†</p><p>CAVEAT: If someone asked Clyde Kruskal <i>is there a theorem that bears your name</i>¬†that is trickier, since <i>The Kruskal Tree Theorem</i>¬†bears his name.... but its not his theorem. Reminds me of the (fictional) scenario where a Alice steals¬† a Field's medal and tells Bob<i> I¬†have a Field's Medal! </i>and Bob¬† thinks Alice is a world-class mathematician since she has a fields medal, rather than thinking Alice is a world class thief. See¬†<a href="https://blog.computationalcomplexity.org/2018/08/how-valuable-is-fields-medal.html">here</a>¬†for my post on that.¬†</p><p>(I originally had Kruskal Three Theorem instead of Tree Theorem. I have corrected this but I hope it inspires Clyde to prove a theorem about the number Three so he can have a named theorem. And if he is lucky, over time, people will confuse it with the Kruskal Tree Theorem!)¬†</p><p><br/></p><p><br/></p><p><br/></p><p><i><br/></i></p></div>
    </content>
    <updated>2022-05-16T04:41:00Z</updated>
    <published>2022-05-16T04:41:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-05-24T09:50:07Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/072</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/072" rel="alternate" type="text/html"/>
    <title>TR22-072 |  Probabilistic Kolmogorov Complexity with Applications to Average-Case Complexity | 

	Zhenjian Lu, 

	Halley Goldberg, 

	Valentine Kabanets, 

	Igor Oliveira</title>
    <summary>Understanding the relationship between the worst-case and average-case complexities of $\mathrm{NP}$ and of other subclasses of $\mathrm{PH}$ is a long-standing problem in complexity theory. Over the last few years, much progress has been achieved in this front through the investigation of meta-complexity: the complexity of problems that refer to the complexity of the input string $x$ (e.g., given a string $x$, estimate its time-bounded Kolmogorov complexity). In particular, [Hir21] employed techniques from meta-complexity to show that if $\mathrm{DistNP} \subseteq \mathrm{AvgP}$ then $\mathrm{UP} \subseteq \mathrm{DTIME}[2^{O(n/\log n)}]$. While this and related results [HN21, CHV22] offer exciting progress after a long gap, they do not survive in the setting of ramdonmized computations: roughly speaking, "randomness" is the opposite of "structure", and upper bounding the amount of structure (time-bounded Kolmogorov complexity) of different objects is crucial in recent applications of meta-complexity. This limitation is significant, since randomized computations are ubiquitous in algorithm design and give rise to a more robust theory of average-case complexity [IL90].

In this work, we develop a probabilistic theory of meta-complexity, by incorporating randomness into the notion of complexity of a string $x$. This is achieved through a new probabilistic variant of time-bounded Kolmogorov complexity that we call $\mathrm{pK}^t$ complexity. Informally, $\mathrm{pK}^t(x)$ measures the complexity of $x$ when shared randomness is available to all parties involved in a computation. By porting key results from meta-complexity to the probabilistic domain of $\mathrm{pK}^t$ complexity and its variants, we are able to establish new connections between worst-case and average-case complexity in the important setting of probabilistic computations:

-  If $\mathrm{DistNP} \subseteq \mathrm{AvgBPP}$, then $\mathrm{UP}\subseteq\mathrm{RTIME}\!\left[2^{O(n/\log n)}\right]$. 

-  If $\mathrm{Dist\Sigma}^{\mathrm{P}}_{2} \subseteq \mathrm{AvgBPP}$, then $\mathrm{AM} \subseteq \mathrm{BPTIME}\!\left[2^{O(n/\log n)}\right]$. 

- In the fine-grained setting [CHV22], we get $\mathrm{UTIME}[2^{O(\sqrt{n\log n})}]\subseteq \mathrm{RTIME}[2^{O(\sqrt{n\log n})}]$ and $\mathrm{AMTIME}[2^{O(\sqrt{n\log n})}] \subseteq \mathrm{BPTIME}[2^{O(\sqrt{n\log n})}]$ from stronger average-case assumptions. 

- If $\mathrm{DistPH}\subseteq\mathrm{AvgBPP}$, then $\mathrm{PH}\subseteq\mathrm{BPTIME}\!\left[2^{O(n/\log n)}\right]$. Specifically, for any $\ell \geq 0$, if $\mathrm{Dist\Sigma}_{\ell+2}^{\mathrm{P}}\subseteq\mathrm{AvgBPP}$ then $\mathrm{\Sigma}_{\ell}^{\mathrm{P}}\subseteq\mathrm{BPTIME}\!\left[2^{O(n/\log n)}\right]$.

- Strengthening a result from [HN21], we show that if $\mathrm{DistNP}\subseteq\mathrm{AvgBPP}$ then polynomial size Boolean circuits can be agnostically PAC learned under any unknown $\mathrm{P}/\mathrm{poly}$-samplable distribution in polynomial time.

In some cases, our framework allows us to significantly simplify existing proofs, or to extend results to the more challenging probabilistic setting with little to no extra effort.</summary>
    <updated>2022-05-16T01:12:32Z</updated>
    <published>2022-05-16T01:12:32Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-05-24T10:37:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8332</id>
    <link href="https://windowsontheory.org/2022/05/15/information-theoretic-cryptography-22-guest-post-by-benny-applebaum/" rel="alternate" type="text/html"/>
    <title>Information Theoretic Cryptography 22: Guest post by Benny Applebaum</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Dear friends, The third information-theoretic cryptography conference (ITC) 2022 will be held in-person at MIT this year from¬†July 5-7. We have an exciting program with 17 cool papers and 6 plenary talks by Yuval Ishai, Rafael Pass, David Zuckerman, Omri Ben-Eliezer, Dakshita Khurana and Yevgeniy Dodis on topics that span the breadth of information-theoretic cryptography¬†(and ‚Ä¶ <a class="more-link" href="https://windowsontheory.org/2022/05/15/information-theoretic-cryptography-22-guest-post-by-benny-applebaum/">Continue reading <span class="screen-reader-text">Information Theoretic Cryptography 22: Guest post by Benny¬†Applebaum</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Dear friends,</p>



<p>The third information-theoretic cryptography conference (ITC) 2022 will be held in-person at MIT this year from¬†July 5-7. We have an exciting program with 17 cool papers and 6 plenary talks by Yuval Ishai, Rafael Pass, David Zuckerman, Omri Ben-Eliezer, Dakshita Khurana and Yevgeniy Dodis on topics that span the breadth of information-theoretic cryptography¬†(and beyond).¬†</p>



<p>More information here:¬†<a href="https://t.co/VhueMjajyf" rel="noreferrer noopener" target="_blank">itcrypto.github.io/2022/index.html</a></p>



<p>We hope to see many of you at the conference.</p>



<p>The organizers</p></div>
    </content>
    <updated>2022-05-15T17:05:29Z</updated>
    <published>2022-05-15T17:05:29Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2022-05-24T10:37:38Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2022/05/15/linkage</id>
    <link href="https://11011110.github.io/blog/2022/05/15/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>A tutorial on how to use Inkscape to make nice mathematical diagrams quickly enough for real-time note-taking in mathematical lectures (\(\mathbb{M}\), via). It‚Äôs from 2019, so doesn‚Äôt take advantage of newer features of Inkscape released since then. I use Illustrator, but without a site license it‚Äôs expensive; the other free program many of our students use is Ipe, more oriented to PDF than SVG but with good TeX integration.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://castel.dev/post/lecture-notes-2/">A tutorial on how to use Inkscape to make nice mathematical diagrams quickly enough for real-time note-taking in mathematical lectures</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108228874974700230">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=31227940">via</a>). It‚Äôs from 2019, so doesn‚Äôt take advantage of newer features of Inkscape released since then. I use Illustrator, but without a site license it‚Äôs expensive; the other free program many of our students use is <a href="https://ipe.otfried.org/">Ipe</a>, more oriented to PDF than SVG but with good TeX integration.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Cop-win_graph">Cop-win graph</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108235112878367692">\(\mathbb{M}\)</a>),</span> now a Wikipedia Good Article. It was the last of my current nominations, so it may be a while until the next. These are graphs on which a cop can catch a robber in a game where they alternate moving on edges or staying put, <a href="https://11011110.github.io/blog/2016/08/18/game-of-cop.html">as I discussed in an earlier post</a>. The GA reviewer made me take out as unsourced a statement that a recognition algorithm of <a href="https://doi.org/10.1016%2FS0166-218X%2803%2900295-6">Spinrad 2004</a> uses time \(O(mn/\log n)\), faster than the bound of \(O(n^3/\log n)\) from Spinrad‚Äôs paper. But I still think it‚Äôs true.</p>
  </li>
  <li>
    <p><a href="https://chaoxuprime.com/posts/2019-01-12-lights-out-game.html">Lights out game on a grid</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@chao/108228363268882685">\(\mathbb{M}\)</a>).</span> This is the puzzle where you have to turn out all of a given set of lights on a grid graph using switches that flip the state of any grid cell and all of its neighbors. It‚Äôs just solving sparse systems of linear equations over \(\mathbb{F}_2\), but Gaussian elimination is slow and the usual form of nested dissection requires full-rank matrices. Instead Chao Xu describes an \(O(n^3)\)-time algorithm.</p>
  </li>
  <li>
    <p><a href="https://sites.google.com/view/publiccommentsonthecmf/">Stanford mathematics professor Brian Conrad takes a deeper look at the proposed revisions to the California Math Framework for high school mathematics</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108247956356449281">\(\mathbb{M}\)</a>,</span> <a href="https://windowsontheory.org/2022/05/02/brian-conrad-takes-down-the-cmf/">via</a>), finding an ‚Äúabundance of false or misleading citations‚Äù, ‚Äúmisrepresentations of facts and evidence‚Äù, ‚Äúguidance lacking  details essential for implementation or seeming to be opinions rather than evidence-based‚Äù, and ‚Äúbias toward data science ‚Ä¶ based on misinformation and hype‚Äù.</p>
  </li>
  <li>
    <p><a href="https://twistypuzzles.com/forum/viewtopic.php?t=37692">A twisty mechanical puzzle with exponential solution length</a> inspires <a href="https://mathstodon.xyz/@henryseg/108194775453014602">Henry Segerman to ask: are superexponential puzzles possible?</a></p>
  </li>
  <li>
    <p>Progress in polyhedral combinatorics <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108259553485852087">\(\mathbb{M}\)</a>,</span> <a href="https://gilkalai.wordpress.com/2022/04/29/joshua-hinman-proved-baranys-conjecture-on-face-numbers-of-polytopes-and-lei-xue-proved-a-lower-bound-conjecture-by-grunbaum/">via</a>): <a href="https://arxiv.org/abs/2204.02568">convex polytopes cannot have fewer intermediate-dimensional faces than the smaller of their numbers of facets or vertices</a>.</p>
  </li>
  <li>
    <p><a href="https://www.ams.org/journals/notices/202205/noti2468/noti2468.html">Steven Clontz reviews <em>Games for Your Mind</em></a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@StevenXClontz/108261574819754988">\(\mathbb{M}\)</a>),</span> by Jason Rosenhouse, in <em>Notices of the AMS</em>. It‚Äôs about logic puzzles in the style of Lewis Carroll and Raymond Smullyan, but the review has a broader focus on puzzles and metapuzzles more generally.</p>
  </li>
  <li>
    <p><a href="https://amandaghassaei.com/projects/digital_marbling/">Digital marbling</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108270841049246147">\(\mathbb{M}\)</a>).</span>  A recent physics-based simulation project for paper marbling, by Amanda Ghassaei, who was also responsible for an <a href="https://origamisimulator.org/">origami simulator</a> that I <a href="https://11011110.github.io/blog/2018/02/28/linkage.html">linked with a different url</a> a few years ago.</p>
  </li>
  <li>
    <p><a href="https://eiko-fried.com/welcome-to-hotel-elsevier-you-can-check-out-any-time-you-like-not/">The information Elsevier tracks and resells about the scientists who access its journals</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108278540265067636">\(\mathbb{M}\)</a>,</span> <a href="https://news.ycombinator.com/item?id=31326672">via</a>). An EU GDPR personal information request reveals not just dates and times from journal paper reading, writing, and reviewing data but also user names, phone numbers, and bank account information, whether you read the emails from them, and a huge list of the spam newsletters that they subscribe you to.</p>
  </li>
  <li>
    <p><a href="https://terrytao.wordpress.com/2022/05/10/partially-specified-mathematical-objects-ambient-parameters-and-asymptotic-notation/">Terry Tao tries to make mathematical sense of notations like \(\pm\) or \(O(\dots)\)</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108280853102871738">\(\mathbb{M}\)</a>)</span>  that specify something partially rather than exactly. It‚Äôs a long post, but I think much less technical than most of Tao‚Äôs posts.</p>
  </li>
  <li>
    <p><a href="https://www.insidehighered.com/news/2022/05/11/how-scholarly-meeting-became-superspreader-event">Pandemic at the conference</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108284204495257458">\(\mathbb{M}\)</a>):</span> ACM CHI, the annual conference in computer‚Äìhuman interaction, was held in a hybrid format with 1900 physical attendees in New Orleans a week ago. It became a coronavirus superspreader event, despite its vaccine and mask mandates.</p>
  </li>
  <li>
    <p><a href="https://retractionwatch.com/2022/05/12/a-college-that-doesnt-exist-an-email-address-that-goes-dark-who-wrote-this-paper/">The mystery of who wrote a mathematics paper in a special issue, heavily based on the work of the highly-cited special issue editor</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108289912652816183">\(\mathbb{M}\)</a>).</span> It‚Äôs by someone who doesn‚Äôt seem to exist at a college that doesn‚Äôt exist. But the special issue editor can show emails from the author, so that‚Äôs something. Searching MathSciNet for similarly-titled works produces confidence-inspiring journals like <em>Chaos, Solitons, and Fractals</em> and <em>Fuzzy Sets and Systems</em>, but this one isn‚Äôt indexed.</p>
  </li>
  <li>
    <p><a href="https://may12.womeninmaths.org/">May 12th was chosen as a day to globally celebrate women in mathematics</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@JordiGH/108289993565001699">\(\mathbb{M}\)</a>).</span>  It was the birthday of Maryam Mirzakhani (1977‚Äì2017), the first and so far only woman to win the Fields Medal. The link lists celebration events continuing for a month or so.</p>
  </li>
  <li>
    <p><a href="https://medium.com/swlh/polyomino-loops-fc8f6fc92c2f">Polyomino loops</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/108304649157797618">\(\mathbb{M}\)</a>).</span> Matthew Yuan wonders, if you play billiards in a polyomino and try shooting a ball diagonally from the midpoint of each of the polyomino edges, how to count the number of loops that these billiard paths will link up into. It‚Äôs somewhat related to the African lusona drawings that I <a href="https://11011110.github.io/blog/2020/08/02/sona-enumeration.html">discussed in an earlier post</a>.</p>
  </li>
  <li>
    <p><a href="https://jeremykun.com/2022/05/14/practical-math-preview-collect-sensitive-survey-responses-privately/">Collecting sensitive survey responses privately</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@j2kun/108301309174075160">\(\mathbb{M}\)</a>).</span> This excerpt by Jeremy Kun from his book-in-progress on practical programming techniques is about <a href="https://en.wikipedia.org/wiki/Randomized_response">randomized response</a>, a method for collecting accurate information from survey respondents on whether they may have participated in an illegal activity (like, say, abortion in the US in the 1960s) without revealing the identities of the participants to the data collectors. Similar ideas of preventing inferences about individuals in data sets also led to the development of <a href="https://en.wikipedia.org/wiki/Differential_privacy">differential privacy</a>.</p>
  </li>
</ul></div>
    </content>
    <updated>2022-05-15T16:11:00Z</updated>
    <published>2022-05-15T16:11:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2022-05-22T00:02:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://lucatrevisan.wordpress.com/?p=4630</id>
    <link href="https://lucatrevisan.wordpress.com/2022/05/14/the-first-xl-computer-scientist/" rel="alternate" type="text/html"/>
    <title>The First XL Computer Scientist</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Some time ago, I received a message to the effect that I was being considered for membership in the ‚ÄúAcademy of the XL‚Äù, to which my reaction was, hey, we have all gone out of shape during the pandemic, and ‚Ä¶ <a href="https://lucatrevisan.wordpress.com/2022/05/14/the-first-xl-computer-scientist/">Continue reading <span class="meta-nav">‚Üí</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Some time ago, I received a message to the effect that I was being considered for membership in the ‚ÄúAcademy of the XL‚Äù, to which my reaction was, hey, we have all gone out of shape during the pandemic, and body-shaming is never‚Ä¶ then it was explained to me that, in this context, ‚ÄúXL‚Äù means ‚Äúforty‚Äù and that the Academy of the Forty is Italy‚Äôs <a href="https://en.wikipedia.org/wiki/Accademia_nazionale_delle_scienze">National Academy of Science</a>.</p>
<p>Italy has a wonderfully named, and well-known within the country, National Academy of Arts and Science, the <a href="https://en.wikipedia.org/wiki/Accademia_dei_Lincei">Accademia dei Lincei</a>, which means something like academy of the ‚Äúeagle-eyed‚Äù (literally, lynx-eyed), that is, people that can see far. The Accademia dei XL is much less well known, although it has a distinguished 240-year history, during which people like Guglielmo Marconi and Enrico Fermi were members. More recently, the much beloved Rita Levi-Montalcini, Holocaust survivor, Nobel Laureate, and Senator-for-life, was a member. Current members include Nobel Laureates Carlo Rubbia and Giorgio Parisi. Noted algebraist Corrado De Concini is the current president.</p>
<p>Be that as it may, the academicians did vote to make me a member, their first computer scientist ever. Next week, at the inauguration of their 240th academic year, I will speak to the other members about randomness and pseudorandomness in computation.</p></div>
    </content>
    <updated>2022-05-14T15:07:57Z</updated>
    <published>2022-05-14T15:07:57Z</published>
    <category term="Italy"/>
    <category term="theory"/>
    <category term="Pseudorandomness"/>
    <category term="things that are excellent"/>
    <category term="XL"/>
    <author>
      <name>luca</name>
    </author>
    <source>
      <id>https://lucatrevisan.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://lucatrevisan.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://lucatrevisan.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://lucatrevisan.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>"Marge, I agree with you - in theory. In theory, communism works. In theory." -- Homer Simpson</subtitle>
      <title>in   theory</title>
      <updated>2022-05-24T10:37:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=20013</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/05/14/rafail-is-no-secret/" rel="alternate" type="text/html"/>
    <title>Rafail Is No Secret</title>
    <summary>Never say anything in an electronic message that you wouldn‚Äôt want appearing, and attributed to you, in tomorrow morning‚Äôs front-page headline in the New York Times‚ÄîColonel David Russell. Rafail Ostrovsky is a professor of computer science at the UCLA Samueli School of Engineering. Ken and I have been friends with him for many years, long [‚Ä¶]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<i>Never say anything in an electronic message that you wouldn‚Äôt want appearing, and attributed to you, in tomorrow morning‚Äôs front-page headline in the New York Times‚ÄîColonel David Russell.</i></p>
<p>
Rafail Ostrovsky is a professor of computer science at the UCLA Samueli School of Engineering. Ken and I have been friends with him for many years, long before he moved to UCLA. He is one of the world experts in security theory and practice. And he is especially strong at seeing new attacks and then finding defenses for them. See his web <a href="http://web.cs.ucla.edu/~rafail/">home</a> site for some details. </p>
<p>
Rafail was just awarded the 2022 <a href="https://en.wikipedia.org/wiki/W._Wallace_McDowell_Award">McDowell award</a>.  For visionary contributions to computer security theory and practice, including foreseeing new cloud vulnerabilities and then pioneering corresponding novel solutions. </p>
<p>
Again first seeing attacks, then inventing defenses. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/05/14/rafail-is-no-secret/ro/" rel="attachment wp-att-20016"><img alt="" class="aligncenter size-medium wp-image-20016" height="300" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/05/ro.jpg?resize=208%2C300&amp;ssl=1" width="208"/></a></p>
<p>
</p><p><b> A Key Result </b></p>
<p/><p>
One of Rafail‚Äôs neat results is how to create strong keys from biological data. This is joint work with Yevgeniy Dodis, Leonid Reyzin, and Adam Smith and is <a href="http://web.cs.ucla.edu/~rafail/PUBLIC/89.pdf">Fuzzy Extractors:</a> How to Generate Strong Keys from Biometrics and Other Noisy Data. </p>
<p>
Rather than try and generate keys from silly to generate patterns such as: 	 	my name + 3.14159 	 the idea is to use your own biological data. This paper unlike traditional cryptographic keys, is (1) not reproducible precisely and (2) not distributed uniformly. Yet it allows strong keys.</p>
<p>
</p><p><b> A Non-Typical Result </b></p>
<p/><p>
Rafail has a <a href="https://eprint.iacr.org/2020/997.pdf">paper</a> that is titled Alibi: A Flaw in Cuckoo-Hashing based Hierarchical ORAM Schemes and a Solution and is joint with Brett Hemenway Falk and Daniel Noble both of University of Pennsylvania. Their paper solves a nice problem, but we believe is unique for its abstract:  </p>
<p>
There once was a table of hashes <br/>
 That held extra items in stashes <br/>
 It all seemed like bliss <br/>
 But things went amiss <br/>
 When the stashes were stored in the caches </p>
<p>
</p><p><b> More Results </b></p>
<p/><p>
Here is another of Rafail‚Äôs results that demonstrates his many abilities. The <a href="https://link.springer.com/content/pdf/10.1007/978-3-540-24676-3_30.pdf">paper</a> is titled Public Key Encryption with Keyword Search and is joint with Dan Boneh, Giovanni Di Crescenzo, and Giuseppe Persiano.  Consider a mail server that stores various messages publicly encrypted for Alice by others. Using our mechanism Alice can send the mail server a key that will enable the server to identify all messages containing some specific keyword, but learn nothing else. We define the concept of public key encryption with keyword search and give several constructions. </p>
<p>
This result is interesting in that Rafail creates a problem that allows security to be partial. The full text is safe but it is still possible to search the text for certain keywords. This allows the security to be weaken, but not to be weaken all the way. </p>
<p>
It is surprising that security can be weaken partially, but not all the way. It might seem likely that this weaken notation of security could be too dangerous. One of the advantages of precise security models is that such results can be safely defined and shown to be safe. This is the fundamental advantage of modern formal definitions for security. </p>
<p>
</p><p><b> Open Problems </b></p>
<p/><p>
Rafail is one of the top researchers in security in the broadest sense. He is one of the best at defining new types of security and then showing that such notions are actually safe.</p>
<p>
Congrats to him for the McDowell award.</p>
<p/></div>
    </content>
    <updated>2022-05-14T13:05:19Z</updated>
    <published>2022-05-14T13:05:19Z</published>
    <category term="Ideas"/>
    <category term="People"/>
    <category term="Results"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>G√∂del's Lost Letter and P=NP</title>
      <updated>2022-05-24T10:37:28Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2022/071</id>
    <link href="https://eccc.weizmann.ac.il/report/2022/071" rel="alternate" type="text/html"/>
    <title>TR22-071 |  Robustly Separating the Arithmetic Monotone Hierarchy Via Graph Inner-Product | 

	Utsab Ghosal, 

	Arkadev Chattopadhyay, 

	Partha Mukhopadhyay</title>
    <summary>We establish an $\epsilon$-sensitive hierarchy separation for monotone arithmetic computations. The notion of $\epsilon$-sensitive monotone lower bounds was recently introduced by Hrubes [Computational Complexity'20]. We show the following:
   
(1) There exists a monotone polynomial over $n$ variables in VNP that cannot be computed by $2^{o(n)}$ size monotone circuits in an $\epsilon$-sensitive way as long as $\epsilon \ge 2^{-\Omega(n)}$.

(2) There exists a polynomial over $n$ variables that can be computed by polynomial size monotone circuits but cannot be computed by any monotone arithmetic branching program (ABP) of $n^{o(\log n)}$ size, even in an $\epsilon$-sensitive fashion as long as $\epsilon \ge n^{-\Omega(\log n)}$.

(3) There exists a polynomial over $n$ variables that can be computed by polynomial size monotone ABP but cannot be computed in $n^{o(\log n)}$ size by monotone formulas even in an $\epsilon$-sensitive way, when $\epsilon \ge n^{-\Omega(\log n)}$.

(4) There exists a polynomial over $n$ variables that can be computed by width-$4$  polynomial size monotone arithmetic branching programs (ABPs) but cannot be computed in $2^{o(n^{1/d})}$ size by monotone, unbounded fan-in formulas of product depth $d$ even in an $\epsilon$-sensitive way, when $\epsilon \ge 2^{-\Omega(n^{1/d})}$. This yields an $\epsilon$-sensitive separation of constant-depth monotone formulas and constant-width monotone ABPs. It seems that even an ordinary separation of the two classes was not known.   

An interesting feature of our separations is that in each case the polynomial exhibited is obtained from a graph inner-product polynomial by choosing an appropriate graph topology. The closely related graph inner-product Boolean function for expander graphs was invented by Hayes [DM &amp; TCS'11], also independently by Pitassi [2009], in the context of best-partition multiparty communication complexity.</summary>
    <updated>2022-05-13T15:36:48Z</updated>
    <published>2022-05-13T15:36:48Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2022-05-24T10:37:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=8329</id>
    <link href="https://windowsontheory.org/2022/05/12/workshop-on-local-algorithm-22-guest-post-by-clement-canonne/" rel="alternate" type="text/html"/>
    <title>Workshop on Local Algorithm 22: Guest post by Cl√©ment Canonne</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">After two years online, the üîé Workshop on Local Algorithms (WOLA) is back in person, and will be held in Warsaw from¬†June 25th¬†to¬†June 27th. Come and discuss local algorithms of all kinds ‚Äî sublinear-time, distributed, streaming, (massively) parallel, as well as graphical models and much more; and exchange ideas, techniques, and insights with others from ‚Ä¶ <a class="more-link" href="https://windowsontheory.org/2022/05/12/workshop-on-local-algorithm-22-guest-post-by-clement-canonne/">Continue reading <span class="screen-reader-text">Workshop on Local Algorithm 22: Guest post by Cl√©ment¬†Canonne</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>After two years online, the <img alt="&#x1F50E;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f50e.png" style="height: 1em;"/> <strong>Workshop on Local Algorithms (WOLA)</strong> is back in person, and will be held in Warsaw from¬†June 25th¬†to¬†June 27th. Come and discuss local algorithms of all kinds ‚Äî sublinear-time, distributed, streaming, (massively) parallel, as well as graphical models and much more; and exchange ideas, techniques, and insights with others from various research communities.</p>



<p>The workshop will feature talks from a range of exciting speakers, social events, poster sessions, and local (!) outings: to stay up to date on the schedule, and register, please head to¬†<a href="https://ideas-ncbr.pl/en/wola/" rel="noreferrer noopener" target="_blank">https://ideas-ncbr.pl/en/wola/</a></p>



<p>Looking forward to seeing you at WOLA!</p>



<p>PS: online attendance is also possible, for those who cannot attend in person. Streaming, after all, is on-topic <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/></p></div>
    </content>
    <updated>2022-05-12T14:05:40Z</updated>
    <published>2022-05-12T14:05:40Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2022-05-24T10:37:38Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=622</id>
    <link href="https://tcsplus.wordpress.com/2022/05/12/tcs-talk-wednesday-may-18-thatchaphol-saranurak-university-of-michigan/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, May 18 ‚Äî Thatchaphol Saranurak, University of Michigan</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, May 18th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Thatchaphol Saranurak from University of Michigan will speak about ‚ÄúAll-pairs minimum cuts in nearly quadratic time: a tutorial ‚Äù (abstract below). You can reserve a spot as an [‚Ä¶]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, May 18th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <a href="https://sites.google.com/site/thsaranurak/"><strong>Thatchaphol Saranurak</strong></a> from University of Michigan will speak about ‚Äú<em>All-pairs minimum cuts in nearly quadratic time: a tutorial </em>‚Äù (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: We recently showed an algorithm for computing all-pairs minimum cuts (or, more precisely, the Gomory-Hu tree) in ~O(n^2) time in weighted graphs and even almost-linear time in unweighted graphs. For weighted graphs, this is the first improvement over the 60-year-old algorithm by Gomory and Hu. Thus, surprisingly, computing all-pairs minimum cuts seems to be strictly easier than computing all-pairs shortest paths, which is conjectured to require n^{3-o(1)} time.</p>
<p>I will give a tutorial on the techniques behind our new result, one of which is called ‚Äúisolating cuts‚Äù. Then, I will survey recent progress in fast minimum cut algorithms and discuss open problems.</p>
<p>Joint work with Amir Abboud, Robert Krauthgamer, Jason Li, Debmalya Panigrahi, and Ohad Trabelsi.</p></blockquote></div>
    </content>
    <updated>2022-05-12T07:31:06Z</updated>
    <published>2022-05-12T07:31:06Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2022-05-24T10:38:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://rjlipton.wpcomstaging.com/?p=20001</id>
    <link href="https://rjlipton.wpcomstaging.com/2022/05/11/differential-privacy/" rel="alternate" type="text/html"/>
    <title>Differential Privacy</title>
    <summary>I‚Äôm low-key. I like my privacy‚ÄîKemba Walker. Avrim Blum, Irit Dinur, Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith, received the ACM 2021 Paris Kanellakis Theory and Practice Award. They worked on and studied the notion of differential privacy. Privacy One of the key advances of modern cryptography is its ability to define new [‚Ä¶]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<i>I‚Äôm low-key. I like my privacy‚ÄîKemba Walker.</i></p>
<p>
Avrim Blum, Irit Dinur, Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith, received the ACM 2021 Paris Kanellakis Theory and Practice <a href="https://awards.acm.org/kanellakis">Award</a>. They worked on and studied the notion of <a href="https://privacytools.seas.harvard.edu/differential-privacy">differential privacy</a>.</p>
<p><a href="https://rjlipton.wpcomstaging.com/2022/05/11/differential-privacy/all-12/" rel="attachment wp-att-20004"><img alt="" class="aligncenter size-full wp-image-20004" height="338" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/05/all.png?resize=600%2C338&amp;ssl=1" width="600"/></a></p>
<p><b> Privacy </b></p>
<p/><p>
One of the key advances of modern cryptography is its ability to define new types of security. One can be pretty naive in defining simple notions of security. For example, it is not too hard to get correct the notion: Given the encrypted message <img alt="{E_K(M)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE_K%28M%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> one cannot easily determine <img alt="{M}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/> without knowing the key <img alt="{K}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002"/>. However, things are much more complex when we wish to define more complex notions. </p>
<p>
This happens with notions of privacy. Differential privacy is a framework for reasoning about statistical databases. Imagine you have two otherwise identical databases, one with your personal information in it, and one without it. Differential Privacy ensures that the probability that a statistical query will produce a given result is (nearly) the same whether it‚Äôs conducted on the first or second database. </p>
<p>
Perhaps a concrete question will help: <i>How can we use data to learn about a population, without learning about specific individuals within the population?</i> Consider these two questions: </p>
<ol>
<li> ‚ÄúHow many people live in Vermont?‚Äù
</li><li> ‚ÄúHow many people named Joe Smith live in Vermont?‚Äù
</li></ol>
<p>
The first reveals a property of the whole population, while the second reveals information about one person. We need to be able to learn about trends in the population while preventing the ability to learn anything new about a particular individual. This is the goal of many statistical analyses of data, such as the statistics published by the U.S. Census Bureau. This is what differential privacy is all about. </p>
<p>
</p><p><b> The Award </b></p>
<p/><p>
From the award citation:</p>
<p>
<em><br/>
Differential privacy is a definition and framework for reasoning about privacy in statistical databases. While the privacy of individuals contributing to a dataset has been a long-standing concern, prior to the Kanellakis recipients‚Äô work, computer scientists only knew how to mitigate several specific privacy attacks via a disparate set of techniques. The foundation for differential privacy emerged in the early 2000‚Äôs from several key papers. At the ACM Symposium on the Principles of Database Systems (PODS 2003) Dinur and Nissim presented a paper which showed that any technique that allows reasonably accurate answers to a large number of queries is inherently non-private.</em></p><em>
</em><p><em>
Later, a sequence of papers by Dwork and Nissim at the International Conference on Cryptology (Crypto 2004); as well as Blum, Dwork, McSherry, and Nissim at the ACM Symposium on the Principles of Database Systems (PODS 2005); and Dwork, McSherry, Nissim, and Smith at the Theory of Cryptology Conference (TCC 2006) further defined and studied the notion of differential privacy.</em> </p>
<p>
Look at <a href="https://towardsdatascience.com/understanding-differential-privacy-85ce191e198a">the article</a> for more discussion of what it is all about. </p>
<p>
</p><p><b> Open Problems </b></p>
<p/><p>
We wish Avrim, Irit, Cynthia, Frank, Kobbi, and Adam congrats on their well deserved award. </p>
<p/></div>
    </content>
    <updated>2022-05-11T20:20:18Z</updated>
    <published>2022-05-11T20:20:18Z</published>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="People"/>
    <category term="Results"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wpcomstaging.com</id>
      <logo>https://s0.wp.com/i/webclip.png</logo>
      <link href="https://rjlipton.wpcomstaging.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wpcomstaging.com" rel="alternate" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>G√∂del's Lost Letter and P=NP</title>
      <updated>2022-05-24T10:37:28Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-5898963605660384340</id>
    <link href="http://blog.computationalcomplexity.org/feeds/5898963605660384340/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/05/queen-elizabeth-is-3rd-longest-reigning.html#comment-form" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/5898963605660384340" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/3722233/posts/default/5898963605660384340" rel="self" type="application/atom+xml"/>
    <link href="http://blog.computationalcomplexity.org/2022/05/queen-elizabeth-is-3rd-longest-reigning.html" rel="alternate" type="text/html"/>
    <title>Queen Elizabeth is the 3rd longest reigning monarch; The problem with definitions</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>¬†A few days ago Queen Elizabeth passed Johann II of Liechtenstein to be the third longest reigning monarch (see¬†<a href="https://en.wikipedia.org/wiki/List_of_longest-reigning_monarchs">here</a>).¬†</p><p>A summary of the top 4:</p><p><br/></p><p>4) Johann II, Liechtenstein ruled from Nov 12 1858 until his death on Feb 11, 1929. When he became King he was 18. He was king for 70 years, 91 days.¬†</p><p>3) Queen Elizabeth II (thats a two, not an eleven) ruled from Feb 2, 1952 until now. When she became Queen she was¬† 25. I am writing this on May 10 at which time she ruled 70 years, 94 days.¬†</p><p>2) Bhumibol Adulyadej (Thailand) ruled from June 9, 1946 until Oct 13, 2016. When he became King he was 19. He was king for 70 years, 126 days.¬†</p><p>1) Louis XIV ruled from May 14, 1643 until Sept 1, 1715. When he became King he was 4 years and 8 months. He was king for 72 years, 110 days.¬†</p><p><br/></p><p>Johann, Elizabeth, and Bhumibol started their reigns a bit young (they would have to to have ruled so long) but their first day of their reign they knew what the job was, what they are supposed to do etc.¬†</p><p>Here is my complaint: Louis XIV being king at the age of 4 years 8 months should not count (someone who proofread this post wondered if 4 years 9 months would count. No.) Shouldn't we define the reign of a king as the point at which he can make real decisions as king? Or something like that.¬†</p><p>For the record of the longest marriage there is a similar problem. The three longest marriages are legit in that the people got married at a reasonable age (I think all were married after they were 17). The fourth longest marriage of all time involved two people that were married when they were 5. That should not count (see¬†<a href="https://en.wikipedia.org/wiki/List_of_long_marriages">here</a>).</p><p>Is there a way to define monarch's reigns and also marriage length so that it corresponds to our intuitions?¬†</p><p>In Math we can use rigorous definitions but in English its harder.¬†</p><p><br/></p><p><br/></p><p><br/></p></div>
    </content>
    <updated>2022-05-11T03:39:00Z</updated>
    <published>2022-05-11T03:39:00Z</published>
    <author>
      <name>gasarch</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03004932739846901628</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="http://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2022-05-24T09:50:07Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://gradientscience.org/datamodels-2/</id>
    <link href="https://gradientscience.org/datamodels-2/" rel="alternate" type="text/html"/>
    <title>Uncovering Brittleness with Datamodels</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="bbutton" href="https://arxiv.org/abs/2202.00622" style="float: left; width: 45%;">
<i class="fas fa-file-pdf"/>
¬† ¬† Paper
</a>
<a class="bbutton" href="https://github.com/MadryLab/datamodels-data" style="float: left; width: 45%;">
<i class="fab fa-github"/>
¬†¬† Data
</a>
<br/></p>

<p>In this blog post we use datamodels to identify and study a new form of model <em>brittleness.</em></p>

<h2 id="recap-datamodels">Recap: Datamodels</h2>

<p>In our <a href="https://gradientscience.org/datamodels-1/">last post</a>, we introduced datamodels: a framework for studying how models use training data to make predictions. While we summarize datamodels in short below, if you haven‚Äôt yet read about datamodels we recommend reading our <a href="https://gradientscience.org/datamodels-1/">last post</a> for the full picture.</p>

<p>Consider a training set $S$ (e.g., a set of images and labels from a computer vision dataset), a learning algorithm $\mathcal{A}$ (e.g., training a deep neural network from scratch with SGD), and a target example $x$ (e.g., a test image and label from the same dataset). A <em>datamodel</em> for the target example $x$ is a parameterized function that takes as input a subset $S‚Äô$ of the original training set $S$, and predicts the outcome of training a model on $S‚Äô$ (using $\mathcal{A}$) and evaluating on $x$. In other words, a datamodel predicts how the choice of a specific training subset changes the final model prediction.</p>

<p><img alt="A graphic showing a test image and a training set. Some of the training images are greyed out to indicate a subset S-prime of the training set. There is an arrow from the training set to a question asking, &quot;if i train a model on examples # 1, 3, 5, etc., how will the model behave on the given target example?&quot; This question is fed to the datamodel, which returns an estimate of what the output (e.g. loss) of a model trained on S-prime and evaluated on x would be." src="https://gradientscience.org/images/datamodels/datamodel_blogpost_figures.001.png"/></p>

<p>Our <a href="https://gradientscience.org/datamodels-1/">last post</a> focused on constructing <em>linear</em> datamodels (one for each CIFAR-10 test image) that accurately predict the outcome of training a deep neural network from scratch on subsets of the CIFAR-10 training set.</p>

<p>Today, we‚Äôll use datamodels to investigate deep neural networks‚Äô predictions. Specifically, we‚Äôll introduce and measure <em>data-level brittleness</em>: how sensitive are model predictions to removing a small number of training set points?</p>

<h2 id="data-level-brittleness-a-motivating-example">Data-level brittleness: a motivating example</h2>

<p>Consider this image of a boat from the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a> test set:</p>

<p><img alt="An image of a boat from the CIFAR-10 test set" src="https://gradientscience.org/images/datamodels/Untitled.png" width="120px"/></p>

<p>A deep neural network (ResNet-9) trained on CIFAR-10 correctly classifies this example as a boat with <strong>71%</strong> (softmax) confidence. The classification is also ‚Äúrobust‚Äù in the sense that over different training runs (each with a different random initialization of the network, batch ordering, data augmentation, etc.), the trained model classifies this example correctly <strong>84%</strong> of the time.</p>

<p>It turns out, however, that if we remove just the following nine images from the CIFAR-10 training set‚Ä¶</p>

<p><img alt="Nine images from the CIFAR-10 training set that, when removed, induce misclassification of the boat example above." src="https://gradientscience.org/images/datamodels/datamodel_blogpost_figures.001%201.png"/></p>

<p>‚Ä¶models trained with the exact same training procedure (applied to the remaining 49,991 images in the training set) correctly classify the boat only <strong>35%</strong> of the time! Furthermore, when we remove only 11 additional training images, the probability of correct classification decreases to merely <strong>10%</strong> (the accuracy of a <em>random</em> classifier!).</p>

<p>Model behavior on this boat image exemplifies <em>data-level brittleness.</em> Models confidently and consistently output correct predictions, but these predictions hinge on a very small set of training examples. (One might hypothesize that in this case, brittleness stems from the fact that there are very few training examples of boats on land or grass.)</p>

<h2 id="quantifying-brittleness-with-datamodels">Quantifying brittleness with datamodels</h2>

<p>How do we actually measure data-level brittleness? In the example above, models misclassified the boat after we removed nine images. These were nine <em>specifically chosen</em> images, however: removing nine <em>randomly chosen</em> training images of boats does not at all degrade models‚Äô probability of correctly classifying the boat image. Even removing the nine most <em>similar</em> training examples to the boat image (e.g., in terms of representation space distance) degrades this probability by only 4%.</p>

<p>So, how do we find the ‚Äúright‚Äù images to remove? Specifically, what we‚Äôre looking for is the smallest subset of the training set whose removal induces misclassification on average, i.e.,</p>

<p>\begin{align}
\tag{1}
\label{eq:origobj}
\min_{R \subset S} |R‚Äô|, \text{ such that }\mathbb{E}[\text{margin of a model
trained on } S \setminus R \text{ on } x] \leq 0.
\end{align}</p>

<p>Unfortunately, problems like this (optimizing a black-box function over the space of all possible subsets of a large set) are computationally challenging to solve. In the worst case, to find the smallest set satisfying the above condition we would have to train several models for each possible training subset.</p>

<p>This is where datamodels come in. Recall that for a target example $x$ (e.g., our  boat example from before), we can construct (read our <a href="https://gradientscience.org/datamodels-1/">previous post</a> to see how) a <em>datamodel</em> $g$ that, for any subset of the training set $S‚Äô$, returns an estimate:</p>

<p>\begin{align}
g(S‚Äô) \approx \mathbb{E}[\text{margin of a classifier trained on $S‚Äô$ when
evaluated on $x$}].
\end{align}</p>

<p>(Here, the expectation is taken over training non-determinism.) Datamodel estimates can be highly accurate. For example, see the following graph of predicted average margin $g(S‚Äô)$ against true average margin (the RHS above) from our last post:</p>

<p><img alt="A graph comparing true and datamodel-predicted outcomes of model training." src="https://gradientscience.org/images/datamodels/Untitled%201.png"/></p>

<p>Datamodel predictiveness means we can (approximately) solve our earlier optimization problem (\eqref{eq:origobj}) by optimizing instead the <em>surrogate objective</em>:</p>

<p>\begin{align}
\tag{2}
\label{eq:surrogate1}
\min_{R \subset S} \vert R \vert \text{ such that } g(S \backslash R) \leq 0
\end{align}</p>

<p>Since $g(\cdot)$ is a simple (linear) function (see the drop-down below for more details), this new optimization problem is computationally easy to solve (and doesn‚Äôt involve training additional models).</p>

<section class="container">
<div>
<div class="checkboxdiv">
<input id="ac-1" name="accordion-1" type="checkbox"/>
<label for="ac-1"><span class="fas fa-chevron-right" id="titlespan"/><strong> Why is it easy to solve?</strong> (Click to expand)</label>
<article class="small">
In our last post, we showed that for deep neural networks, datamodels that are linear with respect to the <em>presence</em> of each training image can suffice to accurately predict model behavior. In the linear datamodel regime, we parameterize our datamodel $g(\cdot)$ for a target example $x$ with a weight vector $w \in \mathbb{R}^{50,000}$ (where $50,000$ is the size of the training set), and the datamodel prediction $g(S‚Äô)$ is precisely:
    
\begin{align}
    g(S‚Äô) = \mathbf{1}_{S‚Äô}^\top w,
\end{align}

where $\mathbf{1}_{S'}$ is a 50,000-dimensional indicator vector of $S'$ (i.e., taking on a value of one at index $i$ if the $i$-th training image is in $S'$, and zero otherwise).

Here, solving the optimization problem \(\eqref{eq:surrogate1}\) corresponds to choosing $R$ as the training images that correspond to the largest indices of $w_i$.
</article>
</div>
</div>
</section>
<p><br/></p>

<p>After finding a subset $R$ that minimizes the surrogate objective above, we can verify that $R$ is an upper bound on the objective above by training a collection of models on the remaining training images $S \setminus R$, and checking to see that the target example is misclassified on average. We can <em>ensure</em> we actually get an upper bound on the size of the minimum $R$ by solving</p>

<p>\begin{align}
\min_{R \subset S} \vert R \vert \text{ such that } g(S \setminus R) \leq C,
\end{align}</p>

<p>where $C&lt;0$ is a threshold that we (very coarsely) search for using the verification procedure‚Äîif the image isn‚Äôt misclassified on average, we can decrease $C$.</p>

<h2 id="looking-at-brittleness-in-aggregate">Looking at brittleness in aggregate</h2>

<p>So far in this post, we‚Äôve seen an example of data-level brittleness, and provided a datamodel-based method for estimating the brittleness of any given prediction. How brittle are model predictions as a whole?</p>

<p>We use our datamodel-based approach to estimate the data-level brittleness of each image in (a random sample of) the CIFAR-10 test set. Specifically, for each test image, we estimate (and bound) the number of training images one would need to remove in order to flip models‚Äô predictions on the test image. We plot the <em>cumulative distribution</em> of these estimates below: a point $(x, y)$ on the blue line below indicates that a $y$ fraction of test set predictions are brittle to the removal of at most $x$ training images.</p>

<p><img alt="CDF of data-level brittleness" src="https://gradientscience.org/images/datamodels/cifar_brittleness_combined_withflips_False.svg"/></p>

<p>It turns out that our motivating boat example is not so unusual. In fact, for around 20% of the CIFAR-10 test images it suffices to remove fewer than 60 training images to induce misclassification! Also, for around half of the test examples, it suffices to remove fewer than 250 training images (still only 0.5% of the training set).</p>

<p>The other lines in the graph above illustrate just how hard it is to identify prediction brittleness via other means. Each one represents a different heuristic: a point $(x, y)$ on the line indicates that for a $y$-fraction of the test set, removing the $x$ most similar images to the target example (according to the corresponding heuristic) is necessary to flip models‚Äô predictions. (See Appendix F.2 in our <a href="https://arxiv.org/abs/2202.00622">paper</a> for more details on these baselines!)</p>

<h2 id="bonus-label-flipping-attacks">Bonus: Label-flipping attacks</h2>

<p>One immediate consequence of the techniques we discovered in this blog post is the existence of strong <em>label-flipping</em> attacks. So far, we‚Äôve looked exclusively at the result of removing training images‚Äîif we use the exact same technique but instead just flip the labels of the images we would have removed, we find more severe brittleness:</p>

<p><img alt="flipping.png" src="https://gradientscience.org/images/datamodels/cifar_brittleness_combined_withflips_True_True.svg"/></p>

<p>The dashed line above is the same as the blue line from earlier‚Äîthe new solid blue line shows that for over half of the CIFAR-10 test images, we are able to induce misclassification by relabeling just 35 (target-specific) images!</p>

<h2 id="conclusion">Conclusion</h2>

<p>In this post, we introduced a new notion of model brittleness, examined how to quantify it with datamodels, and demonstrated that a large fraction of predictions on the CIFAR-10 test set are quite brittle.</p>

<p>Our results demonstrate one of many ways in which datamodels can be a useful proxy for end-to-end training. More broadly (and as we‚Äôll see in our upcoming posts!), datamodels open the door to many other fine-grained analyses of model predictions.</p></div>
    </summary>
    <updated>2022-05-11T00:00:00Z</updated>
    <published>2022-05-11T00:00:00Z</published>
    <source>
      <id>https://gradientscience.org/</id>
      <author>
        <name>Gradient Science</name>
      </author>
      <link href="https://gradientscience.org/" rel="alternate" type="text/html"/>
      <link href="https://gradientscience.org/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Research highlights and perspectives on machine learning and optimization from MadryLab.</subtitle>
      <title>gradient science</title>
      <updated>2022-05-24T01:08:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2022/05/10/postdoc-in-tcs-and-or-combinatorial-optimization-at-university-of-copenhagen-apply-by-june-29-2022/</id>
    <link href="https://cstheory-jobs.org/2022/05/10/postdoc-in-tcs-and-or-combinatorial-optimization-at-university-of-copenhagen-apply-by-june-29-2022/" rel="alternate" type="text/html"/>
    <title>Postdoc in TCS and/or combinatorial optimization at University of Copenhagen (apply by June 29, 2022)</title>
    <summary>The CS department at the University of Copenhagen invites applications for postdoc positions in TCS and/or combinatorial optimization. The application deadline is June 29. See http://www.jakobnordstrom.se/openings/Postdoc-UCPH-220629.html for the full announcement with more information and instructions for how to apply. Informal enquiries are welcome and may be sent to jn@di.ku.dk. Website: https://employment.ku.dk/faculty/?show=156468 Email: jn@di.ku.dk</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The CS department at the University of Copenhagen invites applications for postdoc positions in TCS and/or combinatorial optimization. The application deadline is June 29. See <a href="http://www.jakobnordstrom.se/openings/Postdoc-UCPH-220629.html">http://www.jakobnordstrom.se/openings/Postdoc-UCPH-220629.html</a> for the full announcement with more information and instructions for how to apply. Informal enquiries are welcome and may be sent to jn@di.ku.dk.</p>
<p>Website: <a href="https://employment.ku.dk/faculty/?show=156468">https://employment.ku.dk/faculty/?show=156468</a><br/>
Email: jn@di.ku.dk</p></div>
    </content>
    <updated>2022-05-10T22:12:21Z</updated>
    <published>2022-05-10T22:12:21Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2022-05-24T10:37:30Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2022/05/10/ideal-workshop-on-algorithms-for-massive-data-sets/</id>
    <link href="https://cstheory-events.org/2022/05/10/ideal-workshop-on-algorithms-for-massive-data-sets/" rel="alternate" type="text/html"/>
    <title>IDEAL Workshop on Algorithms for Massive Data Sets</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">May 13, 2022 Northwestern University and Zoom https://www.ideal.northwestern.edu/events/massive-data-sets/ We are inviting you to attend the IDEAL Workshop on Algorithms for Massive Data Sets. The workshop will take place at Northwestern University on Friday, May 13. It will be in a hybrid format. If you are interested in participating in the workshop (in-person or remotely), please ‚Ä¶ <a class="more-link" href="https://cstheory-events.org/2022/05/10/ideal-workshop-on-algorithms-for-massive-data-sets/">Continue reading <span class="screen-reader-text">IDEAL Workshop on Algorithms for Massive Data¬†Sets</span></a></div>
    </summary>
    <updated>2022-05-10T16:07:55Z</updated>
    <published>2022-05-10T16:07:55Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2022-05-24T10:38:04Z</updated>
    </source>
  </entry>
</feed>
