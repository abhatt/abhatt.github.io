<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-06-30T11:21:59Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4886</id>
    <link href="https://www.scottaaronson.com/blog/?p=4886" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4886#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4886" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">David Poulin</title>
    <summary xml:lang="en-US">2020 sucks. Yesterday I learned that David Poulin, a creative and widely-beloved quantum computing and information theorist, has died at age 43, of an aggressive brain cancer. After studying under many of the field’s legends—Gilles Brassard, Wojciech Zurek, Ray Laflamme, Gerard Milburn, John Preskill—David became a professor at the University of Sherbrooke in Quebec. There […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><div class="wp-block-image"><figure class="aligncenter"><img alt="100+ &quot;Dave Poulin&quot; profiles | LinkedIn" src="https://media-exp1.licdn.com/dms/image/C4E03AQG9DmvmxhU3RA/profile-displayphoto-shrink_200_200/0?e=1597276800&amp;v=beta&amp;t=wav_nmh_CgU1IgzEbc89IQlfL5fNg0k6lcxs9_F_6qk"/></figure></div>



<p>2020 sucks.</p>



<p>Yesterday I learned that <a href="https://www.cifar.ca/cifarnews/2020/06/18/a-quantum-festschrift-for-david-poulin">David Poulin</a>, a creative and widely-beloved quantum computing and information theorist, has died at age 43, of an aggressive brain cancer.  After studying under many of the field’s legends—Gilles Brassard, Wojciech Zurek, Ray Laflamme, Gerard Milburn, John Preskill—David became a professor at the University of Sherbrooke in Quebec.  There he played a leading role in CIFAR (the Canadian Institute For Advanced Research), eventually co-directing its quantum information science program with Aephraim Steinberg.  Just this fall (!), David moved to Microsoft Research to start a new phase of his career.  He’s survived by a large family.</p>



<p>While I can’t claim any deep knowledge of David’s work—he and I pursued very different problems—it seems appropriate to mention some of his best-known contributions.  With David Kribs, Ray Laflamme, and Maia Lesosky, he <a href="https://arxiv.org/abs/quant-ph/0504189">introduced</a> the formalism of operator quantum error correction, and made many other contributions to the theory of quantum error-correction and fault-tolerance (including the estimation of thresholds).  He and coauthors <a href="https://www.nature.com/articles/ncomms1147">showed</a> in a <em>Nature</em> paper how to do quantum state tomography on 1D matrix product states efficiently.  With Pavithran Iyer, he <a href="https://arxiv.org/abs/1310.3235">proved</a> that optimal decoding of stabilizer codes is #P-hard.</p>



<p>And if none of that makes a sufficient impression on <em>Shtetl-Optimized</em> readers: well, back in 2013, when D-Wave was claiming to have achieved huge quantum speedups, David Poulin was one of the few experts willing to take a clear skeptical stance in public (including right in my comment section—see <a href="https://www.scottaaronson.com/blog/?p=1400#comment-79596">here</a> for example).</p>



<p>I vividly remember being officemates with David back in 2003, at the Perimeter Institute in Waterloo—before Perimeter had its sleek black building, when it still operated out of a converted tavern.  (My and David’s office was in the basement, reached via a narrow staircase.)  David liked to tease me: for example, if I found him in conversation with someone else and asked what it was about, he’d say, “oh, nothing to do with computational efficiency, no reason for you to care.”  (And yet, much of David’s work ultimately <em>would</em> have to do with computational efficiency.)</p>



<p>David was taken way too soon and will be missed by everyone who knew him.  Feel free to share David stories in the comments.</p></div>
    </content>
    <updated>2020-06-30T04:47:23Z</updated>
    <published>2020-06-30T04:47:23Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Announcements"/>
    <category scheme="https://www.scottaaronson.com/blog" term="Quantum"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-06-30T04:47:23Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15812</id>
    <link href="http://arxiv.org/abs/2006.15812" rel="alternate" type="text/html"/>
    <title>Statistical-Query Lower Bounds via Functional Gradients</title>
    <feedworld_mtime>1593475200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goel:Surbhi.html">Surbhi Goel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gollakota:Aravind.html">Aravind Gollakota</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klivans:Adam.html">Adam Klivans</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15812">PDF</a><br/><b>Abstract: </b>We give the first statistical-query lower bounds for agnostically learning
any non-polynomial activation with respect to Gaussian marginals (e.g., ReLU,
sigmoid, sign). For the specific problem of ReLU regression (equivalently,
agnostically learning a ReLU), we show that any statistical-query algorithm
with tolerance $n^{-\Theta(\epsilon^{-1/2})}$ must use at least $2^{n^c}
\epsilon$ queries for some constant $c &gt; 0$, where $n$ is the dimension and
$\epsilon$ is the accuracy parameter. Our results rule out general (as opposed
to correlational) SQ learning algorithms, which is unusual for real-valued
learning problems. Our techniques involve a gradient boosting procedure for
"amplifying" recent lower bounds due to Diakonikolas et al. (COLT 2020) and
Goel et al. (ICML 2020) on the SQ dimension of functions computed by two-layer
neural networks. The crucial new ingredient is the use of a nonstandard convex
functional during the boosting procedure. This also yields a best-possible
reduction between two commonly studied models of learning: agnostic learning
and probabilistic concepts.
</p></div>
    </summary>
    <updated>2020-06-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15747</id>
    <link href="http://arxiv.org/abs/2006.15747" rel="alternate" type="text/html"/>
    <title>The Hylland-Zeckhauser Rule Under Bi-Valued Utilities</title>
    <feedworld_mtime>1593475200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aziz:Haris.html">Haris Aziz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15747">PDF</a><br/><b>Abstract: </b>The Hylland-Zeckhauser (HZ) rule is a well-known rule for probabilistic
assignment of items. The complexity of the rule has received renewed interest
recently with Vazirani and Yannakakis (2020) proposing a strongly
polynomial-time algorithm for the rule under bi-valued utilities, and making
several general insights. We study the rule under the case of agents having
bi-valued utilities. We point out several characterizations of the HZ rule,
drawing clearer relations with several well-known rules in the literature. As a
consequence, we point out alternative strongly polynomial-time algorithms for
the HZ solution. We also give reductions from computing the HZ solution to
computing well-known solutions based on leximin or Nash social welfare. An
interesting contrast is that the HZ rule is group-strategyproof whereas the
unconstrained competitive equilibrium with equal incomes rule is not even
strategyproof. We also clarify which results change when moving from 1-0 binary
utilities to the more general bi-valued utilities.
</p></div>
    </summary>
    <updated>2020-06-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15744</id>
    <link href="http://arxiv.org/abs/2006.15744" rel="alternate" type="text/html"/>
    <title>Fast and Private Submodular and $k$-Submodular Functions Maximization with Matroid Constraints</title>
    <feedworld_mtime>1593475200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rafiey:Akbar.html">Akbar Rafiey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yoshida:Yuichi.html">Yuichi Yoshida</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15744">PDF</a><br/><b>Abstract: </b>The problem of maximizing nonnegative monotone submodular functions under a
certain constraint has been intensively studied in the last decade, and a wide
range of efficient approximation algorithms have been developed for this
problem. Many machine learning problems, including data summarization and
influence maximization, can be naturally modeled as the problem of maximizing
monotone submodular functions. However, when such applications involve
sensitive data about individuals, their privacy concerns should be addressed.
In this paper, we study the problem of maximizing monotone submodular functions
subject to matroid constraints in the framework of differential privacy. We
provide $(1-\frac{1}{\mathrm{e}})$-approximation algorithm which improves upon
the previous results in terms of approximation guarantee. This is done with an
almost cubic number of function evaluations in our algorithm.
</p>
<p>Moreover, we study $k$-submodularity, a natural generalization of
submodularity. We give the first $\frac{1}{2}$-approximation algorithm that
preserves differential privacy for maximizing monotone $k$-submodular functions
subject to matroid constraints. The approximation ratio is asymptotically tight
and is obtained with an almost linear number of function evaluations.
</p></div>
    </summary>
    <updated>2020-06-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15664</id>
    <link href="http://arxiv.org/abs/2006.15664" rel="alternate" type="text/html"/>
    <title>Minimizing The Maximum Distance Traveled To Form Patterns With Systems of Mobile Robots</title>
    <feedworld_mtime>1593475200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jared Coleman, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kranakis:Evangelos.html">Evangelos Kranakis</a>, Oscar Morales-Ponce, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Opatrny:Jaroslav.html">Jaroslav Opatrny</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Urrutia:Jorge.html">Jorge Urrutia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vogtenhuber:Birgit.html">Birgit Vogtenhuber</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15664">PDF</a><br/><b>Abstract: </b>In the pattern formation problem, robots in a system must self-coordinate to
form a given pattern, regardless of translation, rotation, uniform-scaling,
and/or reflection. In other words, a valid final configuration of the system is
a formation that is \textit{similar} to the desired pattern. While there has
been no shortage of research in the pattern formation problem under a variety
of assumptions, models, and contexts, we consider the additional constraint
that the maximum distance traveled among all robots in the system is minimum.
Existing work in pattern formation and closely related problems are typically
application-specific or not concerned with optimality (but rather feasibility).
We show the necessary conditions any optimal solution must satisfy and present
a solution for systems of three robots. Our work also led to an interesting
result that has applications beyond pattern formation. Namely, a metric for
comparing two triangles where a distance of $0$ indicates the triangles are
similar, and $1$ indicates they are \emph{fully dissimilar}.
</p></div>
    </summary>
    <updated>2020-06-30T01:55:50Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15650</id>
    <link href="http://arxiv.org/abs/2006.15650" rel="alternate" type="text/html"/>
    <title>Social Distancing is Good for Points too!</title>
    <feedworld_mtime>1593475200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Flores=Velazco:Alejandro.html">Alejandro Flores-Velazco</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15650">PDF</a><br/><b>Abstract: </b>The nearest-neighbor rule is a well-known classification technique that,
given a training set P of labeled points, classifies any unlabeled query point
with the label of its closest point in P. The nearest-neighbor condensation
problem aims to reduce the training set without harming the accuracy of the
nearest-neighbor rule.
</p>
<p>FCNN is the most popular algorithm for condensation. It is heuristic in
nature, and theoretical results for it are scarce. In this paper, we settle the
question of whether reasonable upper-bounds can be proven for the size of the
subset selected by FCNN. First, we show that the algorithm can behave poorly
when points are too close to each other, forcing it to select many more points
than necessary. We then successfully modify the algorithm to avoid such cases,
thus imposing that selected points should "keep some distance". This
modification is sufficient to prove useful upper-bounds, along with
approximation guarantees for the algorithm.
</p></div>
    </summary>
    <updated>2020-06-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15584</id>
    <link href="http://arxiv.org/abs/2006.15584" rel="alternate" type="text/html"/>
    <title>A Polynomial Kernel for Line Graph Deletion</title>
    <feedworld_mtime>1593475200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eiben:Eduard.html">Eduard Eiben</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lochet:William.html">William Lochet</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15584">PDF</a><br/><b>Abstract: </b>The line graph of a graph $G$ is the graph $L(G)$ whose vertex set is the
edge set of $G$ and there is an edge between $e,f\in E(G)$ if $e$ and $f$ share
an endpoint in $G$. A graph is called line graph if it is a line graph of some
graph. We study the Line-Graph-Edge Deletion problem, which asks whether we can
delete at most $k$ edges from the input graph $G$ such that the resulting graph
is a line graph. More precisely, we give a polynomial kernel for
Line-Graph-Edge Deletion with $\mathcal{O}(k^{5})$ vertices. This answers an
open question posed by Falk H\"{u}ffner at Workshop on Kernels (WorKer) in
2013.
</p></div>
    </summary>
    <updated>2020-06-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15575</id>
    <link href="http://arxiv.org/abs/2006.15575" rel="alternate" type="text/html"/>
    <title>Random Access in Persistent Strings</title>
    <feedworld_mtime>1593475200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bille:Philip.html">Philip Bille</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=oslash=rtz:Inge_Li.html">Inge Li Gørtz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15575">PDF</a><br/><b>Abstract: </b>We consider compact representations of collections of similar strings that
support random access queries. The collection of strings is given by a rooted
tree where edges are labeled by an edit operation (inserting, deleting, or
replacing a character) and a node represents the string obtained by applying
the sequence of edit operations on the path from the root to the node. The goal
is to compactly represent the entire collection while supporting fast random
access to any part of a string in the collection. This problem captures natural
scenarios such as representing the past history of a edited document or
representing highly-repetitive collections. Given a tree with $n$ nodes, we
show how to represent the corresponding collection in $O(n)$ space and optimal
$O(\log n/ \log \log n)$ query time. This improves the previous time-space
trade-offs for the problem. To obtain our results, we introduce new techniques
and ideas, including a reduction to a new geometric line segment selection
together with an efficient solution.
</p></div>
    </summary>
    <updated>2020-06-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15512</id>
    <link href="http://arxiv.org/abs/2006.15512" rel="alternate" type="text/html"/>
    <title>Parallel Weighted Model Counting with Tensor Networks</title>
    <feedworld_mtime>1593475200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dudek:Jeffrey_M=.html">Jeffrey M. Dudek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vardi:Moshe_Y=.html">Moshe Y. Vardi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15512">PDF</a><br/><b>Abstract: </b>A promising new algebraic approach to weighted model counting makes use of
tensor networks, following a reduction from weighted model counting to
tensor-network contraction. Prior work has focused on analyzing the single-core
performance of this approach, and demonstrated that it is an effective addition
to the current portfolio of weighted-model-counting algorithms.
</p>
<p>In this work, we explore the impact of multi-core and GPU use on
tensor-network contraction for weighted model counting. To leverage multiple
cores, we implement a parallel portfolio of tree-decomposition solvers to find
an order to contract tensors. To leverage a GPU, we use TensorFlow to perform
the contractions. We compare the resulting weighted model counter on 1914
standard weighted model counting benchmarks and show that it significantly
improves the virtual best solver.
</p></div>
    </summary>
    <updated>2020-06-30T01:32:33Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15463</id>
    <link href="http://arxiv.org/abs/2006.15463" rel="alternate" type="text/html"/>
    <title>Queues with Small Advice</title>
    <feedworld_mtime>1593475200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitzenmacher:Michael.html">Michael Mitzenmacher</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15463">PDF</a><br/><b>Abstract: </b>Motivated by recent work on scheduling with predicted job sizes, we consider
the performance of scheduling algorithms with minimal advice, namely a single
bit. Besides demonstrating the power of very limited advice, such schemes are
quite natural. In the prediction setting, one bit of advice can be used to
model a simple prediction as to whether a job is "large" or "small"; that is,
whether a job is above or below a given threshold. Further, one-bit advice
schemes can correspond to mechanisms that tell whether to put a job at the
front or the back for the queue, a limitation which may be useful in many
implementation settings. Finally, queues with a single bit of advice have a
simple enough state that they can be analyzed in the limiting mean-field
analysis framework for the power of two choices. Our work follows in the path
of recent work by showing that even small amounts of even possibly inaccurate
information can greatly improve scheduling performance.
</p></div>
    </summary>
    <updated>2020-06-30T01:29:18Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15412</id>
    <link href="http://arxiv.org/abs/2006.15412" rel="alternate" type="text/html"/>
    <title>Submodular Combinatorial Information Measures with Applications in Machine Learning</title>
    <feedworld_mtime>1593475200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iyer:Rishabh.html">Rishabh Iyer</a>, Ninad Khargoankar, Jeff Bilmes, Himanshu Asanani <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15412">PDF</a><br/><b>Abstract: </b>Information-theoretic quantities like entropy and mutual information have
found numerous uses in machine learning. It is well known that there is a
strong connection between these entropic quantities and submodularity since
entropy over a set of random variables is submodular. In this paper, we study
combinatorial information measures that generalize independence, (conditional)
entropy, (conditional) mutual information, and total correlation defined over
sets of (not necessarily random) variables. These measures strictly generalize
the corresponding entropic measures since they are all parameterized via
submodular functions that themselves strictly generalize entropy. Critically,
we show that, unlike entropic mutual information in general, the submodular
mutual information is actually submodular in one argument, holding the other
fixed, for a large class of submodular functions whose third-order partial
derivatives satisfy a non-negativity property. This turns out to include a
number of practically useful cases such as the facility location and set-cover
functions. We study specific instantiations of the submodular information
measures on these, as well as the probabilistic coverage, graph-cut, and
saturated coverage functions, and see that they all have mathematically
intuitive and practically useful expressions. Regarding applications, we
connect the maximization of submodular (conditional) mutual information to
problems such as mutual-information-based, query-based, and privacy-preserving
summarization -- and we connect optimizing the multi-set submodular mutual
information to clustering and robust partitioning.
</p></div>
    </summary>
    <updated>2020-06-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15381</id>
    <link href="http://arxiv.org/abs/2006.15381" rel="alternate" type="text/html"/>
    <title>The Generalized Independent and Dominating Set Problems on Unit Disk Graphs</title>
    <feedworld_mtime>1593475200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jena:Sangram_K=.html">Sangram K. Jena</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jallu:Ramesh_K=.html">Ramesh K. Jallu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Das:Gautam_K=.html">Gautam K. Das</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nandy:Subhas_C=.html">Subhas C. Nandy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15381">PDF</a><br/><b>Abstract: </b>In this article, we study a generalized version of the maximum independent
set and minimum dominating set problems, namely, the maximum $d$-distance
independent set problem and the minimum $d$-distance dominating set problem on
unit disk graphs for a positive integer $d&gt;0$. We first show that the maximum
$d$-distance independent set problem and the minimum $d$-distance dominating
set problem belongs to NP-hard class. Next, we propose a simple polynomial-time
constant-factor approximation algorithms and PTAS for both the problems.
</p></div>
    </summary>
    <updated>2020-06-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15349</id>
    <link href="http://arxiv.org/abs/2006.15349" rel="alternate" type="text/html"/>
    <title>Chroma Intra Prediction with attention-based CNN architectures</title>
    <feedworld_mtime>1593475200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=oacute=rriz:Marc.html">Marc Górriz</a>, Saverio Blasi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Smeaton:Alan_F=.html">Alan F. Smeaton</a>, Noel E. O'Connor, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mrak:Marta.html">Marta Mrak</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15349">PDF</a><br/><b>Abstract: </b>Neural networks can be used in video coding to improve chroma
intra-prediction. In particular, usage of fully-connected networks has enabled
better cross-component prediction with respect to traditional linear models.
Nonetheless, state-of-the-art architectures tend to disregard the location of
individual reference samples in the prediction process. This paper proposes a
new neural network architecture for cross-component intra-prediction. The
network uses a novel attention module to model spatial relations between
reference and predicted samples. The proposed approach is integrated into the
Versatile Video Coding (VVC) prediction pipeline. Experimental results
demonstrate compression gains over the latest VVC anchor compared with
state-of-the-art chroma intra-prediction methods based on neural networks.
</p></div>
    </summary>
    <updated>2020-06-30T01:20:24Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-06-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15259</id>
    <link href="http://arxiv.org/abs/2006.15259" rel="alternate" type="text/html"/>
    <title>Reconstructing Biological and Digital Phylogenetic Trees in Parallel</title>
    <feedworld_mtime>1593475200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Ramtin Afshar, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goodrich:Michael_T=.html">Michael T. Goodrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Matias:Pedro.html">Pedro Matias</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Osegueda:Martha_C=.html">Martha C. Osegueda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15259">PDF</a><br/><b>Abstract: </b>In this paper, we study the parallel query complexity of reconstructing
biological and digital phylogenetic trees from simple queries involving their
nodes. This is motivated from computational biology, data protection, and
computer security settings, which can be abstracted in terms of two parties, a
\emph{responder}, Alice, who must correctly answer queries of a given type
regarding a degree-$d$ tree, $T$, and a \emph{querier}, Bob, who issues batches
of queries, with each query in a batch being independent of the others, so as
to eventually infer the structure of $T$. We show that a querier can
efficiently reconstruct an $n$-node degree-$d$ tree, $T$, with a logarithmic
number of rounds and quasilinear number of queries, with high probability, for
various types of queries, including \emph{relative-distance queries} and
\emph{path queries}. Our results are all asymptotically optimal and improve the
asymptotic (sequential) query complexity for one of the problems we study.
Moreover, through an experimental analysis using both real-world and synthetic
data, we provide empirical evidence that our algorithms provide significant
parallel speedups while also improving the total query complexities for the
problems we study.
</p></div>
    </summary>
    <updated>2020-06-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15254</id>
    <link href="http://arxiv.org/abs/2006.15254" rel="alternate" type="text/html"/>
    <title>Optimizing Cuckoo Filter for high burst tolerance,low latency, and high throughput</title>
    <feedworld_mtime>1593475200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Aman Khalid <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15254">PDF</a><br/><b>Abstract: </b>In this paper, we present an implementation of a cuckoo filter for membership
testing, optimized for distributed data stores operating in high workloads. In
large databases, querying becomes inefficient using traditional search methods.
To achieve optimal performance it is necessary to use probabilistic data
structures to test the membership of a given key, at the cost of getting false
positives while querying data. The widely used bloom filters can be used for
this, but they have limitations like no support for deletes. To improve upon
this we use a modified version of the cuckoo filter that gives better amortized
times for search, with less false positives.
</p></div>
    </summary>
    <updated>2020-06-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15166</id>
    <link href="http://arxiv.org/abs/2006.15166" rel="alternate" type="text/html"/>
    <title>Dominate or Delete: Decentralized Competing Bandits with Uniform Valuation</title>
    <feedworld_mtime>1593475200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sankararaman:Abishek.html">Abishek Sankararaman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Basu:Soumya.html">Soumya Basu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sankararaman:Karthik_Abinav.html">Karthik Abinav Sankararaman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15166">PDF</a><br/><b>Abstract: </b>We study regret minimization problems in a two-sided matching market where
uniformly valued demand side agents (a.k.a. agents) continuously compete for
getting matched with supply side agents (a.k.a. arms) with unknown and
heterogeneous valuations. Such markets abstract online matching platforms (for
e.g. UpWork, TaskRabbit) and falls within the purview of matching bandit models
introduced in Liu et al. \cite{matching_bandits}. The uniform valuation in the
demand side admits a unique stable matching equilibrium in the system. We
design the first decentralized algorithm - \fullname\; (\name), for matching
bandits under uniform valuation that does not require any knowledge of reward
gaps or time horizon, and thus partially resolves an open question in
\cite{matching_bandits}. \name\; works in phases of exponentially increasing
length. In each phase $i$, an agent first deletes dominated arms -- the arms
preferred by agents ranked higher than itself. Deletion follows dynamic
explore-exploit using UCB algorithm on the remaining arms for $2^i$ rounds.
{Finally, the preferred arm is broadcast in a decentralized fashion to other
agents through {\em pure exploitation} in $(N-1)K$ rounds with $N$ agents and
$K$ arms.} Comparing the obtained reward with respect to the unique stable
matching, we show that \name\; achieves $O(\log(T)/\Delta^2)$ regret in $T$
rounds, where $\Delta$ is the minimum gap across all agents and arms. We
provide a (orderwise) matching regret lower-bound.
</p></div>
    </summary>
    <updated>2020-06-30T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-30T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17244</id>
    <link href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/" rel="alternate" type="text/html"/>
    <title>Taking a Problem Down a Peg</title>
    <summary>By blowing up its objects Composite crop of src1, src2 Joshua Greene and Andrew Lobb proved last month that every smooth Jordan curve in the plane and real , there are four points on the curve that form a rectangle with sides of ratio . Today we explain how this result relates to Otto Toeplitz’s […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>By blowing up its objects</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/greenelobb/" rel="attachment wp-att-17246"><img alt="" class="alignright wp-image-17246" height="120" src="https://rjlipton.files.wordpress.com/2020/06/greenelobb.png?w=183&amp;h=120" width="183"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop of <a href="https://math.berkeley.edu/people/faculty/joshua-evan-greene">src1</a>, <a href="https://groups.oist.jp/mathprog/andrew-lobb">src2</a></font></td>
</tr>
</tbody>
</table>
<p>
Joshua Greene and Andrew Lobb <a href="https://arxiv.org/pdf/2005.09193.pdf">proved</a> last month that every <em>smooth</em> Jordan curve in the plane and real <img alt="{r \leq 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%5Cleq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r \leq 1}"/>, there are four points on the curve that form a rectangle with sides of ratio <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/>.</p>
<p>
Today we explain how this result relates to Otto Toeplitz’s famous “square peg conjecture,” which is the case <img alt="{r = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r = 1}"/> when the curve need not be smooth.</p>
<p>
We noticed this via an <a href="https://www.quantamagazine.org/new-geometric-perspective-cracks-old-problem-about-rectangles-20200625/">article</a> last Thursday by Kevin Hartnett for <em>Quanta</em>. Hartnett describes this research advance as a product of the pandemic inducing them to take time for deeper reflection on fundamental problems. We wonder how much is bubbling on hard problems in our own field—this is one reason for our last post’s <a href="https://rjlipton.wordpress.com/2020/06/21/some-real-and-some-virtual-news">interest</a> in (good kinds of) “gossip.”  He also gives great diagrams for the geometrical intuition.</p>
<p>
We will portray this advance instead along lines of things we’ve said recently about how to attack hard problems by seeking and solving simpler ones or special cases as stepping stones. Dick wrote a <a href="https://rjlipton.wordpress.com/2018/10/21/the-inscribed-square-problem/">post</a> two years ago on the original Toeplitz problem, which this work still leaves open. That post focused on ways general Jordan curves can be nasty. This one needs an extra niceness condition but proves a stronger result for all <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/>. How much can progress on “nice” inform problems with “nasty”? That kind of question comes up in complexity theory all the time.</p>
<p>
</p><p/><h2> Pegging Rectangles </h2><p/>
<p/><p>
A <em>Jordan curve</em> is the image of a continuous 1-1 map <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> from the circle to the plane. The condition of being 1-1 prevents the image from intersecting itself, so it is a single closed loop. By the Jordan curve <a href="https://en.wikipedia.org/wiki/Jordan_curve_theorem">theorem</a>, the loop always partitions the rest of the plane into two connected regions, exactly one of which is bounded. Amazingly, a Jordan curve <a href="https://en.wikipedia.org/wiki/Osgood_curve">can</a> have positive Lebesgue measure, yet cannot fill all of <img alt="{\mathbb{R}^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BR%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{R}^2}"/>. Such curves can, however, approach the kind of space-filling curves defined by Giuseppe Peano, and thus have any Lebesgue density less than <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>, as was noted also by William Osgood in his 1903 <a href="https://www.jstor.org/stable/pdf/1986455.pdf">paper</a>.</p>
<p>
The Toeplitz conjecture is that every Jordan curve has four points that form a square. As noted in Dick’s post, the positive-area case is actually an easy yes-case. Nasty cases are where the curve is nowhere-differentiable with zero area. Thus far, the problem has been answered <em>yes</em> only in the presence of some uniformity condition that limits the local nastiness of the curve. The simplest one is for the curve to be <em>smooth</em> in that <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> has a continuous first derivative. Here is a smooth curve that is not convex, so that the square need not be “inside” the curve:</p>
<p/><p/>
<p><a href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/matschkefig2/" rel="attachment wp-att-17247"><img alt="" class="aligncenter size-full wp-image-17247" src="https://rjlipton.files.wordpress.com/2020/06/matschkefig2.jpg?w=600"/></a></p>
<p>
This diagram is from Benjamin Matchske’s wonderful recent <a href="https://www.ams.org/notices/201404/rnoti-p346.pdf">survey</a> of the peg problem in the <em>AMS Notices</em>. Four months ago we’d have said it looks like a thin heart or fat boomerang. <i>Now</i> it looks to us like a face mask.</p>
<p>
As the survey notes, it is easy to show that every Jordan curve has <em>some</em> rectangle. The rectangle problem is to show that rectangles of <i>every</i> aspect ratio <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> can be pegged to the curve. There are two main reasons the square and rectangle problems are hard and harder:</p>
<ol>
<li>
Although any Jordan curve can be written as a limit of nice ones, the squares in the nice ones can degenerate to a single point in the limit. <p/>
</li><li>
Even for nice curves, a parity property that holds for squares can fail for rectangles.
</li></ol>
<p>
The property in the second point enables arguments of the kind: <em>for generic curves the number of squares is odd, therefore it is nonzero</em>. This then carries over to sufficiently nice curves in the generic closure. The failure of this property for rectangles is a main reason the results by Greene and Lobb are new.</p>
<p>
</p><p/><h2> The Paper </h2><p/>
<p/><p>
The new paper is written tersely at a high level, and we must confess not being able to catch all details in compressed time. But we can highlight some aspects of the argument. First, as we have said, it exemplifies:</p>
<ul>
<li>
<em>Solve a Simpler Problem</em>.
</li></ul>
<p>
This is however coupled with a second aspect:</p>
<ul>
<li>
<em>Bring Up the Reserves</em>.
</li></ul>
<p>
It may be that the rectangle conjecture is not only true but “equally true” in the sense that the fundamental reason applies equally well to the case of rectangles. The parity argument that works for cases involving squares may be a crutch that misses the deepest explanations. Promoting arguments that avoid this crutch may marshal resources needed to make a breakthrough on the main problem for completely general Jordan curves.</p>
<p>
This runs somewhat counter to what we have said about <img alt="{\mathsf{NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{NP}}"/> versus <img alt="{\mathsf{P}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P}}"/> proof attempts recently. The reason for <img alt="{\mathsf{P &lt; NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P &lt; NP}}"/> believed by most is that problems like SAT require <em>exponential</em> time, not just super-polynomial time. Yet no one knows even a <em>super-linear</em> lower bound, apart from barely-superlinear bounds that exploit grainy aspects of the multitape Turing machine model and apply only to it. Nor is any super-linear lower bound known on Boolean circuit size. Maybe it is a viable strategy also to “bring up reserves” by finding restricted cases where (conditional) exponential lower bounds can be proven, as well as to explore contingencies like <a href="https://en.wikipedia.org/wiki/Exponential_time_hypothesis">SETH</a>, as we covered <a href="https://rjlipton.wordpress.com/2015/06/01/puzzling-evidence/">here</a>. But both of use have always felt that the super-linear frontier holds the buried keys to further progress.</p>
<p>
The Greene-Lobb proof has two aspects that may also resonate in complexity:</p>
<ul>
<li>
<em>Blow Up the Objects</em>.
</li></ul>
<p>
The <a href="https://www.quantamagazine.org/new-geometric-perspective-cracks-old-problem-about-rectangles-20200625/">article</a> in <em>Quanta</em> has great diagrams illustrating how the set of pairs of points on the curve corresponds to a Möbius strip in a related space. Cole Hugelmeyer, a graduate student at Princeton, <a href="https://arxiv.org/pdf/1911.07336.pdf">proved</a> last year how to get rectangles covering at least one-third of possible values <img alt="{r \in (0,1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%5Cin+%280%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r \in (0,1]}"/> by embedding the Möbius strips in a four-dimensional space. Intersections between a strip and a rotated copy yield rectangles on the original Jordan curve. </p>
<p>
That led Greene and Lobb to consider larger objects with properties like pairs of Möbius strips in the larger space. The Klein bottle is the natural next thing to consider and led to a feature of their proof that made the desired conclusion pop out:</p>
<ul>
<li>
<em>Identify and Rule Out Obstructions</em>.
</li></ul>
<p>
The clever point pivots on the fact that a Klein bottle cannot be smoothly embedded into the complex plane <img alt="{\mathbb{C}^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BC%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathbb{C}^2}"/> as a Lagrangian submanifold. The proof shows that for any prescribed aspect ratio <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> one can construct a mapping that almost succeeds in embedding such a Klein bottle. The fact that it must fail means that the image must yield a point of intersection witnessing the failure. The presence of this point then yields the construction of four other points on the Jordan curve that form the vertices of the needed rectangle.</p>
<p>
We have briefly <a href="https://rjlipton.wordpress.com/2018/06/06/princeton-is-invariant/">mentioned</a> how the concept of <em>obstructions</em> is integral to the <a href="https://en.wikipedia.org/wiki/Geometric_complexity_theory">Geometric</a> <a href="https://dl.acm.org/doi/10.1145/1944345.1944346">Complexity</a> <a href="http://gct.cs.uchicago.edu/">Theory</a> attack on <img alt="{\mathsf{P &lt; NP}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{P &lt; NP}}"/>. Closer to home, however, is how László Babai's graph isomorphism algorithm and proof works by identifying a subclass of graphs called Johnson graphs as obstructions to a simpler algorithm, as we highlighted <a href="https://rjlipton.wordpress.com/2017/01/06/snow-and-theory/">here</a>.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Can you find more lessons from the new advance on the Toeplitz problem?  Dick and I have considered ideas of blowing up from languages to pairs of languages (and making <i>reductions</i> between problems the fundamental units of analysis) but this has not gone beyond dreamwork.</p>
<p/></font></font></div>
    </content>
    <updated>2020-06-29T21:20:08Z</updated>
    <published>2020-06-29T21:20:08Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="Andrew Lobb"/>
    <category term="Cole Hugelmeyer"/>
    <category term="computational geometry"/>
    <category term="conjecture"/>
    <category term="geometry"/>
    <category term="Joshua Greene"/>
    <category term="Toeplitz"/>
    <author>
      <name>KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-06-30T11:20:52Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-7761235140481153504</id>
    <link href="https://blog.computationalcomplexity.org/feeds/7761235140481153504/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/can-you-name-famous-living-chemist-can.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7761235140481153504" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/7761235140481153504" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/06/can-you-name-famous-living-chemist-can.html" rel="alternate" type="text/html"/>
    <title>Can you name a famous living Chemist? Can anyone?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
I was re-watching the  Greatest-of-all-time Jeopardy championship and the following happen (I paraphrase)<br/>
<br/>
----------------------<br/>
Alex Trebek: The category is Chemistry and we have a special guest reading the clues.<br/>
<br/>
Darling: I wonder who that will be.<br/>
<br/>
Bill: Hmm. I assume some famous chemist.<br/>
------------------------<br/>
<br/>
So who was it? Bryan Cranston, the actor who PLAYED chemist Walter White on <i>Breaking Bad.</i><br/>
<br/>
Why couldn't they get a famous living chemist to read the clues?<br/>
<br/>
My guess: there are no famous living chemists.<br/>
<br/>
The number of famous living scientists is fairly short and they are often known for things that are not quite their science. Some are famous because the popularize science (deGrasse Tyson, Dawkins) or because of something unusual about their life (Hawkings when he was alive) or for something else entirely that they did (Ted Kaczynski).  Are any famous for the actual work that they do in the science?<br/>
<br/>
Andrew Wiles was famous for a brief time, and even made People Magazine's <i>25 most intriguing people of the year</i> list in the early 1990's (after he solved Fermat's Last Theorem). So he was famous but it was short lived.<br/>
<br/>
Terry Tao was on the Colbert Report (see <a href="http://www.cc.com/video-clips/6wtwlg/the-colbert-report-terence-tao">here</a>) after he won the Fields Medal, the MacAuthor Genius award, and the Breakthrough prize. And even that fame was short lived.<br/>
<br/>
I looked at the web page of Nobel Prize winners, <a href="https://www.nobelprize.org/prizes/lists/all-nobel-prizes">here</a>.<br/>
<br/>
The only Chemistry Nobel's I recognized were Marie Curie,  Irene Joilet-Curie (Marie's Daughter), and Erst Rutherford.<br/>
<br/>
The only Physics Nobel's I recognized were<br/>
<br/>
Richard Feynman,<br/>
<br/>
 Eugene Wigner (for writing about <a href="https://www.dartmouth.edu/~matc/MathDrama/reading/Wigner.html">The unreasonable effectiveness of mathematics in the natural sciences</a>),<br/>
<br/>
Richard Hofstadter (since he was the father of Douglas H and an uncle of Leonard H)<br/>
<br/>
 Andrew Geim (since he won  both an Ig-Noble prize and a Nobel prize, see  <a href="https://blog.computationalcomplexity.org/2010/10/noble-and-ig-noble-prizes.html">here</a>)<br/>
<br/>
Wolfgang Pauli (I've heard the term `Pauli Principle" though I did not know what it was until I looked it up while preparing this blog. I prob still don't really know what it means.)<br/>
<br/>
Enrico Fermi<br/>
<br/>
Erwin Schrodinger<br/>
<br/>
Paul Dirac<br/>
<br/>
Robert Millikan<br/>
<br/>
Albert Einstein<br/>
<br/>
Max Karl Ernest Ludwig Planck (I thought his last name was `Institute')<br/>
<br/>
Johannes Diderik van der Waals<br/>
<br/>
Pierre Curie<br/>
<br/>
Marie Curie<br/>
<br/>
<br/>
So, some questions:<br/>
<br/>
a) Am I wrong? Are there famous living chemists I never heard of? Are there any famous living scientists who are famous for their work in science?<br/>
<br/>
b) If I am right then was there ever a time when there were famous scientists?<br/>
<br/>
c) If there was such a time, what changed?<br/>
<br/>
(I ask all of this non-rhetorically and with no agenda to push.)<br/>
<br/>
<br/>
<br/>
<br/>
<br/></div>
    </content>
    <updated>2020-06-29T20:36:00Z</updated>
    <published>2020-06-29T20:36:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-06-30T08:57:14Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/29/postdocs-phd-students-in-the-theory-of-distributed-parallel-computing-at-aalto-university-apply-by-august-31-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/29/postdocs-phd-students-in-the-theory-of-distributed-parallel-computing-at-aalto-university-apply-by-august-31-2020/" rel="alternate" type="text/html"/>
    <title>Postdocs &amp; PhD students in the theory of distributed &amp; parallel computing at Aalto University (apply by August 31, 2020)</title>
    <summary>The research groups of Jukka Suomela and Jara Uitto at Aalto University (Helsinki, Finland) are looking for several postdoctoral researchers and/or doctoral students to work on the foundations of distributed and parallel computing. Website: https://research.cs.aalto.fi/da/jobs/ Email: jukka.suomela@aalto.fi and jara.uitto@aalto.fi</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The research groups of Jukka Suomela and Jara Uitto at Aalto University (Helsinki, Finland) are looking for several postdoctoral researchers and/or doctoral students to work on the foundations of distributed and parallel computing.</p>
<p>Website: <a href="https://research.cs.aalto.fi/da/jobs/">https://research.cs.aalto.fi/da/jobs/</a><br/>
Email: jukka.suomela@aalto.fi and jara.uitto@aalto.fi</p></div>
    </content>
    <updated>2020-06-29T16:00:22Z</updated>
    <published>2020-06-29T16:00:22Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-30T11:20:55Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://benjamin-recht.github.io/2020/06/29/tour-revisited/</id>
    <link href="http://benjamin-recht.github.io/2020/06/29/tour-revisited/" rel="alternate" type="text/html"/>
    <title>What We've Learned to Control</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I’m giving a keynote address at the <a href="https://www.ifac2020.org/">virtual IFAC congress this July</a>, and I submitted an abstract that forces me to reflect on the current state of research at the intersection of machine learning and control. 2020 is particularly appropriate for reflection: For personal reasons, I’ve been working in this space for about half a decade now and <a href="https://www.argmin.net/2018/06/25/outsider-rl/">wrote a blog series on the topic two years ago</a> and it seemed like ideal timing. For the broader community, 2020 happens to be the year we were promised fleets of self-driving cars. Of course, for a myriad of reasons, we’re nowhere close to achieving this goal. Full self-driving has been a key motivator of work in learning-enabled autonomous systems, and it’s important to note this example as a marker of how difficult problems this space really are.</p>

<p>The research community has come to terms with this difficulty, and has committed itself to address the many pressing challenges. Over the last year I attended several great meetings on this topic, including an <a href="https://ajwagen.github.io/adsi_learning_and_control/">NSF funded workshop at UW</a>, a plenary session at <a href="https://ita.ucsd.edu/ws/">ITA</a>, a workshop on intersections of <a href="https://www.ipam.ucla.edu/programs/workshops/intersections-between-control-learning-and-optimization/?tab=overview">learning, control, and optimization at IPAM</a>, and the <a href="https://sites.google.com/berkeley.edu/l4dc/home">second annual conference on Learning for Dynamics and Control</a>. There is clearly a ton of enthusiasm from researchers in a many different disciplines, and we’re seeing fascinating results mixing techniques from machine learning, computer science, and control. Obviously, I’m going to be leaving out many incredible papers, but, focusing on the theoretical end of the spectrum, perhaps I could highlight <a href="https://arxiv.org/abs/1912.11899">new work on policy optimization</a> that demonstrates how simple optimization techniques can efficiently solve classic, nonconvex control-design problems or <a href="https://arxiv.org/abs/1902.08721">work connecting regret minimization and adaptive control</a> that provides nonasymptotic bounds.</p>

<p>This work has been very useful for establishing language to bridge communication between the diverse research camps interested in the space of learning, dynamics and automation. But, as I’ll discuss shortly, I’d argue that it hasn’t provided many promising approaches to improving large-scale autonomy. That’s ok! These problems are incredibly difficult and aren’t going to be solved by wishing for them to be solved. But I also think it might be worth taking a moment to reflect on which problems we are working on. It’s always a bit too easy for theorists to focus  on improving technical results and lose sight of why someone proved those results in the first place.</p>

<p>As an illustrative example, my research group spent a lot of time studying the <a href="http://www.argmin.net/2018/02/08/lqr/">Linear Quadratic Regulator</a> (LQR). The point of this work was initially to establish baselines: LQR has a closed form solution when the model is known, so we wanted to understand how different algorithms might perform when the underlying model was unknown. It turns out that if you are willing to collect enough data, the best thing you can do for LQR is <a href="https://arxiv.org/abs/1902.07826">estimate the dynamical model, and then exploit this model as if it were true</a>. This so-called “certainty equivalent control” is what practitioners have been doing since the mid-60s to fly satellites and solve other optimal control problems. Proving this result required a bunch of new mathematical insights that established connections between high dimensional statistics and automatic control theory. But it did not bring us closer to solving new challenges in robotics or autonomous systems. Our work here merely showed that what the controls community had been doing for 50 years was already about as well as we could do for this important baseline problem.</p>

<p>So what are the ways forward? Are there things that theory-minded folks can work on short term that might help us understand paths towards improving learning systems in complex feedback loops? Let me suggest a few challenges that I see as both very pressing, but also ones where we might be able to make near-term progress.</p>

<h2 id="machine-learning-is-still-not-reliable-technology">Machine Learning is still not reliable technology</h2>

<p>At the aforementioned <a href="https://www.ipam.ucla.edu/programs/workshops/intersections-between-control-learning-and-optimization/?tab=overview">IPAM meeting</a>, Richard Murray gave a <a href="https://www.youtube.com/watch?v=Wi8Y---ce28">fantastic survey of the sorts of standards of reliability imposed in aerospace engineering</a>. Go watch it! I don’t want to spoil it for you, but his discussion of Ram Air Turbines is gripping. Richard covers what is needed to get to the sorts of reliability we’d like in autonomous systems. Unfortunately, having <a href="https://arxiv.org/abs/2003.08237">88.5% Top-1 accuracy on ImageNet</a>—while a stunning achievement—doesn’t tell us how to get to systems with failure rates on the order of 1 in a billion. As Boeing has tragically shown, cutting corners on autonomous system safety standards has horrible, tragic consequences.</p>

<p>How can we make machine learning more robust? How can we approach the failure rates needed for safe, reliable autonomy? And how can we establish testing protocols to assure we have such low failure rates?</p>

<h2 id="prediction-systems-in-feedback-loops">Prediction systems in feedback loops</h2>

<p>One particular aspect that I think is worth considering is how supervised learning systems can function as “sensors” in feedback loops. Even if you know everything about a dynamical system, when you observe the state via an estimator generated by a learned component, it’s not clear how to best take action on this observation. Most classic control and planning assumes that your errors in state-estimation are Gaussian or nicely uniformly bounded. Of course, the errors from machine learning systems are neither of these (I recommend checking out the <a href="https://youtu.be/A0cb7wZVFf4">crazy videos</a> of the <a href="https://twitter.com/greentheonly/status/1130956365063761920">confusion</a> that comes out of Tesla Autopilot’s vision systems). How to properly characterize the errors of machine learning systems for control applications seems like a useful, understudied problem. Using off-the-shelf machine learing analysis, it’s unavoidable to have to densely sample all of the possible scenarios in advance in order to guarantee the sort of uniform error bounds desired by control algorithms. This isn’t practical, and, indeed, it’s clear that this sort of sensor characterization is not needed to make reasonable demos work. Though it’s a bit mundane, I think a huge contribution lies in understanding how much data we need to quantify the uncertainty in learned perception components. It’s still not clear to me if this is a machine learning question or a closed-loop design question, and I suspect both views of the problem will be needed to make progress.</p>

<h2 id="why-are-we-all-sleeping-on-model-predictive-control">Why are we all sleeping on model predictive control?</h2>

<p>I still remain baffled by how <a href="http://www.argmin.net/2018/05/02/adp/">model predictive control</a> (MPC) is consistently under appreciated. We’ll commonly see the same tasks in the same meeting, one task done on a robot using some sort of deep reinforcement learning and the other done using model predictive control, and the disparity in performance is stark. It’s like the difference between watching an Olympic level sprinter and me jogging in my neighborhood with a set of orthotics.</p>

<p>Here’s an example from the IPAM workshop. Martin Riedmiller presented work at DeepMind to catch a ball in a cup:</p>



<p>This system uses two cameras, has a rather large “cup,” (it’s a wastepaper basket) and yet still takes 3 days to train on the robot. Francesco Borrelli presented a different approach. Using only a single camera and basic, simple Newtonian physics, and MPC they were able to achieve this performance on the standard-sized “ball-in-a-cup” toy:</p>



<p>If you only saw these two videos, I can’t fathom why would you invest all of your assets into deep RL. I understand there are still a lot of diehards out there, and I know this will offend them. But I want to make a constructive point: so many theorists are spending a lot of time studying RL algorithms, but few in the ML community are analyzing MPC and why it’s so successful. We should rebalance our allocation of mental resources!</p>

<p>Now, while the basic idea of MPC is very simple, the theory gets very hairy very quickly. It definitely takes some time and effort to learn about how to prove convergence of MPC protocols. I’d urge the MPC crowd to connect more with the learning theory crowd to see if a common ground can be found to better understand how MPC works and how we might push its performance even farther.</p>

<h2 id="perhaps-we-should-stop-taking-cues-from-alphago">Perhaps we should stop taking cues from AlphaGo?</h2>

<p>One of the grand goals in RL is to use function approximation algorithms to estimate value functions. The conventional wisdom asserts that the world is a giant Markov Decision Process and once you have its value function, you can just greedily maximize it and you’ll win at life. Now, this sort of approach clearly doesn’t work for robots, and I’m perplexed by why people still think it will work at all. Part of the motivation is that this approach was used to solve Go. But at some point I think we all have to come to terms with the fact that games are not the real world.</p>

<p>Now, I’d actually argue that RL <em>does</em> work in the real world, but it’s in systems that most people don’t actively think of as RL systems. Greedy value function estimation and exploitation is <em>literally</em> how all internet revenue is made. Systems simply use past data to estimate value functions and then choose the action that maximizes the value at the next step. Though seldom described as such, these are instances of the “greedy contextual bandit” algorithm, and this algorithm makes tech companies tons of money. But many researchers have also pointed out that this algorithm leads to misinformation, polarization, and radicalization.</p>

<p>Everyone tries to motivate RL by the success of AlphaGo, but they should be using the success of Facebook and Google instead. And if they did this, I think it would be a lot more clear why RL is terrifying and dangerous, and one whose limitations we desperately need to understand so that we can build safer tools.</p>

<h2 id="lessons-from-the-70s-about-optimal-control">Lessons from the 70s about optimal control</h2>

<p>I have one set of ideas along these lines that, while I think is important, I still am having a hard time articulating. Indeed, I might just take a few blog posts to work through my thoughts on this, but let me close this blog with a teaser of discussions to come. As I mentioned above, optimal control was a guiding paradigm for a variety of control applications in the 60s and 70s. During this time, it seemed like there might even be hidden benefits to a full-on optimization paradigm: though you’d optimize a single, simple objective, you would often get additional robustness guarantees for free. However, it turned out that this was very misleading and that <a href="https://ieeexplore.ieee.org/document/1101812">there were no guarantees of robustness even for simple optimal control problems</a>. This shouldn’t be too surprising, as if you devote a lot of resources towards one objective, you are likely neglecting some other objective. But showing how and why these fragilities arise is quite delicate. It’s not always obvious how you <em>should</em> be devoting your resources.</p>

<p>Trying to determine how to allocate engineering resources to balance safety and performance is the heart of “robust control.” One thing I’m fascinated by moving forward is if any of the early developments in robust control might transfer over for a new kind of “robust ML.” Unfortunately for all of us, robust control is a rather encrypted literature. There is a lot of mathematics, but often not clear statements about <em>why</em> we study particular problems or what are the fundamental limits of feedback. While diligent young learning theorists have been scouring classic control theory text books for insights, these books don’t always articulate what we can and cannot do and what are the problems that control theory might help solve. We still have a lot of work to do in communicating what we know and what problems remain challenging. I think it would be useful for control theorists to think of how to best communicate the fundamental concepts of robust control. I hope to take up this challenge in the next few months on this blog.</p>

<p><em>I’d like to thank Sarah Dean, Horia Mania, Nik Matni, and Ludwig Schmidt for their helpful feedback on this post. I’d also like to thank John Doyle for several inspiring conversations about robustness in optimal control and on the encrypted state of the control theory literature.</em></p></div>
    </summary>
    <updated>2020-06-29T00:00:00Z</updated>
    <published>2020-06-29T00:00:00Z</published>
    <source>
      <id>http://benjamin-recht.github.io/</id>
      <author>
        <name>Ben Recht</name>
      </author>
      <link href="http://benjamin-recht.github.io/" rel="alternate" type="text/html"/>
      <link href="http://benjamin-recht.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Musings on systems, information, learning, and optimization.</subtitle>
      <title>arg min blog</title>
      <updated>2020-06-29T23:49:10Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15089</id>
    <link href="http://arxiv.org/abs/2006.15089" rel="alternate" type="text/html"/>
    <title>Cutting Polygons into Small Pieces with Chords: Laser-Based Localization</title>
    <feedworld_mtime>1593388800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arkin:Esther_M=.html">Esther M. Arkin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Das:Rathish.html">Rathish Das</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Jie.html">Jie Gao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goswami:Mayank.html">Mayank Goswami</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitchell:Joseph_S=_B=.html">Joseph S. B. Mitchell</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Polishchuk:Valentin.html">Valentin Polishchuk</a>, Csaba D. Toth <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15089">PDF</a><br/><b>Abstract: </b>Motivated by indoor localization by tripwire lasers, we study the problem of
cutting a polygon into small-size pieces, using the chords of the polygon.
Several versions are considered, depending on the definition of the "size" of a
piece. In particular, we consider the area, the diameter, and the radius of the
largest inscribed circle as a measure of the size of a piece. We also consider
different objectives, either minimizing the maximum size of a piece for a given
number of chords, or minimizing the number of chords that achieve a given size
threshold for the pieces. We give hardness results for polygons with holes and
approximation algorithms for multiple variants of the problem.
</p></div>
    </summary>
    <updated>2020-06-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.15024</id>
    <link href="http://arxiv.org/abs/2006.15024" rel="alternate" type="text/html"/>
    <title>Computing all $s$-$t$ bridges and articulation points simplified</title>
    <feedworld_mtime>1593388800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cairo:Massimo.html">Massimo Cairo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khan:Shahbaz.html">Shahbaz Khan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rizzi:Romeo.html">Romeo Rizzi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Sebastian.html">Sebastian Schmidt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tomescu:Alexandru_I=.html">Alexandru I. Tomescu</a>, Elia Zirondelli <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15024">PDF</a><br/><b>Abstract: </b>Given a directed graph $G$ and a pair of nodes $s$ and $t$, an $s$-$t$ bridge
of $G$ is an edge whose removal breaks all $s$-$t$ paths of $G$. Similarly, an
$s$-$t$ articulation point of $G$ is a node whose removal breaks all $s$-$t$
paths of $G$. Computing the sequence of all $s$-$t$ bridges of $G$ (as well as
the $s$-$t$ articulation points) is a basic graph problem, solvable in linear
time using the classical min-cut algorithm.
</p>
<p>When dealing with cuts of unit size ($s$-$t$ bridges) this algorithm can be
simplified to a single graph traversal from $s$ to $t$ avoiding an arbitrary
$s$-$t$ path, which is interrupted at the $s$-$t$ bridges. Further, the
corresponding proof is also simplified making it independent of the theory of
network flows.
</p></div>
    </summary>
    <updated>2020-06-29T23:29:35Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14972</id>
    <link href="http://arxiv.org/abs/2006.14972" rel="alternate" type="text/html"/>
    <title>On 2-Clubs in Graph-Based Data Clustering: Theory and Algorithm Engineering</title>
    <feedworld_mtime>1593388800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Aleksander Figiel, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Himmel:Anne=Sophie.html">Anne-Sophie Himmel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nichterlein:Andr=eacute=.html">André Nichterlein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Niedermeier:Rolf.html">Rolf Niedermeier</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14972">PDF</a><br/><b>Abstract: </b>Editing a graph into a disjoint union of clusters is a standard optimization
task in graph-based data clustering. Here, complementing classic work where the
clusters shall be cliques, we focus on clusters that shall be 2-clubs, that is,
subgraphs of diameter two. This naturally leads to the two NP-hard problems
2-Club Cluster Editing (the allowed editing operations are edge insertion and
edge deletion) and 2-Club Cluster Vertex Deletion (the allowed editing
operations are vertex deletions). Answering an open question from the
literature, we show that 2-Club Cluster Editing is W[2]-hard with respect to
the number of edge modifications, thus contrasting the fixed-parameter
tractability result for the classic Cluster Editing problem (considering
cliques instead of 2-clubs). Then focusing on 2-Club Cluster Vertex Deletion,
which is easily seen to be fixed-parameter tractable, we show that under
standard complexity-theoretic assumptions it does not have a polynomial-size
problem kernel when parameterized by the number of vertex deletions.
Nevertheless, we develop several effective data reduction and pruning rules,
resulting in a competitive solver, clearly outperforming a standard CPLEX
solver in most instances of an established biological test data set.
</p></div>
    </summary>
    <updated>2020-06-29T23:24:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14870</id>
    <link href="http://arxiv.org/abs/2006.14870" rel="alternate" type="text/html"/>
    <title>Quantum Communication Complexity of Distribution Testing</title>
    <feedworld_mtime>1593388800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Belovs:Aleksandrs.html">Aleksandrs Belovs</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Castellanos:Arturo.html">Arturo Castellanos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gall:Fran=ccedil=ois_Le.html">François Le Gall</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Malod:Guillaume.html">Guillaume Malod</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sherstov:Alexander_A=.html">Alexander A. Sherstov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14870">PDF</a><br/><b>Abstract: </b>The classical communication complexity of testing closeness of discrete
distributions has recently been studied by Andoni, Malkin and Nosatzki
(ICALP'19). In this problem, two players each receive $t$ samples from one
distribution over $[n]$, and the goal is to decide whether their two
distributions are equal, or are $\epsilon$-far apart in the $l_1$-distance. In
the present paper we show that the quantum communication complexity of this
problem is $\tilde{O}(n/(t\epsilon^2))$ qubits when the distributions have low
$l_2$-norm, which gives a quadratic improvement over the classical
communication complexity obtained by Andoni, Malkin and Nosatzki. We also
obtain a matching lower bound by using the pattern matrix method. Let us stress
that the samples received by each of the parties are classical, and it is only
communication between them that is quantum. Our results thus give one setting
where quantum protocols overcome classical protocols for a testing problem with
purely classical samples.
</p></div>
    </summary>
    <updated>2020-06-29T23:21:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-06-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14828</id>
    <link href="http://arxiv.org/abs/2006.14828" rel="alternate" type="text/html"/>
    <title>Lee-Yang zeros and the complexity of the ferromagnetic Ising Model on bounded-degree graphs</title>
    <feedworld_mtime>1593388800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Pjotr Buy, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galanis:Andreas.html">Andreas Galanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patel:Viresh.html">Viresh Patel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Regts:Guus.html">Guus Regts</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14828">PDF</a><br/><b>Abstract: </b>We study the computational complexity of approximating the partition function
of the ferromagnetic Ising model in the Lee-Yang circle of zeros given by
$|\lambda|=1$, where $\lambda$ is the external field of the model.
</p>
<p>Complex-valued parameters for the Ising model are relevant for quantum
circuit computations and phase transitions in statistical physics, but have
also been key in the recent deterministic approximation scheme for all
$|\lambda|\neq 1$ by Liu, Sinclair, and Srivastava. Here, we focus on the
unresolved complexity picture on the unit circle, and on the tantalising
question of what happens in the circular arc around $\lambda=1$, where on one
hand the classical algorithm of Jerrum and Sinclair gives a randomised
approximation scheme on the real axis suggesting tractability, and on the other
hand the presence of Lee-Yang zeros alludes to computational hardness.
</p>
<p>Our main result establishes a sharp computational transition at the point
$\lambda=1$; in fact, our techniques apply more generally to the whole unit
circle $|\lambda|=1$. We show #P-hardness for approximating the partition
function on graphs of maximum degree $\Delta$ when $b$, the edge-interaction
parameter, is in the interval $(0,\frac{\Delta-2}{\Delta}]$ and $\lambda$ is a
non-real on the unit circle. This result contrasts with known approximation
algorithms when $|\lambda|\neq 1$ or $b\in (\frac{\Delta-2}{\Delta},1)$, and
shows that the Lee-Yang circle of zeros is computationally intractable, even on
bounded-degree graphs.
</p></div>
    </summary>
    <updated>2020-06-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14798</id>
    <link href="http://arxiv.org/abs/2006.14798" rel="alternate" type="text/html"/>
    <title>Training Convolutional ReLU Neural Networks in Polynomial Time: Exact Convex Optimization Formulations</title>
    <feedworld_mtime>1593388800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ergen:Tolga.html">Tolga Ergen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pilanci:Mert.html">Mert Pilanci</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14798">PDF</a><br/><b>Abstract: </b>We study training of Convolutional Neural Networks (CNNs) with ReLU
activations and introduce exact convex optimization formulations with a
polynomial complexity with respect to the number of data samples, the number of
neurons and data dimension. Particularly, we develop a convex analytic
framework utilizing semi-infinite duality to obtain equivalent convex
optimization problems for several CNN architectures. We first prove that
two-layer CNNs can be globally optimized via an $\ell_2$ norm regularized
convex program. We then show that certain three-layer CNN training problems are
equivalent to an $\ell_1$ regularized convex program. We also extend these
results to multi-layer CNN architectures. Furthermore, we present extensions of
our approach to different pooling methods.
</p></div>
    </summary>
    <updated>2020-06-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-06-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14733</id>
    <link href="http://arxiv.org/abs/2006.14733" rel="alternate" type="text/html"/>
    <title>APX-Hardness and Approximation for the k-Burning Number Problem</title>
    <feedworld_mtime>1593388800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mondal:Debajyoti.html">Debajyoti Mondal</a>, N. Parthiabn, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kavitha:V=.html">V. Kavitha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rajasingh:Indra.html">Indra Rajasingh</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14733">PDF</a><br/><b>Abstract: </b>Consider an information diffusion process on a graph $G$ that starts with
$k&gt;0$ burnt vertices, and at each subsequent step, burns the neighbors of the
currently burnt vertices, as well as $k$ other unburnt vertices. The
\emph{$k$-burning number} of $G$ is the minimum number of steps $b_k(G)$ such
that all the vertices can be burned within $b_k(G)$ steps. Note that the last
step may have smaller than $k$ unburnt vertices available, where all of them
are burned. The $1$-burning number coincides with the well-known burning number
problem, which was proposed to model the spread of social contagion. The
generalization to $k$-burning number allows us to examine different worst-case
contagion scenarios by varying the spread factor $k$.
</p>
<p>In this paper we prove that computing $k$-burning number is APX-hard, for any
fixed constant $k$. We then give an $O((n+m)\log n)$-time 3-approximation
algorithm for computing $k$-burning number, for any $k\ge 1$, where $n$ and $m$
are the number of vertices and edges, respectively. Finally, we show that even
if the burning sources are given as an input, computing a burning sequence
itself is an NP-hard problem.
</p></div>
    </summary>
    <updated>2020-06-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14677</id>
    <link href="http://arxiv.org/abs/2006.14677" rel="alternate" type="text/html"/>
    <title>Average-case Complexity of Teaching Convex Polytopes via Halfspace Queries</title>
    <feedworld_mtime>1593388800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Akash.html">Akash Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singla:Adish.html">Adish Singla</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yue:Yisong.html">Yisong Yue</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Yuxin.html">Yuxin Chen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14677">PDF</a><br/><b>Abstract: </b>We examine the task of locating a target region among those induced by
intersections of $n$ halfspaces in $\mathbb{R}^d$. This generic task connects
to fundamental machine learning problems, such as training a perceptron and
learning a $\phi$-separable dichotomy. We investigate the average teaching
complexity of the task, i.e., the minimal number of samples (halfspace queries)
required by a teacher to help a version-space learner in locating a randomly
selected target. As our main result, we show that the average-case teaching
complexity is $\Theta(d)$, which is in sharp contrast to the worst-case
teaching complexity of $\Theta(n)$. If instead, we consider the average-case
learning complexity, the bounds have a dependency on $n$ as $\Theta(n)$ for
i.i.d. queries and $\Theta(d \log(n))$ for actively chosen queries by the
learner. Our proof techniques are based on novel insights from computational
geometry, which allow us to count the number of convex polytopes and faces in a
Euclidean space depending on the arrangement of halfspaces. Our insights allow
us to establish a tight bound on the average-case complexity for
$\phi$-separable dichotomies, which generalizes the known $\mathcal{O}(d)$
bound on the average number of "extreme patterns" in the classical
computational geometry literature (Cover, 1965).
</p></div>
    </summary>
    <updated>2020-06-29T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-06-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2006.14652</id>
    <link href="http://arxiv.org/abs/2006.14652" rel="alternate" type="text/html"/>
    <title>Constant-Depth and Subcubic-Size Threshold Circuits for Matrix Multiplication</title>
    <feedworld_mtime>1593388800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parekh:Ojas.html">Ojas Parekh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Phillips:Cynthia_A=.html">Cynthia A. Phillips</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/James:Conrad_D=.html">Conrad D. James</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aimone:James_B=.html">James B. Aimone</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14652">PDF</a><br/><b>Abstract: </b>Boolean circuits of McCulloch-Pitts threshold gates are a classic model of
neural computation studied heavily in the late 20th century as a model of
general computation. Recent advances in large-scale neural computing hardware
has made their practical implementation a near-term possibility. We describe a
theoretical approach for multiplying two $N$ by $N$ matrices that integrates
threshold gate logic with conventional fast matrix multiplication algorithms,
that perform $O(N^\omega)$ arithmetic operations for a positive constant
$\omega &lt; 3$. Our approach converts such a fast matrix multiplication algorithm
into a constant-depth threshold circuit with approximately $O(N^\omega)$ gates.
Prior to our work, it was not known whether the $\Theta(N^3)$-gate barrier for
matrix multiplication was surmountable by constant-depth threshold circuits.
</p>
<p>Dense matrix multiplication is a core operation in convolutional neural
network training. Performing this work on a neural architecture instead of
off-loading it to a GPU may be an appealing option.
</p></div>
    </summary>
    <updated>2020-06-29T23:32:12Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-06-29T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/06/28/sorting-integer-offsets</id>
    <link href="https://11011110.github.io/blog/2020/06/28/sorting-integer-offsets.html" rel="alternate" type="text/html"/>
    <title>Sorting with integer offsets</title>
    <summary>Here’s a cute exercise for the next time you’re teaching radix sorting in an algorithms class:</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Here’s a cute exercise for the next time you’re teaching radix sorting in an algorithms class:</p>

<p>Suppose you’re given as input a set of real numbers , and an integer parameter . Describe an algorithm for sorting the  numbers  in time . You can assume that standard arithmetic operations on real numbers (including comparisons and rounding down to an integer) take constant time per operation.</p>

<p>Models of computation that mix constant-time real arithmetic and rounding operations can be problematic, as by building up and then rounding numbers with unlimited precision you can access a level of computational power beyond what actual computers can do, but I don’t think that’s a concern here. If someone wants to use bit-packing tricks to implement a crazy but fast sorting algorithm in this model, they’re beyond the level of this exercise.</p>

<p>The same method (which I’m not going to describe, to preserve its value as an exercise) more generally allows you to take as input pairs  and sort the numbers  in time  where . But it relies heavily on the fact that you’re adding integers to the ’s. For a problem that can’t be handled in this way, consider instead sorting the numbers  where we multiply instead of adding. Or, if you prefer to view this as a type of <a href="https://en.wikipedia.org/wiki/X_%2B_Y_sorting"> sorting</a> problem, take logs in your favorite base and sort the numbers . It’s not at all obvious to me whether this can be done in the same  time bound.</p>

<p>The motivation for looking at all this is <a href="https://cstheory.stackexchange.com/q/47120/95">a question about how to implement the greedy set cover quickly</a>. You can find the unweighted <a href="https://en.wikipedia.org/wiki/Set_cover_problem#Greedy_algorithm">greedy set cover</a> in linear time (linear in the sum of the sizes of the input sets; this is an exercise in CLRS), and you can approximate the weighted greedy set cover very accurately in linear time using similar ideas. If you could sort  quickly you could use the sorted order to compute the weighted greedy set cover exactly in the same time as the sorting algorithm. Which is totally useless because the greedy cover is already an approximation, so a fast and accurate approximation to the greedy cover is good enough. But I think the question of sorting  is interesting despite its uselessness in this application.</p></div>
    </content>
    <updated>2020-06-28T17:54:00Z</updated>
    <published>2020-06-28T17:54:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-06-29T01:17:19Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-2151790274753933095</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/2151790274753933095/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=2151790274753933095" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/2151790274753933095" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/2151790274753933095" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2020/06/stoc-workshop-on-algorithms-with.html" rel="alternate" type="text/html"/>
    <title>STOC Workshop on "Algorithms with Predictions"</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The STOC workshop on Algorithms with Predictions was on Friday, and I thought it went really well!  I can't speak for my talk, but the other 3 talks (Tim Roughgarden, Edith Cohen, Ravi Kumar) were fantastic and inspiring, and I really recommend them for anyone with an interest in "Beyond Worst-Case Analysis".   <br/><br/>The talks are <a href="https://www.youtube.com/watch?v=byKYJwN6XKw&amp;feature=youtu.be">all on Youtube</a>.  And the <a href="https://www.mit.edu/~vakilian/stoc-workshop.html">workshop page</a> is full of useful links and information. </div>
    </content>
    <updated>2020-06-27T18:06:00Z</updated>
    <published>2020-06-27T18:06:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2020-06-27T18:06:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7756</id>
    <link href="https://windowsontheory.org/2020/06/26/stoc-2020-slack-channel-open-from-madhur-tulsiani/" rel="alternate" type="text/html"/>
    <title>STOC 2020 slack channel open (from Madhur Tulsiani)</title>
    <summary>Madhur writes: Thanks to all who participated in STOC 2020! Since the discussions on some of the topics from the business meeting, on SafeToC, and  on the papers/workshops are still ongoing, we will keep the Slack workspace open till July 31st (instead of just one week after the conference, as announced earlier). Also, if any […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Madhur writes:</p>



<p>Thanks to all who participated in STOC 2020! Since the discussions on some of the topics from the business meeting, on SafeToC, and  on the papers/workshops are still ongoing, we will keep the Slack workspace open till <strong>July 31st</strong> (instead of just one week after the conference, as announced earlier). Also, if any members of the community are interested in joining the discussions, they are welcome to email us (<a>stoc2020@ttic.edu</a>) and we can send them an invitation to join the workspace.</p>



<p>Of course the organizers may not always be able to quickly respond to help messages during the next month. However, all members are welcome to participate in discussions, create new topics or channels as needed, and use the workspace as they prefer.</p>



<p>TheoryFest organization team (<a href="mailto:stoc2020@ttic.edu" rel="noreferrer noopener" target="_blank">stoc2020@ttic.edu</a>)</p></div>
    </content>
    <updated>2020-06-27T01:37:25Z</updated>
    <published>2020-06-27T01:37:25Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-06-30T11:21:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19925</id>
    <link href="https://gilkalai.wordpress.com/2020/06/26/to-cheer-you-up-in-difficult-times-6-play-rani-sharims-two-player-games-of-life-read-maya-bar-hillel-presentation-on-catching-lies-with-statistics-and-more/" rel="alternate" type="text/html"/>
    <title>To cheer you up in difficult times 6:  Play Rani Sharim’s two-player games of life,  read Maya Bar-Hillel presentation on catching lies with statistics, and more.</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Sorry for the long blog silence. In this post I wish to give a few links each of which probably deserves a full post. I will start with Rani Sharim’s two-player variants of John Conway’s game-of-life Here is a web-page … <a href="https://gilkalai.wordpress.com/2020/06/26/to-cheer-you-up-in-difficult-times-6-play-rani-sharims-two-player-games-of-life-read-maya-bar-hillel-presentation-on-catching-lies-with-statistics-and-more/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Sorry for the long blog silence. In this post I wish to give a few links each of which probably deserves a full post. I will start with</p>
<h2>Rani Sharim’s two-player variants of John Conway’s game-of-life</h2>
<p><a href="https://ranisharim.github.io/game_of_life_2_players/">Here is a web-page</a> by a student in my “Game Theory” course where you can play several two-players variants of John Conway’s game-of-life.  (A couple of variants were considered before. See, e.g. <a href="https://arxiv.org/abs/cond-mat/0207679">this  paper</a>.)</p>
<p>I really enjoyed playing Rani’s games and it can certainly cheer you up in difficult times. Questions about the game, remarks, and suggestions for improvements and for new features, are most welcome.</p>
<h2>How to catch lies with statistics, a 2006  presentation by Maya Bar-Hillel</h2>
<p><a href="https://gilkalai.files.wordpress.com/2020/06/mayesther.png"><img alt="" class="alignnone size-full wp-image-19929" src="https://gilkalai.files.wordpress.com/2020/06/mayesther.png?w=640"/></a></p>
<p>Maya Bar-Hillel (left) and Ester Samuel-Cahn</p>
<p>Here is an interesting 2006 <a href="https://gilkalai.files.wordpress.com/2020/06/ester.ppt">power point presentation entitled <strong><em>How to detect lies with statistics</em></strong> by Maya Bar-Hillel.</a>  This was a talk given by Maya at the <a href="http://www.esterconference.huji.ac.il/">conference</a> honoring Prof. Ester Samuel- Cahn , Jerusalem, December 18-20, 2006, and it described a planned research project of Maya Bar-Hillel with Yossi Rinott, David Budescu and myself. At the end we did not pursue it, mainly because each of us was involved in various other projects (but also because we were skeptical about some aspects of it.)  Ester Samuel-Cahn (1933-2015) was a famous Israeli statistician. (Here is a <a href="http://www.sci-princess.info/archives/291">post by Yosi Levy in Hebrew</a> about the conference and about Ester.)</p>
<p>The lecture starts with “Last year, <em>Statistical Science</em> celebrated 50 years for `How to Lie with Statistics’ the book [by Durell Huff] whose title inspired this talk.”</p>
<p>And here are a few other quotes from Maya’s presentation</p>
<p>“We are not sure a general toolkit for detecting lies with statistics can be developed. Perhaps that explains why none yet exists.  We have shown just a collection of anecdotes. But they can be classified and categorized. Some do seem generalizeable, at least to some extent.”</p>
<p>and the conclusion</p>
<blockquote><p>A famous quip by Fred Mosteller: “It is easy to lie with statistics, but easier to lie without them.”</p>
<p>Likewise, we should say:  “It is possible to detect (some) lies with statistics, but easier to detect them with other means”.</p></blockquote>
<h2>New bounds for Ryser’s conjecture and related problems</h2>
<p>Peter Keevash, Alexey Pokrovskiy, Benny Sudakov, and Liana Yepremyan’s paper  <a href="https://arxiv.org/abs/2005.00526">New bounds for Ryser’s conjecture and related problems,</a> describes remarkable progress very old questions regarding transversals in Latin square.</p>
<h2>Topological Tverberg news</h2>
<p>I came across a very interesting paper <a href="https://arxiv.org/abs/2005.05251">The topological Tverberg problem beyond <span class="search-hit mathjax">prime</span> powers</a> by Florian Frick and Pablo Soberón with new bounds and a new method for topological Tverberg theorem in the non prime-power case.</p>
<h2>Jeager’s conjecture refuted</h2>
<p>A year ago I came across <a href="https://www.facebook.com/photo.php?fbid=2114324995342352&amp;set=a.507523926022475&amp;type=3&amp;theater">this cool facebook post</a> by Rupei Xu</p>
<blockquote><p>OMG! Just learned that Jaeger’s conjecture is false for every t&gt;=3. An interesting consequence of it is that a specific version of Goddyn’s conjecture on thin spanning trees is false, which shows some negative evidence that the thin spanning tree approaches may fail to lead to a constant factor approximation algorithm for ATSP!</p></blockquote>
<h2>A cool rainbow post <a href="http://matroidunion.org/?p=2541">Short rainbow cycles in graphs and matroids</a> by Tony Huynh</h2>
<h2>More on the game of life</h2>
<p>Let me mention two problems I posted 6-7 years ago about Conway’s game of life. <a class="question-hyperlink" href="https://mathoverflow.net/questions/132402/conways-game-of-life-for-random-initial-position">Conway’s game of life for random initial position</a> and <a class="question-hyperlink" href="https://cstheory.stackexchange.com/questions/17914/does-a-noisy-version-of-conways-game-of-life-support-universal-computation">Does a noisy version of Conway’s game of life support universal computation?</a></p>
<div class="left-sidebar js-pinned-left-sidebar ps-relative" id="left-sidebar">
<div class="left-sidebar--sticky-container js-sticky-leftnav"/>
</div>
<p> </p>
<p> </p></div>
    </content>
    <updated>2020-06-25T21:21:45Z</updated>
    <published>2020-06-25T21:21:45Z</published>
    <category term="Combinatorics"/>
    <category term="Games"/>
    <category term="Rationality"/>
    <category term="Maya Bar Hillel"/>
    <category term="Rani Sharim"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-06-30T11:20:46Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-8890204.post-5732832478359389342</id>
    <link href="http://mybiasedcoin.blogspot.com/feeds/5732832478359389342/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=5732832478359389342" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/5732832478359389342" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/8890204/posts/default/5732832478359389342" rel="self" type="application/atom+xml"/>
    <link href="http://mybiasedcoin.blogspot.com/2020/06/writing-code-for-paper-note-to-students.html" rel="alternate" type="text/html"/>
    <title>Writing Code for a Paper :  A Note to Students</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">This post both relates to some of the stuff I'll be presenting at Friday's STOC workshop on Algorithms with Predictions, but is also for future students in my classes, who sometimes wonder why I have them write code on theory material.  (Somehow this might be a theme for a lecture in my grad class next semester, so maybe these are a first attempt at notes for the lecture.  Comments  and  suggestions welcome.)<br/><br/>Some of the work I'm doing is looking at how queueing systems perform with various sorts of predictions on the times the jobs take.  This particular work I'm doing on my own.  (While most of my research has been and is with collaborators, and it's one of the things I enjoy about computer science -- we're a very collaborative field!, which seems to surprise many people -- I still sometimes like to do research projects on my own.  I've looked at queueing systems since my PhD thesis, and it's a bit outside the research interest of most of my collaborator pool, and it's "fun" sometimes to do my own thing.  The reason why "fun" is in quotes is described below.)  <br/><br/>Often in my work in queueing I'm looking at mean-field limits (meant to model infinite systems of queues, which provides a good approximation for large finite systems under reasonable assumptions), where I can derive families of differential equations describing the system behavior.  I can also simulate the large finite system directly, and make sure the results match.  I generally do this for all of these types of papers.<br/><br/>Now the numbers I get from simulating the system directly and from simulating the differential equations should match (say within 1% or so).  If they don't, something is wrong.  In an effort to avoid wrongness, I won't consider the paper ready for outside consumption until I get a match.  Unfortunately, there are three ways things can go wrong.<br/><br/>1.  My simulation code for the queueing system might have bugs.<br/>2.  My code to evaluate the differential equations might have bugs.<br/>3.  My equations themselves might have bugs.<br/><br/>And I find there are two main categories of bugs.  Sometimes the bugs are simple/standard coding mistakes -- I'm off by 1 on an index, or I cut and paste and forget to change an i++ to a j++ in one my double loops, or I type x instead of a y.  Usually it's pretty easy to find these things, although I've had times where a hidden typo took hours to find.  But sometimes the bug is a thinking mistake -- I've forgotten a subcase and so my equations aren't complete (and so my code evaluating the equations won't give the right answer), or I've not handled a subcase correctly in my simulation.  That type usually takes longer. <br/><br/>Usually, the first time through, most all of these types of bugs happen -- my math is off, I've typed some stuff wrong, it can all happen.  And then, like coders everywhere, I go through and fix it.  And it's painful.  Sometimes everything goes right, a quick check or two and everything works.  For more complicated stuff, it's more time figuring out what went wrong than setting up the code to begin with.  And being the personality type to not let things sit, that can mean late nights figuring out what went wrong.<br/><br/>For my talk this week, there was one last problem I wanted to include, which meant finally taking the model and writing the equations and code.  I didn't even need it for the talk, but it's also the last bit before I put a paper draft on arxiv, so taking advantage of a deadline, I figured now was the time.  Which means the last 2 days, I've spent many hours (and a late night) trying to remove the disagreements.<br/><br/>On the plus side, when everything finally works, it's a wonderful feeling.  And it always makes me feel better when I have worked to verify my math this way;  this time, what kept me up well past midnight and took several hours to track down was actually a boundary case I had left out of the equations.  (I had looked at the equations over and over again without noticing I had left out the subcase;  I had to step through numbers from the differential equations one time step at a time to track down what was missing, and then the numbers told me what I had done wrong.)<br/><br/>On the down side, it's work, and debugging is never particularly fun.<br/><br/>For students out there, maybe I'm just explaining that I understand the pain that I am putting you through.  You may wonder why I have you do simulations that take a few hours if you do them well, but days if you don't think through the best approach.  But using programming and theory together can be powerful;  it's helped me countless times in my research.<br/><br/>(Related: on theory and experiments that <a href="https://cacm.acm.org/magazines/2015/9/191184-theory-without-experiments/fulltext">I've written on before</a>, along with <a href="https://cacm.acm.org/magazines/2015/9/191183-experiments-as-research-validation/fulltext">a viewpoint by Jeffrey Ullman</a>.)<br/><br/><br/></div>
    </content>
    <updated>2020-06-25T17:35:00Z</updated>
    <published>2020-06-25T17:35:00Z</published>
    <author>
      <name>Michael Mitzenmacher</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/02161161032642563814</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-8890204</id>
      <category term="conferences"/>
      <category term="research"/>
      <category term="society"/>
      <category term="algorithms"/>
      <category term="administration"/>
      <category term="teaching"/>
      <category term="Harvard"/>
      <category term="papers"/>
      <category term="graduate students"/>
      <category term="funding"/>
      <category term="talks"/>
      <category term="blogs"/>
      <category term="codes"/>
      <category term="jobs"/>
      <category term="reviews"/>
      <category term="personal"/>
      <category term="travel"/>
      <category term="undergraduate students"/>
      <category term="books"/>
      <category term="open problems"/>
      <category term="PCs"/>
      <category term="consulting"/>
      <category term="randomness"/>
      <category term="CCC"/>
      <category term="blog book project"/>
      <category term="research labs"/>
      <category term="ISIT"/>
      <category term="tenure"/>
      <category term="comments"/>
      <category term="recommendations"/>
      <category term="outreach"/>
      <category term="students"/>
      <author>
        <name>Michael Mitzenmacher</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06738274256402616703</uri>
      </author>
      <link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/>
      <link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div>
      </subtitle>
      <title>My Biased Coin</title>
      <updated>2020-06-27T18:06:03Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://emanueleviola.wordpress.com/?p=775</id>
    <link href="https://emanueleviola.wordpress.com/2020/06/25/we-dont-need-no-education/" rel="alternate" type="text/html"/>
    <title>We don’t need no education</title>
    <summary>Around us, educational systems whose primary emphasis is on social rather than intellectual skills are simply disintegrating. Unequipped for content delivery, teachers spray parents with a mixture of links and credentials whose collection is a complete waste of everybody’s time. Suggestion: What about assigning homework and let teachers provide feedback? To all the school-age kids […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Around us, educational systems whose primary emphasis is on social rather than intellectual skills are simply disintegrating.  Unequipped for content delivery, teachers spray parents with a mixture of links and credentials whose collection is a complete waste of everybody’s time.  Suggestion: What about assigning <em>homework </em>and let teachers provide <em>feedback</em>?</p>



<p>To all the school-age kids stuck at home doing some fun coding, <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwio8MDa4JvqAhWfVhUIHSAIABgQyCkwAHoECBUQBw&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYR5ApYxkU-U&amp;usg=AOvVaw0s6Ai-o5-CNtyqFC7uHT_4">this immortal song is for you</a>.</p></div>
    </content>
    <updated>2020-06-25T10:29:13Z</updated>
    <published>2020-06-25T10:29:13Z</published>
    <category term="Uncategorized"/>
    <category term="Utopia"/>
    <author>
      <name>Manu</name>
    </author>
    <source>
      <id>https://emanueleviola.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://emanueleviola.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://emanueleviola.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://emanueleviola.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://emanueleviola.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>by Manu</subtitle>
      <title>Thoughts</title>
      <updated>2020-06-30T11:21:15Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/25/postdoc-in-experimental-algorithms-at-national-university-of-singapore-apply-by-august-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/25/postdoc-in-experimental-algorithms-at-national-university-of-singapore-apply-by-august-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc in Experimental Algorithms at National University of Singapore (apply by August 15, 2020)</title>
    <summary>A one-year postdoc position (with a possibility of extension for another year) in experimental (/practical) algorithms is available at NUS. The position will be jointly hosted by Diptarka Chakraborty and Kuldeep S. Meel. Applications are invited from candidates who have solid background in algorithm design/formal methods, mathematics. A prior experience in programming would be a […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A one-year postdoc position (with a possibility of extension for another year) in experimental (/practical) algorithms is available at NUS. The position will be jointly hosted by Diptarka Chakraborty and Kuldeep S. Meel. Applications are invited from candidates who have solid background in algorithm design/formal methods, mathematics. A prior experience in programming would be a plus.</p>
<p>Website: <a href="https://sites.google.com/view/diptarka/postdoc-advertisement">https://sites.google.com/view/diptarka/postdoc-advertisement</a><br/>
Email: diptarka@comp.nus.edu.sg</p></div>
    </content>
    <updated>2020-06-25T06:10:01Z</updated>
    <published>2020-06-25T06:10:01Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-30T11:20:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020-2/</id>
    <link href="https://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020-2/" rel="alternate" type="text/html"/>
    <title>Postdoc in TCS at National University of Singapore (apply by August 15, 2020)</title>
    <summary>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics. Website: https://sites.google.com/view/diptarka/postdoc-advertisement Email: diptarka@comp.nus.edu.sg</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics.</p>
<p>Website: <a href="https://sites.google.com/view/diptarka/postdoc-advertisement">https://sites.google.com/view/diptarka/postdoc-advertisement</a><br/>
Email: diptarka@comp.nus.edu.sg</p></div>
    </content>
    <updated>2020-06-25T06:05:34Z</updated>
    <published>2020-06-25T06:05:34Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-30T11:20:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020/</id>
    <link href="https://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020/" rel="alternate" type="text/html"/>
    <title>Postdoc in TCS at National University of Singapore (apply by August 15, 2020)</title>
    <summary>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics. Website: https://sites.google.com/view/diptarka/postdoc-advertisement Email: diptarka@comp.nus.edu.sg</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics.</p>
<p>Website: <a href="https://sites.google.com/view/diptarka/postdoc-advertisement">https://sites.google.com/view/diptarka/postdoc-advertisement</a><br/>
Email: diptarka@comp.nus.edu.sg</p></div>
    </content>
    <updated>2020-06-25T06:05:03Z</updated>
    <published>2020-06-25T06:05:03Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-06-30T11:20:55Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/</id>
    <link href="https://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/" rel="alternate" type="text/html"/>
    <title>IDEAL Workshop on Computational vs Statistical Tradeoffs in Network Inference</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">June 29, 2020 Virtual https://www.ideal.northwestern.edu/events/workshop-computational-vs-statistical-tradeoffs-in-network-inference/ Network models have been used as a tool to understand the role of interconnections between entities in multiple research areas like sociology, biology, meteorology, economics, and computer science. Moreover emerging technological developments allow collecting data on increasingly larger networks. This leads to both computational and statistical challenges when inferring or … <a class="more-link" href="https://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/">Continue reading <span class="screen-reader-text">IDEAL Workshop on Computational vs Statistical Tradeoffs in Network Inference</span></a></div>
    </summary>
    <updated>2020-06-24T23:53:00Z</updated>
    <published>2020-06-24T23:53:00Z</published>
    <category term="workshop"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-events.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-events.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-events.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-events.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-events.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Aggregator for CS theory workshops, schools, and so on</subtitle>
      <title>CS Theory Events</title>
      <updated>2020-06-30T11:21:29Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/096</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/096" rel="alternate" type="text/html"/>
    <title>TR20-096 |  On the asymptotic complexity of sorting | 

	Igor Sergeev</title>
    <summary>We investigate the number of pairwise comparisons sufficient to sort $n$ elements chosen from a linearly ordered set. This number is shown to be $\log_2(n!) + o(n)$ thus improving over the previously known upper bounds of the form $\log_2(n!) + \Theta(n)$. The new bound is achieved by the proposed group insertion sorting algorithm.</summary>
    <updated>2020-06-24T17:41:11Z</updated>
    <published>2020-06-24T17:41:11Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-06-30T11:20:42Z</updated>
    </source>
  </entry>
</feed>
