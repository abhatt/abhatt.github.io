<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-08-04T01:55:18Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.00601</id>
    <link href="http://arxiv.org/abs/2008.00601" rel="alternate" type="text/html"/>
    <title>The Amazing Power of Randomness: NP=RP</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Farag=oacute=:Andr=aacute=s.html">András Faragó</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.00601">PDF</a><br/><b>Abstract: </b>We (claim to) prove the extremely surprising fact that NP=RP. It is achieved
by creating a Fully Polynomial-Time Randomized Approximation Scheme (FPRAS) for
approximately counting the number of independent sets in bounded degree graphs,
with any fixed degree bound, which is known to imply NP=RP. While our method is
rooted in the well known Markov Chain Monte Carlo (MCMC) approach, we overcome
the notorious problem of slow mixing by a new idea for generating a random
sample from among the independent sets. A key tool that enables the result is a
solution to a novel sampling task that we call Subset Sampling. In its basic
form, a stationary sample is given from the (exponentially large) state space
of a Markov chain, as input, and we want to transform it into another
stationary sample that is conditioned on falling into a given subset, which is
still exponentially large. In general, Subset Sampling can be both harder and
easier than stationary sampling from a Markov chain. It can be harder, due to
the conditioning on a subset, which may have more complex structure than the
original state space. But it may also be easier, since a stationary sample is
already given, which, in a sense, already encompasses "most of the hardness" of
such sampling tasks, being already in the stationary distribution, which is
hard to reach in a slowly mixing chain. We show that it is possible to
efficiently balance the two sides: we can capitalize on already having a
stationary sample from the original space, so that the complexity of confining
it to a subset is mitigated. We prove that an efficient approximation is
possible for the considered sampling task, and then it is applied recursively
to create the FPRAS.
</p></div>
    </summary>
    <updated>2020-08-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-08-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.00589</id>
    <link href="http://arxiv.org/abs/2008.00589" rel="alternate" type="text/html"/>
    <title>Finding Closed Quasigeodesics on Convex Polyhedra</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Erik_D=.html">Erik D. Demaine</a>, Adam C. Hesterberg, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Ku:Jason_S=.html">Jason S. Ku</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.00589">PDF</a><br/><b>Abstract: </b>A closed quasigeodesic is a closed loop on the surface of a polyhedron with
at most $180^\circ$ of surface on both sides at all points; such loops can be
locally unfolded straight. In 1949, Pogorelov proved that every convex
polyhedron has at least three (non-self-intersecting) closed quasigeodesics,
but the proof relies on a nonconstructive topological argument. We present the
first finite algorithm to find a closed quasigeodesic on a given convex
polyhedron, which is the first positive progress on a 1990 open problem by
O'Rourke and Wyman. The algorithm's running time is pseudopolynomial, namely
$O\left({n^2 \over \varepsilon^2} {L \over \ell} b\right)$ time, where
$\varepsilon$ is the minimum curvature of a vertex, $L$ is the length of the
longest edge, $\ell$ is the smallest distance within a face between a vertex
and a nonincident edge (minimum feature size of any face), and $b$ is the
maximum number of bits of an integer in a constant-size radical expression of a
real number representing the polyhedron. We take special care with the model of
computation, introducing the $O(1)$-expression RAM and showing that it can be
implemented in the standard word RAM.
</p></div>
    </summary>
    <updated>2020-08-04T01:39:25Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.00581</id>
    <link href="http://arxiv.org/abs/2008.00581" rel="alternate" type="text/html"/>
    <title>A Combinatorial Design for Cascaded Coded Distributed Computing on General Networks</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woolsey:Nicholas.html">Nicholas Woolsey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Rong=Rong.html">Rong-Rong Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Ji:Mingyue.html">Mingyue Ji</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.00581">PDF</a><br/><b>Abstract: </b>Coding theoretic approached have been developed to significantly reduce the
communication load in modern distributed computing system. In particular, coded
distributed computing (CDC) introduced by Li et al. can efficiently trade
computation resources to reduce the communication load in MapReduce like
computing systems. For the more general cascaded CDC, Map computations are
repeated at r nodes to significantly reduce the communication load among nodes
tasked with computing Q Reduce functions s times. In this paper, we propose a
novel low-complexity combinatorial design for cascaded CDC which 1) determines
both input file and output function assignments, 2) requires significantly less
number of input files and output functions, and 3) operates on heterogeneous
networks where nodes have varying storage and computing capabilities. We
provide an analytical characterization of the computation-communication
tradeoff, from which we show the proposed scheme can outperform the
state-of-the-art scheme proposed by Li et al. for the homogeneous networks.
Further, when the network is heterogeneous, we show that the performance of the
proposed scheme can be better than its homogeneous counterpart. In addition,
the proposed scheme is optimal within a constant factor of the information
theoretic converse bound while fixing the input file and the output function
assignments.
</p></div>
    </summary>
    <updated>2020-08-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-08-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.00496</id>
    <link href="http://arxiv.org/abs/2008.00496" rel="alternate" type="text/html"/>
    <title>Minimum $2$-vertex strongly biconnected spanning directed subgraph problem</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaberi:Raed.html">Raed Jaberi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.00496">PDF</a><br/><b>Abstract: </b>A directed graph $G=(V,E)$ is strongly biconnected if $G$ is strongly
connected and its underlying graph is biconnected. A strongly biconnected
directed graph $G=(V,E)$ is called $2$-vertex-strongly biconnected if $|V|\geq
3$ and the induced subgraph on $V\setminus\left\lbrace w\right\rbrace $ is
strongly biconnected for every vertex $w\in V$. In this paper we study the
following problem.
</p>
<p>Given a $2$-vertex-strongly biconnected directed graph $G=(V,E)$, compute an
edge subset $E^{2sb} \subseteq E$ of minimum size such that the subgraph
$(V,E^{2sb})$ is $2$-vertex-strongly biconnected.
</p></div>
    </summary>
    <updated>2020-08-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.00492</id>
    <link href="http://arxiv.org/abs/2008.00492" rel="alternate" type="text/html"/>
    <title>Extendability of simplicial maps is undecidable</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>A. Skopenkov <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.00492">PDF</a><br/><b>Abstract: </b>We present a short proof of the
\v{C}adek-Kr\v{c}\'al-Matou\v{s}ek-Vok\v{r}\'inek-Wagner result from the title
(in the following form due to Filakovsk\'y-Wagner-Zhechev).
</p>
<p>For any fixed integer $l&gt;1$ there is no algorithm recognizing the
extendability of the identity map of $S^l\vee S^l$ to a PL map $X\to S^l\vee
S^l$ of given $2l$-dimensional simplicial complex $X$ containing a subdivision
of $S^l\vee S^l$ as a given subcomplex.
</p>
<p>We also exhibit a gap in the Filakovsk\'y-Wagner-Zhechev proof that
embeddability of complexes is undecidable in codimension $&gt;1$.
</p></div>
    </summary>
    <updated>2020-08-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.00466</id>
    <link href="http://arxiv.org/abs/2008.00466" rel="alternate" type="text/html"/>
    <title>Complexity continuum within Ising formulation of NP problems</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kalinin:Kirill_P=.html">Kirill P. Kalinin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berloff:Natalia_G=.html">Natalia G. Berloff</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.00466">PDF</a><br/><b>Abstract: </b>A promising approach to achieve computational supremacy over the classical
von Neumann architecture explores classical and quantum hardware as Ising
machines. The minimisation of the Ising Hamiltonian is known to be NP-hard
problem for certain interaction matrix classes, yet not all problem instances
are equivalently hard to optimise. We propose to identify computationally
simple instances with an `optimisation simplicity criterion'. Such optimisation
simplicity can be found for a wide range of models from spin glasses to
k-regular maximum cut problems. Many optical, photonic, and electronic systems
are neuromorphic architectures that can naturally operate to optimise problems
satisfying this criterion and, therefore, such problems are often chosen to
illustrate the computational advantages of new Ising machines. We further probe
an intermediate complexity for sparse and dense models by analysing circulant
coupling matrices, that can be `rewired' to introduce greater complexity. A
compelling approach for distinguishing easy and hard instances within the same
NP-hard class of problems can be a starting point in developing a standardised
procedure for the performance evaluation of emerging physical simulators and
physics-inspired algorithms.
</p></div>
    </summary>
    <updated>2020-08-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-08-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.00425</id>
    <link href="http://arxiv.org/abs/2008.00425" rel="alternate" type="text/html"/>
    <title>Concentration-Bound Analysis for Probabilistic Programs and Probabilistic Recurrence Relations</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Jingyi.html">Jingyi Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Yican.html">Yican Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fu:Hongfei.html">Hongfei Fu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goharshady:Amir_Kafshdar.html">Amir Kafshdar Goharshady</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chatterjee:Krishnendu.html">Krishnendu Chatterjee</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.00425">PDF</a><br/><b>Abstract: </b>Analyzing probabilistic programs and randomized algorithms are classical
problems in computer science.The first basic problem in the analysis of
stochastic processes is to consider the expectation or mean, and another basic
problem is to consider concentration bounds, i.e. showing that large deviations
from the mean have small probability. Similarly, in the context of
probabilistic programs and randomized algorithms, the analysis of expected
termination time/running time and their concentration bounds are fundamental
problems. In this work, we focus on concentration bounds for probabilistic
programs and probabilistic recurrences of randomized algorithms. For
probabilistic programs, the basic technique to achieve concentration bounds is
to consider martingales and apply the classical Azuma's inequality. For
probabilistic recurrences of randomized algorithms, Karp's classical "cookbook"
method, which is similar to the master theorem for recurrences, is the standard
approach to obtain concentration bounds. In this work, we propose a novel
approach for deriving concentration bounds for probabilistic programs and
probabilistic recurrence relations through the synthesis of exponential
supermartingales. For probabilistic programs, we present algorithms for
synthesis of such supermartingales in several cases. We also show that our
approach can derive better concentration bounds than simply applying the
classical Azuma's inequality over various probabilistic programs considered in
the literature. For probabilistic recurrences, our approach can derive tighter
bounds than the well-established methods of and for classical algorithms such
as quick sort, quick select, and randomized diameter computation. We also
present a prototype implementation that can automatically infer these bounds.
</p></div>
    </summary>
    <updated>2020-08-04T01:31:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.00358</id>
    <link href="http://arxiv.org/abs/2008.00358" rel="alternate" type="text/html"/>
    <title>Relational Algorithms for k-means Clustering</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moseley:Benjamin.html">Benjamin Moseley</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pruhs:Kirk.html">Kirk Pruhs</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Samadian:Alireza.html">Alireza Samadian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yuyan.html">Yuyan Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.00358">PDF</a><br/><b>Abstract: </b>The majority of learning tasks faced by data scientists involve relational
data, yet most standard algorithms for standard learning problems are not
designed to accept relational data as input. The standard practice to address
this issue is to join the relational data to create the type of geometric input
that standard learning algorithms expect. Unfortunately, this standard practice
has exponential worst-case time and space complexity. This leads us to consider
what we call the Relational Learning Question: ``Which standard learning
algorithms can be efficiently implemented on relational data, and for those
that can not, is there an alternative algorithm that can be efficiently
implemented on relational data and that has similar performance guarantees to
the standard algorithm?'' In this paper, we address the relational learning
question for two well-known algorithms for the standard $k$-means clustering
problem. We first show that the $k$-means++ algorithm can be efficiently
implemented on relational data. In contrast, we show that the adaptive
$k$-means algorithm likely can not be efficiently implemented on relational
data, as this would imply $P = \#P$. However, we show that a slight variation
of this adaptive $k$-means algorithm can be efficiently implemented on
relational data, and that this alternative algorithm has the same performance
guarantee as the original algorithm, that is that it outputs an
$O(1)$-approximate sketch.
</p></div>
    </summary>
    <updated>2020-08-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.00332</id>
    <link href="http://arxiv.org/abs/2008.00332" rel="alternate" type="text/html"/>
    <title>Data Oblivious Algorithms for Multicores</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramachandran:Vijaya.html">Vijaya Ramachandran</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shi:Elaine.html">Elaine Shi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.00332">PDF</a><br/><b>Abstract: </b>As secure processors such as Intel SGX (with hyperthreading) become widely
adopted, there is a growing appetite for private analytics on big data. Most
prior works on data-oblivious algorithms adopt the classical PRAM model to
capture parallelism. However, it is widely understood that PRAM does not best
capture realistic multicore processors, nor does it reflect parallel
programming models adopted in practice.
</p>
<p>In this paper, we initiate the study of parallel data oblivious algorithms on
realistic multicores, best captured by the binary fork-join model of
computation. We first show that data-oblivious sorting can be accomplished by a
binary fork-join algorithm with optimal total work and optimal
(cache-oblivious) cache complexity, and in O(log n log log n) span (i.e.,
parallel time) that matches the best-known insecure algorithm. Using our
sorting algorithm as a core primitive, we show how to data-obliviously simulate
general PRAM algorithms in the binary fork-join model with non-trivial
efficiency. We also present results for several applications including list
ranking, Euler tour, tree contraction, connected components, and minimum
spanning forest. For a subset of these applications, our data-oblivious
algorithms asymptotically outperform the best known insecure algorithms. For
other applications, we show data oblivious algorithms whose performance bounds
match the best known insecure algorithms.
</p>
<p>Complementing these asymptotically efficient results, we present a practical
variant of our sorting algorithm that is self-contained and potentially
implementable. It has optimal caching cost, and it is only a log log n factor
off from optimal work and about a log n factor off in terms of span; moreover,
it achieves small constant factors in its bounds.
</p></div>
    </summary>
    <updated>2020-08-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.00325</id>
    <link href="http://arxiv.org/abs/2008.00325" rel="alternate" type="text/html"/>
    <title>Bringing UMAP Closer to the Speed of Light with GPU Acceleration</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Corey J. Nolet, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lafargue:Victor.html">Victor Lafargue</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raff:Edward.html">Edward Raff</a>, Thejaswi Nanditale, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Oates:Tim.html">Tim Oates</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zedlewski:John.html">John Zedlewski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patterson:Joshua.html">Joshua Patterson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.00325">PDF</a><br/><b>Abstract: </b>The Uniform Manifold Approximation and Projection (UMAP) algorithm has become
widely popular for its ease of use, quality of results, and support for
exploratory, unsupervised, supervised, and semi-supervised learning. While many
algorithms can be ported to a GPU in a simple and direct fashion, such efforts
have resulted in inefficent and inaccurate versions of UMAP. We show a number
of techniques that can be used to make a faster and more faithful GPU version
of UMAP, and obtain speedups of up to 100x in practice. Many of these design
choices/lessons are general purpose and may inform the conversion of other
graph and manifold learning algorithms to use GPUs. Our implementation has been
made publicly available as part of the open source RAPIDS cuML
library(https://github.com/rapidsai/cuml).
</p></div>
    </summary>
    <updated>2020-08-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.00297</id>
    <link href="http://arxiv.org/abs/2008.00297" rel="alternate" type="text/html"/>
    <title>The Price of Tailoring the Index to Your Data: Poisoning Attacks on Learned Index Structures</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kornaropoulos:Evgenios_M=.html">Evgenios M. Kornaropoulos</a>, Silei Ren, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tamassia:Roberto.html">Roberto Tamassia</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.00297">PDF</a><br/><b>Abstract: </b>The concept of learned index structures relies on the idea that the
input-output functionality of a database index can be viewed as a prediction
task and, thus, be implemented using a machine learning model instead of
traditional algorithmic techniques. This novel angle for a decades-old problem
has inspired numerous exciting results in the intersection of machine learning
and data structures. However, the main advantage of learned index structures,
i.e., the ability to adjust to the data at hand via the underlying ML-model,
can become a disadvantage from a security perspective as it could be exploited.
</p>
<p>In this work, we present the first study of poisoning attacks on learned
index structures. The required poisoning approach is different from all
previous works since the model under attack is trained on a cumulative
distribution function (CDF) and, thus, every injection on the training set has
a cascading impact on multiple data values. We formulate the first poisoning
attacks on linear regression models trained on the CDF, which is a basic
building block of the proposed learned index structures. We generalize our
poisoning techniques to attack a more advanced two-stage design of learned
index structures called recursive model index (RMI), which has been shown to
outperform traditional B-Trees. We evaluate our attacks on real-world and
synthetic datasets under a wide variety of parameterizations of the model and
show that the error of the RMI increases up to $300\times$ and the error of its
second-stage models increases up to $3000\times$.
</p></div>
    </summary>
    <updated>2020-08-04T01:22:14Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.00270</id>
    <link href="http://arxiv.org/abs/2008.00270" rel="alternate" type="text/html"/>
    <title>Fast Classical and Quantum Algorithms for Online $k$-server Problem on Trees</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kapralov:Ruslan.html">Ruslan Kapralov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khadiev:Kamil.html">Kamil Khadiev</a>, Joshua Mokut, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shen:Yixin.html">Yixin Shen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yagafarov:Maxim.html">Maxim Yagafarov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.00270">PDF</a><br/><b>Abstract: </b>We consider online algorithms for the $k$-server problem on trees. Chrobak
and Larmore proposed a $k$-competitive algorithm for this problem that has the
optimal competitive ratio. However, a naive implementation of their algorithm
has $O(n)$ time complexity for processing each query, where $n$ is the number
of nodes in the tree. We propose a new time-efficient implementation of this
algorithm that has $O(n\log n)$ time complexity for preprocessing and
$O\left(k^2 + k\cdot \log n\right)$ time for processing a query. We also
propose a quantum algorithm for the case where the nodes of the tree are
presented using string paths. In this case, no preprocessing is needed, and the
time complexity for each query is $O(k^2\sqrt{n}\log n)$. When the number of
queries is $o\left(\frac{\sqrt{n}}{k^2\log n}\right)$, we obtain a quantum
speed-up on the total runtime compared to our classical algorithm.
</p>
<p>Our algorithm builds on a result of independent interest: we give a quantum
algorithm to find the first marked element in a collection of $m$ objects, that
works even in the presence of two-sided bounded errors on the input oracle. It
has worst-case complexity $O(\sqrt{m})$. In the particular case of one-sided
errors on the input, it has expected time complexity $O(\sqrt{x})$ where $x$ is
the position of the first marked element.
</p></div>
    </summary>
    <updated>2020-08-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.00266</id>
    <link href="http://arxiv.org/abs/2008.00266" rel="alternate" type="text/html"/>
    <title>On parity decision trees for Fourier-sparse Boolean functions</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mande:Nikhil_S=.html">Nikhil S. Mande</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sanyal:Swagato.html">Swagato Sanyal</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.00266">PDF</a><br/><b>Abstract: </b>We study parity decision trees for Boolean functions. The motivation of our
study is the log-rank conjecture for XOR functions and its connection to
Fourier analysis and parity decision tree complexity. Let f be a Boolean
function with Fourier support S and Fourier sparsity k.
</p>
<p>1) We prove via the probabilistic method that there exists a parity decision
tree of depth O(sqrt k) that computes f. This matches the best known upper
bound on the parity decision tree complexity of Boolean functions (Tsang, Wong,
Xie, and Zhang, FOCS 2013). Moreover, while previous constructions (Tsang et
al., FOCS 2013, Shpilka, Tal, and Volk, Comput. Complex. 2017) build the trees
by carefully choosing the parities to be queried in each step, our proof shows
that a naive sampling of the parities suffices.
</p>
<p>2) We generalize the above result by showing that if the Fourier spectra of
Boolean functions satisfy a natural "folding property", then the above proof
can be adapted to establish existence of a tree of complexity polynomially
smaller than O(sqrt k). We make a conjecture in this regard which, if true,
implies that the communication complexity of an XOR function is bounded above
by the fourth root of the rank of its communication matrix, improving upon the
previously known upper bound of square root of rank (Tsang et al., FOCS 2013,
Lovett, J. ACM. 2016).
</p>
<p>3) It can be shown by elementary techniques that for any Boolean function f
and all pairs (alpha, beta) of parities in S, there exists another pair (gamma,
delta) of parities in S such that alpha + beta = gamma + delta. We show, among
other results, that there must exist several gamma in F_2^n such that there are
at least three pairs (alpha_1, alpha_2) of parities in S with alpha_1 + alpha_2
= gamma.
</p></div>
    </summary>
    <updated>2020-08-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-08-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2008.00044</id>
    <link href="http://arxiv.org/abs/2008.00044" rel="alternate" type="text/html"/>
    <title>On the Computational Complexity of Linear Discrepancy</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Lily.html">Lily Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nikolov:Aleksandar.html">Aleksandar Nikolov</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2008.00044">PDF</a><br/><b>Abstract: </b>Many problems in computer science and applied mathematics require rounding a
vector $\mathbf{w}$ of fractional values lying in the interval $[0,1]$ to a
binary vector $\mathbf{x}$ so that, for a given matrix $\mathbf{A}$,
$\mathbf{A}\mathbf{x}$ is as close to $\mathbf{A}\mathbf{w}$ as possible. For
example, this problem arises in LP rounding algorithms used to approximate
$\mathsf{NP}$-hard optimization problems and in the design of uniformly
distributed point sets for numerical integration. For a given matrix
$\mathbf{A}$, the worst-case error over all choices of $\mathbf{w}$ incurred by
the best possible rounding is measured by the linear discrepancy of
$\mathbf{A}$, a quantity studied in discrepancy theory, and introduced by
Lovasz, Spencer, and Vesztergombi (EJC, 1986).
</p>
<p>We initiate the study of the computational complexity of linear discrepancy.
Our investigation proceeds in two directions: (1) proving hardness results and
(2) finding both exact and approximate algorithms to evaluate the linear
discrepancy of certain matrices. For (1), we show that linear discrepancy is
$\mathsf{NP}$-hard. Thus we do not expect to find an efficient exact algorithm
for the general case. Restricting our attention to matrices with a constant
number of rows, we present a poly-time exact algorithm for matrices consisting
of a single row and matrices with a constant number of rows and entries of
bounded magnitude. We also present an exponential-time approximation algorithm
for general matrices, and an algorithm that approximates linear discrepancy to
within an exponential factor.
</p></div>
    </summary>
    <updated>2020-08-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-04T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.16135</id>
    <link href="http://arxiv.org/abs/2007.16135" rel="alternate" type="text/html"/>
    <title>Improved Time Warp Edit Distance -- A Parallel Dynamic Program in Linear Memory</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wright:Garrett.html">Garrett Wright</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.16135">PDF</a><br/><b>Abstract: </b>Edit Distance is a classic family of dynamic programming problems, among
which Time Warp Edit Distance refines the problem with the notion of a metric
and temporal elasticity. A novel Improved Time Warp Edit Distance algorithm
that is both massively parallelizable and requiring only linear storage is
presented. This method uses the procession of a three diagonal band to cover
the original dynamic program space. Every element of the diagonal update can be
computed in parallel. The core method is a feature of the TWED Longest Common
Subsequence data dependence and is applicable to dynamic programs that share
similar band subproblem structure. The algorithm has been implemented as a CUDA
C library with Python bindings. Speedups for challenging problems are
phenomenal.
</p></div>
    </summary>
    <updated>2020-08-04T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15821</id>
    <link href="http://arxiv.org/abs/2007.15821" rel="alternate" type="text/html"/>
    <title>Geometric All-Way Boolean Tensor Decomposition</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wan:Changlin.html">Changlin Wan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chang:Wennan.html">Wennan Chang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhao:Tong.html">Tong Zhao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cao:Sha.html">Sha Cao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Chi.html">Chi Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15821">PDF</a><br/><b>Abstract: </b>Boolean tensor has been broadly utilized in representing high dimensional
logical data collected on spatial, temporal and/or other relational domains.
Boolean Tensor Decomposition (BTD) factorizes a binary tensor into the Boolean
sum of multiple rank-1 tensors, which is an NP-hard problem. Existing BTD
methods have been limited by their high computational cost, in applications to
large scale or higher order tensors. In this work, we presented a
computationally efficient BTD algorithm, namely \textit{Geometric Expansion for
all-order Tensor Factorization} (GETF), that sequentially identifies the rank-1
basis components for a tensor from a geometric perspective. We conducted
rigorous theoretical analysis on the validity as well as algorithemic
efficiency of GETF in decomposing all-order tensor. Experiments on both
synthetic and real-world data demonstrated that GETF has significantly improved
performance in reconstruction accuracy, extraction of latent structures and it
is an order of magnitude faster than other state-of-the-art methods.
</p></div>
    </summary>
    <updated>2020-08-04T00:02:31Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15720</id>
    <link href="http://arxiv.org/abs/2007.15720" rel="alternate" type="text/html"/>
    <title>Algebraic 3D Graphic Statics: reciprocal constructions</title>
    <feedworld_mtime>1596499200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hablicsek:M=aacute=rton.html">Márton Hablicsek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akbarzadeh:Masoud.html">Masoud Akbarzadeh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Yi.html">Yi Guo</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15720">PDF</a><br/><b>Abstract: </b>The recently developed 3D graphic statics (3DGS) lacks a rigorous
mathematical definition relating the geometrical and topological properties of
the reciprocal polyhedral diagrams as well as a precise method for the
geometric construction of these diagrams. This paper provides a fundamental
algebraic formulation for 3DGS by developing equilibrium equations around the
edges of the primal diagram and satisfying the equations by the closeness of
the polygons constructed by the edges of the corresponding faces in the
dual/reciprocal diagram. The research provides multiple numerical methods for
solving the equilibrium equations and explains the advantage of using each
technique. The approach of this paper can be used for compression-and-tension
combined form-finding and analysis as it allows constructing both the form and
force diagram based on the interpretation of the input diagram. Besides, the
paper expands on the geometric/static degrees of (in)determinacies of the
diagrams using the algebraic formulation and shows how these properties can be
used for the constrained manipulation of the polyhedrons in an interactive
environment without breaking the reciprocity between the two.
</p></div>
    </summary>
    <updated>2020-08-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17379</id>
    <link href="https://rjlipton.wordpress.com/2020/08/03/cleverer-automata-exist/" rel="alternate" type="text/html"/>
    <title>Cleverer Automata Exist</title>
    <summary>A breakthrough on the separating words problem Zachary Chase is a graduate student of Ben Green at Oxford. Chase has already solved a number of interesting problems–check his site for more details. His advisor is famous for his brilliant work—especially in additive combinatorics. One example is his joint work with Terence Tao proving this amazing […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>A breakthrough on the separating words problem</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/?attachment_id=17371" rel="attachment wp-att-17371"><img alt="" class="alignright wp-image-17371" src="https://rjlipton.files.wordpress.com/2020/08/chase.png?w=125" width="125"/></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p/><p>
Zachary Chase is a graduate student of Ben Green at Oxford. Chase has already solved a number of interesting problems–check his <a href="http://people.maths.ox.ac.uk/~chase/">site</a> for more details. His advisor is famous for his brilliant work—especially in additive combinatorics. One example is his joint work with Terence Tao <a href="https://en.wikipedia.org/wiki/Green-Tao_theorem">proving</a> this amazing statement:</p>
<blockquote><p><b>Theorem 1</b> <em> The prime numbers contain arbitrarily long arithmetic progressions. </em>
</p></blockquote>
<p>
</p><p>
Today we wish to report Chase’s new <a href="https://arxiv.org/pdf/2007.12097.pdf">paper</a> on a problem we have twice discussed before. </p>
<p>
But first Ken wants to say something about Oxford where he got his degree long before Green arrived. </p>
<p>
</p><p/><h2> Oxford Making Waves </h2><p/>
<p/><p>
Green moved to Oxford in 2013. He holds a professorship associated to Magdalen College. I (Ken) did not know him when I started at Oxford in 1981. It would have been hard, as Green was only 4 years old at the time. But I did know the preteen Ruth Lawrence when she started there and even once played a departmental croquet match including her in which Bryan Birch made some epic long shots. Lawrence had <a href="https://en.wikipedia.org/wiki/Ruth_Lawrence">joined</a> St. Hugh’s College in 1983 at the age of twelve.</p>
<p>
Oxford has been Dick’s and my mind more in the past six years than before. Both of us were guests of Joël Ouaknine in 2012–2015 when he was there. Oxford has developed a front-line group in quantum computation, which fits as David Deutsch’s role as an originator began from there—note my story in the middle of this recent <a href="https://rjlipton.wordpress.com/2020/01/15/halting-is-poly-time-quantum-provable/">post</a>.</p>
<p>
Recently Oxford has been in the <a href="https://www.statnews.com/2020/07/20/study-provides-first-glimpse-of-efficacy-of-oxford-astrazeneca-covid-19-vaccine/">news</a> for developing a promising Covid-19 vaccine. <a href="https://www.precisionvaccinations.com/vaccines/chadox1-mers-coronavirus-vaccine">ChAdOx1</a> heads Wikipedia’s <a href="https://en.wikipedia.org/wiki/COVID-19_vaccine#Vaccine_candidates">list</a> of candidate vaccines and has gone to final <a href="https://www.nationalgeographic.com/science/2020/07/oxford-vaccine-enters-final-phase-of-covid-19-trials-in-brazil-cvd/">trials</a>, though there is still a long evaluation process before approval for general use.</p>
<p>
Before that, a modeling <a href="https://nymag.com/intelligencer/2020/03/oxford-study-coronavirus-may-have-infected-half-of-u-k.html">study</a> from Oxford in March raised the question of whether many more people have had Covid-19 without symptoms or any knowledge. This kind of possibility has since been <a href="https://marginalrevolution.com/marginalrevolution/2020/06/karl-friston-on-immunological-dark-matter.html">likened</a> to a “dark matter” hypothesis, not just now regarding Covid-19 but a decade <a href="https://pubmed.ncbi.nlm.nih.gov/21839767/">ago</a> and before. </p>
<p>
A main <a href="https://theconversation.com/coronavirus-techniques-from-physics-promise-better-covid-19-models-can-they-deliver-139925">supporting</a> <a href="https://www.brunel.ac.uk/news-and-events/news/articles/Coronavirus-techniques-from-physics-promise-better-COVID-19-models-can-they-deliver">argument</a> is that a wide class of mathematical models can be fitted with higher relative likelihood if the hypothesis is true. I have wanted to take time to evaluate this argument amid the wider backdrop of <a href="https://rjlipton.wordpress.com/2018/05/19/lost-in-complexity/">controversy</a> over inference methods in physics, but online chess with unfortunately ramped-up frequency of cheating has filled up all disposable time and more.</p>
<p>
</p><p/><h2> The Problem </h2><p/>
<p/><p>
Back to Chase’s new results on the following problem: </p>
<blockquote><p><b> </b> <em> Given two distinct binary strings of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/> there is always a finite state deterministic automaton (FSA) that accepts one and rejects the other. <i>How few states can such a machine have?</i> </em>
</p></blockquote>
<p/><p>
This is called the <em>separating words problem</em> (SWP). Here we consider it for binary strings only.</p>
<p>
John Robson proved <img alt="{O(n^{2/5})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%7B2%2F5%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(n^{2/5})}"/> states are enough—we suppress any log factors. Some like to write this as <img alt="{\tilde{O}(n^{2/5})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BO%7D%28n%5E%7B2%2F5%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde{O}(n^{2/5})}"/>. Chase <a href="https://arxiv.org/pdf/2007.12097.pdf">improves</a> this to <img alt="{\tilde{O}(n^{1/3})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BO%7D%28n%5E%7B1%2F3%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde{O}(n^{1/3})}"/>:</p>
<blockquote><p><b>Theorem 2</b> <em><a name="Chasethm"/> For any distinct <img alt="{x,y \in \{0,1\}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x,y \in \{0,1\}^{n}}"/>, there is a finite state deterministic automaton with <img alt="{O(n^{1/3} \log^{7} n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%7B1%2F3%7D+%5Clog%5E%7B7%7D+n%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{O(n^{1/3} \log^{7} n)}"/> states that accepts <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x}"/> but not <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{y}"/>. </em>
</p></blockquote>
<p/><p>
We previously discussed this twice at GLL. We discussed the background and early results <a href="https://rjlipton.wordpress.com/2019/09/08/separating-words-by-automata/">here</a>. The original problem is due to Pavel Goralcik and Vaclav Koubek. They proved an upper bound that was <img alt="{o(n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bo%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{o(n)}"/>. Then we went over Robson’s bound <a href="https://rjlipton.wordpress.com/2019/09/16/separating-words-decoding-a-paper/">here</a>. The best upper bound was Robson’s result until Chase came along.</p>
<p>
</p><p/><h2> The Approach </h2><p/>
<p/><p>
All the approaches to SWP seem to have a common thread. They find some family of “hash” functions <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H}"/> so that:</p>
<ol>
<li>
Any <img alt="{h}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h}"/> in <img alt="{H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{H}"/> can be computed by a FSA with few states. <p/>
</li><li>
For any <img alt="{x \neq y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cneq+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x \neq y}"/> binary strings of length <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>, there is an <img alt="{h \in H}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh+%5Cin+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h \in H}"/> so that <img alt="{h(x) \neq h(y)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29+%5Cneq+h%28y%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{h(x) \neq h(y)}"/>.
</li></ol>
<p>
The challenge is to find clever families that can do do both. Be easy to compute and also be able to tell strings apart. Actually this is only a coarse outline—Chase’s situation is a bit more complicated. </p>
<p>
</p><p/><h2> The Proof </h2><p/>
<p/><p>
We have taken the statement of Theorem <a href="https://rjlipton.wordpress.com/feed/#Chasethm">2</a> verbatim from the paper. It has a common pecadillo of beginning a sentence for a specific <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> but writing <img alt="{O(\cdots n \cdots)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Ccdots+n+%5Ccdots%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\cdots n \cdots)}"/> later. However, this is how we think intuitively: in terms of how the pieces of the formula behave. Chase declares right away his intent to ignore the power of <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/>. How he gets the power <img alt="{1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/3}"/> of <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is the real point. We can convey the intuition in brief.</p>
<p>
A length-<img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> binary string can be identified with its set <img alt="{A \subseteq [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA+%5Csubseteq+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A \subseteq [n]}"/> of positions where the string has a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. Chase begins by showing how a power of <img alt="{1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/2}"/> on <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> is obtainable by considering sets of the form </p>
<p align="center"><img alt="\displaystyle  A_{i,p} = \{j : j \in A \wedge j \equiv i \pmod{p}\}, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A_%7Bi%2Cp%7D+%3D+%5C%7Bj+%3A+j+%5Cin+A+%5Cwedge+j+%5Cequiv+i+%5Cpmod%7Bp%7D%5C%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  A_{i,p} = \{j : j \in A \wedge j \equiv i \pmod{p}\}, "/></p>
<p>where <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> is prime and <img alt="{i &lt; p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%3C+p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i &lt; p}"/>. Suppose we know a bound <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> such that for all distinct <img alt="{A,B \subseteq n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB+%5Csubseteq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B \subseteq n}"/> (that is, all distinct binary strings of legnth <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/>) there is a prime <img alt="{p &lt; k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3C+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p &lt; k}"/> and <img alt="{i &lt; p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%3C+p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i &lt; p}"/> such that </p>
<p align="center"><img alt="\displaystyle  |A_{i,p}| \neq |B_{i,p}|. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7CA_%7Bi%2Cp%7D%7C+%5Cneq+%7CB_%7Bi%2Cp%7D%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |A_{i,p}| \neq |B_{i,p}|. "/></p>
<p>Then by the Chinese Remainder Theorem, there is a prime <img alt="{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q}"/> of magnitude about <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/> such that </p>
<p align="center"><img alt="\displaystyle  |A_{i,p}| \not\equiv |B_{i,p}| \pmod{q}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7CA_%7Bi%2Cp%7D%7C+%5Cnot%5Cequiv+%7CB_%7Bi%2Cp%7D%7C+%5Cpmod%7Bq%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  |A_{i,p}| \not\equiv |B_{i,p}| \pmod{q}. "/></p>
<p>Now we can make a finite automaton <img alt="{M_{A,B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM_%7BA%2CB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M_{A,B}}"/> with states <img alt="{(j,\ell)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28j%2C%5Cell%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(j,\ell)}"/> that always increments <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> modulo <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> and increments <img alt="{\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell}"/> modulo <img alt="{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q}"/> each time it reads a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/> when <img alt="{j \equiv i \pmod{p}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj+%5Cequiv+i+%5Cpmod%7Bp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j \equiv i \pmod{p}}"/>. Then <img alt="{M_{A,B}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BM_%7BA%2CB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{M_{A,B}}"/> has order-of <img alt="{pq \approx k\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bpq+%5Capprox+k%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{pq \approx k\log n}"/> states. The finisher is that <img alt="{k = \tilde{O}(n^{1/2})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+%5Ctilde%7BO%7D%28n%5E%7B1%2F2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k = \tilde{O}(n^{1/2})}"/> suffices. Again we ignore the pecadillo but we add some redundant words to the statement in the paper between dashes:</p>
<blockquote><p><b>Lemma 3</b> <em> For any distinct <img alt="{A,B \subseteq [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB+%5Csubseteq+%5Bn%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A,B \subseteq [n]}"/>—of size at most <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{n}"/>—there is a prime <img alt="{p = \tilde{O}(n^{1/2})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+%5Ctilde%7BO%7D%28n%5E%7B1%2F2%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{p = \tilde{O}(n^{1/2})}"/> such that for some <img alt="{i \in [p]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%5Cin+%5Bp%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{i \in [p]}"/>, <img alt="{|A_{i,p}| \neq |B_{i,p}|.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CA_%7Bi%2Cp%7D%7C+%5Cneq+%7CB_%7Bi%2Cp%7D%7C.%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{|A_{i,p}| \neq |B_{i,p}|.}"/> </em>
</p></blockquote>
<p/><p>
The power <img alt="{1/2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/2}"/> is of course weaker than Robson’s <img alt="{2/5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%2F5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2/5}"/>, but this statement conceals two “<a href="https://rjlipton.wordpress.com/2011/08/05/give-me-a-lever/">levers</a>” that enable leap-frogging <img alt="{2/5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%2F5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2/5}"/> to get <img alt="{1/3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1/3}"/>. The first is that we don’t have to limit attention to sets <img alt="{A,B}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A,B}"/> that come from places where the corresponding strings <img alt="{x,y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x,y}"/> have a <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>. Consider any string <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> and take <img alt="{A_w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_w%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_w}"/> to be the set of index positions <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/> in which <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> has the substring <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> beginning at place <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/>. Define <img alt="{B_w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BB_w%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{B_w}"/> likewise for <img alt="{y}" class="latex" src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{y}"/>. Then we can try to prove results of the following form given <img alt="{m &lt; n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3C+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m &lt; n}"/>:</p>
<blockquote><p><b>Proposition 4</b> <em> For all distinct <img alt="{x,y \in \{0,1\}^n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy+%5Cin+%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{x,y \in \{0,1\}^n}"/> there is <img alt="{w \in \{0,1\}^m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw+%5Cin+%5C%7B0%2C1%5C%7D%5Em%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{w \in \{0,1\}^m}"/> such that <img alt="{A_w \neq B_w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_w+%5Cneq+B_w%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A_w \neq B_w}"/> and </em></p><em>
<p align="center"><img alt="\displaystyle  |A_w|,|B_w| = O(\frac{n}{m}). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7CA_w%7C%2C%7CB_w%7C+%3D+O%28%5Cfrac%7Bn%7D%7Bm%7D%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  |A_w|,|B_w| = O(\frac{n}{m}). "/></p>
</em><p><em/>
</p></blockquote>
<p/><p>
A finite automaton using this extension needs <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> states to store <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> in its finite control. The second lever is to try to prove results of this form, where now the words “of size at most <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/>” are not redundant:</p>
<blockquote><p><b>Lemma 5 (?)</b> <em><a name="conjlemma"/> For any distinct <img alt="{A,B \subseteq [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA%2CB+%5Csubseteq+%5Bn%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{A,B \subseteq [n]}"/> of size at most <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{N}"/> there is a prime <img alt="{p = \tilde{O}(N^{1/2})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+%5Ctilde%7BO%7D%28N%5E%7B1%2F2%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{p = \tilde{O}(N^{1/2})}"/> such that for some <img alt="{i \in [p]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi+%5Cin+%5Bp%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{i \in [p]}"/>, <img alt="{|A_{i,p}| \neq |B_{i,p}|.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%7CA_%7Bi%2Cp%7D%7C+%5Cneq+%7CB_%7Bi%2Cp%7D%7C.%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{|A_{i,p}| \neq |B_{i,p}|.}"/>  </em>
</p></blockquote>
<p/><p>
Now we need to balance the levers using the proposition and the lemma together.  Since <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> will add order-<img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> states to the automaton, we balance it against <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> from the previous argument.  So take <img alt="{m = n^{1/3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+n%5E%7B1%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m = n^{1/3}}"/>. Then <img alt="{N = \frac{n}{m} \approx n^{2/3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN+%3D+%5Cfrac%7Bn%7D%7Bm%7D+%5Capprox+n%5E%7B2%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N = \frac{n}{m} \approx n^{2/3}}"/>. Lemma <a href="https://rjlipton.wordpress.com/feed/#conjlemma">5</a> then gives the bound </p>
<p align="center"><img alt="\displaystyle  k = \tilde{O}(N^{1/2}) = \tilde{O}(n^{1/3}) " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++k+%3D+%5Ctilde%7BO%7D%28N%5E%7B1%2F2%7D%29+%3D+%5Ctilde%7BO%7D%28n%5E%7B1%2F3%7D%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  k = \tilde{O}(N^{1/2}) = \tilde{O}(n^{1/3}) "/></p>
<p>on the magnitude of the needed primes <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/>. This yields the <img alt="{\tilde{O}(n^{1/3})}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BO%7D%28n%5E%7B1%2F3%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\tilde{O}(n^{1/3})}"/> breakthrough on SWP.</p>
<p/><p>
Here a famous New Yorker <a href="https://www.allposters.com/-sp/Oh-if-only-it-were-so-simple-New-Yorker-Cartoon-Posters_i9168200_.htm?UPI=PGQEG50&amp;PODConfigID=8419447&amp;sOrigID=169338">cartoon</a> with the caption “If only it were so simple” comes to mind.  But there is a catch. Chase is not quite able to prove lemma <a href="https://rjlipton.wordpress.com/feed/#conjlemma">5</a>. However, the <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> lever comes with extra flexibility that enables finding <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> that make <img alt="{A_w \neq B_w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BA_w+%5Cneq+B_w%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{A_w \neq B_w}"/> and also give those sets an extra regularity property <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>. Using <img alt="{X}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{X}"/>, he is able to show the existence of good hash functions of a certain type. The modified lemma is enough to prove his new bound.  The proof still uses intricate analysis including integrals.</p>
<p>
This is classic high-power mathematics. When some idea is blocked, try to weaken the requirements. Sometimes it is possible to still proceed. It is a lesson that we sometimes forget, but a valuable one nevertheless.</p>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
We like the SWP and think Chase’s contribution is impressive. Note that it adds a third element <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> to <img alt="{p}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{p}"/> and <img alt="{q}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{q}"/> in the automaton.  Can the argument be pushed further by finding more levers to add more elements?  Is Lemma 5 true as stated, and with what (other) tradeoffs of <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> and <img alt="{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{N}"/> between it and Proposition 4?</p>
<p>
We feel there could also be interesting applications for his theorem as it stands. Is the ability to tell two strings apart with a simple device—a FSA with not many states—useful? Could it solve some open problem? It does seem like a basic insight, yet we have no candidate application. Perhaps you have an idea. </p>
<p/><p><br/>
[added Q on Lemma 5 to “Open Problems”, “lower” bound –&gt; “upper” bound in third section.]</p></font></font></div>
    </content>
    <updated>2020-08-03T14:50:54Z</updated>
    <published>2020-08-03T14:50:54Z</published>
    <category term="All Posts"/>
    <category term="Ideas"/>
    <category term="News"/>
    <category term="primes"/>
    <category term="Proofs"/>
    <category term="Results"/>
    <category term="trick"/>
    <category term="Ben Green"/>
    <category term="estimates"/>
    <category term="finite automata"/>
    <category term="hash functions"/>
    <category term="levers"/>
    <category term="log factors"/>
    <category term="Oxford"/>
    <category term="separating words problem"/>
    <category term="SWP"/>
    <category term="Zachary Chase"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-08-04T01:54:18Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsmath.wordpress.com/?p=2293</id>
    <link href="https://tcsmath.wordpress.com/2020/08/02/itcs-2021-call-for-papers/" rel="alternate" type="text/html"/>
    <title>ITCS 2021 Call for Papers</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">The 12th Innovations in Theoretical Computer Science (ITCS) conference will be held online from January 6-8, 2021. The submission deadline is September 7, 2020. The program committee encourages you to send your papers our way! See the call for papers for information about submitting to the conference. ITCS seeks to promote research that carries a strong conceptual message (e.g., introducing … <a class="more-link" href="https://tcsmath.wordpress.com/2020/08/02/itcs-2021-call-for-papers/">Continue reading <span class="screen-reader-text">ITCS 2021 Call for Papers</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The <strong>12th Innovations in Theoretical Computer Science (ITCS)</strong> conference will be held <strong>online</strong> from <strong>January 6-8, 2021</strong>.   The <strong>submission deadline</strong> is <strong>September 7, 2020</strong>.</p>



<p>The <a href="http://itcs-conf.org/">program committee</a> encourages you to send your papers our way!  See the <a href="http://itcs-conf.org/">call for papers</a> for information about submitting to the conference.</p>



<p>ITCS seeks to promote research that carries a strong conceptual message (e.g., introducing a new concept, model or understanding, opening a new line of inquiry within traditional or interdisciplinary areas, introducing new mathematical techniques and methodologies, or new applications of known techniques). ITCS welcomes both conceptual and technical contributions whose contents will advance and inspire the greater theory community.</p>



<p/>



<h3>Important dates</h3>



<ul><li><strong>Submission deadline: </strong> September 7, 2020 (05:59PM PDT) </li><li><strong>Notification to authors:</strong> November 1, 2020</li><li><strong>Conference dates: </strong>January 6-8, 2021</li></ul>



<p/>



<p/></div>
    </content>
    <updated>2020-08-03T02:06:40Z</updated>
    <published>2020-08-03T02:06:40Z</published>
    <category term="Announcement"/>
    <category term="ITCS"/>
    <category term="theory conference"/>
    <author>
      <name>James</name>
    </author>
    <source>
      <id>https://tcsmath.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsmath.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsmath.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsmath.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsmath.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>some mathematics &amp; computation</subtitle>
      <title>tcs math</title>
      <updated>2020-08-04T01:20:20Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-1233384953933252805</id>
    <link href="https://blog.computationalcomplexity.org/feeds/1233384953933252805/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/the-gauss-story-is-false-yet-we-still.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1233384953933252805" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/1233384953933252805" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2019/04/the-gauss-story-is-false-yet-we-still.html" rel="alternate" type="text/html"/>
    <title>The Gauss story is false yet we still tell it. Should we?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>
When teaching discrete math a while back I told the following story which some had already heard in High School: <br/>
<i><br/></i>
<i>When Gauss was in 1st grade the class was being bad. So the teacher made them sit down and add up the numbers from 1 to 100. Gauss did it in 2 minutes by noting that if S was the answer then </i><br/>
<i><br/></i>
<i>2S = (100+1) +(99+2) + ... + (1 + 100) = 100*101</i><br/>
<i><br/></i>
<i>So S = 50*101.  Then he went to Google and typed in 50*101 for the answer.</i><br/>
<i><br/></i>
The class laughed because of course the last part about Google was false. But I then told them that the entire story was false and showed them the following slides:  <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/gaussstory.pdf">here</a>  Take a look at them (there are only 4 of them) before reading on.<div><br/></div><div>(ADDED LATER: here is an article by Brian Hayes that documents the history of the story.</div><div><br/></div><div><a href="http://bit-player.org/wp-content/extras/bph-publications/AmSci-2006-05-Hayes-Gauss.pdf" target="_blank">http://bit-player.org/wp-content/extras/bph-publications/AmSci-2006-05-Hayes-Gauss.pdf</a></div><div><br/></div><div>)<br/>
<br/>
<br/>
So I told them the Gauss Story was false (I am right about this) and then told them a lie- that the story's progression over time was orderly. I then told them that that was false (hmmm- actually I might not of, oh well).<br/>
<br/>
One of my students emailed me this semester<br/>
<br/>
<i>Dr Gasarch- one of my Math professors is telling the Gauss story as if its true! You should make a public service announcement and tell people its false!</i><div><i><br/></i></div><div>I do not think this is needed. I also don't know how one goes about making a public service announcement  I also  suspect the teacher knew it was false but told it anyway.<div>
<br/>
OKAY- what do you do if you have a nice story that has some good MATH in it but  its not true?<br/>
<br/><b>Options:</b></div><div><br/></div><div>Tell it and let the students think its true.</div><div><br/></div><div>Tell it and debunk it.</div><div><br/></div><div>Tell it and debunk it and tell another myth</div><div><br/></div><div>Tell it and debunk it and tell another myth and then debunk that</div><div><br/></div><div>Ask your readers what they would do. Which I do now: What do you do? <br/><br/></div></div></div></div>
    </content>
    <updated>2020-08-03T02:02:00Z</updated>
    <published>2020-08-03T02:02:00Z</published>
    <author>
      <name>Unknown</name>
      <email>noreply@blogger.com</email>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-08-03T13:13:37Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.16192</id>
    <link href="http://arxiv.org/abs/2007.16192" rel="alternate" type="text/html"/>
    <title>Load Plus Communication Balancing in Contiguous Partitions for Distributed Sparse Matrices: Linear-Time Algorithms</title>
    <feedworld_mtime>1596412800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ahrens:Peter.html">Peter Ahrens</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.16192">PDF</a><br/><b>Abstract: </b>We study partitioning to parallelize multiplication of one or more dense
vectors by a sparse matrix (SpMV or SpMM). We consider contiguous partitions,
where the rows (or columns) of the matrix are split into $K$ parts without
reordering. We present exact and approximate contiguous partitioning algorithms
that minimize the runtime of the longest-running processor under cost models
that combine work factors and hypergraph communication factors. This differs
from traditional graph or hypergraph partitioning models which minimize total
communication under a work balance constraint. We address regimes where
partitions of the row space and column space are expected to match (the
symmetric case) or are allowed to differ (the nonsymmetric case).
</p>
<p>Our algorithms use linear space. Our exact algorithm runs in linear time when
$K^2$ is sublinear. Our $(1 + \epsilon)$-approximate algorithm runs in linear
time when $K\log(1/\epsilon)$ is sublinear.
</p>
<p>We combine concepts from high-performance computing and computational
geometry. Existing load balancing algorithms optimize a linear model of
per-processor work. We make minor adaptations to optimize arbitrary nonuniform
monotonic increasing or decreasing cost functions which may be expensive to
evaluate. We then show that evaluating our model of communication is equivalent
to planar dominance counting. We specialize Chazelle's dominance counting
algorithm to points in the bounded integer plane and generalize it to trade
reduced construction time for increased query time, since our partitioners make
very few queries.
</p>
<p>Our algorithms split the original row (or column) ordering into parts to
optimize diverse cost models. Combined with reordering or embedding techniques,
our algorithms might be used to build more general heuristic partitioners, as
they can optimally round one-dimensional embeddings of direct $K$-way
noncontiguous partitioning problems.
</p></div>
    </summary>
    <updated>2020-08-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.16144</id>
    <link href="http://arxiv.org/abs/2007.16144" rel="alternate" type="text/html"/>
    <title>On the Two-Dimensional Knapsack Problem for Convex Polygons</title>
    <feedworld_mtime>1596412800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Merino:Arturo.html">Arturo Merino</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wiese:Andreas.html">Andreas Wiese</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.16144">PDF</a><br/><b>Abstract: </b>We study the two-dimensional geometric knapsack problem for convex polygons.
Given a set of weighted convex polygons and a square knapsack, the goal is to
select the most profitable subset of the given polygons that fits
non-overlappingly into the knapsack. We allow to rotate the polygons by
arbitrary angles. We present a quasi-polynomial time $O(1)$-approximation
algorithm for the general case and a polynomial time $O(1)$-approximation
algorithm if all input polygons are triangles, both assuming polynomially
bounded integral input data. Also, we give a quasi-polynomial time algorithm
that computes a solution of optimal weight under resource augmentation, i.e.,
we allow to increase the size of the knapsack by a factor of $1+\delta$ for
some $\delta&gt;0$ but compare ourselves with the optimal solution for the
original knapsack. To the best of our knowledge, these are the first results
for two-dimensional geometric knapsack in which the input objects are more
general than axis-parallel rectangles or circles and in which the input
polygons can be rotated by arbitrary angles.
</p></div>
    </summary>
    <updated>2020-08-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.16111</id>
    <link href="http://arxiv.org/abs/2007.16111" rel="alternate" type="text/html"/>
    <title>MSPP: A Highly Efficient and Scalable Algorithm for Mining Similar Pairs of Points</title>
    <feedworld_mtime>1596412800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saha:Subrata.html">Subrata Saha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Soliman:Ahmed.html">Ahmed Soliman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rajasekaran:Sanguthevar.html">Sanguthevar Rajasekaran</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.16111">PDF</a><br/><b>Abstract: </b>The closest pair of points problem or closest pair problem (CPP) is an
important problem in computational geometry where we have to find a pair of
points from a set of points in metric space with the smallest distance between
them. This problem arises in a number of applications, such as but not limited
to clustering, graph partitioning, image processing, patterns identification,
and intrusion detection. For example, in air-traffic control, we must monitor
aircrafts that come too close together, since this may potentially indicate a
possible collision. Numerous algorithms have been presented for solving the
CPP. The algorithms that are employed in practice have a worst case quadratic
run time complexity. In this article we present an elegant approximation
algorithm for the CPP called MSPP: Mining Similar Pairs of Points. It is faster
than currently best known algorithms while maintaining a very good accuracy.
The proposed algorithm also detects a set of closely similar pairs of points in
Euclidean and Pearson metric spaces and can be adapted in numerous real world
applications, such as clustering, dimension reduction, constructing and
analyzing gene/transcript co-expression network, among others.
</p></div>
    </summary>
    <updated>2020-08-03T23:20:28Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15924</id>
    <link href="http://arxiv.org/abs/2007.15924" rel="alternate" type="text/html"/>
    <title>Orientation-Preserving Vectorized Distance Between Curves</title>
    <feedworld_mtime>1596412800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Phillips:Jeff_M=.html">Jeff M. Phillips</a>, Hasan Pourmahmood-Aghababa <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15924">PDF</a><br/><b>Abstract: </b>We introduce an orientation-preserving landmark-based distance for continuous
curves, which can be viewed as an alternative to the Fr$\rm\acute{e}$chet or
Dynamic Time Warping distances. This measure retains many of the properties of
those measures, and we prove some relations, but can be interpreted as a
Euclidean distance in a particular vector space. Hence it is significantly
easier to use, faster for general nearest neighbor queries, and allows easier
access to classification results than those measures. It is based on the
\emph{signed} distance function to the curves or other objects from a fixed set
of landmark points. We also prove new stability properties with respect to the
choice of landmark points, and along the way introduce a concept called signed
local feature size (slfs) which parameterizes these notions. Slfs explains the
complexity of shapes such as non-closed curves where the notion of local
orientation is in dispute -- but is more general than the well-known concept of
(unsigned) local feature size, and is for instance infinite for closed simple
curves. Altogether, this work provides a novel, simple, and powerful method for
oriented shape similarity and analysis.
</p></div>
    </summary>
    <updated>2020-08-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15839</id>
    <link href="http://arxiv.org/abs/2007.15839" rel="alternate" type="text/html"/>
    <title>Robust and Heavy-Tailed Mean Estimation Made Simple, via Regret Minimization</title>
    <feedworld_mtime>1596412800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hopkins:Samuel_B=.html">Samuel B. Hopkins</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jerry.html">Jerry Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Fred.html">Fred Zhang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15839">PDF</a><br/><b>Abstract: </b>We study the problem of estimating the mean of a distribution in high
dimensions when either the samples are adversarially corrupted or the
distribution is heavy-tailed. Recent developments in robust statistics have
established efficient and (near) optimal procedures for both settings. However,
the algorithms developed on each side tend to be sophisticated and do not
directly transfer to the other, with many of them having ad-hoc or complicated
analyses.
</p>
<p>In this paper, we provide a meta-problem and a duality theorem that lead to a
new unified view on robust and heavy-tailed mean estimation in high dimensions.
We show that the meta-problem can be solved either by a variant of the Filter
algorithm from the recent literature on robust estimation or by the quantum
entropy scoring scheme (QUE), due to Dong, Hopkins and Li (NeurIPS '19). By
leveraging our duality theorem, these results translate into simple and
efficient algorithms for both robust and heavy-tailed settings. Furthermore,
the QUE-based procedure has run-time that matches the fastest known algorithms
on both fronts.
</p>
<p>Our analysis of Filter is through the classic regret bound of the
multiplicative weights update method. This connection allows us to avoid the
technical complications in previous works and improve upon the run-time
analysis of a gradient-descent-based algorithm for robust mean estimation by
Cheng, Diakonikolas, Ge and Soltanolkotabi (ICML '20).
</p></div>
    </summary>
    <updated>2020-08-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15784</id>
    <link href="http://arxiv.org/abs/2007.15784" rel="alternate" type="text/html"/>
    <title>New Results in Sona Drawing: Hardness and TSP Separation</title>
    <feedworld_mtime>1596412800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chiu:Man=Kwun.html">Man-Kwun Chiu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Erik_D=.html">Erik D. Demaine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diomidov:Yevhenii.html">Yevhenii Diomidov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eppstein:David.html">David Eppstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hearn:Robert_A=.html">Robert A. Hearn</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hesterberg:Adam.html">Adam Hesterberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Korman:Matias.html">Matias Korman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parada:Irene.html">Irene Parada</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rudoy:Mikhail.html">Mikhail Rudoy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15784">PDF</a><br/><b>Abstract: </b>Given a set of point sites, a sona drawing is a single closed curve, disjoint
from the sites and intersecting itself only in simple crossings, so that each
bounded region of its complement contains exactly one of the sites. We prove
that it is NP-hard to find a minimum-length sona drawing for $n$ given points,
and that such a curve can be longer than the TSP tour of the same points by a
factor $&gt; 1.5487875$. When restricted to tours that lie on the edges of a
square grid, with points in the grid cells, we prove that it is NP-hard even to
decide whether such a tour exists. These results answer questions posed at CCCG
2006.
</p></div>
    </summary>
    <updated>2020-08-03T23:32:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-08-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15743</id>
    <link href="http://arxiv.org/abs/2007.15743" rel="alternate" type="text/html"/>
    <title>Distribution-Free Models of Social Networks</title>
    <feedworld_mtime>1596412800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roughgarden:Tim.html">Tim Roughgarden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seshadhri:C=.html">C. Seshadhri</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15743">PDF</a><br/><b>Abstract: </b>The structure of large-scale social networks has predominantly been
articulated using generative models, a form of average-case analysis. This
chapter surveys recent proposals of more robust models of such networks. These
models posit deterministic and empirically supported combinatorial structure
rather than a specific probability distribution. We discuss the formal
definitions of these models and how they relate to empirical observations in
social networks, as well as the known structural and algorithmic results for
the corresponding graph classes.
</p></div>
    </summary>
    <updated>2020-08-03T23:23:58Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2007.15709</id>
    <link href="http://arxiv.org/abs/2007.15709" rel="alternate" type="text/html"/>
    <title>An Asymptotic Lower Bound for Online Vector Bin Packing</title>
    <feedworld_mtime>1596412800</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bansal:Nikhil.html">Nikhil Bansal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen:Ilan_R=.html">Ilan R. Cohen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2007.15709">PDF</a><br/><b>Abstract: </b>We consider the online vector bin packing problem where $n$ items specified
by $d$-dimensional vectors must be packed in the fewest number of identical
$d$-dimensional bins. Azar et al. (STOC'13) showed that for any online
algorithm $A$, there exist instances I, such that $A(I)$, the number of bins
used by $A$ to pack $I$, is $\Omega(d/\log^2 d)$ times $OPT(I)$, the minimal
number of bins to pack $I$. However in those instances, $OPT(I)$ was only
$O(\log d)$, which left open the possibility of improved algorithms with better
asymptotic competitive ratio when $OPT(I) \gg d$. We rule this out by showing
that for any arbitrary function $q(\cdot)$ and any randomized online algorithm
$A$, there exist instances $I$ such that $ E[A(I)] \geq c\cdot d/\log^3d \cdot
OPT(I) + q(d)$, for some universal constant $c$.
</p></div>
    </summary>
    <updated>2020-08-03T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-08-03T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/08/02/sona-enumeration</id>
    <link href="https://11011110.github.io/blog/2020/08/02/sona-enumeration.html" rel="alternate" type="text/html"/>
    <title>Sona enumeration</title>
    <summary>The last of my CCCG 2020 papers is now on the arXiv: “New Results in Sona Drawing: Hardness and TSP Separation”, arXiv:2007.15784, with Chiu, Demaine, Diomidov, Hearn, Hesterberg, Korman, Parada, and Rudoy. (As you might infer from the long list of coauthors, it’s a Barbados workshop paper.) The paper studies a mathematical formalization of the lusona drawings of southwest Africa; in this formalization, a sona curve for a given set of points is a curve that can be drawn in a single motion, intersecting itself only at simple crossings, and surrounding each given point in a separate region of the plane, with no empty regions. The paper proves that it’s hard to find the shortest one, hard even to find whether one exists when restricted to grid edges, and gives tighter bounds for the widest possible ratio between sona curve length and TSP tour length; see the preprint or the video I already posted for more information.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The last of my CCCG 2020 papers is now on the arXiv: “New Results in Sona Drawing: Hardness and TSP Separation”, <a href="https://arxiv.org/abs/2007.15784">arXiv:2007.15784</a>, with Chiu, Demaine, Diomidov, Hearn, Hesterberg, Korman, Parada, and Rudoy. (As you might infer from the long list of coauthors, it’s a Barbados workshop paper.) The paper studies a mathematical formalization of the <a href="https://en.wikipedia.org/wiki/Lusona">lusona</a> drawings of southwest Africa; in this formalization, a sona curve for a given set of points is a curve that can be drawn in a single motion, intersecting itself only at simple crossings, and surrounding each given point in a separate region of the plane, with no empty regions. The paper proves that it’s hard to find the shortest one, hard even to find whether one exists when restricted to grid edges, and gives tighter bounds for the widest possible ratio between sona curve length and TSP tour length; see the preprint or <a href="https://11011110.github.io/blog/2020/07/22/three-cccg-videos.html">the video I already posted</a> for more information.</p>

<p>To save this post from being content-free, here’s a research question that we didn’t even state in the paper, let alone make any progress on solving: just how many of these curves can a given set of points have? A sona curve can be described as a 4-regular plane multigraph (satisfying certain extra conditions) together with an assignment of the given points to its bounded faces, so there are finitely many of these things up to some sort of topological equivalence. And because this is topological it shouldn’t matter where the points are placed in the plane: the number of curves should be a function only of the number of points. I tried hand-enumerating the curves for up to three points but it was already messy and I’m not certain I got them all. (In an earlier version of this post I definitely didn’t get them all — I had to update the figure below after finding more.) Here are the ones I found:</p>

<p style="text-align: center;"><img alt="Sona curves for up to three points" src="https://11011110.github.io/blog/assets/2020/sona-enum.svg"/></p>

<p>If this hand enumeration is correct, then the numbers of sona curves for  labeled points form an integer sequence beginning  and the numbers for unlabeled points form a sequence beginning  but I don’t really know anything more than that for this problem.</p>

<p>Another research direction I don’t know much about yet: given a topological equivalence class of sona drawings, how can we find a good layout for it as an explicit drawing? There’s lots of research on drawing plane graphs nicely but it’s not clear how much of it carries over to making nice sona curves.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104624173377453724">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-08-02T23:48:00Z</updated>
    <published>2020-08-02T23:48:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-08-03T07:36:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/116</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/116" rel="alternate" type="text/html"/>
    <title>TR20-116 |  Toward better depth lower bounds: the XOR-KRW conjecture | 

	Alexander Smal, 

	Ivan Mihajlin</title>
    <summary>In this paper, we propose a new conjecture, the XOR-KRW conjecture, which is a relaxation of the Karchmer-Raz-Wigderson conjecture [KRW95]. This relaxation is still strong enough to imply $\mathbf{P} \not\subseteq \mathbf{NC}^1$ if proven. We also present a weaker version of this conjecture that might be used for breaking $n^3$ lower bound for De~Morgan formulas. Our study of this conjecture allows us to partially answer an open question stated in [GMWW17] regarding the composition of the universal relation with a function. To be more precise, we prove that there exists a function $g$ such that the composition of the universal relation with $g$ is significantly harder than just a universal relation. The fact that we can only prove the existence of $g$ is an inherent feature of our approach.
    
The paper's main technical contribution is a method of converting lower bounds for multiplexer-type relations into lower bounds against functions. In order to do this, we develop techniques to lower bound communication complexity using reductions from non-deterministic communication complexity and non-classical models: half-duplex and partially half-duplex communication models.</summary>
    <updated>2020-08-02T06:10:06Z</updated>
    <published>2020-08-02T06:10:06Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-04T01:54:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://gilkalai.wordpress.com/?p=19988</id>
    <link href="https://gilkalai.wordpress.com/2020/08/01/to-cheer-you-up-in-difficult-times-8-nathan-keller-and-ohad-klein-proved-tomaszewskis-conjecture-on-randomly-signed-sums/" rel="alternate" type="text/html"/>
    <title>To Cheer you up in Difficult Times 8: Nathan Keller and Ohad Klein Proved Tomaszewski’s Conjecture on Randomly Signed Sums</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Today we talk about the paper, Proof of Tomaszewski’s Conjecture on Randomly Signed Sums, by Nathan Keller and Ohad Klein. Consider a unit vector That is latex \sum_{i=1}^n a_i^2=1$. Consider all () signed sums where each is either 1 or … <a href="https://gilkalai.wordpress.com/2020/08/01/to-cheer-you-up-in-difficult-times-8-nathan-keller-and-ohad-klein-proved-tomaszewskis-conjecture-on-randomly-signed-sums/">Continue reading <span class="meta-nav">→</span></a></div>
    </summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Today we talk about the paper, <a href="https://arxiv.org/abs/2006.16834">Proof of Tomaszewski’s Conjecture on Randomly Signed Sums</a>, by Nathan Keller and Ohad Klein.</p>
<p>Consider a unit vector <img alt="a=(a_1,a_2,\dots, a_n)." class="latex" src="https://s0.wp.com/latex.php?latex=a%3D%28a_1%2Ca_2%2C%5Cdots%2C+a_n%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a=(a_1,a_2,\dots, a_n)."/> That is latex \sum_{i=1}^n a_i^2=1$. Consider all (<img alt="2^n" class="latex" src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^n"/>) signed sums <img alt="\displaystyle \epsilon_1a_1+\epsilon_2a_2+\cdots +\epsilon_n a_n, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cepsilon_1a_1%2B%5Cepsilon_2a_2%2B%5Ccdots+%2B%5Cepsilon_n+a_n%2C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle \epsilon_1a_1+\epsilon_2a_2+\cdots +\epsilon_n a_n, "/> where each <img alt="\epsilon_k" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cepsilon_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\epsilon_k"/> is either 1 or -1.</p>
<p><strong>Theorem (Keller and Klein (2020) asked by Boguslav Tomaszewski (1986)): </strong>For at least <img alt="2^{n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=2%5E%7Bn-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="2^{n-1}"/> signed sums <img alt="\displaystyle |\epsilon_1a_1+\epsilon_2a_2+\cdots +\epsilon_n a_n| \le 1 ." class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7C%5Cepsilon_1a_1%2B%5Cepsilon_2a_2%2B%5Ccdots+%2B%5Cepsilon_n+a_n%7C+%5Cle+1+.&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\displaystyle |\epsilon_1a_1+\epsilon_2a_2+\cdots +\epsilon_n a_n| \le 1 ."/></p>
<p>Another way to state the theorem is that the probability of a signed sum to be in the interval [-1, 1] is at least 1/2.</p>
<p>To see that this is best possible consider the case that <img alt="n=2" class="latex" src="https://s0.wp.com/latex.php?latex=n%3D2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n=2"/> and let <img alt="a_1,a_2" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ca_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1,a_2"/> be non zero. For the sum in question to exceed one we need both summands to have the same sign which happens half of the times. There is another example of importance, the vector <img alt="(\frac{1}{2}, \frac{1}{2}, \frac {1}{2}, \frac{1}{2})" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Cfrac%7B1%7D%7B2%7D%2C+%5Cfrac%7B1%7D%7B2%7D%2C+%5Cfrac+%7B1%7D%7B2%7D%2C+%5Cfrac%7B1%7D%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="(\frac{1}{2}, \frac{1}{2}, \frac {1}{2}, \frac{1}{2})"/>. Here 3/8 of the absolute values of signed sums (6 out of 16) are below 1 (in fact, equal to zero), 1/2 equal to 1 and 1/8 exceed 1. Holzman and Kleitman proved in 1992 that the fraction of absolute values of signed sums below 1 is always at least 3/8.</p>
<p>Congratulations to Nathan and Ohad. I will say a little more about the problem below but before that, a few more things.</p>
<h3>A few more things</h3>
<p>Luca Trevisan posted on his blog In Theory a post “Silver linings” about two cheerful pieces of news. The first one is “Karlin, Klein, and Oveis Gharan have just <a href="https://arxiv.org/abs/2007.01409">posted a paper</a> in which, at long last, they improve over the 1.5 approximation ratio for metric TSP which was achieved, in 1974, by Christofides.”</p>
<p>The second  one is about breaking the logarithmic barrier for Roth’s theorem that we wrote about here. This was also discussed by Bill <a>Gasarch </a>on Computational Complexity. In the comment section of my post there is an interesting discussion regarding timetable for future achievements and how surprising they would be.</p>
<p>The third is about Ron Graham, a friend and a mathematical giant who passed away a few days ago. Here is a <a href="https://www.facebook.com/fan.chung.9/posts/10220086655131549">moving post</a> by Fan Chung, <a href="http://www.math.ucsd.edu/~fan/ron/">a web page for Ron</a> set by Fan, and a <a href="https://rjlipton.wordpress.com/2020/07/10/ron-graham-1935-2020/">blog post by Dick and Ken on GLL</a>.</p>
<p>The fourth is that there is a nice collection of open problems on Boolean functions that is cited in the paper of Nathan and Ohad:  Y. Filmus, H. Hatami, S. Heilman, E. Mossel, R. O’Donnell, S. Sachdeva, A. Wan, and K. Wimmer, <a href="https://simons.berkeley.edu/sites/default/files/openprobsmerged.pdf">Real analysis in computer science: A collection of open problems</a>.</p>
<p>The fifth is that both our (HUJI) combinatorics seminar and basic notions seminar are running and are recorded. Here are the links. (Hmm, the links are not yet available, I will update.)</p>
<h2>Back to the result of Keller and Klein</h2>
<h3><a href="https://gilkalai.files.wordpress.com/2020/08/dkrh2.png"><img alt="" class="alignnone size-full wp-image-20034" height="365" src="https://gilkalai.files.wordpress.com/2020/08/dkrh2.png?w=640&amp;h=365" width="640"/></a></h3>
<p><span style="color: #ff0000;">Daniel Kleitman and Ron Holzman</span></p>
<h3>A quick orientation</h3>
<p>If the <img alt="a_i" class="latex" src="https://s0.wp.com/latex.php?latex=a_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i"/>s are all the same, or small, or random, then to compute the probability that the weighted sum is between -1 and 1, we can use some Gaussian approximation and then we will find ourselves in a clash of constants that goes our way. The probability will be close to a constant well above 1/2. So what we need to understand is the case where some <img alt="a_i" class="latex" src="https://s0.wp.com/latex.php?latex=a_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_i"/>s are large.</p>
<h3>Early papers on the problem</h3>
<p>The problem first appeared in the American Math Monthly.  Richard Guy <a href="https://www.math.wisc.edu/~miller/res/fun-problem.pdf">collected several problems  and challenged the readers Any Answers Anent These Analytical Enigmas?</a> (I don’t know what the fate of the other questions is.)  Holzman and Kleitman <a href="https://holzman.technion.ac.il/files/2012/09/combsigns.pdf">proved in 1992</a> that the fraction of absolute values of signed sums below 1 is always at least 3/8, and this is tight. For many years, 3/8 was the record for the original problem, until  the 2017 paper by Ravi Boppana and Ron Holzman: <a href="https://arxiv.org/abs/1704.00350">Tomaszewski’s problem on randomly signed sums: Breaking the 3/8 barrier</a>, where a lower bound of 0.406, was proved. The current record 0f 0.46 was proved in the paper <a href="https://arxiv.org/abs/2005.05031">Improved Bound for Tomaszewski’s Problem</a> by Vojtěch Dvořák, Peter van Hintum, and Marius Tiba. The new definite result by Nathan and Ohad used some ideas of these early papers.</p>
<h3>What is the crux of matters</h3>
<p>Let me quote what the authors kindly wrote me:</p>
<blockquote><p><em>“The crux of the matter is how to deal with the case of very large coefficients (<img alt="a_1+a_2&gt;1" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ba_2%3E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1+a_2&gt;1"/>). We gave a short semi-inductive argument covering this case (this is Section 5 of the paper). The argument is only semi-inductive, as it requires the full assertion of Tomaszewski for any n'&lt;n, and gives only the case (<img alt="a_1+a_2&gt;1" class="latex" src="https://s0.wp.com/latex.php?latex=a_1%2Ba_2%3E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a_1+a_2&gt;1"/>) for <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="n"/>. But this means that if we can handle all other cases by other methods then we will be done.</em></p>
<p><em>The semi-inductive argument takes only 3 pages. Handling the other cases takes 72 more pages and requires several new tools, but is closer to things that were done in previous works. (Actually, after we found the 3-page argument, we were quite sure we will be able to finalize the proof; this indeed happened, but took a year).”</em></p></blockquote>
<p>Most of the paper deals with the case of small coefficients. This requires several ideas and new tools.</p>
<h3>Rademacher sums: Improved Berry-Esseen and local tail inequalities</h3>
<p>If all coefficients are “sufficiently small”, then we can<br/>
approximate X by a Gaussian and the inequality should follow. However, using the standard <a href="https://en.wikipedia.org/wiki/Berry%E2%80%93Esseen_theorem">Berry-Esseen bound</a>, this holds only if all coefficients are less than 0.16.<br/>
Nathan and Ohad showed that for Rademacher sums, namely random variables of the form <img alt="X=\sum a_i x_i" class="latex" src="https://s0.wp.com/latex.php?latex=X%3D%5Csum+a_i+x_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="X=\sum a_i x_i"/>, as discussed in the conjecture, a stronger Berry-Esseen<br/>
bound can be obtained, and this bound shows immediately that Tomaszewski’s assertion holds whenever all coefficients are less than 0.31. The stronger bound stems<br/>
from a method of Prawitz, presented in the 1972 paper. H. Prawitz, <a href="https://www.tandfonline.com/doi/abs/10.1080/03461238.1972.10404645">Limits for a distribution, if the characteristic function is given in a finite domain</a>, which appeared in the Scandinavian <span style="color: #ff0000;">Actuarial</span> journal.</p>
<p>The second tool is local tail inequalities for Rademacher sums, of the form <img alt="\Pr[a&lt;X&lt;b] \leq \Pr[c&lt;X&lt;d]," class="latex" src="https://s0.wp.com/latex.php?latex=%5CPr%5Ba%3CX%3Cb%5D+%5Cleq+%5CPr%5Bc%3CX%3Cd%5D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\Pr[a&lt;X&lt;b] \leq \Pr[c&lt;X&lt;d],"/> where <em>a,b,c,d</em> satisfy certain conditions. Inequalities of this kind were obtained before by Devroye and Lugosi in the 2008 paper:  <a href="https://arxiv.org/abs/0712.1686">Local tail bounds for functions of independent random variables</a>.</p>
<p>These local tail inequalities already have some other applications, e.g., to analysis of Boolean functions. They were developed and applied in an earlier paper paper of Keller and Klein: <a href="https://arxiv.org/abs/1710.07429">Biased halfspaces, noise sensitivity, and relative Chernoff inequalities</a>. Let me mention my related MO question <a href="https://mathoverflow.net/questions/85835/a-variance-tail-description-for-continuous-probability-distributions">A variance tail description for continuous probability distributions.</a></p>
<h3>A couple more ingredients</h3>
<p><strong>A  stopping time argument.</strong> Variants of Tomaszewski’s problem appeared in various fields. The problem was stated independently in a 2002 paper by Ben-Tal, Nemirovski, Roos, <a href="https://www2.isye.gatech.edu/~nemirovs/SIOPT_RQP_2002.pdf">Robust solutions of uncertain quadratic and conic-quadratic problems.</a>  A stopping time argument introduced there (for proving a lower bound of 1/3) played a crucial role in subsequent works and the critical semi-inductive argument by Nathan and Ohad.</p>
<p><strong>Refinements of the famous <a href="https://en.wikipedia.org/wiki/Chebyshev%27s_inequality">Chebyshev’s inequality</a>.</strong>  (Did you know Chebyshev’s full name? Ans: Pafnuty Lvovich Chebyshev.)</p>
<dl>
<dd/>
</dl>
<h3>Questions and connections that come to mind</h3>
<p><strong>Q1:</strong> What can be said about families <img alt="\cal F" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ccal+F&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="\cal F"/> of signs that can serve as those signs for which  <img alt="|\epsilon_1a_1+\epsilon_2a_2+\cdots +\epsilon_n a_n| \le 1 ," class="latex" src="https://s0.wp.com/latex.php?latex=%7C%5Cepsilon_1a_1%2B%5Cepsilon_2a_2%2B%5Ccdots+%2B%5Cepsilon_n+a_n%7C+%5Cle+1+%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="|\epsilon_1a_1+\epsilon_2a_2+\cdots +\epsilon_n a_n| \le 1 ,"/> for some vector <img alt="a" class="latex" src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" title="a"/>.</p>
<p><strong>Q2:</strong> What can be said about the complex version or even more generally about high dimensions?</p>
<p><strong>Q3:</strong> Are there any relations to <a href="https://www.jstor.org/stable/1971442?seq=1">Littlewood-Offord type problems</a>?</p>
<p><strong>Q4:</strong> Is there any relation to the <a href="https://ocw.mit.edu/courses/mathematics/18-s096-topics-in-mathematics-of-data-science-fall-2015/projects/MIT18_S096F15_Open0.1.pdf">Komlos Conjecture</a>?</p>
<p>See also <a href="https://mathoverflow.net/questions/53669/anti-concentration-of-bernoulli-sums/53683#53683">this MO question</a> by Luca Trevisan and <a href="https://mathoverflow.net/questions/366894/a-rademacher-root-7-anti-concentration-inequality">this one</a> by George Lowther.</p>
<h3><span style="color: #ff0000;"><strong>Is there a simpler proof?</strong></span></h3>
<p>We can ask about simpler or just different proofs for almost every result we discuss here. But here the statement is so simple…</p>
<div class="thumb tright">
<div class="thumbinner"/>
</div>
<div class="thumb tright">
<div class="thumbinner">
<div class="thumbcaption"/>
</div>
</div></div>
    </content>
    <updated>2020-08-01T18:32:23Z</updated>
    <published>2020-08-01T18:32:23Z</published>
    <category term="Analysis"/>
    <category term="Combinatorics"/>
    <category term="Probability"/>
    <category term="Boguslav Tomaszewski"/>
    <category term="Nathan Keller"/>
    <category term="Ohad Klein"/>
    <author>
      <name>Gil Kalai</name>
    </author>
    <source>
      <id>https://gilkalai.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://gilkalai.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://gilkalai.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://gilkalai.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://gilkalai.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Gil Kalai's blog</subtitle>
      <title>Combinatorics and more</title>
      <updated>2020-08-04T01:54:13Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/115</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/115" rel="alternate" type="text/html"/>
    <title>TR20-115 |  The Busy Beaver Frontier | 

	Scott Aaronson</title>
    <summary>The Busy Beaver function, with its incomprehensibly rapid growth, has captivated generations of computer scientists, mathematicians, and hobbyists. In this survey, I offer a personal view of the BB function 58 years after its introduction, emphasizing lesser-known insights, recent progress, and especially favorite open problems. Examples of such problems include: when does the BB function first exceed the Ackermann function? Is the value of BB(20) independent of set theory? Can we prove that BB(n+1)&gt;2^BB(n) for large enough n? Given BB(n), how many advice bits are needed to compute BB(n+1)? Do all Busy Beavers halt on all inputs, not just the 0 input? Is it decidable, given n, whether BB(n) is even or odd?</summary>
    <updated>2020-08-01T05:13:00Z</updated>
    <published>2020-08-01T05:13:00Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-04T01:54:08Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/07/31/linkage</id>
    <link href="https://11011110.github.io/blog/2020/07/31/linkage.html" rel="alternate" type="text/html"/>
    <title>Linkage</title>
    <summary>Gil Kalai on recent developments in Roth’s theorem (, see also). Salem and Spencer and later Behrend proved in the 1940s that subsets of with no triple in arithmetic progression can have nearly linear size, and Klaus Roth proved in 1953 that they must be sublinear. The upper bounds have slowly come down, to in this new result, but they’re still far from Behrend’s lower bound.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><ul>
  <li>
    <p><a href="https://gilkalai.wordpress.com/2020/07/08/to-cheer-you-up-in-difficult-times-7-bloom-and-sisask-just-broke-the-logarithm-barrier-for-roths-theorem/">Gil Kalai on recent developments in Roth’s theorem</a> (<a href="https://mathstodon.xyz/@11011110/104533566344469712"/>, <a href="https://blog.computationalcomplexity.org/2020/07/erdos-turan-for-k3-is-true.html">see also</a>). Salem and Spencer and later Behrend proved in the 1940s that <a href="https://en.wikipedia.org/wiki/Salem%E2%80%93Spencer_set">subsets of  with no triple in arithmetic progression</a> can have nearly linear size, and Klaus Roth proved in 1953 that <a href="https://en.wikipedia.org/wiki/Roth%27s_theorem_on_arithmetic_progressions">they must be sublinear</a>. The upper bounds have slowly come down, to  in this new result, but they’re still far from Behrend’s  lower bound.</p>
  </li>
  <li>
    <p><a href="https://cameroncounts.wordpress.com/2020/06/27/peter-sarnaks-hardy-lecture/">Peter Cameron describes Peter Sarnak’s Hardy Lecture</a> (<a href="https://mathstodon.xyz/@11011110/104539029304056696"/>). It’s on the spectral theory of graphs. If you know about this you probably already know that regular graphs with a big gap between the largest eigenvalue (degree) and the second largest are very good expander graphs. It turns out that 3-regular graphs with gaps elsewhere in their spectrum are also important in the theories of waveguides and fullerenes, and some tight bounds on where those gaps can be are now known.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2007.07983">Optimal angle bounds for quadrilateral meshes</a> (<a href="https://mathstodon.xyz/@11011110/104544859698397049"/>). Christopher J. Bishop meshes any simple polygon (why simple?) with max angle 120° and min angle max(60°, min of the polygon). Nice techniques involving conformal mapping, hyperbolic tessellation, and thick/thin decompositions of hyperbolic convex hulls of ideal sets. Also amusing to see him have to disambiguate my name from David B. A. Epstein’s within a single paragraph.</p>
  </li>
  <li>
    <p><a href="https://imgur.com/gallery/72lduu6">One-dimensional diagonal cellular automata generate Sierpinski carpets and intricate branching structures</a> (<a href="https://mathstodon.xyz/@11011110/104550317577491129"/>, <a href="https://community.wolfram.com/groups/-/m/t/1890120">see also</a>). Via the June 27 update to <a href="http://www.mathpuzzle.com/">mathpuzzle.com</a> which also has plenty of other neat stuff involving tilings, drawings of symmetric graphs, graceful labeling, rectangle dissection into similar rectangles, etc.</p>
  </li>
  <li>
    <p><a href="https://mathoverflow.net/a/366118">Terry Tao on mathematical notation</a> (<a href="https://mathstodon.xyz/@JordiGH/104552943941946623"/>), in response to a MathOverflow question about why there’s more than one way to write inner products.</p>
  </li>
  <li>
    <p><a href="http://matroidunion.org/?p=2693">Carmesin’s 3d version of Whitney’s planarity criterion</a> (<a href="https://mathstodon.xyz/@11011110/104567191288903767"/>): a simply-connected 2-dimensional simplicial complex (meeting a technical condition, “locality”) can be topologically embedded into Euclidean space if and only if a certain ternary matroid on its faces has a graphic dual. The proof relies on Perelman’s proof of the Poincaré conjecture! Simply-connected complexes are pretty restrictive but they include e.g. the cone over a graph, which embeds if and only if the graph is planar.</p>
  </li>
  <li>
    <p><a href="https://cp4space.wordpress.com/2020/07/24/fast-growing-functions-revisited/">Fast-growing functions revisited</a> (<a href="https://mathstodon.xyz/@11011110/104573335749947907"/>). News of recent developments relating the <a href="https://en.wikipedia.org/wiki/Busy_beaver">busy beaver function</a> with <a href="https://en.wikipedia.org/wiki/Graham%27s_number">Graham’s number</a>, and proofs of some older claims.</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1007/s12109-020-09750-0">Wikipedia, the free online medical encyclopedia anyone can plagiarize: Time to address wiki‑plagiarism</a> (<a href="https://mathstodon.xyz/@11011110/104576022559029845"/>, <a href="https://retractionwatch.com/2020/07/25/weekend-reads-image-duplication-software-debuts-papers-that-plagiarize-wikipedia-time-to-get-serious-about-research-fraud/">via</a>). In this editorial in <em>Publishing Research Quarterly</em>, Michaël R. Laurent identifies five PubMed-indexed papers that copied content from Wikipedia without crediting it (noting that this is much more prevalent in predatory book and journal publishing), and argues that doing this should be treated as a form of academic misconduct.</p>
  </li>
  <li>
    <p><a href="https://andrewducker.dreamwidth.org/3861716.html">Facebook temporarily blocks posts of links to dreamwidth</a> (<a href="https://mathstodon.xyz/@11011110/104581191674329045"/>, <a href="https://news.ycombinator.com/item?id=23956640">via</a>). Maybe it was just a mistake? And I guess the decentralization of Mastodon would make doing this to Mastodon posts somewhat harder. But this continued walling-off of the open web is not a good thing.</p>
  </li>
  <li>
    <p><a href="https://nebusresearch.wordpress.com/2020/07/23/my-all-2020-mathematics-a-to-z-fibonacci/">How much we don’t know about Fibonacci</a> (<a href="https://mathstodon.xyz/@nebusj/104581720945583863"/>). Entry F in Joseph Nebus’s 2020 mathematics A-to-Z.</p>
  </li>
  <li>
    <p><a href="https://cp4space.wordpress.com/2020/07/25/rational-dodecahedron-inscribed-in-unit-sphere/">Rational dodecahedron inscribed in unit sphere</a> (<a href="https://mathstodon.xyz/@11011110/104595876537307480"/>). It’s easy to inscribe a dodecahedron in the unit sphere: just use a regular one of the appropriate size. And it’s <a href="https://johncarlosbaez.wordpress.com/2011/09/12/fools-gold/">not hard to construct a dodecahedron combinatorially equivalent to the regular dodecahedron but with integer coordinates</a>. Now Adam Goucher shows how to do both at once, in answer to <a href="https://mathoverflow.net/q/234212/440">an old MathOverflow question</a>.</p>
  </li>
  <li>
    <p><em><a href="https://doi.org/10.1007/978-1-4612-5759-2">Descartes on Polyhedra</a></em> (<a href="https://mathstodon.xyz/@11011110/104606789909959594"/>, <a href="https://en.wikipedia.org/wiki/Descartes_on_Polyhedra">see also</a>). This book is mainly on whether Descartes (circa 1630) knew Euler’s formula  (before Euler in 1752, but after Maurolico in 1537). It also covers Descartes’ invention of polyhedral figurate numbers beyond the cubes and pyramidal ones known to the Greeks. Descartes’ manuscript has an interesting history: found after his death in a desk, sunk in the Seine, copied by Leibniz, both copies lost, and Leibniz’s copy finally rediscovered in 1860.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=yY9GAyJtuJ0">Spherical geometry is stranger than hyperbolic (in how it looks from an in-universe viewpoint)</a> (<a href="https://mathstodon.xyz/@11011110/104611506183926064"/>, <a href="https://news.ycombinator.com/item?id=24011727">via</a>).</p>
  </li>
</ul></div>
    </content>
    <updated>2020-07-31T21:03:00Z</updated>
    <published>2020-07-31T21:03:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-08-03T07:36:44Z</updated>
    </source>
  </entry>

  <entry>
    <id>https://11011110.github.io/blog/2020/07/29/polyhedra-convex-unfoldings</id>
    <link href="https://11011110.github.io/blog/2020/07/29/polyhedra-convex-unfoldings.html" rel="alternate" type="text/html"/>
    <title>Polyhedra with convex unfoldings</title>
    <summary>My newest arXiv preprint is “Acutely triangulated, stacked, and very ununfoldable polyhedra” with Erik and Martin Demaine (arXiv:2007.14525). It’s about polyhedra with acute-triangle faces that cannot be unfolded without cutting their surface into many separate polygons. I already posted a video for the paper so see that for more information.</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>My newest arXiv preprint is “Acutely triangulated, stacked, and very ununfoldable polyhedra” with Erik and Martin Demaine (<a href="https://arxiv.org/abs/2007.14525">arXiv:2007.14525</a>). It’s about polyhedra with acute-triangle faces that cannot be unfolded without cutting their surface into many separate polygons. I <a href="https://11011110.github.io/blog/2020/07/22/three-cccg-videos.html">already posted a video for the paper</a> so see that for more information.</p>

<p>Instead, I thought I’d go into a little more detail about a throwaway remark in the video and the paper (one that I already got an email query about). It says that <a href="https://en.wikipedia.org/wiki/Ideal_polyhedron">ideal hyperbolic polyhedra</a> can always be unfolded (into the hyperbolic plane). These polyhedra are the hyperbolic convex hulls of finitely many limit points of the hyperbolic space; their faces are ideal polygons, glued together along entire hyperbolic lines. More strongly, if you cut an ideal polyhedron along any spanning tree of its vertices and edges, the result always unfolds into a convex ideal hyperbolic polygon. Here, for instance, is a net for an ideal cube:</p>

<p style="text-align: center;"><img alt="Net for an ideal cube" src="https://11011110.github.io/blog/assets/2020/ideal-cube-net.svg"/></p>

<p>I don’t know of a previous reference for this result, and the paper and video state it without proof (because it’s an introductory remark and not the topic of the paper), but it’s easy to prove a stronger statement by induction: any collection of ideal hyperbolic polygons (like the faces of an ideal polyhedron), when connected edge-to-edge in a complex with the connectivity of a tree (like the faces of any convex polyhedron when you cut it along a spanning tree), unfolds to an ideal convex polygon. As a base case, when you have one polygon in your collection, it unfolds to itself. When you have more than one, find a leaf polygon of the tree structure, remove it, and unfold the rest into a convex ideal polygon. Now add back the leaf. It needs to be connected to the rest of the complex along a hyperbolic line, which (by the induction hypothesis that the rest unfolds convexly) has the rest of the complex on one side and an empty hyperbolic halfplane on the other side. Any convex ideal polygon can be placed within this halfplane so that the side on which it should be glued matches up with the boundary line of the halfplane, with enough freedom to match up the points along this line that should be matched up.</p>

<p>This caused me to wonder: which Euclidean convex polyhedra have the same property, that cutting them along any spanning tree leads to a convex unfolding? The answer is: not very many. By <a href="https://en.wikipedia.org/wiki/Descartes%27_theorem_on_total_angular_defect">Descartes’ theorem on total angular defect</a>, the angular defects at the vertices of a convex polyhedron add up to . If a polyhedron is to have all spanning trees produce a (weakly) convex unfolding, then each vertex has to have angular defect at least , because otherwise cutting along a spanning tree that has a leaf at that vertex will make an unfolding that is non-convex at that vertex. And this is the only thing that can go wrong, because if all angular defects are at least  then the unfolding will be convex at each of its vertices and cannot self-overlap.</p>

<p>So to answer the question about Euclidean polyhedra with all unfoldings convex, we need only look for ways to partition the total angular defect of  among some set of vertices so that each one gets at least . If we know the defects of all the vertices and the distances between vertices, then by <a href="https://en.wikipedia.org/wiki/Alexandrov%27s_uniqueness_theorem">Alexandrov’s uniqueness theorem</a> the shape of the polyhedron will be determined. Since we’re using Alexandrov, we should also consider a <a href="https://en.wikipedia.org/wiki/Dihedron">dihedron</a> (two mirror-image convex faces glued at their edges) to be a special case of a polyhedron. This leaves, as the only cases:</p>

<ul>
  <li>
    <p>A triangular dihedron based on a right or acute triangle.</p>
  </li>
  <li>
    <p>A rectangular dihedron.</p>
  </li>
  <li>
    <p>A tetrahedron with angular defect exactly  at each vertex.</p>
  </li>
</ul>

<p style="text-align: center;"><img alt="Convex unfoldings of dihedra and a disphenoid" src="https://11011110.github.io/blog/assets/2020/convex-unfoldings.svg"/></p>

<p>The unfoldings of the dihedra have two copies of their face, mirrored across a joining edge. The tetrahedra with all-convex unfoldings are exactly the <a href="https://en.wikipedia.org/wiki/Disphenoid">disphenoids</a>, the tetrahedra whose four faces are congruent. They unfold either to a copy of the same face shape,
expanded by a factor of two in each dimension and creased into four copies along its <a href="https://en.wikipedia.org/wiki/Medial_triangle">medial triangle</a>, or a parallelogram, creased to form a strip of four congruent triangles. Their unfoldings were discussed by Jin Akiyama in his paper “Tile-makers and semi-tile-makers” (<em>American Mathematical Monthly</em> 2007, <a href="https://doi.org/10.1080/00029890.2007.11920450">doi:10.1080/00029890.2007.11920450</a>, <a href="https://www.jstor.org/stable/27642275">jstor:27642275</a>), as part of a broader investigation of polyhedra whose every unfolding tiles the plane.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104601177683049272">Discuss on Mastodon</a>)</p></div>
    </content>
    <updated>2020-07-29T22:18:00Z</updated>
    <published>2020-07-29T22:18:00Z</published>
    <author>
      <name>David Eppstein</name>
    </author>
    <source>
      <id>https://11011110.github.io/blog/feed.xml</id>
      <author>
        <name>David Eppstein</name>
      </author>
      <link href="https://11011110.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/>
      <link href="https://11011110.github.io/blog/" rel="alternate" type="text/html"/>
      <subtitle>Geometry, graphs, algorithms, and more</subtitle>
      <title>11011110</title>
      <updated>2020-08-03T07:36:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/07/29/junior-fellowship-andvanced-fellowship-at-eth-institute-for-theoretical-studies-in-zurich-apply-by-september-23-2020/</id>
    <link href="https://cstheory-jobs.org/2020/07/29/junior-fellowship-andvanced-fellowship-at-eth-institute-for-theoretical-studies-in-zurich-apply-by-september-23-2020/" rel="alternate" type="text/html"/>
    <title>Junior Fellowship / Andvanced Fellowship at ETH Institute for Theoretical Studies in Zurich (apply by September 23, 2020)</title>
    <summary>Junior and Advanced Fellows of the ETH Institute for Theoretical Studies are independent postdocs of exceptional talent and promise, having achieved significant results in mathematics, theoretical computer science or the theoretical natural sciences. Junior Fellows stay at the Institute for up to three years, Advanced Fellows up to five years. Website: https://eth-its.ethz.ch/fellows/nomination-of-junior-fellows1.html Email: nominations@eth-its.ethz.ch</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Junior and Advanced Fellows of the ETH Institute for Theoretical Studies are independent postdocs of exceptional talent and promise, having achieved significant results in mathematics, theoretical computer science or the theoretical natural sciences. Junior Fellows stay at the Institute for up to three years, Advanced Fellows up to five years.</p>
<p>Website: <a href="https://eth-its.ethz.ch/fellows/nomination-of-junior-fellows1.html">https://eth-its.ethz.ch/fellows/nomination-of-junior-fellows1.html</a><br/>
Email: nominations@eth-its.ethz.ch</p></div>
    </content>
    <updated>2020-07-29T14:52:31Z</updated>
    <published>2020-07-29T14:52:31Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-08-04T01:54:21Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/114</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/114" rel="alternate" type="text/html"/>
    <title>TR20-114 |  Disjointness through the Lens of Vapnik–Chervonenkis Dimension: Sparsity and Beyond | 

	Anup Bhattacharya, 

	Sourav Chakraborty, 

	Arijit Ghosh, 

	Gopinath Mishra, 

	Manaswi Paraashar</title>
    <summary>The disjointness problem - where Alice and Bob are given two subsets of $\{1, \dots, n\}$ and they have to check if their sets intersect - is a central problem in the world of communication complexity. While both deterministic and randomized communication complexities for this problem are known to be $\Theta(n)$, it is also known that if the sets are assumed to be drawn from some restricted set systems then the communication complexity can be much lower. In this work, we explore how communication complexity measures change with respect to the complexity of the underlying set system. The complexity measure for the set system that we use in this work is the Vapnik–Chervonenkis (VC) dimension. More precisely, on any set system with VC dimension bounded by $d$, we analyze how large can the deterministic and randomized communication complexities be, as a function of $d$ and $n$.  The $d$-sparse set disjointness problem, where the sets have size at most $d$, is one such set system with VC dimension $d$. The deterministic and the randomized communication complexities of the $d$-sparse set disjointness problem have been well studied and is known to be $\Theta \left( d \log \left({n}/{d}\right)\right)$ and $\Theta(d)$, respectively, in the multi-round communication setting. In this paper, we address the question of whether the randomized communication complexity is always upper bounded by a function of the VC dimension of the set system, and does there always exist a gap between the deterministic and randomized communication complexity for set systems with small VC dimension. 

In this paper, we construct two natural set systems of VC dimension $d$, motivated from geometry. Using these set systems we show that the deterministic and randomized communication complexity can be $\widetilde{\Theta}\left(d\log \left( n/d \right)\right)$ for set systems of VC dimension $d$ and this matches the deterministic upper bound for all set systems of VC dimension $d$. We also study the deterministic and randomized communication complexities of the set intersection problem when sets belong to a set system of bounded VC dimension. We show that there exists set systems of VC dimension $d$ such that both deterministic and randomized (one-way and multi-round) complexities for the set intersection problem can be as high as $\Theta\left( d\log \left( n/d \right) \right)$, and this is tight among all set systems of VC dimension $d$.</summary>
    <updated>2020-07-29T14:15:30Z</updated>
    <published>2020-07-29T14:15:30Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-04T01:54:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/113</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/113" rel="alternate" type="text/html"/>
    <title>TR20-113 |  Relaxed Locally Correctable Codes with Nearly-Linear Block Length and Constant Query Complexity | 

	Tom Gur, 

	Igor Shinkar, 

	Alessandro Chiesa</title>
    <summary>Locally correctable codes (LCCs) are error correcting codes C : \Sigma^k \to \Sigma^n which admit local algorithms that correct any individual symbol of a corrupted codeword via a minuscule number of queries. This notion is stronger than that of locally decodable codes (LDCs), where the goal is to only recover individual symbols of the message. One of the central problems in algorithmic coding theory is to construct O(1)-query LCCs and LDCs with minimal block length. Alas, state-of-the-art of such codes requires super-polynomial block length to admit O(1)-query algorithms for local correction and decoding, despite much attention during the last two decades.

This lack of progress prompted the study of relaxed LCCs and LDCs, which allow the correction algorithm to abort (but not err) on a small fraction of the locations. This relaxation turned out to allow constant-query correcting and decoding algorithms for codes with polynomial block length. Focusing on local correction, Gur, Ramnarayan, and Rothblum (ITCS~2018) showed that there exist O(1)-query relaxed LCCs that achieve nearly-quartic block length n = k^{4+\alpha}, for an arbitrarily small constant \alpha&gt;0.

We construct an O(1)-query relaxed LCC with nearly-linear block length n = k^{1+\alpha}, for an arbitrarily small constant \alpha&gt;0. This significantly narrows the gap between the lower bound which states that there are no O(1)-query relaxed LCCs with block length n = k^{1+o(1)}. In particular, our construction matches the parameters achieved by Ben-Sasson et al. (SIAM J. Comput. 2006), who constructed relaxed LDCs with the same parameters. This resolves an open problem raised by Gur, Ramnarayan, and Rothblum (ITCS 2018).</summary>
    <updated>2020-07-27T20:27:01Z</updated>
    <published>2020-07-27T20:27:01Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-04T01:54:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/112</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/112" rel="alternate" type="text/html"/>
    <title>TR20-112 |  Simulating DQBF Preprocessing Techniques with Resolution Asymmetric Tautologies | 

	Joshua Blinkhorn</title>
    <summary>Dependency quantified Boolean formulas (DQBF) describe an NEXPTIME-complete generalisation of QBF, which in turn generalises SAT. QRAT is a recently proposed proof system for quantified Boolean formulas (QBF), which simulates the full suite of QBF preprocessing techniques and thus forms a uniform proof checking format for solver verification.

In this work, we study QRAT in the more general DQBF context, obtaining a sound and complete refutational DQBF proof system that we call DQRAT. We show that DQRAT can simulate the full suite of dedicated DQBF preprocessing techniques, except those relying on defined variables, which we cover with the introduction of a new form of prefix modification. Our work enables generalisations of further QBF preprocessing techniques (e.g. blocked literal elimination) that were not previously considered for DQBF.</summary>
    <updated>2020-07-27T19:18:09Z</updated>
    <published>2020-07-27T19:18:09Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-08-04T01:54:08Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=17349</id>
    <link href="https://rjlipton.wordpress.com/2020/07/27/a-brilliant-book-on-combinatorics/" rel="alternate" type="text/html"/>
    <title>A Brilliant Book on Combinatorics</title>
    <summary>And Razborov’s brilliant proof method Stasys Jukna is the author of the book Extremal Combinatorics With Applications in Computer Science. Today we talk about Jukna’s book on extremal combinatorics. The structure of his book is great. The material is useful and well presented. Rather than add more general comments about his book, we thought we […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>
<font color="#0044cc"><br/>
<em>And Razborov’s brilliant proof method</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2020/07/jukna1.png"><img alt="" class="alignright size-full wp-image-17351" src="https://rjlipton.files.wordpress.com/2020/07/jukna1.png?w=600"/></a></p>
<p>
Stasys Jukna is the author of the <a href="https://www.google.com/books/edition/Extremal_Combinatorics/NV3Y8vjWo8kC?hl=en&amp;gbpv=1">book</a> <em>Extremal Combinatorics With Applications in Computer Science</em>. </p>
<p>
Today we talk about Jukna’s book on extremal combinatorics.</p>
<p><span id="more-17349"/></p>
<p>
The structure of his book is great. The material is useful and well presented. Rather than add more general comments about his book, we thought we might highlight one tiny part—the part on monotone circuit lower bounds. Here goes. All below is based directly on his discussion. Any errors or misguided comments are ours.</p>
<p>
</p><p/><h2> Monotone Boolean Functions </h2><p/>
<p/><p>
Fix an input size <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> and consider some property of subsets <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> of <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/>. Let <img alt="{f(S)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S)=1}"/> exactly when <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> has the property. We can think of <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> as a Boolean function. You believe that this property is hard to compute—how do you go about proving that? </p>
<p>
In general we have no tools, but if the property is monotone, then there are some powerful methods. Recall <em>monotone</em> means that if <img alt="{f(S)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S)=1}"/> then any set <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> so that <img alt="{S \subset T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS+%5Csubset+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S \subset T}"/> still has the property. For example, <img alt="{f(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S)}"/> could be that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> includes at least half of the elements of <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/>. It cannot be that <img alt="{S}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S}"/> has an even number of elements. Another example is when <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> is given in <em>disjunctive normal form</em> (DNF), </p>
<p align="center"><img alt="\displaystyle  f \equiv T_1 \vee T_2 \vee \cdots T_m, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f+%5Cequiv+T_1+%5Cvee+T_2+%5Cvee+%5Ccdots+T_m%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f \equiv T_1 \vee T_2 \vee \cdots T_m, "/></p>
<p>where each <b>term</b> <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> is a conjunction of variables. Each <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> can be regarded as a subset of <img alt="{[n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[n]}"/>. Then <img alt="{f(S) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S) = 1}"/> if and only if <img alt="{S \supseteq T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS+%5Csupseteq+T_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S \supseteq T_k}"/> for some <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>. Every monotone function also has a <em>conjunctive normal form</em> (CNF) </p>
<p align="center"><img alt="\displaystyle  f \equiv C_f = C_1 \wedge C_2 \wedge \cdots \wedge C_\ell, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f+%5Cequiv+C_f+%3D+C_1+%5Cwedge+C_2+%5Cwedge+%5Ccdots+%5Cwedge+C_%5Cell%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f \equiv C_f = C_1 \wedge C_2 \wedge \cdots \wedge C_\ell, "/></p>
<p>where each <b>clause</b> <img alt="{C_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_k}"/> is a disjunction of variables. Then <img alt="{f(S) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S) = 1}"/> if and only if <img alt="{S \cap C_k \neq \emptyset}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BS+%5Ccap+C_k+%5Cneq+%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{S \cap C_k \neq \emptyset}"/> for <em>all</em> <img alt="{k.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k.}"/> The problem is that the numbers <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> of terms and <img alt="{\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell}"/> of clauses involved may be huge. The clauses may have different sizes. Given a CNF <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> of maximum clause size <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/>, we write <img alt="{C^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^s}"/> for the conjunction of clauses of size exactly <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> and <img alt="{C^{&lt;s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5E%7B%3Cs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^{&lt;s}}"/> for the rest. We similarly write <img alt="{D^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^r}"/> and <img alt="{D^{&lt;r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5E%7B%3Cr%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^{&lt;r}}"/> for DNFs <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/>.</p>
<p>
The lower bound methods are on the size of a monotone circuit for <img alt="{f(S)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(S)}"/>. That is the circuit can only use gates <img alt="{AND}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BAND%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{AND}"/> and <img alt="{OR}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BOR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{OR}"/>, but no other types of gates, especially not <img alt="{NOT}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BNOT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{NOT}"/> gates. Of course, if <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> has no small monotone circuits, then it has no small DNF or CNF formulas either. </p>
<p>
The neat fact on which the lower-bound technique builds is that if <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> <b>does</b> have small monotone circuits, then we can “wrap” it between a CNF and a DNF in various customizable ways:</p>
<blockquote><p><b>Theorem 1 (informal)</b> <em><a name="informal"/> For every <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f}"/> with small monotone circuits and <img alt="{r,s &gt; 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%2Cs+%3E+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{r,s &gt; 0}"/> we can find a CNF <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C}"/> of maximum clause size <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{s}"/> and a DNF <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{D}"/> of maximum term size <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{r}"/> such that </em></p><em>
<p align="center"><img alt="\displaystyle  C \leq f \leq D \qquad\text{and also}\qquad D^{&lt;r} \leq C^{&lt;s}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cleq+f+%5Cleq+D+%5Cqquad%5Ctext%7Band+also%7D%5Cqquad+D%5E%7B%3Cr%7D+%5Cleq+C%5E%7B%3Cs%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="\displaystyle  C \leq f \leq D \qquad\text{and also}\qquad D^{&lt;r} \leq C^{&lt;s}. "/></p>
</em><p><em>Moreover, <img alt="{C^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C^s}"/> and <img alt="{D^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5Er%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{D^r}"/> are small. </em>
</p></blockquote>
<p/><p>
We have said “wrap” not “sandwich” because although <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> is the “upper slice,” the part of <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> with smaller terms—but there could be many of them—wraps around to be under the corresponding part of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. This fact will enable us to throw away the smaller clauses and terms. How small is “small”? We will say later. We are trying to solve problems of exposition by keeping a high-level view at the start. </p>
<p>
</p><p/><h2> Exposition Problems </h2><p/>
<p/><p>
Tim Gowers has written an <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.587.8986&amp;rep=rep1&amp;type=pdf">article</a> about the lower method for monotone functions. The method is due to Alexander Razborov in his seminal 1985 <a href="http://people.cs.uchicago.edu/~razborov/files/clique.pdf">paper</a> and extended by Noga Alon and Ravi Boppana in their <a href="https://core.ac.uk/download/pdf/191378189.pdf">paper</a> right afterward, and by Benjamin Rossman in his 2009 <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.156.5526&amp;rep=rep1&amp;type=pdf">paper</a>, to name a few. </p>
<p>
Gowers says right away that the original papers on this method are clear and well written. But he believes that there is need for more exposition. The method is so important that it must be made easy for all to understand. He says his article is an attempt to solve an <i>open exposition problem</i>. The notion of an exposition problem is due to Timothy Chow who <a href="https://arxiv.org/pdf/0712.1320.pdf">wrote</a>:</p>
<blockquote><p><b> </b> <em> All mathematicians are familiar with the concept of an open research problem. I propose the less familiar concept of an open exposition problem. </em>
</p></blockquote>
<p/><p>
Chow raised this issue with respect to the forcing method in set theory due to Paul Cohen. A modest suggestion: Read Chow on forcing, a great exposition; read Gowers on the monotone lower bound method, another great one. Both are much better than anything we can do. But we will put our own spin on the lower bound method. And hope to add to the quest to solve the exposition problem. </p>
<p/><h2> The Method—High Level </h2><p/>
<p/><p>
Suppose that <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> is a monotone boolean circuit that has <img alt="{n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n}"/> inputs and computes <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/> at the last gate. The method is called the <i>approximation method</i> because the idea is that it builds two other boolean functions <img alt="{\mathsf{lower}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Blower%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{lower}}"/> and <img alt="{\mathsf{upper}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bupper%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{upper}}"/>: for all <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/> in <img alt="{\{0,1\}^{n}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\{0,1\}^{n}}"/>: </p>
<p align="center"><img alt="\displaystyle  \mathsf{lower}(x) \le f(x) \le \mathsf{upper}(x). " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7Blower%7D%28x%29+%5Cle+f%28x%29+%5Cle+%5Cmathsf%7Bupper%7D%28x%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \mathsf{lower}(x) \le f(x) \le \mathsf{upper}(x). "/></p>
<p>This follows a tradition in math that we often replace a complex function, <img alt="{f(x)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(x)}"/>, with simpler upper and lower bounds. Standard stuff. </p>
<p>
Usually the point is that the approximators are not only easier to understand but also simpler in some objective sense. For example, Christophe Chesneau and Yogesh Bagul give a nice short <a href="https://hal.archives-ouvertes.fr/hal-01934571/document">compendium</a> of approximating formulas involving trigonometric functions by formulas without them, including that for all <img alt="{0&lt;x&lt;1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%3Cx%3C1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0&lt;x&lt;1}"/>, </p>
<p align="center"><img alt="\displaystyle  \exp(-bx^{2}) &lt; \sin(x)/x &lt; \exp(-x^{2}/6), " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cexp%28-bx%5E%7B2%7D%29+%3C+%5Csin%28x%29%2Fx+%3C+%5Cexp%28-x%5E%7B2%7D%2F6%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \exp(-bx^{2}) &lt; \sin(x)/x &lt; \exp(-x^{2}/6), "/></p>
<p>with <img alt="{b \approx 0.172604}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bb+%5Capprox+0.172604%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{b \approx 0.172604}"/>. If you have to reason about the behavior of <img alt="{\sin(x)/x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Csin%28x%29%2Fx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\sin(x)/x}"/>, it is nice to have these upper and lower bounds. Note that the upper bound kind-of wraps around because it is the same kind of function as the lower bound.</p>
<p>
What gives the monotone method a special twist is that <img alt="{\mathsf{lower}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Blower%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{lower}}"/> and <img alt="{\mathsf{upper}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bupper%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\mathsf{upper}}"/> are not necessarily simple in the sense of being small.  Rather, they <em>make simple errors</em>—ones that can be corrected with small effort. The correction process yields <img alt="{C^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^s}"/> and <img alt="{D^r.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5Er.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^r.}"/>  Isolating what is small, however, requires us to trade an “AND” of two inequalities for an “OR” of two economical ones. We know that at least one of the latter inequalities must be true. We arrange that either one gives us the kind of lower bound we seek. </p>
<p>
</p><p/><h2> Some More Detail </h2><p/>
<p/><p>
Here is how the trade happens. From Theorem <a href="https://rjlipton.wordpress.com/feed/#informal">1</a> we have: </p>
<p align="center"><img alt="\displaystyle  C^s \wedge C^{&lt;s} \leq f \leq D^{&lt;r} \vee D^r, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C%5Es+%5Cwedge+C%5E%7B%3Cs%7D+%5Cleq+f+%5Cleq+D%5E%7B%3Cr%7D+%5Cvee+D%5Er%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C^s \wedge C^{&lt;s} \leq f \leq D^{&lt;r} \vee D^r, "/></p>
<p>where: <img alt="{C^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^s}"/> and <img alt="{D^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^r}"/> are small, and while <img alt="{C^{&lt;s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5E%7B%3Cs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^{&lt;s}}"/> and <img alt="{D^{&lt;r}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5E%7B%3Cr%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^{&lt;r}}"/> might be big, we have <img alt="{D^{&lt;r} \leq C^{&lt;s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5E%7B%3Cr%7D+%5Cleq+C%5E%7B%3Cs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^{&lt;r} \leq C^{&lt;s}}"/>. The trick is to ask:</p>
<blockquote><p><b> </b> <em> Is <img alt="{C^{&lt;s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5E%7B%3Cs%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C^{&lt;s}}"/> empty—that is, is it the trivial <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{1}"/> function? </em>
</p></blockquote>
<p>
</p><ul>
<li>
If <em>yes</em>, then it goes away on the left-hand side. We get: <p/>
<p align="center"><img alt="\displaystyle  C^s \leq f. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C%5Es+%5Cleq+f.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  C^s \leq f. "/></p>
<p>Since <img alt="{C^s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^s}"/> is small, this is something we want. We got a small lower bound on <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> that holds for <b>all</b> arguments <img alt="{x}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x}"/>. </p>
</li><li>
If <em>no</em>, then it has a nontrivial clause corresponding to a set <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/> of size at most <img alt="{s-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s-1}"/>. This is where the wraparound comes in. We have: <p/>
<p align="center"><img alt="\displaystyle  D^{&lt;r} \leq C^{&lt;s} \leq E, " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%5E%7B%3Cr%7D+%5Cleq+C%5E%7B%3Cs%7D+%5Cleq+E%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  D^{&lt;r} \leq C^{&lt;s} \leq E, "/></p>
<p>since we chose at least one clause. Substituting on the right-hand side thus gives us: </p>
<p align="center"><img alt="\displaystyle  f \leq E \vee D^r. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f+%5Cleq+E+%5Cvee+D%5Er.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  f \leq E \vee D^r. "/></p>
<p>Now <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/> is small, since it is just one clause, and <img alt="{D^r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^r}"/> is small. We got a small upper bound rather than lower bound, but the fact that it has a restricted form and holds for <b>all</b> cases we can input to <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/> will give us a lower bound on <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/>.
</p></li></ul>
<p>
Finally we are ready to state the theorem, which quantifies “small.” To follow Jukna, we now need to replace “<img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/>” by “<img alt="{r+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r+1}"/>” and “<img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/>” by “<img alt="{s+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s+1}"/>.” But the essence is the same.</p>
<blockquote><p><b>Theorem 2</b> <em><a name="tsimple"/> If <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f}"/> has a monotone Boolean circuit of size <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{t}"/>, then for any <img alt="{r,s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%2Cs%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{r,s}"/> such that <img alt="{1 \leq r,s \leq n-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1+%5Cleq+r%2Cs+%5Cleq+n-1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{1 \leq r,s \leq n-1}"/>, we can build a conjunction <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C}"/> of at most <img alt="{t \cdot r^{s+1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%5Ccdot+r%5E%7Bs%2B1%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{t \cdot r^{s+1}}"/> clauses of size exactly <img alt="{s+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%2B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{s+1}"/>, a disjunction <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{D}"/> of at most <img alt="{t \cdot s^{r+1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%5Ccdot+s%5E%7Br%2B1%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{t \cdot s^{r+1}}"/> terms of size exactly <img alt="{r+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%2B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{r+1}"/>, and a set <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{E}"/> of size at most <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{s}"/> such that either <img alt="{C \leq f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%5Cleq+f%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{C \leq f}"/> or <img alt="{f \leq D \cup E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%5Cleq+D+%5Ccup+E%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{f \leq D \cup E}"/>. </em>
</p></blockquote>
<p/><p>
Rather than re-prove this, we will continue the discussion with a concrete example. An exposition trick is: give examples before the general case and then abstract. Our example will involve graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>—so the variables have the form <img alt="{x_{i,j}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%2Cj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i,j}}"/>, where <img alt="{x_{i,j} = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%2Cj%7D+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i,j} = 1}"/> means there is an edge between vertex <img alt="{i}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{i}"/> and vertex <img alt="{j}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{j}"/>, <img alt="{x_{i,j} = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%2Cj%7D+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{x_{i,j} = 0}"/> otherwise. Putting <img alt="{m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m}"/> as the number of vertices, the number of possible edges is <img alt="{n = \binom{m}{2}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+%5Cbinom%7Bm%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{n = \binom{m}{2}}"/>. We think of <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> as a set of edges, so <img alt="{G \subseteq [n]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG+%5Csubseteq+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G \subseteq [n]}"/>.</p>
<p>
</p><p/><h2> Checking for Triangles </h2><p/>
<p/><p>
Let <img alt="{f(G)=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28G%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(G)=1}"/> hold precisely when <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> has a triangle. This is clearly a monotone property. Our goal is to use the lower and upper bounds to prove that the monotone complexity of <img alt="{f(G)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(G)}"/> is almost of order <img alt="{m^{3}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%5E%7B3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m^{3}}"/>. A side note is that the general complexity is much less via <img alt="{m \times m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m \times m}"/> matrix products. </p>
<p>
The first beauty of using the method is that <em>you</em> get to choose the parameters <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> and <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> with a goal <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> in mind. The <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> and <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> must be in <img alt="{[1,n-1]}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5B1%2Cn-1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{[1,n-1]}"/>. The value of <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> will be a lower bound on the size of any monotone boolean circuit for <img alt="{f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f}"/>. The parameters <img alt="{r,s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%2Cs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r,s}"/> are bounds on the clause and term size of the DNF and the CNF. You can select them any way you wish. But of course choose them wisely.</p>
<p>
In this case we know that <img alt="{r=1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r=1}"/> is a right choice. We will say what <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> is later but we will have <img alt="{s=(\log n)^{O(1)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%3D%28%5Clog+n%29%5E%7BO%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s=(\log n)^{O(1)}}"/>. Once you pick them, the CNF <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/> and DNF <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> (and small set <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/>, a set of <img alt="{O(\log n)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{O(\log n)}"/> edges in this case) are chosen for you. You have no control over the sets <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> that make up the terms of <img alt="{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D}"/> and the sets <img alt="{C_\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_\ell}"/> that correspond to the clauses of <img alt="{C}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C}"/>. Well you do know something about them. Here is what you do know about how many sets there are and how big the sets are:</p>
<ol>
<li>
For <img alt="{k=1,\dots,t \cdot s^{r+1} = ts^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%3D1%2C%5Cdots%2Ct+%5Ccdot+s%5E%7Br%2B1%7D+%3D+ts%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k=1,\dots,t \cdot s^{r+1} = ts^2}"/>, each <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> is of size <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>. <p/>
</li><li>
For <img alt="{\ell=1,\dots, t \cdot r^{s+1} = t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cell%3D1%2C%5Cdots%2C+t+%5Ccdot+r%5E%7Bs%2B1%7D+%3D+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\ell=1,\dots, t \cdot r^{s+1} = t}"/>, each <img alt="{C_\ell}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_\ell}"/> is of size <img alt="{s+1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s+1}"/>.
</li></ol>
<p>The goal in either case is to force <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> to be large. We’ve numbered the right-hand case first.</p>
<ol>
<li>
Case <img alt="{f \leq D \cup E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf+%5Cleq+D+%5Ccup+E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f \leq D \cup E}"/>. Here we want to consider graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> that <b>do</b> have a triangle—and nothing else. Because <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/> includes at most <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> edges, hence touches at most <img alt="{2s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2s}"/> vertices, and <img alt="{2s \ll m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2s+%5Cll+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2s \ll m}"/>, we can focus on triangles among the <img alt="{m' = m - 2s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bm%27+%3D+m+-+2s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{m' = m - 2s}"/> untouched vertices. There are <img alt="{T = \binom{m'}{3} = \Theta(m^3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT+%3D+%5Cbinom%7Bm%27%7D%7B3%7D+%3D+%5CTheta%28m%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T = \binom{m'}{3} = \Theta(m^3)}"/> such triangles, hence <img alt="{T}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T}"/> graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> to consider.<p/>
<p>
Since these graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> have no edges in <img alt="{E}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{E}"/> but make <img alt="{f(G) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28G%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(G) = 1}"/>, there must be some <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/> such that <img alt="{T_k(G) = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%28G%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k(G) = 1}"/>. Since <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> has size <img alt="{2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2}"/>, this means <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{T_k}"/> has two edges of the triangle. Now the point is:</p>
<blockquote><p><b> </b> <em> For each <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T_k}"/>, there is at most <b>one</b> triangle that <img alt="{T_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" title="{T_k}"/> can be two edges of. </em>
</p></blockquote>
<p/><p>
Hence there must be at least as many terms as possible triangles. This means: </p>
<p align="center"><img alt="\displaystyle  ts^2 \geq \binom{m'}{3}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++ts%5E2+%5Cgeq+%5Cbinom%7Bm%27%7D%7B3%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  ts^2 \geq \binom{m'}{3}. "/></p>
<p>Because <img alt="{s = (\log n)^{O(1)}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs+%3D+%28%5Clog+n%29%5E%7BO%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s = (\log n)^{O(1)}}"/>, we finally get <img alt="{t = \tilde{\Omega}(m^3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%3D+%5Ctilde%7B%5COmega%7D%28m%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t = \tilde{\Omega}(m^3)}"/>, where the tilde means to ignore factors of <img alt="{\log n}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\log n}"/>.</p>
<p/></li><li>
Case <img alt="{C \leq f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%5Cleq+f%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C \leq f}"/>. Here we want to consider graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> such that <img alt="{f(G) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bf%28G%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{f(G) = 0}"/> but <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> is chock full of as many edges as one can have without creating a triangle. Such <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> include complete bipartite graphs. There are <img alt="{2^{m-1} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bm-1%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{m-1} - 1}"/> such graph inputs, as can be realized from how any binary string <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> except <img alt="{0^m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%5Em%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0^m}"/> and <img alt="{1^m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%5Em%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1^m}"/> encodes such a graph—and only its bit-complement <img alt="{w'}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w'}"/> encodes the same labeled graph.<p/>
<p>
In order to keep <img alt="{C \leq f}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC+%5Cleq+f%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C \leq f}"/> we need <img alt="{C(G) = 0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%28G%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C(G) = 0}"/> for all such <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>, so we need (at least) one clause <img alt="{C_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_k}"/> to <em>fail</em> on <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/>. This means that all vertices touched by the edges in <img alt="{C_k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C_k}"/> must be in the same partition. The more vertices touched, the fewer strings <img alt="{w}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{w}"/> have all <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>s (or all <img alt="{1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{1}"/>s) in the corresponding positions, which means the fewer graphs <img alt="{G}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{G}"/> “covered” by that clause. We want to know how many clauses we need to cover all these graphs, hence we try to minimize the number of vertices touched by each clause. That number is at least <img alt="{s' = \lceil \sqrt{2s}\rceil}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%27+%3D+%5Clceil+%5Csqrt%7B2s%7D%5Crceil%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s' = \lceil \sqrt{2s}\rceil}"/>. The number of graphs we cover is at most <img alt="{2^{m - s'} - 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bm+-+s%27%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{2^{m - s'} - 1}"/> (the <img alt="{-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{-1}"/> excludes the empty graph). Thus the number <img alt="{t}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t}"/> of clauses we need satisfies </p>
<p align="center"><img alt="\displaystyle  t \geq \frac{2^{m-1} - 1}{2^{m - s'} - 1} \geq 2^{s' - 1}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++t+%5Cgeq+%5Cfrac%7B2%5E%7Bm-1%7D+-+1%7D%7B2%5E%7Bm+-+s%27%7D+-+1%7D+%5Cgeq+2%5E%7Bs%27+-+1%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  t \geq \frac{2^{m-1} - 1}{2^{m - s'} - 1} \geq 2^{s' - 1}. "/></p>
<p>By taking <img alt="{s' &gt; 4.5\log^2 m}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%27+%3E+4.5%5Clog%5E2+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s' &gt; 4.5\log^2 m}"/> we can make <img alt="{t \geq m^3}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%5Cgeq+m%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t \geq m^3}"/> in this case. We can actually get bigger functions with bigger <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/>, but this balances against case 1 where <img alt="{t = \tilde{\Omega}(m^3)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bt+%3D+%5Ctilde%7B%5COmega%7D%28m%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{t = \tilde{\Omega}(m^3)}"/> was the best we could do, so that is our lower bound.
</p></li></ol>
<p>
</p><p/><h2> Open Problems </h2><p/>
<p/><p>
Does this help in understanding the approximation method? Can you work out the concretely optimum choice of <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> in the triangle example?</p>
<p>
Would you prefer not changing <img alt="{r}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r}"/> and <img alt="{s}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{s}"/> in the statement of Theorem <a href="https://rjlipton.wordpress.com/feed/#tsimple">2</a>? Then we would have worded the triangle example with “<img alt="{r = 2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%3D+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r = 2}"/>” rather than “<img alt="{r = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Br+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{r = 1}"/>.” The former is a little more suggestive of the idea of having two edges of a triangle. Doing so, however, could make notation in the proof of Theorem <a href="https://rjlipton.wordpress.com/feed/#tsimple">2</a> somewhat messier. Another possibility was keeping Jukna’s usage throughout, so that the earlier version <a href="https://rjlipton.wordpress.com/feed/#informal">1</a> of the theorem would say <img alt="{D^{\leq r} \leq C^{\leq s}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5E%7B%5Cleq+r%7D+%5Cleq+C%5E%7B%5Cleq+s%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^{\leq r} \leq C^{\leq s}}"/> with <img alt="{C^{s+1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BC%5E%7Bs%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{C^{s+1}}"/> and <img alt="{D^{r+1}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7BD%5E%7Br%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{D^{r+1}}"/> being small. We try to solve “exposition problems” in every post but feel a dilemma here. Comments might help us on a followup post. </p>
<p/></font></font></div>
    </content>
    <updated>2020-07-27T06:39:13Z</updated>
    <published>2020-07-27T06:39:13Z</published>
    <category term="All Posts"/>
    <category term="History"/>
    <category term="Ideas"/>
    <category term="Proofs"/>
    <category term="Alexander Razborov"/>
    <category term="approximation"/>
    <category term="Boolean functions"/>
    <category term="circuits"/>
    <category term="complexity"/>
    <category term="exposition problems"/>
    <category term="lower bounds"/>
    <category term="monotone"/>
    <category term="Stasys Jukna"/>
    <author>
      <name>RJLipton+KWRegan</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-08-04T01:54:18Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-3389282706697250678</id>
    <link href="https://blog.computationalcomplexity.org/feeds/3389282706697250678/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/do-computers-make-us-more-safe-or-less.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3389282706697250678" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/3389282706697250678" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/07/do-computers-make-us-more-safe-or-less.html" rel="alternate" type="text/html"/>
    <title>Do computers make us more safe or less safe?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Norbert Weiner wrote a paper <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/moral.pdf">Some Moral and Technical Consequences of Automation</a> in 1960. It warns of the dangers of computers in two ways:<br/>
<br/>
1) If a chess program is only trained against expert chess players then it might get confused if its opponent makes a bad move. This is not dangerous. But imagine a nuclear missle system that assumes the opponent is rational. If the opponent is not rational then it might launch and have an accidental nuclear war. So <i>there must be a human component </i>so that this won't happen.<br/>
<br/>
I offer a story and a counter narrative. In the 5th season, 23rd episode of the TV show Castle,<br/>
title <i>The Human Factor </i>a character had the following story to tell:<br/>
<i><br/>
The drone on its own was going to bomb a car. But the human noticed that there were red roses on the car, so it was a wedding couple, not a terrorist. If a human had not been involved the drone may have killed an innocent just married couple!</i><br/>
<br/>
This scene bothered me. It could EASILY be the other way around: the human wants to bomb and the drone (which has better vision) notices the roses. Or there may be many other ways that a computer could be BETTER than a human. I am not saying that a completely automated system is better, I am saying that its not obvious which way to go.  Both in some combination? What combination? Who has the final say? And in the drone scenario there may not be time for a human to consider the options.<br/>
<br/>
2) The Sorcerer's apprentice scenario. In The Sorcerer's Apprentice segment of the (original) movie Fantasia, Mickey mouse tells a broom to get him a glass of water. The broom keeps bringing him water and Mickey almost drowns. Computers may take orders to literally and not stop. I wonder if  automated stock-trading and automated auctions may have this problem. Is there a case known where this really did cause a problem?<div><br/></div><div>So what do you think?</div><div><br/></div><div>NOW- do computers (or, more generally technology) make us more safe or less safe?</div><div><br/></div><div>FUTURE- same question.</div></div>
    </content>
    <updated>2020-07-27T03:18:00Z</updated>
    <published>2020-07-27T03:18:00Z</published>
    <author>
      <name>GASARCH</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/03615736448441925334</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-08-03T13:13:37Z</updated>
    </source>
  </entry>
</feed>
