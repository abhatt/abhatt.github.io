<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-04-27T13:21:56Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/060</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/060" rel="alternate" type="text/html"/>
    <title>TR20-060 |  Leakage-Resilient Extractors and Secret-Sharing against Bounded Collusion Protocols | 

	Eshan Chattopadhyay, 

	Xin Li, 

	Vipul Goyal, 

	Jesse Goodman</title>
    <summary>In a recent work, Kumar, Meka, and Sahai (FOCS 2019) introduced the notion of bounded collusion protocols (BCPs), in which $N$ parties wish to compute some joint function $f:(\{0,1\}^n)^N\to\{0,1\}$ using a public blackboard, but such that only $p$ parties may collude at a time. This generalizes well studied models in multiparty communication complexity, such as the number-in-hand (NIH) and number-on-forehead (NOF) models, which are just endpoints on this rich spectrum. We construct explicit hard functions against this spectrum, and achieve a tradeoff between collusion and complexity. Using this, we obtain improved leakage-resilient secret sharing schemes against bounded collusion protocols. 

Our main tool in obtaining hard functions against BCPs are explicit constructions of leakage resilient extractors against BCPs for a wide range of parameters. Kumar et al. (FOCS 2019) studied  such extractors and called them cylinder intersection extractors. In fact, such extractors directly yield correlation bounds against BCPs. We focus on the following setting: the input to the extractor consists of $N$ independent sources of length $n$, and the leakage function Leak $:(\{0,1\}^n)^N\to\{0,1\}^\mu\in\mathcal{F}$ is a BCP with some collusion bound $p$ and leakage (output length) $\mu$. While our extractor constructions are very general, we highlight some interesting parameter settings:

1. In the case when the input sources are uniform, and $p=0.99N$ parties collude, our extractor can handle $n^{\Omega(1)}$ bits of leakage, regardless of the dependence between $N,n$. The best NOF lower bound (i.e., $p=N-1$) on the other hand requires $N&lt;\log n$ even to handle $1$ bit of leakage.

2. Next, we show that for the same setting as above, we can drop the entropy requirement to $k=$ polylog $n$, while still handling polynomial leakage for $p=0.99N$.  This resolves an open question about cylinder intersection extractors raised by Kumar et al. (FOCS 2019), and we find an application of such low entropy extractors in a new type of secret sharing.

We also provide an explicit compiler that transforms any function with high NOF (distributional) communication complexity into a leakage-resilient extractor that can handle polylogarithmic entropy and substantially more leakage against BCPs. Thus any improvement of NOF lower bounds will immediately yield better leakage-resilient extractors.

Using our extractors against BCPs, we obtain improved $N$-out-of-$N$ leakage-resilient secret sharing schemes. The previous best scheme from Kumar et al. (FOCS 2019) required share size to grow exponentially in the collusion bound, and thus cannot efficiently handle $p=\omega(\log N)$. Our schemes have no dependence of this form, and can thus handle collusion size $p=0.99N$.</summary>
    <updated>2020-04-27T06:12:53Z</updated>
    <published>2020-04-27T06:12:53Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-27T13:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/059</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/059" rel="alternate" type="text/html"/>
    <title>TR20-059 |  Pr-ZSUBEXP is not contained in Pr-RP | 

	Gonen Krak, 

	Noam Parzanchevski, 

	Amnon Ta-Shma</title>
    <summary>We unconditionally prove there exists a promise problem in promise ZSUBEXP that cannot be solved in promise RP. 
The proof technique builds upon Kabanets' easy witness method [Kab01] as implemented by Impagliazzo et. al [IKW02], with a separate diagonalization carried out on each of the two alternatives in the win-win argument. We remark that even though the easy witness method is a key component in many celebrated results in derandomization, we are not aware of any previous unconditional separation like the one we show.

We remark that the result relativizes. We could not prove a similar result for total functions, nor for functions in ZTime(T(n)) for T(n) below a half-exponential function (i.e., T such that T(T(n)) &lt; 2^n).</summary>
    <updated>2020-04-27T05:27:15Z</updated>
    <published>2020-04-27T05:27:15Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-27T13:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/058</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/058" rel="alternate" type="text/html"/>
    <title>TR20-058 |  Interactive Proofs for Verifying Machine Learning | 

	Jonathan Shafer, 

	Amir Yehudayoff, 

	Shafi Goldwasser, 

	Guy Rothblum</title>
    <summary>We consider the following question: using a source of labeled data and interaction with an untrusted prover, what is the complexity of verifying that a given hypothesis is "approximately correct"? We study interactive proof systems for PAC verification, where a verifier that interacts with a prover is required to accept good hypotheses, and reject bad hypotheses. Both the verifier and the prover are efficient and have access to data samples from an unknown distribution. We are interested in cases where the verifier can use significantly less data than is required for (agnostic) PAC learning, or use a substantially cheaper data source (e.g., using only random samples for verification, even though learning requires membership queries). We believe that today, when data and data-driven algorithms are quickly gaining prominence, the question of verifying purported outcomes of data analyses is very well-motivated.
		
We show three main results. First, we prove that for a specific hypothesis class, verification is significantly cheaper than learning in terms of the number of random samples required, even if the verifier engages with the prover only in a single-round (NP-like) protocol. Moreover, for this class we prove that single-round verification is also significantly cheaper than testing closeness to the class. Second, for the broad class of Fourier-sparse boolean functions, we show a multi-round (IP-like) verification protocol, where the prover uses membership queries, and the verifier is able to assess the result while only using random samples. Third, we show that verification is not always more efficient. Namely, we show a class of functions where verification requires as many samples as learning does, up to a logarithmic factor.</summary>
    <updated>2020-04-27T01:42:43Z</updated>
    <published>2020-04-27T01:42:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-27T13:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16982</id>
    <link href="https://rjlipton.wordpress.com/2020/04/26/time-for-some-jokes/" rel="alternate" type="text/html"/>
    <title>Time For Some Jokes</title>
    <summary>Can we still smile? [ Hardy and Littlewood] John Littlewood lived through the 1918–1919 flu pandemic, yet he appears not to have remarked on it in print. Nor can we find mention of it by Godfrey Hardy in A Mathematician’s Apology—though Hardy did write about the ravages of WW I. Today, Ken and I thought […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Can we still smile?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/04/26/time-for-some-jokes/unknown-139/" rel="attachment wp-att-16991"><img alt="" class="alignright size-full wp-image-16991" src="https://rjlipton.files.wordpress.com/2020/04/unknown-2.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Hardy and Littlewood]</font></td>
</tr>
</tbody>
</table>
<p>
John Littlewood lived through the 1918–1919 flu pandemic, yet he appears not to have remarked on it in print. Nor can we find mention of it by Godfrey Hardy in <em>A Mathematician’s Apology</em>—though Hardy did write about the ravages of WW I.</p>
<p>
Today, Ken and I thought you might like some fun comments that are not about the current pandemic. </p>
<p>
This is not to say we are ignoring it. We are all fighting the virus in one way or another. Our hearts go out to those of you fighting it directly. We are all worried about ourselves and others. We are stuck at home, at least most of us. We are all in this terrible time together. We hope you all are safe and well. </p>
<p>
We thought we would list a few jokes and stories that you might enjoy. We wrote recently about one kind of mathematical <a href="https://rjlipton.wordpress.com/2020/02/28/reductions-and-jokes/">joke</a> that can be given various proportions of pure levity and mathematical content. Our friends Lance Fortnow and Bill Gasarch, plus commenters in their <a href="https://blog.computationalcomplexity.org/2006/06/funniest-computer-science-joke-ever.html">item</a>, collected some jokes on the computer science side.</p>
<p>
Littlewood’s notion of “mathematical joke” leaned more on mathematical content, though his <a href="https://en.wikipedia.org/wiki/A_Mathematician's_Miscellany">memoir</a> <em>A Mathematician’s Miscellany</em> includes many funny stories as well. At the end of his introduction to the book, he wrote:</p>
<blockquote><p><b> </b> <em> A good mathematical joke is better, and better mathematics, than a dozen mediocre papers. </em>
</p></blockquote>
<p/><p>
We will start at the levity end. This is almost a math <a href="http://web.sonoma.edu/Math/faculty/falbo/jokes.html">joke</a>:</p>
<blockquote><p><b> </b> <em> The Daily News published a story saying that one-half of the MP (Members of Parliament) were crooks.<br/>
The Government took great exception to that and demanded a retraction and an apology.<br/>
The newspaper responded the next day with an apology and reported that one-half of the MPs were not crooks. </em>
</p></blockquote>
<p/><p>
We like this one, even if it is not really a hardcore math one. It does rely on the fact that <img alt="{\frac{1}{2} + \frac{1}{2} = 1.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B1%7D%7B2%7D+%3D+1.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{1}{2} + \frac{1}{2} = 1.}"/></p>
<p>
</p><p/><h2> Jokes and More </h2><p/>
<p/><p>
The following are some examples that we hope you all like. They are from a variety of sources: </p>
<ul>
<li>
Jokes that mathematicians think are <a href="https://www.businessinsider.com/13-math-jokes-that-every-mathematician-finds-absolutely-hilarious-2013-5">funny</a>. <p/>
</li><li>
Some are from <a href="https://cstheory.stackexchange.com/questions/3111/funny-tcs-related-papers-etc">StackExchange</a>. <p/>
</li><li>
Others are from Andrej Cherkaev’s <a href="https://www.math.utah.edu/~cherk/mathjokes.html">page</a>.
</li></ul>
<p>We have lightly edited a few.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> “My age is two billion years old,” said Paul Erdös. The point is: </p>
<blockquote><p><b> </b> <em> When I was seventeen years old it was said the earth was two billion years old. Now they say it is four billion years old. So my age is about two billion years old. </em>
</p></blockquote>
<p/><p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> There was a statistician that drowned crossing a river <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/> It was 3 feet deep on average. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> An infinite number of mathematicians walk into a bar. The first one orders a beer. The second orders half a beer. The third orders a third of a beer. The bartender bellows, “Get the heck out of here, are you trying to ruin me?”</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> An chemist, a physicist, and a mathematician are stranded on an island when a can of food rolls ashore. The chemist and the physicist comes up with many ingenious ways to open the can. Then suddenly the mathematician gets a bright idea: “Assume we have a can opener <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/>” </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> A theorist decides she wants to learn more about practical problems. She sees a seminar with the title: “The Theory of Gears.” So she goes. The speaker stands up and begins, “The theory of gears with a finite number of teeth is well known <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/></p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The reason that every major university maintains a department of mathematics is that it is cheaper to do this than to institutionalize all those people.</p>
<p>
Regarding the last one, Littlewood did after all write in his book:</p>
<blockquote><p><b> </b> <em> Mathematics is a dangerous profession; an appreciable proportion of us go mad. </em>
</p></blockquote>
<p/><p>
This appears to have been a playful swipe at Hardy’s decision to leave Cambridge for Oxford. It was couched in a discussion of events that would seem to have had tiny probabilities before they happened. </p>
<p>
The last two we’ve picked out from the above sites verge into philosophy:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The cherry theorem: Question: What is a small, red, round thing that has a cherry pit inside? <br/>
Answer: A cherry.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> René Descartes went into his favorite bar and the bartender asked, “would you like your usual drink tonight, Monsieur Descartes?” Descartes replied “I think not.” Then he promptly ceased to exist.</p>
<p>
</p><p/><h2> Wrong Derivations, Right Results </h2><p/>
<p/><p>
Littlewood’s standards for a “mathematical joke” were higher than ours, but we will start by adapting an example from this MathOverflow <a href="https://mathoverflow.net/questions/38856/jokes-in-the-sense-of-littlewood-examples">discussion</a> of Littlewood-style jokes. Sometimes we can play a joke on ourselves by deriving a result we know is right but with an incorrect proof. Here is the example:</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <a href="https://www.reddit.com/r/math/comments/1bntfg/are_there_or_can_there_be_jokes_or_puns_in/">Casting out 6’s</a>. Suppose we want to simplify the fraction <img alt="{\frac{166}{664}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B166%7D%7B664%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{166}{664}}"/>. We can use the rule of casting out 6’s to get </p>
<p align="center"><img alt="\displaystyle  \frac{166}{664} = \frac{16}{64} = \frac{1}{4}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B166%7D%7B664%7D+%3D+%5Cfrac%7B16%7D%7B64%7D+%3D+%5Cfrac%7B1%7D%7B4%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{166}{664} = \frac{16}{64} = \frac{1}{4}. "/></p>
<p>
The rule works quite generally:</p>
<p align="center"><img alt="\displaystyle  \frac{1666}{6664} = \frac{16666}{66664} = \frac{166666}{666664} = \cdots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B1666%7D%7B6664%7D+%3D+%5Cfrac%7B16666%7D%7B66664%7D+%3D+%5Cfrac%7B166666%7D%7B666664%7D+%3D+%5Ccdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{1666}{6664} = \frac{16666}{66664} = \frac{166666}{666664} = \cdots "/></p>
<p/><p/>
<p align="center"><img alt="\displaystyle  \frac{26}{65} = \frac{266}{665} = \frac{2666}{6665} = \frac{26666}{66665} = \cdots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B26%7D%7B65%7D+%3D+%5Cfrac%7B266%7D%7B665%7D+%3D+%5Cfrac%7B2666%7D%7B6665%7D+%3D+%5Cfrac%7B26666%7D%7B66665%7D+%3D+%5Ccdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{26}{65} = \frac{266}{665} = \frac{2666}{6665} = \frac{26666}{66665} = \cdots "/></p>
<p>You can even turn the paper upside down and cast out the <img alt="{6}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{6}"/>‘s that you see then:</p>
<p/><p align="center"><img alt="\displaystyle  \frac{19}{95} = \frac{199}{995} = \frac{1999}{9995} = \frac{19999}{99995} = \cdots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B19%7D%7B95%7D+%3D+%5Cfrac%7B199%7D%7B995%7D+%3D+%5Cfrac%7B1999%7D%7B9995%7D+%3D+%5Cfrac%7B19999%7D%7B99995%7D+%3D+%5Ccdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{19}{95} = \frac{199}{995} = \frac{1999}{9995} = \frac{19999}{99995} = \cdots "/></p>
<p/><p/>
<p align="center"><img alt="\displaystyle  \frac{49}{98} = \frac{499}{998} = \frac{4999}{9998} = \frac{49999}{99998} = \cdots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B49%7D%7B98%7D+%3D+%5Cfrac%7B499%7D%7B998%7D+%3D+%5Cfrac%7B4999%7D%7B9998%7D+%3D+%5Cfrac%7B49999%7D%7B99998%7D+%3D+%5Ccdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{49}{98} = \frac{499}{998} = \frac{4999}{9998} = \frac{49999}{99998} = \cdots "/></p>
<p>
Note, this is a joke: The rule of course does not actually work all the time: 	</p>
<p align="center"><img alt="\displaystyle  \frac{56}{65} = \frac{5}{5} = 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B56%7D%7B65%7D+%3D+%5Cfrac%7B5%7D%7B5%7D+%3D+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{56}{65} = \frac{5}{5} = 1. "/></p>
<p/><p><br/>
We thought to try to come up with our own examples, or at least blend in other sources. It once struck me (Ken), on reading a column by Martin Gardner on difference equations, that they give a “convincing proof” of <img alt="{0^0 = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%5E0+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0^0 = 1}"/>. Consider the powers of a natural number <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>, say <img alt="{k = 5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k = 5}"/>. Take differences like so: </p>
<p align="center"><img alt="\displaystyle  \begin{array}{ccccccccccc} 1 &amp; &amp; 5 &amp; &amp; 25 &amp; &amp; 125 &amp; &amp; 625 &amp; &amp; \dots\\ &amp; 4 &amp; &amp; 20 &amp; &amp; 100 &amp; &amp; 500 &amp; &amp; \dots\\ &amp; &amp; 16 &amp; &amp; 80 &amp; &amp; 400 &amp; &amp; \dots &amp; &amp; \\ &amp; &amp; &amp; 64 &amp; &amp; 320 &amp; &amp; \dots &amp; &amp; &amp;\\ &amp; &amp; &amp; &amp; 256 &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \ddots &amp; &amp; &amp; \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Bccccccccccc%7D+1+%26+%26+5+%26+%26+25+%26+%26+125+%26+%26+625+%26+%26+%5Cdots%5C%5C+%26+4+%26+%26+20+%26+%26+100+%26+%26+500+%26+%26+%5Cdots%5C%5C+%26+%26+16+%26+%26+80+%26+%26+400+%26+%26+%5Cdots+%26+%26+%5C%5C+%26+%26+%26+64+%26+%26+320+%26+%26+%5Cdots+%26+%26+%26%5C%5C+%26+%26+%26+%26+256+%26+%26+%26+%26+%5C%5C+%26+%26+%26+%26+%26+%5Cddots+%26+%26+%26+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{ccccccccccc} 1 &amp; &amp; 5 &amp; &amp; 25 &amp; &amp; 125 &amp; &amp; 625 &amp; &amp; \dots\\ &amp; 4 &amp; &amp; 20 &amp; &amp; 100 &amp; &amp; 500 &amp; &amp; \dots\\ &amp; &amp; 16 &amp; &amp; 80 &amp; &amp; 400 &amp; &amp; \dots &amp; &amp; \\ &amp; &amp; &amp; 64 &amp; &amp; 320 &amp; &amp; \dots &amp; &amp; &amp;\\ &amp; &amp; &amp; &amp; 256 &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \ddots &amp; &amp; &amp; \end{array} "/></p>
<p>
The powers of <img alt="{k-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k-1}"/> always appear on the bottom diagonal. Thus we have: <img alt="{(k-1)^0 = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28k-1%29%5E0+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(k-1)^0 = 1}"/>, <img alt="{(k-1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28k-1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(k-1)}"/>, <img alt="{(k-1)^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28k-1%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(k-1)^2}"/>, and so on. Now do this for <img alt="{k = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k = 1}"/>:</p>
<p align="center"><img alt="\displaystyle \begin{array}{ccccccccccc} 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; \dots\\ &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots\\ &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots &amp; &amp; \\ &amp; &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots &amp; &amp; &amp;\\ &amp; &amp; &amp; &amp; 0 &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \ddots &amp; &amp; &amp; \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Bccccccccccc%7D+1+%26+%26+1+%26+%26+1+%26+%26+1+%26+%26+1+%26+%26+%5Cdots%5C%5C+%26+0+%26+%26+0+%26+%26+0+%26+%26+0+%26+%26+%5Cdots%5C%5C+%26+%26+0+%26+%26+0+%26+%26+0+%26+%26+%5Cdots+%26+%26+%5C%5C+%26+%26+%26+0+%26+%26+0+%26+%26+%5Cdots+%26+%26+%26%5C%5C+%26+%26+%26+%26+0+%26+%26+%26+%26+%5C%5C+%26+%26+%26+%26+%26+%5Cddots+%26+%26+%26+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \begin{array}{ccccccccccc} 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; \dots\\ &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots\\ &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots &amp; &amp; \\ &amp; &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots &amp; &amp; &amp;\\ &amp; &amp; &amp; &amp; 0 &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \ddots &amp; &amp; &amp; \end{array} "/></p>
<p>The diagonal now holds the powers of <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>. It thus follows that <img alt="{0^0 = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%5E0+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0^0 = 1}"/>.</p>
<p/><h2> Open Problems </h2><p/>
<p>What are your favorite mathematical jokes? Please send them to us. Be safe. Be well.</p>
<p><a href="https://rjlipton.wordpress.com/2020/04/26/time-for-some-jokes/sign-2/" rel="attachment wp-att-16987"><img alt="" class="aligncenter size-medium wp-image-16987" height="111" src="https://rjlipton.files.wordpress.com/2020/04/sign-1.png?w=300&amp;h=111" width="300"/></a></p>
<p>
[fixed equations in last main section]</p></font></font></div>
    </content>
    <updated>2020-04-27T00:37:51Z</updated>
    <published>2020-04-27T00:37:51Z</published>
    <category term="Oldies"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="jokes"/>
    <category term="math jokes"/>
    <category term="stories"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-04-27T13:20:44Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11862</id>
    <link href="http://arxiv.org/abs/2004.11862" rel="alternate" type="text/html"/>
    <title>Fr\'echet Distance for Uncertain Curves</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Buchin:Kevin.html">Kevin Buchin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fan:Chenglin.html">Chenglin Fan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/L=ouml=ffler:Maarten.html">Maarten Löffler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Popov:Aleksandr.html">Aleksandr Popov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raichel:Benjamin.html">Benjamin Raichel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roeloffzen:Marcel.html">Marcel Roeloffzen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11862">PDF</a><br/><b>Abstract: </b>In this paper we study a wide range of variants for computing the (discrete
and continuous) Fr\'echet distance between uncertain curves. We define an
uncertain curve as a sequence of uncertainty regions, where each region is a
disk, a line segment, or a set of points. A realisation of a curve is a
polyline connecting one point from each region. Given an uncertain curve and a
second (certain or uncertain) curve, we seek to compute the lower and upper
bound Fr\'echet distance, which are the minimum and maximum Fr\'echet distance
for any realisations of the curves.
</p>
<p>We prove that both the upper and lower bound problems are NP-hard for the
continuous Fr\'echet distance in several uncertainty models, and that the upper
bound problem remains hard for the discrete Fr\'echet distance. In contrast,
the lower bound (discrete and continuous) Fr\'echet distance can be computed in
polynomial time. Furthermore, we show that computing the expected discrete
Fr\'echet distance is #P-hard when the uncertainty regions are modelled as
point sets or line segments. The construction also extends to show #P-hardness
for computing the continuous Fr\'echet distance when regions are modelled as
point sets.
</p>
<p>On the positive side, we argue that in any constant dimension there is a
FPTAS for the lower bound problem when $\Delta / \delta$ is polynomially
bounded, where $\delta$ is the Fr\'echet distance and $\Delta$ bounds the
diameter of the regions. We then argue there is a near-linear-time
3-approximation for the decision problem when the regions are convex and
roughly $\delta$-separated. Finally, we also study the setting with
Sakoe--Chiba time bands, where we restrict the alignment between the two
curves, and give polynomial-time algorithms for upper bound and expected
discrete and continuous Fr\'echet distance for uncertainty regions modelled as
point sets.
</p></div>
    </summary>
    <updated>2020-04-27T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11860</id>
    <link href="http://arxiv.org/abs/2004.11860" rel="alternate" type="text/html"/>
    <title>Optimal group testing under real world restrictions</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gebhard:Oliver.html">Oliver Gebhard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hahn=Klimroth:Max.html">Max Hahn-Klimroth</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parczyk:Olaf.html">Olaf Parczyk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Penschuck:Manuel.html">Manuel Penschuck</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rolvien:Maurice.html">Maurice Rolvien</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11860">PDF</a><br/><b>Abstract: </b>In the group testing problem one aims to infer a small set of $k$ infected
individuals out of a large population of size $n$. At our disposal we have a
testing scheme which allows us to test a group of individuals, such that the
outcome of the test is positive, if and only if at least one infected
individual is part of the test. All tests are carried out in parallel. The
overall goal is to find a test design and an inference algorithm requiring as
few tests as possible, such that the infected individuals can be identified
with high probability. As most relevant during the outbreak of pandemic
diseases (Wang et al., 2011), our analysis focusses on the so-called sublinear
regime of group testing, where $k \sim n^\theta$. The optimal group testing
schemes require a test-size of $\sim n/k$ and each individual has to take part
in $\sim \log n$ tests (Coja-Oghlan et. al, 2019). In real world applications,
like testing many individuals in a short period of time during the outbreak of
epidemics, pooling in such a way is not possible due to dilution effects.
Evidence of those effects is known for important applications like HIV (Wein,
1996) or COVID-19 (Seifried and Ciesek, 2020). Our main contribution is the
analysis of a group testing model, where we restrict the individuals-per-test
to be finite. We present an easy to implement scheme to pool individuals into
tests under these natural restrictions coming with the efficient decoding
algorithm DD and present simulations which suggest that the decoding procedure
succeeds for moderate population sizes. Furthermore, we show that our pooling
scheme requires the fewest tests as possible under all pooling schemes.
Finally, we apply our methods to the finitely many tests-per-individuals
setting, where we provide a full understanding of the random regular
test-design in this model by building up on work of (Gandikota et al., 2016).
</p></div>
    </summary>
    <updated>2020-04-27T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11796</id>
    <link href="http://arxiv.org/abs/2004.11796" rel="alternate" type="text/html"/>
    <title>Optimal Streaming Approximations for all Boolean Max-2CSPs</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chou:Chi=Ning.html">Chi-Ning Chou</a>, Alexander Golonev, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Velusamy:Santhoshini.html">Santhoshini Velusamy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11796">PDF</a><br/><b>Abstract: </b>We prove tight upper and lower bounds on approximation ratios of all Boolean
Max-2CSP problems in the streaming model. Specifically, for every type of
Max-2CSP problem, we give an explicit constant $\alpha$, s.t. for any
$\epsilon&gt;0$ (i) there is an $(\alpha-\epsilon)$-streaming approximation using
space $O(\log{n})$; and (ii) any $(\alpha+\epsilon)$-streaming approximation
requires space $\Omega(\sqrt{n})$. This generalizes the celebrated work of
[Kapralov, Khanna, Sudan SODA 2015; Kapralov, Krachun STOC 2019], who showed
that the optimal approximation ratio for Max-CUT was $1/2$.
</p>
<p>Prior to this work, the problem of determining this ratio was open for all
other Max-2CSPs. Our results are quite surprising for some specific Max-2CSPs.
For the Max-DCUT problem, there was a gap between an upper bound of $1/2$ and a
lower bound of $2/5$ [Guruswami, Velingker, Velusamy APPROX 2017]. We show that
neither of these bounds is tight, and the optimal ratio for Max-DCUT is $4/9$.
We also establish that the tight approximation for Max-2SAT is $\sqrt{2}/2$,
and for Exact Max-2SAT it is $3/4$. As a byproduct, our result gives a
separation between space-efficient approximations for Max-2SAT and Exact
Max-2SAT. This is in sharp contrast to the setting of polynomial-time
algorithms with polynomial space, where the two problems are known to be
equally hard to approximate.
</p></div>
    </summary>
    <updated>2020-04-27T01:20:40Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11761</id>
    <link href="http://arxiv.org/abs/2004.11761" rel="alternate" type="text/html"/>
    <title>Incompressibility of H-free edge modification problems: Towards a dichotomy</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marx:D=aacute=niel.html">Dániel Marx</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sandeep:R=_B=.html">R. B. Sandeep</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11761">PDF</a><br/><b>Abstract: </b>Given a graph $G$ and an integer $k$, the $H$-free Edge Editing problem is to
find whether there exists at most $k$ pairs of vertices in $G$ such that
changing the adjacency of the pairs in $G$ results in a graph without any
induced copy of $H$. The existence of polynomial kernels for $H$-free Edge
Editing received significant attention in the parameterized complexity
literature. Nontrivial polynomial kernels are known to exist for some graphs
$H$ with at most 4 vertices, but starting from 5 vertices, polynomial kernels
are known only if $H$ is either complete or empty. This suggests the conjecture
that there is no other $H$ with at least 5 vertices were $H$-free Edge Editing
admits a polynomial kernel. Towards this goal, we obtain a set $\mathcal{H}$ of
nine 5-vertex graphs such that if for every $H\in\mathcal{H}$, $H$-free Edge
Editing is incompressible and the complexity assumption $NP \not\subseteq
coNP/poly$ holds, then $H$-free Edge Editing is incompressible for every graph
$H$ with at least five vertices that is neither complete nor empty. That is,
proving incompressibility for these nine graphs would give a complete
classification of the kernelization complexity of $H$-free Edge Editing for
every $H$ with at least 5 vertices.
</p>
<p>We obtain similar result also for $H$-free Edge Deletion. Here the picture is
more complicated due to the existence of another infinite family of graphs $H$
where the problem is trivial (graphs with exactly one edge). We obtain a larger
set $\mathcal{H}$ of nineteen graphs whose incompressibility would give a
complete classification of the kernelization complexity of $H$-free Edge
Deletion for every graph $H$ with at least 5 vertices. Analogous results follow
also for the $H$-free Edge Completion problem by simple complementation.
</p></div>
    </summary>
    <updated>2020-04-27T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11731</id>
    <link href="http://arxiv.org/abs/2004.11731" rel="alternate" type="text/html"/>
    <title>A 12/7-approximation algorithm for the discrete Bamboo Garden Trimming problem</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ee:Martijn_van.html">Martijn van Ee</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11731">PDF</a><br/><b>Abstract: </b>We study the discrete Bamboo Garden Trimming problem (BGT), where we are
given n bamboos with different growth rates. At the end of each day, one can
cut down one bamboo to height zero. The goal in BGT is to make a perpetual
schedule of cuts such that the height of the tallest bamboo ever is minimized.
Here, we improve the current best approximation guarantee by designing a
12/7-approximation algorithm. This result is based on a reduction to the
Pinwheel Scheduling problem. We show that a guarantee of 12/7 is essentially
the best we can hope for if our algorithm is based on this type of reduction.
</p></div>
    </summary>
    <updated>2020-04-27T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11666</id>
    <link href="http://arxiv.org/abs/2004.11666" rel="alternate" type="text/html"/>
    <title>Faster Parallel Multiterminal Cuts</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Henzinger:Monika.html">Monika Henzinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Noe:Alexander.html">Alexander Noe</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schulz:Christian.html">Christian Schulz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11666">PDF</a><br/><b>Abstract: </b>We give an improved branch-and-bound solver for the multiterminal cut
problem, based on the recent work of Henzinger et al.. We contribute new,
highly effective data reduction rules to transform the graph into a smaller
equivalent instance. In addition, we present a local search algorithm that can
significantly improve a given solution to the multiterminal cut problem. Our
exact algorithm is able to give exact solutions to more and harder problems
compared to the state-of-the-art algorithm by Henzinger et al.; and give better
solutions for more than two third of the problems that are too large to be
solved to optimality. Additionally, we give an inexact heuristic algorithm that
computes high-quality solutions for very hard instances in reasonable time.
</p></div>
    </summary>
    <updated>2020-04-27T01:23:04Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11642</id>
    <link href="http://arxiv.org/abs/2004.11642" rel="alternate" type="text/html"/>
    <title>Robust testing of low-dimensional functions</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/De:Anindya.html">Anindya De</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mossel:Elchanan.html">Elchanan Mossel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Neeman:Joe.html">Joe Neeman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11642">PDF</a><br/><b>Abstract: </b>A natural problem in high-dimensional inference is to decide if a classifier
$f:\mathbb{R}^n \rightarrow [-1,1]$ depends on a small number of linear
directions of its input data. Call a function $g: \mathbb{R}^n \rightarrow
[-1,1]$, a linear $k$-junta if it is completely determined by some
$k$-dimensional subspace of the input space. A recent work of the authors
showed that linear $k$-juntas are testable. Thus there exists an algorithm to
distinguish between:
</p>
<p>1. $f: \mathbb{R}^n \rightarrow \{-1,1\}$ which is a linear $k$-junta with
surface area $s$,
</p>
<p>2. $f$ is $\epsilon$-far from any linear $k$-junta, where the query
complexity of the algorithm is independent of the ambient dimension $n$.
</p>
<p>Following the surge of interest in noise-tolerant property testing, in this
paper we prove a noise-tolerant (or robust) version of this result. Namely, we
give an algorithm which given any $c&gt;0$, $\epsilon&gt;0$, distinguishes between
</p>
<p>1. $f: \mathbb{R}^n \rightarrow \{-1,1\}$ has correlation at least $c$ with
some linear $k$-junta with surface area $s$.
</p>
<p>2. $f$ has correlation at most $c-\epsilon$ with any linear $k$-junta.
</p>
<p>Our query complexity is qualitatively the same, i.e., remains independent of
$n$ and is polynomially dependent on $k$. A major motivation for studying
Linear Junta Testing come from statistical models where it is crucial to allow
noise. In the language of model compression, our results show statistical
models can be "compressed" in query complexity that depends only on the size of
the desired compression, when the compression is a linear Junta.
</p></div>
    </summary>
    <updated>2020-04-27T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11621</id>
    <link href="http://arxiv.org/abs/2004.11621" rel="alternate" type="text/html"/>
    <title>Computation of Hadwiger Number and Related Contraction Problems: Tight Lower Bounds</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fomin:Fedor_V=.html">Fedor V. Fomin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lokshtanov:Daniel.html">Daniel Lokshtanov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mihajlin:Ivan.html">Ivan Mihajlin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Saket.html">Saket Saurabh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zehavi:Meirav.html">Meirav Zehavi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11621">PDF</a><br/><b>Abstract: </b>We prove that the Hadwiger number of an $n$-vertex graph $G$ (the maximum
size of a clique minor in $G$) cannot be computed in time $n^{o(n)}$, unless
the Exponential Time Hypothesis (ETH) fails. This resolves a well-known open
question in the area of exact exponential algorithms. The technique developed
for resolving the Hadwiger number problem has a wider applicability. We use it
to rule out the existence of $n^{o(n)}$-time algorithms (up to ETH) for a large
class of computational problems concerning edge contractions in graphs.
</p></div>
    </summary>
    <updated>2020-04-27T01:28:17Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11606</id>
    <link href="http://arxiv.org/abs/2004.11606" rel="alternate" type="text/html"/>
    <title>Homological Scaffold via Minimal Homology Bases</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guerra:Marco.html">Marco Guerra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gregorio:Alessandro_De.html">Alessandro De Gregorio</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fugacci:Ulderico.html">Ulderico Fugacci</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Petri:Giovanni.html">Giovanni Petri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vaccarino:Francesco.html">Francesco Vaccarino</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11606">PDF</a><br/><b>Abstract: </b>The homological scaffold leverages persistent homology to construct a
topologically sound summary of a weighted network. However, its crucial
dependency on the choice of representative cycles hinders the ability to trace
back global features onto individual network components, unless one provides a
principled way to make such a choice. In this paper, we apply recent advances
in the computation of minimal homology bases to introduce a quasi-canonical
version of the scaffold, called minimal, and employ it to analyze data both
real and in silico. At the same time, we verify that, statistically, the
standard scaffold is a good proxy of the minimal one for sufficiently complex
networks.
</p></div>
    </summary>
    <updated>2020-04-27T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11582</id>
    <link href="http://arxiv.org/abs/2004.11582" rel="alternate" type="text/html"/>
    <title>Small circuits and dual weak PHP in the universal theory of p-time algorithms</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jan Krajicek <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11582">PDF</a><br/><b>Abstract: </b>We prove, under a computational complexity hypothesis, that it is consistent
with the true universal theory of p-time algorithms that a specific p-time
function extending $n$ bits to $m \geq n^2$ bits violates the dual weak
pigeonhole principle: every string $y$ of length $m$ equals to the value of the
function for some $x$ of length $n$. The function is the truth-table function
assigning to a circuit the table of the function it computes and the hypothesis
is that every language in P has circuits of a fixed polynomial size $n^d$.
</p></div>
    </summary>
    <updated>2020-04-27T01:20:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11568</id>
    <link href="http://arxiv.org/abs/2004.11568" rel="alternate" type="text/html"/>
    <title>Efficient Algorithms for Approximating Quantum Partition Functions</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mann:Ryan_L=.html">Ryan L. Mann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Helmuth:Tyler.html">Tyler Helmuth</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11568">PDF</a><br/><b>Abstract: </b>We establish a polynomial-time approximation algorithm for partition
functions of quantum spin models at high temperature. Our algorithm is based on
the quantum cluster expansion of Neto\v{c}n\`y and Redig and the cluster
expansion approach to designing algorithms due to Helmuth, Perkins, and Regts.
Similar results have previously been obtained by related methods, and our main
contribution is a simple and slightly sharper analysis for the case of pairwise
interactions on bounded-degree graphs.
</p></div>
    </summary>
    <updated>2020-04-27T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11540</id>
    <link href="http://arxiv.org/abs/2004.11540" rel="alternate" type="text/html"/>
    <title>Deep Global Registration</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Choy:Christopher.html">Christopher Choy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dong:Wei.html">Wei Dong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koltun:Vladlen.html">Vladlen Koltun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11540">PDF</a><br/><b>Abstract: </b>We present Deep Global Registration, a differentiable framework for pairwise
registration of real-world 3D scans. Deep global registration is based on three
modules: a 6-dimensional convolutional network for correspondence confidence
prediction, a differentiable Weighted Procrustes algorithm for closed-form pose
estimation, and a robust gradient-based SE(3) optimizer for pose refinement.
Experiments demonstrate that our approach outperforms state-of-the-art methods,
both learning-based and classical, on real-world data.
</p></div>
    </summary>
    <updated>2020-04-27T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11445</id>
    <link href="http://arxiv.org/abs/2004.11445" rel="alternate" type="text/html"/>
    <title>Directed Girth</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dalirrooyfard:Mina.html">Mina Dalirrooyfard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Williams:Virginia_Vassilevska.html">Virginia Vassilevska Williams</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11445">PDF</a><br/><b>Abstract: </b>It is known that a better than $2$-approximation algorithm for the girth in
dense directed unweighted graphs needs $n^{3-o(1)}$ time unless one uses fast
matrix multiplication. Meanwhile, the best known approximation factor for a
combinatorial algorithm running in $O(mn^{1-\epsilon})$ time (by Chechik et
al.) is $3$. Is the true answer $2$ or $3$?
</p>
<p>The main result of this paper is a (conditionally) tight approximation
algorithm for directed graphs. First, we show that under a popular hardness
assumption, any algorithm, even one that exploits fast matrix multiplication,
would need to take at least $mn^{1-o(1)}$ time for some sparsity $m$ if it
achieves a $(2-\epsilon)$-approximation for any $\epsilon&gt;0$. Second we give a
$2$-approximation algorithm for the girth of unweighted graphs running in
$\tilde{O}(mn^{3/4})$ time, and a $(2+\epsilon)$-approximation algorithm (for
any $\epsilon&gt;0$) that works in weighted graphs and runs in $\tilde{O}(m\sqrt
n)$ time. Our algorithms are combinatorial.
</p>
<p>We also obtain a $(4+\epsilon)$-approximation of the girth running in
$\tilde{O}(mn^{\sqrt{2}-1})$ time, improving upon the previous best
$\tilde{O}(m\sqrt n)$ running time by Chechik et al. Finally, we consider the
computation of roundtrip spanners. We obtain a $(5+\epsilon)$-approximate
roundtrip spanner on $\tilde{O}(n^{1.5}/\epsilon^2)$ edges in $\tilde{O}(m\sqrt
n/\epsilon^2)$ time. This improves upon the previous approximation factor
$(8+\epsilon)$ of Chechik et al. for the same running time.
</p></div>
    </summary>
    <updated>2020-04-27T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11439</id>
    <link href="http://arxiv.org/abs/2004.11439" rel="alternate" type="text/html"/>
    <title>Efficient Dispersion on an Anonymous Ring in the Presence of Byzantine Robots</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Molla:Anisur_Rahaman.html">Anisur Rahaman Molla</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mondal:Kaushik.html">Kaushik Mondal</a>, William K. Moses Jr <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11439">PDF</a><br/><b>Abstract: </b>The problem of dispersion of mobile robots on a graph asks that $n$ robots
initially placed arbitrarily on the nodes of an $n$-node anonymous graph,
autonomously move to reach a final configuration where exactly each node has at
most one robot on it. This problem is of significant interest due to its
relationship to other fundamental robot coordination problems, such as
exploration, scattering, load balancing, relocation of self-driving electric
cars to recharge stations, etc. The robots have unique IDs, typically in the
range $[1,poly(n)]$ and limited memory, whereas the graph is anonymous, i.e.,
the nodes do not have identifiers. The objective is to simultaneously minimize
two performance metrics: (i) time to achieve dispersion and (ii) memory
requirement at each robot. This problem has been relatively well-studied when
robots are non-faulty.
</p>
<p>In this paper, we introduce the notion of Byzantine faults to this problem,
i.e., we formalize the problem of dispersion in the presence of up to $f$
Byzantine robots. We then study the problem on a ring while simultaneously
optimizing the time complexity of algorithms and the memory requirement per
robot. Specifically, we design deterministic algorithms that attempt to match
the time lower bound ($\Omega(n)$ rounds) and memory lower bound ($\Omega(\log
n)$ bits per robot).
</p></div>
    </summary>
    <updated>2020-04-27T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11380</id>
    <link href="http://arxiv.org/abs/2004.11380" rel="alternate" type="text/html"/>
    <title>Point Location and Active Learning: Learning Halfspaces Almost Optimally</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hopkins:Max.html">Max Hopkins</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kane:Daniel_M=.html">Daniel M. Kane</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lovett:Shachar.html">Shachar Lovett</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahajan:Gaurav.html">Gaurav Mahajan</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11380">PDF</a><br/><b>Abstract: </b>Given a finite set $X \subset \mathbb{R}^d$ and a binary linear classifier
$c: \mathbb{R}^d \to \{0,1\}$, how many queries of the form $c(x)$ are required
to learn the label of every point in $X$? Known as \textit{point location},
this problem has inspired over 35 years of research in the pursuit of an
optimal algorithm. Building on the prior work of Kane, Lovett, and Moran (ICALP
2018), we provide the first nearly optimal solution, a randomized linear
decision tree of depth $\tilde{O}(d\log(|X|))$, improving on the previous best
of $\tilde{O}(d^2\log(|X|))$ from Ezra and Sharir (Discrete and Computational
Geometry, 2019). As a corollary, we also provide the first nearly optimal
algorithm for actively learning halfspaces in the membership query model. En
route to these results, we prove a novel characterization of Barthe's Theorem
(Inventiones Mathematicae, 1998) of independent interest. In particular, we
show that $X$ may be transformed into approximate isotropic position if and
only if there exists no $k$-dimensional subspace with more than a
$k/d$-fraction of $X$, and provide a similar characterization for exact
isotropic position.
</p></div>
    </summary>
    <updated>2020-04-27T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-32902056.post-3346245643417184590</id>
    <link href="http://paulwgoldberg.blogspot.com/feeds/3346245643417184590/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=32902056&amp;postID=3346245643417184590" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/32902056/posts/default/3346245643417184590" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/32902056/posts/default/3346245643417184590" rel="self" type="application/atom+xml"/>
    <link href="http://paulwgoldberg.blogspot.com/2020/04/surge-pricing-anyone.html" rel="alternate" type="text/html"/>
    <title>Surge pricing, anyone?</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div dir="ltr" style="text-align: left;">One social contribution that I tentatively attribute to Uber is popularisation of the concept of surge pricing. That is, we try to call an Uber and all-too-frequently get told that we have to pay a premium at this particular point in time, due to high demand. On the other hand, recent shortages of toilet paper, paracetamol, and certain foods were not accompanied by any kind of surge pricing, and the limits imposed on how much stuff you can buy, were not so effective in keeping these goods available. At this point, things have improved, although I have not been able to buy flour recently: the shortage of flour in the supermarkets I visit seems to be chronic.<br/><br/>Now I appreciate the objection to charging to charging a premium to allcomers, rich and poor alike, in the context of vital food and medicine. (Although, limits on purchases can also be criticised as being unfair to a single purchaser buying for a large family, or a key worker who is short of time and doesn't want to search excessively for a desired item.) In trying to advocate surge pricing, let me turn instead to possible examples less controversial, such as hairdressers and garden centres. When these establishments are allowed to reopen, it seems reasonable that they should charge a premium (temporarily). Not only do they need the money, but it would help to control a flood of customers all causing long queues and infecting each other at close quarters. To be honest, I’m not optimistic that this will happen, since they will still worry about accusations of price-gouging, plus there’s the question of how big a premium is appropriate.<br/><br/><a href="https://www.economist.com/britain/2020/04/25/the-impossibility-of-measuring-inflation-in-a-pandemic">An article in the Economist</a> highlights a related problem, which is the difficulty of measuring the rate of inflation, at a time when various goods and services (whose prices get used to measure inflation) are unavailable. Coming back to flour, it may be felt that some of it (not all!) should be sold at market price, meaning one that some people will pay, but where it stays on the shelves for a few days, at least. There is a moral case against selling goods too cheaply, which is that it becomes an attempt to hide a problem — a successful attempt, if inflation cannot be measured.<br/><br/>Finally, the problem discussed here touches on a defect at the heart of traditional economic theory, which is the <a href="https://en.wikipedia.org/wiki/Arrow%E2%80%93Debreu_model">celebrated existence</a> of “correct” prices, unaccompanied by a means of arriving at those prices. The Algorithmic Game Theory community has quite rightly worried about price discovery and its computational obstacles. But the obstacles are also social, and status quo bias plays a big part.</div></div>
    </content>
    <updated>2020-04-26T14:43:00Z</updated>
    <published>2020-04-26T14:43:00Z</published>
    <category scheme="http://www.blogger.com/atom/ns#" term="aggregator"/>
    <category scheme="http://www.blogger.com/atom/ns#" term="economics"/>
    <author>
      <name>Paul Goldberg</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/10952445127830395305</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-32902056</id>
      <category term="aggregator"/>
      <category term="UK academia"/>
      <category term="politics"/>
      <category term="meetings"/>
      <category term="research"/>
      <category term="research directions"/>
      <category term="conferences"/>
      <category term="funding"/>
      <category term="economics"/>
      <category term="people"/>
      <category term="rant"/>
      <category term="academia"/>
      <category term="forecasts"/>
      <category term="internet"/>
      <category term="advertisement"/>
      <category term="game theory"/>
      <category term="trips"/>
      <category term="University of Liverpool"/>
      <category term="editorial"/>
      <category term="technical"/>
      <category term="times higher"/>
      <category term="announcements"/>
      <category term="publications"/>
      <category term="teaching"/>
      <category term="work"/>
      <category term="postgraduate research"/>
      <category term="technology"/>
      <category term="books"/>
      <category term="social choice"/>
      <category term="talks"/>
      <category term="CACM"/>
      <category term="games"/>
      <category term="liverpool"/>
      <category term="open problems"/>
      <category term="problems"/>
      <category term="research assessment"/>
      <category term="tongue in cheek"/>
      <category term="administration"/>
      <category term="architecture"/>
      <category term="email"/>
      <category term="environment"/>
      <category term="higher education"/>
      <category term="mechanism design"/>
      <category term="puzzles"/>
      <category term="web sites"/>
      <category term="URLs"/>
      <category term="USS"/>
      <category term="education"/>
      <category term="oxford"/>
      <category term="schools"/>
      <category term="UCU"/>
      <category term="UK"/>
      <category term="go"/>
      <category term="intellectual property"/>
      <category term="jobs"/>
      <category term="league table"/>
      <category term="math education"/>
      <category term="money"/>
      <category term="products"/>
      <category term="science"/>
      <category term="students"/>
      <category term="Liberal democrats"/>
      <category term="XJTLU"/>
      <category term="behavioural economics"/>
      <category term="china"/>
      <category term="current affairs"/>
      <category term="diversity"/>
      <category term="epsrc"/>
      <category term="family"/>
      <category term="geography"/>
      <category term="holidays"/>
      <category term="joke"/>
      <category term="misc"/>
      <category term="nerd humour"/>
      <category term="pensions"/>
      <category term="predictions"/>
      <category term="proposals"/>
      <category term="psephology"/>
      <category term="region"/>
      <category term="student finance"/>
      <category term="visits"/>
      <category term="warwick"/>
      <category term="web"/>
      <category term="weekends"/>
      <category term="wikipedia"/>
      <category term="writing"/>
      <author>
        <name>Paul Goldberg</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/10952445127830395305</uri>
      </author>
      <link href="http://paulwgoldberg.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/32902056/posts/default/-/aggregator" rel="self" type="application/atom+xml"/>
      <link href="http://paulwgoldberg.blogspot.com/search/label/aggregator" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/32902056/posts/default/-/aggregator/-/aggregator?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>theoretical computer science, economics, and academic life in general. Writing in personal capacity, not representing my employer or other colleagues</subtitle>
      <title>Paul Goldberg</title>
      <updated>2020-04-26T14:43:37Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-21129445.post-1422354062966011246</id>
    <link href="http://mysliceofpizza.blogspot.com/feeds/1422354062966011246/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="http://www.blogger.com/comment.g?blogID=21129445&amp;postID=1422354062966011246" rel="replies" type="text/html"/>
    <link href="http://www.blogger.com/feeds/21129445/posts/default/1422354062966011246" rel="edit" type="application/atom+xml"/>
    <link href="http://www.blogger.com/feeds/21129445/posts/default/1422354062966011246" rel="self" type="application/atom+xml"/>
    <link href="http://mysliceofpizza.blogspot.com/2020/04/john-conway.html" rel="alternate" type="text/html"/>
    <title>John Conway</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><div dir="ltr" style="text-align: left;">I managed to join a zoom meeting yesterday to honor John Conway. Peter Winkler paid tribute with a story about the brick-stacking puzzle (was interesting to hear "skintle" in context of puzzles). Roger Penrose paid tribute with tilings but also an old classic,  Morley's Trisector Theorem. Others like Don Knuth appeared in the pre-meeting chat room, but I could not stay for the entire 3 hrs+ homage. Thanks to everyone!  JHC, RIP.  I was reminded that we are the math, friends and puzzles we leave behind. </div></div>
    </content>
    <updated>2020-04-26T14:11:00Z</updated>
    <published>2020-04-26T14:11:00Z</published>
    <category scheme="http://www.blogger.com/atom/ns#" term="aggregator"/>
    <author>
      <name>metoo</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/07192519900962182610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-21129445</id>
      <category term="aggregator"/>
      <category term="Non-CS"/>
      <author>
        <name>metoo</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/07192519900962182610</uri>
      </author>
      <link href="http://mysliceofpizza.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="http://www.blogger.com/feeds/21129445/posts/default/-/aggregator" rel="self" type="application/atom+xml"/>
      <link href="http://mysliceofpizza.blogspot.com/search/label/aggregator" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="http://www.blogger.com/feeds/21129445/posts/default/-/aggregator/-/aggregator?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>books, stories, poems, algorithms, math and computer science. 

some art and anecdotes too.</subtitle>
      <title>my slice of pizza</title>
      <updated>2020-04-26T18:57:57Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/057</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/057" rel="alternate" type="text/html"/>
    <title>TR20-057 |  Polynomial Data Structure Lower Bounds in the Group Model | 

	Omri Weinstein, 

	Gleb Posobin, 

	Oded Regev, 

	Alexander Golovnev</title>
    <summary>Proving super-logarithmic data structure lower bounds in the static \emph{group model} has been a fundamental challenge in computational geometry since the early 80's. We prove a polynomial ($n^{\Omega(1)}$) lower bound for an explicit range counting problem of $n^3$ convex polygons in $\R^2$ (each with $n^{\tilde{O}(1)}$ facets/semialgebraic-complexity), against linear storage arithmetic data structures in the group model. Our construction and analysis are based on a combination of techniques in Diophantine approximation, pseudorandomness, and compressed sensing---in particular, on the existence and partial derandomization of optimal \emph{binary} compressed sensing matrices in the polynomial sparsity regime ($k = n^{1-\delta}$). As a byproduct, this establishes a (logarithmic) separation between compressed sensing matrices and the stronger RIP property.</summary>
    <updated>2020-04-26T11:44:42Z</updated>
    <published>2020-04-26T11:44:42Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-27T13:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/056</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/056" rel="alternate" type="text/html"/>
    <title>TR20-056 |  Catalytic Approaches to the Tree Evaluation Problem | 

	Ian Mertz, 

	James  Cook</title>
    <summary>The study of branching programs for the Tree Evaluation Problem, introduced by S. Cook et al. (TOCT 2012), remains one of the most promising approaches to separating L from P. Given a label in $[k]$ at each leaf of a complete binary tree and an explicit function  in $[k]^2 \to [k]$ for recursively computing the value of each internal node from its children, the problem is to compute the value at the root node. The problem is parameterized by the alphabet size $k$ and the height $h$ of the tree. A branching program implementing the straightforward recursive algorithm uses $\Theta((k + 1)^h)$ states, organized into $2^h-1$ layers of width up to $k^h$. Until now no better deterministic algorithm was known.

We present a series of three new algorithms solving the Tree Evaluation Problem. They are inspired by the work of Buhrman et al. on catalytic space (STOC 2012), applied outside the catalytic-space setting. First we give a novel branching program with $2^{4h} poly(k)$ layers of width $2^{3k}$, which beats the straightforward algorithm when $h = \omega(k / \log k)$. Next we give a branching program with $k^{2h} poly(k)$ layers of width $k^3$.  This has total size comparable to the straightforward algorithm, but is implemented using the catalytic framework. Finally we interpolate between the two algorithms to give a branching program with $(O(k/h))^{2h} poly(k)$ layers of width $(O(k/h))^{\epsilon h}$ for any constant $\epsilon &gt; 0$, which beats the straightforward algorithm for all $h \geq k^{1/2 + poly(\epsilon)}$. These are the first deterministic branching programs to beat the straightforward algorithm, but more importantly this is the first non-trivial approach to proving deterministic upper bounds for Tree Evaluation.

We also contribute new machinery to the catalytic computing program, which may be of independent interest to some readers.</summary>
    <updated>2020-04-26T06:11:13Z</updated>
    <published>2020-04-26T06:11:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-27T13:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11315</id>
    <link href="http://arxiv.org/abs/2004.11315" rel="alternate" type="text/html"/>
    <title>Engineering Data Reduction for Nested Dissection</title>
    <feedworld_mtime>1587859200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Wolfgang Ost, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schulz:Christian.html">Christian Schulz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Strash:Darren.html">Darren Strash</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11315">PDF</a><br/><b>Abstract: </b>Many applications rely on time-intensive matrix operations, such as
factorization, which can be sped up significantly for large sparse matrices by
interpreting the matrix as a sparse graph and computing a node ordering that
minimizes the so-called fill-in. In this paper, we engineer new data reduction
rules for the minimum fill-in problem, which significantly reduce the size of
the graph while producing an equivalent (or near-equivalent) instance. By
applying both new and existing data reduction rules exhaustively before nested
dissection, we obtain improved quality and at the same time large improvements
in running time on a variety of instances. Our overall algorithm outperforms
the state-of-the-art significantly: it not only yields better elimination
orders, but it does so significantly faster than previously possible. For
example, on road networks, where nested dissection algorithms are typically
used as a preprocessing step for shortest path computations, our algorithms are
on average six times faster than Metis while computing orderings with less
fill-in.
</p></div>
    </summary>
    <updated>2020-04-26T22:33:10Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11173</id>
    <link href="http://arxiv.org/abs/2004.11173" rel="alternate" type="text/html"/>
    <title>Coloring Problems on Bipartite Graphs of Small Diameter</title>
    <feedworld_mtime>1587859200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Campos:Victor_A=.html">Victor A. Campos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gomes:Guilherme_C=_M=.html">Guilherme C. M. Gomes</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ibiapina:Allen.html">Allen Ibiapina</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lopes:Raul.html">Raul Lopes</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sau:Ignasi.html">Ignasi Sau</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Silva:Ana.html">Ana Silva</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11173">PDF</a><br/><b>Abstract: </b>We investigate a number of coloring problems restricted to bipartite graphs
with bounded diameter. We prove that the $k$-List Coloring, List $k$-Coloring,
and $k$-Precoloring Extension problems are NP-complete on bipartite graphs with
diameter at most $d$, for every $k\ge 4$ and every $d\ge 3$, and for $k=3$ and
$d\ge 4$, and that List $k$-Coloring is polynomial when $d=2$ (i.e., on
complete bipartite graphs) for every $k \geq 3$. Since $k$-List Coloring was
already known to be NP-complete on complete bipartite graphs, and polynomial
for $k=2$ on general graphs, the only remaining open problems are List
$3$-Coloring and $3$-Precoloring Extension when $d=3$.
</p>
<p>We also prove that the Surjective $C_6$-Homomorphism problem is NP-complete
on bipartite graphs with diameter at most $4$, answering a question posed by
Bodirsky, K\'ara, and Martin [Discret. Appl. Math. 2012]. As a byproduct, we
get that deciding whether $V(G)$ can be partitioned into 3 subsets each
inducing a complete bipartite graph is NP-complete. An attempt to prove this
result was presented by Fleischner, Mujuni, Paulusma, and Szeider [Theor.
Comput. Sci. 2009], but we realized that there was an apparently non-fixable
flaw in their proof.
</p>
<p>Finally, we prove that the $3$-Fall Coloring problem is NP-complete on
bipartite graphs with diameter at most $4$, and give a polynomial reduction
from $3$-Fall Coloring on bipartite graphs with diameter $3$ to $3$-Precoloring
Extension on bipartite graphs with diameter $3$. The latter result implies that
if $3$-Fall Coloring is NP-complete on these graphs, then the complexity gaps
mentioned above for List $k$-Coloring and $k$-Precoloring Extension would be
closed. This would also answer a question posed by Kratochv\'il, Tuza, and
Voigt [Proc. of WG 2002].
</p></div>
    </summary>
    <updated>2020-04-26T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11166</id>
    <link href="http://arxiv.org/abs/2004.11166" rel="alternate" type="text/html"/>
    <title>Dynamic Programming Approach to the Generalized Minimum Manhattan Network Problem</title>
    <feedworld_mtime>1587859200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Yuya Masumura, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Oki:Taihei.html">Taihei Oki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yamaguchi:Yutaro.html">Yutaro Yamaguchi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11166">PDF</a><br/><b>Abstract: </b>We study the generalized minimum Manhattan network (GMMN) problem: given a
set $P$ of pairs of two points in the Euclidean plane $\mathbb{R}^2$, we are
required to find a minimum-length geometric network which consists of
axis-aligned segments and contains a shortest path in the $L_1$ metric (a
so-called Manhattan path) for each pair in $P$. This problem commonly
generalizes several NP-hard network design problems that admit constant-factor
approximation algorithms, such as the rectilinear Steiner arborescence (RSA)
problem, and it is open whether so does the GMMN problem.
</p>
<p>As a bottom-up exploration, Schnizler (2015) focused on the intersection
graphs of the rectangles defined by the pairs in $P$, and gave a
polynomial-time dynamic programming algorithm for the GMMN problem whose input
is restricted so that both the treewidth and the maximum degree of its
intersection graph are bounded by constants. In this paper, as the first
attempt to remove the degree bound, we provide a polynomial-time algorithm for
the star case, and extend it to the general tree case based on an improved
dynamic programming approach.
</p></div>
    </summary>
    <updated>2020-04-26T22:35:54Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11146</id>
    <link href="http://arxiv.org/abs/2004.11146" rel="alternate" type="text/html"/>
    <title>On the computation of the M{\"o}bius transform</title>
    <feedworld_mtime>1587859200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barbier:Morgan.html">Morgan Barbier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheballah:Hayat.html">Hayat Cheballah</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bars:Jean=Marie_Le.html">Jean-Marie Le Bars</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11146">PDF</a><br/><b>Abstract: </b>The M{\"o}bius transform is a crucial transformation into the Boolean world;
it allows to change the Boolean representation between the True Table and
Algebraic Normal Form. In this work, we introduce a new algebraic point of view
of this transformation based on the polynomial form of Boolean functions. It
appears that we can perform a new notion: the M{\"o}bius computation variable
by variable and new computation properties. As a consequence, we propose new
algorithms which can produce a huge speed up of the M{\"o}bius computation for
sub-families of Boolean function. Furthermore we compute directly the
M{\"o}bius transformation of some particular Boolean functions. Finally, we
show that for some of them the Hamming weight is directly related to the
algebraic degree of specific factors.
</p></div>
    </summary>
    <updated>2020-04-26T22:34:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11128</id>
    <link href="http://arxiv.org/abs/2004.11128" rel="alternate" type="text/html"/>
    <title>The Weighted Euler Curve Transform for Shape and Image Analysis</title>
    <feedworld_mtime>1587859200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Qitong Jiang, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kurtek:Sebastian.html">Sebastian Kurtek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Needham:Tom.html">Tom Needham</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11128">PDF</a><br/><b>Abstract: </b>The Euler Curve Transform (ECT) of Turner et al.\ is a complete invariant of
an embedded simplicial complex, which is amenable to statistical analysis. We
generalize the ECT to provide a similarly convenient representation for
weighted simplicial complexes, objects which arise naturally, for example, in
certain medical imaging applications. We leverage work of Ghrist et al.\ on
Euler integral calculus to prove that this invariant---dubbed the Weighted
Euler Curve Transform (WECT)---is also complete. We explain how to transform a
segmented region of interest in a grayscale image into a weighted simplicial
complex and then into a WECT representation. This WECT representation is
applied to study Glioblastoma Multiforme brain tumor shape and texture data. We
show that the WECT representation is effective at clustering tumors based on
qualitative shape and texture features and that this clustering correlates with
patient survival time.
</p></div>
    </summary>
    <updated>2020-04-26T22:39:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.10969</id>
    <link href="http://arxiv.org/abs/2004.10969" rel="alternate" type="text/html"/>
    <title>Non-Adaptive Adaptive Sampling on Turnstile Streams</title>
    <feedworld_mtime>1587859200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahabadi:Sepideh.html">Sepideh Mahabadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Razenshteyn:Ilya.html">Ilya Razenshteyn</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Samson.html">Samson Zhou</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.10969">PDF</a><br/><b>Abstract: </b>Adaptive sampling is a useful algorithmic tool for data summarization
problems in the classical centralized setting, where the entire dataset is
available to the single processor performing the computation. Adaptive sampling
repeatedly selects rows of an underlying matrix
$\mathbf{A}\in\mathbb{R}^{n\times d}$, where $n\gg d$, with probabilities
proportional to their distances to the subspace of the previously selected
rows. Intuitively, adaptive sampling seems to be limited to trivial multi-pass
algorithms in the streaming model of computation due to its inherently
sequential nature of assigning sampling probabilities to each row only after
the previous iteration is completed. Surprisingly, we show this is not the case
by giving the first one-pass algorithms for adaptive sampling on turnstile
streams and using space $\text{poly}(d,k,\log n)$, where $k$ is the number of
adaptive sampling rounds to be performed.
</p>
<p>Our adaptive sampling procedure has a number of applications to various data
summarization problems that either improve state-of-the-art or have only been
previously studied in the more relaxed row-arrival model. We give the first
relative-error algorithms for column subset selection, subspace approximation,
projective clustering, and volume maximization on turnstile streams that use
space sublinear in $n$. We complement our volume maximization algorithmic
results with lower bounds that are tight up to lower order terms, even for
multi-pass algorithms. By a similar construction, we also obtain lower bounds
for volume maximization in the row-arrival model, which we match with
competitive upper bounds.
</p>
<p>See paper for full abstract.
</p></div>
    </summary>
    <updated>2020-04-26T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.10898</id>
    <link href="http://arxiv.org/abs/2004.10898" rel="alternate" type="text/html"/>
    <title>Qd-tree: Learning Data Layouts for Big Data Analytics</title>
    <feedworld_mtime>1587859200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Zongheng.html">Zongheng Yang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chandramouli:Badrish.html">Badrish Chandramouli</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Chi.html">Chi Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gehrke:Johannes.html">Johannes Gehrke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Yinan.html">Yinan Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Minhas:Umar_Farooq.html">Umar Farooq Minhas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Larson:Per==Aring=ke.html">Per-Åke Larson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kossmann:Donald.html">Donald Kossmann</a>, Rajeev Acharya <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.10898">PDF</a><br/><b>Abstract: </b>Corporations today collect data at an unprecedented and accelerating scale,
making the need to run queries on large datasets increasingly important.
Technologies such as columnar block-based data organization and compression
have become standard practice in most commercial database systems. However, the
problem of best assigning records to data blocks on storage is still open. For
example, today's systems usually partition data by arrival time into row
groups, or range/hash partition the data based on selected fields. For a given
workload, however, such techniques are unable to optimize for the important
metric of the number of blocks accessed by a query. This metric directly
relates to the I/O cost, and therefore performance, of most analytical queries.
Further, they are unable to exploit additional available storage to drive this
metric down further.
</p>
<p>In this paper, we propose a new framework called a query-data routing tree,
or qd-tree, to address this problem, and propose two algorithms for their
construction based on greedy and deep reinforcement learning techniques.
Experiments over benchmark and real workloads show that a qd-tree can provide
physical speedups of more than an order of magnitude compared to current
blocking schemes, and can reach within 2X of the lower bound for data skipping
based on selectivity, while providing complete semantic descriptions of created
blocks.
</p></div>
    </summary>
    <updated>2020-04-26T22:27:06Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.10873</id>
    <link href="http://arxiv.org/abs/2004.10873" rel="alternate" type="text/html"/>
    <title>Some results on Vertex Separator Reconfiguration</title>
    <feedworld_mtime>1587859200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gomes:Guilherme_C=_M=.html">Guilherme C. M. Gomes</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nogueira:S=eacute=rgio_H=.html">Sérgio H. Nogueira</a>, Vinicius F. dos Santos <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.10873">PDF</a><br/><b>Abstract: </b>We present the first results on the complexity of the reconfiguration of
vertex separators under the three most popular rules: token addition/removal,
token jumping, and token sliding. We show that, aside from some trivially
negative instances, the first two rules are equivalent to each other and that,
even if only on a subclass of bipartite graphs, TJ is not equivalent to the
other two unless $\mathsf{NP} = \mathsf{PSPACE}$; we do this by showing a
relationship between separators and independent sets in this subclass of
bipartite graphs. In terms of polynomial time algorithms, we show that every
class with a polynomially bounded number of minimal vertex separators admits an
efficient algorithm under token jumping, then turn our attention to two classes
that do not meet this condition: $\{3P_1, diamond\}$-free and series-parallel
graphs. For the first, we describe a novel characterization, which we use to
show that reconfiguring vertex separators under token jumping is always
possible and that, under token sliding, it can be done in polynomial time; for
series-parallel graphs, we also prove that reconfiguration is always possible
under TJ and exhibit a polynomial time algorithm to construct the
reconfiguration sequence.
</p></div>
    </summary>
    <updated>2020-04-26T23:21:59Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.10805</id>
    <link href="http://arxiv.org/abs/2004.10805" rel="alternate" type="text/html"/>
    <title>Hardness of Identity Testing for Restricted Boltzmann Machines and Potts models</title>
    <feedworld_mtime>1587859200</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blanca:Antonio.html">Antonio Blanca</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Zongchen.html">Zongchen Chen</a>, Daniel Štefankovič, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vigoda:Eric.html">Eric Vigoda</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.10805">PDF</a><br/><b>Abstract: </b>We study identity testing for restricted Boltzmann machines (RBMs), and more
generally for undirected graphical models. Given sample access to the Gibbs
distribution corresponding to an unknown or hidden model $M^*$ and given an
explicit model $M$, can we distinguish if either $M = M^*$ or if they are
(statistically) far apart? Daskalakis et al. (2018) presented a polynomial-time
algorithm for identity testing for the ferromagnetic (attractive) Ising model.
In contrast, for the antiferromagnetic (repulsive) Ising model, Bez\'akov\'a et
al. (2019) proved that unless $RP=NP$ there is no identity testing algorithm
when $\beta d=\omega(\log{n})$, where $d$ is the maximum degree of the visible
graph and $\beta$ is the largest edge weight in absolute value.
</p>
<p>We prove analogous hardness results for RBMs (i.e., mixed Ising models on
bipartite graphs), even when there are no latent variables or an external
field. Specifically, we show that if $RP \neq NP$, then when $\beta
d=\omega(\log{n})$ there is no polynomial-time algorithm for identity testing
for RBMs; when $\beta d =O(\log{n})$ there is an efficient identity testing
algorithm that utilizes the structure learning algorithm of Klivans and Meka
(2017). In addition, we prove similar lower bounds for purely ferromagnetic
RBMs with inconsistent external fields, and for the ferromagnetic Potts model.
Previous hardness results for identity testing of Bez\'akov\'a et al. (2019)
utilized the hardness of finding the maximum cuts, which corresponds to the
ground states of the antiferromagnetic Ising model. Since RBMs are on bipartite
graphs such an approach is not feasible. We instead introduce a general
methodology to reduce from the corresponding approximate counting problem and
utilize the phase transition that is exhibited by RBMs and the mean-field Potts
model.
</p></div>
    </summary>
    <updated>2020-04-26T22:33:34Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-24T01:30:00Z</updated>
    </source>
  </entry>

  <entry>
    <id>http://offconvex.github.io/2020/04/24/ExpLR1/</id>
    <link href="http://offconvex.github.io/2020/04/24/ExpLR1/" rel="alternate" type="text/html"/>
    <title>Exponential Learning Rate Schedules for Deep Learning (Part 1)</title>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>This blog post concerns our <a href="https://arxiv.org/pdf/1910.07454.pdf">ICLR20 paper</a> on a surprising discovery about learning rate (LR), the most basic hyperparameter in deep learning.</p>

<p>As illustrated in many online blogs, setting LR too small  might slow down the optimization, and setting it too large  might make the network overshoot the area of low losses. The standard mathematical analysis for  the right choice of LR relates it to <a href="https://en.wikipedia.org/wiki/Smoothness">smoothness</a> of the loss function.</p>

<p>Many practitioners use a ‘step decay’ LR schedule, which systematically drops the LR after specific training epochs. One often hears the intuition—with some mathematical justification if one treats SGD as a random walk in the  loss landscape— that large learning rates are useful in the initial (“exploration”) phase of training whereas lower rates  in later epochs allow a slow settling down to a local minimum in the landscape. Intriguingly, this intuition is called into  question by the success of exotic learning rate schedules such as <a href="https://arxiv.org/abs/1608.03983">cosine</a> (Loshchilov&amp;Hutter, 2016), and <a href="https://arxiv.org/abs/1506.01186">triangular</a> (Smith, 2015), featuring an oscillatory LR.  These divergent approaches suggest that LR, the most basic and intuitive hyperparameter in deep learning, has not revealed all its mysteries yet.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/lr_schedules.png" style="width: 450px;"/>
<br/>
<b>Figure 1.</b> Examples of Step Decay, Triangular and Cosine LR schedules.
</div>
<p><br/></p>

<h1 id="surprise-exponentially-increasing-lr">Surprise: Exponentially increasing LR</h1>

<p>We report experiments that state-of-the-art networks for image recognition tasks can be trained with an exponentially increasing LR (ExpLR): in each iteration it increases by $(1+\alpha)$ for some $\alpha &gt; 0$.  (The $\alpha$ can be varied over epochs.) Here $\alpha$ is not too small in our experiments, so as you would imagine, the LR hits astronomical values in no time.  To the best of our knowledge, this is the first time such a rate schedule has been successfully used, let alone for highly successful architectures. In fact, as we will see below, the reason we even did this bizarre experiment  was that we already had a mathematical proof that it would work. Specifically, we could show that such ExpLR schedules are at least as powerful as the standard step-decay ones, by which we mean that ExpLR can let us achieve (in function space) all the nets obtainable via the currently popular step-decay schedules.</p>

<h2 id="so-why-does-this-work">So why does this work?</h2>

<p>One key property of state-of-the-art nets we rely on is that they all use some normalization of parameters within layers, usually Batch Norm (BN), which has been shown to give benefits in optimization and generalization across architectures. Our result also holds for other normalizations, including Group Normalization (Wu &amp; He, 2018), Layer Normalization (Ba et al., 2016), Instance Norm (Ulyanov et al., 2016), etc.</p>

<p>The second key property of current training is that they use weight decay (aka $\ell_2$ regularizer). When combined with BN, this implies strange dynamics in parameter space, and the experimental papers (<a href="https://arxiv.org/abs/1706.05350">van Laarhoven, 2017</a>, <a href="https://arxiv.org/abs/1803.01814">Hoffer et al., 2018a</a> and <a href="https://openreview.net/forum?id=B1lz-3Rct7">Zhang et al., 2019</a>),  noticed that combining BN and weight decay can  be viewed as increasing the LR.</p>

<p>Our paper gives a rigorous proof of the power of ExpLR by showing the following about the end-to-end function  being computed (see Main Thm in the paper):</p>

<blockquote>
  <p>(Informal Theorem) For commonly  used values of the paremeters, every net produced by <em>Weight Decay + Constant LR + BN + Momentum</em> can also be produced (in function space) via <em>ExpLR + BN + Momentum</em></p>
</blockquote>

<p>*NB: If the LR is not fixed but decaying in discrete steps, then the equivalent ExpLR training decays the exponent. (See our paper for details.)</p>

<p>At first sight such a claim may seem difficult (if not impossible) to prove given that we lack any mathematical characterization of nets produced by training (note that the theorem makes no mention of the dataset!).  The  equivalence is shown by reasoning about <em>trajectory</em> of optimization, instead of the usual “landscape view” of stationary points, gradient norms, Hessian norms, smoothness, etc.. This is an example of the importance of trajectory analysis, as argued in <a href="http://www.offconvex.org/2019/06/03/trajectories/">earlier blog post of Sanjeev’s</a> because optimization and generalization are deeply intertwined for deep learning. Conventional wisdom says LR controls optimization, and the regularizer controls generalization. Our result shows that the effect of weight decay can  under fairly normal conditions be * exactly*  realized by the ExpLR rate schedule.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/exp_lr.png" style="width: 550px;"/>
</div>
<p><strong>Figure 2.</strong> Training PreResNet32 on CIFAR10 with fixed LR $0.1$, momentum $0.9$ and other standard hyperparameters. Trajectory was unchanged when WD was turned off  and LR at iteration $t$ was $\tilde{\eta}_ t = 0.1\times1.481^t$. (The constant $1.481$ is predicted by our theory given the original hyperparameters.) Plot on right shows  weight norm $\pmb{w}$ of the first convolutional layer in the second residual block. It grows exponentially as one would expect, satisfying $|\pmb{w}_ t|_ 2^2/\tilde{\eta}_ t = $ constant.</p>

<p><a href="http://www.offconvex.org/feed.xml# (We first want to clarify that the exponential LR schedules work for normalized networks only and will lead parameter and output explosion for networks without normalization. )">comment</a>:# (In the rest of the post, we will first explain how does this equivalence result arises from various types of normalization schemes and then sketch the proof. We will also present a more general exponential growing learning schedule called ‘'’Tapered Exponential Learning Rate Schedule’, or TEXP, which is both experimentally and theoretically equivalent to the standard Step Decay schedule + Weight Decay. )</p>

<h2 id="scale-invariance-and-equivalence">Scale Invariance and Equivalence</h2>

<p>The formal proof holds for any training loss satisfying 
what we call <em>Scale Invariance</em>:</p>



<p>BN and other normalization schemes result in a Scale-Invariant Loss for the popular deep architectures (Convnet, Resnet, DenseNet etc.) if the output layer –where normally no normalization is used– is fixed throughout training. Empirically, <a href="https://openreview.net/forum?id=S1Dh8Tg0-">Hoffer et al. (2018b)</a>  found that randomly fixing the output layer at the start does not harm the final accuracy. 
(Appendix C of our paper demonstrates scale invariance for  various architectures; it is somewhat nontrivial.)</p>

<p>For batch ${\mathcal{B}} = \{ x_ i \} _ {i=1}^B$, network parameter ${\pmb{\theta}}$, we  denote the network by $f_ {\pmb{\theta}}$ and the loss function at iteration $t$ by $L_ t(f_ {\pmb{\theta}}) = L(f_ {\pmb{\theta}}, {\mathcal{B}}_ t)$ . We also use $L_ t({\pmb{\theta}})$ for convenience. We say the network $f_ {\pmb{\theta}}$ is <em>scale invariant</em> if $\forall c&gt;0$, $f_ {c{\pmb{\theta}}} = f_ {\pmb{\theta}}$, which implies the loss $L_ t$ is also scale invariant, i.e., $L_  t(c{\pmb{\theta}}_ t)=L_ t({\pmb{\theta}}_ t)$, $\forall c&gt;0$. A key source of intuition is the following lemma provable via chain rule:</p>

<blockquote>
  <p><strong>Lemma 1</strong>. A scale-invariant loss $L$ satisfies
(1). $\langle\nabla_ {\pmb{\theta}} L, {\pmb{\theta}} \rangle=0$ ;<br/>
(2). $\left.\nabla_ {\pmb{\theta}} L \right|_ {\pmb{\theta} = \pmb{\theta}_ 0} = c \left.\nabla_ {\pmb{\theta}} L\right|_  {\pmb{\theta} = c\pmb{\theta}_ 0}$, for any $c&gt;0$.</p>
</blockquote>

<p>The first property immediately implies that $|{\pmb{\theta}}_ t|$ is monotone increasing for SGD if WD is turned off by Pythagoren Theorem. And based on this, <a href="https://arxiv.org/pdf/1812.03981.pdf">our previous work</a> with Kaifeng Lyu shows that GD with any fixed learning rate can reach $\varepsilon$ approximate stationary point for scale invariant objectives in $O(1/\varepsilon^2)$ iterations.</p>
<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/inv_lemma.png" style="width: 360px;"/>
<br/>
<b>Figure 3.</b> Illustration of Lemma 1. 
</div>
<p><br/></p>

<p>Below is the main result of the paper. We will explain the proof idea (using scale-invariance) in a later post.</p>
<blockquote>
  <p><strong>Theorem 1(Main, Informal).</strong> SGD on a scale-invariant objective with initial learning rate $\eta$, weight decay factor $\lambda$, and momentum factor $\gamma$ is equivalent to SGD with momentum factor $\gamma$ where at iteration $t$, the ExpLR $\tilde{\eta}_ t$  is defined as $\tilde{\eta}_ t = \alpha^{-2t-1} \eta$ without weight decay($\tilde{\lambda} = 0$) where $\alpha$ is a non-zero root of equation 
     </p>
</blockquote>

<blockquote>
  <p>Specifically, when momentum $\gamma=0$,  the above schedule can be simplified as $\tilde{\eta}_ t = (1-\lambda\eta)^{-2t-1} \eta$.</p>
</blockquote>

<h3 id="sota-performance-with-exponential-lr">SOTA performance with exponential LR</h3>

<p>As mentioned, reaching state-of-the-art accuracy  requires reducing the learning rate a few times. Suppose the training has $K$ phases, and the learning rate is divided by some constant $C_I&gt;1$ when entering phase $I$. To realize the same effect with an exponentially increasing LR, we have:</p>

<blockquote>
  <p><strong>Theorem 2:</strong> ExpLR with the below modification generates the same network sequence as Step Decay with momentum factor $\gamma$ and WD $\lambda$ does. We call it <em>Tapered Exponential LR schedule</em> (TEXP).<br/>
<strong>Modification when entering a new phase $I$</strong>: (1). switching to some smaller exponential growing rate; (2). divinding the current LR by $C_I$.</p>
</blockquote>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/texp_lr.png" style="width: 235px;"/>
<img src="http://www.offconvex.org/assets/TEXP.png" style="width: 500px;"/>
</div>
<p><strong>Figure 5.</strong> PreResNet32 trained with Step Decay (as in Figure 1) and its corresponding TEXP schedule. As predicted by Theorem 2, they have similar trajectories and performances.</p>

<h2 id="conclusion">Conclusion</h2>

<p>We hope that this bit of theory and supporting experiments have changed your outlook on learning rates for deep learning.</p>

<p>A follow-up post will present the proof idea and give more insight into why ExpLR suggests a rethinking of the “landscape view” of optimization in deep learning.</p></div>
    </summary>
    <updated>2020-04-24T10:00:00Z</updated>
    <published>2020-04-24T10:00:00Z</published>
    <source>
      <id>http://offconvex.github.io/</id>
      <author>
        <name>Off the Convex Path</name>
      </author>
      <link href="http://offconvex.github.io/" rel="alternate" type="text/html"/>
      <link href="http://offconvex.github.io/feed.xml" rel="self" type="application/atom+xml"/>
      <subtitle>Algorithms off the convex path.</subtitle>
      <title>Off the convex path</title>
      <updated>2020-04-26T22:41:16Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-US">
    <id>https://www.scottaaronson.com/blog/?p=4772</id>
    <link href="https://www.scottaaronson.com/blog/?p=4772" rel="alternate" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?p=4772#comments" rel="replies" type="text/html"/>
    <link href="https://www.scottaaronson.com/blog/?feed=atom&amp;p=4772" rel="replies" type="application/atom+xml"/>
    <title xml:lang="en-US">Martinis, The Plot Against America, Kill Chain</title>
    <summary xml:lang="en-US">As if we didn’t have enough to worry us, this week brought the sad news that John Martinis, who for five years was the leader and public face of Google’s experimental quantum computing effort, has quit Google and returned to his earlier post at UC Santa Barbara. I’ve spoken about what happened both with John […]</summary>
    <content type="xhtml" xml:lang="en-US"><div xmlns="http://www.w3.org/1999/xhtml"><p>As if we didn’t have enough to worry us, this week brought the <a href="https://www.wired.com/story/googles-head-quantum-computing-hardware-resigns/">sad news</a> that John Martinis, who for five years was the leader and public face of Google’s experimental quantum computing effort, has quit Google and returned to his earlier post at UC Santa Barbara.  I’ve spoken about what happened both with John and with Hartmut Neven, the head of Google’s Quantum AI Lab.  Without betraying confidences, or asserting anything that either side would disagree with, I think I can say that it came down to a difference in management philosophies.  Google tends to be consensus-driven, whereas John is of the view that building a million-qubit, error-corrected quantum computer will take more decisive leadership.  I can add: I’d often wondered how John had time to travel the world, giving talks about quantum supremacy, while also managing the lab’s decisions on a day-to-day basis.  It looks now like I was right to wonder!  Potential analogies flood the mind: is this like a rock band that breaks up right after its breakout hit?  Is it like Steve Jobs leaving Apple?  Anyway, I wish the Google team the best in John’s absence, and I also wish John the best with whatever he does next.</p>



<p>I was never big on HBO (e.g., I still haven’t seen a single minute of <em>Game of Thrones</em>), but in the last couple of weeks, Dana and I found ourselves watching two absolutely compelling HBO shows—one a fictional miniseries and the other a documentary, but both on the theme of the fragility of American democracy.</p>



<p><a href="https://www.hbo.com/the-plot-against-america"><em>The Plot Against America</em></a>, based on the <a href="https://en.wikipedia.org/wiki/The_Plot_Against_America">2004 Philip Roth novel</a> of the same name (which Dana read and which I now plan to read), is about an alternate history where the aviator Charles Lindbergh defeats FDR in the 1940 presidential election, on a fascist and isolationist platform, in events that—as countless people have pointed out—are eerily, terrifyingly prescient of what would actualy befall the US in 2016.  The series follows a Jewish insurance salesman and his family in Newark, NJ—isn’t that what it always is with Philip Roth?—as they try to cope with the country’s gradual, all-too-plausible slide downward, from the genteel antisemitism that already existed in <em>our</em> timeline’s 1940 all the way to riots, assassinations, and pogroms (although never to an American Holocaust).  One of the series’ final images is of paper ballots, in a rematch presidential election, being carted away and burned, underscoring just how much depends here on the mundane machinery of democracy.</p>



<p>Which brings me to <a href="https://www.hbo.com/documentaries/kill-chain-the-cyber-war-on-americas-elections"><em>Kill Chain: The Cyber War on America’s Elections</em></a>, a documentary about the jaw-droppingly hackable electronic voting machines used in US elections and the fight to do something about them.  The show mostly follows the journey of <a href="https://en.wikipedia.org/wiki/Harri_Hursti">Harri Hursti</a>, a Finnish-born programmer who’s made this issue his life’s work, but it also extensively features my childhood best friend <a href="https://en.wikipedia.org/wiki/Alex_Halderman">Alex Halderman</a>.  OK, but isn’t this a theoretical issue, one that (perhaps rightly) exercises security nerds like Alex, but surely hasn’t changed the outcomes of actual elections?</p>



<p>Yeah, so about that.  You know Brian Kemp, the doofus governor of Georgia, who’s infamously announced plans to reopen the state right away, ignoring the pleading of public health experts—a  act that will fill Georgia’s ICUs and morgues as surely as night follows day?  And you know how Kemp defeated the Democrat, Stacey Abrams, by a razor-thin margin, in a 2018 election of which Kemp himself was the overseer?  It turns out that Kemp’s office distributed defective memory cards to African-American and Democratic precincts, though not to white and Republican ones.  There’s also striking statistical evidence that at least some voting machines were hacked, although because there was no paper trail it can never be proved.</p>



<p>In short, what <em>The Plot Against America</em> and <em>Kill Chain</em> have in common is that they <em>would be</em> desperately needed warnings about the ease with which democracy could collapse in the US, except for the detail that much of what they warn about has already happened, and now it’s not clear how we get back.</p></div>
    </content>
    <updated>2020-04-23T18:00:30Z</updated>
    <published>2020-04-23T18:00:30Z</published>
    <category scheme="https://www.scottaaronson.com/blog" term="Rage Against Doofosity"/>
    <category scheme="https://www.scottaaronson.com/blog" term="The Fate of Humanity"/>
    <author>
      <name>Scott</name>
      <uri>http://www.scottaaronson.com</uri>
    </author>
    <source>
      <id>https://www.scottaaronson.com/blog/?feed=atom</id>
      <link href="https://www.scottaaronson.com/blog" rel="alternate" type="text/html"/>
      <link href="https://www.scottaaronson.com/blog/?feed=atom" rel="self" type="application/atom+xml"/>
      <subtitle xml:lang="en-US">The Blog of Scott Aaronson</subtitle>
      <title xml:lang="en-US">Shtetl-Optimized</title>
      <updated>2020-04-23T18:03:42Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://tcsplus.wordpress.com/?p=426</id>
    <link href="https://tcsplus.wordpress.com/2020/04/23/tcs-talk-wednesday-april-29-sepideh-mahabadi-ttic/" rel="alternate" type="text/html"/>
    <title>TCS+ talk: Wednesday, April 29 — Sepideh Mahabadi, TTIC</title>
    <summary>The next TCS+ talk will take place this coming Wednesday, April 29th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). Sepideh Mahabadi from TTIC will speak about “Non-Adaptive Adaptive Sampling in Turnstile Streams” (abstract below). You can reserve a spot as an individual or a group to join […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next TCS+ talk will take place this coming Wednesday, April 29th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Sepideh Mahabadi</strong> from TTIC will speak about “<em>Non-Adaptive Adaptive Sampling in Turnstile Streams</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a>the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a>on our website</a> on the day of the talk, so people who did not sign up will still be able to watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a>suggest</a> a possible topic or speaker, please see <a>the website</a>.</p>
<blockquote><p>Abstract: Adaptive sampling is a useful algorithmic tool for data summarization problems in the classical centralized setting, where the entire dataset is available to the single processor performing the computation. Adaptive sampling repeatedly selects rows of an underlying <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0" title="n"/> by <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=fff&amp;fg=444444&amp;s=0" title="d"/> matrix <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=fff&amp;fg=444444&amp;s=0" title="A"/>, where <img alt="n \gg d" class="latex" src="https://s0.wp.com/latex.php?latex=n+%5Cgg+d&amp;bg=fff&amp;fg=444444&amp;s=0" title="n \gg d"/>, with probabilities proportional to their distances to the subspace of the previously selected rows. Intuitively, adaptive sampling seems to be limited to trivial multi-pass algorithms in the streaming model of computation due to its inherently sequential nature of assigning sampling probabilities to each row only after the previous iteration is completed. Surprisingly, we show this is not the case by giving the first one-pass algorithms for adaptive sampling on turnstile streams and using space <img alt="\text{poly}(d,k,\log n)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bpoly%7D%28d%2Ck%2C%5Clog+n%29&amp;bg=fff&amp;fg=444444&amp;s=0" title="\text{poly}(d,k,\log n)"/>, where <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0" title="k"/> is the number of adaptive sampling rounds to be performed.</p>
<p>Our adaptive sampling procedure has a number of applications to various data summarization problems on turnstile streams that either improve state-of-the-art or have only been previously studied in the more relaxed row-arrival model. This includes column subset selection, subspace approximation, projective clustering, and volume maximization. We complement our volume maximization algorithmic results with lower bounds that are tight up to lower order terms, even for multi-pass algorithms. By a similar construction, we also obtain lower bounds for volume maximization in the row-arrival model, which we match with competitive upper bounds.</p>
<p>This is a joint work with Ilya Razenshteyn, David Woodruff, and Samson Zhou.</p></blockquote></div>
    </content>
    <updated>2020-04-23T16:59:09Z</updated>
    <published>2020-04-23T16:59:09Z</published>
    <category term="Announcements"/>
    <author>
      <name>plustcs</name>
    </author>
    <source>
      <id>https://tcsplus.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A carbon-free dissemination of ideas across the globe.</subtitle>
      <title>TCS+</title>
      <updated>2020-04-27T13:21:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/055</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/055" rel="alternate" type="text/html"/>
    <title>TR20-055 |  Bounded Collusion Protocols, Cylinder-Intersection Extractors and Leakage-Resilient Secret Sharing | 

	Ashutosh Kumar, 

	Raghu Meka, 

	David Zuckerman</title>
    <summary>In this work we study bounded collusion protocols (BCPs) recently introduced in the context of secret sharing by Kumar, Meka, and Sahai (FOCS 2019). These are multi-party communication protocols on $n$ parties where in each round a subset of $p$-parties (the collusion bound) collude together and write a function of their inputs on a public blackboard. 

BCPs interpolate elegantly between the well-studied number-in-hand (NIH) model ($p=1$) and the number-on-forehead (NOF) model ($p=n-1$). Motivated by questions in communication complexity, secret sharing, and pseudorandomness we investigate BCPs more thoroughly answering several questions about them. 

* We prove a polynomial (in the input-length) lower bound for an explicit function against BCPs where any constant fraction of players can collude. Previously, non-trivial lower bounds were only known when the collusion bound was at most logarithmic in the input-length (owing to bottlenecks in NOF lower bounds). 

* For all $t \leq n$, we construct efficient $t$-out-of-$n$ secret sharing schemes where the secret remains hidden even given the transcript of a BCP with collusion bound $O(t/\log t)$. Prior work could only handle collusions of size $O(\log n)$. Along the way, we construct leakage-resilient schemes against disjoint and adaptive leakage,  resolving a question asked by Goyal and Kumar (STOC 2018).

* An explicit $n$-source cylinder intersection extractor whose output is close to uniform even when given the transcript of a BCP with a constant fraction of parties colluding. The min-entropy rate we require is $0.3$ (independent of collusion bound $p \ll n$). 

Our results rely on a new class of exponential sums that interpolate between the ones considered in additive combinatorics by Bourgain (Geometric and Functional Analysis 2009) and Petridis and Shparlinski (Journal d'Analyse Mathématique 2019).</summary>
    <updated>2020-04-23T09:54:31Z</updated>
    <published>2020-04-23T09:54:31Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-27T13:20:34Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/054</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/054" rel="alternate" type="text/html"/>
    <title>TR20-054 |  Communication Complexity with Defective Randomness  | 

	Marshall Ball, 

	Oded Goldreich, 

	Tal Malkin</title>
    <summary>Starting with the two standard model of randomized communication complexity, we study the communication complexity of functions when the protocol has access to a defective source of randomness. 
Specifically, we consider both the public-randomness and private-randomness cases, while replacing the commonly postulated perfect randomness with distributions over $\ell$ bit strings that have min-entropy at least $k\leq\ell$. 
We present general upper and lower bounds on the communication complexity in these cases, where the bounds are typically linear in $\ell-k$ and also depend on the size of the fooling set for the function being computed and on its standard randomized complexity.</summary>
    <updated>2020-04-22T19:02:32Z</updated>
    <published>2020-04-22T19:02:32Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-27T13:20:34Z</updated>
    </source>
  </entry>

  <entry>
    <id>tag:blogger.com,1999:blog-3722233.post-8100403263538580223</id>
    <link href="https://blog.computationalcomplexity.org/feeds/8100403263538580223/comments/default" rel="replies" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/complexity-vidcast-future-edition.html#comment-form" rel="replies" type="text/html"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8100403263538580223" rel="edit" type="application/atom+xml"/>
    <link href="https://www.blogger.com/feeds/3722233/posts/default/8100403263538580223" rel="self" type="application/atom+xml"/>
    <link href="https://blog.computationalcomplexity.org/2020/04/complexity-vidcast-future-edition.html" rel="alternate" type="text/html"/>
    <title>Complexity Vidcast - Future Edition</title>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">Bill and Lance aim to <a href="https://www.youtube.com/watch?v=4G2cxVRe0X8">talk about the future</a> but can't escape the present.<br/>
<br/>
<br/></div>
    </content>
    <updated>2020-04-22T18:28:00Z</updated>
    <published>2020-04-22T18:28:00Z</published>
    <author>
      <name>Lance Fortnow</name>
      <email>noreply@blogger.com</email>
      <uri>http://www.blogger.com/profile/06752030912874378610</uri>
    </author>
    <source>
      <id>tag:blogger.com,1999:blog-3722233</id>
      <category term="typecast"/>
      <category term="focs metacomments"/>
      <author>
        <name>Lance Fortnow</name>
        <email>noreply@blogger.com</email>
        <uri>http://www.blogger.com/profile/06752030912874378610</uri>
      </author>
      <link href="https://blog.computationalcomplexity.org/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default" rel="self" type="application/atom+xml"/>
      <link href="https://blog.computationalcomplexity.org/" rel="alternate" type="text/html"/>
      <link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/>
      <link href="https://www.blogger.com/feeds/3722233/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/>
      <subtitle>Computational Complexity and other fun stuff in math and computer science from Lance Fortnow and Bill Gasarch</subtitle>
      <title>Computational Complexity</title>
      <updated>2020-04-26T15:25:58Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1650</id>
    <link href="https://theorydish.blog/2020/04/22/private-libraries/" rel="alternate" type="text/html"/>
    <title>Reading in Private</title>
    <summary>(This blog post is based on joint work with Dima Kogan.) One of the great unsung perks of being a college student is having access to the university library. There is something thrilling about hunting down exactly the right reference deep in the stacks, or reading through the archived papers of a public figure from years back. The pandemic has closed all of our libraries for the time being. Even so, through the fruits of computer science—databases, the Internet, e-readers, and so on—we can get access to much of the same information even when we are cooped up at home. But for me, one of the true pleasures of using a library is the fact that I can browse through any book I want in complete privacy. If I want to go up to the stacks and read about tulip gardening, or road-bike maintenance, or strategies for managing anxiety, I can do that pretty much without anyone else knowing. In contrast, if I go online today and search for “tulip gardening,” Google will take careful note of my interest in tulips and I will be seeing ads about gardening tools for months. An ideal digital library would let us download [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><i>(This blog post is based on joint work with </i><a href="https://cs.stanford.edu/~dkogan/"><i>Dima Kogan</i></a><i>.)</i></p>
<p>One of the great unsung perks of being a college student is having access to the university library. There is something thrilling about hunting down exactly the right reference deep in the stacks, or reading through the archived papers of a public figure from years back.</p>
<p>The pandemic has closed all of our libraries for the time being. Even so, through the fruits of computer science—databases, the Internet, e-readers, and so on—we can get access to much of the same information even when we are cooped up at home.</p>
<p>But for me, one of the true pleasures of using a library is the fact that I can browse through any book I want in complete privacy. If I want to go up to the stacks and read about tulip gardening, or road-bike maintenance, or strategies for managing anxiety, I can do that pretty much without anyone else knowing.</p>
<p>In contrast, if I go online today and search for “tulip gardening,” Google will take careful note of my interest in tulips and I will be seeing ads about gardening tools for months.</p>
<p>An ideal digital library would let us download and read books without anyone—not even the library itself—learning which books we are reading. How could we build such a privacy-respecting digital library?</p>
<p>In this post, we will discuss the private-library problem and how <a href="https://eprint.iacr.org/2019/1075">our recent work on private information retrieval</a> might be able to help solve it.</p>
<h3><b>The Private-Library Problem</b></h3>
<p>Let us define the problem a little more precisely. We will imagine a protocol running between a library, which holds the books, and a student, who wants to download a particular book.</p>
<p>Say that the library has <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/> books—let’s call the books <img alt="x=(x_1, \dots, x_N)" class="latex" src="https://s0.wp.com/latex.php?latex=x%3D%28x_1%2C+%5Cdots%2C+x_N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x=(x_1, \dots, x_N)"/>. To keep things simple, let’s pretend that each book consists of just a single bit of information, so <img alt="x_i \in \{0,1\}" class="latex" src="https://s0.wp.com/latex.php?latex=x_i+%5Cin+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_i \in \{0,1\}"/> for all <img alt="i \in \{1, \dots, N\}" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i \in \{1, \dots, N\}"/>.</p>
<p>The student starts out holding the index <img alt="i \in \{1, \dots, N\}" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i \in \{1, \dots, N\}"/> of her desired book. To fetch the digital book from the library, the student and library exchange some messages. At the end of the interaction, we want the following two properties to hold:</p>
<ul>
<li><b>Correctness.</b> The student should have her desired book (i.e., the bit <img alt="x_i" class="latex" src="https://s0.wp.com/latex.php?latex=x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x_i"/>).</li>
<li><b>Privacy. </b>The library should have not learned any information, in a cryptographic sense, about which book the student downloaded.</li>
</ul>
<p>Of course, we have grossly simplified the problem: a real book is more than a single bit in length, book titles are not consecutive integers, maybe the student would like to find a book using a keyword search, etc. But even this simplified private-information-retrieval problem, which <a href="http://www.tau.ac.il/~bchor/PIR.pdf">Chor, Goldreich, Kushilevitz, and Sudan introduced</a> in the 90s, is already interesting enough.</p>
<h3><b>A simple but inefficient solution</b></h3>
<p>There is a simple solution to this problem: the student can just ask the library to send her the contents of all <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/> books. This solution achieves both correctness and privacy, so what’s the problem? Are we done?</p>
<p>Well, there are two problems:</p>
<ol>
<li>The amount of <b>communication</b> is large: Just to read a single book, the client must download the contents of the entire library! So this is terribly inefficient.</li>
<li>The amount of <b>computation</b> is large: Just to fetch a single book, the library must do work proportional to the size of the entire library. So “checking out” a book from this digital library will take a long time.</li>
</ol>
<p>Research on private information retrieval typically focuses on the first problem: how can we reduce the <i>communication</i> cost? Using a <a href="https://dl.acm.org/doi/abs/10.1145/2968443">variety</a> of <a href="https://ieeexplore.ieee.org/abstract/document/646125">clever</a> <a href="https://dl.acm.org/doi/abs/10.1145/2976749.2978429">techniques</a>, it is possible to drive down the communication cost to something very small—sub-polynomial or even logarithmic in the library size <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/>.</p>
<p>But today we are interested in the <i>computational</i> burden on the library. Is there any way that the student can privately download a book from the library while requiring the library to do only <img alt="o(N)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="o(N)"/> work in the process?</p>
<h3><b>Doing the hard work in advance</b></h3>
<p>To have both correctness and privacy, it seems that the library needs to touch each of the <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/> books in the process of responding to each student’s request. And, in some sense, <a href="http://groups.csail.mit.edu/cis/pubs/malkin/BIM.ps">this is true</a>. So, to allow the library to run in time sublinear in <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/>, we will have to tweak the problem slightly.</p>
<p>Our idea is to have the library do the <img alt="O(N)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(N)"/>-time computation in an <b>offline phase</b>, which takes place <i>before</i> the student decides which book she wants to read. For example, this offline phase might happen overnight while the library’s servers would otherwise be idle.</p>
<p>Later on, once the student decides which book in the library she wants to read, the student and library can run a <img alt="o(N)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="o(N)"/>-time <b>online phase</b> in which the student is able to retrieve her desired book. The total communication cost, in both offline and online phases, will be <img alt="o(N)" class="latex" src="https://s0.wp.com/latex.php?latex=o%28N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="o(N)"/>.</p>
<p>So, by pushing the library’s expensive linear scan to an offline phase, the library can service the student’s request for a book in sublinear online time.</p>
<h3><b>Our offline/online private information retrieval scheme</b></h3>
<p>Let’s see how to construct such an offline/online scheme. To make things simple for the purposes of this post, let’s assume that the student has access to two non-colluding libraries that hold the same set of books. To be concrete, let’s call the two libraries “Stanford” and “Berkeley.”</p>
<p>The privacy property will hold as long as the librarians at Stanford and Berkeley don’t get together and share the information that they learned while running the protocol with the student. So Stanford and Berkeley here are “non-colluding.” (Equivalently, our scheme that protects privacy against an adversary that controls one of the two libraries—but not both.)</p>
<div class="wp-caption aligncenter" id="attachment_1670" style="width: 571px;"><img alt="Offline-online PIR" class=" wp-image-1670" height="365" src="https://theorydish.files.wordpress.com/2020/04/offlineonline.png?w=561&amp;h=365" width="561"/><p class="wp-caption-text" id="caption-attachment-1670">In the offline phase, which happens before the student knows which book she wants to read, the Stanford library does linear work. In the online phase, which runs once the student has the index of her desired book, the Berkeley library runs in sublinear time. (We are suppressing log factors here.)</p></div>
<p>Now, let’s describe an offline/online protocol by which the student can privately fetch a book from the digital library:</p>
<p><b>Offline Phase.</b></p>
<ul>
<li>The student partitions the integers <img alt="\{1, .., N\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C+..%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{1, .., N\}"/> into <img alt="\sqrt{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\sqrt{N}"/> non-overlapping sets chosen at random, where each set has size <img alt="\sqrt{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\sqrt{N}"/>. Call these sets <img alt="S_1, \dots, S_{\sqrt{N}}" class="latex" src="https://s0.wp.com/latex.php?latex=S_1%2C+%5Cdots%2C+S_%7B%5Csqrt%7BN%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_1, \dots, S_{\sqrt{N}}"/>.</li>
<li>The student sends these sets <img alt="S_1, \dots, S_{\sqrt{N}}" class="latex" src="https://s0.wp.com/latex.php?latex=S_1%2C+%5Cdots%2C+S_%7B%5Csqrt%7BN%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_1, \dots, S_{\sqrt{N}}"/> to Stanford (the first library). To reduce the communication cost here, the student can compress these sets using pseudorandomness.</li>
<li>For each set <img alt="S_j" class="latex" src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_j"/>, the Stanford library computes the <i>parity</i> of all of the books indexed by set <img alt="S_j" class="latex" src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_j"/> and returns the parity bits <img alt="(b_1, \dots, b_{\sqrt{N}})" class="latex" src="https://s0.wp.com/latex.php?latex=%28b_1%2C+%5Cdots%2C+b_%7B%5Csqrt%7BN%7D%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(b_1, \dots, b_{\sqrt{N}})"/> to the student. In other words, if the books are <img alt="x=(x_1, \dots, x_N) \in \{0,1\}^n" class="latex" src="https://s0.wp.com/latex.php?latex=x%3D%28x_1%2C+%5Cdots%2C+x_N%29+%5Cin+%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="x=(x_1, \dots, x_N) \in \{0,1\}^n"/>, then <img alt="b_j = \sum_{k \in S_j} x_k \bmod 2" class="latex" src="https://s0.wp.com/latex.php?latex=b_j+%3D+%5Csum_%7Bk+%5Cin+S_j%7D+x_k+%5Cbmod+2&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="b_j = \sum_{k \in S_j} x_k \bmod 2"/>.</li>
</ul>
<p>The total communication in this phase is only <img alt="O(\sqrt{N})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(\sqrt{N})"/> bits and the student and the Stanford library can run this step <i>before</i> the student decides which book she wants to read.</p>
<p><b>Online Phase.</b> Once the student decides that she wants to read book <img alt="i \in \{1, \dots, N\}" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i \in \{1, \dots, N\}"/>, the student and Berkeley (the second library) run the following steps:</p>
<ul>
<li>The student finds the set <img alt="S_j" class="latex" src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_j"/> that contains the index <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/> of her desired book.</li>
<li>The student flips a coin that is weighted to come up heads with some probability <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p"/>, to be fixed later.</li>
<li>If the coin lands <span style="text-decoration: underline;">heads</span>:
<ul>
<li>The student sends <img alt="S \gets S_j \setminus \{i\}" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Cgets+S_j+%5Csetminus+%5C%7Bi%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S \gets S_j \setminus \{i\}"/> to the Berkeley library.</li>
</ul>
</li>
<li>If the coin lands <span style="text-decoration: underline;">tails</span>:
<ul>
<li>The student samples <img alt="i' \gets_R S_j \setminus \{i\}" class="latex" src="https://s0.wp.com/latex.php?latex=i%27+%5Cgets_R+S_j+%5Csetminus+%5C%7Bi%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i' \gets_R S_j \setminus \{i\}"/>.</li>
<li>The student sends <img alt="S \gets S_j \setminus \{i'\}" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Cgets+S_j+%5Csetminus+%5C%7Bi%27%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S \gets S_j \setminus \{i'\}"/> to the Berkeley library.</li>
</ul>
</li>
<li>The Berkeley library receives the set <img alt="S \subseteq \{1, \dots, N\}" class="latex" src="https://s0.wp.com/latex.php?latex=S+%5Csubseteq+%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S \subseteq \{1, \dots, N\}"/> from the student. The Berkeley library returns the contents of all books whose indices appear in set <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S"/> to the student.</li>
<li>Now, the student can recover its desired book as follows:
<ul>
<li>If <span style="text-decoration: underline;">heads</span>: the student now has the parity of the books in <img alt="S_j" class="latex" src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_j"/> (from the offline phase) and the value of all books in <img alt="S_j" class="latex" src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S_j"/> that are not book <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/>. This is enough to recover the contents of book <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/>.</li>
<li>If <span style="text-decoration: underline;">tails</span>: <img alt="i \in S" class="latex" src="https://s0.wp.com/latex.php?latex=i+%5Cin+S&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i \in S"/>. In this case the Berkeley library has sent the contents of book <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/> to the student in the online phase.</li>
</ul>
</li>
</ul>
<p>Even before we fix the weight <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p"/> of the coin, we see that the protocol satisfies <b>correctness</b>, since no matter how the coin lands the client recovers its desired book. Also, the total communication cost is <img alt="O(\sqrt{N} \log N)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%7D+%5Clog+N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(\sqrt{N} \log N)"/> bits, which is sublinear as we had hoped. Finally, the <b>online computation cost</b> is also sublinear: the Berkeley library just needs to return <img alt="\sqrt{N}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Csqrt%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\sqrt{N}"/> books to the client, which it can do in time roughly <img alt="O(\sqrt{N})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(\sqrt{N})"/>.</p>
<p>The last matter to address is <b>privacy</b>. Again, we are assuming that the adversary controls only one of the two libraries.</p>
<ul>
<li>In the offline phase, the student’s message to the Stanford library is independent of <img alt="i" class="latex" src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="i"/>, so the protocol is perfectly private with respect to Stanford.</li>
<li>In the online phase, we must be more careful. It turns out that if we choose the weight <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p"/> of the coin as <img alt="p = 1 - (\sqrt{N} - 1)/N" class="latex" src="https://s0.wp.com/latex.php?latex=p+%3D+1+-+%28%5Csqrt%7BN%7D+-+1%29%2FN&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="p = 1 - (\sqrt{N} - 1)/N"/>, then the set <img alt="S" class="latex" src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="S"/> that the student sends to UC Berkeley in the online phase is just a uniformly random size-<img alt="(\sqrt{N}-1)" class="latex" src="https://s0.wp.com/latex.php?latex=%28%5Csqrt%7BN%7D-1%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(\sqrt{N}-1)"/> subset of <img alt="\{1, \dots, N\}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\{1, \dots, N\}"/>.</li>
</ul>
<h3><b>Open problems</b></h3>
<p>So, the student can privately fetch a book from our digital libraries in sublinear online time. What else is left to do?</p>
<ul>
<li>Getting rid of the need for two non-colluding libraries is a clear next step. <a href="https://eprint.iacr.org/2019/1075">Our work</a> has some results along these lines, but they pay a price either in (a) asymptotic efficiency or in (b) the strength of the cryptographic assumptions required.</li>
<li>A beautiful paper of <a href="https://www.cs.bgu.ac.il/~beimel/Papers/BIM.pdf">Beimel, Ishai, and Malkin</a> shows that if the library can store its collection of books using a special type of error-correcting encoding, the <b>total</b> computational time at the libraries (not just the online time) can be sublinear in <img alt="N" class="latex" src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="N"/>. As far as we know, these schemes are not concretely efficient enough to use in practice. Could they be made so?</li>
<li>Privacy is just one of the many pleasures of using a physical library. During this period of confinement, I also miss the smell of the books, the beauty of light filtering through the stacks, and the peacefulness of thinking in a study carrel. Can a digital library ever give us these things too?</li>
</ul>
<p>If any of these questions catch your fancy, please check out <a href="https://eprint.iacr.org/2019/1075">our Eurocrypt paper</a> for more background, pointers, and results.</p>
<p>Don Knuth <a href="http://jmlr.csail.mit.edu/reviewing-papers/knuth_mathematical_writing.pdf">has reportedly said</a> “Using a great library to solve a specific problem… Now <i>that</i> […] is real living.” With better digital libraries, maybe we could all live a little bit more during these challenging days.</p></div>
    </content>
    <updated>2020-04-22T07:07:04Z</updated>
    <published>2020-04-22T07:07:04Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Henry Corrigan-Gibbs</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-04-27T13:21:27Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://agtb.wordpress.com/?p=3472</id>
    <link href="https://agtb.wordpress.com/2020/04/21/ec-2020-will-be-virtual/" rel="alternate" type="text/html"/>
    <title>SIGecom Announcement: EC 2020 will be virtual</title>
    <summary>As many of you have probably anticipated, due to concerns regarding the novel coronavirus COVID-19, the 2020 ACM Conference on Economics and Computation (EC 2020) will be held virtually. This change of format will of course present us with difficult challenges, but we believe it will offer exciting new opportunities as well.  (And not to […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>As many of you have probably anticipated, due to concerns regarding the novel coronavirus COVID-19, the <a href="http://ec20.sigecom.org/">2020 ACM Conference on Economics and Computation (EC 2020)</a> will be held virtually.</p>
<p>This change of format will of course present us with difficult challenges, but we believe it will offer exciting new opportunities as well.  (And not to worry, your opportunity to attend EC in Budapest is just deferred to 2021.)</p>
<p>The <a href="http://sigecom.org/officers.html">SIGecom Executive Committee</a> has appointed and will serve on a Virtual Transition Team that additionally includes the following new conference officers:</p>
<ul>
<li>Virtual General Chair: <a href="https://sites.northwestern.edu/hartline/">Jason Hartline</a></li>
<li>Virtual Local Chair: <a href="https://yannai.gonch.name/">Yannai Gonczarowski</a></li>
<li>Virtual Global Outreach Chairs: <a href="https://www.cs.cornell.edu/~red/">Rediet Abebe</a> and <a href="https://research.fb.com/people/sodomka-eric/">Eric Sodomka</a></li>
</ul>
<p>This team is working with the <a href="http://ec20.sigecom.org/committees-acm/organizing-committee/">EC 2020 organizing committee</a> and <a href="http://ec20.sigecom.org/committees-acm/program-committee/">EC 2020 PC chairs</a> to put together a plan that leverages the opportunities of the virtual format to the fullest extent. Though these plans are still in the works, we have identified the following “minimal commitment” for authors of accepted papers to the main EC conference: at least one author will need to</p>
<ul>
<li>register for the conference;</li>
<li>be available virtually on the conference dates (July 14-16);</li>
<li>provide a camera-ready paper or abstract by the camera-ready deadline;</li>
<li>provide a pre-recorded talk presenting the paper two weeks in advance (by June 28).</li>
</ul>
<p>We are optimistic that, while a virtual EC may lack some of the positive features of a classical conference, the format will also provide opportunities that improve on the classical experience.  As with any conference there will be opportunities to participate beyond the “minimal commitment.”  We hope that speakers and participants will join in other activities, which may include preview sessions for talks before the conference proper, watch parties for speakers and attendees, and mechanisms for reaching a wider audience with the technical program. With many academic interactions moving virtual, the barriers to collaboration with distant colleagues have lowered, and we hope that EC 2020 will kindle and rekindle global collaborations.</p>
<div>
<p>Further details about these activities as well as the minimal requirements will be circulated by June 1.</p>
<p>Tutorial speakers and workshop organizers will receive separate emails from the Tutorial and Workshop Chairs about plans for moving these events online.</p>
</div></div>
    </content>
    <updated>2020-04-21T14:05:08Z</updated>
    <published>2020-04-21T14:05:08Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Jason Hartline</name>
    </author>
    <source>
      <id>https://agtb.wordpress.com</id>
      <logo>https://secure.gravatar.com/blavatar/52ef314e11e379febf97d1a97547f4cd?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fbuttonw-com.png</logo>
      <link href="https://agtb.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://agtb.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://agtb.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://agtb.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Computation, Economics, and Game Theory</subtitle>
      <title>Turing's Invisible Hand</title>
      <updated>2020-04-27T13:20:41Z</updated>
    </source>
  </entry>
</feed>
