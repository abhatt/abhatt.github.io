<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/" xmlns:indexing="urn:atom-extension:indexing" indexing:index="no"><access:restriction xmlns:access="http://www.bloglines.com/about/specs/fac-1.0" relationship="deny"/>
  <title>Theory of Computing Blog Aggregator</title>
  <updated>2020-04-28T14:21:52Z</updated>
  <generator uri="http://intertwingly.net/code/venus/">Venus</generator>
  <author>
    <name>Arnab Bhattacharyya, Suresh Venkatasubramanian</name>
    <email>arbhat+cstheoryfeed@gmail.com</email>
  </author>
  <id>http://www.cstheory-feed.org/atom.xml</id>
  <link href="http://www.cstheory-feed.org/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="http://www.cstheory-feed.org/" rel="alternate"/>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/061</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/061" rel="alternate" type="text/html"/>
    <title>TR20-061 |  Tree-depth and the Formula Complexity of Subgraph Isomorphism | 

	Benjamin Rossman, 

	Deepanshu Kush</title>
    <summary>For a fixed "pattern" graph $G$, the $\textit{colored}$ $G\textit{-subgraph isomorphism problem}$ (denoted $\mathrm{SUB}(G)$) asks, given an $n$-vertex graph $H$ and a coloring $V(H) \to V(G)$, whether $H$ contains a properly colored copy of $G$. The complexity of this problem is tied to parameterized versions of $\mathit{P}$ ${=}?$ $\mathit{NP}$ and $\mathit{L}$ ${=}?$ $\mathit{NL}$, among other questions. An overarching goal is to understand the complexity of $\mathrm{SUB}(G)$, under different computational models, in terms of natural invariants of the pattern graph $G$.

In this paper, we establish a close relationship between the $\textit{formula complexity}$ of $\mathrm{SUB}$ and an invariant known as $\textit{tree-depth}$ (denoted $\mathrm{td}(G)$). $\mathrm{SUB}(G)$ is known to be solvable by monotone $\mathit{AC^0}$ formulas of size $O(n^{\mathrm{td}(G)})$. Our main result is an $n^{\tilde\Omega(\mathrm{td}(G)^{1/3})}$ lower bound for formulas that are monotone $\textit{or}$ have sub-logarithmic depth. This complements a lower bound of Li, Razborov and Rossman (SICOMP 2017) relating tree-width and $\mathit{AC^0}$ circuit size. As a corollary, it implies a stronger homomorphism preservation theorem for first-order logic on finite structures (Rossman, ITCS 2017).

The technical core of this result is an $n^{\Omega(k)}$ lower bound in the special case where $G$ is a complete binary tree of height $k$, which we establish using the $\textit{pathset framework}$ introduced in (Rossman, SICOMP 2018). (The lower bound for general patterns follows via a recent excluded-minor characterization of tree-depth (Czerwi\'nski et al, arXiv:1904.13077).) Additional results of this paper extend the pathset framework and improve upon both, the best known upper and lower bounds on the average-case formula size of $\mathrm{SUB}(G)$ when $G$ is a path.</summary>
    <updated>2020-04-28T11:49:13Z</updated>
    <published>2020-04-28T11:49:13Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-28T14:20:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://cstheory-jobs.org/2020/04/28/tenure-track-assistant-associate-or-full-professor-theory-of-computation-at-university-of-groningen-the-netherlands-apply-by-may-5-2020/</id>
    <link href="https://cstheory-jobs.org/2020/04/28/tenure-track-assistant-associate-or-full-professor-theory-of-computation-at-university-of-groningen-the-netherlands-apply-by-may-5-2020/" rel="alternate" type="text/html"/>
    <title>Tenure Track Assistant, Associate or Full Professor Theory of Computation at University of Groningen, the Netherlands  (apply by May 5, 2020)</title>
    <summary>The University of Groningen seeks for an outward looking researcher in Computer Science who will perform research on theory of computation, broadly construed, in relation to new (neuromorphic) computing systems and architectures. We offer a challenging position in a unique world-class research environment, where close collaborations between research groups with different expertise are encouraged. Website: […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The University of Groningen seeks for an outward looking researcher in Computer Science who will perform research on theory of computation, broadly construed, in relation to new (neuromorphic) computing systems and architectures. We offer a challenging position in a unique world-class research environment, where close collaborations between research groups with different expertise are encouraged.</p>
<p>Website: <a href="https://www.rug.nl/about-ug/work-with-us/job-opportunities/?details=00347-02S0007KLP">https://www.rug.nl/about-ug/work-with-us/job-opportunities/?details=00347-02S0007KLP</a><br/>
Email: b.noheda@rug.nl, j.b.t.m.roerdink@rug.nl and/or j.h.m.van.der.velde@rug.nl</p></div>
    </content>
    <updated>2020-04-28T08:50:14Z</updated>
    <published>2020-04-28T08:50:14Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>shacharlovett</name>
    </author>
    <source>
      <id>https://cstheory-jobs.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://cstheory-jobs.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://cstheory-jobs.org" rel="alternate" type="text/html"/>
      <link href="https://cstheory-jobs.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://cstheory-jobs.org/?pushpress=hub" rel="hub" type="text/html"/>
      <title>Theoretical Computer Science Jobs</title>
      <updated>2020-04-28T14:20:39Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12683</id>
    <link href="http://arxiv.org/abs/2004.12683" rel="alternate" type="text/html"/>
    <title>Approximate Turing Kernelization for Problems Parameterized by Treewidth</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hols:Eva=Maria_C=.html">Eva-Maria C. Hols</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kratsch:Stefan.html">Stefan Kratsch</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pieterse:Astrid.html">Astrid Pieterse</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12683">PDF</a><br/><b>Abstract: </b>We extend the notion of lossy kernelization, introduced by Lokshtanov et al.
[STOC 2017], to approximate Turing kernelization. An $\alpha$-approximate
Turing kernel for a parameterized optimization problem is a polynomial-time
algorithm that, when given access to an oracle that outputs $c$-approximate
solutions in $O(1)$ time, obtains an $(\alpha \cdot c)$-approximate solution to
the considered problem, using calls to the oracle of size at most $f(k)$ for
some function $f$ that only depends on the parameter.
</p>
<p>Using this definition, we show that Independent Set parameterized by
treewidth $\ell$ has a $(1+\varepsilon)$-approximate Turing kernel with
$O(\frac{\ell^2}{\varepsilon})$ vertices, answering an open question posed by
Lokshtanov et al. [STOC 2017]. Furthermore, we give
$(1+\varepsilon)$-approximate Turing kernels for the following graph problems
parameterized by treewidth: Vertex Cover, Edge Clique Cover, Edge-Disjoint
Triangle Packing and Connected Vertex Cover.
</p>
<p>We generalize the result for Independent Set and Vertex Cover, by showing
that all graph problems that we will call "friendly" admit
$(1+\varepsilon)$-approximate Turing kernels of polynomial size when
parameterized by treewidth. We use this to obtain approximate Turing kernels
for Vertex-Disjoint $H$-packing for connected graphs $H$, Clique Cover,
Feedback Vertex Set and Edge Dominating Set.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12667</id>
    <link href="http://arxiv.org/abs/2004.12667" rel="alternate" type="text/html"/>
    <title>Robust Algorithms under Adversarial Injections</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garg:Paritosh.html">Paritosh Garg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kale:Sagar.html">Sagar Kale</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rohwedder:Lars.html">Lars Rohwedder</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Svensson:Ola.html">Ola Svensson</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12667">PDF</a><br/><b>Abstract: </b>In this paper, we study streaming and online algorithms in the context of
randomness in the input. For several problems, a random order of the input
sequence---as opposed to the worst-case order---appears to be a necessary evil
in order to prove satisfying guarantees. However, algorithmic techniques that
work under this assumption tend to be vulnerable to even small changes in the
distribution. For this reason, we propose a new \emph{adversarial injections}
model, in which the input is ordered randomly, but an adversary may inject
misleading elements at arbitrary positions. We believe that studying algorithms
under this much weaker assumption can lead to new insights and, in particular,
more robust algorithms. We investigate two classical combinatorial-optimization
problems in this model: Maximum matching and cardinality constrained monotone
submodular function maximization. Our main technical contribution is a novel
streaming algorithm for the latter that computes a $0.55$-approximation. While
the algorithm itself is clean and simple, an involved analysis shows that it
emulates a subdivision of the input stream which can be used to greatly limit
the power of the adversary.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12646</id>
    <link href="http://arxiv.org/abs/2004.12646" rel="alternate" type="text/html"/>
    <title>Input-Sparsity Low Rank Approximation in Schatten Norm</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Yi.html">Yi Li</a>, David Woodruff <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12646">PDF</a><br/><b>Abstract: </b>We give the first input-sparsity time algorithms for the rank-$k$ low rank
approximation problem in every Schatten norm. Specifically, for a given
$n\times n$ matrix $A$, our algorithm computes $Y,Z\in \mathbb{R}^{n\times k}$,
which, with high probability, satisfy $\|A-YZ^T\|_p \leq
(1+\epsilon)\|A-A_k\|_p$, where $\|M\|_p = \left (\sum_{i=1}^n \sigma_i(M)^p
\right )^{1/p}$ is the Schatten $p$-norm of a matrix $M$ with singular values
$\sigma_1(M), \ldots, \sigma_n(M)$, and where $A_k$ is the best rank-$k$
approximation to $A$. Our algorithm runs in time
$\tilde{O}(\operatorname{nnz}(A) +
n^{\alpha_p}\operatorname{poly}(k/\epsilon))$, where $\alpha_p = 1$ for $p\in
[1,2)$ and $\alpha_p = 1 + (\omega-1)(1-2/p)$ for $p&gt;2$ and $\omega \approx
2.374$ is the exponent of matrix multiplication. For the important case of $p =
1$, which corresponds to the more "robust" nuclear norm, we obtain
$\tilde{O}(\operatorname{nnz}(A) + n \cdot \operatorname{poly}(k/\epsilon))$
time, which was previously only known for the Frobenius norm ($p = 2$).
Moreover, since $\alpha_p &lt; \omega$ for every $p$, our algorithm has a better
dependence on $n$ than that in the singular value decomposition for every $p$.
Crucial to our analysis is the use of dimensionality reduction for Ky-Fan
$p$-norms.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12633</id>
    <link href="http://arxiv.org/abs/2004.12633" rel="alternate" type="text/html"/>
    <title>On Perturbation Resilience of Non-Uniform $k$-Center</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bandyapadhyay:Sayan.html">Sayan Bandyapadhyay</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12633">PDF</a><br/><b>Abstract: </b>The Non-Uniform $k$-center (NUkC) problem has recently been formulated by
Chakrabarty, Goyal and Krishnaswamy [ICALP, 2016] as a generalization of the
classical $k$-center clustering problem. In NUkC, given a set of $n$ points $P$
in a metric space and non-negative numbers $r_1, r_2, \ldots , r_k$, the goal
is to find the minimum dilation $\alpha$ and to choose $k$ balls centered at
the points of $P$ with radius $\alpha\cdot r_i$ for $1\le i\le k$, such that
all points of $P$ are contained in the union of the chosen balls. They showed
that the problem is NP-hard to approximate within any factor even in tree
metrics. On the other hand, they designed a "bi-criteria" constant
approximation algorithm that uses a constant times $k$ balls. Surprisingly, no
true approximation is known even in the special case when the $r_i$'s belong to
a fixed set of size 3. In this paper, we study the NUkC problem under
perturbation resilience, which was introduced by Bilu and Linial
[Combinatorics, Probability and Computing, 2012]. We show that the problem
under 2-perturbation resilience is polynomial time solvable when the $r_i$'s
belong to a constant sized set. However, we show that perturbation resilience
does not help in the general case. In particular, our findings imply that even
with perturbation resilience one cannot hope to find any "good" approximation
for the problem.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12590</id>
    <link href="http://arxiv.org/abs/2004.12590" rel="alternate" type="text/html"/>
    <title>In-Place Bijective Burrows-Wheeler Transforms</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/K=ouml=ppl:Dominik.html">Dominik Köppl</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hashimoto:Daiki.html">Daiki Hashimoto</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hendrian:Diptarama.html">Diptarama Hendrian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shinohara:Ayumi.html">Ayumi Shinohara</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12590">PDF</a><br/><b>Abstract: </b>One of the most well-known variants of the Burrows-Wheeler transform (BWT)
[Burrows and Wheeler, 1994] is the bijective BWT (BBWT) [Gil and Scott, arXiv
2012], which applies the extended BWT (EBWT) [Mantaci et al., TCS 2007] to the
multiset of Lyndon factors of a given text. Since the EBWT is invertible, the
BBWT is a bijective transform in the sense that the inverse image of the EBWT
restores this multiset of Lyndon factors such that the original text can be
obtained by sorting these factors in non-increasing order. In this paper, we
present algorithms constructing or inverting the BBWT in-place using quadratic
time. We also present conversions from the BBWT to the BWT, or vice versa,
either (a) in-place using quadratic time, or (b) in the run-length compressed
setting using $O(n \lg r / \lg \lg r)$ time with $O(r \lg n)$ bits of words,
where $r$ is the sum of character runs in the BWT and the BBWT.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12532</id>
    <link href="http://arxiv.org/abs/2004.12532" rel="alternate" type="text/html"/>
    <title>In-Place Parallel-Partition Algorithms using Exclusive-Read-and-Write Memory: An In-Place Algorithm With Provably Optimal Cache Behavior</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuszmaul:William.html">William Kuszmaul</a>, Alek Westover <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12532">PDF</a><br/><b>Abstract: </b>We present an in-place algorithm for the parallel partition problem that has
linear work and polylogarithmic span. The algorithm uses only exclusive
read/write shared variables, and can be implemented using parallel-for-loops
without any additional concurrency considerations (i.e., the algorithm is
EREW). A key feature of the algorithm is that it exhibits provably optimal
cache behavior, up to small-order factors.
</p>
<p>We also present a second in-place EREW algorithm that has linear work and
span $O(\log n \cdot \log \log n)$, which is within an $O(\log\log n)$ factor
of the optimal span. By using this low-span algorithm as a subroutine within
the cache-friendly algorithm, we are able to obtain a single EREW algorithm
that combines their theoretical guarantees: the algorithm achieves span $O(\log
n \cdot \log \log n)$ and optimal cache behavior. As an immediate consequence,
we also get an in-place EREW quicksort algorithm with work $O(n \log n)$, span
$O(\log^2 n \cdot \log \log n)$.
</p>
<p>Whereas the standard EREW algorithm for parallel partitioning is
memory-bandwidth bound on large numbers of cores, our cache-friendly algorithm
is able to achieve near-ideal scaling in practice by avoiding the
memory-bandwidth bottleneck. The algorithm's performance is comparable to that
of the Blocked Strided Algorithm of Francis, Pannan, Frias, and Petit, which is
the previous state-of-the art for parallel EREW sorting algorithms, but which
lacks theoretical guarantees on its span and cache behavior.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12497</id>
    <link href="http://arxiv.org/abs/2004.12497" rel="alternate" type="text/html"/>
    <title>Forty New Invariants of N-Periodics in the Elliptic Billiard</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Reznik:Dan.html">Dan Reznik</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garcia:Ronaldo.html">Ronaldo Garcia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koiller:Jair.html">Jair Koiller</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12497">PDF</a><br/><b>Abstract: </b>We present some 40 newfound invariants displayed by N-periodics in the
Elliptic Billiard, obtained through experimental exploration. These involve
distances, areas, angles and centers of mass of N-periodics and associated
polygons (inner, outer, pedal, antipedal). Some depend on the parity of N,
others on other positional constraints. A few invariants have already been
proven with elegant tools of Analytic and Algebraic Geometry. We welcome reader
input to add to the list of proofs.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12496</id>
    <link href="http://arxiv.org/abs/2004.12496" rel="alternate" type="text/html"/>
    <title>Learning and Testing Junta Distributions with Subcube Conditioning</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Xi.html">Xi Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jayaram:Rajesh.html">Rajesh Jayaram</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levi:Amit.html">Amit Levi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Waingarten:Erik.html">Erik Waingarten</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12496">PDF</a><br/><b>Abstract: </b>We study the problems of learning and testing junta distributions on
$\{-1,1\}^n$ with respect to the uniform distribution, where a distribution $p$
is a $k$-junta if its probability mass function $p(x)$ depends on a subset of
at most $k$ variables. The main contribution is an algorithm for finding
relevant coordinates in a $k$-junta distribution with subcube conditioning
[BC18, CCKLW20]. We give two applications:
</p>
<p>1. An algorithm for learning $k$-junta distributions with
$\tilde{O}(k/\epsilon^2) \log n + O(2^k/\epsilon^2)$ subcube conditioning
queries, and
</p>
<p>2. An algorithm for testing $k$-junta distributions with $\tilde{O}((k +
\sqrt{n})/\epsilon^2)$ subcube conditioning queries.
</p>
<p>All our algorithms are optimal up to poly-logarithmic factors.
</p>
<p>Our results show that subcube conditioning, as a natural model for accessing
high-dimensional distributions, enables significant savings in learning and
testing junta distributions compared to the standard sampling model. This
addresses an open question posed by Aliakbarpour, Blais, and Rubinfeld [ABR17].
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12465</id>
    <link href="http://arxiv.org/abs/2004.12465" rel="alternate" type="text/html"/>
    <title>Succinct Filters for Sets of Unknown Sizes</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Mingmou.html">Mingmou Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yin:Yitong.html">Yitong Yin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Huacheng.html">Huacheng Yu</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12465">PDF</a><br/><b>Abstract: </b>The membership problem asks to maintain a set $S\subseteq[u]$, supporting
insertions and membership queries, i.e., testing if a given element is in the
set. A data structure that computes exact answers is called a dictionary. When
a (small) false positive rate $\epsilon$ is allowed, the data structure is
called a filter.
</p>
<p>The space usages of the standard dictionaries or filters usually depend on
the upper bound on the size of $S$, while the actual set can be much smaller.
</p>
<p>Pagh, Segev and Wieder (FOCS'13) were the first to study filters with varying
space usage based on the current $|S|$. They showed in order to match the space
with the current set size $n=|S|$, any filter data structure must use
$(1-o(1))n(\log(1/\epsilon)+(1-O(\epsilon))\log\log n)$ bits, in contrast to
the well-known lower bound of $N\log(1/\epsilon)$ bits, where $N$ is an upper
bound on $|S|$. They also presented a data structure with almost optimal space
of $(1+o(1))n(\log(1/\epsilon)+O(\log\log n))$ bits provided that
$n&gt;u^{0.001}$, with expected amortized constant insertion time and worst-case
constant lookup time.
</p>
<p>In this work, we present a filter data structure with improvements in two
aspects:
</p>
<p>- it has constant worst-case time for all insertions and lookups with high
probability;
</p>
<p>- it uses space $(1+o(1))n(\log (1/\epsilon)+\log\log n)$ bits when
$n&gt;u^{0.001}$, achieving optimal leading constant for all $\epsilon=o(1)$.
</p>
<p>We also present a dictionary that uses $(1+o(1))n\log(u/n)$ bits of space,
matching the optimal space in terms of the current size, and performs all
operations in constant time with high probability.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12424</id>
    <link href="http://arxiv.org/abs/2004.12424" rel="alternate" type="text/html"/>
    <title>An Efficient Index Method for the Optimal Route Query over Multi-Cost Networks</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Yajun.html">Yajun Yang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Hang.html">Hang Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Hong.html">Hong Gao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hu:Qinghua.html">Qinghua Hu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Xin.html">Xin Wang</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12424">PDF</a><br/><b>Abstract: </b>Smart city has been consider the wave of the future and the route
recommendation in networks is a fundamental problem in it. Most existing
approaches for the shortest route problem consider that there is only one kind
of cost in networks. However, there always are several kinds of cost in
networks and users prefer to select an optimal route under the global
consideration of these kinds of cost. In this paper, we study the problem of
finding the optimal route in the multi-cost networks. We prove this problem is
NP-hard and the existing index techniques cannot be used to this problem. We
propose a novel partition-based index with contour skyline techniques to find
the optimal route. We propose a vertex-filtering algorithm to facilitate the
query processing. We conduct extensive experiments on six real-life networks
and the experimental results show that our method has an improvement in
efficiency by an order of magnitude compared to the previous heuristic
algorithms.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12258</id>
    <link href="http://arxiv.org/abs/2004.12258" rel="alternate" type="text/html"/>
    <title>How to hide a clique?</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feige:Uriel.html">Uriel Feige</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grinberg:Vadim.html">Vadim Grinberg</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12258">PDF</a><br/><b>Abstract: </b>In the well known planted clique problem, a clique (or alternatively, an
independent set) of size $k$ is planted at random in an Erdos-Renyi random
$G(n, p)$ graph, and the goal is to design an algorithm that finds the maximum
clique (or independent set) in the resulting graph. We introduce a variation on
this problem, where instead of planting the clique at random, the clique is
planted by an adversary who attempts to make it difficult to find the maximum
clique in the resulting graph. We show that for the standard setting of the
parameters of the problem, namely, a clique of size $k = \sqrt{n}$ planted in a
random $G(n, \frac{1}{2})$ graph, the known polynomial time algorithms can be
extended (in a non-trivial way) to work also in the adversarial setting. In
contrast, we show that for other natural settings of the parameters, such as
planting an independent set of size $k=\frac{n}{2}$ in a $G(n, p)$ graph with
$p = n^{-\frac{1}{2}}$, there is no polynomial time algorithm that finds an
independent set of size $k$, unless NP has randomized polynomial time
algorithms.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12224</id>
    <link href="http://arxiv.org/abs/2004.12224" rel="alternate" type="text/html"/>
    <title>A $(1-e^{-1}-\varepsilon)$-Approximation for the Monotone Submodular Multiple Knapsack Problem</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fairstein:Yaron.html">Yaron Fairstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kulik:Ariel.html">Ariel Kulik</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Naor:Joseph.html">Joseph Naor</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raz:Danny.html">Danny Raz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shachnai:Hadas.html">Hadas Shachnai</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12224">PDF</a><br/><b>Abstract: </b>We study the problem of maximizing a monotone submodular function subject to
a Multiple Knapsack constraint (SMKP) . The input is a set $I$ of items, each
associated with a non-negative weight, and a set of bins, each having a
capacity. Also, we are given a submodular, monotone and non-negative function
$f$ over subsets of the items. The objective is to find a subset of items $A
\subseteq I$ and a packing of the items in the bins, such that $f(A)$ is
maximized. SMKP is a natural extension of both Multiple Knapsack and the
problem of monotone submodular maximization subject to a knapsack constraint.
</p>
<p>Our main result is a nearly optimal polynomial time
$(1-e^{-1}-\varepsilon)$-approximation algorithm for the problem, for any
$\varepsilon&gt;0$. Our algorithm relies on a refined analysis of techniques for
constrained submodular optimization combined with sophisticated application of
tools used in the development of approximation schemes for packing problems.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12223</id>
    <link href="http://arxiv.org/abs/2004.12223" rel="alternate" type="text/html"/>
    <title>Online Mincut: Advice, Randomization and More</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Banerjee:Avah.html">Avah Banerjee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Ding:Guoli.html">Guoli Ding</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12223">PDF</a><br/><b>Abstract: </b>In this paper we study the mincut problem on connected graphs in the online
setting. We consider the vertex arrival model; whenever a new vertex arrives
it's adjacency to previously revealed vertices are given. An online algorithm
must make an irrevocable decision to determine the side of the cut that the
vertex must belong to in order to minimize the size of the cut.
</p>
<p>Various models are considered. 1) For classical and advice models we give
tight bounds on the competitive ratio of deterministic algorithms. 2) Next we
consider few semi-adversarial inputs: random order of arrival with
adversarially generated and sparse graphs. 3) Lastly we introduce a new model,
which we call the friendly sequence model. We look at several online
optimization problems : mincut, maxcut and submodular maximization and show
that there are input ordering where a greedy strategy can produce an optimal
answer.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12222</id>
    <link href="http://arxiv.org/abs/2004.12222" rel="alternate" type="text/html"/>
    <title>Extending Partial 1-Planar Drawings</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eiben:Eduard.html">Eduard Eiben</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ganian:Robert.html">Robert Ganian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hamm:Thekla.html">Thekla Hamm</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klute:Fabian.html">Fabian Klute</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/N=ouml=llenburg:Martin.html">Martin Nöllenburg</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12222">PDF</a><br/><b>Abstract: </b>Algorithmic extension problems of partial graph representations such as
planar graph drawings or geometric intersection representations are of growing
interest in topological graph theory and graph drawing. In such an extension
problem, we are given a tuple $(G,H,\mathcal{H})$ consisting of a graph $G$, a
connected subgraph $H$ of $G$ and a drawing $\mathcal{H}$ of $H$, and the task
is to extend $\mathcal{H}$ into a drawing of $G$ while maintaining some desired
property of the drawing, such as planarity.
</p>
<p>In this paper we study the problem of extending partial 1-planar drawings,
which are drawings in the plane that allow each edge to have at most one
crossing. In addition we consider the subclass of IC-planar drawings, which are
1-planar drawings with independent crossings. Recognizing 1-planar graphs as
well as IC-planar graphs is \NP-complete and the \NP-completeness easily
carries over to the extension problem. Therefore, our focus lies on
establishing the tractability of such extension problems in a weaker sense than
polynomial-time tractability. Here, we show that both problems are
fixed-parameter tractable when parameterized by the number of edges missing
from $H$, i.e., the edge deletion distance between $H$ and $G$. The second part
of the paper then turns to a more powerful parameterization which is based on
measuring the vertex+edge deletion distance between the partial and complete
drawing, i.e., the minimum number of vertices and edges that need to be deleted
to obtain $H$ from $G$.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12166</id>
    <link href="http://arxiv.org/abs/2004.12166" rel="alternate" type="text/html"/>
    <title>An algorithmic weakening of the Erd\H{o}s-Hajnal conjecture</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonnet:=Eacute=douard.html">Édouard Bonnet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thomass=eacute=:St=eacute=phan.html">Stéphan Thomassé</a>, Xuan Thang Tran, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Watrigant:R=eacute=mi.html">Rémi Watrigant</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12166">PDF</a><br/><b>Abstract: </b>We study the approximability of the Maximum Independent Set (MIS) problem in
$H$-free graphs (that is, graphs which do not admit $H$ as an induced
subgraph). As one motivation we investigate the following conjecture: for every
fixed graph $H$, there exists a constant $\delta &gt; 0$ such that MIS can be
$n^{1 - \delta}$-approximated in $H$-free graphs, where $n$ denotes the number
of vertices of the input graph. We first prove that a constructive version of
the celebrated Erd\H{o}s-Hajnal conjecture implies ours. We then prove that the
set of graphs $H$ satisfying our conjecture is closed under the so-called graph
substitution. This, together with the known polynomial-time algorithms for MIS
in $H$-free graphs (e.g. $P_6$-free and fork-free graphs), implies that our
conjecture holds for many graphs $H$ for which the Erd\H{o}s-Hajnal conjecture
is still open. We then focus on improving the constant $\delta$ for some graph
classes: we prove that the classical Local Search algorithm provides an
$OPT^{1-\frac{1}{t}}$-approximation in $K_{t,t}$-free graphs (hence a
$\sqrt{OPT}$-approximation in $C_4$-free graphs), and, while there is a simple
$\sqrt{n}$-approximation in triangle-free graphs, it cannot be improved to
$n^{\frac{1}{4}-\varepsilon}$ for any $\varepsilon &gt; 0$ unless $NP \subseteq
BPP$. More generally, we show that there is a constant $c$ such that MIS in
graphs of girth $\gamma$ cannot be $n^{\frac{c}{\gamma}}$-approximated. Up to a
constant factor in the exponent, this matches the ratio of a known
approximation algorithm by Monien and Speckenmeyer, and by Murphy. To the best
of our knowledge, this is the first strong (i.e., $\Omega(n^\delta)$ for some
$\delta &gt; 0$) inapproximability result for Maximum Independent Set in a proper
hereditary class.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12144</id>
    <link href="http://arxiv.org/abs/2004.12144" rel="alternate" type="text/html"/>
    <title>Multi-robot motion planning of k-colored discs is PSPACE-hard</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Thomas Brocken, G. Wessel van der Heijden, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kostitsyna:Irina.html">Irina Kostitsyna</a>, Lloyd E. Lo-Wong, Remco J. A. Surtel <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12144">PDF</a><br/><b>Abstract: </b>In the problem of multi-robot motion planning, a group of robots, placed in a
polygonal domain with obstacles, must be moved from their starting positions to
a set of target positions. We consider the specific case of unlabeled disc
robots of two different sizes. That is, within one class of robots, where a
class is given by the robots' size, any robot can be moved to any of the
corresponding target positions. We prove that the decision problem of whether
there exists a schedule moving the robots to the target positions is
PSPACE-hard.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12143</id>
    <link href="http://arxiv.org/abs/2004.12143" rel="alternate" type="text/html"/>
    <title>Lazy listing of equivalence classes -- A paper on dynamic programming and tropical circuits</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yishu.html">Yishu Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mary:Arnaud.html">Arnaud Mary</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sagot:Marie=France.html">Marie-France Sagot</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sinaimeri:Blerina.html">Blerina Sinaimeri</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12143">PDF</a><br/><b>Abstract: </b>When a problem has more than one solution, it is often important, depending
on the underlying context, to list them all. Even when the listing can be done
in polynomial delay, that is, spending no more than polynomial time to go from
one solution to the next, this can be costly as the number of solutions
themselves may be huge, including sometimes exponential. This paper addresses
this problem by proposing what we called a \emph{lazy listing} algorithm. By
this we mean that, instead of listing all solutions, we list, in an efficient
way, directly only the equivalence classes or one representative per class.
Besides the need to then provide an \emph{a priori} relation of equivalence
between solutions, we place ourselves in the special context where the problem
to be addressed, either after some preliminary polynomial time dynamic
programming computation or directly from the start, leads to a decomposable
tropical circuit.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12063</id>
    <link href="http://arxiv.org/abs/2004.12063" rel="alternate" type="text/html"/>
    <title>Low-Degree Hardness of Random Optimization Problems</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gamarnik:David.html">David Gamarnik</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jagannath:Aukosh.html">Aukosh Jagannath</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wein:Alexander_S=.html">Alexander S. Wein</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12063">PDF</a><br/><b>Abstract: </b>We consider the problem of finding nearly optimal solutions of optimization
problems with random objective functions. Such problems arise widely in the
theory of random graphs, theoretical computer science, and statistical physics.
Two concrete problems we consider are (a) optimizing the Hamiltonian of a
spherical or Ising p-spin glass model, and (b) finding a large independent set
in a sparse Erdos-Renyi graph. Two families of algorithms are considered: (a)
low-degree polynomials of the input---a general framework that captures methods
such as approximate message passing and local algorithms on sparse graphs,
among others; and (b) the Langevin dynamics algorithm, a canonical Monte Carlo
analogue of the gradient descent algorithm (applicable only for the spherical
p-spin glass Hamiltonian).
</p>
<p>We show that neither family of algorithms can produce nearly optimal
solutions with high probability. Our proof uses the fact that both models are
known to exhibit a variant of the overlap gap property (OGP) of near-optimal
solutions. Specifically, for both models, every two solutions whose objectives
are above a certain threshold are either close or far from each other. The crux
of our proof is the stability of both algorithms: a small perturbation of the
input induces a small perturbation of the output. By an interpolation argument,
such a stable algorithm cannot overcome the OGP barrier.
</p>
<p>The stability of the Langevin dynamics is an immediate consequence of the
well-posedness of stochastic differential equations. The stability of
low-degree polynomials is established using concepts from Gaussian and Boolean
Fourier analysis, including noise sensitivity, hypercontractivity, and total
influence.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.12002</id>
    <link href="http://arxiv.org/abs/2004.12002" rel="alternate" type="text/html"/>
    <title>Finding Planted Cliques in Sublinear Time</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mardia:Jay.html">Jay Mardia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Asi:Hilal.html">Hilal Asi</a>, Kabir Aladin Chandrasekher <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12002">PDF</a><br/><b>Abstract: </b>We study the planted clique problem in which a clique of size $k$ is planted
in an Erd\H{o}s-R\'enyi graph of size $n$ and one wants to recover this planted
clique. For $k=\Omega(\sqrt{n})$, polynomial time algorithms can find the
planted clique. The fastest such algorithms run in time linear $O(n^2)$ (or
nearly linear) in the size of the input [FR10,DGGP14,DM15a]. In this work, we
develop sublinear time algorithms that find the planted clique when
$k=\omega(\sqrt{n \log \log n})$. Our algorithms can recover the clique in time
$\widetilde{O}\left(n+(\frac{n}{k})^{3}\right)=\widetilde{O}\left(n^{\frac{3}{2}}\right)$
when $k=\Omega(\sqrt{n\log n})$, and in time
$\widetilde{O}\left(n^2/\exp{\left(\frac{k^2}{24n}\right)}\right)$ for
$\omega(\sqrt{n\log \log n})=k=o(\sqrt{n\log{n}})$. An ${\Omega}(n)$ running
time lower bound for the planted clique recovery problem follows easily from
the results of [RS19] and therefore our recovery algorithms are optimal
whenever $k = \Omega(n^{\frac{2}{3}})$. As the lower bound of [RS19] builds on
purely information theoretic arguments, it cannot provide a detection lower
bound stronger than $\widetilde{\Omega}(\frac{n^2}{k^2})$. Since our algorithms
for $k = \Omega(\sqrt{n \log n})$ run in time
$\widetilde{O}\left(\frac{n^3}{k^3} + n\right)$, we show stronger lower bounds
based on computational hardness assumptions. With a slightly different notion
of the planted clique problem we show that the Planted Clique Conjecture
implies the following. A natural family of non-adaptive algorithms---which
includes our algorithms for clique detection---cannot reliably solve the
planted clique detection problem in time $O\left(
\frac{n^{3-\delta}}{k^3}\right)$ for any constant $\delta&gt;0$. Thus we provide
evidence that if detecting small cliques is hard, it is also likely that
detecting large cliques is not \textit{too} easy.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11937</id>
    <link href="http://arxiv.org/abs/2004.11937" rel="alternate" type="text/html"/>
    <title>A linear fixed parameter tractable algorithm for connected pathwidth</title>
    <feedworld_mtime>1588032000</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kant=eacute=:Mamadou_Moustapha.html">Mamadou Moustapha Kanté</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paul:Christophe.html">Christophe Paul</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thilikos:Dimitrios_M=.html">Dimitrios M. Thilikos</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11937">PDF</a><br/><b>Abstract: </b>The graph parameter of pathwidth can be seen as a measure of the topological
resemblance of a graph to a path. A popular definition of pathwidth is given in
terms of node search where we are given a system of tunnels that is
contaminated by some infectious substance and we are looking for a search
strategy that, at each step, either places a searcher on a vertex or removes a
searcher from a vertex and where an edge is cleaned when both endpoints are
simultaneously occupied by searchers. It was proved that the minimum number of
searchers required for a successful cleaning strategy is equal to the pathwidth
of the graph plus one. Two desired characteristics for a cleaning strategy is
to be monotone (no recontamination occurs) and connected (clean territories
always remain connected). Under these two demands, the number of searchers is
equivalent to a variant of pathwidth called {\em connected pathwidth}. We prove
that connected pathwidth is fixed parameter tractable, in particular we design
a $2^{O(k^2)}\cdot n$ time algorithm that checks whether the connected
pathwidth of $G$ is at most $k.$ This resolves an open question by
[Dereniowski, Osula, and Rz{\k{a}}{\.{z}}ewski, Finding small-width connected
path-decompositions in polynomial time. Theor. Comput. Sci., 794:85-100, 2019].
For our algorithm, we enrich the typical sequence technique that is able to
deal with the connectivity demand. Typical sequences have been introduced in
[Bodlaender and Kloks. Efficient and constructive algorithms for the pathwidth
and treewidth of graphs. J. Algorithms, 21(2):358-402, 1996] for the design of
linear parameterized algorithms for treewidth and pathwidth. The proposed
extension is based on an encoding of the connectivity property that is quite
versatile and may be adapted so to deliver linear parameterized algorithms for
the connected variants of other width parameters as well.
</p></div>
    </summary>
    <updated>2020-04-28T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-28T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://windowsontheory.org/?p=7716</id>
    <link href="https://windowsontheory.org/2020/04/27/lessons-from-covid-19-what-works-online-and-what-doesnt/" rel="alternate" type="text/html"/>
    <title>Lessons from COVID-19: What works online and what doesn’t</title>
    <summary>(I am now on Twitter , so you can follow this blog there too if you prefer it. –Boaz) Between Zoom meetings and deadlines, I thought I’d jot down a few of my impressions so far on what lessons we can draw from this period on how well research and education can work online. I’ve […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>(I am now on <a href="https://twitter.com/boazbaraktcs">Twitter</a> ,  so you can follow this blog there too if you prefer it. –Boaz)</p>



<p>Between Zoom meetings and deadlines, I thought I’d jot down a few of my impressions so far on what lessons we can draw from this period on how well research and education can work online.  I’ve had a few surprises in both directions – things that worked better than I would have expected, and aspects that were more problematic than I realized. These are personal impressions – please do comment on your own experiences.</p>



<p>As a rule of thumb, the interactions that most successfully replicate online are those that are relatively short and focused (an hour or so – e.g., a focused research meeting, seminar talk, or a lecture in a course).  Other interactions (e.g., faculty meetings) are also fairly easily to port online, perhaps because the original wasn’t that great to begin with.</p>



<p>The things that are harder to replicate are sustained interactions over longer periods. These include more extended and less directed research collaborations, informal workshops, as well as support for students outside lectures in education.</p>



<p><strong>Works well: Research seminars</strong></p>



<p>I’ve been pleasantly surprised by how effective research seminars such as our <a href="https://mltheory.org/">machine learning theory seminar</a> are over Zoom. In particular these were no less interactive than physical seminars – in fact people are offten <em>more</em> comfortable asking questions on chat than they would during in-person seminars. I hope such seminars become common practice even after this period ends- flying a speaker across the country or the world to give an hour talk doesn’t makes much sense given that there is a perfectly satisfactory alternative. </p>



<p><strong>Works well: Lectures</strong></p>



<p>This term I am teaching <a href="https://cs127.boazbarak.org/schedule/">cryptography</a>, and online lectures on Zoom have gone surprisingly well (after  working out some <a href="https://windowsontheory.org/2020/03/26/technology-for-theory-covid-19-edition/">technical issues</a>). Students participate on chat and ask questions, and seem to be following the lecture quite well. The important caveat is that lectures only work well for the students that attend and can follow them. For students who need extra support, it’s become much harder to access it.  It’s also much easier for students to (literally) “fall off the screen” and fall behind in a course, which brings me to the next point.</p>



<p><strong>Works less well: Support outside lectures</strong></p>



<p>Lectures are just one component of a course. Most of students’ learning occurs outside the classroom, where students meet together and work on problem sets, or discuss course material. These interactions between students (both related and unrelated to course) are where much of their intellectual growth happens. </p>



<p>All these interactions are greatly diminished online, and I did not yet see a good alternative. I’ve seen reduced attendance in office hours and sections, and reports are that students find it much harder to have the sort of chance discussions and opportunities to find study partners that they value so much.  If anything, this experience had made me <em>less</em> positive about the possibility of online education replacing physical colleges (though there are interesting <a href="https://en.wikipedia.org/wiki/Minerva_Schools_at_KGI">hybrid models</a>, where the students are co-located but lecturers are online).</p>



<p><strong>Works less well: unstructured research collaborations</strong></p>



<p>A focused meeting reporting on results or deciding on work allocation works pretty well over Zoom. So far it seems that extended brainstorming meetings, such as talking to someone over several hours in a coffeeshop, are much harder to replicate. In particular, a good part of such meetings is often spent with people staring in silence into their notebooks. As I <a href="https://twitter.com/boazbaraktcs/status/1253330145789673473">wrote</a>,  mutual silence seems to be very hard to do over Zoom.</p>



<p>Generally, informal week-long workshops, where much time is devoted to unstructured discussions, are ones that are most important to hold in person, and are hard (or maybe impossible) to replicate online. I have still not attended an online conference, but I suspect that these aspects of the conference would also be the ones hardest to replicate.</p>



<p><strong>Works well: faculty meetings</strong></p>



<p>I’ve always found it hard to bring a laptop to a faculty meeting and get work done, while listening with one ear to what’s going on. This is so much easier over Zoom <img alt="&#x1F642;" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"/></p></div>
    </content>
    <updated>2020-04-27T21:01:00Z</updated>
    <published>2020-04-27T21:01:00Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Boaz Barak</name>
    </author>
    <source>
      <id>https://windowsontheory.org</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://windowsontheory.org/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://windowsontheory.org" rel="alternate" type="text/html"/>
      <link href="https://windowsontheory.org/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://windowsontheory.org/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>A Research Blog</subtitle>
      <title>Windows On Theory</title>
      <updated>2020-04-28T14:20:56Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://theorydish.blog/?p=1676</id>
    <link href="https://theorydish.blog/2020/04/27/whats-your-story/" rel="alternate" type="text/html"/>
    <title>What’s Your Story?</title>
    <summary>Last quarter, I taught a course on research methods in TOC, which gave me an opportunity to think through many aspects of research. I was promoting a human-centric perspective on research: how to facilitate better research by addressing the conditions needed for an individual researcher and groups of researchers to succeed. As science is a communal effort, the communication of science is critical, and thus one of the topics we covered is oral presentations. There are plenty of resources about research talks, and mostly they emphasize form over matter. How many words in a slide? How many slides in a talk? how to and how not to use font colors? How to and how not to use animation? and so on. While all of these are important, I find that the failing of many research talks is on a much more basic level. Think back to a research talk you heard recently, or to one you heard a few months ago. You may remember how you felt and what you thought of the talk but what do you remember of this talk in terms of content? Most of us will find that we don’t remember much, I rarely do. Yet [...]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>Last quarter, I taught <a href="https://omereingold.wordpress.com/cs-353-the-practice-of-theory-research/">a course on research methods</a> in TOC, which gave me an opportunity to think through many aspects of research. I was promoting a human-centric perspective on research: how to facilitate better research by addressing the conditions needed for an individual researcher and groups of researchers to succeed. As science is a communal effort, the communication of science is critical, and thus one of the topics we covered is oral presentations.</p>
<p>There are plenty of resources about research talks, and mostly they emphasize form over matter. How many words in a slide? How many slides in a talk? how to and how not to use font colors? How to and how not to use animation? and so on. While all of these are important, I find that the failing of many research talks is on a much more basic level.</p>
<p>Think back to a research talk you heard recently, or to one you heard a few months ago. You may remember how you felt and what you thought of the talk but what do you remember of this talk in terms of content? Most of us will find that we don’t remember much, I rarely do. Yet in our presentations, we often follow a research-paper-like mold and squeeze in many little details that are somehow important to us, forgetting that they will all vanish in our audience’s memory soon after (or completely missed in the first place). Giving a talk (writing a paper, writing a blog post etc.) is about communication: who is your audience? what are the limitation of the medium? what is the message you want to convey? Since so little stays with the audience long term, it makes sense to make sure that this little will be what seems most important for you to convey.</p>
<p>The idea I am promoting here is not new, and there are various techniques towards this goal. One (which I think Oded Goldreich shared with me), is to think of audience’s attention as a limited currency. Whenever you share a big idea you spend a big token and other ideas cost a smaller token. Imagine you have one or two big tokens and a few smaller tokens. <a href="https://www.youtube.com/watch?v=5OFAhBw0OXs">Another approach</a>, emphasizes the notion of <strong>a premise</strong>. The idea promoted here is that a talk needs a premise and this should be the title of the talk. Furthermore, every slide needs a premise and it should be the title of the slide. A premise is a main idea and is a complete sentence. It is not unusual to find a slide titled “Analysis” or “Efficiency” but neither of these is a premise. “Problem X has an efficient algorithm” could be. The talk’s premise could help you distill what you want the audience to take out of your talk. It also helps shape the talk, as everything that doesn’t serve the premise shouldn’t be there. Note that each paper can provoke many different premises and thus many different talks.</p>
<p>Here I want to play with a different idea, that I find intriguing, even if it may seem a bit extreme. It will not be controversial that a good talk (and paper) tells a story. After all, humans understand and remember narratives. But could we take inspiration from the form of storytelling in fiction writing? A vast literature, classifies different kinds of stories and explores their templates (see for example <a href="http://storybistro.com/7-story-frameworks/">this short discussion</a>).  Can we find analogues to these types in scientific research talks?</p>
<p>The type of story that is easiest to relate to is the <strong>Quest/Hero’s Journey</strong> (think Lord of the Rings). These have several distinct ingredients: a call to adventure, tests, allies, enemies, ordeal, reward, victorious return. Some research talks that follow this template do it well and preserve a sense of suspense and excitement, others seem like a long list of problems and the tricks that the work uses to handle them.</p>
<p>I believe that many other story templates can find analogues is research talks as well. Here are my initial attempts:</p>
<ul>
<li><strong>Coming of age</strong> stories – this area of research previously only had naive ideas but this works brings significant depth.</li>
<li><strong>The Under<span style="color: #000000;">dog</span></strong><span style="color: #000000;"> (think David and Goliath): a modest technique that concurred a great challenge.</span></li>
<li><strong>Rags to Riches</strong> (think the Ugly Duckling): an area or technique that were not successful prove powerful.
<ul>
<li>Similarly: <strong>Rebirth</strong> (reinvention, renewal).</li>
</ul>
</li>
<li><strong>Comedy</strong> (or the Clarity Tale) – conceptual works shedding a new perspective.</li>
<li><strong>Tragedy</strong> (or the Cautionary Tale) – Some impossibility results come to mind (couldn’t we view Arrow’s impossibility theorem as being tragic?)</li>
<li><strong>Redemption stories</strong>: the field so far has missed the point, was misleading or harmful, but this work makes amends.</li>
</ul>
<p>Can you suggest papers and a story type that could fit them?</p></div>
    </content>
    <updated>2020-04-27T16:26:33Z</updated>
    <published>2020-04-27T16:26:33Z</published>
    <category term="Uncategorized"/>
    <author>
      <name>Omer Reingold</name>
    </author>
    <source>
      <id>https://theorydish.blog</id>
      <logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo>
      <link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://theorydish.blog" rel="alternate" type="text/html"/>
      <link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>Stanford's CS Theory Research Blog</subtitle>
      <title>Theory Dish</title>
      <updated>2020-04-28T14:21:22Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/060</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/060" rel="alternate" type="text/html"/>
    <title>TR20-060 |  Leakage-Resilient Extractors and Secret-Sharing against Bounded Collusion Protocols | 

	Eshan Chattopadhyay, 

	Xin Li, 

	Vipul Goyal, 

	Jesse Goodman</title>
    <summary>In a recent work, Kumar, Meka, and Sahai (FOCS 2019) introduced the notion of bounded collusion protocols (BCPs), in which $N$ parties wish to compute some joint function $f:(\{0,1\}^n)^N\to\{0,1\}$ using a public blackboard, but such that only $p$ parties may collude at a time. This generalizes well studied models in multiparty communication complexity, such as the number-in-hand (NIH) and number-on-forehead (NOF) models, which are just endpoints on this rich spectrum. We construct explicit hard functions against this spectrum, and achieve a tradeoff between collusion and complexity. Using this, we obtain improved leakage-resilient secret sharing schemes against bounded collusion protocols. 

Our main tool in obtaining hard functions against BCPs are explicit constructions of leakage resilient extractors against BCPs for a wide range of parameters. Kumar et al. (FOCS 2019) studied  such extractors and called them cylinder intersection extractors. In fact, such extractors directly yield correlation bounds against BCPs. We focus on the following setting: the input to the extractor consists of $N$ independent sources of length $n$, and the leakage function Leak $:(\{0,1\}^n)^N\to\{0,1\}^\mu\in\mathcal{F}$ is a BCP with some collusion bound $p$ and leakage (output length) $\mu$. While our extractor constructions are very general, we highlight some interesting parameter settings:

1. In the case when the input sources are uniform, and $p=0.99N$ parties collude, our extractor can handle $n^{\Omega(1)}$ bits of leakage, regardless of the dependence between $N,n$. The best NOF lower bound (i.e., $p=N-1$) on the other hand requires $N&lt;\log n$ even to handle $1$ bit of leakage.

2. Next, we show that for the same setting as above, we can drop the entropy requirement to $k=$ polylog $n$, while still handling polynomial leakage for $p=0.99N$.  This resolves an open question about cylinder intersection extractors raised by Kumar et al. (FOCS 2019), and we find an application of such low entropy extractors in a new type of secret sharing.

We also provide an explicit compiler that transforms any function with high NOF (distributional) communication complexity into a leakage-resilient extractor that can handle polylogarithmic entropy and substantially more leakage against BCPs. Thus any improvement of NOF lower bounds will immediately yield better leakage-resilient extractors.

Using our extractors against BCPs, we obtain improved $N$-out-of-$N$ leakage-resilient secret sharing schemes. The previous best scheme from Kumar et al. (FOCS 2019) required share size to grow exponentially in the collusion bound, and thus cannot efficiently handle $p=\omega(\log N)$. Our schemes have no dependence of this form, and can thus handle collusion size $p=0.99N$.</summary>
    <updated>2020-04-27T06:12:53Z</updated>
    <published>2020-04-27T06:12:53Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-28T14:20:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/059</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/059" rel="alternate" type="text/html"/>
    <title>TR20-059 |  Pr-ZSUBEXP is not contained in Pr-RP | 

	Gonen Krak, 

	Noam Parzanchevski, 

	Amnon Ta-Shma</title>
    <summary>We unconditionally prove there exists a promise problem in promise ZSUBEXP that cannot be solved in promise RP. 
The proof technique builds upon Kabanets' easy witness method [Kab01] as implemented by Impagliazzo et. al [IKW02], with a separate diagonalization carried out on each of the two alternatives in the win-win argument. We remark that even though the easy witness method is a key component in many celebrated results in derandomization, we are not aware of any previous unconditional separation like the one we show.

We remark that the result relativizes. We could not prove a similar result for total functions, nor for functions in ZTime(T(n)) for T(n) below a half-exponential function (i.e., T such that T(T(n)) &lt; 2^n).</summary>
    <updated>2020-04-27T05:27:15Z</updated>
    <published>2020-04-27T05:27:15Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-28T14:20:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>https://eccc.weizmann.ac.il/report/2020/058</id>
    <link href="https://eccc.weizmann.ac.il/report/2020/058" rel="alternate" type="text/html"/>
    <title>TR20-058 |  Interactive Proofs for Verifying Machine Learning | 

	Jonathan Shafer, 

	Amir Yehudayoff, 

	Shafi Goldwasser, 

	Guy Rothblum</title>
    <summary>We consider the following question: using a source of labeled data and interaction with an untrusted prover, what is the complexity of verifying that a given hypothesis is "approximately correct"? We study interactive proof systems for PAC verification, where a verifier that interacts with a prover is required to accept good hypotheses, and reject bad hypotheses. Both the verifier and the prover are efficient and have access to data samples from an unknown distribution. We are interested in cases where the verifier can use significantly less data than is required for (agnostic) PAC learning, or use a substantially cheaper data source (e.g., using only random samples for verification, even though learning requires membership queries). We believe that today, when data and data-driven algorithms are quickly gaining prominence, the question of verifying purported outcomes of data analyses is very well-motivated.
		
We show three main results. First, we prove that for a specific hypothesis class, verification is significantly cheaper than learning in terms of the number of random samples required, even if the verifier engages with the prover only in a single-round (NP-like) protocol. Moreover, for this class we prove that single-round verification is also significantly cheaper than testing closeness to the class. Second, for the broad class of Fourier-sparse boolean functions, we show a multi-round (IP-like) verification protocol, where the prover uses membership queries, and the verifier is able to assess the result while only using random samples. Third, we show that verification is not always more efficient. Namely, we show a class of functions where verification requires as many samples as learning does, up to a logarithmic factor.</summary>
    <updated>2020-04-27T01:42:43Z</updated>
    <published>2020-04-27T01:42:43Z</published>
    <source>
      <id>https://eccc.weizmann.ac.il/</id>
      <author>
        <name>ECCC papers</name>
      </author>
      <link href="https://eccc.weizmann.ac.il/" rel="alternate" type="text/html"/>
      <link href="https://example.com/feeds/reports/" rel="self" type="application/atom+xml"/>
      <subtitle>Latest Reports published at https://eccc.weizmann.ac.il</subtitle>
      <title>ECCC - Reports</title>
      <updated>2020-04-28T14:20:26Z</updated>
    </source>
  </entry>

  <entry xml:lang="en">
    <id>http://rjlipton.wordpress.com/?p=16982</id>
    <link href="https://rjlipton.wordpress.com/2020/04/26/time-for-some-jokes/" rel="alternate" type="text/html"/>
    <title>Time For Some Jokes</title>
    <summary>Can we still smile? [ Hardy and Littlewood] John Littlewood lived through the 1918–1919 flu pandemic, yet he appears not to have remarked on it in print. Nor can we find mention of it by Godfrey Hardy in A Mathematician’s Apology—though Hardy did write about the ravages of WW I. Today, Ken and I thought […]</summary>
    <content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><font color="#0044cc"><br/>
<em>Can we still smile?</em><br/>
<font color="#000000"/></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/04/26/time-for-some-jokes/unknown-139/" rel="attachment wp-att-16991"><img alt="" class="alignright size-full wp-image-16991" src="https://rjlipton.files.wordpress.com/2020/04/unknown-2.jpeg?w=600"/></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Hardy and Littlewood]</font></td>
</tr>
</tbody>
</table>
<p>
John Littlewood lived through the 1918–1919 flu pandemic, yet he appears not to have remarked on it in print. Nor can we find mention of it by Godfrey Hardy in <em>A Mathematician’s Apology</em>—though Hardy did write about the ravages of WW I.</p>
<p>
Today, Ken and I thought you might like some fun comments that are not about the current pandemic. </p>
<p>
This is not to say we are ignoring it. We are all fighting the virus in one way or another. Our hearts go out to those of you fighting it directly. We are all worried about ourselves and others. We are stuck at home, at least most of us. We are all in this terrible time together. We hope you all are safe and well. </p>
<p>
We thought we would list a few jokes and stories that you might enjoy. We wrote recently about one kind of mathematical <a href="https://rjlipton.wordpress.com/2020/02/28/reductions-and-jokes/">joke</a> that can be given various proportions of pure levity and mathematical content. Our friends Lance Fortnow and Bill Gasarch, plus commenters in their <a href="https://blog.computationalcomplexity.org/2006/06/funniest-computer-science-joke-ever.html">item</a>, collected some jokes on the computer science side.</p>
<p>
Littlewood’s notion of “mathematical joke” leaned more on mathematical content, though his <a href="https://en.wikipedia.org/wiki/A_Mathematician's_Miscellany">memoir</a> <em>A Mathematician’s Miscellany</em> includes many funny stories as well. At the end of his introduction to the book, he wrote:</p>
<blockquote><p><b> </b> <em> A good mathematical joke is better, and better mathematics, than a dozen mediocre papers. </em>
</p></blockquote>
<p/><p>
We will start at the levity end. This is almost a math <a href="http://web.sonoma.edu/Math/faculty/falbo/jokes.html">joke</a>:</p>
<blockquote><p><b> </b> <em> The Daily News published a story saying that one-half of the MP (Members of Parliament) were crooks.<br/>
The Government took great exception to that and demanded a retraction and an apology.<br/>
The newspaper responded the next day with an apology and reported that one-half of the MPs were not crooks. </em>
</p></blockquote>
<p/><p>
We like this one, even if it is not really a hardcore math one. It does rely on the fact that <img alt="{\frac{1}{2} + \frac{1}{2} = 1.}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B1%7D%7B2%7D+%3D+1.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{1}{2} + \frac{1}{2} = 1.}"/></p>
<p>
</p><p/><h2> Jokes and More </h2><p/>
<p/><p>
The following are some examples that we hope you all like. They are from a variety of sources: </p>
<ul>
<li>
Jokes that mathematicians think are <a href="https://www.businessinsider.com/13-math-jokes-that-every-mathematician-finds-absolutely-hilarious-2013-5">funny</a>. <p/>
</li><li>
Some are from <a href="https://cstheory.stackexchange.com/questions/3111/funny-tcs-related-papers-etc">StackExchange</a>. <p/>
</li><li>
Others are from Andrej Cherkaev’s <a href="https://www.math.utah.edu/~cherk/mathjokes.html">page</a>.
</li></ul>
<p>We have lightly edited a few.</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> “My age is two billion years old,” said Paul Erdös. The point is: </p>
<blockquote><p><b> </b> <em> When I was seventeen years old it was said the earth was two billion years old. Now they say it is four billion years old. So my age is about two billion years old. </em>
</p></blockquote>
<p/><p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> There was a statistician that drowned crossing a river <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/> It was 3 feet deep on average. </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> An infinite number of mathematicians walk into a bar. The first one orders a beer. The second orders half a beer. The third orders a third of a beer. The bartender bellows, “Get the heck out of here, are you trying to ruin me?”</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> An chemist, a physicist, and a mathematician are stranded on an island when a can of food rolls ashore. The chemist and the physicist comes up with many ingenious ways to open the can. Then suddenly the mathematician gets a bright idea: “Assume we have a can opener <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/>” </p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> A theorist decides she wants to learn more about practical problems. She sees a seminar with the title: “The Theory of Gears.” So she goes. The speaker stands up and begins, “The theory of gears with a finite number of teeth is well known <img alt="{\dots}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\dots}"/></p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The reason that every major university maintains a department of mathematics is that it is cheaper to do this than to institutionalize all those people.</p>
<p>
Regarding the last one, Littlewood did after all write in his book:</p>
<blockquote><p><b> </b> <em> Mathematics is a dangerous profession; an appreciable proportion of us go mad. </em>
</p></blockquote>
<p/><p>
This appears to have been a playful swipe at Hardy’s decision to leave Cambridge for Oxford. It was couched in a discussion of events that would seem to have had tiny probabilities before they happened. </p>
<p>
The last two we’ve picked out from the above sites verge into philosophy:</p>
<p>
<img alt="{\bullet }" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet }"/> The cherry theorem: Question: What is a small, red, round thing that has a cherry pit inside? <br/>
Answer: A cherry.</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> René Descartes went into his favorite bar and the bartender asked, “would you like your usual drink tonight, Monsieur Descartes?” Descartes replied “I think not.” Then he promptly ceased to exist.</p>
<p>
</p><p/><h2> Wrong Derivations, Right Results </h2><p/>
<p/><p>
Littlewood’s standards for a “mathematical joke” were higher than ours, but we will start by adapting an example from this MathOverflow <a href="https://mathoverflow.net/questions/38856/jokes-in-the-sense-of-littlewood-examples">discussion</a> of Littlewood-style jokes. Sometimes we can play a joke on ourselves by deriving a result we know is right but with an incorrect proof. Here is the example:</p>
<p>
<img alt="{\bullet}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\bullet}"/> <a href="https://www.reddit.com/r/math/comments/1bntfg/are_there_or_can_there_be_jokes_or_puns_in/">Casting out 6’s</a>. Suppose we want to simplify the fraction <img alt="{\frac{166}{664}}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B166%7D%7B664%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{\frac{166}{664}}"/>. We can use the rule of casting out 6’s to get </p>
<p align="center"><img alt="\displaystyle  \frac{166}{664} = \frac{16}{64} = \frac{1}{4}. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B166%7D%7B664%7D+%3D+%5Cfrac%7B16%7D%7B64%7D+%3D+%5Cfrac%7B1%7D%7B4%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{166}{664} = \frac{16}{64} = \frac{1}{4}. "/></p>
<p>
The rule works quite generally:</p>
<p align="center"><img alt="\displaystyle  \frac{1666}{6664} = \frac{16666}{66664} = \frac{166666}{666664} = \cdots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B1666%7D%7B6664%7D+%3D+%5Cfrac%7B16666%7D%7B66664%7D+%3D+%5Cfrac%7B166666%7D%7B666664%7D+%3D+%5Ccdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{1666}{6664} = \frac{16666}{66664} = \frac{166666}{666664} = \cdots "/></p>
<p/><p/>
<p align="center"><img alt="\displaystyle  \frac{26}{65} = \frac{266}{665} = \frac{2666}{6665} = \frac{26666}{66665} = \cdots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B26%7D%7B65%7D+%3D+%5Cfrac%7B266%7D%7B665%7D+%3D+%5Cfrac%7B2666%7D%7B6665%7D+%3D+%5Cfrac%7B26666%7D%7B66665%7D+%3D+%5Ccdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{26}{65} = \frac{266}{665} = \frac{2666}{6665} = \frac{26666}{66665} = \cdots "/></p>
<p>You can even turn the paper upside down and cast out the <img alt="{6}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{6}"/>‘s that you see then:</p>
<p/><p align="center"><img alt="\displaystyle  \frac{19}{95} = \frac{199}{995} = \frac{1999}{9995} = \frac{19999}{99995} = \cdots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B19%7D%7B95%7D+%3D+%5Cfrac%7B199%7D%7B995%7D+%3D+%5Cfrac%7B1999%7D%7B9995%7D+%3D+%5Cfrac%7B19999%7D%7B99995%7D+%3D+%5Ccdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{19}{95} = \frac{199}{995} = \frac{1999}{9995} = \frac{19999}{99995} = \cdots "/></p>
<p/><p/>
<p align="center"><img alt="\displaystyle  \frac{49}{98} = \frac{499}{998} = \frac{4999}{9998} = \frac{49999}{99998} = \cdots " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B49%7D%7B98%7D+%3D+%5Cfrac%7B499%7D%7B998%7D+%3D+%5Cfrac%7B4999%7D%7B9998%7D+%3D+%5Cfrac%7B49999%7D%7B99998%7D+%3D+%5Ccdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{49}{98} = \frac{499}{998} = \frac{4999}{9998} = \frac{49999}{99998} = \cdots "/></p>
<p>
Note, this is a joke: The rule of course does not actually work all the time: 	</p>
<p align="center"><img alt="\displaystyle  \frac{56}{65} = \frac{5}{5} = 1. " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B56%7D%7B65%7D+%3D+%5Cfrac%7B5%7D%7B5%7D+%3D+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \frac{56}{65} = \frac{5}{5} = 1. "/></p>
<p/><p><br/>
We thought to try to come up with our own examples, or at least blend in other sources. It once struck me (Ken), on reading a column by Martin Gardner on difference equations, that they give a “convincing proof” of <img alt="{0^0 = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%5E0+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0^0 = 1}"/>. Consider the powers of a natural number <img alt="{k}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k}"/>, say <img alt="{k = 5}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k = 5}"/>. Take differences like so: </p>
<p align="center"><img alt="\displaystyle  \begin{array}{ccccccccccc} 1 &amp; &amp; 5 &amp; &amp; 25 &amp; &amp; 125 &amp; &amp; 625 &amp; &amp; \dots\\ &amp; 4 &amp; &amp; 20 &amp; &amp; 100 &amp; &amp; 500 &amp; &amp; \dots\\ &amp; &amp; 16 &amp; &amp; 80 &amp; &amp; 400 &amp; &amp; \dots &amp; &amp; \\ &amp; &amp; &amp; 64 &amp; &amp; 320 &amp; &amp; \dots &amp; &amp; &amp;\\ &amp; &amp; &amp; &amp; 256 &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \ddots &amp; &amp; &amp; \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Bccccccccccc%7D+1+%26+%26+5+%26+%26+25+%26+%26+125+%26+%26+625+%26+%26+%5Cdots%5C%5C+%26+4+%26+%26+20+%26+%26+100+%26+%26+500+%26+%26+%5Cdots%5C%5C+%26+%26+16+%26+%26+80+%26+%26+400+%26+%26+%5Cdots+%26+%26+%5C%5C+%26+%26+%26+64+%26+%26+320+%26+%26+%5Cdots+%26+%26+%26%5C%5C+%26+%26+%26+%26+256+%26+%26+%26+%26+%5C%5C+%26+%26+%26+%26+%26+%5Cddots+%26+%26+%26+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle  \begin{array}{ccccccccccc} 1 &amp; &amp; 5 &amp; &amp; 25 &amp; &amp; 125 &amp; &amp; 625 &amp; &amp; \dots\\ &amp; 4 &amp; &amp; 20 &amp; &amp; 100 &amp; &amp; 500 &amp; &amp; \dots\\ &amp; &amp; 16 &amp; &amp; 80 &amp; &amp; 400 &amp; &amp; \dots &amp; &amp; \\ &amp; &amp; &amp; 64 &amp; &amp; 320 &amp; &amp; \dots &amp; &amp; &amp;\\ &amp; &amp; &amp; &amp; 256 &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \ddots &amp; &amp; &amp; \end{array} "/></p>
<p>
The powers of <img alt="{k-1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k-1}"/> always appear on the bottom diagonal. Thus we have: <img alt="{(k-1)^0 = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28k-1%29%5E0+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(k-1)^0 = 1}"/>, <img alt="{(k-1)}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28k-1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(k-1)}"/>, <img alt="{(k-1)^2}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B%28k-1%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{(k-1)^2}"/>, and so on. Now do this for <img alt="{k = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{k = 1}"/>:</p>
<p align="center"><img alt="\displaystyle \begin{array}{ccccccccccc} 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; \dots\\ &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots\\ &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots &amp; &amp; \\ &amp; &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots &amp; &amp; &amp;\\ &amp; &amp; &amp; &amp; 0 &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \ddots &amp; &amp; &amp; \end{array} " class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Bccccccccccc%7D+1+%26+%26+1+%26+%26+1+%26+%26+1+%26+%26+1+%26+%26+%5Cdots%5C%5C+%26+0+%26+%26+0+%26+%26+0+%26+%26+0+%26+%26+%5Cdots%5C%5C+%26+%26+0+%26+%26+0+%26+%26+0+%26+%26+%5Cdots+%26+%26+%5C%5C+%26+%26+%26+0+%26+%26+0+%26+%26+%5Cdots+%26+%26+%26%5C%5C+%26+%26+%26+%26+0+%26+%26+%26+%26+%5C%5C+%26+%26+%26+%26+%26+%5Cddots+%26+%26+%26+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\displaystyle \begin{array}{ccccccccccc} 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; \dots\\ &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots\\ &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots &amp; &amp; \\ &amp; &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots &amp; &amp; &amp;\\ &amp; &amp; &amp; &amp; 0 &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \ddots &amp; &amp; &amp; \end{array} "/></p>
<p>The diagonal now holds the powers of <img alt="{0}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0}"/>. It thus follows that <img alt="{0^0 = 1}" class="latex" src="https://s0.wp.com/latex.php?latex=%7B0%5E0+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="{0^0 = 1}"/>.</p>
<p/><h2> Open Problems </h2><p/>
<p>What are your favorite mathematical jokes? Please send them to us. Be safe. Be well.</p>
<p><a href="https://rjlipton.wordpress.com/2020/04/26/time-for-some-jokes/sign-2/" rel="attachment wp-att-16987"><img alt="" class="aligncenter size-medium wp-image-16987" height="111" src="https://rjlipton.files.wordpress.com/2020/04/sign-1.png?w=300&amp;h=111" width="300"/></a></p>
<p>
[fixed equations in last main section]</p></font></font></div>
    </content>
    <updated>2020-04-27T00:37:51Z</updated>
    <published>2020-04-27T00:37:51Z</published>
    <category term="Oldies"/>
    <category term="People"/>
    <category term="Proofs"/>
    <category term="jokes"/>
    <category term="math jokes"/>
    <category term="stories"/>
    <author>
      <name>rjlipton</name>
    </author>
    <source>
      <id>https://rjlipton.wordpress.com</id>
      <logo>https://s0.wp.com/i/buttonw-com.png</logo>
      <link href="https://rjlipton.wordpress.com/feed/" rel="self" type="application/atom+xml"/>
      <link href="https://rjlipton.wordpress.com" rel="alternate" type="text/html"/>
      <link href="https://rjlipton.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/>
      <link href="https://rjlipton.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/>
      <subtitle>a personal view of the theory of computation</subtitle>
      <title>Gödel’s Lost Letter and P=NP</title>
      <updated>2020-04-28T14:20:35Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11862</id>
    <link href="http://arxiv.org/abs/2004.11862" rel="alternate" type="text/html"/>
    <title>Fr\'echet Distance for Uncertain Curves</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Buchin:Kevin.html">Kevin Buchin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fan:Chenglin.html">Chenglin Fan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/L=ouml=ffler:Maarten.html">Maarten Löffler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Popov:Aleksandr.html">Aleksandr Popov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raichel:Benjamin.html">Benjamin Raichel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roeloffzen:Marcel.html">Marcel Roeloffzen</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11862">PDF</a><br/><b>Abstract: </b>In this paper we study a wide range of variants for computing the (discrete
and continuous) Fr\'echet distance between uncertain curves. We define an
uncertain curve as a sequence of uncertainty regions, where each region is a
disk, a line segment, or a set of points. A realisation of a curve is a
polyline connecting one point from each region. Given an uncertain curve and a
second (certain or uncertain) curve, we seek to compute the lower and upper
bound Fr\'echet distance, which are the minimum and maximum Fr\'echet distance
for any realisations of the curves.
</p>
<p>We prove that both the upper and lower bound problems are NP-hard for the
continuous Fr\'echet distance in several uncertainty models, and that the upper
bound problem remains hard for the discrete Fr\'echet distance. In contrast,
the lower bound (discrete and continuous) Fr\'echet distance can be computed in
polynomial time. Furthermore, we show that computing the expected discrete
Fr\'echet distance is #P-hard when the uncertainty regions are modelled as
point sets or line segments. The construction also extends to show #P-hardness
for computing the continuous Fr\'echet distance when regions are modelled as
point sets.
</p>
<p>On the positive side, we argue that in any constant dimension there is a
FPTAS for the lower bound problem when $\Delta / \delta$ is polynomially
bounded, where $\delta$ is the Fr\'echet distance and $\Delta$ bounds the
diameter of the regions. We then argue there is a near-linear-time
3-approximation for the decision problem when the regions are convex and
roughly $\delta$-separated. Finally, we also study the setting with
Sakoe--Chiba time bands, where we restrict the alignment between the two
curves, and give polynomial-time algorithms for upper bound and expected
discrete and continuous Fr\'echet distance for uncertainty regions modelled as
point sets.
</p></div>
    </summary>
    <updated>2020-04-27T22:47:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11860</id>
    <link href="http://arxiv.org/abs/2004.11860" rel="alternate" type="text/html"/>
    <title>Optimal group testing under real world restrictions</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gebhard:Oliver.html">Oliver Gebhard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hahn=Klimroth:Max.html">Max Hahn-Klimroth</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parczyk:Olaf.html">Olaf Parczyk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Penschuck:Manuel.html">Manuel Penschuck</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rolvien:Maurice.html">Maurice Rolvien</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11860">PDF</a><br/><b>Abstract: </b>In the group testing problem one aims to infer a small set of $k$ infected
individuals out of a large population of size $n$. At our disposal we have a
testing scheme which allows us to test a group of individuals, such that the
outcome of the test is positive, if and only if at least one infected
individual is part of the test. All tests are carried out in parallel. The
overall goal is to find a test design and an inference algorithm requiring as
few tests as possible, such that the infected individuals can be identified
with high probability. As most relevant during the outbreak of pandemic
diseases (Wang et al., 2011), our analysis focusses on the so-called sublinear
regime of group testing, where $k \sim n^\theta$. The optimal group testing
schemes require a test-size of $\sim n/k$ and each individual has to take part
in $\sim \log n$ tests (Coja-Oghlan et. al, 2019). In real world applications,
like testing many individuals in a short period of time during the outbreak of
epidemics, pooling in such a way is not possible due to dilution effects.
Evidence of those effects is known for important applications like HIV (Wein,
1996) or COVID-19 (Seifried and Ciesek, 2020). Our main contribution is the
analysis of a group testing model, where we restrict the individuals-per-test
to be finite. We present an easy to implement scheme to pool individuals into
tests under these natural restrictions coming with the efficient decoding
algorithm DD and present simulations which suggest that the decoding procedure
succeeds for moderate population sizes. Furthermore, we show that our pooling
scheme requires the fewest tests as possible under all pooling schemes.
Finally, we apply our methods to the finitely many tests-per-individuals
setting, where we provide a full understanding of the random regular
test-design in this model by building up on work of (Gandikota et al., 2016).
</p></div>
    </summary>
    <updated>2020-04-27T22:41:52Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11796</id>
    <link href="http://arxiv.org/abs/2004.11796" rel="alternate" type="text/html"/>
    <title>Optimal Streaming Approximations for all Boolean Max-2CSPs</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chou:Chi=Ning.html">Chi-Ning Chou</a>, Alexander Golonev, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Velusamy:Santhoshini.html">Santhoshini Velusamy</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11796">PDF</a><br/><b>Abstract: </b>We prove tight upper and lower bounds on approximation ratios of all Boolean
Max-2CSP problems in the streaming model. Specifically, for every type of
Max-2CSP problem, we give an explicit constant $\alpha$, s.t. for any
$\epsilon&gt;0$ (i) there is an $(\alpha-\epsilon)$-streaming approximation using
space $O(\log{n})$; and (ii) any $(\alpha+\epsilon)$-streaming approximation
requires space $\Omega(\sqrt{n})$. This generalizes the celebrated work of
[Kapralov, Khanna, Sudan SODA 2015; Kapralov, Krachun STOC 2019], who showed
that the optimal approximation ratio for Max-CUT was $1/2$.
</p>
<p>Prior to this work, the problem of determining this ratio was open for all
other Max-2CSPs. Our results are quite surprising for some specific Max-2CSPs.
For the Max-DCUT problem, there was a gap between an upper bound of $1/2$ and a
lower bound of $2/5$ [Guruswami, Velingker, Velusamy APPROX 2017]. We show that
neither of these bounds is tight, and the optimal ratio for Max-DCUT is $4/9$.
We also establish that the tight approximation for Max-2SAT is $\sqrt{2}/2$,
and for Exact Max-2SAT it is $3/4$. As a byproduct, our result gives a
separation between space-efficient approximations for Max-2SAT and Exact
Max-2SAT. This is in sharp contrast to the setting of polynomial-time
algorithms with polynomial space, where the two problems are known to be
equally hard to approximate.
</p></div>
    </summary>
    <updated>2020-04-27T23:20:42Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11761</id>
    <link href="http://arxiv.org/abs/2004.11761" rel="alternate" type="text/html"/>
    <title>Incompressibility of H-free edge modification problems: Towards a dichotomy</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marx:D=aacute=niel.html">Dániel Marx</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sandeep:R=_B=.html">R. B. Sandeep</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11761">PDF</a><br/><b>Abstract: </b>Given a graph $G$ and an integer $k$, the $H$-free Edge Editing problem is to
find whether there exists at most $k$ pairs of vertices in $G$ such that
changing the adjacency of the pairs in $G$ results in a graph without any
induced copy of $H$. The existence of polynomial kernels for $H$-free Edge
Editing received significant attention in the parameterized complexity
literature. Nontrivial polynomial kernels are known to exist for some graphs
$H$ with at most 4 vertices, but starting from 5 vertices, polynomial kernels
are known only if $H$ is either complete or empty. This suggests the conjecture
that there is no other $H$ with at least 5 vertices were $H$-free Edge Editing
admits a polynomial kernel. Towards this goal, we obtain a set $\mathcal{H}$ of
nine 5-vertex graphs such that if for every $H\in\mathcal{H}$, $H$-free Edge
Editing is incompressible and the complexity assumption $NP \not\subseteq
coNP/poly$ holds, then $H$-free Edge Editing is incompressible for every graph
$H$ with at least five vertices that is neither complete nor empty. That is,
proving incompressibility for these nine graphs would give a complete
classification of the kernelization complexity of $H$-free Edge Editing for
every $H$ with at least 5 vertices.
</p>
<p>We obtain similar result also for $H$-free Edge Deletion. Here the picture is
more complicated due to the existence of another infinite family of graphs $H$
where the problem is trivial (graphs with exactly one edge). We obtain a larger
set $\mathcal{H}$ of nineteen graphs whose incompressibility would give a
complete classification of the kernelization complexity of $H$-free Edge
Deletion for every graph $H$ with at least 5 vertices. Analogous results follow
also for the $H$-free Edge Completion problem by simple complementation.
</p></div>
    </summary>
    <updated>2020-04-27T22:28:11Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11731</id>
    <link href="http://arxiv.org/abs/2004.11731" rel="alternate" type="text/html"/>
    <title>A 12/7-approximation algorithm for the discrete Bamboo Garden Trimming problem</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ee:Martijn_van.html">Martijn van Ee</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11731">PDF</a><br/><b>Abstract: </b>We study the discrete Bamboo Garden Trimming problem (BGT), where we are
given n bamboos with different growth rates. At the end of each day, one can
cut down one bamboo to height zero. The goal in BGT is to make a perpetual
schedule of cuts such that the height of the tallest bamboo ever is minimized.
Here, we improve the current best approximation guarantee by designing a
12/7-approximation algorithm. This result is based on a reduction to the
Pinwheel Scheduling problem. We show that a guarantee of 12/7 is essentially
the best we can hope for if our algorithm is based on this type of reduction.
</p></div>
    </summary>
    <updated>2020-04-27T22:41:46Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11666</id>
    <link href="http://arxiv.org/abs/2004.11666" rel="alternate" type="text/html"/>
    <title>Faster Parallel Multiterminal Cuts</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Henzinger:Monika.html">Monika Henzinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Noe:Alexander.html">Alexander Noe</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schulz:Christian.html">Christian Schulz</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11666">PDF</a><br/><b>Abstract: </b>We give an improved branch-and-bound solver for the multiterminal cut
problem, based on the recent work of Henzinger et al.. We contribute new,
highly effective data reduction rules to transform the graph into a smaller
equivalent instance. In addition, we present a local search algorithm that can
significantly improve a given solution to the multiterminal cut problem. Our
exact algorithm is able to give exact solutions to more and harder problems
compared to the state-of-the-art algorithm by Henzinger et al.; and give better
solutions for more than two third of the problems that are too large to be
solved to optimality. Additionally, we give an inexact heuristic algorithm that
computes high-quality solutions for very hard instances in reasonable time.
</p></div>
    </summary>
    <updated>2020-04-27T22:25:44Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11642</id>
    <link href="http://arxiv.org/abs/2004.11642" rel="alternate" type="text/html"/>
    <title>Robust testing of low-dimensional functions</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/De:Anindya.html">Anindya De</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mossel:Elchanan.html">Elchanan Mossel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Neeman:Joe.html">Joe Neeman</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11642">PDF</a><br/><b>Abstract: </b>A natural problem in high-dimensional inference is to decide if a classifier
$f:\mathbb{R}^n \rightarrow [-1,1]$ depends on a small number of linear
directions of its input data. Call a function $g: \mathbb{R}^n \rightarrow
[-1,1]$, a linear $k$-junta if it is completely determined by some
$k$-dimensional subspace of the input space. A recent work of the authors
showed that linear $k$-juntas are testable. Thus there exists an algorithm to
distinguish between:
</p>
<p>1. $f: \mathbb{R}^n \rightarrow \{-1,1\}$ which is a linear $k$-junta with
surface area $s$,
</p>
<p>2. $f$ is $\epsilon$-far from any linear $k$-junta, where the query
complexity of the algorithm is independent of the ambient dimension $n$.
</p>
<p>Following the surge of interest in noise-tolerant property testing, in this
paper we prove a noise-tolerant (or robust) version of this result. Namely, we
give an algorithm which given any $c&gt;0$, $\epsilon&gt;0$, distinguishes between
</p>
<p>1. $f: \mathbb{R}^n \rightarrow \{-1,1\}$ has correlation at least $c$ with
some linear $k$-junta with surface area $s$.
</p>
<p>2. $f$ has correlation at most $c-\epsilon$ with any linear $k$-junta.
</p>
<p>Our query complexity is qualitatively the same, i.e., remains independent of
$n$ and is polynomially dependent on $k$. A major motivation for studying
Linear Junta Testing come from statistical models where it is crucial to allow
noise. In the language of model compression, our results show statistical
models can be "compressed" in query complexity that depends only on the size of
the desired compression, when the compression is a linear Junta.
</p></div>
    </summary>
    <updated>2020-04-27T00:00:00Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11621</id>
    <link href="http://arxiv.org/abs/2004.11621" rel="alternate" type="text/html"/>
    <title>Computation of Hadwiger Number and Related Contraction Problems: Tight Lower Bounds</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fomin:Fedor_V=.html">Fedor V. Fomin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lokshtanov:Daniel.html">Daniel Lokshtanov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mihajlin:Ivan.html">Ivan Mihajlin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Saket.html">Saket Saurabh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zehavi:Meirav.html">Meirav Zehavi</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11621">PDF</a><br/><b>Abstract: </b>We prove that the Hadwiger number of an $n$-vertex graph $G$ (the maximum
size of a clique minor in $G$) cannot be computed in time $n^{o(n)}$, unless
the Exponential Time Hypothesis (ETH) fails. This resolves a well-known open
question in the area of exact exponential algorithms. The technique developed
for resolving the Hadwiger number problem has a wider applicability. We use it
to rule out the existence of $n^{o(n)}$-time algorithms (up to ETH) for a large
class of computational problems concerning edge contractions in graphs.
</p></div>
    </summary>
    <updated>2020-04-27T22:30:49Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Data Structures and Algorithms"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.DS" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Data Structures and Algorithms (cs.DS) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.DS updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11606</id>
    <link href="http://arxiv.org/abs/2004.11606" rel="alternate" type="text/html"/>
    <title>Homological Scaffold via Minimal Homology Bases</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guerra:Marco.html">Marco Guerra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gregorio:Alessandro_De.html">Alessandro De Gregorio</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fugacci:Ulderico.html">Ulderico Fugacci</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Petri:Giovanni.html">Giovanni Petri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vaccarino:Francesco.html">Francesco Vaccarino</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11606">PDF</a><br/><b>Abstract: </b>The homological scaffold leverages persistent homology to construct a
topologically sound summary of a weighted network. However, its crucial
dependency on the choice of representative cycles hinders the ability to trace
back global features onto individual network components, unless one provides a
principled way to make such a choice. In this paper, we apply recent advances
in the computation of minimal homology bases to introduce a quasi-canonical
version of the scaffold, called minimal, and employ it to analyze data both
real and in silico. At the same time, we verify that, statistically, the
standard scaffold is a good proxy of the minimal one for sufficiently complex
networks.
</p></div>
    </summary>
    <updated>2020-04-27T22:47:19Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11582</id>
    <link href="http://arxiv.org/abs/2004.11582" rel="alternate" type="text/html"/>
    <title>Small circuits and dual weak PHP in the universal theory of p-time algorithms</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b>Jan Krajicek <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11582">PDF</a><br/><b>Abstract: </b>We prove, under a computational complexity hypothesis, that it is consistent
with the true universal theory of p-time algorithms that a specific p-time
function extending $n$ bits to $m \geq n^2$ bits violates the dual weak
pigeonhole principle: every string $y$ of length $m$ equals to the value of the
function for some $x$ of length $n$. The function is the truth-table function
assigning to a circuit the table of the function it computes and the hypothesis
is that every language in P has circuits of a fixed polynomial size $n^d$.
</p></div>
    </summary>
    <updated>2020-04-27T23:20:29Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11568</id>
    <link href="http://arxiv.org/abs/2004.11568" rel="alternate" type="text/html"/>
    <title>Efficient Algorithms for Approximating Quantum Partition Functions</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mann:Ryan_L=.html">Ryan L. Mann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Helmuth:Tyler.html">Tyler Helmuth</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11568">PDF</a><br/><b>Abstract: </b>We establish a polynomial-time approximation algorithm for partition
functions of quantum spin models at high temperature. Our algorithm is based on
the quantum cluster expansion of Neto\v{c}n\`y and Redig and the cluster
expansion approach to designing algorithms due to Helmuth, Perkins, and Regts.
Similar results have previously been obtained by related methods, and our main
contribution is a simple and slightly sharper analysis for the case of pairwise
interactions on bounded-degree graphs.
</p></div>
    </summary>
    <updated>2020-04-27T23:20:32Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Complexity"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CC" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Complexity (cs.CC) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CC updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>

  <entry xml:lang="en-us">
    <id>http://arxiv.org/abs/2004.11540</id>
    <link href="http://arxiv.org/abs/2004.11540" rel="alternate" type="text/html"/>
    <title>Deep Global Registration</title>
    <feedworld_mtime>1587945600</feedworld_mtime>
    <summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Choy:Christopher.html">Christopher Choy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dong:Wei.html">Wei Dong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koltun:Vladlen.html">Vladlen Koltun</a> <br/><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11540">PDF</a><br/><b>Abstract: </b>We present Deep Global Registration, a differentiable framework for pairwise
registration of real-world 3D scans. Deep global registration is based on three
modules: a 6-dimensional convolutional network for correspondence confidence
prediction, a differentiable Weighted Procrustes algorithm for closed-form pose
estimation, and a robust gradient-based SE(3) optimizer for pose refinement.
Experiments demonstrate that our approach outperforms state-of-the-art methods,
both learning-based and classical, on real-world data.
</p></div>
    </summary>
    <updated>2020-04-27T22:42:21Z</updated>
    <author>
      <name/>
    </author>
    <source>
      <id>http://arxiv.org/</id>
      <category term="Computer Science -- Computational Geometry"/>
      <link href="http://arxiv.org/" rel="alternate" type="text/html"/>
      <link href="http://export.arxiv.org/rss/cs.CG" rel="self" type="application/rdf+xml"/>
      <subtitle>Computer Science -- Computational Geometry (cs.CG) updates on the arXiv.org e-print archive</subtitle>
      <title>cs.CG updates on arXiv.org</title>
      <updated>2020-04-27T01:30:00Z</updated>
    </source>
  </entry>
</feed>
